- en: Parallelism and Rayon
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 并行性与Rayon
- en: 'In this chapter, we will cover the following recipes:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将介绍以下食谱：
- en: Parallelizing iterators
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 并行化迭代器
- en: Running two operations together
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 同时运行两个操作
- en: Sending data across threads
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在线程间发送数据
- en: Sharing resources in multithreaded closures
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在多线程闭包中共享资源
- en: Accessing resources in parallel with RwLocks
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用RwLocks并行访问资源
- en: Atomically accessing primitives
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 原子访问原语
- en: Putting it all together in a connection handler
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在连接处理器中将所有内容组合在一起
- en: Introduction
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 简介
- en: There used to be a time when your code got faster every year automatically,
    as processors got better and better. But nowadays, as Herb Sutter famously stated,
    *The Free Lunch Is Over* ([http://www.gotw.ca/publications/concurrency-ddj.htm](http://www.gotw.ca/publications/concurrency-ddj.htm)).
    The age of not better, but more numerous processor cores arrived a long time ago.
    Not all programming languages are well suited for this radical change towards
    omnipresent concurrency.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 曾经有一段时间，随着处理器的不断升级，你的代码每年都会自动变快。但如今，正如Herb Sutter著名地指出，*免费午餐已经结束* ([http://www.gotw.ca/publications/concurrency-ddj.htm](http://www.gotw.ca/publications/concurrency-ddj.htm))。处理器核心数量增加而不是性能提升的时代已经很久远了。并不是所有编程语言都适合这种向无处不在的并发性的根本转变。
- en: 'Rust was designed with exactly this problem in mind. Its borrow checker makes
    sure that most concurrent algorithms work fine. It goes even further: your code
    won''t even compile if it''s not parallelizable, even if you don''t yet use more
    than one thread. Because of these unique guarantees, one of Rust''s main selling
    points has been dubbed *fearless concurrency*.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: Rust的设计正是针对这个问题。它的借用检查器确保大多数并发算法都能正常工作。它甚至更进一步：如果你的代码不可并行化，即使你还没有使用超过一个线程，你的代码甚至无法编译。正因为这些独特的保证，Rust的一个主要卖点被称作*无畏并发*。
- en: And we are about to find out why.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 我们即将找出原因。
- en: Parallelizing iterators
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 并行化迭代器
- en: Wouldn't it be cool to have a magic button that allowed you to just make any
    algorithm parallel, without you doing anything? Well, as long as your algorithm
    uses iterators, `rayon` is exactly that!
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 要有一个魔法按钮，让你能够轻松地将任何算法并行化，而不需要你做任何事情，岂不是很好？嗯，只要你的算法使用迭代器，`rayon`就是那个东西！
- en: How to do it...
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到这一点...
- en: Create a Rust project to work on during this chapter with `cargo new chapter-seven`.
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`cargo new chapter-seven`创建一个Rust项目，以便在本章中工作。
- en: Navigate into the newly-created `chapter-seven` folder. For the rest of this
    chapter, we will assume that your command line is currently in this directory.
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导航到新创建的`chapter-seven`文件夹。在本章的其余部分，我们将假设你的命令行当前位于此目录。
- en: Open the `Cargo.toml` file that has been generated for you.
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开为你生成的`Cargo.toml`文件。
- en: 'Under `[dependencies]`, add the following line:'
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`[dependencies]`下添加以下行：
- en: '[PRE0]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: If you want, you can go to `rayon`'s crates.io page ([https://crates.io/crates/rayon](https://crates.io/crates/rayon))
    to check for the newest version and use that one instead.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想，你可以访问`rayon`的crates.io页面([https://crates.io/crates/rayon](https://crates.io/crates/rayon))，检查最新版本并使用它。
- en: Inside the `src` folder, create a new folder called `bin`.
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`src`文件夹内，创建一个名为`bin`的新文件夹。
- en: Delete the generated `lib.rs` file, as we are not creating a library.
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 删除生成的`lib.rs`文件，因为我们不是在创建一个库。
- en: In the `src/bin` folder, create a file called `par_iter.rs`.
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`src/bin`文件夹中，创建一个名为`par_iter.rs`的文件。
- en: 'Add the following code and run it with `cargo run --bin par_iter`:'
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 添加以下代码，并使用`cargo run --bin par_iter`运行它：
- en: '[PRE1]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: How it works...
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: '`rayon` implements the trait `ParallelIterator` for every type that implements
    its standard library equivalent `Iterator`, which we got to know in [Chapter 2](977b8621-cb73-43de-9a2b-4bc9f5583542.xhtml),
    *Working with Collections; **Access Collections as iterators*. In fact, you can
    use all the knowledge from said recipe again here. The methods provided by the
    `ParallelIterator` trait are nearly the same as the ones provided by `Iterator`,
    so in virtually all cases where you notice an iterator operation taking too long
    and bottlenecking you, you can simply replace `.iter()` with `.par_iter()`[10].
    Similarly, for moving iterators, you can use `.into_par_iter()` instead of `.into_iter()`.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '`rayon`为每个实现了其标准库等效`Iterator`的类型的`ParallelIterator`特例实现了特例，我们在[第2章](977b8621-cb73-43de-9a2b-4bc9f5583542.xhtml)，*使用集合；**将集合作为迭代器访问*中了解到。实际上，你可以再次使用该食谱中的所有知识。`ParallelIterator`特例提供的方法几乎与`Iterator`提供的方法相同，所以几乎在所有你注意到迭代器操作耗时过长并成为瓶颈的情况下，你只需简单地将`.iter()`替换为`.par_iter()`[10]。同样，对于移动迭代器，你可以使用`.into_par_iter()`而不是`.into_iter()`。'
- en: '`rayon` handles all the tedious work for you, as it automatically distributes
    the work evenly between all of your available cores. Just keep in mind that despite
    this magic, you''re still dealing with parallelism here, so you have no guarantees
    about the order in which the items in your iterator are going to be handled, as
    evidenced by line [10], which will print in a different order each time you execute
    the program:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '`rayon` 会为你处理所有繁琐的工作，因为它会自动将工作均匀分配到所有可用的核心上。但请记住，尽管有这种魔法，你仍然在处理并行性，因此你无法保证迭代器中项的处理顺序，正如第
    [10] 行所示，每次执行程序时都会以不同的顺序打印：'
- en: '[PRE2]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: See also
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参见
- en: '*Access collections as iterators* recipe in [Chapter 2](977b8621-cb73-43de-9a2b-4bc9f5583542.xhtml),
    *Working with Collections*'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*访问集合作为迭代器*菜谱在[第2章](977b8621-cb73-43de-9a2b-4bc9f5583542.xhtml)，*与集合一起工作*'
- en: Running two operations together
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 同时运行两个操作
- en: The parallel iterators from the last recipe are internally built upon a more
    fundamental function, `rayon::join`, which takes two closures and *potentially*
    runs them in parallel. This way, even the balance of performance gain versus the
    overhead of spawning a thread has been done for you.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 上一个菜谱中的并行迭代器在内部基于一个更基本的功能构建，即 `rayon::join`，它接受两个闭包并*可能*并行运行它们。这样，性能提升与启动线程开销之间的平衡也已经为你完成。
- en: If you have an algorithm that doesn't use iterators but still consists of some
    clearly separated parts that could benefit from running concurrently, consider
    using `rayon::join` for that.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你有一个不使用迭代器但仍然由一些明显分离的部分组成且可以从并行运行中受益的算法，考虑使用 `rayon::join`。
- en: How to do it...
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到这一点...
- en: Open the `Cargo.toml` file that was generated earlier for you.
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开之前为你生成的 `Cargo.toml` 文件。
- en: 'If you didn''t do so in the last recipe, under `[dependencies]`, add the following
    line:'
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你在上一个菜谱中没有这样做，请在 `[dependencies]` 下添加以下行：
- en: '[PRE3]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: If you want, you can go to `rayon`'s crates.io page ([https://crates.io/crates/rayon](https://crates.io/crates/rayon))
    to check for the newest version and use that one instead.
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你想，你可以访问 `rayon` 的 crates.io 页面([https://crates.io/crates/rayon](https://crates.io/crates/rayon))，检查最新版本并使用它。
- en: In the folder `bin`, create a file called `join.rs`.
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `bin` 文件夹中创建一个名为 `join.rs` 的文件。
- en: 'Add the following code and run it with `cargo run --bin join`:'
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 添加以下代码，并使用 `cargo run --bin join` 运行：
- en: '[PRE4]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: How it works...
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: '`rayon::join` is pretty simple. It takes two closures, potentially runs them
    in parallel, and returns their returned values in a tuple [25]. Wait a second,
    did we just say *potentially*? Isn''t it always better to run things in parallel?'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '`rayon::join` 非常简单。它接受两个闭包，*可能*并行运行它们，并以元组的形式返回它们的返回值 [25]。等等，我们刚刚说了*可能*？难道不是总是并行运行事物更好吗？'
- en: Nope, at least not always. Sure, if you really care about things running together
    at all times without blocking, say a GUI and its underlying I/O where you definitely
    don't want the mouse cursor to freeze when opening a file, you always need to
    have all processes running in their own thread. But most applications for concurrency
    don't have this requirement. A big part of what makes concurrency so important
    is its ability to run code that would normally run sequentially (that is, one
    line after another) in parallel if required. Notice the choice of words here—*code
    that would normally run sequentially*. These kinds of algorithms do not inherently
    need concurrency, but they might get a boost out of it. Now comes the *potential*
    part—firing up a thread might not be worth it.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 不，至少不是总是这样。当然，如果你真的在乎事物始终一起运行而不阻塞，比如说一个GUI及其底层的I/O，你绝对不希望当打开文件时鼠标光标冻结，你总是需要所有进程在自己的线程中运行。但大多数并发应用程序没有这个要求。并发之所以如此重要的一个重要部分是它能够并行运行通常按顺序（即，一行接一行）运行的代码。注意这里的措辞—*通常按顺序运行的代码*。这类算法本身不需要并发，但它们可能会从中受益。现在来说说*潜在*的部分—启动一个线程可能并不值得。
- en: 'To understand why, let''s look at the hardware side of things. We are not going
    to dive too deep into this territory because:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解原因，让我们看看硬件方面。我们不会深入这个领域，因为：
- en: a) the fact that you're reading this book makes me think you're more of a software
    person and b) the exact mechanisms of CPUs tend to change very rapidly nowadays
    and we don't want the information provided here to be outdated in a year.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: a) 你在读这本书的事实让我认为你更倾向于软件人员，b) CPU的确切机制现在变化非常快，我们不希望这里提供的信息在一年后过时。
- en: Your CPU divides its work among its *cores*. A core is the basic computation
    unit of the CPU. If the device you're reading this on is not made out of paper
    and younger than two decades, it most probably contains multiple cores. These
    kinds of cores are called *physical* and can work on different things at the same
    time. A physical core itself also has ways to perform multiple jobs. Some can
    divide themselves into multiple *logical* cores, splitting work further. For example,
    an Intel CPU can use *hyper-threading*, which means that if a program only uses
    the integer addition unit of a physical core, a virtual core might start working
    on the floating points addition unit for another program until the first one is
    done.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 你的 CPU 将其工作分配给其 *核心*。核心是 CPU 的基本计算单元。如果你正在阅读此内容的设备不是用纸做的，并且不到二十年，它很可能包含多个核心。这类核心被称为
    *物理*，可以同时处理不同的事情。物理核心本身也有执行多项任务的方法。一些可以将自己分成多个 *逻辑* 核心，进一步分割工作。例如，英特尔 CPU 可以使用
    *超线程*，这意味着如果一个程序只使用物理核心的整数加法单元，一个虚拟核心可能会开始为另一个程序处理浮点数加法单元，直到第一个完成。
- en: If you don't care about the available amount of cores and simply start new threads
    without limit, the operating system will start creating threads that don't actually
    run concurrently, because it ran out of cores. In this case, it will perform *context
    switching*, which means that it stores the current state of the thread, pauses
    it, works on another thread for a split second, and then resumes the thread again.
    As you can imagine, this costs quite some resources.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你不在乎可用的核心数量，并且无限制地启动新线程，操作系统将开始创建实际上不会并发运行的线程，因为它已经没有核心了。在这种情况下，它将执行 *上下文切换*，这意味着它存储线程的当前状态，暂停它，短暂地处理另一个线程，然后再次恢复线程。正如你可以想象的那样，这会消耗相当多的资源。
- en: This is why if it's not vital to run two things in parallel, you should first
    check if there are any cores *idle* (that is, available) in the first place. Because
    `rayon::join` does this check for you; among other things, it will only run the
    two closures in parallel if it's actually worth it to do so. If you need to do
    this work yourself, check out the `num_cpus` crate ([https://crates.io/crates/num_cpus](https://crates.io/crates/num_cpus)).
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是为什么如果并行运行两件事不是至关重要，你应该首先检查是否真的有任何 *空闲*（即可用）的核心。因为 `rayon::join` 会为你做这个检查；除此之外，它只有在这样做真正值得时才会并行运行两个闭包。如果你需要自己执行这项工作，请查看
    `num_cpus` crate ([https://crates.io/crates/num_cpus](https://crates.io/crates/num_cpus))。
- en: 'By the way, the parallel iterators from the last recipe go even further: If
    the amount of elements and work in them is so small that it would cost more to
    initiate a new thread for them than to run it sequentially, they will automatically
    forego concurrency for you.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 顺便说一下，上道菜谱中的并行迭代器更进一步：如果元素的数量和工作量如此之小，以至于为它们启动一个新线程的成本比顺序运行它们还要高，它们将自动放弃并发为你。
- en: There's more...
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: 'The underlying mechanism of `rayon` is *work stealing*. This means that when
    we call the following function, the current thread will immediately start working
    on `a` and place `b` in a queue:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '`rayon` 的底层机制是 *工作窃取*。这意味着当我们调用以下函数时，当前线程将立即开始处理 `a` 并将 `b` 放入队列：'
- en: '[PRE5]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Meanwhile, whenever a core is idle, `rayon` will let it work on the next task
    in the queue. The new thread then *steals* the task from the others. In our case,
    that would be `b`. If `a` happens to finish before `b`, the main thread will look
    into the queue and try to steal work as well. The queue can contain more than
    two items if `rayon::join` is called multiple times in a recursive function.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 同时，每当一个核心空闲时，`rayon` 将允许它处理队列中的下一个任务。然后新线程会从其他线程中“窃取”任务。在我们的例子中，那将是 `b`。如果 `a`
    比意外地先于 `b` 完成，主线程将检查队列并尝试窃取工作。如果递归函数中多次调用 `rayon::join`，队列可以包含超过两个项目。
- en: 'The author of `rayon`, Niko Matsakis, wrote down the following pseudo Rust
    code to illustrate this principle in his introductory blog post at [http://smallcultfollowing.com/babysteps/blog/2015/12/18/rayon-data-parallelism-in-rust/](http://smallcultfollowing.com/babysteps/blog/2015/12/18/rayon-data-parallelism-in-rust/):'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '`rayon` 的作者 Niko Matsakis 在他的介绍博客文章中写下了以下伪 Rust 代码，以说明这一原则：[http://smallcultfollowing.com/babysteps/blog/2015/12/18/rayon-data-parallelism-in-rust/](http://smallcultfollowing.com/babysteps/blog/2015/12/18/rayon-data-parallelism-in-rust/)：'
- en: '[PRE6]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: By the way, the recursive Fibonacci implementation provided in this example
    [34] is easy to look at and illustrates the point of using `rayon::join`, but
    is also really, really inefficient. To learn why, and how to improve on it, check
    out the [Chapter 10](f2c7ca21-145e-40af-8502-8b42b37fe290.xhtml), *Using Experimental
    Nightly Features*; *Benchmarking your code**.*
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 顺便说一下，这个例子中提供的递归斐波那契实现[34]很容易查看，并说明了使用`rayon::join`的目的，但也是非常不高效的。要了解为什么，以及如何改进它，请查看第10章[Chapter
    10](f2c7ca21-145e-40af-8502-8b42b37fe290.xhtml)，*使用实验性夜间功能*；*基准测试你的代码**.*
- en: See also
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参见
- en: '*Benchmarking your code* recipe in [Chapter 10](f2c7ca21-145e-40af-8502-8b42b37fe290.xhtml),
    *Using Experimental Nightly Features*'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第10章[Chapter 10](f2c7ca21-145e-40af-8502-8b42b37fe290.xhtml)，*使用实验性夜间功能*中的*基准测试你的代码*配方
- en: Sharing resources in multithreaded closures
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在多线程闭包中共享资源
- en: It's time to look at parallelism at a lower level, without any crates to help
    us. We will now check out how to share a resource across threads so that they
    all can work with the same object. This recipe will also serve as a refresher
    on manually creating threads, in case it's been a while since you learned about
    it.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 是时候在更低的层面上查看并行性，而不需要任何帮助我们的crate。我们现在将检查如何跨线程共享资源，以便它们都可以使用同一个对象。这个配方也将作为手动创建线程的复习，以防你很久以前就学过它。
- en: How to do it...
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到...
- en: In the folder `bin`, create a file called `sharing_in_closures.rs`.
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`bin`文件夹中创建一个名为`sharing_in_closures.rs`的文件。
- en: 'Add the following code and run it with `cargo run --bin sharing_in_closures`:'
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 添加以下代码，并用`cargo run --bin sharing_in_closures`运行它：
- en: '[PRE7]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: How it works...
  id: totrans-68
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'A fundamental building block of parallelism in Rust is the `Arc`, which stands
    for **Atomically Reference Counted**. Functionally, it works the same way as an
    `Rc`, which we have looked at in [Chapter 5](6b8b0c3c-2644-4684-b1f4-b1e08d62450c.xhtml),
    *Advanced Data Structures*; *Sharing ownership with smart pointers*. The only
    difference is that the reference counting is done using *atomic primitives*, which
    are versions of primitive data types like `usize` that have well-defined parallel
    interactions. This has two consequences:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: Rust中并行性的基本构建块是`Arc`，代表**原子引用计数**。功能上，它的工作方式与我们在[Chapter 5](6b8b0c3c-2644-4684-b1f4-b1e08d62450c.xhtml)，*高级数据结构*；*与智能指针共享所有权*中看到的`Rc`相同。唯一的区别是引用计数是使用*原子原语*完成的，这些是具有良好定义的并行交互的原生数据类型的版本，如`usize`。这有两个后果：
- en: An `Arc` is slightly slower than an `Rc`, as the reference counting involves
    a bit more work
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Arc`比`Rc`慢一点，因为引用计数涉及更多的工作'
- en: An `Arc` can be used safely across threads
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Arc`可以在线程间安全地使用'
- en: 'The constructor of `Arc` looks the same as `Rc`[7]:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '`Arc`的构造函数看起来与`Rc`[7]相同：'
- en: '[PRE8]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: This creates an `Arc` over a `String`. A `String` is a `struct` that is not
    inherently saved to be manipulated across threads. In Rust terms, we say that
    `String` is not `Sync` (more about that later in the recipe *Atomically access
    primitives*).
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 这创建了一个覆盖`String`的`Arc`。`String`是一个`struct`，它不是天生就保存下来以便跨线程操作的。在Rust术语中，我们说`String`不是`Sync`（关于这一点，稍后在配方*原子访问原语*中会详细介绍）。
- en: Now let's look at how a thread is initialized. `thread::spawn()` takes a closure
    and executes it in a new thread. Because this is done in parallel, the main thread
    doesn't wait until the thread is done; it continues working right after its creation.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看线程是如何初始化的。`thread::spawn()`接受一个闭包并在新线程中执行它。因为这是并行执行的，所以主线程不会等待线程完成；它在创建后立即继续工作。
- en: 'The following creates a thread that prints out the content of `some_resource`
    and gives us a handle to that thread called `thread_a`[10]:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 以下创建了一个线程，该线程打印出`some_resource`的内容，并为我们提供了一个名为`thread_a`的线程句柄[10]：
- en: '[PRE9]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Afterward (or at the same time), we do the exact same thing in a second thread
    called `thread_b`.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 之后（或同时），我们在第二个线程`thread_b`中做完全相同的事情。
- en: To understand why we need an `Arc` and can't just pass the resource directly
    to the closure, let's take a closer look at how closures work.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解为什么我们需要`Arc`而不能直接将资源传递给闭包，让我们更仔细地看看闭包是如何工作的。
- en: 'Closures in Rust can only operate on three kinds of variables:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: Rust中的闭包只能操作三种类型的变量：
- en: Arguments passed to them
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 传递给它们的参数
- en: '`static` variables (variables with the `''static` lifetime; see [Chapter 5](6b8b0c3c-2644-4684-b1f4-b1e08d62450c.xhtml),
    *Advanced Data Structures*; *Creating lazy static objects*)'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`static`变量（具有`''static`生命周期的变量；参见[Chapter 5](6b8b0c3c-2644-4684-b1f4-b1e08d62450c.xhtml)，*高级数据结构*；*创建懒加载静态对象*）'
- en: Variables it owns, either by creating them or by moving them into the closure
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它拥有的变量，无论是通过创建还是通过将它们移动到闭包中
- en: 'With this in mind, let''s look at the most simplistic approach an inexperienced
    Rust programmer might take:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到这一点，让我们看看一个没有经验的Rust程序员可能会采取的最简单的方法：
- en: '[PRE10]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'If we try to run this, the compiler tells us the following:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们尝试运行这个程序，编译器会告诉我们以下信息：
- en: '![](img/b102a819-7de0-4337-a3a5-008a19f5c43f.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b102a819-7de0-4337-a3a5-008a19f5c43f.png)'
- en: 'Seems like it doesn''t like our usage of `some_resource`. Look at the rules
    for variable usage in closures again:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来它不喜欢我们使用 `some_resource` 的方式。再次看看闭包中变量使用的规则：
- en: '`some_resource` has not been passed as an argument'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`some_resource` 没有被作为参数传递'
- en: It is not `static`
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它不是 `static`
- en: It was neither created in the closure nor moved into it
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它既没有被创建在闭包中，也没有被移动到闭包中
- en: 'But what does *closure may outlive the current function* mean? Well, because
    closures can be stored in a normal variable, they can be returned from a function.
    Imagine now if we programmed a function that created a variable called `some_resource`,
    used it inside a closure, and returned it. Since the function owns `some_resource`,
    it would be dropped while returning the closure, making any reference to it invalid.
    We don''t want any invalid variables, so the compiler stops us from potentially
    enabling them. Instead, it suggests moving the ownership of `some_resource` into
    the closure by using the `move` keyword. Let''s try that:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 但“闭包可能比当前函数存活时间更长”是什么意思呢？嗯，因为闭包可以被存储在普通变量中，所以它们可以从函数中返回。想象一下，如果我们编写了一个函数，创建了一个名为
    `some_resource` 的变量，在闭包中使用它，然后返回它。由于函数拥有 `some_resource`，在返回闭包时会丢弃它，使得对它的任何引用都变得无效。我们不希望有任何无效的变量，所以编译器阻止我们可能启用它们。相反，它建议使用
    `move` 关键字将 `some_resource` 的所有权移动到闭包中。让我们试试：
- en: '[PRE11]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The compiler responds with this:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 编译器给出了以下响应：
- en: '![](img/adf522f0-4203-4965-bc7c-ca33345a722e.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![](img/adf522f0-4203-4965-bc7c-ca33345a722e.png)'
- en: 'Because we moved `some_resource` into the closure inside of `thread_a`, `thread_b`
    can no longer use it! The solution is to create a clone of the reference to `some_resource`
    and only move the clone into the closure:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 因为我们将 `some_resource` 移动到了 `thread_a` 中的闭包内部，`thread_b` 就不能再使用它了！解决方案是创建 `some_resource`
    引用的一个副本，并且只将副本移动到闭包中：
- en: '[PRE12]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'This now runs perfectly fine, but it looks a bit weird, as we are now carrying
    the mental baggage of the knowledge that the resource we''re dealing with is,
    in fact, a `clone`. This can be solved in a more elegant way by putting the clone
    into a new scope, where it can have the same name as the original, leaving us
    with the final version of our code:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 现在运行得很好，但看起来有点奇怪，因为我们现在带着关于我们正在处理的资源实际上是一个 `clone` 的知识负担。这可以通过将副本放入一个新的作用域中并使用与原始变量相同的名称来解决，这样我们就得到了我们代码的最终版本：
- en: '[PRE13]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Looks way clearer, doesn't it? This way of passing `Rc` and `Arc` variables
    to a closure is a well-known Rust idiom that we are going to use in all other
    recipes of the chapter from here on out.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来清晰多了，不是吗？这种将 `Rc` 和 `Arc` 变量传递给闭包的方式是Rust中众所周知的一种惯用法，从现在起我们将在这个章节的所有其他菜谱中使用它。
- en: The last thing we are going to do in this recipe is join the two threads by
    calling `.join()` on them [26 and 27]. Joining a thread means blocking the current
    thread until the joined thread is done with its work. It's called like that because
    we *join the two threads of our program back into a single one*. It helps to visually
    imagine actual sewing threads when thinking about this concept.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱的最后，我们将通过在它们上调用 `.join()` 来合并两个线程 [26 和 27]。合并一个线程意味着阻塞当前线程，直到合并的线程完成其工作。之所以这样称呼，是因为我们将程序的两个线程合并为一个单一的线程。在思考这个概念时，想象实际的缝纫线会有所帮助。
- en: We join them before the end of the program, as otherwise, we would have no guarantee
    that they would actually run all the way through before our program quits. Generally
    speaking, you should `join` your threads when you need their results and can't
    wait for them any longer, or they're about to be dropped otherwise.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在程序结束之前合并它们，否则我们无法保证它们在我们程序退出之前真正运行到底。一般来说，当你需要线程的结果并且不能再等待它们时，或者它们即将被丢弃时，你应该
    `join` 你的线程。
- en: See also
  id: totrans-103
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参见
- en: '*Sharing ownership with smart pointers* and *Creating lazy static objects*
    recipes in [Chapter 5](6b8b0c3c-2644-4684-b1f4-b1e08d62450c.xhtml), *Advanced
    Data Structures*'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第5章](6b8b0c3c-2644-4684-b1f4-b1e08d62450c.xhtml)中的*使用智能指针共享所有权*和*创建懒加载静态对象*菜谱'
- en: Sending data across threads
  id: totrans-105
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在线程间发送数据
- en: So far, we've looked at threads that work independently. Now, let's take a look
    at intertwined threads that need to share data. This situation is common when
    setting up servers, as the thread receiving client messages is usually not the
    same as the one that actually handles and responds to the client input. Rust gives
    us the concept of *channels* as a solution. A channel is split into a *sender*
    and a *receiver* which can share data across threads.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已查看独立工作的线程。现在，让我们看看需要共享数据的交织线程。在设置服务器时，这种情况很常见，因为接收客户端消息的线程通常与实际处理和响应客户端输入的线程不同。Rust
    通过提供 *通道* 的概念作为解决方案。通道被分为 *发送者* 和 *接收者*，它们可以在线程之间共享数据。
- en: How to do it...
  id: totrans-107
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到这一点...
- en: Open the `Cargo.toml` file that was  generated earlier for you.
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开之前为您生成的 `Cargo.toml` 文件。
- en: 'Under `[dependencies]`, add the following line:'
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `[dependencies]` 下添加以下行：
- en: '[PRE14]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: If you want, you can go to rand's crates.io page ([https://crates.io/crates/rand](https://crates.io/crates/rand))
    to check for the newest version and use that one instead.
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你想，你可以访问 rand 的 crates.io 页面 ([https://crates.io/crates/rand](https://crates.io/crates/rand))
    检查最新版本并使用它。
- en: In the folder `bin`, create a file called `channels.rs`.
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `bin` 文件夹中，创建一个名为 `channels.rs` 的文件。
- en: 'Add the following code and run it with `cargo run --bin channels`:'
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 添加以下代码，并用 `cargo run --bin channels` 运行它：
- en: '[PRE15]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: How it works...
  id: totrans-115
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: As explained in the comments of the code, calling `std::sync::mpsc::channel()`
    generates a tuple consisting of a `Sender` and a `Receiver`, which are conventionally
    called `tx` for *transmission* and `rx` for *reception* [12].
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 如代码注释中所述，调用 `std::sync::mpsc::channel()` 会生成一个包含 `Sender` 和 `Receiver` 的元组，它们通常被称为
    `tx` 用于 *传输* 和 `rx` 用于 *接收* [12]。
- en: This naming convention doesn't come from Rust, but has been a standard in the
    telecommunications industry since at least 1960 when the RS-232 (**Recommended
    Standard 232**) was introduced, detailing how computers and modems should communicate
    with each other.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 这种命名约定并非来自 Rust，但自至少 1960 年 RS-232（**推荐标准 232**）被引入以来，一直是电信行业的标准，详细说明了计算机和调制解调器应该如何相互通信。
- en: 'These two halves of the same channel can communicate with each other independently
    of the current thread they''re in. The module''s name, `mspc`, tells us that this
    channel is a `Multi-producer, single-consumer` channel, which means that we can
    `clone` our sender as many times as we want. We can use this fact to our advantage
    when dealing with closures [16 to 21]:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 同一通道的这两部分可以在它们所在的当前线程之外独立地相互通信。模块的名称 `mspc` 告诉我们这个通道是一个 `多生产者，单消费者` 通道，这意味着我们可以按需多次
    `克隆` 我们的消息发送者。在处理闭包时，我们可以利用这一事实 [16 到 21]：
- en: '[PRE16]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: We do not need to wrap our sender in an `Arc`, because it natively supports
    arbitrary cloning! Inside of the closure you can see the sender's main functionality.
    The `send()` method sends data across threads to the receiver. It will return
    an error if the receiver is not available anymore, as in when it is dropped too
    early. In this thread here, we will simply send the numbers `0` to `9` concurrently
    to the receiver. One thing to note is that because a channel's halves are statically
    typed, they are only going to be able to send one specific data type around. If
    the first thing you send is an `i32`, your channel will only work with `i32`.
    If you send a `String`, it will be a `String` channel.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不需要将我们的发送者包裹在 `Arc` 中，因为它原生支持任意克隆！在闭包内部，你可以看到发送者的主要功能。`send()` 方法将数据发送到接收者所在的线程。如果接收者不再可用，例如它被过早地丢弃，它将返回一个错误。在这个线程中，我们将简单地并发地向接收者发送数字
    `0` 到 `9`。需要注意的是，由于通道的两部分是静态类型的，它们只能发送一种特定的数据类型。如果你首先发送一个 `i32`，你的通道将只能与 `i32`
    一起工作。如果你发送一个 `String`，它将是一个 `String` 通道。
- en: 'On to the receiver we go [23 to 28]:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来是接收者 [23 到 28]：
- en: '[PRE17]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: The `recv()` method, which stands for *receive*, blocks the current thread until
    a message has arrived. Similar to its counterpart, it returns an error if the
    sender is unavailable. Because we know that we only sent 10 messages, we only
    call it 10 times. There is no need to explicitly `join` the threads we created
    for the sender, because `recv()` blocked the main thread until no more messages
    were left, which means that the sender finished sending all they had to send,
    that is, all the threads already finished their job. This way, we already joined
    them.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '`recv()` 方法代表 *接收*，它会阻塞当前线程，直到收到消息。与它的对应方法类似，如果发送者不可用，它会返回一个错误。因为我们知道我们只发送了
    10 条消息，所以我们只调用它 10 次。我们没有必要显式地 `join` 我们为发送者创建的线程，因为 `recv()` 阻塞了主线程，直到没有更多消息为止，这意味着发送者已经发送了所有需要发送的消息，也就是说，所有线程已经完成了它们的工作。这样，我们实际上已经将它们连接在一起了。'
- en: But in real life, you do not have a guarantee about the amount of times a client
    will send information to you. For a more realistic demonstration, we will now
    create a thread that sends random messages [37] to the receiver until it finally
    has enough and quits by sending `"Goodbye!"` [48]. Note how we created a new channel
    pair, as the old one was set to the type `i32 ` because integer literals such
    as `1` or `2` are treated as `i32` by default.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 但在现实生活中，你无法保证客户端会向你发送信息的次数。为了更现实的演示，我们现在将创建一个线程，该线程会向接收者发送随机消息 [37]，直到它最终发送足够多的消息并退出，发送
    `"Goodbye!"` [48]。注意我们如何创建了一个新的通道对，因为旧的通道被设置为 `i32` 类型，因为默认情况下整数字面量（如 `1` 或 `2`）被视为
    `i32`。
- en: 'While the sending code looks almost identical to the one before, the receiving
    end looks a bit different [55 to 57]:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然发送代码看起来几乎与之前相同，但接收端看起来略有不同 [55 到 57]：
- en: '[PRE18]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: As you can see, a receiver can be iterated over. It behaves like an infinite
    iterator over all messages that will ever come, blocking when waiting for a new
    one, similar to calling `recv()` in a loop. The difference is that the iteration
    will automatically stop when the sender is unavailable. Because we terminate the
    sending thread when it sends `"Goodbye!"` [48], this iteration over the receiver
    will also stop when receiving it, as the sender will have been dropped at that
    point. Because this means that we have a guarantee about the sending thread being
    finished, we do not need to join it.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，接收者可以被迭代。它表现得像一个无限迭代器，遍历所有将来的消息，等待新消息时阻塞，类似于在循环中调用 `recv()`。区别在于，当发送者不可用时，迭代会自动停止。因为我们当发送者发送
    `"Goodbye!"` [48] 时终止发送线程，所以当接收它时，这个接收者的迭代也会停止，因为此时发送者已经被丢弃。因为这意味着我们有发送线程完成的确切保证，所以我们不需要将其连接。
- en: There's more...
  id: totrans-128
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: A channel is not `Sync` and, as such, can only be moved across channels but
    not shared between them. If you need the channel to be `Sync` you can use `std::sync::mpsc::sync_channel`,
    which blocks when a buffer of unanswered messages is full. An example for when
    this might be necessary is when a web framework offers to manage your types but
    only works with `Sync` structs. You can read more on `Sync` in the recipe *Atomically
    access primitives*.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 通道不是 `Sync`，因此只能跨通道移动，但不能在它们之间共享。如果您需要通道是 `Sync`，可以使用 `std::sync::mpsc::sync_channel`，当未回答的消息缓冲区满时，它会阻塞。一个可能需要这种情况的例子是，当网络框架提供管理您的类型，但只与
    `Sync` 结构一起工作时。您可以在 *原子访问原语* 的配方中了解更多关于 `Sync` 的信息。
- en: The `mpsc` channels, as their name suggests, allow many senders but only one
    receiver. Most of the time, this will be good enough, but if you find yourself
    needing the exact opposite, as in one sender and multiple receivers, check out
    Sean McArthur's `spmc` crate at [https://crates.io/crates/spmc](https://crates.io/crates/spmc),
    which provides you with `Single-producer, multi-consumer` channels.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 如其名称所示，`mpsc` 通道允许多个发送者，但只有一个接收者。大多数时候，这已经足够好了，但如果您发现自己需要完全相反的情况，即一个发送者和多个接收者，请查看
    Sean McArthur 的 `spmc` crate，网址为 [https://crates.io/crates/spmc](https://crates.io/crates/spmc)，它为您提供了
    `单生产者，多消费者` 通道。
- en: See also
  id: totrans-131
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参见
- en: '*Access collections as Iterator* recipe in [Chapter 2](977b8621-cb73-43de-9a2b-4bc9f5583542.xhtml),
    *Working with Collections*'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 [第 2 章](977b8621-cb73-43de-9a2b-4bc9f5583542.xhtml) 的 *访问集合作为迭代器* 配方中，*与集合一起工作*。
- en: Accessing resources in parallel with RwLocks
  id: totrans-133
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 RwLocks 并行访问资源
- en: 'When we shared resources with an `Arc`, we only did so immutably. The moment
    we want our threads to mutate our resources, we need to use some kind of locking
    mechanism to secure the golden rule of parallelism: multiple readers or one writer.
    `RwLock` enforces just that rule across threads and blocks them if they violate
    the rule.'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们使用 `Arc` 共享资源时，我们只以不可变的方式这样做。当我们想要我们的线程修改资源时，我们需要使用某种锁定机制来确保并行主义的黄金法则：多个读者或一个写者。`RwLock`
    在线程之间强制执行这一规则，并在它们违反规则时阻塞它们。
- en: How to do it...
  id: totrans-135
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: In the folder `bin`, create a file called `rw_lock.rs`.
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `bin` 文件夹中创建一个名为 `rw_lock.rs` 的文件。
- en: 'Add the following code and run it with `cargo run --bin rwlock`:'
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 添加以下代码并使用 `cargo run --bin rwlock` 运行它：
- en: '[PRE19]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: How it works...
  id: totrans-139
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: The `RwLock` is the parallel equivalent of the `RefCell` we worked with in [Chapter
    5](6b8b0c3c-2644-4684-b1f4-b1e08d62450c.xhtml), *Advanced Data Structures**;*
    *Working with interior mutability*. The big difference is that, while `RefCell`
    panics on a violation of Rust's ownership concept, `RwLock` simply blocks the
    current thread until the violation is over.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '`RwLock` 是我们在 [第 5 章](6b8b0c3c-2644-4684-b1f4-b1e08d62450c.xhtml)，“高级数据结构”；“处理内部可变性”中使用的
    `RefCell` 的并行等价物。两者之间的大不同是，虽然 `RefCell` 在违反 Rust 的所有权概念时会引发恐慌，但 `RwLock` 只是简单地阻塞当前线程，直到违反行为结束。'
- en: The analog of the `borrow()` method of `RefCell` is `read()` [17], which locks
    the resource for immutable access. The analog of `borrow_mut()` is `write()` [51],
    which locks the resource for mutable access. Makes sense, doesn't it?
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '`RefCell` 的 `borrow()` 方法的对应物是 `read()` [17]，它锁定资源以进行不可变访问。`borrow_mut()` 的对应物是
    `write()` [51]，它锁定资源以进行可变访问。这说得通，不是吗？'
- en: These methods return a `Result`, which tells us whether the thread is *poisoned*.
    The meaning of poisoning is different for every lock. In an `RwLock`, it means
    that the thread that locked the resource for `write` access panicked. This way,
    you can react to panics in other threads and treat them in some way. One example
    where this can be useful is sending some logs to a server before a crash happens
    in order to diagnose the problem. In most cases, though, it will be okay if you
    simply `panic` along, as a `panic` usually stands for a critical failure that
    cannot be mended.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 这些方法返回一个 `Result`，它告诉我们线程是否已被 *毒化*。对于每个锁，毒化的含义都不同。在 `RwLock` 中，这意味着锁定资源进行 `write`
    访问的线程发生了恐慌。这样，你可以对其他线程中的恐慌做出反应并以某种方式处理它们。一个这样的例子是在崩溃发生之前向服务器发送一些日志以便诊断问题。然而，在大多数情况下，如果你简单地
    `panic`，通常就足够了，因为 `panic` 通常代表无法修复的严重故障。
- en: 'In our example, we demonstrate the concept by setting up two threads that request
    `read` access: `reader_a` [11] and `reader_b` [27]. Because an `RwLock` allows
    multiple readers, they will concurrently print out the value of our resource [19
    and 35]. In the meantime, `writer` [45] tries to lock the resource for `write`
    access. It will have to wait until both `reader_a` and `reader_b` are currently
    not using the resource. By the same rules, when the `writer` gets their turn and
    mutates the resource [54], both `reader_a` and `reader_b` have to wait until it''s
    done.'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的示例中，我们通过设置两个请求 `read` 访问权限的线程来展示这个概念：`reader_a` [11] 和 `reader_b` [27]。由于
    `RwLock` 允许多个读者，它们将并发地打印出我们资源的值 [19 和 35]。与此同时，`writer` [45] 尝试锁定资源以进行 `write`
    访问。它必须等待直到 `reader_a` 和 `reader_b` 都不再使用该资源。按照同样的规则，当 `writer` 轮到它们并修改资源 [54]
    时，`reader_a` 和 `reader_b` 必须等待它完成。
- en: Because all of this happens roughly at the same time, every execution of this
    example is going to give you slightly different results. I encourage you to run
    the program multiple times and compare the output.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 因为所有这些操作几乎同时发生，所以每次运行这个示例都会给出略微不同的结果。我鼓励你多次运行程序并比较输出。
- en: There's more...
  id: totrans-145
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: Despite its nice usability, `RwLock` is still no silver bullet for all concurrent
    problems. There is a concept in concurrent programming called *deadlock*. It arises
    when two processes wait for the unlocking of resources that the other holds. This
    will lead to them waiting forever, as no one is ready to take the first step.
    Kind of like teenagers in love. An example of this would be a `writer_a` requesting
    access to a file that `writer_b` holds. `writer_b`, in the meantime, needs some
    kind of user information from `writer_a` before he can give up the file lock.
    The best way to avoid this problem is to keep it in the back of your mind and
    remember it when you're about to create processes that depend on each other.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管`RwLock`具有良好的可用性，但它仍然不是所有并发问题的万能药。在并发编程中有一个概念叫做*死锁*。当两个进程等待解锁其他进程持有的资源时，就会发生死锁。这将导致它们永远等待，因为没有人为第一步做好准备。有点像热恋中的青少年。一个例子是`writer_a`请求访问`writer_b`持有的文件。与此同时，`writer_b`需要从`writer_a`那里获取一些用户信息，然后他才能放弃文件锁。避免这种问题的最好方法是把它放在心里，当你即将创建相互依赖的进程时，要记住它。
- en: Another lock that is fairly popular in other languages is the `Mutex`, which
    Rust also provides under `std::sync::Mutex`. When it locks resources, it treats
    every process like a writer, so no two threads will *ever* be able to work at
    the same time with a `Mutex`, even if they don't mutate the data. We are going
    to create a very simple implementation of it ourselves in the next recipe.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种在其他语言中相当流行的锁是`Mutex`，Rust也在`std::sync::Mutex`下提供了它。当它锁定资源时，它将每个进程都视为一个写者，所以即使它们没有修改数据，也没有两个线程能够同时使用`Mutex`。我们将在下一个菜谱中创建一个非常简单的实现。
- en: See also
  id: totrans-148
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参见
- en: '*Working with interior mutability* recipe in [Chapter 5](6b8b0c3c-2644-4684-b1f4-b1e08d62450c.xhtml), *Advanced
    Data Structures*'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在第5章的*高级数据结构*中的*与内部可变性一起工作*菜谱
- en: Atomically accessing primitives
  id: totrans-150
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 原子访问原始数据
- en: When reading about all of these parallel structures, you might have wondered
    how they are implemented. In this recipe, we are going to take a look under the
    hood and learn about the most basic parallel data types, which are called *atomics*.
    We are going to do this by implementing our very own `Mutex`.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 当你阅读关于所有这些并行结构时，你可能想知道它们是如何实现的。在这个菜谱中，我们将揭开盖子，了解最基本的并行数据类型，这些类型被称为*原子*。我们将通过实现我们自己的`Mutex`来完成这项工作。
- en: How to do it...
  id: totrans-152
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到这一点...
- en: In the folder `bin`, create a file called `atomic.rs`.
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`bin`文件夹中创建一个名为`atomic.rs`的文件。
- en: 'Add the following code and run it with `cargo run --bin atomic`:'
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 添加以下代码，并用`cargo run --bin atomic`运行它：
- en: '[PRE20]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Now comes the implementation of our very own homemade mutex:'
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在是我们自己制作的互斥锁的实现：
- en: '[PRE21]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: How it works...
  id: totrans-158
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'As of the time of writing, there are four `atomic` types in the standard library
    under the `std::sync::atomic` module: `AtomicBool`, `AtomicIsize`, `AtomicUsize`,
    and `AtomicPtr`. Each one of them represents a primitive type, namely `bool`,
    `isize`, `usize`, and `*mut`. We are not going to look at the last, which, being
    a pointer, you will probably only have to deal with when interfacing with programs
    written in other languages anyways.'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 到写作的时候，标准库中的`std::sync::atomic`模块下有四种`atomic`类型：`AtomicBool`、`AtomicIsize`、`AtomicUsize`和`AtomicPtr`。它们每一个都代表一个原始类型，即`bool`、`isize`、`usize`和`*mut`。我们不会查看最后一个，因为作为一个指针，你只有在与其他语言编写的程序进行接口时才可能需要处理它。
- en: In case you haven't encountered `isize` and `usize` before, they are representations
    of the smallest amount of bytes needed to address any part of the memory of your
    machine. On 32-bit targets this is 4 bytes, while 64-bit systems will need 8 bytes.
    `isize` uses those bytes to represent a *signed* number, as in an integer that
    can be negative. `usize` instead represents an *unsigned* number, which can only
    be positive but has a lot more capacity for huge numbers in that direction. They
    are usually used when dealing with collections capacities. For example, `Vec`
    returns a `usize` when calling its `.len()` method. Additionally, on the nightly
    toolchain, there are atomic variants of all other concrete integer types like
    `u8` or `i32`.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你之前没有遇到过`isize`和`usize`，它们是你机器内存任何部分所需的最小字节数的表示。在32位目标上这是4字节，而在64位系统上则需要8字节。`isize`使用这些字节来表示一个*有符号*数字，就像一个可以负的整数。而`usize`则表示一个*无符号*数字，它只能为正，但在那个方向上有更多的容量来处理巨大的数字。它们通常用于处理集合容量。例如，`Vec`在调用其`.len()`方法时返回一个`usize`。此外，在夜间工具链中，所有其他具体整数类型（如`u8`或`i32`）都有原子变体。
- en: 'The `atomic` versions of our primitives work the same way as their cousins,
    with one important distinction: they have well-defined behavior when used in parallel
    environments. All their methods take a parameter of the type `atomic::Ordering`,
    which stands for which low-level concurrent strategy to use. In this example,
    we are only going to use `Ordering::SeqCst`, which stands for s*equentially consistent*.
    This, in turn, means that the behavior is quite intuitive. If some data is stored
    or modified using this ordering, another thread can see its content after the
    write as if the two threads ran one after another. Or, in other words, the behavior
    is *consistent* with that of a *sequential* series of events. This strategy will
    always work with all parallel algorithms. All other orderings merely relax the
    constraints on the data involved in order to get some kind of performance benefit.'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 我们原语的`atomic`版本与它们的亲戚工作方式相同，但有一个重要的区别：它们在并行环境中使用时具有明确的行为。所有这些方法都接受一个`atomic::Ordering`类型的参数，代表要使用哪种低级并发策略。在这个例子中，我们只将使用`Ordering::SeqCst`，它代表`s*equentially
    consistent*（顺序一致）。这反过来意味着行为相当直观。如果某些数据使用这种排序存储或修改，另一个线程在写入后可以看到其内容，就像两个线程一个接一个地运行一样。或者换句话说，行为与一系列事件的*顺序*行为是一致的。这种策略总是与所有并行算法一起工作。所有其他排序只是放松涉及数据的相关约束，以获得某种性能上的好处。
- en: With this knowledge in hand, you should be able to understand most things done
    in `main` up to the usage of `NaiveMutex`[72]. Note how some of the `atomic` methods
    are just different ways of doing the same as with our normal primitives, with
    the added twist of specifying an ordering and most of them returning the old value.
    For instance, `some_number.fetch_add(12, Ordering::SeqCst)`, apart from returning
    the old value of `some_number`, is essentially nothing but `some_number += 12`.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 拥有这些知识，你应该能够理解`main`函数中大多数操作，直到`NaiveMutex`[72]的使用。注意一些`atomic`方法只是以不同的方式做与我们的正常原语相同的事情，增加了指定排序的附加功能，并且大多数方法返回旧值。例如，`some_number.fetch_add(12,
    Ordering::SeqCst)`除了返回`some_number`的旧值外，本质上只是`some_number += 12`。
- en: A real use case for atomics comes up in the second part of the example code,
    where we implement our very own `Mutex`. A mutex, prominently featured in all
    modern programming languages, is a kind of lock that does not allow *any* two
    threads to access a resource at the same time. After reading the last recipe,
    you know that you can imagine a `Mutex` as a kind of `RwLock` that always locks
    everything in `write` mode.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 原子的实际用例出现在示例代码的第二部分，其中我们实现了自己的`Mutex`。互斥锁（mutex）在所有现代编程语言中都非常突出，是一种不允许任何两个线程同时访问资源的锁。在阅读了最后一个食谱之后，你知道你可以将`Mutex`想象成一种`RwLock`，它总是以`write`模式锁定一切。
- en: 'Let''s jump a few lines forward in our code to [102]:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在代码中跳过几行，来到[102]：
- en: '[PRE22]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: As you can see, we are going to base our `NaiveMutex` on a simple atomic flag,
    `locked`, which is going to track whether our mutex is available or not. The other
    member, `data`, holds the underlying resource we are interested in locking. Its
    type, `UnsafeCell`, is the underlying type of every struct that implements some
    kind of interior mutability (see [Chapter 5](6b8b0c3c-2644-4684-b1f4-b1e08d62450c.xhtml), *Advanced
    Data Structures*; *Working with interior mutability*).
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，我们将基于一个简单的原子标志`locked`来构建我们的`NaiveMutex`，它将跟踪互斥锁是否可用。另一个成员`data`持有我们想要锁定的底层资源。它的类型`UnsafeCell`是每个实现某种内部可变性的结构的底层类型（参见[第5章](6b8b0c3c-2644-4684-b1f4-b1e08d62450c.xhtml)，*高级数据结构*；*处理内部可变性*）。
- en: 'The next struct is going to look familiar to you if you''ve read [Chapter 6](d2c7b7cb-3060-40b8-adb4-408eee7940a1.xhtml),
    *Handling Errors*; *Understanding RAII*, as it''s an RAII guard with a reference
    to its parent [110]:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个结构体如果你阅读了[第6章](d2c7b7cb-3060-40b8-adb4-408eee7940a1.xhtml)，*处理错误*；*理解RAII*，你会觉得它很熟悉；因为它是一个带有对其父级[110]引用的RAII保护器：
- en: '[PRE23]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Let''s take a look at how we lock a thread:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看我们如何锁定一个线程：
- en: '[PRE24]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Looks a bit weird at first glance, doesn''t it? `compare_and_swap` is one of
    the more complex `atomic` operations. It works as follows:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 初看可能有点奇怪，不是吗？`compare_and_swap`是较为复杂的`atomic`操作之一。它的工作原理如下：
- en: It compares the value of the atomic with the first parameter
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它比较原子的值与第一个参数
- en: If they are the same, it stores the second parameter in the atomic
  id: totrans-173
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果它们相同，它将第二个参数存储在原子中
- en: Lastly, it returns the value of the atomic from before the function call
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，它返回函数调用之前的原子值
- en: 'Let''s apply that to our call:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将这个应用到我们的调用中：
- en: '`compare_and_swap` checks if `self.locked` contains `false`'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`compare_and_swap`检查`self.locked`是否包含`false`'
- en: If so, it sets `self.locked` to `true`
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果是这样，它将`self.locked`设置为`true`
- en: In any case, it will return the old value
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在任何情况下，它都会返回旧值
- en: 'If the returned value is `true`, it means our mutex is currently locked. What
    should our thread do then? Absolutely nothing: `{ }`. Because we call this in
    a `while` loop, we will continue doing nothing (this is called *spinning*) until
    the situation changes. This algorithm is called **spinlock**.'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 如果返回的值是`true`，这意味着我们的互斥锁当前是锁定状态。那么我们的线程应该做什么呢？绝对什么也不做：`{ }`。因为我们是在`while`循环中调用这个的，所以我们会继续什么也不做（这被称为*自旋*），直到情况发生变化。这个算法被称为**自旋锁**。
- en: When our mutex is finally available, we set its `locked` flag to `true` and
    return an RAII guard with a reference to our `NaiveMutex`.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们的互斥锁最终可用时，我们将它的`locked`标志设置为`true`，并返回一个RAII守护者，其中包含对`NaiveMutex`的引用。
- en: This is not how the real `std::sync::Mutex` is implemented. Because exclusively
    locking a resource is a very basic concurrent task, operating systems natively
    support it. The `Mutex` implemented in the Rust standard library is still built
    by the RAII pattern as well, but uses the OS's mutex handles instead of our custom
    logic. Fun fact—the Windows implementation uses SRWLocks ([https://msdn.microsoft.com/en-us/library/windows/desktop/aa904937(v=vs.85).aspx](https://msdn.microsoft.com/en-us/library/windows/desktop/aa904937(v=vs.85).aspx)),
    which are Windows's native version of `RwLock`, as they proved to be faster than
    a native `Mutex`. So, on Windows at least, the two types really are very similar.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 这不是真正的`std::sync::Mutex`的实现方式。因为独占锁定资源是一个非常基本的并发任务，操作系统原生支持它。Rust标准库中实现的`Mutex`仍然是通过RAII模式构建的，但使用的是操作系统的互斥锁句柄而不是我们的自定义逻辑。有趣的事实——Windows实现使用SRWLocks([https://msdn.microsoft.com/en-us/library/windows/desktop/aa904937(v=vs.85).aspx](https://msdn.microsoft.com/en-us/library/windows/desktop/aa904937(v=vs.85).aspx))，这是Windows的本地版本的`RwLock`，因为它们证明比本地的`Mutex`更快。所以，至少在Windows上，这两种类型实际上非常相似。
- en: 'The implementation of `NaiveMutexGuard` provides the counterpart of `lock`
    during its dropping [138]:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: '`NaiveMutexGuard`的实现提供了在丢弃时的`lock`的对应物[138]：'
- en: '[PRE25]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'We simply `store` the value `false` in `self.locked` whenever our guard goes
    out of scope (see [Chapter 6](d2c7b7cb-3060-40b8-adb4-408eee7940a1.xhtml), *Handling
    Errors*; *Implementing the Drop trait**)*. The next two trait `NaiveMutexGuard`
    implements are `Deref` and `DerefMut`, which let us call methods of type `T` directly
    on `NaiveMutexGuard<T>`. They both share nearly the same implementation [146]:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 我们简单地将值`false`存储在`self.locked`中，每当我们的守护者超出作用域时（参见[第6章](d2c7b7cb-3060-40b8-adb4-408eee7940a1.xhtml)，*处理错误*；*实现Drop特性**）。接下来的两个特性`NaiveMutexGuard`实现是`Deref`和`DerefMut`，这使得我们可以在`NaiveMutexGuard<T>`上直接调用类型`T`的方法。它们几乎有相同的实现[146]：
- en: '[PRE26]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Remember when we said that you'll have to deal with pointers on rare occasions?
    Well, this is one of those times.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 记得我们说过你会在罕见的情况下处理指针吗？嗯，这就是其中之一。
- en: '`UnsafeCell` doesn''t guarantee any borrowing safety, hence the name and the
    `unsafe` block. It relies on you to make sure all calls to it are actually safe.
    Because of this, it gives you a raw mutable pointer, which you can manipulate
    in any way you want. What we do here is dereference it with `*`, so `*mut T` becomes
    only `T`. Then we return a normal reference to that with `&`[146]. The only thing
    different in the implementation of `deref_mut` is that we instead return a mutable
    reference with `&mut` [152]. All of our `unsafe` calls are guaranteed to follow
    Rust''s ownership principles, as we only allow one scope to borrow our resource
    anyway.'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: '`UnsafeCell`不保证任何借用安全性，因此得名和`unsafe`块。它依赖于你确保所有对其的调用实际上都是安全的。正因为如此，它给你一个原始的可变指针，你可以以任何你想要的方式操作它。我们在这里使用`*`对其进行解引用，所以`*mut
    T`变成了只有`T`。然后我们使用`&`返回对该对象的正常引用[146]。在`deref_mut`的实现中唯一不同的是，我们返回一个可变引用`&mut` [152]。我们所有的`unsafe`调用都保证遵循Rust的所有权原则，因为我们无论如何只允许一个作用域借用我们的资源。'
- en: 'The last thing required for our `Mutex` implementation is the following line,
    which we skipped before:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 我们`Mutex`实现所需的最后一件事是以下这一行，我们之前跳过了：
- en: '[PRE27]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: The `Sync` trait has a pretty small implementation, right? That's because it
    is a *marker*. It belongs to a family of traits that don't actually do anything
    themselves but only exist to tell the compiler something about the types that
    implement them. Another trait in the `std::marker` module is `Send`, which we
    also use here.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: '`Sync`特性有一个相当小的实现，对吧？这是因为它是一个*标记*。它属于一组特性，它们实际上并不做任何事情，但只存在于告诉编译器有关实现它们的类型的信息。`std::marker`模块中的另一个特性是`Send`，我们在这里也使用它。'
- en: If a type `T` implements `Send`, it tells the world that it is safe to be moved
    (*sent*) between threads by passing it around as a value instead of a reference.
    Nearly all types of Rust implement `Send`.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 如果类型`T`实现了`Send`，它告诉世界可以通过将其作为值传递而不是引用来安全地在线程之间移动（发送）。几乎所有的Rust类型都实现了`Send`。
- en: If `T` is `Sync`, it tells the compiler that it is safe to be shared between
    threads (it behaves in a *synchronized* way) by passing it around per reference,
    `&T`. This is harder to accomplish than `Send`, but our `NaiveMutex` guarantees
    that types in it can be shared around, as we only allow one access to its inner
    type at a time. This is why we implement the `Sync` trait for every `Send` in
    our mutex. If it's safe to pass it around, it's automatically also safe to share
    it within `NaiveMutex`.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 如果`T`是`Sync`，它告诉编译器可以通过传递`&T`引用来安全地在线程之间共享（它以**同步**的方式行为）。这比`Send`更难实现，但我们的`NaiveMutex`保证了其中的类型可以被共享，因为我们只允许一次访问其内部类型。这就是为什么我们为我们的互斥锁中的每个`Send`实现`Sync`特性的原因。如果可以传递它，那么在`NaiveMutex`内部共享它也是自动安全的。
- en: Back in `main` you can now find some usage examples of our `Mutex`[75 and 84],
    similar to the examples in the previous recipe.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 回到`main`函数，你现在可以找到一些我们`Mutex`[75和84]的使用示例，类似于前一个配方中的示例。
- en: There's more...
  id: totrans-194
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更多...
- en: 'Because `SeqCst` is good enough for most applications and the complexity involved
    in all other orderings, we are not going to look at any others. Don''t be disappointed,
    however—Rust uses nearly the same `atomic` layout and functionality as C++, so
    there are plenty of sources to tell you how complex the issue really is. Anthony
    Williams, author of the well-known book *C++: Concurrency In Action* ([http://www.cplusplusconcurrencyinaction.com/](http://www.cplusplusconcurrencyinaction.com/)),
    uses an entire 45 pages (!) to simply describe all the atomic orderings and how
    to use them. An additional 44 pages go into showing examples of all of these orderings.
    Does an average program benefit from this level of dedication? Let''s look at
    the man''s own words, with the background knowledge that `std::memory_order_seq_cst`
    is how C++ calls `SeqCst`:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: '因为`SeqCst`对于大多数应用来说已经足够好了，并且所有其他排序所涉及到的复杂性，所以我们不会查看任何其他的。不过，不要失望——Rust使用与C++几乎相同的`atomic`布局和功能，所以有很多资源可以告诉你这个问题实际上有多复杂。知名书籍《C++:
    Concurrency In Action》的作者Anthony Williams（[http://www.cplusplusconcurrencyinaction.com/](http://www.cplusplusconcurrencyinaction.com/)）用整整45页（！）来简单地描述所有原子排序及其使用方法。另外44页用于展示所有这些排序的示例。普通程序能从这个级别的投入中受益吗？让我们看看这位先生的亲身说法，背景知识是`std::memory_order_seq_cst`是C++对`SeqCst`的调用：'
- en: 'The basic premise is: do not use anything other than `std::memory_order_seq_cst`
    (the default) unless (a) you really **really** know what you are doing, and can
    **prove** that the relaxed usage is safe in all cases, and (b) your profiler demonstrates
    that the data structure and operations you are intending to use the relaxed orderings
    with are a bottleneck.'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 基本前提是：除非（a）你真的**真的**清楚你在做什么，并且可以**证明**在所有情况下放宽使用是安全的，以及（b）你的性能分析器显示你打算使用放宽排序的数据结构和操作是瓶颈，否则不要使用除`std::memory_order_seq_cst`（默认）之外的其他任何东西。
- en: 'Source: [https://stackoverflow.com/a/9564877/5903309](https://stackoverflow.com/a/9564877/5903309)'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：[https://stackoverflow.com/a/9564877/5903309](https://stackoverflow.com/a/9564877/5903309)
- en: In short, you should wait to learn about the different kinds of orderings until
    you have a very good reason to use them. This is, by the way, also the approach
    of Java, which makes all variables marked as `volatile` behave in a sequentially
    consistent way.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，你应该等到有很好的理由使用它们时再学习不同类型的排序。顺便说一句，这也是Java的方法，它使所有标记为`volatile`的变量以顺序一致的方式行为。
- en: See also
  id: totrans-199
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参见
- en: '*Working with interior mutability* recipe in [Chapter 5](6b8b0c3c-2644-4684-b1f4-b1e08d62450c.xhtml),
    *Advanced Data Structures*'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*处理内部可变性*配方在[第5章](6b8b0c3c-2644-4684-b1f4-b1e08d62450c.xhtml)，*高级数据结构*'
- en: '*Implementing the Drop trait* and *Understanding RAII* recipe in [Chapter 6](d2c7b7cb-3060-40b8-adb4-408eee7940a1.xhtml),
    *Handling Errors*'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*实现Drop特性*和*理解RAII*配方在[第6章](d2c7b7cb-3060-40b8-adb4-408eee7940a1.xhtml)，*处理错误*'
- en: Putting it all together in a connection handler
  id: totrans-202
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在连接处理器中将所有内容组合在一起
- en: We have looked at a lot of different practices in isolation now. The true strength
    of these building blocks, however, comes from combining them. This recipe is going
    to show you how to combine some of them into a realistic starting point for the
    connection handling part of a server.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经单独审视了许多不同的实践。然而，这些构建块的真实力量来自于它们的组合。这个食谱将向您展示如何将其中的一些组合起来，作为服务器连接处理部分的现实起点。
- en: How to do it...
  id: totrans-204
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到...
- en: In the folder `bin`, create a file called `connection_handler.rs`.
  id: totrans-205
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`bin`文件夹中创建一个名为`connection_handler.rs`的文件。
- en: 'Add the following code and run it with `cargo run --bin connection_handler`:'
  id: totrans-206
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 添加以下代码并使用`cargo run --bin connection_handler`运行它：
- en: '[PRE28]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Using our connection handler by simulating connecting and disconnecting clients:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 通过模拟连接和断开客户端来使用我们的连接处理器：
- en: '[PRE29]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: How it works...
  id: totrans-210
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: This recipe doesn't introduce any new modules or concepts. It's here to provide
    you with a general idea of how to combine all the things you've learned in this
    recipe in a somewhat realistic context. Specifically, our context consists of
    code that manages clients that connect with us in some way.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 这个食谱不引入任何新的模块或概念。它在这里是为了提供一个大致的想法，说明如何在某种现实环境中结合你在本食谱中学到的所有东西。具体来说，我们的上下文由管理以某种方式连接到我们的客户端的代码组成。
- en: '`Client` [8] holds all information relevant to a connection. As a basic example,
    it currently contains the client''s IP address. Other possibilities would be the
    client''s username, location, device, ping, and so on.'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: '`Client` [8] 包含与连接相关的所有信息。作为一个基本示例，它目前包含客户端的IP地址。其他可能性包括客户端的用户名、位置、设备、ping等。'
- en: The `ConnectionHandler` [14] itself holds a list, more specifically a `HashMap`,
    of the active connections, indexed by a unique ID. Analogous to that, it also
    stores the ID for the next connection.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: '`ConnectionHandler` [14] 本身持有一个列表，更具体地说是一个`HashMap`，其中包含活动连接，按唯一ID索引。类似地，它还存储下一个连接的ID。'
- en: We are using unique IDs instead of a `Vec<Client>` because clients might be
    able to connect, multiple times, to whatever service we are providing on the same
    device. The easiest example for this is multiple tabs open in a browser, all accessing
    the same website. Generally speaking, it is good practice to always hold your
    data behind unique keys to save yourself from trouble down the road.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用唯一的ID而不是`Vec<Client>`，因为客户端可能能够多次连接到我们在同一设备上提供的任何服务。最容易的例子是在浏览器中打开多个标签页，所有标签页都访问同一个网站。一般来说，始终在唯一键后面保存你的数据是一个好的做法，以避免将来遇到麻烦。
- en: The implementations of the structs should be straightforward. Methods that need
    to modify the `clients` member lock it with `.write()`, all others with `.read()`.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 结构体的实现应该是直接的。需要修改`clients`成员的方法使用`.write()`锁定，其他所有方法使用`.read()`。
- en: 'The code used to get a new ID at `add_connection` adds one to `next_id` and
    returns its last value, as usual for an `atomic`[42]:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 在`add_connection`中用于获取新ID的代码会将`next_id`加一，并返回其最后一个值，这是对`atomic`[42]的常规操作：
- en: '[PRE30]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: After adding the connection to the `clients`, we return the newly-acquired ID
    to the caller, so that they can store the ID however they want and reuse it when
    it's time to kick the client with `remove_connection` [50], which in turn returns
    an `Option` telling the caller if the removed ID was in the client list in the
    first place. We do not return the removed `Client` directly because that would
    reveal unnecessary implementation details to the user of `ConnectionHandler`.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 在将连接添加到`clients`之后，我们将新获得的ID返回给调用者，以便他们可以按自己的方式存储ID，并在需要使用`remove_connection`
    [50] 将客户端踢出时重新使用它。`remove_connection`会返回一个`Option`，告诉调用者被移除的ID最初是否在客户端列表中。我们不直接返回被移除的`Client`，因为这会向`ConnectionHandler`的用户透露不必要的实现细节。
- en: The code in `main` simulates parallel access to the hypothetical service. A
    bunch of clients connect to our `ConnectionHandler` and some leave again. `thread::sleep`
    [70, 80 and 90] blocks the current thread for a specified time and is used here
    to simulate the effect of various events happening at irregular intervals, represented
    by the different waiting times for each task.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: '`main`中的代码模拟了对假设服务的并行访问。一些客户端连接到我们的`ConnectionHandler`，然后又离开了。`thread::sleep`
    [70, 80和90]会阻塞当前线程一段时间，在这里用于模拟各种事件以不规则间隔发生的效果，这些效果由每个任务的不同等待时间表示。'
- en: As with the `RwLock` example, this program will have very different output every
    time you run it, so try it out multiple times.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 就像`RwLock`示例一样，每次运行此程序时，输出都会非常不同，所以请多次尝试。
- en: There's more...
  id: totrans-221
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: If you need to react to the messages from your clients in a different thread,
    you can use `channel`, which we looked at earlier in the chapter. One use case
    for this would be programming an online video game. You'll want to aggregate all
    input from your players, react to it by simulating your world, and then broadcast
    local changes to the players, with each of these tasks happening concurrently
    in a single thread.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你需要在不同线程中响应用户的消息，你可以使用`channel`，这是我们之前在章节中提到的。这个用例的一个例子就是编程一个在线视频游戏。你将希望聚合所有来自玩家的输入，通过模拟你的世界来响应它，然后向玩家广播局部变化，这些任务将在单个线程中并发执行。
