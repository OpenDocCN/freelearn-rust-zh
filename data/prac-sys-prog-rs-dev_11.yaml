- en: '*Chapter 9*: Managing Concurrency'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第9章*：管理并发'
- en: Concurrent systems are all around us. When you download a file, listen to streaming
    music, initiate a text chat with a friend, and print something in the background
    on your computer, *all at the same time*, you are experiencing the magic of concurrency
    in action. The operating system manages all these for you in the background, scheduling
    tasks across available processors (CPUs).
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 并发系统无处不在。当你下载文件、收听流媒体音乐、与朋友开始文本聊天，以及在你的电脑后台打印某些东西时，*同时进行*，你正在体验并发编程的魔力。操作系统在后台为你管理所有这些，跨可用的处理器（CPU）调度任务。
- en: 'But do you know how to write a program that can do multiple things at the same
    time? More importantly, do you know how to do it in a way that is both memory-
    and thread-safe, while ensuring optimal use of system resources? Concurrent programming
    is one way to achieve this. But concurrent programming is considered to be a difficult
    topic in most programming languages due to challenges in *synchronizing tasks*
    and *sharing data safely across multiple threads of execution*. In this chapter,
    you''ll learn about the basics of concurrency in Rust and how Rust makes it easier
    to prevent common pitfalls and enables us to write concurrent programs in a safe
    manner. This chapter is structured as shown here:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 但你知道如何编写一个可以同时做很多事情的程序吗？更重要的是，你知道如何以既内存安全又线程安全的方式做到这一点，同时确保系统资源的最佳使用吗？并发编程是实现这一目标的一种方式。但并发编程在大多数编程语言中都被认为是困难的，因为存在*同步任务*和*在多个执行线程之间安全共享数据*的挑战。在本章中，你将了解Rust中并发的基础，以及Rust如何使防止常见陷阱变得更容易，并使我们能够以安全的方式编写并发程序。本章的结构如下所示：
- en: Reviewing concurrency basics
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 复习并发基础
- en: Spawning and configuring threads
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建和配置线程
- en: Error handling in threads
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 线程中的错误处理
- en: Message passing between threads
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 线程间的消息传递
- en: Achieving concurrency with shared state
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过共享状态实现并发
- en: Pausing thread execution with timers
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用定时器暂停线程执行
- en: By the end of this chapter, you'll have learned how to write concurrent programs
    in Rust by spawning new threads, handling thread errors, transferring and sharing
    data safely across threads to synchronize tasks, understanding the basics of thread-safe
    data types, and pausing the execution of current threads for synchronization.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章结束时，你将学会如何通过创建新线程、处理线程错误、在线程之间安全地传输和共享数据以同步任务、理解线程安全数据类型的基础以及暂停当前线程的执行以进行同步，来用Rust编写并发程序。
- en: Technical requirements
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'Verify that `rustup`, `rustc`, and `cargo` have been installed correctly with
    the following commands:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下命令验证`rustup`、`rustc`和`cargo`是否已正确安装：
- en: '[PRE0]'
  id: totrans-12
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The Git repo for the code in this chapter can be found at: [https://github.com/PacktPublishing/Practical-System-Programming-for-Rust-Developers/tree/master/Chapter09](https://github.com/PacktPublishing/Practical-System-Programming-for-Rust-Developers/tree/master/Chapter09).'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中代码的Git仓库可以在以下位置找到：[https://github.com/PacktPublishing/Practical-System-Programming-for-Rust-Developers/tree/master/Chapter09](https://github.com/PacktPublishing/Practical-System-Programming-for-Rust-Developers/tree/master/Chapter09)。
- en: Let's get started with some basic concepts of concurrency.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从并发的一些基本概念开始。
- en: Reviewing concurrency basics
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 复习并发基础
- en: In this section, we'll cover the basics of **multi-threading** and clarify the
    terminology around **concurrency** and **parallelism**.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将介绍**多线程**的基础，并阐明关于**并发**和**并行**的术语。
- en: To appreciate the value of concurrent programming, we have to understand the
    need of today's programs to make decisions quickly or process a large amount of
    data in a short period of time. Several use cases become impossible to achieve
    if we strictly rely on sequential execution. Let's consider a few examples of
    systems that must perform multiple things simultaneously.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 要欣赏并发编程的价值，我们必须理解当今程序需要快速做出决策或短时间内处理大量数据的必要性。如果我们严格依赖顺序执行，那么几个用例将无法实现。让我们考虑一些必须同时执行多项任务的系统示例。
- en: An autonomous car needs to perform many tasks at the same time, such as processing
    inputs from a wide array of sensors (to construct an internal map of its surroundings),
    plotting the path of the vehicle, and sending instructions to the vehicle's actuators
    (to control the brakes, acceleration, and steering). It needs to process continually
    arriving input events, and respond in tenths of a second.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 一辆自动驾驶汽车需要同时执行许多任务，例如处理来自各种传感器的输入（以构建其周围环境的内部地图），规划车辆的路径，并向车辆的执行器发送指令（以控制刹车、加速和转向）。它需要持续处理不断到达的输入事件，并在十分之一秒内做出响应。
- en: There are also other, more mundane examples. A web browser handles user inputs
    while simultaneously rendering a web page incrementally, as new data is received.
    A website handles requests from multiple simultaneous users. A web crawler has
    to access many thousands of sites simultaneously to gather information about the
    websites and their contents. It is impractical to do all these things sequentially.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 同时还有其他一些更为常见的例子。一个网页浏览器在接收新数据的同时，会处理用户输入并逐步渲染网页。一个网站会处理来自多个同时在线用户的请求。一个网络爬虫需要同时访问成千上万的网站以收集有关网站及其内容的信息。按顺序执行所有这些事情是不切实际的。
- en: We've so far seen a few use cases that require multiple tasks to be performed
    simultaneously. But there is also a technical reason that is driving concurrency
    in programming, which is that CPU clock speeds on a single core are hitting upper
    practical limits. So, it is becoming necessary to add more CPU cores, and more
    processors on a single machine. This is in turn driving the need for software
    that can efficiently utilize the additional CPU cores. To achieve this, portions
    of a program should be executable concurrently on different CPU cores, rather
    than being constrained by the sequential execution of instructions on a single
    CPU core.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到了一些需要同时执行多个任务的用例。但还有一个技术原因在推动编程中的并发，那就是单核CPU的时钟速度已经接近实际上限。因此，有必要增加更多的CPU核心和单台机器上的更多处理器。这反过来又推动了需要能够高效利用额外CPU核心的软件的需求。为了实现这一点，程序的一部分应该在不同的CPU核心上并发执行，而不是被限制在单核CPU上的指令顺序执行。
- en: These factors have resulted in the increased use of multi-threading concepts
    in programming. Here, there are two related terms that need to be understood –
    *concurrency* and *parallelism*. Let's take a closer look at this.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 这些因素导致了在编程中多线程概念的广泛应用。这里有两个相关的术语需要理解——*并发* 和 *并行*。让我们更深入地了解一下。
- en: Concurrency versus parallelism
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 并发与并行
- en: In this section, we'll review the fundamentals of multi-threading and understand
    the differences between *concurrent* and *parallel* execution models of a program.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将回顾多线程的基本原理，并了解程序中 *并发* 和 *并行* 执行模型之间的区别。
- en: '![Figure 9.1 – Concurrency basics](img/Figure_9.1_B16405.jpg)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![图9.1 – 并发基础](img/Figure_9.1_B16405.jpg)'
- en: Figure 9.1 – Concurrency basics
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.1 – 并发基础
- en: '*Figure 9.1* shows three different computation scenarios within a Unix/Linux
    process:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '*图9.1* 展示了Unix/Linux进程内的三个不同的计算场景：'
- en: '**Sequential execution**: Let''s assume that a process has two tasks **A**
    and **B**. **Task A** has three subtasks **A1**, **A2**, and **A3**, which are
    executed sequentially. Likewise, **Task B** has two tasks, **B1** and **B2**,
    that are executed one after the other. Overall, the process executes all tasks
    of process *A* before taking on process *B* tasks. There is a challenge in this
    model. Assume the case where task **A2** involves waiting for an external network
    or user input, or for a system resource to become available. Here, all tasks lined
    up after task **A2** will be blocked until **A2** completes. This is not an efficient
    use of the CPU and causes a delay in the completion of all the scheduled tasks
    that belong to the process.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**顺序执行**：假设一个进程有两个任务 **A** 和 **B**。**任务 A** 包含三个子任务 **A1**、**A2** 和 **A3**，它们是顺序执行的。同样，**任务
    B** 包含两个任务，**B1** 和 **B2**，它们是依次执行的。总体来说，进程在执行进程 *A* 的所有任务之后，才会开始执行进程 *B* 的任务。这种模型存在一个挑战。假设任务
    **A2** 需要等待外部网络或用户输入，或者等待系统资源可用。在这种情况下，所有排在任务 **A2** 后面的任务都将被阻塞，直到 **A2** 完成。这不是CPU的高效使用，并且会导致属于该进程的所有预定任务完成延迟。'
- en: '**Concurrent execution**: Sequential programs are limited as they do not have
    the ability to deal with multiple simultaneous inputs. This is the reason many
    modern applications are *concurrent* where there are multiple threads of execution
    running concurrently.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**并发执行**：顺序程序有限制，因为它们没有处理多个同时输入的能力。这就是为什么许多现代应用程序是**并发**的，其中存在多个并发执行的执行线程。'
- en: In the concurrent model, the process interleaves the tasks, that is, alternates
    between the execution of **Task A** and **Task B**, until both of them are complete.
    Here, even if **A2** is blocked, it allows progress with the other sub-tasks.
    Each sub-task, **A1**, **A2**, **A3**, **B1**, and **B2**, can be scheduled on
    separate execution threads. These threads could run either on a single processor
    or scheduled across multiple processor cores. One thing to bear in mind is that
    concurrency is about *order-independent* computations as opposed to sequential
    execution, which relies on steps executed in a specific order to arrive at the
    correct program outcome. Writing programs to accommodate *order-independent* computations
    is more challenging than writing sequential programs.
  id: totrans-29
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在并发模型中，进程会交错执行任务，即交替执行**任务A**和**任务B**，直到它们都完成。在这里，即使**A2**被阻塞，它也允许其他子任务继续进行。每个子任务，**A1**、**A2**、**A3**、**B1**和**B2**，都可以在单独的执行线程上调度。这些线程可以在单个处理器上运行，也可以跨多个处理器核心调度。需要注意的是，并发是关于**顺序无关**的计算，而不是依赖于执行特定顺序以到达正确程序结果的顺序执行。编写适应**顺序无关**计算的程序比编写顺序程序更具挑战性。
- en: '**Parallel execution**: This is a variant of the *concurrent execution* model.
    In this model, the process executes **Task A** and **Task B** truly in parallel,
    on separate CPU processors or cores. This assumes, of course, that the software
    is written in a way that such parallel execution is possible, and there are no
    dependencies between **Task A** and **Task B** that could stall the execution
    or corrupt the data.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**并行执行**：这是**并发执行**模型的一种变体。在这个模型中，进程真正地在不同的CPU处理器或核心上并行执行**任务A**和**任务B**。当然，这假设软件是以一种使得这种并行执行成为可能的方式编写的，并且**任务A**和**任务B**之间没有可能导致执行停滞或数据损坏的依赖关系。'
- en: Parallel computing is a broad term. *Parallelism* can be achieved either within
    a single machine by having **multi-cores** or **multi-processors** or there can
    be clusters of different computers that can cooperatively perform a set of tasks.
  id: totrans-31
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 并行计算是一个广泛的概念。**并行性**可以通过在单个机器内拥有**多核**或**多处理器**来实现，或者可以有不同的计算机集群，它们可以协作执行一系列任务。
- en: When to use concurrent versus parallel execution?
  id: totrans-32
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 何时使用并发与并行执行？
- en: A program or a function is *compute-intensive* when it involves a lot of computations
    such as in graphics, meteorological, or genome processing. Such programs spend
    the bulk of their time using CPU cycles and will benefit from having better and
    faster CPUs.
  id: totrans-33
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 当程序或函数涉及大量计算（如图形、气象或基因组处理）时，它是**计算密集型**的。这类程序的大部分时间都用于使用CPU周期，并且将受益于拥有更好、更快的CPU。
- en: A program is *I/O-intensive* when a bulk of the processing involves communicating
    with input/output devices such as network sockets, filesystems, and other devices.
    Such programs benefit from having faster I/O subsystems, such as for disk or network
    access.
  id: totrans-34
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 当大量处理涉及与输入/输出设备（如网络套接字、文件系统和其他设备）通信时，程序是**I/O密集型**的。这类程序从拥有更快的I/O子系统（如磁盘或网络访问）中受益。
- en: Broadly, *parallel execution* (true parallelism) is more relevant for increasing
    the throughput of programs in *compute-intensive* use cases, while *concurrent
    processing* (or pseudo-parallelism) can be suitable for increasing throughput
    and reducing latency in *I/O-intensive* use cases.
  id: totrans-35
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 广义上讲，**并行执行**（真正的并行性）对于在**计算密集型**用例中增加程序的吞吐量更为相关，而**并发处理**（或伪并行性）可以在**I/O密集型**用例中增加吞吐量和降低延迟。
- en: In this section, we've seen two ways to write concurrent programs – *concurrency*
    and *parallelism*, and how these differ from sequential models of execution. Both
    these models use *multi-threading* as the foundational concept. Let's talk more
    about this in the next section.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们看到了编写并发程序的两种方法——**并发**和**并行**，以及这些方法如何与顺序执行模型不同。这两个模型都使用**多线程**作为基础概念。让我们在下一节中更多地讨论这一点。
- en: Concepts of multi-threading
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**多线程**的概念'
- en: In this section, we'll deep-dive into how multi-threading is implemented in
    Unix.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将深入探讨在Unix中如何实现多线程。
- en: Unix supports threads as a mechanism for a process to perform multiple tasks
    concurrently. A Unix process starts up with a single thread, which is the main
    thread of execution. But additional threads can be spawned, that can *execute
    concurrently in a single-processor system*, or *execute in parallel in a multi-processor
    system*.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: Unix支持线程作为进程执行多个任务并发的机制。一个Unix进程以单个线程启动，这是执行的主线程。但可以生成额外的线程，这些线程可以在单处理器系统中**并发执行**，或者在多处理器系统中**并行执行**。
- en: Each thread has access to its own *stack* for storing its own *local variables*
    and *function parameters*. Threads also maintain their own register state including
    the *stack pointer* and *program counter*. All the threads in a process share
    the same memory address space, which means that they share access to the *data*
    segments (*initialized data*, *uninitialized data*, and the *heap*). Threads also
    share the same *program code* (process instructions).
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 每个线程都有自己的**栈**来存储自己的**局部变量**和**函数参数**。线程还维护自己的寄存器状态，包括**栈指针**和**程序计数器**。进程中的所有线程共享相同的内存地址空间，这意味着它们共享对**数据段**（*初始化数据*、*未初始化数据*和*堆*）的访问。线程还共享相同的**程序代码**（进程指令）。
- en: In a multi-threaded process, multiple threads concurrently execute the same
    program. They may be executing different parts of a program (such as different
    functions) or they may be invoking the same function in different threads (working
    with a different set of data for processing). But note that for a function to
    be invoked by multiple threads at the same time, it needs to be *thread-safe*.
    Some ways to make a function thread-safe are to avoid the usage of *global* or
    *static* variables in the function, using a *mutex* to restrict usage of a function
    to just one thread at a time, or using *mutex* to synchronize usage of a piece
    of shared data.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在多线程进程中，多个线程并发执行相同的程序。它们可能正在执行程序的不同部分（例如不同的函数），或者它们可能在不同的线程中调用相同的函数（使用不同的数据集进行处理）。但请注意，为了使函数能够被多个线程同时调用，它需要是**线程安全的**。使函数线程安全的一些方法包括在函数中避免使用**全局**或**静态**变量，使用**互斥锁**来限制一次只有一个线程使用函数，或者使用**互斥锁**来同步对共享数据的访问。
- en: But it is a design choice to model a concurrent program either as a group of
    processes or as a group of threads within the same process. Let's compare the
    two approaches, for a Unix-like system.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，将并发程序建模为一组进程或同一进程内的线程组是一个设计选择。让我们比较这两种方法，以Unix-like系统为例。
- en: It is much easier to share data across threads as they are in the same process
    space. Threads also share common resources of a process such as *file descriptors*
    and *user/group IDs*. Thread creation is faster than process creation. Context
    switching between threads is also faster for the CPU due to their sharing the
    same memory space. But threads bring their own share of complexities.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 由于线程位于同一进程空间中，因此跨线程共享数据要容易得多。线程还共享进程的公共资源，如**文件描述符**和**用户/组ID**。线程创建比进程创建更快。由于它们共享相同的内存空间，因此线程之间的上下文切换对CPU来说也更快。但线程也带来了自己的复杂性。
- en: As discussed earlier, shared functions must be thread-safe and access to shared
    global data should be carefully synchronized. Also, a critical defect in one of
    the threads can affect other threads or even bring the entire process down. Additionally,
    there is no guarantee about the order in which different parts of code in different
    threads will run, which can lead to data races, deadlocks, or hard-to-reproduce
    bugs. Bugs related to concurrency are difficult to debug since factors such as
    CPU speed, the number of threads, and the set of running applications at a point
    in time, can alter the outcome of a concurrent program. In spite of these drawbacks,
    if one decides to proceed with the thread-based concurrency model, aspects such
    as code structure, the use of global variables, and thread synchronization should
    be carefully designed.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，共享函数必须是线程安全的，对共享全局数据的访问应谨慎同步。此外，一个线程中的关键缺陷可能会影响其他线程，甚至可能导致整个进程崩溃。此外，没有保证不同线程中不同代码部分运行的顺序，这可能导致数据竞争、死锁或难以复现的bug。由于CPU速度、线程数量和特定时间点运行的应用程序集等因素可能会改变并发程序的结果，因此与并发相关的bug难以调试。尽管存在这些缺点，如果决定采用基于线程的并发模型，代码结构、全局变量的使用和线程同步等方面应仔细设计。
- en: '*Figure 9.2* shows the memory layout of threads within a process:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '*图9.2*显示了进程内线程的内存布局：'
- en: '![Figure 9.2 – Memory layout of threads in a process](img/Figure_9.2_B16405.jpg)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.2 – 进程中线程的内存布局](img/Figure_9.2_B16405.jpg)'
- en: Figure 9.2 – Memory layout of threads in a process
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.2 – 进程中线程的内存布局
- en: The figure shows how a set of tasks in process P1 are represented in memory
    when they are executed in a multi-threaded model. We've seen in detail the memory
    layout of a process, in [*Chapter 5*](B16405_05_Final_NM_ePUB.xhtml#_idTextAnchor083),
    *Memory Management in Rust*. *Figure 9.2* extends the process memory layout with
    details of how memory is allocated for individual threads within a process.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 图表展示了在多线程模型下执行时，进程 P1 中的任务集在内存中的表示。我们在 [*第 5 章*](B16405_05_Final_NM_ePUB.xhtml#_idTextAnchor083)，*Rust
    中的内存管理* 中详细看到了进程的内存布局。*图 9.2* 通过展示进程内各个线程内存分配的细节，扩展了进程内存布局。
- en: As discussed earlier, all threads are allocated memory within the process memory
    space. By default, the main thread is created with its own stack. Additional threads
    are also assigned their own stack as and when they are created. The shared model
    of concurrency, which we discussed earlier in the chapter, is possible because
    global and static variables of a process are accessible by all threads, and each
    thread also can pass around pointers to memory created on the heap to other threads.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，所有线程都在进程内存空间内分配内存。默认情况下，主线程创建时带有自己的栈。随着线程的创建，额外的线程也会分配自己的栈。我们之前在章节中讨论的共享并发模型是可能的，因为进程的全局和静态变量对所有线程都是可访问的，并且每个线程还可以将堆上创建的内存指针传递给其他线程。
- en: The program code, however, is common for the threads. Each thread can execute
    a different section of the code from the program text segment, and store the local
    variables and function parameters within their respective thread stack. When it
    is the turn of a thread to execute, its program counter (containing the address
    of the instruction to execute) is loaded for the CPU to execute the set of instructions
    for a given thread.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，程序代码对线程来说是通用的。每个线程都可以从程序文本段的不同部分执行代码，并在各自的线程栈中存储局部变量和函数参数。当轮到线程执行时，其程序计数器（包含要执行指令的地址）被加载到
    CPU 中，以便执行给定线程的指令集。
- en: In the example shown in the diagram, if task *A2* is blocked waiting for I/O,
    then the CPU will switch execution to another task such as *B1* or *A1*.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在图表所示的示例中，如果任务 *A2* 被阻塞等待 I/O，那么 CPU 将切换执行到另一个任务，例如 *B1* 或 *A1*。
- en: With this, we conclude the section on concurrency and multi-threading basics.
    We are now ready to get started with writing concurrent programs using the Rust
    Standard Library.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这种方式，我们完成了关于并发和多线程基本知识的章节。我们现在可以开始使用 Rust 标准库编写并发程序了。
- en: Spawning and configuring threads
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建和配置线程
- en: In the previous section, we reviewed the fundamentals of multi-threading that
    apply broadly to all user processes in the Unix environment. There is, however,
    another aspect of threading that is dependent on the programming language for
    implementation – this is the *threading model*.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我们回顾了适用于 Unix 环境中所有用户进程的多线程基本原理。然而，线程的另一个方面取决于编程语言的实现 – 这就是 *线程模型*。
- en: Rust implements a *1:1 model* of threading where each operating system thread
    maps to one user-level thread created by the Rust Standard Library. The alternative
    model is *M:N* (also known as **green threads**) where there are *M green threads*
    (user-level threads managed by a runtime) that map to *N kernel-level threads*.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: Rust 实现了一种 *1:1 模型* 的线程，其中每个操作系统线程映射到由 Rust 标准库创建的一个用户级线程。另一种模型是 *M:N*（也称为 **绿色线程**），其中存在
    *M 个绿色线程*（由运行时管理的用户级线程），它们映射到 *N 个内核级线程*。
- en: In this section, we'll cover the fundamentals of creating *1:1* operating system
    threads using the Rust Standard Library. The Rust Standard Library module for
    thread-related functions is `std::thread`.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将介绍使用 Rust 标准库创建 *1:1* 操作系统线程的基本知识。与线程相关的函数的 Rust 标准库模块是 `std::thread`。
- en: 'There are two ways to create a new thread using the Rust Standard Library.
    The first method uses the `thread::spawn` function, and the second method uses
    the builder pattern using the `thread::Builder` struct. Let''s look at an example
    of the `thread::spawn` function first:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Rust 标准库创建新线程有两种方式。第一种方法使用 `thread::spawn` 函数，第二种方法使用 `thread::Builder` 结构体的构建模式。让我们首先看看
    `thread::spawn` 函数的示例：
- en: '[PRE1]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The `std::thread` module is used in this program. `thread::spawn()` is the function
    used to spawn a new thread. In the program shown, we're spawning four new child
    threads in the main function (which runs in the main thread in the process). Run
    this program with `cargo run`. Run it a few more times. What did you expect to
    see, and what did you actually see?
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个程序中使用了`std::thread`模块。`thread::spawn()`是用于创建新线程的函数。在显示的程序中，我们在主函数中（在进程的主线程中运行）创建了四个新的子线程。使用`cargo
    run`运行此程序。运行几次。你期望看到什么，实际上看到了什么？
- en: You would have expected to see four lines printed to the terminal listing the
    *thread IDs*. But you would have noticed that the results vary each time. Sometimes
    you see one line printed, sometimes you see more, and sometimes none. Why is this?
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 你本应看到四行打印到终端，列出*线程ID*。但你可能会注意到每次的结果都不同。有时你会看到一行打印，有时你会看到更多，有时则没有。这是为什么？
- en: The reason for this inconsistency is that there is no guarantee of the order
    in which the threads are executed. Further, if the `main()` function completes
    before the child threads are executed, you won't see the expected output in your
    terminal.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 这种不一致的原因在于无法保证线程执行的顺序。此外，如果`main()`函数在子线程执行之前完成，你将不会在终端看到预期的输出。
- en: 'To fix this, what we need to do is to join the *child threads* that are created
    to the *main thread*. Then the `main()` thread waits until all the child threads
    have been executed. To see this in action, let''s alter the program as shown:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这个问题，我们需要做的是将创建的*子线程*连接到*主线程*。然后`main()`线程等待直到所有子线程都执行完毕。为了看到这个效果，让我们按照以下方式修改程序：
- en: '[PRE2]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The changes from the previous program are highlighted. `thread::spawn()` returns
    a thread handle that we're storing in a `Vec` collection data type. Before the
    end of the `main()` function, we join each child thread to the main thread. This
    ensures that the `main()` function waits until the completion of all the child
    threads before it exits.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 与上一个程序相比，这些更改被突出显示。`thread::spawn()`返回一个线程句柄，我们将其存储在`Vec`集合数据类型中。在`main()`函数结束之前，我们将每个子线程连接到主线程。这确保了`main()`函数在退出之前等待所有子线程完成。
- en: Let's run the program again. You'll notice four lines printed, one for each
    thread. Run the program a few more times. You'll see four lines printed every
    time. This is progress. It shows that joining the child threads to the main threads
    is helping. However, the order of thread execution (as seen by the order of print
    outputs on the terminal) varies with each run. This is because, when we span multiple
    child threads, there is no guarantee of the order in which the threads are executed.
    This is a feature of multi-threading (as discussed earlier), not a bug. But this
    is also one of the challenges of working with threads, as this brings difficulties
    in synchronizing activities across threads. We'll learn how to address this a
    little later in the chapter.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们再次运行程序。你会注意到打印了四行，每行对应一个线程。再次运行程序几次。每次都会打印四行。这是进步。这表明将子线程连接到主线程是有帮助的。然而，线程执行的顺序（如终端上打印输出的顺序所示）每次运行都会变化。这是因为，当我们创建多个子线程时，无法保证线程执行的顺序。这是多线程（如前所述）的一个特性，而不是一个错误。但这也是与线程一起工作的挑战之一，因为它给跨线程同步活动带来了困难。我们将在本章稍后学习如何解决这个问题。
- en: We've so far seen how to use the `thread::spawn()` function to create a new
    thread. Let's now see the second way to create a new thread.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到了如何使用`thread::spawn()`函数创建新线程。现在让我们看看创建新线程的第二种方法。
- en: 'The `thread::spawn()` function uses default parameters for thread name and
    stack size. If you''d like to set them explicitly, you can use `thread:Builder`.
    This is a *thread factory* that uses the `Builder` pattern to configure the properties
    of a new thread. The previous example has been rewritten here using the `Builder`
    pattern:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '`thread::spawn()`函数使用默认参数来设置线程名称和堆栈大小。如果你想明确设置它们，可以使用`thread:Builder`。这是一个*线程工厂*，它使用`Builder`模式来配置新线程的属性。以下示例已经使用`Builder`模式重写：'
- en: '[PRE3]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The changes are highlighted in the code. We are creating a new `builder` object
    by using the `new()` function, and then configuring the name of the thread using
    the `name()` method. We're then using the `spawn()` method on an instance of the
    `Builder` pattern. Note that the `spawn()` method returns a `JoinHandle` type
    wrapped in `io::Result<JoinHandle<T>>`, so we have to unwrap the return value
    of the method to retrieve the child process handle.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 代码中的更改已被突出显示。我们通过使用`new()`函数创建一个新的`builder`对象，然后使用`name()`方法配置线程的名称。然后我们在`Builder`模式的实例上使用`spawn()`方法。请注意，`spawn()`方法返回一个被`io::Result<JoinHandle<T>>`类型包裹的`JoinHandle`类型，因此我们必须解包方法的返回值以检索子进程句柄。
- en: Run the code and you'll see the four thread names printed to your terminal.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 运行代码，你将在终端看到四个线程名称被打印出来。
- en: We've so far seen how to spawn new threads. Let's now take a look at error handling
    while working with threads.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到了如何创建新的线程。现在让我们看看在处理线程时如何进行错误处理。
- en: Error handling in threads
  id: totrans-72
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 线程中的错误处理
- en: 'The Rust Standard Library contains the `std::thread::Result` type, which is
    a specialized `Result` type for threads. An example of how to use this is shown
    in the following code:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: Rust标准库包含`std::thread::Result`类型，这是一个专门为线程设计的`Result`类型。以下代码展示了如何使用此类型的一个示例：
- en: '[PRE4]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: We have a function, `copy_file()`, that copies a source file to a destination
    file. This function returns a `thread::Result<()>` type, which we are unwrapping
    using a `match` statement in the `main()` function. If the `copy_file()` function
    returns a `Result::Err` variant, we handle it by printing an error message.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有一个名为`copy_file()`的函数，该函数将源文件复制到目标文件。这个函数返回一个`thread::Result<()>`类型的值，我们在`main()`函数中使用`match`语句来解包它。如果`copy_file()`函数返回`Result::Err`变体，我们通过打印错误信息来处理它。
- en: 'Run the program with `cargo run` with an invalid source filename. You will
    see the error message: `Ok()` branch of the `match` clause, and the success message
    will be printed.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`cargo run`运行程序并传入一个无效的源文件名。你将看到错误信息：`match`子句的`Ok()`分支，成功信息将被打印出来。
- en: 'This example shows us how to handle errors propagated by a thread in the calling
    function. What if we want a way to recognize that the current thread is panicking,
    even before it is propagated to the calling function. The Rust Standard Library
    has a function, `thread::panicking()`, available in the `std::thread` module for
    this. Let''s learn how to use it by modifying the previous example:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 这个例子展示了如何处理由线程传播到调用函数中的错误。如果我们想在错误传播到调用函数之前就识别出当前线程正在恐慌，该怎么办？Rust标准库在`std::thread`模块中提供了一个名为`thread::panicking()`的函数，用于此目的。让我们通过修改前面的例子来学习如何使用它：
- en: '[PRE5]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: We've created a struct, `Filenames`, which contains the source and destination
    filenames to copy. We're initializing the source filename with an invalid value.
    We're also implementing the `Drop` trait for the `Filenames` struct, which gets
    called when an instance of the struct goes out of scope. In this `Drop` trait
    implementation, we are using the `thread::panicking()` function to check if the
    current thread is panicking, and are handling it by printing out an error message.
    The error is then propagated to the main function, which also handles the thread
    error and prints out another error message.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 我们创建了一个名为`Filenames`的结构体，其中包含要复制的源文件名和目标文件名。我们使用一个无效值初始化源文件名。我们还为`Filenames`结构体实现了`Drop`特质，当结构体的实例超出作用域时会被调用。在这个`Drop`特质实现中，我们使用`thread::panicking()`函数来检查当前线程是否正在恐慌，并通过打印错误信息来处理它。然后错误被传播到主函数，主函数也处理线程错误并打印出另一个错误信息。
- en: 'Run the program with `cargo run` and an invalid source filename, and you will
    see the following messages printed to your terminal:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`cargo run`运行程序并传入一个无效的源文件名，你将在终端看到以下信息打印出来：
- en: '[PRE6]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Also, note the use of the `move` keyword in the `closure` supplied to the `spawn()`
    function. This is needed for the thread to transfer ownership of the `file_struct`
    data structure from the `main` thread to the newly spawned thread.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，请注意在提供给`spawn()`函数的`closure`中使用`move`关键字。这对于线程将`file_struct`数据结构的所有权从主线程转移到新创建的线程是必需的。
- en: We've seen how to handle thread panic in the calling function and also how to
    detect if the current thread is panicking. Handling errors in child threads is
    very important to ensure that the error is isolated and does not bring the whole
    process down. Hence special attention is needed to design error handling for multi-threaded
    programs.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到了如何在调用函数中处理线程恐慌，以及如何检测当前线程是否正在恐慌。处理子线程中的错误对于确保错误被隔离并且不会使整个进程崩溃非常重要。因此，在设计多线程程序的错误处理时需要特别注意。
- en: Next, we'll move on to the topic of how to synchronize computations across threads,
    which is an important aspect of writing concurrent programs.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将继续讨论如何在线程之间同步计算的话题，这是编写并发程序的一个重要方面。
- en: Message passing between threads
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 线程间的消息传递
- en: Concurrency is a powerful feature that enables the writing of new kinds of applications.
    However, the execution and debugging of concurrent programs are difficult because
    their execution is non-deterministic. We saw this through examples in the previous
    section where the order of print statements varied for each run of the program.
    The order in which the threads will be executed is not known ahead of time. A
    concurrent program developer must make sure that the program will execute correctly
    overall, regardless of the order in which the individual threads are executed.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 并发是一个强大的功能，它使得编写新类型的应用程序成为可能。然而，并发程序的执行和调试是困难的，因为它们的执行是非确定性的。我们在上一节中的示例中看到了这一点，其中打印语句的顺序在每次程序运行时都不同。线程将执行的顺序在事先是未知的。并发程序的开发者必须确保程序将总体上正确执行，而不管个别线程执行的顺序如何。
- en: One way to ensure program correctness in the face of the unpredictable ordering
    of thread execution is to introduce mechanisms for synchronizing activities across
    threads. One such model for concurrent programming is *message-passing concurrency*.
    It is a way to structure the components of a concurrent program. In our case,
    concurrent components are *threads* (but they can also be processes). The Rust
    Standard Library has implemented a *message-passing concurrency* solution called
    **channels**. *A channel* is basically like a pipe, with two parts – a *producer*
    and a *consumer*. The *producer* puts a message into a *channel*, and a *consumer*
    reads from the *channel*.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在面对线程执行顺序不可预测的情况下，确保程序正确性的一个方法是通过引入跨线程同步活动的机制。这种并发编程模型之一是 *消息传递并发*。这是一种结构化并发程序组件的方法。在我们的案例中，并发组件是
    *线程*（但它们也可以是进程）。Rust 标准库实现了一个名为 **channels** 的 *消息传递并发* 解决方案。*通道* 基本上就像一个管道，有两个部分
    - 一个 *生产者* 和一个 *消费者*。*生产者* 将消息放入 *通道*，而 *消费者* 从 *通道* 中读取。
- en: 'Many programming languages implement the concept of channels for inter-thread
    communications. But Rust''s implementation of *channels* has a special property
    – *multiple producer single consumer* (`mpsc`). This means, there can be multiple
    sending ends but only one consuming end. Translate this to the world of threads:
    we can have multiple threads that send values into a channel, but there can be
    only one thread that can receive and consume these values. Let''s see how this
    works with an example that we''ll build out step by step. The complete code listing
    is also provided in the Git repo for the chapter under `src/message-passing.rs`:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 许多编程语言实现了线程间通信的概念。但 Rust 的 *通道* 实现有一个特殊的属性 - *多生产者单消费者* (`mpsc`)。这意味着可以有多个发送端，但只有一个消费端。将此翻译成线程的世界：我们可以有多个线程将值发送到通道，但只能有一个线程可以接收并消费这些值。让我们通过一个我们将逐步构建的示例来看看这是如何工作的。完整的代码列表也提供在
    Git 仓库中该章节的 `src/message-passing.rs`：
- en: 'Let''s first declare the module imports – the `mpsc` and `thread` modules from
    the standard library:'
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先声明模块导入 - 从标准库中导入的 `mpsc` 和 `thread` 模块：
- en: '[PRE7]'
  id: totrans-90
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Within the `main()` function, create a new `mpsc` channel:'
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `main()` 函数中，创建一个新的 `mpsc` 通道：
- en: '[PRE8]'
  id: totrans-92
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Clone the channel so we can have two transmitting threads:'
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 复制通道，以便我们可以有两个传输线程：
- en: '[PRE9]'
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Note that we now have two transmission handles – `transmitter1` and `transmitter2`,
    and one receiving handle – `receiver`.
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 注意，我们现在有两个传输句柄 - `transmitter1` 和 `transmitter2`，以及一个接收句柄 - `receiver`。
- en: 'Spawn a new thread moving the transmission handle `transmitter1` into the thread
    closure. Inside this thread, send a bunch of values into the channel using the
    transmission handle:'
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个新的线程，将传输句柄 `transmitter1` 移入线程闭包中。在这个线程内部，使用传输句柄向通道发送一系列值：
- en: '[PRE10]'
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Spawn a second thread moving the transmission handle `transmitter2` into the
    thread closure. Inside this thread, send another bunch of values into the channel
    using the transmission handle:'
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 启动一个第二线程，将传输句柄`transmitter2`移动到线程闭包中。在这个线程内部，使用传输句柄将另一组值发送到通道中：
- en: '[PRE11]'
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'In the main thread of the program, use the receiving handle of the channel
    to consume the values being written into the channel by the two child threads:'
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在程序的主线程中，使用通道的接收句柄来消费两个子线程写入通道的值：
- en: '[PRE12]'
  id: totrans-101
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The complete code listing is shown:'
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 完整的代码列表如下：
- en: '[PRE13]'
  id: totrans-103
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Run the program with `cargo run`. (*Note:* If you are running code from the
    Packt Git repo, use `cargo run --bin message-passing`). You'll see the values
    printed out in the main program thread, which are sent from the two child threads.
    Each time you run the program, you may get a different order in which the values
    are received, as the order of thread execution is *non-deterministic*.
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`cargo run`运行程序。（*注意：*如果你是从Packt Git仓库运行代码，请使用`cargo run --bin message-passing`）。你将在主程序线程中看到打印出来的值，这些值是从两个子线程发送过来的。每次运行程序时，你可能会收到不同的值接收顺序，因为线程执行的顺序是*非确定性的*。
- en: The `mpsc` channel offers a lightweight inter-thread synchronization mechanism
    that can be used for message-based communications across threads. This type of
    concurrent programming model is useful when you want to spawn out multiple threads
    for different types of computations and want to have the main thread aggregate
    the results.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '`mpsc`通道提供了一个轻量级的线程间同步机制，可用于跨线程的消息传递通信。这种并发编程模型在你想要为不同类型的计算启动多个线程，并希望主线程汇总结果时非常有用。'
- en: One aspect to note in `mpsc` is that once a value is sent down a channel, the
    sending thread no longer has ownership of it. If you want to retain ownership
    or continue to use a value, but still need a way to share the value with other
    threads, there is another concurrency model that Rust supports called **shared-state
    concurrency**. We'll look at that next.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 在`mpsc`中需要注意的一个方面是，一旦一个值被发送到通道中，发送线程就不再拥有它。如果你想保留所有权或继续使用一个值，但仍然需要一种方式与其他线程共享这个值，那么Rust支持另一种并发模型，称为**共享状态并发**。我们将在下一节中探讨这一点。
- en: Achieving concurrency with shared state
  id: totrans-107
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实现共享状态并发
- en: In this section, we'll discuss the second model of concurrent programming supported
    in the Rust Standard Library – the *shared-state* or *shared-memory* model of
    concurrency. Recall that all threads in a process share the same process memory
    space, so why not use that as a way to communicate between threads, rather than
    message-passing? We'll look at how to achieve this using Rust.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将讨论Rust标准库支持的第二种并发编程模型——*共享状态*或*共享内存*并发模型。回想一下，进程中的所有线程都共享相同的进程内存空间，那么为什么不使用它作为线程间通信的方式，而不是消息传递呢？我们将探讨如何使用Rust实现这一点。
- en: A combination of `Mutex` and `Arc` constitutes the primary way to implement
    *shared-state concurrency*. `Mutex` (mutual exclusion lock) is a mechanism that
    allows only one thread to access a piece of data at one time. First, a data value
    is wrapped in a `Mutex` type, which acts as a lock. You can visualize `Mutex`
    like a box with an external lock, protecting something valuable inside. To access
    what's in the box, first of all, we have to ask someone to open the lock and hand
    over the box. Once we're done, we hand over the box back and someone else asks
    to take charge of it.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '`Mutex`和`Arc`的组合构成了实现*共享状态并发*的主要方式。`Mutex`（互斥锁）是一种机制，它允许一次只有一个线程访问一块数据。首先，一个数据值被包裹在一个`Mutex`类型中，它充当一个锁。你可以将`Mutex`想象成一个带有外部锁的盒子，里面保护着一些有价值的东西。要访问盒子里的东西，首先我们必须请求某人打开锁并交出盒子。一旦我们完成，我们就把盒子交回去，然后其他人请求接管它。'
- en: Similarly, to access or mutate a value protected by a `Mutex`, we must acquire
    the lock first. Asking for a lock on a `Mutex` object returns a `MutexGuard` type,
    which lets us access the inner value. During this time, no other thread can access
    this value protected by the `MutexGuard`. Once we're done using it, we have to
    release the `MutexGuard` (which Rust does for us automatically as the `MutexGuard`
    goes out of scope, without us having to call a separate `unlock()` method).
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，要访问或修改由`Mutex`保护的价值，我们必须首先获取锁。在`Mutex`对象上请求锁返回一个`MutexGuard`类型，它允许我们访问内部值。在这段时间内，没有其他线程可以访问这个由`MutexGuard`保护的价值。一旦我们使用完毕，我们必须释放`MutexGuard`（Rust会为我们自动释放，因为`MutexGuard`超出了作用域，我们不需要调用单独的`unlock()`方法）。
- en: But there is another issue to resolve. Protecting a value with a lock is just
    one part of the solution. We also have to give ownership of a value to multiple
    threads. To support multiple ownership of a value, Rust uses *reference-counted*
    *smart pointers* – `Rc` and `Arc`. `Rc` allows multiple owners for a value through
    its `clone()` method. But `Rc` is not safe to use across threads, and `Arc` (which
    stands for Atomically Reference Counted) is the thread-safe equivalent of `Rc`.
    So, we need to wrap the `Mutex` with an `Arc` reference-counted smart-pointer,
    and transfer ownership of the value across threads. Once the ownership of the
    Arc-protected Mutex is transferred to another thread, the receiving thread can
    call `lock()` on the Mutex to get exclusive access to the inner value. The Rust
    ownership model helps in enforcing the rules around this model.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 但还有一个问题需要解决。使用锁来保护一个值只是解决方案的一部分。我们还需要将一个值的所有权赋予多个线程。为了支持一个值的多个所有权，Rust 使用了*引用计数*的*智能指针*
    – `Rc` 和 `Arc`。`Rc` 通过其 `clone()` 方法允许一个值有多个所有者。但是 `Rc` 在线程间使用并不安全，而 `Arc`（代表原子引用计数）是
    `Rc` 的线程安全版本。因此，我们需要用 `Arc` 引用计数的智能指针包装 `Mutex`，并在线程间传递值的所有权。一旦 Arc-保护的 Mutex
    的所有权被转移到另一个线程，接收线程就可以在 Mutex 上调用 `lock()` 来获取对内部值的独占访问。Rust 的所有权模型有助于强制执行围绕此模型的规定。
- en: The way the `Arc<T>` type works is that it provides the shared ownership of
    a value of type `T`, allocated in the heap. By calling the associated function
    `clone()` on an `Arc` instance, a new instance of the `Arc` reference-counted
    pointer is created, which points to the same allocation on the heap as the source
    `Arc`, while increasing a reference count. With each `clone()`, the reference
    count is increased by the `Arc` smart pointer. When each `cloned()` pointer goes
    out of scope, the reference counter is decremented. When the last of the clones
    go out of scope, both the `Arc` pointer and the value it points to (in the heap)
    are destroyed.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '`Arc<T>` 类型的工作方式是，它提供了类型为 `T` 的值的共享所有权，该值在堆上分配。通过在 `Arc` 实例上调用关联函数 `clone()`，创建了一个新的
    `Arc` 引用计数指针实例，它指向与源 `Arc` 相同的堆分配，同时增加引用计数。每次调用 `clone()`，`Arc` 智能指针都会增加引用计数。当每个
    `cloned()` 指针超出作用域时，引用计数器会减少。当最后一个克隆超出作用域时，`Arc` 指针及其指向的值（在堆上）都会被销毁。'
- en: To summarize, `Mutex` ensures that at most one thread is able to access some
    data at one time, while `Arc` enables shared ownership of some data and prolongs
    its lifetime until all the threads have finished using it.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，`Mutex` 确保最多只有一个线程能同时访问某些数据，而 `Arc` 使某些数据的共享所有权成为可能，并延长其生命周期，直到所有线程都完成使用它。
- en: Let's see the usage of `Mutex` with `Arc` to demonstrate shared-state concurrency
    with a step-by-step example. This time, we'll write a more complex example than
    just incrementing a shared counter value across threads. We'll take the example
    we wrote in [*Chapter 6*](B16405_06_Final_NM_ePUB.xhtml#_idTextAnchor101), *Working
    with Files and Directories in Rust*, to compute source file stats for all Rust
    files in a directory tree, and modify it to make it a concurrent program. We'll
    define the structure of the program in the next section. The complete code for
    this section can be found in the Git repo under `src/shared-state.rs`.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过一个逐步的示例来查看 `Mutex` 与 `Arc` 的用法，以演示共享状态并发。这次，我们将编写一个比仅仅在多个线程间增加共享计数器值更复杂的示例。我们将使用我们在[*第
    6 章*](B16405_06_Final_NM_ePUB.xhtml#_idTextAnchor101)中写的示例，*在 Rust 中处理文件和目录*，来计算目录树中所有
    Rust 文件的源文件统计信息，并将其修改为并发程序。我们将在下一节中定义程序的结构。本节的完整代码可以在 Git 仓库的 `src/shared-state.rs`
    下找到。
- en: Defining the program structure
  id: totrans-115
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 定义程序结构
- en: What we'd like to do is to take a list of directories as input to our program,
    compute source file statistics for each file within each of these directories,
    and print out a consolidated set of source code stats.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望做的是将目录列表作为程序的输入，计算每个目录中每个文件的源文件统计信息，并打印出一系列源代码统计信息。
- en: Let's first create a `dirnames.txt` file in the root folder of the cargo project,
    containing a list of directories with a full path, one per line. We'll read each
    entry from this file and spawn a separate thread to compute the source file stats
    for the Rust files within that directory tree. So, if there are five directory-name
    entries in the file, there will be five threads created from the main program,
    each of which will recursively walk through the directory structure of the entry,
    and compute the consolidated Rust source file stats. Each thread will increment
    the computed value in a shared data structure. We'll use `Mutex` and `Arc` to
    protect access and update the shared data safely across threads.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们首先在cargo项目的根目录中创建一个`dirnames.txt`文件，其中包含一个目录的完整路径列表，每行一个。我们将从该文件中读取每个条目，并为该目录树中的Rust文件启动一个单独的线程来计算源文件统计信息。因此，如果文件中有五个目录名称条目，主程序将创建五个线程，每个线程将递归地遍历条目的目录结构，并计算合并的Rust源文件统计信息。每个线程将增加共享数据结构中的计算值。我们将使用`Mutex`和`Arc`来保护线程间安全地访问和更新共享数据。
- en: 'Let''s start writing the code:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始编写代码：
- en: 'We''ll start with the module imports for this program:'
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将从这个程序的模块导入开始：
- en: '[PRE14]'
  id: totrans-120
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Define a struct to store the source file stats:'
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个结构体来存储源文件统计信息：
- en: '[PRE15]'
  id: totrans-122
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Within the `main()` function, create a new instance of `SrcStats`, protect
    it with a `Mutex` lock, and then wrap it inside an `Arc` type:'
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`main()`函数中，创建一个新的`SrcStats`实例，使用`Mutex`锁来保护它，然后将其包装在`Arc`类型中：
- en: '[PRE16]'
  id: totrans-124
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Read the `dirnames.txt` file, and store the individual entries in a vector:'
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 读取`dirnames.txt`文件，并将单个条目存储在一个向量中：
- en: '[PRE17]'
  id: totrans-126
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Iterate through the `dir_lines` vector, and for each entry, spawn a new thread
    to perform the following two steps:'
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 遍历`dir_lines`向量，并为每个条目启动一个新线程以执行以下两个步骤：
- en: a) Accumulate the list of files from each subdirectory in the tree.
  id: totrans-128
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a) 累积树中每个子目录的文件列表。
- en: b) Then open each file and compute the stats. Update the stats in the shared-memory
    struct protected by `Mutex` and `Arc`.
  id: totrans-129
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: b) 然后打开每个文件并计算统计信息。更新由`Mutex`和`Arc`保护的共享内存结构中的统计信息。
- en: 'The overall skeletal structure of the code for this step looks like this:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 此步骤的代码整体结构看起来像这样：
- en: '[PRE18]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: In this section, we read the list of directory entries for computing source
    file statistics from a file. We then iterated through the list to spawn a thread
    to process each entry. In the next section, we'll define the processing to be
    done in each thread.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们从文件中读取目录条目列表以计算源文件统计信息。然后我们遍历列表以启动一个线程来处理每个条目。在下一节中，我们将定义每个线程中要执行的处理。
- en: Aggregating source file statistics in shared state
  id: totrans-133
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在共享状态中聚合源文件统计信息
- en: 'In this section, we''ll write the code for computing source file statistics
    in each thread and aggregate the results in shared state. We''ll look at the code
    in two parts – *sub-steps A* and *B*:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将编写每个线程中计算源文件统计信息的代码，并将结果聚合到共享状态中。我们将分两部分查看代码 – *子步骤A*和*子步骤B*：
- en: 'In *sub-step A*, let''s read through each subdirectory under the directory
    entry, and accumulate the consolidated list of all Rust source files in the `file_entries`
    vector. The code for *sub-step A* is shown. Here, we are first creating two vectors
    to hold the directory and filenames respectively. Then we are iterating through
    the directory entries of each item from the `dirnames.txt` file, and accumulating
    the entry names into the `dir_entries` or `file_entries` vector depending upon
    whether it is a directory or an individual file:'
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在*子步骤A*中，让我们遍历目录条目下的每个子目录，并将所有Rust源文件的合并列表累积到`file_entries`向量中。*子步骤A*的代码如下。在这里，我们首先创建两个向量来分别存储目录和文件名。然后我们遍历`dirnames.txt`文件中的每个项目目录条目，根据它是目录还是单个文件，将条目名称累积到`dir_entries`或`file_entries`向量中：
- en: '[PRE19]'
  id: totrans-136
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: At the end of *sub-step A*, all individual filenames are stored in the `file_entries`
    vector, which we will use in *sub-step B* for further processing.
  id: totrans-137
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在*子步骤A*结束时，所有单个文件名都存储在`file_entries`向量中，我们将在*子步骤B*中使用它进行进一步处理。
- en: 'In *sub-step B*, we''ll read each file from the `file_entries` vector, compute
    the source stats for each file, and save the values in the shared memory struct.
    Here is the code snippet for *sub-step B*:'
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在*子步骤B*中，我们将从`file_entries`向量中读取每个文件，计算每个文件的源统计信息，并将值保存到共享内存结构中。以下是*子步骤B*的代码片段：
- en: '[PRE20]'
  id: totrans-139
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Let''s again review the skeletal structure of the program shown next. We''ve
    so far seen the code to be executed within the thread, which includes processing
    for steps A and B:'
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们再次回顾接下来展示的程序框架。到目前为止，我们已经看到了线程中要执行的代码，这包括步骤 A 和 B 的处理：
- en: '[PRE21]'
  id: totrans-141
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Let''s look at the last part of the code now. As discussed earlier, in order
    to ensure that the main thread does not complete before the child threads are
    completed, we have to join the child thread handles with the main threads. Also,
    let''s print out the final value of the thread-safe `stats_counter` struct, which
    contains aggregated source stats from all the Rust source files under the directory
    (updated by the individual threads):'
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们来看代码的最后部分。正如之前讨论的，为了确保主线程在子线程完成之前不完成，我们必须将子线程句柄与主线程连接起来。此外，让我们打印出线程安全的 `stats_counter`
    结构体的最终值，该结构体包含目录下所有 Rust 源文件（由各个线程更新）的聚合源代码统计信息：
- en: '[PRE22]'
  id: totrans-143
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: The complete code listing can be found in the Git repo for the chapter in `src/shared-state.rs`.
  id: totrans-144
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 完整的代码列表可以在 `src/shared-state.rs` 中找到的该章节的 Git 仓库中。
- en: Before running this program, ensure to create a file, `dirnames.txt`, in the
    root folder of the cargo project, containing a list of directory entries with
    a full path, each on a separate line.
  id: totrans-145
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在运行此程序之前，请确保在 cargo 项目的根目录中创建一个名为 `dirnames.txt` 的文件，其中包含具有完整路径的目录条目列表，每个条目占一行。
- en: 'Run the project with `cargo run`. (*Note*: If you are running code from the
    Packt Git repo, use `cargo run --bin shared-state`.) You will see the consolidated
    source stats printed out. Note that we have now implemented a multi-threaded version
    of the project we wrote in [*Chapter 6*](B16405_06_Final_NM_ePUB.xhtml#_idTextAnchor101),
    *Working with Files and Directories in Rust*. As an exercise, alter this example
    to implement the same project with the *message-passing concurrency* model.'
  id: totrans-146
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `cargo run` 运行项目。（*注意*：如果您正在从 Packt Git 仓库运行代码，请使用 `cargo run --bin shared-state`。）您将看到打印出的合并后的源代码统计信息。请注意，我们现在已经实现了我们在
    [*第 6 章*](B16405_06_Final_NM_ePUB.xhtml#_idTextAnchor101) 中编写的项目的多线程版本，即 *在 Rust
    中处理文件和目录*。作为一个练习，修改此示例以使用 *消息传递并发* 模型实现相同的项目。
- en: In this section, we've seen how multiple threads can safely write to a shared
    value (wrapped in `Mutex` and `Arc`) that is stored in process heap memory, in
    a thread-safe manner. In the next section, we will review one more mechanism available
    to control thread execution, which is to selectively pause the processing of the
    current thread.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们看到了多个线程如何安全地向存储在进程堆内存中的共享值（包装在 `Mutex` 和 `Arc` 中）写入，以线程安全的方式进行。在下一节中，我们将回顾另一种可用于控制线程执行的机制，即选择性地暂停当前线程的处理。
- en: Send and Sync traits
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 发送和同步特性
- en: We saw earlier how a data type can be shared across threads, and how messages
    can be passed between threads. There is another aspect of concurrency in Rust
    though. Rust defines data types as thread-safe or not.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前看到数据类型可以在线程之间共享，以及消息如何在线程之间传递。然而，Rust 中还有并发的一个方面。Rust 将数据类型定义为线程安全或不安全。
- en: 'From a concurrency perspective, there are two categories of data types in Rust:
    those that are `Send` (that is, implement the `Send` trait), which means they
    are safe to be transferred from one thread to another. And the rest are *thread-unsafe*
    types. A related concept is `Sync`, which is associated with references of types.
    A type is considered to be `Sync` if its reference can be passed to another thread
    safely. So, `Send` means it is safe to transfer ownership of a type from one thread
    to another, while `Sync` means the data type can be shared (using references)
    safely by multiple threads at the same time. Note though that in `Send`, after
    a value has been transferred from the sending to the receiving thread, the sending
    thread can no longer use that value.'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 从并发角度来看，Rust 中的数据类型分为两类：那些实现了 `Send` 特性的（即，可以安全地从一条线程转移到另一条线程）。其余的都是 *线程不安全*
    类型。一个相关的概念是 `Sync`，它与类型的引用相关联。如果一个类型的引用可以安全地传递到另一个线程，则认为该类型是 `Sync`。因此，`Send`
    表示从一个线程安全地转移到另一个线程的所有权是安全的，而 `Sync` 表示数据类型可以通过引用（同时）安全地被多个线程共享。但请注意，在 `Send` 中，在值从发送线程转移到接收线程之后，发送线程就不再可以使用该值了。
- en: '`Send` and `Sync` are also automatically derived traits. This means that if
    a type consists of members that implement `Send` or `Sync` types, the type itself
    automatically becomes `Send` or `Sync`. The Rust primitives (almost all of them)
    implement `Send` and `Sync`, which means if you create a custom type from Rust
    primitives, your custom type also becomes `Send` or `Sync`. We''ve seen an example
    of this in the previous section, where the `SrcStats` (source stats) struct was
    transferred across the boundaries of threads without us having to explicitly implement
    `Send` or `Sync` on the struct.'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '`Send`和`Sync`也是自动推导的特性。这意味着如果一个类型由实现`Send`或`Sync`类型的成员组成，那么该类型本身会自动成为`Send`或`Sync`。Rust的原始类型（几乎全部）都实现了`Send`和`Sync`，这意味着如果你从Rust原始类型创建一个自定义类型，你的自定义类型也会成为`Send`或`Sync`。我们已经在上一节中看到了一个例子，其中`SrcStats`（源统计）结构体在不需要我们显式地在结构体上实现`Send`或`Sync`的情况下，跨线程边界进行传输。'
- en: However, if there is a need to implement `Send` or `Sync` traits for a data
    type manually, it would have to be done in unsafe Rust.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果需要手动为数据类型实现`Send`或`Sync`特性，这必须在`unsafe Rust`中进行。
- en: To summarize, in Rust, every data type is classified as either *thread-safe*
    or *thread-unsafe*, and the Rust compiler enforces the safe transfer or sharing
    of thread-safe types across threads.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，在Rust中，每个数据类型都被分类为*线程安全*或*线程不安全*，Rust编译器强制执行线程安全类型的线程间安全传输或共享。
- en: Pausing thread execution with timers
  id: totrans-154
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用定时器暂停线程执行
- en: 'Sometimes, during the processing of a thread, there may be a need to pause
    execution either to wait for another event or to synchronize execution with other
    threads. Rust provides support for this using the `std::thread::sleep` function.
    This function takes a time duration of type `time::Duration` and pauses execution
    of the thread for the specified time. During this time, the processor time can
    be made available to other threads or applications running on the computer system.
    Let''s see an example of the usage of `thread::sleep`:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，在处理线程的过程中，可能需要暂停执行，要么是为了等待另一个事件，要么是为了与其他线程同步执行。Rust通过`std::thread::sleep`函数提供对此类操作的支持。此函数接受一个类型为`time::Duration`的时间持续时间，并暂停线程的执行指定的时间。在这段时间内，处理器时间可以提供给其他线程或计算机系统上运行的其他应用程序。让我们看看`thread::sleep`的使用示例：
- en: '[PRE23]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Using the `sleep()` function is fairly straightforward, but this blocks the
    current thread and it is important to make judicious use of this in a multi-threaded
    program. An alternative to using `sleep()` would be to use an async programming
    model to implement threads with non-blocking I/O.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`sleep()`函数相当简单，但它会阻塞当前线程，在多线程程序中合理使用这一点非常重要。使用`sleep()`的替代方案是使用异步编程模型来实现具有非阻塞I/O的线程。
- en: Async I/O in Rust
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: Rust中的异步I/O
- en: In the multi-threaded model, if there is a blocking I/O call in any thread,
    it blocks the program workflow. The *async* model relies on non-blocking system
    calls for I/O, for example, to access the filesystem or network. In the example
    of a web server with multiple simultaneous incoming connections, instead of spawning
    a separate thread to handle each connection in a blocking manner, *async* I/O
    relies on a runtime that does not block the current thread but instead schedules
    other tasks while waiting on I/O.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 在多线程模型中，如果任何线程中有阻塞I/O调用，它将阻塞程序的工作流程。*异步*模型依赖于非阻塞的系统调用进行I/O，例如，访问文件系统或网络。在具有多个同时传入连接的Web服务器示例中，而不是为每个连接创建一个单独的线程以阻塞方式处理，*异步*
    I/O依赖于一个不会阻塞当前线程但会在等待I/O时安排其他任务的运行时。
- en: While Rust has built-in `Async/Await` syntax, which makes it easier to write
    *async* code, it does not provide any asynchronous system call support. For this,
    we need to rely on external libraries such as `Tokio`, which provide both the
    *async runtime* (executor) and the *async* versions of the I/O functions that
    are present in the Rust Standard Library.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然 Rust 内置了`Async/Await`语法，这使得编写*异步*代码变得更容易，但它不提供任何异步系统调用支持。为此，我们需要依赖外部库，如`Tokio`，它提供了*异步运行时*（执行器）以及Rust标准库中存在的I/O函数的*异步*版本。
- en: So, when would one use *async* versus the *multi-threaded* approach to concurrency?
    The broad thumb-rule is that the *async* model is suited to programs that perform
    a lot of I/O, whereas, for computation-intensive (CPU-bound) tasks, *multi-threaded
    concurrency* is a better approach. Keep in mind though that it is not a binary
    choice, as in practice it is not uncommon to see *async* programs that also utilize
    *multi-threading* in a hybrid model.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，何时应该使用*异步*与*多线程*的并发方法呢？一个粗略的规则是，*异步*模型适合执行大量 I/O 的程序，而对于计算密集型（CPU-bound）任务，*多线程并发*是一个更好的方法。但请注意，这并不是一个二选一的选择，因为在实践中，看到同时利用*异步*和*多线程*的混合模型并不罕见。
- en: 'For more information on async in Rust, refer to the following link: [https://rust-lang.github.io/async-book/](https://rust-lang.github.io/async-book/).'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 想了解更多关于 Rust 中异步的信息，请参阅以下链接：[https://rust-lang.github.io/async-book/](https://rust-lang.github.io/async-book/)。
- en: Summary
  id: totrans-163
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we covered the basics of concurrency and multi-threaded programming
    in Rust. We started by reviewing the need for concurrent programming models. We
    understood the differences between the concurrent and parallel execution of programs.
    We learned how to spawn new threads using two different methods. We handled errors
    using a special `Result` type in the thread module and also learned how to check
    whether the current thread is panicking. We looked at how threads are laid out
    in process memory. We discussed two techniques for synchronizing processing across
    threads – *message-passing concurrency* and *shared-state concurrency*, with practical
    examples. As a part of this, we learned about channels, `Mutex` and `Arc` in Rust,
    and the role they play in writing concurrent programs. We then discussed how Rust
    classifies data types as *thread-safe* or not, and saw how to pause the execution
    of the current thread.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们介绍了 Rust 中并发和多线程编程的基础知识。我们首先回顾了并发编程模型的需求。我们理解了程序并发执行和并行执行之间的区别。我们学习了如何使用两种不同的方法来创建新线程。我们使用线程模块中的特殊
    `Result` 类型来处理错误，并学习了如何检查当前线程是否正在恐慌。我们探讨了线程在进程内存中的布局。我们讨论了两种跨线程同步处理的技术——*消息传递并发*和*共享状态并发*，并提供了实际示例。作为其中的一部分，我们学习了
    Rust 中的通道、`Mutex` 和 `Arc`，以及它们在编写并发程序中的作用。然后，我们讨论了 Rust 如何将数据类型分类为*线程安全*或*不安全*，并展示了如何暂停当前线程的执行。
- en: This concludes the chapter on managing concurrency in Rust. This also concludes
    *Section 2* of this book, which is on managing and controlling system resources
    in Rust.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 这就结束了 Rust 中管理并发的章节。这也结束了本书的*第2节*，该节讨论了在 Rust 中管理和控制系统资源。
- en: We will now move on to the last part of the book – *Section 3* covering *advanced
    topics*. In the next chapter, we will cover how to perform *device I/O* in Rust,
    and internalize learning through an example project.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将继续本书的最后一部分——*第3节*，涵盖*高级主题*。在下一章中，我们将介绍如何在 Rust 中执行*设备 I/O*，并通过一个示例项目来内化学习。
