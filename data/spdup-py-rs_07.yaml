- en: '*Chapter 8*: Structuring an End-to-End Python Package in Rust'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第 8 章*：在 Rust 中构建端到端 Python 包的结构'
- en: Now that we have covered enough Rust and `pyo3` to theoretically build a range
    of real-world solutions, we must be careful. It would not be good if we decided
    to reinvent the wheel in Rust and ended up with a slower outcome after coding
    the solution. Hence, understanding how to solve a problem and testing our implementation
    is important. In this chapter, we will be building a Python package using Rust
    that solves a simplified real-world problem and loads data from files to build
    a catastrophe model. We will structure the package in a manner where we can slot
    in extra functionality if our model gets more complex. Once we build our model,
    we will test it to see whether our implementation is worth it in terms of scaling
    and speed.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经掌握了足够的 Rust 和 `pyo3` 知识，理论上可以构建一系列现实世界的解决方案，我们必须小心。如果我们决定在 Rust 中重新发明轮子，并在编码解决方案后得到较慢的结果，那就不好了。因此，理解如何解决问题并测试我们的实现非常重要。在本章中，我们将使用
    Rust 构建一个 Python 包，该包解决一个简化的现实世界问题，并从文件中加载数据来构建灾难模型。我们将以这种方式构建包，以便在模型变得更加复杂时可以添加额外的功能。一旦我们构建了模型，我们将对其进行测试，以查看我们的实现是否在扩展和速度方面值得。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Breaking down a catastrophe modeling problem for our package
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将灾难建模问题分解为我们的包
- en: Building an end-to-end solution as a package
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将端到端解决方案作为包构建
- en: Utilizing and testing our package
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 利用和测试我们的包
- en: This chapter enables us to take what we have learned throughout the book and
    solve a real-world problem and handle data files. Testing our solution will also
    enable us to avoid spending too much time on a solution that will have a slower
    result, preventing us from potentially missing our shot at implementing Rust in
    Python systems at our place of work.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 本章使我们能够将本书中学到的知识应用于解决现实世界的问题，并处理数据文件。测试我们的解决方案也将使我们避免花费太多时间在结果较慢的解决方案上，从而防止我们错过在办公场所实施
    Rust 在 Python 系统中的机会。
- en: Technical requirements
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: The code and data for this chapter can be found at [https://github.com/PacktPublishing/Speed-up-your-Python-with-Rust/tree/main/chapter_eight](https://github.com/PacktPublishing/Speed-up-your-Python-with-Rust/tree/main/chapter_eight).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的代码和数据可以在[https://github.com/PacktPublishing/Speed-up-your-Python-with-Rust/tree/main/chapter_eight](https://github.com/PacktPublishing/Speed-up-your-Python-with-Rust/tree/main/chapter_eight)找到。
- en: Breaking down a catastrophe modeling problem for our package
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将灾难建模问题分解为我们的包
- en: The project that we are going to build is a catastrophe model. This is where
    we calculate the probability of a catastrophe such as a hurricane, flood, or terror
    attack happening in a particular geographical location. We could do this using
    longitude and latitude coordinates. However, if we are going to do this, it is
    going to take a lot of computational power and time with little benefit. For instance,
    if we were going to calculate the probability of the flooding at Charing Cross
    Hospital in London, we could use the coordinates *51.4869° N, 0.2195° W*.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将要构建的项目是一个灾难模型。这是我们在特定地理位置计算灾难（如飓风、洪水或恐怖袭击）发生概率的地方。我们可以使用经纬度坐标来做这件事。然而，如果我们这样做，这将需要大量的计算能力和时间，而收益却很小。例如，如果我们想要计算伦敦查令十字医院的洪水概率，我们可以使用坐标
    *51.4869° N, 0.2195° W*。
- en: 'However, if we use the coordinates *51.4865° N, 0.2190° W,* we would still
    be hitting Charing Cross Hospital, despite us changing the coordinates by *0.0004°
    N, 0.0005° W.* We could change the coordinates even more and we would still be
    hitting Charing Cross Hospital. Therefore, we would be doing loads of computations
    to calculate repeatedly the probability of flooding of the same building, which
    is not efficient. To combat this, we can break down the locations into bins and
    give them a numerical value, as shown here:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果我们使用坐标 *51.4865° N, 0.2190° W*，即使我们改变了 *0.0004° N, 0.0005° W* 的坐标，我们仍然会击中查令十字医院。因此，我们将进行大量的计算来重复计算同一建筑的洪水概率，这并不高效。为了解决这个问题，我们可以将位置分解为分区，并给它们一个数值，如图所示：
- en: '![Figure 8.1 – Geographical bins for a catastrophe model of an island'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.1 – 岛屿灾难模型的地理分区'
- en: '](img/Figure_8.01_B17720.jpg)'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_8.01_B17720.jpg)'
- en: Figure 8.1 – Geographical bins for a catastrophe model of an island
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.1 – 岛屿灾难模型的地理分区
- en: Here, we can see that if a line of data in our model referred to bin `25`, this
    means that the line of data is referring to land in the middle of our island that
    we are concerned with. We can make our calculations even more efficient. For instance,
    we can see that the squares in *Figure 8.1* with the coordinates of `33`, `35`,
    `47`, and `49` and `1`, `2`, `8`, and `9` are in the sea. Therefore, the probability
    of flooding in these squares is zero because it is already water, and there is
    nothing that we care about in terms of flooding in the sea. Because we are merely
    mapping our calculations onto these bins, nothing is stopping us from redefining
    all of the bins inside these squares as one bin.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到，如果模型中的数据行指的是`25`号区间，这意味着该数据行指的是我们关注的岛屿中间的土地。我们可以使我们的计算更加高效。例如，我们可以看到*图8.1*中坐标为`33`、`35`、`47`和`49`以及`1`、`2`、`8`和`9`的正方形位于海洋中。因此，这些正方形发生洪水的概率为零，因为它们已经是水，而且海洋中没有什么我们关心的是关于洪水的。因为我们只是将这些计算映射到这些区间上，所以没有任何阻止我们重新定义这些正方形内部的所有区间为一个区间的。
- en: Therefore, we must perform only one operation to calculate the risk of flooding
    in all our sea bins and that would be zero because the sea is already flooded.
    In fact, nothing is stopping us from sticking to square classifications for one
    bin. Bin number 1 could be all the squares that are 100% inside the sea, saving
    us a lot of time. We can also go the other way. We can make some of our bins more
    refined. For instance, areas near the coast might have more nuanced gradients
    of flooding, as a small distance closer to the sea could greatly increase the
    risk of flooding; therefore, we could break bin number 26 down into smaller bins.
    To avoid being dragged into the weeds, we will just refer to arbitrary bin numbers
    in our model data. Catastrophe modeling is its own subject, and we are merely
    using it to show how to build Rust Python packages that can solve real problems
    as opposed to trying to build the most accurate catastrophe model. Now that we
    understand how we map geographical data with probabilities, we can move on to
    the calculation of those probabilities.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们只需执行一个操作来计算所有海洋区间的洪水风险，这将是一个零值，因为海洋已经洪水了。实际上，没有什么阻止我们坚持一个区间的正方形分类。编号为1的区间可以是所有100%位于海洋中的正方形，这样可以节省我们很多时间。我们也可以反过来操作。我们可以使一些区间更加精细。例如，沿海地区可能具有更细微的洪水梯度，因为靠近海洋的小距离可能会大大增加洪水风险；因此，我们可以将编号为26的区间分解成更小的区间。为了避免陷入细节，我们将在模型数据中引用任意的区间编号。灾难建模是它自己的主题，我们只是在用它来展示如何构建可以解决实际问题的Rust
    Python包，而不是试图构建最准确的灾难模型。现在我们了解了如何使用概率映射地理数据，我们可以继续计算这些概率。
- en: Like with the mapping of geographical data, probability calculations are more
    complex and nuanced than what we are going to cover in this book. Companies like
    OASISLMF work with academic departments at universities to model risks of catastrophes
    and the damage inflicted. However, there is an overarching theme that we must
    do when calculating these probabilities. We will have to calculate the total probability
    of damage using the probability of the event happening in the area, and the probability
    of the event causing damage. To do this, we must multiply these probabilities
    together. We also must break down the probability of the event happening at a
    certain intensity. For instance, a category one hurricane is less likely to cause
    damage to a building compared to a category five hurricane. Therefore, we are
    going to run these probability calculations for each intensity bin.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 就像地理数据的映射一样，概率计算比我们在本书中将要讨论的要复杂和微妙得多。像OASISLMF这样的公司会与大学里的学术部门合作，来模拟灾难的风险以及造成的损害。然而，在计算这些概率时，我们必须遵循一个总的主题。我们必须使用事件在该区域发生的概率以及事件造成损害的概率来计算损害的总概率。为了做到这一点，我们必须将这些概率相乘。我们还必须分解事件以一定强度发生的概率。例如，一级飓风造成建筑损害的可能性比五级飓风要小。因此，我们将为每个强度区间运行这些概率计算。
- en: 'We cannot go any further in designing our process without looking at the data
    that we have available. The data is in the form of `CSV` files and is available
    in our GitHub repository stated in the *Technical requirements* section. The first
    data file that we can inspect is the `footprint.csv` file. This file presents
    the probability of a catastrophe with a certain intensity happening in an area:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在没有查看我们可用的数据之前，我们不能进一步设计我们的流程。数据以`CSV`文件的形式存在，并在*技术要求*部分中提到的GitHub仓库中可用。我们可以检查的第一个数据文件是`footprint.csv`文件。该文件展示了在某个区域发生一定强度灾难的概率：
- en: '![](img/Table_8.1.jpg)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Table_8.1.jpg)'
- en: Here, we can see that we have taken in a series of event IDs. We can merge the
    `footprint.csv` data with the event IDs we passed in. This enables us to map the
    event IDs that we passed in with an area, intensity, and probability of it happening.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到我们输入了一系列事件ID。我们可以将`footprint.csv`数据与传入的事件ID合并。这使得我们能够将传入的事件ID与一个区域、强度和发生的概率进行映射。
- en: 'Now that we have merged our geographical data, we can now look at our damage
    data in the `vulnerability.csv` file:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经合并了我们的地理数据，我们现在可以查看`vulnerability.csv`文件中的损害数据：
- en: '![](img/Table_8.2.jpg)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Table_8.2.jpg)'
- en: 'Looking at this, we can merge the damage data of the intensity bin ID, duplicating
    whatever we need. We then must multiply the probabilities to get the total probability.
    The flow can be summed up as follows:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 观察这个流程，我们可以合并强度分箱ID的损害数据，复制我们需要的任何内容。然后我们必须乘以概率以得到总概率。流程可以总结如下：
- en: '![Figure 8.2 – Catastrophe model flow'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 8.2 – 灾难模型流程'
- en: '](img/Figure_8.02_B17720.jpg)'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_8.02_B17720.jpg)'
- en: Figure 8.2 – Catastrophe model flow
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.2 – 灾难模型流程
- en: 'Considering the data and flow, we can see that we now have events that have
    an intensity bin ID, damage bin ID, probability of the event happening in the
    area, and the probability of the event causing damage in a certain bin. These
    can then be passed on to another stage, which is the process of calculating financial
    losses. We will stop here, but we must remember that real-world applications need
    to adapt for expansion. For instance, there is interpolation. This is where we
    use a function to estimate the values across a bin, which is demonstrated here:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑数据和流程，我们可以看到我们现在有具有强度分箱ID、损害分箱ID、事件在该区域发生的概率以及事件在某个分箱中造成损害的概率的事件。这些可以传递到另一个阶段，即计算财务损失的过程。我们将在这里停止，但我们必须记住，现实世界的应用需要适应扩展。例如，有插值。这就是我们使用一个函数来估计分箱之间的值，这里进行了演示：
- en: '![](img/Figure_8.03_B17720.jpg)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Figure_8.03_B17720.jpg)'
- en: Figure 8.3 – Linear interpolation of a distribution
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.3 – 分布的线性插值
- en: Here, we can see that if we just use bins, our reading between `2` and `2.9`
    would be the same. We know that the distribution is increasing, so we use a simple
    linear function, and the value of our reading increases as the reading increases.
    There are other more complex functions we can use, but this can increase the accuracy
    of readings if the bins are too wide. While we will not be using interpolation
    in our example, it is a legitimate step that we might want to slot in later. Considering
    this, our processes need to be isolated.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到如果我们仅仅使用分箱，我们在`2`和`2.9`之间的读取将是相同的。我们知道分布是增加的，所以我们使用一个简单的线性函数，我们的读取值随着读取值的增加而增加。我们可以使用其他更复杂的函数，但如果分箱太宽，这可以提高读取的准确性。虽然我们不会在我们的例子中使用插值，但这是一个我们可能希望在以后插入的合法步骤。考虑到这一点，我们的流程需要被隔离。
- en: 'There is only one other thing that we must consider when designing our package,
    which is the storage of our model data. Our probabilities will be defined by an
    academic team that collected and analyzed a range of data sources and specific
    knowledge. For instance, damage to buildings requires structural engineering knowledge
    and knowledge of hurricanes. While we might expect our teams to update the models
    in later releases, we do not want the end user to easily manipulate data. We also
    do not want to hardcode the data into our Rust code; therefore, storing `CSV`
    files in our package would be useful for this demonstration. Considering this,
    our package should take the following structure:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在设计我们的包时，我们必须考虑的另一件事是我们模型数据的存储。我们的概率将由一个收集和分析了一系列数据源和特定知识的学术团队定义。例如，建筑物的损害需要结构工程知识和飓风知识。虽然我们可能期望我们的团队在后续版本中更新模型，但我们不希望最终用户轻易地操作数据。我们也不希望在Rust代码中硬编码数据；因此，在包中存储`CSV`文件对于这个演示是有用的。考虑到这一点，我们的包应该采取以下结构：
- en: '[PRE0]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[PRE1]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[PRE2]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[PRE3]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[PRE4]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[PRE5]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[PRE6]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[PRE7]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[PRE8]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '[PRE9]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '[PRE10]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[PRE11]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[PRE12]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '[PRE13]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[PRE14]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '[PRE15]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '[PRE16]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '[PRE17]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: The structure should be familiar to you. In the preceding file structure, we
    can see that our merge processes for the probability of the event happening and
    the damage are in their own folders. Data structures for the process are housed
    in the `structs.rs` file and functions around the process are defined in the `processes.rs`
    file. The `flitton_oasis_risk_modelling` folder will house our compiled Rust code;
    therefore, our `CSV` files are also stored there.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 结构应该对你来说很熟悉。在先前的文件结构中，我们可以看到我们的合并过程，即事件发生概率和损害的合并过程，都在它们自己的文件夹中。过程的数据结构存储在`structs.rs`文件中，而围绕过程的功能定义在`processes.rs`文件中。`flitton_oasis_risk_modelling`文件夹将存放我们的编译后的Rust代码；因此，我们的`CSV`文件也存储在那里。
- en: We state that we are storing our `CSV` files in the `MANIFEST.in` file. Our
    `lib.rs` file is where our interface between our Rust and Python is defined. Now
    that we have defined the process for our catastrophe model, we can move on to
    the next section of building our end-to-end package.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在`MANIFEST.in`文件中声明我们存储我们的`CSV`文件。我们的`lib.rs`文件定义了我们的Rust和Python之间的接口。现在我们已经定义了我们的灾难模型的过程，我们可以继续构建我们的端到端包的下一部分。
- en: Building an end-to-end solution as a package
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将端到端解决方案作为一个包构建
- en: 'In the previous section, we identified what we needed to do to build our catastrophe
    model package. We can achieve it with the following steps:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我们确定了构建我们的灾难模型包需要做什么。我们可以通过以下步骤实现：
- en: Build a footprint merging process.
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构建足迹合并过程。
- en: Build a vulnerability and probability merging process.
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构建脆弱性和概率合并过程。
- en: Build a Python interface in Rust.
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在Rust中构建Python接口。
- en: Build an interface in Python.
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在Python中构建一个接口。
- en: Build package installation instructions.
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构建包安装说明。
- en: 'Before we build anything, we must define our dependencies in our `Cargo.toml`
    file with the following code:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们构建任何东西之前，我们必须在我们的`Cargo.toml`文件中定义我们的依赖项，以下代码：
- en: '[PRE18]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '[PRE19]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '[PRE20]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '[PRE21]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '[PRE22]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '[PRE23]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '[PRE24]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '[PRE25]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '[PRE26]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '[PRE27]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '[PRE28]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '[PRE29]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '[PRE30]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: '[PRE31]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Here, we can see that we are using the `csv` crate to load our data and the
    `serde` crate to serialize the data that we had loaded from the `CSV` file. With
    this approach, it is important that we start by coding the processes first. This
    enables us to know what we need when we get to building our interfaces. Considering
    this, we can start building our footprint merging process.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到我们正在使用`csv`crate来加载数据，使用`serde`crate来序列化我们从`CSV`文件中加载的数据。采用这种方法，我们首先编码过程是很重要的。这样，当我们构建接口时，我们就知道我们需要什么。考虑到这一点，我们可以开始构建我们的足迹合并过程。
- en: Building a footprint merging process
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 构建足迹合并过程
- en: 'Our footprint merging process is essentially loading our footprint data and
    merging it with our input IDs. Once this is done, we then return the data to be
    fed into another process. We initially need to build our data structs before we
    build our processes, as our processes will need them. We can build our footprint
    struct in the `src/footprint/structs.rs` file with the following code:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的足迹合并过程本质上是在加载我们的足迹数据并将其与我们的输入ID合并。一旦完成，我们就将数据返回以供另一个过程使用。在我们构建过程之前，我们最初需要构建我们的数据结构，因为我们的过程将需要它们。我们可以在`src/footprint/structs.rs`文件中用以下代码构建我们的足迹结构体：
- en: '[PRE32]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: '[PRE33]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: '[PRE34]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: '[PRE35]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: '[PRE36]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: '[PRE37]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: '[PRE38]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: '[PRE39]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: Here, we can see that we apply the `Deserialize` macro to the struct so that
    when we load data from the file, it can be directly loaded into our `FootPrint`
    struct. We will also want to clone our struct if similar multiple event IDs are
    being passed into our package.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到我们应用了`Deserialize`宏到结构体上，这样当我们从文件加载数据时，它可以直接加载到我们的`FootPrint`结构体中。如果我们向我们的包传递了多个类似的事件ID，我们还将想要克隆我们的结构体。
- en: 'Now that we have our struct, we can build our merging process in our `src/footprint/processes.rs`
    file:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们已经有了我们的结构体，我们就可以在我们的`src/footprint/processes.rs`文件中构建我们的合并过程：
- en: 'First, we have to define the imports we need with the following code:'
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们必须用以下代码定义我们需要的导入：
- en: '[PRE40]'
  id: totrans-88
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: We must remember that we did not define our struct in the `src/footprint/mod.rs`
    file, so this will not run yet, but we will define it in time before running our
    code.
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们必须记住，我们没有在`src/footprint/mod.rs`文件中定义我们的结构体，所以这还不能运行，但我们将在运行代码之前定义它。
- en: 'We can now build a function that will read a footprint from the file with the
    following code:'
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在可以构建一个函数，用以下代码从文件中读取足迹：
- en: '[PRE41]'
  id: totrans-91
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: Here, we can see our function requires the directory where our data file is
    housed. We then add the filename to the path, open the file, and pass it through
    the `from_reader` function. We then define an empty vector and add the data that
    we deserialize. We now have a vector of `FootPrint` structs, which we return.
  id: totrans-92
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到我们的函数需要一个包含数据文件的目录。然后我们将文件名添加到路径中，打开文件，并通过`from_reader`函数传递它。然后我们定义一个空向量，并将反序列化的数据添加到其中。现在我们有一个`FootPrint`结构体的向量，我们将其返回。
- en: 'Now that we have our `load data` function, we can now build our `merge footprints`
    function in the same file with the following code:'
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们有了`load data`函数，我们可以在同一个文件中构建`merge footprints`函数，以下是一段代码：
- en: '[PRE42]'
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: Here, we can see that we take in a vector of event IDs and a vector of `FootPrint`
    structs. We then loop through our event IDs. For each event, we then loop through
    all the `FootPrint` structs, adding the struct to our buffer if it matches the
    event ID. We then return the buffer meaning that we have merged all that we need.
    We do not need to code any more processes. To make them useful, we can build an
    interface in the `src/footprint/mod.rs` file.
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到我们接受一个事件ID的向量和一个`FootPrint`结构体的向量。然后我们遍历事件ID。对于每个事件，我们遍历所有的`FootPrint`结构体，如果结构体与事件ID匹配，就将结构体添加到我们的缓冲区中。然后我们返回缓冲区，这意味着我们已经合并了所有需要的内容。我们不需要编写更多的流程。为了使它们变得有用，我们可以在`src/footprint/mod.rs`文件中构建一个接口。
- en: 'So, we must import what we need with the following code:'
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 因此，我们必须使用以下代码导入所需的模块：
- en: '[PRE43]'
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Now that we have imported all that we need, we can build our interface in the
    same file with the following code:'
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们已经导入了所有需要的模块，我们可以在同一个文件中构建我们的界面，以下是一段代码：
- en: '[PRE44]'
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: Here, we merely accept the file path and event IDs and pass them through our
    processes, returning the results.
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这里，我们仅仅接受文件路径和事件ID，并将它们通过我们的处理流程传递，返回结果。
- en: With this, our footprint processes are built, meaning that we can move on to
    the next step of building the vulnerability merge processes.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 这样，我们的足迹处理流程就构建完成了，这意味着我们可以继续构建漏洞合并处理流程的下一步。
- en: Building the vulnerability merge process
  id: totrans-102
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 构建漏洞合并流程
- en: 'Now that we have merged our event IDs with our footprint data, we have a working
    map of the probabilities of certain events happening at certain intensities within
    a range of geographical locations. We can merge this with the probabilities of
    damage occurring due to the catastrophe by following these steps:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经将事件ID与我们的足迹数据合并，我们得到了一个工作映射，它显示了在地理区域内一定强度下某些事件发生的概率。我们可以通过以下步骤将此与由于灾难发生的损坏概率合并：
- en: 'In this process, we must load the vulnerabilities and then merge them with
    our existing data. To facilitate this, we will have to build two structs – one
    for the data that is loaded from the file and another for the result after the
    merge. Because we are loading the data, we will need to use the `serde` crate.
    In our `src/vulnerabilities/structs.rs` file, we import it with the following
    code:'
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这个过程中，我们必须加载漏洞并将它们与现有数据合并。为了方便起见，我们将需要构建两个结构体——一个用于从文件加载的数据，另一个用于合并后的结果。因为我们正在加载数据，所以我们需要使用`serde`包。在我们的`src/vulnerabilities/structs.rs`文件中，我们使用以下代码导入它：
- en: '[PRE45]'
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'We then build our struct to load the file with the following code:'
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们使用以下代码构建我们的结构体来加载文件：
- en: '[PRE46]'
  id: totrans-107
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE46]'
- en: We must note here that the probability of the data we are loading is labeled
    under the `probability` field. This is the same with our `FootPrint` struct. Because
    of this, we must rename the `probability` field to avoid clashes during the merge.
    We also need to calculate the total probability.
  id: totrans-108
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们必须注意，我们正在加载的数据的概率被标记在`probability`字段下。这与我们的`FootPrint`结构体相同。因此，我们必须将`probability`字段重命名，以避免合并时的冲突。我们还需要计算总概率。
- en: 'Considering this, our result after the merge takes the form of the following
    code:'
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 考虑到这一点，合并后的结果形式如下所示：
- en: '[PRE47]'
  id: totrans-110
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'With this, our structs are complete and we can build our processes in our `src/vulnerabilities/processes.rs`
    file. Here, we are going to have two functions, reading the vulnerabilities, and
    then merging them with our model:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 这样，我们的结构体就完整了，我们可以在`src/vulnerabilities/processes.rs`文件中构建我们的处理流程。在这里，我们将有两个函数，一个是读取漏洞，然后使用我们的模型将它们合并：
- en: 'First, we must import everything that we need with the following code:'
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们必须使用以下代码导入所有需要的模块：
- en: '[PRE48]'
  id: totrans-113
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE48]'
- en: Here, we can see that we are relying on the `FootPrint` struct from our `footprint`
    module.
  id: totrans-114
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到我们依赖于来自`footprint`模块的`FootPrint`结构体。
- en: 'Now that we have everything, we can build our first process, which is loading
    the data with the following code:'
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们已经拥有了所有东西，我们可以构建我们的第一个进程，即使用以下代码加载数据：
- en: '[PRE49]'
  id: totrans-116
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE49]'
- en: Here, we can see that this is similar code to our loading process in our footprint
    module. Refactoring this into a generalized function would be a good exercise.
  id: totrans-117
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这里，我们可以看到这与我们在足迹模块中的加载过程类似。将其重构为通用函数将是一个很好的练习。
- en: 'Now that we have our loading function, we can merge `Vec<Vulnerability>` with
    `Vec<FootPrint>` to get `Vec<VulnerabilityFootPrint>`. We can define the function
    with the following code:'
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们有了加载函数，我们可以将 `Vec<Vulnerability>` 与 `Vec<FootPrint>` 合并，以获得 `Vec<VulnerabilityFootPrint>`。我们可以使用以下代码定义该函数：
- en: '[PRE50]'
  id: totrans-119
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Here, we can see that we have a new vector called `buffer`, which is where
    the merged data will be stored in the `. . .` placeholder. We can see that we
    loop through the footprints for each vulnerability. If `intensity_bin_id` matches,
    we execute the code in the `. . .` placeholder, which is the following code:'
  id: totrans-120
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这里，我们可以看到我们有一个名为 `buffer` 的新向量，它将存储在 `. . .` 占位符中的合并数据。我们可以看到我们遍历每个漏洞的足迹。如果
    `intensity_bin_id` 匹配，我们执行 `. . .` 占位符中的代码，如下所示：
- en: '[PRE51]'
  id: totrans-121
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE51]'
- en: Here, we are merely mapping the correct values to the correct fields of our
    `VulnerabilityFootPrint` struct. In the last field, we calculate the total probability
    by multiplying the other probabilities together.
  id: totrans-122
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这里，我们只是将正确的值映射到我们的 `VulnerabilityFootPrint` 结构体的正确字段。在最后一个字段中，我们通过将其他概率相乘来计算总概率。
- en: 'Our processes are finally done, so we move on to building our interface for
    this process in our `src/vulnerabilities/mod.rs` file:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的过程终于完成了，所以我们继续在 `src/vulnerabilities/mod.rs` 文件中构建我们这个过程的接口：
- en: 'We first import what we need with the following code:'
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们首先使用以下代码导入我们需要的内容：
- en: '[PRE52]'
  id: totrans-125
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE52]'
- en: With this, we can create a function that takes in a base path for the directory
    of where our data files are and our footprint data.
  id: totrans-126
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 通过这种方式，我们可以创建一个函数，该函数接受数据文件所在目录的基路径以及足迹数据。
- en: 'We then pass them through both of our processes, loading and merging, and then
    return our merged data with the following code:'
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们然后将它们通过加载和合并这两个进程，并使用以下代码返回我们的合并数据：
- en: '[PRE53]'
  id: totrans-128
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE53]'
- en: We have now built our two processes for constructing our data model. We can
    move on to our next step, which is building our Python interface in Rust.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已经构建了构建数据模型所需的两个进程。我们可以继续进行下一步，即在 Rust 中构建我们的 Python 接口。
- en: Building a Python interface in Rust
  id: totrans-130
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在 Rust 中构建 Python 接口
- en: 'The Python interface is defined in the `src/lib.rs` file, where we use the
    `pyo3` crate to get our Rust code to communicate with the Python system. Here
    are the steps:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: Python 接口定义在 `src/lib.rs` 文件中，我们在这里使用 `pyo3` crate 使我们的 Rust 代码能够与 Python 系统进行通信。以下是步骤：
- en: 'First, we must import what we need with the following code:'
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们必须使用以下代码导入我们需要的内容：
- en: '[PRE54]'
  id: totrans-133
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE54]'
- en: Here, we can see that we import what we need from the `pyo3` crate. We will
    be wrapping a `get_model` function with `wrap_pyfunction` and returning a list
    of `PyDict` structs. We also define the process modules, structs, and functions
    that we need to build our model.
  id: totrans-134
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这里，我们可以看到我们导入了来自 `pyo3` crate 的所需内容。我们将使用 `wrap_pyfunction` 包装 `get_model` 函数，并返回
    `PyDict` 结构体的列表。我们还定义了构建模型所需的过程模块、结构体和函数。
- en: 'We can then define our function with the following code:'
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以定义我们的函数，如下所示：
- en: '[PRE55]'
  id: totrans-136
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE55]'
- en: It must be noted that we accept a `Python` struct into our function. This is
    automatically filled. If we get the `Python` struct via the `Python` struct, we
    can return the Python structures that we create in the function using the `Python`
    struct that we took in.
  id: totrans-137
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 必须注意的是，我们接受一个 `Python` 结构体到我们的函数中。这是自动填充的。如果我们通过 `Python` 结构体获取 `Python` 结构体，我们可以使用我们接受的
    `Python` 结构体返回在函数中创建的 Python 结构体。
- en: 'In the `. . .` placeholder, we create a `PyDict` struct with all the data for
    the model row and push it to our buffer with the following code:'
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `. . .` 占位符中，我们创建一个包含模型行所有数据的 `PyDict` 结构体，并使用以下代码将其推送到我们的缓冲区：
- en: '[PRE56]'
  id: totrans-139
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE56]'
- en: Here, we can see that we can push different types to our `PyDict` struct and
    Rust does not care.
  id: totrans-140
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这里，我们可以看到我们可以将不同类型推送到我们的 `PyDict` 结构体，而 Rust 并不在乎。
- en: 'We can then wrap our function and define our module with the following code:'
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们可以使用以下代码包装我们的函数并定义我们的模块：
- en: '[PRE57]'
  id: totrans-142
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE57]'
- en: Now that all our Rust programming is done, we can move on to building our Python
    interface in the next step.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们所有的 Rust 编程都完成了，我们可以继续在下一步构建我们的 Python 接口。
- en: Building our interface in Python
  id: totrans-144
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在 Python 中构建我们的接口
- en: When it comes to our Python interface, we will have to build a function in a
    Python script in the `flitton_oasis_rist_modelling/__init__.py` file. We also
    store our data `CSV` files in the `flitton_oasis_rist_modelling` directory. Remember,
    we do not want our users interfering with the `CSV` files or having to know where
    they are. To do this, we will use the `os` Python module to find the directory
    of our module to load our `CSV` data.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 当涉及到我们的Python接口时，我们将在`flitton_oasis_rist_modelling/__init__.py`文件中的Python脚本中构建一个函数。我们还把我们的数据`CSV`文件存储在`flitton_oasis_rist_modelling`目录中。记住，我们不希望我们的用户干扰`CSV`文件或需要知道它们的位置。为此，我们将使用`os`Python模块来找到我们的模块目录以加载我们的`CSV`数据。
- en: 'To do this, we import what we need in the `flitton_oasis_rist_modelling/__init__.py`
    file with the following code:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 要做到这一点，我们需要在`flitton_oasis_rist_modelling/__init__.py`文件中导入所需的模块，以下代码：
- en: '[PRE58]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: '[PRE59]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'Remember, our Rust code will compile into a binary and be stored in the `flitton_oasis_rist_modelling`
    directory, so we can do a relative import for all the wrapped functions in our
    Rust code. Now, we can code our `construct_model` model function with the following
    code:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，我们的Rust代码将编译成一个二进制文件并存储在`flitton_oasis_rist_modelling`目录中，因此我们可以对我们的Rust代码中的所有包装函数进行相对导入。现在，我们可以用以下代码编写我们的`construct_model`模型函数：
- en: '[PRE60]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: '[PRE61]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: '[PRE62]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: Here, we can see that all the user needs to do is pass in the event IDs. However,
    if we tried to install this package using `pip`, we would get errors stating that
    the `CSV` files cannot be found; this is because our setup does not include the
    data files. We can solve this in our next step of building package installation
    instructions.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到用户需要做的只是传入事件ID。然而，如果我们尝试使用`pip`安装这个包，我们会得到错误信息，指出无法找到`CSV`文件；这是因为我们的设置中不包括数据文件。我们可以在构建包安装说明的下一步中解决这个问题。
- en: Building package installation instructions
  id: totrans-154
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 构建包安装说明
- en: 'To do this, we must state that we want to keep all `CSV` files in our `MANIFEST.in`
    file with the following code:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 要做到这一点，我们必须声明我们想要在`MANIFEST.in`文件中保留所有`CSV`文件，以下代码：
- en: '[PRE63]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'Now that we have done this, we can move to our `setup.py` file to define our
    setup:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经完成了这个步骤，我们可以转到`setup.py`文件来定义我们的设置：
- en: 'First, we must import what we need with the following code:'
  id: totrans-158
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们必须用以下代码导入所需的模块：
- en: '[PRE64]'
  id: totrans-159
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE64]'
- en: Here, as we have done before, we fetch the `setuptools_rust` package; although
    it is not essential for the running of the package, it is needed for the installation.
  id: totrans-160
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这里，就像我们之前做的那样，我们获取`setuptools_rust`包；尽管它对于包的运行不是必需的，但它对于安装是必需的。
- en: 'We can now define our setup parameters with the following code:'
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们可以用以下代码定义我们的设置参数：
- en: '[PRE65]'
  id: totrans-162
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'Here, we can see that we do not need any Python third-party packages. We have
    also defined our Rust extension, set the `include_package_data` parameter to `True`,
    and defined our package data with `package_data={'''': [''*.csv'']}`. With this,
    all `CSV` files will be kept when installing our package.'
  id: totrans-163
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '在这里，我们可以看到我们不需要任何Python第三方包。我们还定义了我们的Rust扩展，将`include_package_data`参数设置为`True`，并使用`package_data={'''':
    [''*.csv'']}`定义了我们的包数据。这样，在安装我们的包时，所有`CSV`文件都将被保留。'
- en: 'We are nearly finished; all we have to do is define the `rustflags` environment
    variables in the `.cargo/config` file with the following code:'
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们几乎完成了；我们只需要在`.cargo/config`文件中定义`rustflags`环境变量，以下代码：
- en: '[PRE66]'
  id: totrans-165
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE66]'
- en: With this, we can upload our code and install it in our Python system.
  id: totrans-166
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 使用这个方法，我们可以上传我们的代码并在我们的Python系统中安装它。
- en: 'We can now use our Python module. We can test this in our module with the terminal
    output, as follows:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以使用我们的Python模块。我们可以在模块中使用终端输出进行测试，如下所示：
- en: '[PRE67]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: '[PRE68]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: '[PRE69]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: '[PRE70]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: '[PRE71]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: '[PRE72]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: '[PRE73]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: '[PRE74]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: '[PRE75]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: '[PRE76]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: '[PRE77]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: '[PRE78]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: '[PRE79]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE79]'
- en: '[PRE80]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE80]'
- en: '[PRE81]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE81]'
- en: '[PRE82]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE82]'
- en: '[PRE83]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE83]'
- en: '[PRE84]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE84]'
- en: '[PRE85]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE85]'
- en: '[PRE86]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE86]'
- en: '[PRE87]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE87]'
- en: '[PRE88]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE88]'
- en: '[PRE89]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE89]'
- en: '[PRE90]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE90]'
- en: '[PRE91]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE91]'
- en: '[PRE92]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE92]'
- en: '[PRE93]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE93]'
- en: There's more data that is printed out, but if your printout correlates with
    the preceding output, then there is a high chance that the rest of your data is
    accurate. Here, we have built a real-world solution that loads data and does a
    series of operations and processes to come up with a model. However, it is a basic
    model that would not be used in real-life catastrophe modeling; we have coded
    it in isolated modules so that we can slot in more processes when we need to.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 打印出来的数据更多，但如果你的打印输出与前面的输出相关联，那么你剩余的数据很可能也是准确的。在这里，我们已经构建了一个现实世界的解决方案，该解决方案加载数据并执行一系列操作和过程来生成模型。然而，这是一个基本的模型，不会用于现实生活中的灾难建模；我们已经将其编码在独立的模块中，以便在需要时可以添加更多过程。
- en: However, we need to ensure that all our effort was not for nothing. We can do
    what we did in this package with a few lines of Python code using pandas, which
    is written in C, so it could be quicker or at the same speed. Considering this,
    we need to test to ensure that we are not wasting our time by testing our code
    in the next section.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们需要确保我们的努力没有白费。我们可以使用pandas和几行Python代码来做到这一点，pandas是用C语言编写的，所以它可能更快或者速度相同。考虑到这一点，我们需要在下一节测试以确保我们没有浪费时间。
- en: Utilizing and testing our package
  id: totrans-197
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 利用和测试我们的包
- en: 'We have started building out our solution in a Python package coded in Rust.
    However, we need to justify to our team and ourselves that all this effort was
    worth it. We can test to see whether we should continue with our efforts in a
    single isolated Python script. In this Python script, we can test by following
    these steps:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经开始使用Rust编写的Python包构建我们的解决方案。然而，我们需要向我们的团队和我们自己证明所有这些努力都是值得的。我们可以通过一个单独的Python脚本来测试是否应该继续我们的努力。在这个Python脚本中，我们可以按照以下步骤进行测试：
- en: Build a Python construct model using pandas.
  id: totrans-199
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用pandas构建Python结构模型。
- en: Build random event ID generator functions.
  id: totrans-200
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构建随机事件ID生成函数。
- en: Time our Python and Rust implementations with a series of different data sizes.
  id: totrans-201
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用一系列不同的数据大小来计时我们的Python和Rust实现。
- en: Once we have carried out all the aforementioned steps, we will know whether
    we should progress further with our module.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们完成了上述所有步骤，我们就会知道是否应该进一步推进我们的模块。
- en: 'In our testing script, before we start coding anything, we must import all
    of what we need with the following code:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的测试脚本中，在我们开始编码任何东西之前，我们必须使用以下代码导入所有需要的模块：
- en: '[PRE94]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE94]'
- en: '[PRE95]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE95]'
- en: '[PRE96]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE96]'
- en: '[PRE97]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE97]'
- en: '[PRE98]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE98]'
- en: Here, we are using the `random` module to generate random event IDs and the
    `time` module to time our implementations. We are using `pandas` to build our
    model, `matplotlib` to plot the outcomes, and our Rust implementation. We can
    now build our model.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们使用`random`模块生成随机事件ID，使用`time`模块来计时我们的实现。我们使用`pandas`构建我们的模型，`matplotlib`来绘制结果，以及我们的Rust实现。现在我们可以构建我们的模型。
- en: Building a Python construct model using pandas
  id: totrans-210
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用pandas构建Python结构模型
- en: 'Now that we have imported everything that we need, we can move on to loading
    data from the CSV files in Python and use it to construct a model in Python using
    pandas with the following steps:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经导入了所有需要的模块，我们可以继续在Python中加载数据从CSV文件，并使用pandas构建模型，以下是步骤：
- en: 'First, our function must take in event IDs. We also must load our data from
    our `CSV` files with the following code:'
  id: totrans-212
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们的函数必须接受事件ID。我们还必须使用以下代码从我们的`CSV`文件加载数据：
- en: '[PRE99]'
  id: totrans-213
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE99]'
- en: 'Now that we have all our data, we can merge our data and rename the `probability`
    column to avoid clashing with the following code:'
  id: totrans-214
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们已经拥有了所有数据，我们可以合并我们的数据，并将`probability`列重命名为避免与以下代码冲突：
- en: '[PRE100]'
  id: totrans-215
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE100]'
- en: Here, we can see that we are using less code.
  id: totrans-216
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到我们使用了更少的代码。
- en: 'Now, we can do our final process, which is merging with the vulnerabilities
    and then calculating the total probability with the following code:'
  id: totrans-217
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们可以进行最终的处理，即与漏洞合并，然后使用以下代码计算总概率：
- en: '[PRE101]'
  id: totrans-218
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE101]'
- en: With this, our Python model is now complete. We can now move on to our next
    step of building our random event ID generator functions.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 这样，我们的Python模型现在就完成了。我们现在可以继续下一步，构建随机事件ID生成函数。
- en: Building a random event ID generator function
  id: totrans-220
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 构建一个随机事件ID生成函数
- en: 'When it comes to our Rust implementation, we need a list of integers. For our
    Python model, we need to pass in a list of dictionaries with an event ID stored
    in it. We can define these functions with the following code:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 当涉及到我们的Rust实现时，我们需要一个整数列表。对于我们的Python模型，我们需要传递一个包含事件ID的字典列表。我们可以使用以下代码定义这些函数：
- en: '[PRE102]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE102]'
- en: '[PRE103]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE103]'
- en: '[PRE104]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE104]'
- en: '[PRE105]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE105]'
- en: '[PRE106]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE106]'
- en: '[PRE107]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE107]'
- en: Now that we have everything we need, we can carry out the final step of testing
    our implementations.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经拥有了所有需要的东西，我们可以执行测试实现的最后一步。
- en: Timing our Python and Rust implementations with a series of different data sizes
  id: totrans-229
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用一系列不同的数据大小来计时我们的Python和Rust实现
- en: 'We now have everything we need to test our Rust and Python implementation.
    Running both Python and Rust models with timing can be done by carrying out the
    following steps:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经拥有了测试我们的Rust和Python实现所需的一切。通过执行以下步骤，我们可以运行Python和Rust模型并计时：
- en: 'To test our implementation, we define our entry point and all the data structures
    for our time graph with the following code:'
  id: totrans-231
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了测试我们的实现，我们定义了我们的入口点和我们的时间图的所有数据结构，以下代码：
- en: '[PRE108]'
  id: totrans-232
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE108]'
- en: 'For our testing data, we are going to loop through a list of integers from
    `10` to `3000` in steps of `10` with the following code:'
  id: totrans-233
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于我们的测试数据，我们将使用以下代码遍历从 `10` 到 `3000` 的整数列表，步长为 `10`：
- en: '[PRE109]'
  id: totrans-234
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE109]'
- en: 'Both Python and Rust implementations will be running the same event ID dataset
    sizes, which is why we only have one `x` vector. We can now test our Python implementation
    with the following code:'
  id: totrans-235
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Python 和 Rust 的实现将运行相同的事件 ID 数据集大小，这就是为什么我们只有一个 `x` 向量。现在我们可以使用以下代码测试我们的 Python
    实现：
- en: '[PRE110]'
  id: totrans-236
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE110]'
- en: Here, we generate our ID dataset to the size of the integer of the loop. We
    then start our timer, construct our model in Python, finish the timer, and add
    the time taken to our Python data list.
  id: totrans-237
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这里，我们将我们的 ID 数据集生成到循环中整数的规模。然后我们开始计时，用 Python 构建我们的模型，结束计时，并将所用时间添加到我们的 Python
    数据列表中。
- en: 'We take the same approach with our Rust test with the following code:'
  id: totrans-238
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们使用以下代码对 Rust 进行测试：
- en: '[PRE111]'
  id: totrans-239
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE111]'
- en: Our data collection is now complete.
  id: totrans-240
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们的数据收集现在已经完成。
- en: 'All we need to do is plot the results when the loop has finished with the following
    code:'
  id: totrans-241
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们需要做的只是使用以下代码在循环结束后绘制结果：
- en: '[PRE112]'
  id: totrans-242
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE112]'
- en: 'We have now written all the code for testing, which should display a graph
    like this:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已经编写了所有测试代码，它应该显示一个像这样的图表：
- en: '![Figure 8.4 – Rust versus Python for the time taken for model generation for
    the size of data'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.4 – Rust 与 Python 在模型生成时间上的比较，针对数据大小]'
- en: '](img/Figure_8.04_B17720.jpg)'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.04_B17720.jpg](img/Figure_8.04_B17720.jpg)'
- en: Figure 8.4 – Rust versus Python for the time taken for model generation for
    the size of data
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.4 – Rust 与 Python 在模型生成时间上的比较，针对数据大小
- en: In the preceding figure, we see that initially, our Rust implementation is faster
    than our Python pandas implementation. However, once we get past the 1,300 mark,
    our Rust model gets slower than our Python pandas model. This is because our code
    does not scale well. We are performing loops within loops. In our pandas model,
    we vectorize our total probability. pandas is a well-written module where multiple
    developers have optimized the merge functions.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的图中，我们看到我们的 Rust 实现在一开始比我们的 Python pandas 实现更快。然而，一旦超过 1,300 的标记，我们的 Rust
    模型比 Python pandas 模型慢。这是因为我们的代码扩展性不好。我们在循环中执行循环。在我们的 pandas 模型中，我们对总概率进行向量化。pandas
    是一个编写良好的模块，多个开发者已经优化了合并函数。
- en: Therefore, although our Rust code will be faster than Python and pandas code,
    if our implementation is sloppy and does not scale well, we may even be slowing
    down our program. I have seen poorly implemented C++ be beaten by Python pandas.
    Understanding this nuance is important when trying to implement Rust in your system.
    Rust is a new language, and colleagues will be let down if you promise big gains,
    poorly implement code, and result in slower performance after burning a lot of
    time coding implementation in Rust.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，尽管我们的 Rust 代码将比 Python 和 pandas 代码更快，但如果我们的实现不够严谨且扩展性不好，我们甚至可能会减慢我们的程序。我见过实现不佳的
    C++ 被 Python pandas 超越。在尝试将 Rust 应用于您的系统时，理解这个细微差别非常重要。Rust 是一种新的语言，如果承诺大幅提升，却因代码实现不佳而导致在
    Rust 中编码实现花费了大量时间后性能反而更慢，同事们可能会感到失望。
- en: Seeing that this is a book about building Python packages in Rust as opposed
    to data processing in Rust, this is where we stop. However, Xavier Tao implemented
    an efficient merge process in Rust, resulting in Rust taking 75% less time and
    78% less memory. This is noted in the *Further reading* section. There is also
    a Rust implementation of pandas called **Polars**, which also has Python bindings.
    It is faster than standard pandas, and this documentation is also listed in the
    *Further reading* section.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这是一本关于在 Rust 中构建 Python 包的书籍，而不是关于 Rust 中的数据处理，所以我们在这里停止。然而，Xavier Tao 在 Rust
    中实现了一个高效的合并过程，这使得 Rust 的运行时间减少了 75%，内存减少了 78%。这一点在 *进一步阅读* 部分有所说明。还有一个名为 **Polars**
    的 Rust 实现 pandas，它也有 Python 绑定。它的速度比标准的 pandas 快，这份文档也列在 *进一步阅读* 部分中。
- en: The takeaway message here is that Rust enables us to build fast memory-efficient
    solutions, but we must be careful with our implementation and test to see whether
    what we are doing is sensible. We should be careful, especially if we are trying
    to build a solution from scratch that has an optimized solution in an existing
    Python package.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的启示信息是，Rust 使我们能够构建快速且内存高效的解决方案，但我们必须小心我们的实现并测试我们所做的是否合理。如果我们试图从头开始构建一个在现有的
    Python 包中有优化解决方案的解决方案，我们更应该小心。
- en: Summary
  id: totrans-251
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we went through the basics of building a simple catastrophe
    model. We then broke down the logic and converted it into steps so that we could
    build the catastrophe model in Rust. This included taking in paths, loading data
    from files, including data in our package, and building a Python interface so
    that our users do not have to know about what is going on under the hood when
    constructing a model. After all of this, we tested our module and ensured that
    we kept increasing the data size of the test to see how it scales. We saw that,
    initially, our Rust solution was faster because Rust is faster than Python and
    pandas. However, our implementation did not scale well, as we did a loop within
    a loop for our merge.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了构建简单灾难模型的基础知识。然后，我们将逻辑分解成步骤，以便在 Rust 中构建灾难模型。这包括获取路径、从文件中加载数据、在我们的包中包含数据，以及构建一个
    Python 接口，这样我们的用户在构建模型时就不必了解底层发生了什么。在完成所有这些之后，我们测试了我们的模块，并确保我们不断增加测试数据的大小，以查看其扩展性。我们发现，最初，我们的
    Rust 解决方案更快，因为 Rust 比 Python 和 Pandas 快。然而，我们的实现扩展性不佳，因为我们在一个循环内部又嵌套了一个循环来进行合并。
- en: As the data size increased, our Rust code ended up being slower. In previous
    chapters, we have shown multiple times that Rust implementations are generally
    faster. However, this does not counteract the effects of bad code implementation.
    If you are relying on a Python third-party module to perform a complex process,
    it probably is not a good idea to rewrite it in Rust for performance gains. If
    a Rust crate is not available for the same solution, then it is probably best
    to leave that part of the solution to the Python module.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 随着数据量的增加，我们的 Rust 代码最终变得较慢。在之前的章节中，我们多次展示了 Rust 实现通常更快。然而，这并不能抵消糟糕代码实现的影响。如果你依赖于
    Python 第三方模块来执行复杂过程，那么为了性能提升而将其重写为 Rust 可能不是一个好主意。如果不存在用于相同解决方案的 Rust crate，那么最好将解决方案的这一部分留给
    Python 模块。
- en: In the next chapter, we will be building a Flask web application to lay the
    groundwork for applying Rust to a Python web application.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将构建一个 Flask 网络应用程序，为将 Rust 应用于 Python 网络应用程序奠定基础。
- en: Further reading
  id: totrans-255
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'Polars documentation for Rust Crate Polars (2021): [https://docs.rs/polars/0.15.1/polars/frame/struct.DataFrame.html](https://docs.rs/polars/0.15.1/polars/frame/struct.DataFrame.html%0D)'
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rust Crate Polars 的 Polars 文档（2021年）：[https://docs.rs/polars/0.15.1/polars/frame/struct.DataFrame.html](https://docs.rs/polars/0.15.1/polars/frame/struct.DataFrame.html%0D)
- en: '*Data Manipulation: Pandas vs Rust*, *Xavier Tao* (2021): [https://able.bio/haixuanTao/data-manipulation-pandas-vs-rust--1d70e7fc](https://able.bio/haixuanTao/data-manipulation-pandas-vs-rust--1d70e7fc)'
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*数据处理：Pandas 对 Rust*，*夏维尔·陶*（2021年）：[https://able.bio/haixuanTao/data-manipulation-pandas-vs-rust--1d70e7fc](https://able.bio/haixuanTao/data-manipulation-pandas-vs-rust--1d70e7fc)'
