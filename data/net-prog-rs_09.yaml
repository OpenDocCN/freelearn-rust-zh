- en: Appendix
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 附录
- en: 'Rust is an open source project with a large number of contributors from all
    over the world. As with any such project, there are often multiple solutions to
    the same problems. The crate ecosystem makes this easier, since people can publish
    multiple crates that propose multiple ways of solving the same set of problems.
    This approach fosters a healthy sense of competition in true open source spirit. In
    this book, we have covered a number of different topics in the ecosystem. This
    chapter will be an addendum to those topics. We will discuss:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: Rust 是一个开源项目，拥有来自世界各地的众多贡献者。与任何此类项目一样，通常存在多种解决同一问题的方法。crate 生态系统使得这变得更容易，因为人们可以发布多个
    crate，提出解决同一组问题的多种方法。这种方法在真正的开源精神中培养了健康的竞争感。在本书中，我们已经涵盖了生态系统中的许多不同主题。本章将是对这些主题的补充。我们将讨论：
- en: Coroutine and generator-based approaches to concurrency
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于协程和生成器的并发方法
- en: The async/await abstraction
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: async/await 抽象
- en: Data parallelism
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据并行
- en: Parsing using Pest
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Pest 进行解析
- en: Miscellaneous utilities in the ecosystem
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生态系统中的各种实用工具
- en: Introduction to coroutines and generators
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 协程和生成器简介
- en: 'We looked into the Tokio ecosystem earlier. We saw how it is very common to
    chain futures in Tokio, yielding a larger task that can then be scheduled as necessary.
    In practice, the following often looks like the pseudocode:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前探讨了 Tokio 生态系统。我们看到了在 Tokio 中链式连接 future 是非常常见的，这产生了一个更大的任务，然后可以按需调度。在实践中，以下通常看起来像伪代码：
- en: '[PRE0]'
  id: totrans-9
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Here, our function takes in a URL and recursively downloads raw HTML. It then
    parses and collects links in the document. Our task is run in an event loop. Arguably,
    the control flow here is harder to follow, due to all the callbacks and how they
    interact. This becomes more complex with larger tasks and more conditional branches.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们的函数接收一个 URL 并递归地下载原始 HTML。然后它解析并收集文档中的链接。我们的任务在事件循环中运行。由于所有回调及其交互，这里的控制流可能更难以跟踪。随着任务规模增大和条件分支增多，这变得更加复杂。
- en: The idea of coroutines helps us to better reason about non-linearity in these
    examples. A coroutine (also known as a **generator**) is a generalization of a
    function that can suspend or resume itself at will, yielding control to another
    entity. Since they do not require preemption by a supersizing entity, they are
    often easier to work with. Note that we always assume a cooperative model where
    a coroutine yields when it is waiting for  a computation to finish or I/O, and
    we ignore cases where a coroutine might be malicious in some other way. When a
    coroutine starts execution again, it resumes from the point where it left off,
    providing a form of continuity. They generally have multiple entry and exit points.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 协程的概念帮助我们更好地理解这些例子中的非线性。协程（也称为**生成器**）是函数的一种推广，它可以随意挂起或恢复自身，并将控制权交给另一个实体。由于它们不需要被超实体抢占，因此通常更容易处理。请注意，我们始终假设一个协作模型，其中协程在等待计算完成或
    I/O 时会挂起，并且我们忽略了协程可能以其他方式恶意行为的案例。当协程再次开始执行时，它会从上次离开的地方继续，提供一种连续性。它们通常有多个入口和出口点。
- en: Having set that up, a subroutine (function) becomes approximately a special
    case of coroutine, which has exactly one entry and exit point, and cannot be externally
    suspended. Computer science literature also distinguishes between generators and
    coroutines, arguing that the former cannot control where execution continues after
    they are suspended, while the later can. However, in our current context, we will
    use generator and coroutines interchangeably.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在设置好之后，一个子程序（函数）就变成了协程的一个特殊情况，它有且只有一个入口和出口点，并且不能被外部挂起。计算机科学文献也区分了生成器和协程，认为前者在挂起后无法控制执行继续的位置，而后者可以。然而，在我们当前的环境中，我们将互换使用生成器和协程。
- en: 'Coroutines can be of two broad types: stackless and stackful. Stackless coroutines
    do not maintain a stack when they are suspended. As a result, they cannot resume
    at arbitrary locations. Stackful coroutines, on the other hand, always maintain
    a small stack. This enables them to suspend and resume from any arbitrary point
    in execution. They always preserve the complete state when they suspend. Thus,
    from a caller''s point of view, they behave like any regular function that can
    run independent of current execution. In practice, stackful coroutines are generally
    more resource heavy but easier to work with (for the caller). Note that all coroutines
    are resource light compared to threads and processes.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 协程可以分为两大类：无栈协程和有栈协程。无栈协程在挂起时不会维护栈。因此，它们不能在任意位置恢复。相反，有栈协程始终维护一个小栈。这使得它们可以从执行中的任意点挂起和恢复。它们在挂起时总是保留完整的状态。因此，从调用者的角度来看，它们的行为就像任何可以独立于当前执行运行的常规函数。在实践中，有栈协程通常更占用资源，但更容易与调用者一起工作。请注意，与线程和进程相比，所有协程的资源消耗都较小。
- en: 'In the recent past, Rust has been experimenting with a generator implementation
    in the standard library. These are located in `std::ops`, and like all new features,
    this is behind multiple feature gates: `generators` and `generator_trait`. There
    are a few parts to this implementation. Firstly, there is a new yield keyword
    for yielding from a generator. Generators are defined by overloading the closure
    syntax. Secondly, there are a few items defined as follows:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在最近过去，Rust 在标准库中实验了一种生成器实现。这些位于 `std::ops` 中，并且像所有新功能一样，这背后有多个功能门：`generators`
    和 `generator_trait`。这个实现有几个部分。首先，有一个新的 `yield` 关键字用于从生成器中 `yield`。生成器通过重载闭包语法来定义。其次，有一些项目如下定义：
- en: '[PRE1]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Since these are generators (not coroutines), they can have only one `yield`
    and only one `return`.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这些是生成器（而不是协程），它们只能有一个 `yield` 和一个 `return`。
- en: 'The `Generator` trait has two types: one for the `yield` case and one for the
    `return` case. The `resume` function resumes execution from the last point. The
    return value for resume is `GeneratorState`, which is an enum, and looks like
    this:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '`Generator` 特性有两种类型：一种用于 `yield` 的情况，另一种用于 `return` 的情况。`resume` 函数从最后一个点恢复执行。`resume`
    的返回值是 `GeneratorState`，这是一个枚举类型，看起来如下：'
- en: '[PRE2]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: There are two variants; `Yielded` represents the variant for the `yield` statement,
    and `Complete` represents the variant for the `return` statement. Also, the `Yielded`
    variant represents that the generator can continue again from the last yield statement.
    `Complete` represents that the generator has finished executing.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 有两个变体；`Yielded` 代表 `yield` 语句的变体，而 `Complete` 代表 `return` 语句的变体。此外，`Yielded`
    变体表示生成器可以从最后一个 `yield` 语句继续执行。`Complete` 表示生成器已经完成执行。
- en: 'Let''s look at an example of using this to generate the Collatz sequence:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看一个使用这个生成 Collatz 序列的例子：
- en: '[PRE3]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Since these are in the standard library, we do not need external dependencies.
    We start with the feature gates and imports. In our main function, we define a
    generator using the closure syntax. Notice how it captures the variable called
    `input` from the enclosing scope. Instead of returning the current position at
    the sequence, we `yield` it. And when we are done, we `return` from the generator.
    Now we need to call `resume` on the generator to actually run it. We do that in
    an infinite loop, since we do not know in advance how many times we will need
    to iterate. In that, we `match` on the `resume` call; in both arms, we print out
    the value that we have. Additionally, in the `Complete` arm, we need to `break`
    away from the loop.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这些在标准库中，我们不需要外部依赖。我们从功能门和导入开始。在我们的主函数中，我们使用闭包语法定义一个生成器。注意它如何从封装作用域捕获名为 `input`
    的变量。我们不是返回序列的当前位置，而是 `yield` 它。当我们完成时，我们从生成器返回。现在我们需要在生成器上调用 `resume` 来实际运行它。我们在一个无限循环中这样做，因为我们事先不知道需要迭代多少次。在这个循环中，我们对
    `resume` 调用进行 `match`；在两个分支中，我们打印出我们拥有的值。此外，在 `Complete` 分支中，我们需要从循环中 `break`
    出来。
- en: Note that we did not use the implicit return syntax here; rather, we did an
    explicit `return end;`. This was not necessary, but this makes the code a little
    bit easier to read in this case.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们在这里没有使用隐式返回语法；而是执行了显式的 `return end;`。这不是必需的，但在这个情况下这使得代码更容易阅读。
- en: 'This is what it produces:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是它产生的结果：
- en: '[PRE4]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Generators are only available in nightly Rust, for now. Their syntax is expected
    to change over time, possibly by a huge amount.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，生成器仅在 nightly Rust 中可用。它们的语法预计会随着时间的推移而改变，可能变化很大。
- en: How May handles coroutines
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: May 处理协程的方式
- en: The Rust ecosystem has a number of coroutine implementations, while the core
    team is working on in-language implementations. Of these, one of the widely used
    is called *May*, which is a standalone stackful coroutine library based on generators.
    May strives to be user-friendly enough so that a function can be asynchronously
    invoked using a simple macro that takes in the function. In feature parity with
    the Go programming language, this macro is called `go!`. Let's look at a small
    example of using May.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: Rust生态系统有几个协程实现，而核心团队正在努力进行语言内实现。在这些实现中，一个广泛使用的是名为*May*的实现，它是一个基于生成器的独立堆栈式协程库。May力求足够用户友好，以便可以使用一个简单的宏异步调用函数，该宏接受函数作为参数。与Go编程语言的功能相匹配，这个宏被称为`go!`。让我们看看使用May的一个小例子。
- en: 'We will use our good ol'' friend, Collatz sequence, for this example; this
    will show us multiple ways of achieving the same goal. Let''s start with setting
    up our project using Cargo:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用我们熟悉的老朋友，Collatz序列，来举例；这将展示我们实现相同目标的多种方式。让我们从使用Cargo设置我们的项目开始：
- en: '[PRE5]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The following is the main file. There are two examples here; one uses the generator
    crate to yield numbers in the collatz sequence, acting as a coroutine. The other
    one is a regular function, which is being run as a coroutine using the `go!` macro:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 以下为主要文件。这里有两个示例；一个使用生成器crate在Collatz序列中产生数字，充当协程。另一个是一个常规函数，它使用`go!`宏作为协程运行：
- en: '[PRE6]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Let's start with the `collatz_generator` function that takes in an input to
    start from and returns an iterator of type `u64`. To be able to specify this,
    we will need to activate the `conservative_impl_trait` feature. We create a scoped
    generator using `Gn::new_scoped` from the generator crate. It takes in a closure
    that actually does the computation. We yield the current value using the `yield_`
    function and signal the end of the computation using the `done!` macro.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从`collatz_generator`函数开始，它接受一个起始输入并返回一个类型为`u64`的迭代器。为了能够指定这一点，我们需要激活`conservative_impl_trait`功能。我们使用生成器crate中的`Gn::new_scoped`创建一个作用域生成器。它接受一个闭包，实际上执行计算。我们使用`yield_`函数产生当前值，并使用`done!`宏表示计算结束。
- en: Our second example is a regular function that returns a vector of numbers in
    the Collatz sequence. It collects intermediate results in a vector and finally
    returns it once the sequence reaches `1`. In our main function, we parse and sanitize
    input as we always do. We then call our non-generator function asynchronously
    in a coroutine using the `go!` macro. However, `collatz_generator` returns an
    iterator, which we can iterate over in a loop while printing out the numbers.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的第二个示例是一个返回Collatz序列中数字向量的常规函数。它在向量中收集中间结果，并在序列达到`1`时最终返回它。在我们的主函数中，我们像往常一样解析和清理输入。然后我们使用`go!`宏异步地在协程中调用我们的非生成器函数。然而，`collatz_generator`返回一个迭代器，我们可以在循环中迭代它，同时打印出数字。
- en: 'As one would expect, this is how the output looks:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 如预期的那样，输出看起来是这样的：
- en: '[PRE7]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'May also includes an asynchronous network stack implementation (like Tokio),
    and over the last few months, it has gathered a mini ecosystem of a few dependent
    crates. Apart from the generator and coroutine implementations, there is an HTTP
    library based on those, an RPC library, and a crate that supports actor-based
    programming. Let''s look at an example where we write our hyper HTTP using May.
    Here is what a Cargo config looks like:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: May 还包括一个异步网络堆栈实现（如Tokio），在过去的几个月里，它已经聚集了一个由几个依赖crate组成的迷你生态系统。除了生成器和协程实现之外，还有一个基于这些的HTTP库，一个RPC库，以及一个支持基于actor编程的crate。让我们看看一个使用May编写hyper
    HTTP的示例。以下是Cargo配置的样子：
- en: '[PRE8]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'At the time of writing, `may_minihttp` is not published in `crates.io` yet,
    so we will need to use the repository to build. Here is the main file:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写本文时，`may_minihttp`尚未在`crates.io`上发布，因此我们需要使用仓库来构建。以下是主要文件：
- en: '[PRE9]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: This time, our code is much shorter than with Hyper. This is because May nicely
    abstracts away a lot of things, while letting us have a similar set of functionalities.
    Like the `Service` trait earlier, the `HttpService` trait is what defines a server.
    Functionality is defined by the `call` function. There are some minor differences
    in function calls and how responses are constructed. Another advantage here is
    that this does not expose futures and works with regular `Result`. Arguably, this
    model is easier to understand and follow. In the `main` function, we set the number
    of I/O workers to the number of cores we have. We then start the server on port
    `3000` and wait for it to exit. According to some rough benchmarks on the GitHub
    page, the `may` based HTTP server is slightly faster than a Tokio implementation.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 这次，我们的代码比Hyper要短得多。这是因为May很好地抽象了很多东西，同时让我们拥有类似的功能集。就像之前的`Service` trait一样，`HttpService`
    trait定义了服务器。功能由`call`函数定义。在函数调用和响应构建方面有一些细微的差异。这里的另一个优点是它不暴露future，并且与常规`Result`一起工作。可以说，这个模型更容易理解和遵循。在`main`函数中，我们将I/O工作者的数量设置为我们的核心数。然后我们在端口`3000`上启动服务器并等待其退出。根据GitHub页面上的某些粗略基准测试，基于May的HTTP服务器比Tokio实现略快。
- en: 'Here is what we see upon running the server. In this particular run, it got
    two `GET` requests:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 运行服务器后，我们看到的是这个。在这个特定的运行中，它收到了两个`GET`请求：
- en: '[PRE10]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Our client side is just `curl`, and we see `done` being printed for each request.
    Note that since our server and the client are on the same physical box, we can
    use `127.0.0.1` as the server''s address. If that is not the case, the actual
    address should be used:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 我们客户端只是`curl`，并且我们看到每个请求都会打印出`done`。请注意，由于我们的服务器和客户端在同一台物理机器上，我们可以使用`127.0.0.1`作为服务器的地址。如果不是这种情况，应该使用实际的地址：
- en: '[PRE11]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Awaiting the future
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 等待future
- en: In the last section, we saw how tasks composed of multiple futures are often
    difficult to write and debug. One attempt at remedying this is using a crate that
    wraps futures and associated error handling, yielding a more linear flow of code.
    This crate is called *futures-await* and is under active development.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我们看到了由多个future组成的任务通常难以编写和调试。一个试图解决这个问题的方法是使用一个封装future和相关错误处理的crate，从而产生更线性的代码流。这个crate被称为*futures-await*，并且正在积极开发中。
- en: 'This crate provides two primary mechanisms of dealing with futures:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 这个crate提供了处理future的两种主要机制：
- en: The `#[async]` attribute that can be applied to functions, marking them as asynchronous.
    These functions must return the `Result` of their computation as a future.
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以应用于函数的`#[async]`属性，将其标记为异步。这些函数必须返回它们的计算`Result`作为future。
- en: The `await!` macro that can be used with async functions to consume the future,
    returning a `Result`.
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以与异步函数一起使用的`await!`宏，用于消耗future，返回一个`Result`。
- en: 'Given these constructions, our earlier example download will look like this:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 给定这些构造，我们之前的示例下载将看起来像这样：
- en: '[PRE12]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: This is arguably easier to read than the example with futures. Internally, the
    compiler translates this to code which looks like our earlier example. Additionally,
    since each of the steps returns a `Result`, we can use the `?` operator to nicely
    bubble up errors. The final task can then be run in an event loop, like always.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 这可能比使用future的例子更容易阅读。内部，编译器将此转换为类似于我们之前的示例的代码。此外，由于每个步骤都返回一个`Result`，我们可以使用`?`运算符优雅地冒泡错误。最终的任务可以像往常一样在事件循环中运行。
- en: 'Let''s look at a more concrete example, rewriting our hyper server project
    using this crate. In this case, our Cargo setup looks like this:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一个更具体的例子，使用这个crate重写我们的超服务器项目。在这种情况下，我们的Cargo设置看起来是这样的：
- en: '[PRE13]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Here is our code, as shown in the following code snippet. Notice that we have
    not used types from the futures crate like last time. Instead, we have used types
    re-exported from futures-await, which are wrapped versions of those types:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是我们的代码，如下面的代码片段所示。请注意，我们没有使用像上次那样的futures crate中的类型。相反，我们使用了从futures-await重新导出的类型，这些类型是这些类型的封装版本：
- en: '[PRE14]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The `async_block!` macro takes in a closure and converts that to an `async`
    function. Thus, our server here is an `async` function. We also use an asynchronous
    `for` loop (a `for` loop marked by `#[async]`) to asynchronously iterate over
    the stream of connections. The rest of the code is exactly the same as last time.
    Running the server is simple; we will use Cargo:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '`async_block!`宏接受一个闭包并将其转换为`async`函数。因此，我们这里的服务器是一个`async`函数。我们还使用异步的`for`循环（一个标记为`#[async]`的`for`循环）异步地遍历连接流。其余的代码与上次完全相同。运行服务器很简单；我们将使用Cargo：'
- en: '[PRE15]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'On the client side, we can use curl:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在客户端，我们可以使用 curl：
- en: '[PRE16]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: At the time of writing, running this example will produce a warning about using
    *bind_connection*. Since there is no clear deprecation timeline for this API,
    we will ignore the warning for now.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写本文时，运行此示例将产生关于使用 *bind_connection* 的警告。由于没有明确的弃用时间表，我们将暂时忽略此警告。
- en: Data parallelism
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据并行
- en: Data parallelism is a way of speeding up computation by making data a central
    entity. This is in contrast to the coroutine and thread-based parallelism that
    we have seen so far. In those cases, we first determine tasks that can be run
    independently. We then distribute available data to those tasks as needed. This
    approach is often called **task parallelism**. Our topic of discussion in this
    section is data parallelism. In this case, we need to figure out what parts of
    the input data can be used independently; then multiple tasks can be assigned
    to individual parts. This also conforms to the divide and conquer approach, one
    strong example being `mergesort`.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 数据并行是一种通过使数据成为中心实体来加速计算的方法。这与我们迄今为止看到的基于协程和线程的并行处理形成对比。在那些情况下，我们首先确定可以独立运行的任务。然后根据需要将可用数据分配给那些任务。这种方法通常被称为
    **任务并行**。本节讨论的主题是数据并行。在这种情况下，我们需要找出哪些输入数据部分可以独立使用；然后可以将多个任务分配给各个部分。这也符合分而治之的方法，一个强有力的例子是
    `mergesort`。
- en: 'The Rust ecosystem has a library called **Rayon** that provides simple APIs
    for writing data parallel code. Let''s look at a simple example of using Rayon
    for a binary search on a given slice. We start with setting up our project using
    `cargo`:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: Rust 生态系统有一个名为 **Rayon** 的库，它提供了编写数据并行代码的简单 API。让我们看看使用 Rayon 对给定切片进行二分查找的简单示例。我们首先使用
    `cargo` 设置我们的项目：
- en: '[PRE17]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Let''s look at the Cargo configuration file:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看 Cargo 配置文件：
- en: '[PRE18]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'In our code, we have two implementations of the binary search function, both
    being recursive. The naive implementation is called `binary_search_recursive` and
    does not do any data parallelism. The other version, called `binary_search_rayon`,
    computes the two cases in parallel. Both functions take in a slice of type `T`
    that implements a number of traits. They also take an element of the same type.
    The functions will look for the given element in the slice and return `true` if
    it exists, and `false` otherwise. Let''s look at the code now:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的代码中，我们实现了两种二分查找函数，两者都是递归的。原始实现称为 `binary_search_recursive`，并且不执行任何数据并行处理。另一种版本，称为
    `binary_search_rayon`，并行计算两种情况。这两个函数都接受一个类型为 `T` 的切片，该切片实现了一些特质。它们还接受相同类型的元素。这些函数将在切片中查找指定的元素，如果存在则返回
    `true`，否则返回 `false`。现在让我们看看代码：
- en: '[PRE19]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: In both cases, the first thing to do is to sort the input slice, since a binary
    search requires input to be sorted. `binary_search_recursive` is straightforward;
    we compute the middle point, and if the element there is the one we want, we return
    a `true`. We also include a case checking if there is only one element left in
    the slice and if that is the element we want. We return `true` or `false`, accordingly.
    This case forms the base case for our recursion. We can then check if our desired
    element is less than or greater than the current mid-point. We recursively search
    either side, based on that check.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在这两种情况下，首先要做的事情是对输入切片进行排序，因为二分查找需要排序的输入。`binary_search_recursive` 是直接的；我们计算中间点，如果那里的元素是我们想要的，我们返回
    `true`。我们还包括一个检查切片中是否只剩下一个元素，并且如果那个元素是我们想要的。相应地返回 `true` 或 `false`。这个情况形成了我们递归的基础情况。然后我们可以检查我们想要的元素是否小于或大于当前的中点。根据这个检查，我们递归地搜索两边。
- en: 'The Rayon case is mostly the same, the only difference being how we recurse.
    We use a `scope` to spawn the two cases in parallel and collect their results.
    The scope takes in a closure and invokes that in reference to the named scope, `s`.
    The scope also ensures that each of the tasks is completed before it exits. We
    collect the results from each half in two variables, and finally, we return a
    logical OR of those, since we care about finding the element in either of the
    two halves. Here is how a sample run looks:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: Rayon 的情况基本上相同，唯一的区别在于我们如何递归。我们使用 `scope` 并行生成两种情况并收集它们的结果。作用域接受一个闭包，并在这个命名作用域
    `s` 中调用它。作用域还确保在退出之前每个任务都已完成。我们从每个半部分收集结果到两个变量中，最后，我们返回这些结果的逻辑或，因为我们关心的是在两个半部分中的任何一个找到元素。以下是一个示例运行情况：
- en: '[PRE20]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Rayon also provides a parallel iterator, an iterator that has the same semantics
    as the one in the standard library, but where elements might be accessed in parallel.
    This construct is useful in situations where each unit of data can be processed
    completely independently, without any form of synchronization between each processing
    task. Let''s look at an example of how to use these iterators, starting with the
    project setup using Cargo:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: Rayon 还提供了一个并行迭代器，这是一个与标准库中的迭代器具有相同语义的迭代器，但元素可能以并行方式访问。这种结构在每种数据单元都可以完全独立处理，且每个处理任务之间没有任何同步的情况下非常有用。让我们看看如何使用这些迭代器的例子，从使用
    Cargo 的项目设置开始：
- en: '[PRE21]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'In this case, we will compare the performance of a regular iterator to that
    of a parallel iterator using Rayon. For that, we will need to use the `rustc-test`
    crate. Here is how the Cargo setup looks:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们将使用 Rayon 比较常规迭代器和并行迭代器的性能。为此，我们需要使用 `rustc-test` 包。以下是 Cargo 设置的看起来：
- en: '[PRE22]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Here is the code, as shown in the following code snippet. We have two functions
    doing the exact same thing. Both of them receive a vector of integers, they then
    iterate over that vector and filter out even integers. Finally, they return squares
    of odd integers:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是代码，如以下代码片段所示。我们有两个执行完全相同操作的函数。它们都接收一个整数向量，然后遍历该向量并过滤出偶数整数。最后，它们返回奇数整数的平方：
- en: '[PRE23]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'We start with importing everything from Rayon. In `filter_parallel`, we use
    `par_iter` to get a parallel iterator. `filter_sequential` is the same, the only
    difference being that it uses the `iter` function to get a regular iterator. In
    our main function, we create two sequences and pass those to our functions while
    printing the outputs. Here is what we should see:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先从 Rayon 导入所有内容。在 `filter_parallel` 中，我们使用 `par_iter` 来获取一个并行迭代器。`filter_sequential`
    与之相同，唯一的区别在于它使用 `iter` 函数来获取一个常规迭代器。在我们的主函数中，我们创建两个序列并将它们传递给我们的函数，同时打印输出。以下是我们应该看到的内容：
- en: '[PRE24]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Not surprisingly, both return the same result. The most important part of this
    example is the benchmark. For this to work, we will need to activate the test
    feature using `#![feature(test)]` and declare a new test module. In that, we import
    everything from the top-level module, which is the main file in this case. We
    also import `test::Bencher`, which will be used for running the benchmarks. The
    benchmarks are defined by the `#[bench]` attributes, which are applied to functions
    that take in an object which is a mutable reference to a `Bencher` type. We pass
    the functions that we need to benchmark to the bencher, which takes care of running
    those and printing results.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 并不令人意外，两者返回相同的结果。这个例子中最重要的一部分是基准测试。为了使其工作，我们需要使用 `#![feature(test)]` 激活测试功能并声明一个新的测试模块。在那里，我们从顶层模块导入所有内容，在这个案例中，顶层模块是主文件。我们还导入了
    `test::Bencher`，它将被用于运行基准测试。基准测试由 `#[bench]` 属性定义，这些属性应用于接受一个对象作为 `Bencher` 类型可变引用的函数。我们将需要基准测试的函数传递给基准测试器，基准测试器负责运行这些函数并打印结果。
- en: 'The benchmarks can be run using Cargo:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用 Cargo 运行基准测试：
- en: '[PRE25]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: This output shows the two functions and how much time it took to execute an
    iteration of each. The number in the bracket indicates the confidence interval
    for the given measurement. While the confidence interval for the parallel version
    is larger than the non-parallel one, it does perform 58 times more iterations
    than the non-parallel one. Thus, the parallel version is considerably faster.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 这个输出显示了两个函数以及执行每个迭代所需的时间。括号中的数字表示给定测量的置信区间。虽然并行版本的置信区间比非并行版本大，但它确实执行了比非并行版本多
    58 倍的迭代。因此，并行版本要快得多。
- en: Parsing using Pest
  id: totrans-86
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Pest 进行解析
- en: 'We studied different parsing techniques in [Chapter 4](part0053.html#1IHDQ0-e803f047c8b7448c90887daa96419287)*,* *Data
    serialization, De-Serialization, and Parsing*. We looked at using parser combinators
    using Nom, building a large parser from smaller parts. There is a completely different
    way of solving the same problem of parsing textual data, using **Parsing Expression
    Grammar (PEG)**. A PEG is a formal grammar that defines how a parser should behave.
    Thus, it includes a finite set of rules, from basic tokens to more complex structures.
    A library that can take in such grammar to produce a functional parser is Pest.
    Let''s look at an example of rewriting our HTTP parsing example from [Chapter
    4](part0053.html#1IHDQ0-e803f047c8b7448c90887daa96419287),* Data Serialization,
    De-Serialization, and Parsing*, using Pest. Start with the Cargo project set up:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在[第4章](part0053.html#1IHDQ0-e803f047c8b7448c90887daa96419287)*数据序列化、反序列化和解析*中研究了不同的解析技术。我们探讨了使用Nom的解析器组合器，从较小的部分构建一个大型解析器。解决解析文本数据相同问题的另一种完全不同的方法是使用**解析表达式语法（PEG）**。PEG是一种形式语法，它定义了解析器应该如何行为。因此，它包括一组有限的规则，从基本标记到更复杂的结构。可以接受此类语法的库是Pest。让我们看看使用Pest重写我们的HTTP解析示例[第4章](part0053.html#1IHDQ0-e803f047c8b7448c90887daa96419287)*数据序列化、反序列化和解析*的例子。从Cargo项目设置开始：
- en: '[PRE26]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Like always, we will need to declare dependency on Pest components like this:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 和往常一样，我们需要声明对Pest组件的依赖，如下所示：
- en: '[PRE27]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'The next step is to define our grammar, which is a linear collection of parsing
    rules. Like we did previously, we are interested in parsing `HTTP GET` or `POST`
    requests. Here is what the grammar looks like:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是定义我们的语法，它是一系列解析规则的线性集合。像之前一样，我们对解析`HTTP GET`或`POST`请求感兴趣。以下是语法的样子：
- en: '[PRE28]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: The first step is to define literal rules that are to be matched verbatim. These
    correspond to the leaf parsers in Nom. We define literals for newline, carriage
    return, space, the two request strings, the separator, and the fixed string for
    the HTTP version. We also define `request` as the logical OR of the two request
    literals. A list of characters is the logical OR of all lowercase letters and
    all uppercase letters. At this point, we have all we need to define the final
    rule. That is given by `ident_list` and consists of the request, followed by a
    single space, then a separator; then we indicate that our parser should accept
    one or more characters using `*`. The next valid input is again a separator, followed
    by a single space, the version string, a carriage return, and finally, a newline.
    Note that consecutive inputs are separated by the `~` character. The leading `_`
    in front indicates that this is a silent rule and should only be used at the top
    level, as we will see shortly.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是定义要逐字匹配的文本规则。这些对应于Nom中的叶解析器。我们定义了换行符、回车符、空格、两个请求字符串、分隔符以及HTTP版本固定字符串的文本。我们还定义了`request`作为两个请求文本的逻辑或。字符列表是所有小写字母和所有大写字母的逻辑或。到此为止，我们已经有了定义最终规则所需的一切。这由`ident_list`给出，由请求、一个空格、然后是分隔符组成；然后我们指出我们的解析器应使用`*`接受一个或多个字符。下一个有效输入又是分隔符，后面跟一个空格、版本字符串、回车符，最后是换行符。请注意，连续输入由`~`字符分隔。前面的下划线`_`表示这是一个静默规则，并且应该仅在顶层使用，正如我们很快就会看到的。
- en: 'The main file looks like this:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 主文件看起来是这样的：
- en: '[PRE29]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: The code is simple; the library provides one basic trait, called `Parser`. This
    can be custom derived for unit structures to produce a functional parser based
    on the grammar file, as input using an attribute called `grammar`. Notably, this
    library uses custom derivatives and custom attributes very efficiently to provide
    a nicer user experience. In our case, the unit structure is called `RequestParser`,
    which implements the `parse` method. In our main function, we call the that method,
    passing in the rule from which parsing should start (in our case, that happens
    to be the final top-level rule, called `ident_list`) and a string to parse. Errors
    are handled by aborting, since there is not much point in continuing if parsing
    failed.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 代码很简单；库提供了一个基本特性，称为`Parser`。这可以通过使用名为`grammar`的属性为单元结构自定义派生，以基于语法文件生成一个功能解析器。值得注意的是，这个库非常高效地使用自定义派生和自定义属性来提供更好的用户体验。在我们的例子中，单元结构被称为`RequestParser`，它实现了`parse`方法。在我们的主函数中，我们调用这个方法，传入解析应该开始的规则（在我们的情况下，那恰好是最终的顶级规则，称为`ident_list`）以及要解析的字符串。由于解析失败后继续没有太多意义，错误通过终止来处理。
- en: 'Having set this structure up, we attempt to parse two strings. The first one
    is a normal HTTP request. The `parse` method returns an iterator over the stream
    of parsed tokens. We loop over them and print out the name of the rule that token
    matched with, the span in the input that has the token, and the literal text in
    that token. Later, we attempt to parse a string which does not have a valid HTTP
    request. Here is the output:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在设置好这个结构后，我们尝试解析两个字符串。第一个是一个正常的HTTP请求。`parse`方法返回一个解析令牌流上的迭代器。我们遍历它们并打印出与令牌匹配的规则名称，输入中包含令牌的范围，以及该令牌中的文本。稍后，我们尝试解析一个没有有效HTTP请求的字符串。以下是输出：
- en: '[PRE30]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: The first thing to notice is that parsing a wrong HTTP request failed. The error
    message is nice and clear, explaining exactly where it failed to parse. The correct
    request did parse successfully and printed out the tokens and all required details
    to further process those.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 首先要注意的是解析错误的HTTP请求失败了。错误信息很友好且清晰，解释了解析失败的确切位置。正确的请求解析成功并打印出了所有必要的令牌和详细信息，以便进一步处理。
- en: Miscellaneous utilities
  id: totrans-100
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 杂项实用工具
- en: 'In C and C++, a common workflow is to define a set of bits as flags. They are
    generally defined at powers of two, so the first flag will have the decimal value
    of one, the second one will have two, and so on. This helps in performing logical
    combinations of those flags. The Rust ecosystem has a crate to facilitate the
    same workflow. Let''s look at an example of using the bitflags crate for working
    with flags. Let''s start with initializing an empty project using Cargo:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在C和C++中，一个常见的流程是定义一组位作为标志。它们通常定义为2的幂，因此第一个标志的十进制值为1，第二个标志的值为2，依此类推。这有助于执行这些标志的逻辑组合。Rust生态系统有一个crate来简化相同的流程。让我们看看使用bitflags
    crate处理标志的示例。让我们从使用Cargo初始化一个空项目开始：
- en: '[PRE31]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'We will set up our project manifest to add `bitflags` as a dependency:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将设置项目清单以添加`bitflags`作为依赖项：
- en: '[PRE32]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'When all of that is ready, our main file will look like this:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 当所有这些都准备好了，我们的主文件将看起来像这样：
- en: '[PRE33]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: We import our dependencies and then use the `bitflags!` macro to define a number
    of flags, as mentioned before, we set their values in powers of two. We also demonstrate
    attaching additional properties to the `bitflags` using the trait system. For
    this, we have a custom trait called `Format` that prints a given input as a decimal.
    The conversion is achieved using the `bits()` method that returns all the bits
    in the given input. The next step is to implement our trait for the `Flags` structure.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 我们导入我们的依赖项，然后使用`bitflags!`宏定义一系列标志，如前所述，我们将它们的值设置为2的幂。我们还展示了使用特性系统附加到`bitflags`上的额外属性。为此，我们有一个自定义特性`Format`，它将给定输入打印为十进制。转换是通过使用返回给定输入中所有位的`bits()`方法来实现的。下一步是实现我们的特性为`Flags`结构。
- en: Once we have done that, we move on to the `main` function; in there, we construct
    a logical OR of two given flags. We use the `decimal` method to print out representations
    of the bitflags and ensure they are equal. Finally, we use the `all` function
    to display a human readable form of the flags. Here, the `contains` function returns
    `true`, since the flag `X` is indeed in the logical OR of `X` and `Y`.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在完成这些后，我们继续到`main`函数；在那里，我们构造两个给定标志的逻辑或。我们使用`decimal`方法打印出位标志的表示，并确保它们相等。最后，我们使用`all`函数显示标志的人类可读形式。在这里，`contains`函数返回`true`，因为标志`X`确实在`X`和`Y`的逻辑或中。
- en: 'Here is what we should see upon running this:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 运行此代码后我们应该看到以下内容：
- en: '[PRE34]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: The values of individual flags should always be an integer type.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 单个标志的值始终应该是整数类型。
- en: 'Another useful utility for network programming is the `url` crate. This crate
    provides a number of functionalities to parse parts of URLs, from links to web
    pages to relative addresses. Let''s look at a very simple example, starting with
    the project setup:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 网络编程中另一个有用的实用工具是`url` crate。这个crate提供了解析URL部分的功能，从网页链接到相对地址。让我们看一个非常简单的例子，从项目设置开始：
- en: '[PRE35]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'The Cargo manifest should look like this:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 货物清单应该看起来像这样：
- en: '[PRE36]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Let''s look at the main file. In this relatively short example, we are parsing
    a GitLab URL to extract a few important pieces of information:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看主文件。在这个相对简短的示例中，我们正在解析GitLab URL以提取一些重要的信息：
- en: '[PRE37]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: This example URL contains a fragment, pointing to a one-line number in a file.
    The scheme is set to git, and there is a username and password set for HTTP based
    authentication. The URL crate provides a method call `parse` that takes in a string
    and returns a struct that has all required information. We can subsequently call
    individual methods on that variable to print out relevant information.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 这个示例URL包含一个片段，指向文件中的一行数字。方案设置为git，并且为基于HTTP的认证设置了用户名和密码。URL crate提供了一个名为`parse`的方法，它接受一个字符串并返回一个包含所有所需信息的结构体。我们随后可以调用该变量的单个方法来打印出相关信息。
- en: 'Here is what this code outputs, matching our expectation:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是这段代码的输出结果，符合我们的预期：
- en: '[PRE38]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: Summary
  id: totrans-121
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: This last chapter was a mix of a number of topics which we did not consider
    to be mainstream enough for other chapters. But we should remember that, in a
    large ecosystem like Rust has, things evolve very quickly. So some ideas which
    may not be mainstream today, might just be adopted in the community tomorrow.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 这最后一章包含了多个主题，我们认为它们不够主流，不适合放在其他章节中。但我们应该记住，在一个像Rust这样的庞大生态系统中，事物发展非常迅速。所以，今天可能不是主流的一些想法，明天可能会被社区采纳。
- en: Overall, Rust is a wonderful language with enormous potential. We earnestly
    hope that this book helped the reader get a sense of how to harness its power
    for network programming.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 总体来说，Rust是一种非常棒的语言，具有巨大的潜力。我们真诚地希望这本书能帮助读者了解如何利用其力量进行网络编程。
