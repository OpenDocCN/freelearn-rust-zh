- en: Algorithm Evaluation
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 算法评估
- en: When looking at algorithms as defined entities, what makes one algorithm better
    than the other? Is it the number of steps required to finish? The amount of memory
    that is committed? CPU cycles? How do they compare across machines and operating
    systems with different memory allocators?
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 当将算法视为定义实体时，是什么使得一个算法比另一个算法更好？是完成所需的步骤数？所分配的内存量？CPU周期？它们如何在具有不同内存分配器的机器和操作系统之间进行比较？
- en: 'There are a lot of questions here that need answers, since comparing work with
    others is important in order to find the best approach possible to solve a given
    problem. In this chapter, you can look forward to learning about the following:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有很多问题需要回答，因为比较他人的工作对于找到解决给定问题的最佳方法非常重要。在本章中，你可以期待了解以下内容：
- en: Evaluating algorithms in practice
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实践中评估算法
- en: Classifying algorithm and data structure behaviors
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对算法和数据结构行为进行分类
- en: Estimating the plausibility of a better algorithm
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 估算更好算法的可行性
- en: The Big O notation
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 大O符号
- en: 'Physics is not a topic in this book, but its influence is far-reaching and
    powerful enough to be obeyed everywhere, even by virtual constructs such as algorithms!
    However great their design, they still are constrained by two important factors:
    time and space.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 物理学不是本书的主题，但其影响深远，强大到无处不在，甚至算法这样的虚拟构造也要遵守！然而，无论设计多么伟大，它们仍然受限于两个重要因素：时间和空间。
- en: Time? Whenever anything needs to be done, a sequence of steps is required. By
    multiplying the number of steps by the time for each step, the total—absolute—time
    is easy to calculate. Or so we think. For computers, this is *mostly* true, but
    many questions make it very hard to really know, since modern CPUs go way beyond
    what previous generations were able to achieve. Is that only thanks to higher
    clock rates? What about the additional cores? SIMD? Simply taking the absolute
    time won't achieve real comparability between algorithms. Maybe the number of
    steps is what we should use.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 时间？无论何时需要完成任何事情，都需要一系列步骤。通过将每个步骤的时间乘以步骤的数量，总时间——绝对时间——很容易计算。或者我们认为是这样。对于计算机来说，这*大部分*是正确的，但许多问题使得真正知道这一点变得非常困难，因为现代CPU的能力远远超过了前几代。这仅仅是由于更高的时钟频率吗？额外的核心？SIMD？仅仅计算绝对时间并不能真正实现算法之间的可比性。也许步骤的数量是我们应该使用的。
- en: Space (as in memory) has become a commodity in many domains over the last few
    years, even in the embedded space. While the situation has improved, it still
    pays to be mindful of how many bytes are stored in memory and how much that contributes
    to the goal of the algorithm. Or in other words, is this worth it? Many algorithmic
    tasks face a trade-off between what's stored in memory and what's computed on
    demand. The latter might be just enough to solve the problem, or it might not
    be; this is a decision the developer has to make.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去几年中，空间（即内存）在许多领域已经成为一种商品，甚至在嵌入式空间也是如此。尽管情况有所改善，但仍然值得注意存储在内存中的字节数以及这对算法目标的贡献。换句话说，这是否值得？许多算法任务面临着存储在内存中的内容与按需计算的内容之间的权衡。后者可能刚好足够解决问题，也可能不够；这是开发者必须做出的决定。
- en: Other people's code
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 他人代码
- en: 'Consequently, every algorithm must have a "number of steps required" and "bytes
    of memory required" property, right? Close: since they are ever-changing variables,
    a universal way of describing what other people have achieved is necessary.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，每个算法都必须有一个“所需步骤数”和“所需内存字节数”属性，对吗？接近：由于它们是不断变化的变量，有必要找到一个描述他人所取得的成就的通用方法。
- en: 'Typically, programmers instinctively know how to do that: "is this thing really
    doing everything twice?!" should be a familiar outcry. What has been said here?
    Assuming it''s a function that has an input parameter `x`, it sounds like the
    function is doing something with `x` twice. Mathematically speaking, this would
    be expressed as *f(x) = 2x*.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，程序员本能地知道如何做到这一点：“这个玩意儿真的做了两次吗？！”应该是一个熟悉的呼喊。这里说了什么？假设它是一个具有输入参数`x`的函数，听起来这个函数对`x`做了两次操作。从数学的角度来说，这可以表示为*f(x)
    = 2x*。
- en: What this is really saying is that for every input, the required number of steps
    to fully execute the function is twice the input—isn't this exactly what we have
    been looking for? What would be a better way to write it down?
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 这实际上是在说，对于每个输入，完全执行函数所需的步骤数是输入的两倍——这不是我们一直在寻找的吗？有什么更好的方法来写下它？
- en: The Big O
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 大O符号
- en: 'Looking at that issue from a (mathematical) function perspective, this is a
    shared need across mathematics, computer science, physics, and so on: they all
    want to know how expensive a function is. This is why a common notation was invented
    by Edmund Landau: the Big O notation (or Landau notation) consisting of the uppercase
    letter *O,* which declares the *order* of a function. The main growth factor is
    then put into parentheses following the letter *O*.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 从（数学）函数的角度来看这个问题，这是数学、计算机科学、物理学等领域的一个共同需求：他们都想知道一个函数有多贵。这就是为什么爱德蒙·兰道发明了一种常见的符号：大
    O 符号（或兰道符号），由大写字母 *O* 组成，它声明了函数的 *阶*。然后主要增长因子放在字母 *O* 后面的括号中。
- en: There are other, related notations that use small *o*, Omegas, Theta, and others,
    but those are less relevant in practical terms. Check the *Further reading* section
    for an article by Donald Knuth on this.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 还有其他一些相关的符号，使用小 *o*、Omega、Theta 等，但在实际应用中这些不太相关。请参阅 *进一步阅读* 部分，了解唐纳德·克努特关于此的文章。
- en: Asymptotic runtime complexity
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 渐近运行时间复杂度
- en: For computer science, the exact, absolute runtime is typically not important
    when implementing algorithms (you can always get a faster computer). Instead,
    the runtime complexity is more important since it directly influences performance
    as an overall measure of work, independent of details.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 对于计算机科学来说，在实现算法时，确切的绝对运行时间通常并不重要（你总是可以获取更快的计算机）。相反，运行时间复杂度更重要，因为它直接影响了性能，作为工作整体的一个衡量标准，独立于细节。
- en: 'Since this is not an exact measurement and the actual performance is influenced
    by other factors, sticking with an asymptotic (read: rough) measure is the best
    strategy. In addition to that, algorithms have best and worst cases. Unless you
    are trying to improve on a particular case, the worst case is what''s typically
    compared:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这并不是一个精确的测量，实际性能受其他因素的影响，因此坚持使用渐近的（即：粗略的）度量是最好的策略。除此之外，算法有最好和最坏的情况。除非你试图改进特定的情况，否则通常比较的是最坏的情况：
- en: '[PRE0]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Iterating over this, `Vec<T>` has a runtime complexity of *O(n)* where *n* is
    the length of `Vec<T>`, regardless of the fact that the loop will break right
    away. Why? Because of pessimism. In reality, it is often hard to say what the
    input vector looks like and when it will actually exit, so the worst case is that
    it goes over the entire sequence without breaking, that is, *n* times. Now that
    we have seen how to write this down, let's see how to find out the runtime complexity
    of our own algorithms.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 对此进行迭代，`Vec<T>` 的运行时间复杂度为 *O(n)*，其中 *n* 是 `Vec<T>` 的长度，无论循环是否会立即中断。为什么？因为悲观主义。实际上，通常很难说输入向量看起来是什么样子，以及它何时会真正退出，所以最坏的情况是它遍历整个序列而没有中断，即
    *n* 次。现在我们已经看到了如何写下这一点，让我们看看如何找出我们自己的算法的运行时间复杂度。
- en: Making your own
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自行制作
- en: There are only a few aspects that change the complexity of an algorithm, those
    that have been shown to proportionally increase the total time required of an
    algorithm.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 只有少数方面会改变算法的复杂度，那些已经证明会成比例增加算法所需总时间的方面。
- en: 'These are as follows:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 这些如下所示：
- en: An arithmetic operation (`10 + 30`)
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个算术运算（`10 + 30`）
- en: An assignment (`let x = 10`)
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个赋值（`let x = 10`）
- en: A test (`x == 10`)
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个测试（`x == 10`）
- en: A read or write of a basic type (`u32`, `bool`, and so on)
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基本类型的读取或写入（`u32`、`bool` 等）
- en: If a piece of code only does one of these operations, it is one step, that is,
    *O(1),* and whenever there is a choice (`if` or `match`), the more complex branch
    has to be picked. Regardless of any input parameters, it will be the same number
    of steps—or constant time. If they are run in a loop, things get more interesting.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一段代码只执行这些操作中的一个，那么它是一步，即 *O(1)*，并且每当有一个选择（`if` 或 `match`），就必须选择更复杂的分支。无论任何输入参数如何，它都将执行相同数量的步骤——即常数时间。如果它们在循环中运行，事情就变得更有趣了。
- en: Loops
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 循环
- en: When in a loop, and the number of iterations is not known at compile time, it
    will be a major influence on runtime complexity. If an operation mentioned earlier
    is executed in the loop (for example, a `sum` operation), one could declare the
    complexity as *O(1 * n)* for the arithmetic operation. After adding another operation,
    we could express it as *O(2 * n)* and, while this would be correct, these are
    not the driving forces of the loop. Regardless of the number of operations that
    are executed *n* times, the main growth factor remains *n*. Hence, we simply say
    *O(n),* unless you are trying to compare the same algorithm, where the number
    of iterations actually makes a difference. If there are subsequent loops, the
    most expensive one is picked.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 当在一个循环中，且循环的迭代次数在编译时未知时，它将对运行时间复杂度产生重大影响。如果之前提到的操作在循环中执行（例如，一个 `sum` 操作），可以将算术操作的复杂度声明为
    *O(1 * n)*。在添加另一个操作后，我们可以将其表示为 *O(2 * n)*，虽然这是正确的，但这些不是循环的主要驱动力。无论执行 *n* 次的操作数量如何，主要增长因子仍然是
    *n*。因此，我们简单地说是 *O(n)*，除非你试图比较同一算法，其中迭代次数实际上是有区别的。如果有后续的循环，则选择最昂贵的那个。
- en: 'However, upon nesting loops, the complexity changes considerably. Consider
    this (really bad) algorithm for comparing two lists:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在嵌套循环之后，复杂度会显著变化。考虑这个（真的很差）比较两个列表的算法：
- en: '[PRE1]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: For each element in the first collection, the second collection is fully iterated.
    In other words, each element is looked at *n * m* times, resulting in a runtime
    complexity of *O(n*m)*, or, if both collections are the same size, *O(n²)*.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 对于第一个集合中的每个元素，第二个集合将被完全迭代。换句话说，每个元素被查看 *n * m* 次，导致运行时间复杂度为 *O(n*m)*，或者如果两个集合大小相同，则为
    *O(n²)*。
- en: Can it get even worse? Yes!
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 能变得更糟吗？是的！
- en: Recursion
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 递归
- en: Since all recursive algorithms can be unrolled into a loop, they can achieve
    the same results. However, recursion, or more specifically backtracking (which
    will be discussed in more detail in [Chapter 11](0131b10b-0ea4-4663-966a-46d6ecda142b.xhtml),
    *Random and Combinatorial*), makes it easier to create higher runtime complexities.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 由于所有递归算法都可以展开成循环，因此它们可以达到相同的结果。然而，递归，或者更具体地说回溯（将在第11章[0131b10b-0ea4-4663-966a-46d6ecda142b.xhtml]“随机与组合”中更详细地讨论），使得创建更高的运行时间复杂度变得更容易。
- en: Typical combinatorial problems result in exponential runtimes, since there are
    a number of variations (such as different colors) that have to be enumerated *n*
    times so that a constraint is satisfied, which is only evaluated at the end. If
    there are two colors, the runtime complexity will therefore be *O(2^n)* for a
    sequence of *n* colors, if no two colors can be adjacent to each other in a graph
    (graph coloring problem).
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 典型的组合问题会导致指数级的运行时间，因为存在许多变体（例如不同的颜色），必须枚举 *n* 次以满足约束，而这个约束只在最后评估。如果有两种颜色，那么在图中没有两种颜色可以相邻的情况下，序列的运行时间复杂度将是
    *O(2^n)*。
- en: Recursive algorithms also make it hard to estimate runtime complexity quickly,
    since the branch development is hard to visualize.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 递归算法也使得快速估计运行时间复杂度变得困难，因为分支发展难以可视化。
- en: Complexity classes
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 复杂度类别
- en: In general, all algorithms fall into one of a few classes. Let's look at these
    classes ordered by their growth speed. Depending on the literature, there might
    be more or fewer classes, but this is a good set to start with since they represent
    the major directions of growth behavior.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，所有算法都落入几个类别之一。让我们按增长速度的顺序查看这些类别。根据文献的不同，可能会有更多或更少的类别，但这是一个好的起点，因为它们代表了增长行为的主要方向。
- en: O(1)
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: O(1)
- en: Constant time, which means everything will take the same amount of time. Since
    this chart would be a horizontal line at the *y* value of *1*, we will skip it
    in favor of sparing a tree.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 常数时间，这意味着所有操作都将花费相同的时间。由于这个图表将在 *y* 值为 *1* 的水平线上，我们将跳过它以节省一棵树。
- en: O(log(n))
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: O(log(n))
- en: Growth is defined by the logarithmic function (in general, base 2), which is
    better than linear growth.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 增长由对数函数（通常以2为底）定义，这比线性增长更好。
- en: 'Here is the plot of the mathematical function:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 这是数学函数的图像：
- en: '![](img/ad843385-9de2-43d1-a95e-9a7289852ef4.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ad843385-9de2-43d1-a95e-9a7289852ef4.png)'
- en: O(n)
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: O(n)
- en: 'Linear time, which means that the solution performance depends on the input
    in a linear way:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 线性时间，这意味着解决方案的性能以线性方式依赖于输入：
- en: '![](img/3db23b99-73e0-4ae4-9a72-52f08be1f8b7.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3db23b99-73e0-4ae4-9a72-52f08be1f8b7.png)'
- en: O(n log(n))
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: O(n log(n))
- en: 'This is sometimes called quasilinear time and is the best achievable complexity
    for sorting:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 这有时被称为准线性时间，是排序能够达到的最佳复杂度：
- en: '![](img/0084a6fa-de2c-496a-af29-8ad592f8c8af.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0084a6fa-de2c-496a-af29-8ad592f8c8af.png)'
- en: O(n²)
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: O(n²)
- en: 'The squared runtime is typical for the naive implementation of search or sorting
    algorithms:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 平方运行时间对于搜索或排序算法的直观实现来说是典型的：
- en: '![](img/b6f8dd4b-d78c-4562-844f-758d836ef0f8.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b6f8dd4b-d78c-4562-844f-758d836ef0f8.png)'
- en: O(2n)
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: O(2n)
- en: 'This is among the most expensive classes and can often be found in really hard-to-solve
    problems. This plot has a significantly smaller *x* value (*0 - 10*) and generates
    a higher *y* value (or runtime) than the `O(n log(n))` chart:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 这是最昂贵的类别之一，通常可以在一些非常难以解决的问题中找到。这个图表的 *x* 值（*0 - 10*）显著小于 `O(n log(n))` 图表，并产生更高的
    *y* 值（或运行时间）：
- en: '![](img/a186b9ab-3fdf-48e7-995a-9ccd28266e92.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a186b9ab-3fdf-48e7-995a-9ccd28266e92.png)'
- en: Comparison
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 比较
- en: Having individual charts is great for imagining the projected runtime and estimating
    what a task's performance could look like when its input is increased. If we plot
    all of these lines into a single chart, however, their performance will become
    obvious.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 拥有个体图表对于想象预期的运行时间和估计当输入增加时任务性能可能的样子非常有帮助。然而，如果我们把这些线都画在一张图上，它们的性能就会变得明显。
- en: 'The typical comparison is against the linear time complexity (*O(n)*), since
    most naive solutions would be expected to achieve this performance:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 典型的比较是针对线性时间复杂度（*O(n)*），因为大多数直观的解决方案都预期能够达到这种性能：
- en: '![](img/becff7dd-48c4-4026-a18b-67110922a5f3.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![](img/becff7dd-48c4-4026-a18b-67110922a5f3.png)'
- en: With this chart in mind, we can look at problems and their expected performance
    in the next section.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到这张图，我们可以在下一节中查看问题和它们的预期性能。
- en: In the wild
  id: totrans-65
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在野外
- en: In reality, there are a lot of factors that may influence the choice of space
    and runtime complexity. Typically, these factors are forms of resource constraints,
    such as power consumption on embedded devices, clock cycles in a cloud-hosted
    environment, and so on.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，有很多因素可能会影响空间和运行时间复杂度的选择。通常，这些因素是资源约束的形式，例如嵌入式设备上的功耗、云托管环境中的时钟周期等等。
- en: Since it is difficult to find out the complexities of a particular algorithm,
    it is helpful to know a few, so the choice comes intuitively. Often, the runtime
    complexity is not the only important aspect, but the absolute execution time counts.
    Under these conditions, a higher runtime complexity can be preferable if *n* is
    sufficiently small.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 由于很难找出特定算法的复杂度，了解一些常见的复杂度是有帮助的，这样选择就会变得直观。通常，运行时间复杂度并不是唯一重要的方面，绝对执行时间也很重要。在这些条件下，如果
    *n* 足够小，较高的运行时间复杂度可能是可取的。
- en: This is best demonstrated when `Vec<T>` contains only a few elements, where
    a linear search is a lot faster than sorting and then running a binary search.
    The overhead of sorting might just be too much compared to searching right away.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 这在 `Vec<T>` 只包含少量元素时表现得最好，其中线性搜索比排序后运行二分搜索要快得多。与立即搜索相比，排序的开销可能太大。
- en: Getting this trade-off and the overall implementation right is hugely beneficial
    for the entire program and will outweigh any other optimizations. Let's take a
    look at a few runtime complexities that can be found in everyday life.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 获得这种权衡和整体实现正确对于整个程序来说非常有益，并且会超过任何其他优化。让我们看看日常生活中可以找到的一些运行时间复杂度。
- en: Data structures
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据结构
- en: 'Algorithms on lists of all kinds almost always exhibit *O(n)* behavior, since
    most actions involve shifting or going through other elements. Hence, operations
    such as insert at or remove from a position, as well as finding elements (when
    unsorted), are *O(n)*. This is very visible, particularly in linked lists, with
    only a few exceptions: a dynamic array''s element access (*O(1)*), prepending/appending
    elements or lists, and splitting lists appending elements in a linked list (*O(1)*).'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 所有类型的列表算法几乎总是表现出 *O(n)* 的行为，因为大多数操作都涉及移动或遍历其他元素。因此，在某个位置插入或删除元素，以及查找元素（当未排序时），都是
    *O(n)*。这在链表中尤为明显，只有少数例外：动态数组元素的访问（*O(1)*）、前缀/后缀元素或列表，以及链表中添加元素时的列表分割（*O(1)*）。
- en: Special cases of lists, such as **stacks** and **queues**, make use of these
    exceptions and let a user insert to or remove from only the ends of that list.
    **Skip lists** on the other hand employ a tree-like strategy for achieving great
    search performance, which speeds up inserts and removals too. But this comes at
    the expense of memory, since the additional elements are proportional (*log(n)*)
    to the list length.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 列表的特殊情况，例如**栈**和**队列**，利用这些异常，并允许用户仅在该列表的端点插入或删除。另一方面，**跳表**采用类似树的策略以实现出色的搜索性能，这也会加快插入和删除的速度。但这是以内存为代价的，因为额外的元素与列表长度成比例（*log(n)*)。
- en: For search, **trees** are great. Regular trees (that is, anything that can be
    a B-Tree) exhibit *O(log(n))* complexities on many operations, including insert,
    remove, and find. This is particularly great since difference to *O(n)* actually
    increases the more elements there are in the collection.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 对于搜索，**树**是很好的。常规树（即可以是B树的一切）在许多操作上表现出*O(log(n))*的复杂度，包括插入、删除和查找。这特别出色，因为与*O(n)*的差异实际上随着集合中元素数量的增加而增加。
- en: The only thing potentially better are **maps** and **sets**, if the underlying
    implementation uses an appropriate hashing algorithm. Any operation *s**hould*
    be completed in constant time (*O(1)*), if there are no collisions. Typically,
    there will be some collisions, but the runtime complexity will not exceed *O(n)*
    because, if all else fails, a linear search works. Consequently, real performance
    will be somewhere in between, with the hashing algorithm being the most important
    influence. For most libraries, hash maps (and sets) are faster than their tree-based
    counterparts.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 最好的可能就是**映射**和**集合**，如果底层实现使用了合适的哈希算法。如果没有冲突，任何操作*都应该*在常数时间内（*O(1)*）完成。通常会有一些冲突，但运行时间复杂度不会超过*O(n)*，因为如果所有其他方法都失败了，线性搜索仍然有效。因此，实际性能将介于两者之间，其中哈希算法是最重要的因素。对于大多数库来说，哈希映射（和集合）比基于树的对应物要快。
- en: Everyday things
  id: totrans-75
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 日常事物
- en: 'Whenever something needs sorting, there are a lot of ways to achieve that,
    but the baseline is *O(n²)*. It''s the same way most people order their socks:
    pick one and find the match, then repeat (called **selection sort**). How else
    would one compare all elements to find their order? Better approaches, such as
    heap sort, merge sort, and so on, all exhibit *O(n log(n))* behavior in the worst
    case, which is the best possible (consistent) performance for sorting algorithms.
    Additionally, since the best case for any sorting algorithm is *O(n)*—making sure
    everything was already in order—the average case matters the most. We will get
    into strategies about that later in this book.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 每当需要排序时，有很多方法可以实现这一点，但基础是*O(n²)*。这与大多数人整理袜子的方式相同：挑选一个并找到匹配的，然后重复（称为**选择排序**）。否则，如何比较所有元素以找到它们的顺序？更好的方法，如堆排序、归并排序等，在最坏情况下都表现出*O(n
    log(n))*的行为，这是排序算法可能达到的最佳（一致）性能。此外，由于任何排序算法的最佳情况是*O(n)*——确保一切都已经排序——平均情况最为重要。我们将在本书后面的章节中探讨这方面的策略。
- en: 'Search (or lookup) is another topic that we will get into in [Chapter 10](32002bad-c2bb-46e9-918d-12d7dabfe579.xhtml),
    *Finding Stuff*, but the associated runtime complexities are great examples. Searching
    on any unsorted data structure will be *O(n)* most of the time, while sorted collections
    can utilize binary search (a tree''s search strategy) and achieve *O(log(n))*.
    In order to save the cost of sorting, ideal hash tables provide the absolute best
    case for search: *O(1)*.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 搜索（或查找）是另一个我们将在[第10章](32002bad-c2bb-46e9-918d-12d7dabfe579.xhtml)“寻找东西”中探讨的主题，但相关的运行时间复杂度是很好的例子。在大多数未排序的数据结构上进行搜索将通常是*O(n)*，而排序的集合可以利用二分搜索（树的搜索策略）并实现*O(log(n))*。为了节省排序的成本，理想的哈希表提供了搜索的最佳情况：*O(1)*。
- en: Exotic things
  id: totrans-78
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 异常事物
- en: One class that was omitted from the earlier list is **polynomial time** (**P**
    in short). This class is quicker to solve than the exponential time class, but
    worse than *O(n²)*. These problems include checking whether a number is a prime
    number, or solving a Sudoku. However, there are other problems in this class as
    well that actually have *no* "quick" (that is, solvable in P) solution, but a
    solution can be verified in P time. These are called **NP** (an abbreviation of
    **non-deterministic polynomial time**) problems and the hardest of them are NP-hard
    (see the information box).
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在早期列表中省略的一个类别是**多项式时间**（简称**P**）。这个类比指数时间类更快地解决，但比*O(n²)*差。这些问题包括检查一个数是否为素数，或解决数独。然而，这个类别中还有其他问题，实际上并没有“快速”（即在P时间内可解）的解决方案，但可以在P时间内验证解决方案。这些被称为**NP**（**非确定性多项式时间**的缩写）问题，其中最困难的是NP-难（见信息框）。
- en: The distinction between P, NP, NP-complete, and NP-hard is not intuitive. NP
    problems are problems that can be solved using a non-deterministic Turing machine
    in P time. **NP-hard** problems are problems without a solution that, if solved,
    would have a polynomial time solution and if it is also an NP problem, it is also
    considered NP-complete. Additionally, finding a solution for one of either class
    (NP-hard or NP-complete) would imply a solution for *all* NP-hard/NP-complete
    problems.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: P、NP、NP-完全和NP-难之间的区别并不直观。NP问题是可以使用非确定性图灵机在P时间内解决的问题。**NP-难**问题是没有解决方案的问题，如果解决了，将会有多项式时间解决方案，如果它也是一个NP问题，那么它也被认为是NP-完全的。此外，找到其中一个类（NP-难或NP-完全）的解决方案将意味着所有NP-难/NP-完全问题的解决方案。
- en: While there are no known algorithms to solve these problems quickly, there typically
    are naive approaches that result in *very* long runtimes. Popular problems in
    this space include the traveling salesman problem (*O(n!)*), the knapsack problem
    (*O(2^n)*, and the subset sum problem (*O(2^(n/2))*), all of which are currently
    solved (or approximated) using heuristics or programming techniques. For those
    interested, check the further reading section for links.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然没有已知算法可以快速解决这些问题，但通常有一些原始方法会导致**非常**长的运行时间。这个领域中的流行问题包括旅行商问题（*O(n!)*）、背包问题（*O(2^n)*）和子集和问题（*O(2^(n/2)*)），所有这些问题目前都是通过启发式方法或编程技术来解决（或近似）的。对那些感兴趣的人来说，请查看进一步阅读部分以获取链接。
- en: Summary
  id: totrans-82
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: 'The Big O notation is a way to describe the time and space requirements of
    an algorithm (or data structure). This is not an exact science, however; it''s
    about finding the primary growth factor of each of the things mentioned to answer
    this question: what happens when the problem space grows bigger?'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 大O符号是描述算法（或数据结构）的时间和空间需求的一种方式。这并不是一门精确的科学；它关于找到所提到的事物的主要增长因子来回答这个问题：当问题空间变大时会发生什么？
- en: Any algorithm will fall within a few relevant classes that describe that behavior.
    By applying the algorithm to one more element, how many more steps have to be
    taken? One easy way is to visualize the individual charts and think of whether
    it will be linear (*O(n)*), quasilinear (*O(n log(n))*), quadratic (*O(n²)*),
    or even exponential (*O(2^n)*). Whatever the case may be, it is always best to
    do less work than there are elements to be looked at, such as constant (*O(1)*)
    or logarithmic (*O(log(n)*) behaviors!
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 任何算法都将属于几个相关的类别，这些类别描述了该行为。通过将算法应用于一个额外的元素，需要采取多少额外的步骤？一个简单的方法是可视化单个图表，并思考它是否将是线性的（*O(n)*）、准线性的（*O(n
    log(n)*）、二次的（*O(n²)*）甚至是指数的（*O(2^n)*）。无论情况如何，总是最好做的工作比要查看的元素少，例如常数（*O(1)*）或对数（*O(log(n)*）行为！
- en: Selecting the operations is typically done based on the worst-case behavior,
    that is, the upper limit of what is going to happen. In the next chapter, we will
    take a closer look at these behaviors in the cases of popular search algorithms.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 选择操作通常基于最坏的行为，即将要发生的上限。在下一章中，我们将更详细地研究这些行为在流行搜索算法中的情况。
- en: Questions
  id: totrans-86
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: Why estimate runtime complexity over, for example, number of statements?
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为什么要在例如语句数量上估计运行时间复杂度？
- en: How does runtime complexity relate to math functions?
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 运行时间复杂度如何与数学函数相关？
- en: Is the complexity class that is typically provided the best or worst case?
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通常提供的复杂度类是最好还是最坏的情况？
- en: Why are loops important in estimating complexity?
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为什么循环在估计复杂度时很重要？
- en: Is *O(n log(n))* a better or worse runtime complexity than *O(log(n))*?
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*O(n log(n))*的运行时间复杂度比*O(log(n))*更好还是更差？'
- en: What are some commonly known complexity classes?
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一些常见的复杂度类有哪些？
- en: Further reading
  id: totrans-93
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'You can refer to the following links to get more information on the topics
    covered in this chapter:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以参考以下链接，获取本章涵盖主题的更多信息：
- en: Wikipedia's list of best-, worst-, and average-case complexities ([https://en.wikipedia.org/wiki/Best,_worst_and_average_case](https://en.wikipedia.org/wiki/Best,_worst_and_average_case))
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 维基百科关于最佳、最坏和平均情况复杂性的列表 ([https://en.wikipedia.org/wiki/Best,_worst_and_average_case](https://en.wikipedia.org/wiki/Best,_worst_and_average_case))
- en: Big O Cheatsheet ([http://bigocheatsheet.com/](http://bigocheatsheet.com/))
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Big O Cheatsheet ([http://bigocheatsheet.com/](http://bigocheatsheet.com/))
- en: Heuristic algorithms at Northwestern University ([https://optimization.mccormick.northwestern.edu/index.php/Heuristic_algorithms](https://optimization.mccormick.northwestern.edu/index.php/Heuristic_algorithms))
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 西北大学的启发式算法 ([https://optimization.mccormick.northwestern.edu/index.php/Heuristic_algorithms](https://optimization.mccormick.northwestern.edu/index.php/Heuristic_algorithms))
- en: Heuristic design and optimization at MIT ([http://www.mit.edu/~moshref/Heuristics.html](http://www.mit.edu/~moshref/Heuristics.html))
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 麻省理工学院的启发式设计和优化 ([http://www.mit.edu/~moshref/Heuristics.html](http://www.mit.edu/~moshref/Heuristics.html))
- en: '*Big Omicron And Big Omega And Big Theta* by Donald Knuth ([http://www.phil.uu.nl/datastructuren/10-11/knuth_big_omicron.pdf](http://www.phil.uu.nl/datastructuren/10-11/knuth_big_omicron.pdf))'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由唐纳德·克努特所著的 *Big Omicron And Big Omega And Big Theta* ([http://www.phil.uu.nl/datastructuren/10-11/knuth_big_omicron.pdf](http://www.phil.uu.nl/datastructuren/10-11/knuth_big_omicron.pdf))
