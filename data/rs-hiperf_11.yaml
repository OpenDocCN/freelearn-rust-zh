- en: Asynchronous Programming
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 异步编程
- en: Until now, the only way we have seen to achieve concurrency in Rust is to create
    multiple threads, one way or another, to share the work. Nevertheless, those threads
    sometimes need to stop and look for something, such as a file or a network response.
    In those cases, the whole thread will be blocked and it will need to wait for
    the response.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们在 Rust 中实现并发的方式只有创建多个线程，无论哪种方式，都是为了分担工作。然而，这些线程有时需要停下来寻找某些东西，比如文件或网络响应。在这些情况下，整个线程将会被阻塞，并需要等待响应。
- en: This means that if we want to achieve a low latency for things such as an HTTP
    server, one way to do it is by spawning one thread per request, so that each request
    can be served as quickly as possible even if others block.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着，如果我们想为像 HTTP 服务器这样的东西实现低延迟，一种方法是为每个请求创建一个线程，这样每个请求都可以尽可能快地被服务，即使其他请求被阻塞。
- en: As we have seen, spawning hundreds of threads is not scalable, since each thread
    will have its own memory and will consume resources even if it's blocked. In this
    chapter, you will learn a new way of doing things by using asynchronous programming.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所看到的，创建数百个线程是不可扩展的，因为每个线程都将有自己的内存，即使在阻塞的情况下也会消耗资源。在本章中，你将通过使用异步编程学习一种新的做事方式。
- en: 'In this chapter, you will learn about the following:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你将学习以下内容：
- en: Asynchronous primitives with `mio`
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 `mio` 的异步原语
- en: Using `futures`
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 `futures`
- en: The new `async`/`await` syntax and generators
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 新的 `async`/`await` 语法和生成器
- en: Asynchronous I/O with `tokio` and `websockets`
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 `tokio` 和 `websockets` 进行异步 I/O
- en: Introduction to asynchronous programming
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 异步编程简介
- en: If you want to achieve high performance in computing, you will need to run tasks
    concurrently. Whether you are running complex computations that take days, such
    as machine learning training, or you are running a web server that needs to respond
    to thousands of requests per second, you will need to do more than one thing at
    the same time.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想在计算中实现高性能，你需要并发运行任务。无论你是运行需要几天时间才能完成的复杂计算，比如机器学习训练，还是运行需要每秒响应数千个请求的 Web
    服务器，你都需要同时做很多事情。
- en: Thankfully, as we have already seen, our processors and operating systems are
    prepared for concurrency, and in fact, multithreading is a great way to achieve
    it. The main issue is that as we saw in the previous chapter, we should not be
    using more threads than logical CPUs in our computer.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，正如我们之前所看到的，我们的处理器和操作系统已经为并发做好了准备，实际上，多线程是实现并发的绝佳方式。主要问题是，正如我们在上一章中看到的，我们不应该在我们的计算机中使用比逻辑
    CPU 更多的线程。
- en: We can, of course, but some threads will be waiting for others to execute, and
    the kernel will be orchestrating how much time each thread gets in the CPU. This
    will consume even more resources and make the overall process slower. It can sometimes
    be useful, though, to have more threads than the number of cores. Maybe some of
    them only wake up once every few seconds to do small tasks, or we know that most
    of them will block due to some I/O operation.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 我们当然可以，但一些线程将等待其他线程执行，内核将协调每个线程在 CPU 中获得多少时间。这将消耗更多资源，并使整个过程变慢。尽管如此，有时拥有比核心数量更多的线程可能是有用的。也许其中一些每几秒钟才会醒来执行小任务，或者我们知道它们中的大多数会因为某些
    I/O 操作而阻塞。
- en: When a thread blocks, the execution stops. No further instruction will run in
    the CPU until it gets unblocked. This can happen when we read a file, for example.
    Until the reading ends, no further instruction will be executed. This of course,
    depends on how we read the file.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 当一个线程阻塞时，执行将停止。直到它被解除阻塞，CPU 不会运行任何进一步的指令。例如，当我们读取文件时，这可能会发生。当然，这取决于我们如何读取文件。
- en: But in the latter case, instead of creating more threads we can do better—asynchronous
    programming. When programming asynchronously, we let the code continue being executed
    while we are still waiting for a certain result. That will avoid blocking the
    thread and let you use less threads for the same task, while still being concurrent.
    You can also use asynchronous programming for tasks not related to I/O, but if
    they are CPU bound (their bottleneck is the CPU), you won't get speed improvements,
    since the CPU will always be running at its best. To learn how asynchronous I/O
    works in Rust, let's first dive into how the CPU handles I/O.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 但在后一种情况下，我们不必创建更多的线程，而可以做得更好——使用异步编程。在异步编程时，我们让代码在等待某个结果的同时继续执行。这样就可以避免阻塞线程，让你在完成相同任务的同时使用更少的线程，同时保持并发。你也可以为与I/O无关的任务使用异步编程，但如果它们是CPU密集型的（瓶颈在CPU上），你不会获得速度上的提升，因为CPU总是以最佳状态运行。要了解Rust中异步I/O是如何工作的，让我们首先深入了解CPU是如何处理I/O的。
- en: Understanding I/O in the CPU
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解CPU中的I/O
- en: The `std::io` module in Rust handles all input/output operations. These operations
    can vary from keyboard/mouse input to reading a file, or from using TCP/IP sockets
    to command-line utilities (`stdio`/`stderr`). But how does it work internally?
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: Rust中的`std::io`模块处理所有输入/输出操作。这些操作可能包括键盘/鼠标输入、读取文件，或者使用TCP/IP套接字到命令行工具（`stdio`/`stderr`）。但它是如何内部工作的呢？
- en: Instead of understanding how the Rust standard library does it, we will dig
    some levels deeper to understand how it works at CPU level. We will later go back
    to see how the kernel provides this functionality to Rust. This will be based
    mostly in the x86_64 platform and Linux kernel, but other platforms handle these
    things similarly.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不会深入理解Rust标准库是如何实现的，而是要深入到CPU级别来理解它是如何工作的。我们稍后会回到如何通过内核将此功能提供给Rust。这主要基于x86_64平台和Linux内核，但其他平台处理这些事情的方式类似。
- en: 'There are two main types of I/O architecture: channel-based I/O and memory-mapped
    I/O. Channel-based I/O is really niche and is not used in modern PCs or most servers.
    In CPU architectures such as x86/x86_64 (most modern day Intel and AMD CPUs),
    memory-mapped I/O is used. But what does it mean?'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: I/O架构主要有两种类型：基于通道的I/O和内存映射I/O。基于通道的I/O非常小众，在现代PC或大多数服务器上并不使用。在x86/x86_64（大多数现代的Intel和AMD
    CPU）这样的CPU架构中，使用的是内存映射I/O。但这是什么意思呢？
- en: As you should know by now, the CPU gets all the required information for its
    work from the RAM memory. As we saw in previous chapters, this information will
    later be cached in the CPU cache, and it won't be used until it gets to the CPU
    registers, but this is not so relevant for now. So, if the CPU wants to get information
    about what key was pressed on the keyboard, or what TCP frames the website you
    are visiting is sending, it needs to either have some extra hardware channel to
    those input/output interfaces, or those interfaces have to change something in
    the RAM.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所知，CPU从RAM内存中获取所有工作所需的信息。正如我们在前面的章节中看到的，这些信息最终会被缓存到CPU缓存中，直到它们到达CPU寄存器才会被使用，但这对现在来说并不那么重要。因此，如果CPU想要获取有关键盘上按下的哪个键或你访问的网站正在发送的TCP帧的信息，它需要要么有一些额外的硬件通道到这些输入/输出接口，要么这些接口需要在RAM中做出一些改变。
- en: The first option is the channel-based I/O. CPUs that use channel-based I/O have
    dedicated channels and hardware for I/O operations. This usually increases the
    price of the CPUs a lot. On the other hand, in memory-mapped I/O the second option
    gets used—the memory gets somehow modified when an I/O operation happens.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 第一种选择是基于通道的I/O。使用基于通道的I/O的CPU有专门的通道和硬件用于I/O操作。这通常会使CPU的价格大幅增加。另一方面，在内存映射I/O中，使用的是第二种选择——当发生I/O操作时，内存会以某种方式被修改。
- en: Here, we have to pause a little bit to understand this better. Even though we
    may think that all our memory is in our RAM sticks, it's not exactly like that.
    Memory is divided into virtual and physical memory. Each program has one virtual
    memory address available for each addressable byte with the size of a CPU word.
    This means that a 32-bit CPU will have 2^(32) virtual memory addresses available
    for each of its programs and a 64-bit CPU will have 2^(64) addresses. This would
    mean having 4 GiB of RAM in the case of 32-bit computers and 16 EiB of RAM in
    the case of a 64-bit CPU. **EiBs** are **exbibytes**, or 1,014 **PiB** (**pebibytes**).
    Each PiB is 1024 **GiB** (**gibibytes**). Remember that gibibytes are the two-power
    version of **gigabytes** (**GB**). And all of this is true for each of the processes
    in the CPU.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们需要稍微停顿一下，更好地理解这一点。尽管我们可能认为所有的内存都在我们的RAM条上，但事实并非如此。内存被分为虚拟内存和物理内存。每个程序都有一个虚拟内存地址，用于每个可寻址的字节，其大小与CPU字的大小相同。这意味着32位CPU将为每个程序提供2^(32)个虚拟内存地址，64位CPU将提供2^(64)个地址。这意味着32位计算机将有4
    GiB的RAM，而64位CPU将有16 EiB的RAM。**EiBs**是**exbibytes**，或1,014 **PiB**（**pebibytes**）。每个PiB是1024
    **GiB**（**gibibytes**）。记住，gibibytes是**gigabytes**（**GB**）的两进制版本。所有这些对CPU中的每个进程都适用。
- en: There are some issues with this. First, if we have two processes, we would need
    double the amount of memory, right? But the kernel can only address that amount
    of memory (it's a process itself). So we need **translation tables** (**TLBs**),
    that tell each process where their memory is. But even though we may have 4 GiB
    of RAM for 32-bit CPUs, we don't have 16 EiB of RAM anywhere. Not only that, 32-bit
    CPUs have existed long before we were able to create PCs with 4 GiB of RAM. How
    can a process address more RAM than what we have installed?
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 这个问题有一些问题。首先，如果我们有两个进程，我们需要双倍的内存，对吧？但是内核只能处理那么多的内存（它本身就是一个进程）。所以我们需要**转换表**（**TLBs**），告诉每个进程它们的内存在哪里。但是尽管我们可能为32位CPU配备了4
    GiB的RAM，我们并没有16 EiB的RAM。不仅如此，32位CPU在我们能够制造出4 GiB RAM的PC之前就已经存在了。一个进程如何能够访问比我们安装的内存更多的RAM呢？
- en: The solution is simple—we call that address space the virtual memory space,
    and the real RAM the physical memory space. If a process requires more memory
    than the available physical memory, two things can happen—either our kernel can
    move some memory addresses out of RAM into the disk and allocate some more RAM
    for this process, or it will receive an out-of-memory error. The first option
    is called page swapping, and it's really common in Unix systems, where you sometimes
    even decide how much space in the disk you want to provide for that.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 解决方案很简单——我们将这个地址空间称为虚拟内存空间，而真正的RAM称为物理内存空间。如果一个进程需要的内存比可用的物理内存多，可能会发生两件事——要么我们的内核可以将一些内存地址从RAM移动到磁盘，并为这个进程分配更多的RAM，要么它将收到一个内存不足的错误。第一种选择被称为页面交换，这在Unix系统中非常常见，有时你甚至可以决定为它提供多少磁盘空间。
- en: Moving information from the RAM to the disk will slow things down a lot, since
    the disk itself is really slow compared to the RAM (even modern day SSDs are much
    slower than RAM). Nevertheless, here we find that there is some I/O happening
    to swap that memory information to the disk, right? How does that happen?
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 将信息从RAM移动到磁盘会大大减慢速度，因为与RAM相比，磁盘本身非常慢（即使是现代的SSD也比RAM慢得多）。尽管如此，我们在这里发现，确实有一些I/O操作将内存信息交换到磁盘，对吧？这是如何发生的？
- en: Well, we said that the virtual memory space was specific for each process, and
    we said that the kernel was another process. This means that the kernel also has
    the whole memory space available for it to use. This is where memory-mapped I/O
    comes in. The CPU will decide to map new devices to some addresses. This means
    that the kernel will be able to read information about the I/O interface just
    by reading some concrete positions in its virtual address space.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 好吧，我们说过虚拟内存空间是针对每个进程的，我们也说过内核是另一个进程。这意味着内核也有整个内存空间可供使用。这就是内存映射I/O出现的地方。CPU将决定将新的设备映射到某些地址。这意味着内核只需读取其虚拟地址空间中的某些具体位置，就能读取有关I/O接口的信息。
- en: In this regard, there are some variants as to how to read that information.
    Two main ways exist—port-mapped I/O and direct memory access or DMA. Port-mapped
    I/O is used, of course, for TCP/IP, serial, and other kinds of peripheral communication.
    It will have some certain addresses allocated to it. These addresses will be a
    buffer, which means that as the input comes, it will write one by one the next
    memory address. Once it gets to the end, it will start from the beginning again,
    so the kernel has to be fast enough to read the information before it gets rewritten.
    It can also block the port, stopping the communication.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在这方面，关于如何读取这些信息有一些变体。主要有两种方式——端口映射I/O和直接内存访问或DMA。端口映射I/O当然用于TCP/IP、串行和其他类型的外围通信。它将分配一些特定的地址给它。这些地址将是一个缓冲区，这意味着当输入到来时，它将逐个写入下一个内存地址。一旦到达末尾，它将重新从开始，因此内核必须足够快，以便在信息被重写之前读取信息。它还可以阻塞端口，停止通信。
- en: In the case of DMA, the memory space of the device will be directly mapped in
    the virtual memory. This enables accessing that memory as if it were part of the
    virtual address space of the current PC. Which approach is used depends on the
    task and the device we want to communicate with. You may now be wondering how
    the kernel handles all this for your programs.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在DMA的情况下，设备的内存空间将直接映射到虚拟内存中。这使得我们可以像访问当前PC的虚拟地址空间的一部分那样访问该内存。所采用的方法取决于任务和我们要与之通信的设备。你现在可能想知道内核是如何为你的程序处理所有这些的。
- en: Getting the kernel to control the I/O
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 控制内核的I/O
- en: When a new TCP/IP connection gets established, or when a new key is pressed
    on the keyboard, the kernel must know about it so that it can act accordingly.
    There are two ways of doing this—the kernel could be looking to those ports or
    memory addresses once and again to look for changes, which would make the CPU
    work for nothing most of the time, or the kernel could be notified by a CPU interrupt.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 当一个新的TCP/IP连接建立，或者当键盘上按下新的键时，内核必须知道这一点，以便它可以相应地采取行动。有两种方法可以做到这一点——内核可以一次又一次地查看那些端口或内存地址以寻找变化，这会使CPU大部分时间都在做无用功，或者内核可以通过CPU中断来通知。
- en: As you can imagine, most kernels decide to go for the second option. They are
    idle, letting other processes use the CPU until there's a change in some I/O port
    or address. This makes the CPU interrupt at a hardware level, and gives control
    to the kernel. The kernel will check what happened and decide accordingly. If
    there is some process waiting for that interrupt, it will wake that process and
    let it know that there is some new information for it.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所想，大多数内核决定选择第二种方案。它们是空闲的，让其他进程使用CPU，直到某个I/O端口或地址发生变化。这使得CPU在硬件级别中断，并将控制权交给内核。内核将检查发生了什么，并相应地决定。如果有进程正在等待那个中断，它将唤醒那个进程，并让它知道有一些新信息供它处理。
- en: It may be, though, that the process waiting for the information is already awake.
    This happens in asynchronous programming. The process will keep on performing
    some computations while it's still waiting for the I/O transaction. In this case,
    the process will have registered some callback function in the kernel, so that
    the kernel knows what to call once the I/O operation is ready.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，等待信息的进程可能已经唤醒了。这种情况发生在异步编程中。当进程仍在等待I/O事务时，它将继续执行一些计算。在这种情况下，进程将在内核中注册一些回调函数，以便内核知道一旦I/O操作准备好后应该调用什么。
- en: This means that while the I/O operation was being performed, the process was
    doing useful things, instead of being blocked and waiting for the kernel to return
    the result of the I/O operation. This enables you to use the CPU almost all the
    time, without pausing the execution, making your code perform better.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着在I/O操作执行期间，进程正在做有用的事情，而不是被阻塞并等待内核返回I/O操作的结果。这使得你几乎可以始终使用CPU，而无需暂停执行，从而使你的代码性能更佳。
- en: Asynchronous programming from the programmer's perspective
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从程序员的角度看异步编程
- en: Until now, we have seen how I/O works from a hardware and software perspective.
    We mentioned that it is possible to have our process working while waiting for
    the I/O, but how do we do it?
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经从硬件和软件的角度了解了I/O的工作原理。我们提到，在等待I/O的同时，我们的进程可以继续工作，但我们应该如何实现呢？
- en: The kernel has some things to help us with this. In the case of Linux, it has
    the `epoll()` system call, which lets the kernel know that our code wants to receive
    some information from an I/O interface, but that it doesn't need to lock itself
    until the information is available. The kernel will know what callback to run
    when the information is ready, and meanwhile, our program can do a lot of computations.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 内核有一些东西可以帮助我们完成这项工作。在Linux的情况下，它有`epoll()`系统调用，它让内核知道我们的代码想要从I/O接口接收一些信息，但不需要锁定自己直到信息可用。内核将知道当信息准备好时应该运行哪个回调，同时，我们的程序可以执行大量的计算。
- en: This is very useful, for example, if we are processing some data and we know
    that in the future we will need some information from a file. We can ask the kernel
    to get the information from the file while we continue the computation, and as
    soon as we need the information from the file, we won't need to wait for the file
    reading operation—the information will just be there. This reduces the disk read
    latency a lot, since it will be almost as fast as reading from the RAM instead
    of the disk.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 这非常有用，例如，如果我们正在处理一些数据，并且我们知道将来我们需要从文件中获取一些信息。我们可以要求内核在我们继续计算的同时从文件中获取信息，一旦我们需要从文件中获取信息，我们就不需要等待文件读取操作——信息就会在那里。这大大减少了磁盘读取延迟，因为它几乎和从RAM中读取一样快，而不是从磁盘读取。
- en: We can use this approach for TCP/IP connections, serial connections, and, in
    general, anything that requires I/O access. This `epoll()` system call comes directly
    from the Linux C API, but in Rust we have great wrappers that make all of this
    much easier without overhead. Let's check them out.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '我们可以使用这种方法来处理TCP/IP连接、串行连接，以及一般需要I/O访问的任何东西。这个`epoll()`系统调用直接来自Linux C API，但在Rust中，我们有很好的封装器，使得所有这些操作都变得容易，而且没有开销。让我们来看看它们。 '
- en: Understanding futures
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解未来
- en: If we use the `std::io::Read` and `std::io::Write` traits in our code, we will
    be able to easily read and write data from I/O interfaces, but every time we do
    it, the thread doing the call will block until the data is received. Luckily,
    the great crate ecosystem Rust has brings us great opportunities to improve this
    situation.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们在代码中使用`std::io::Read`和`std::io::Write`特性，我们将能够轻松地从I/O接口读取和写入数据，但每次我们这样做时，执行调用的线程都会阻塞，直到数据接收完成。幸运的是，Rust的优秀的crate生态系统为我们带来了改善这种情况的绝佳机会。
- en: In many programming languages, you can find the concept of *not yet available
    data*. In JavaScript, for example, they are called promises, and in Rust, we call
    them futures. A future represents any data that will be available at some point
    in the future but may not be available yet. You can check whether a future has
    a value at any time, and get it if it does. If not, you can either perform some
    computation in the meantime or block the current thread until the value gets there.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多编程语言中，你可以找到“尚未可用数据”的概念。例如，在JavaScript中，它们被称为promises，而在Rust中，我们称它们为futures。Future表示将来某个时刻将可用的任何数据，但目前可能尚未可用。你可以在任何时间检查future是否有值，如果有，就可以获取它。如果没有，你可以在其间执行一些计算，或者阻塞当前线程，直到值到达。
- en: Rust futures not only give us this feature, but they even give us tons of helpful
    APIs that we can use to improve the readability and reduce the amount of code
    written. The `futures` crate does all this with *zero-cost* abstractions. This
    means that it will not require extra allocations and the code will be as close
    as possible to the best assembly code you could write to make all this possible.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: Rust的futures不仅为我们提供了这个特性，而且还提供了大量的有用API，我们可以使用它们来提高代码的可读性并减少代码量。`futures` crate通过零成本抽象来实现这一切。这意味着它不会需要额外的分配，代码将尽可能接近你为了实现所有这些功能所能编写的最佳汇编代码。
- en: 'Futures not only work for I/O; they can be used with any kind of computation
    or data. We will be using the 0.2.x version of the futures crate in these examples.
    At the time of writing, that version is still in the alpha development phase,
    but it''s expected to be released really soon. Let''s see an example of how futures
    work. We will first need to add the `futures` crate as a dependency in the `Cargo.toml`
    file, and then we can start writing some code in the `main.rs` file of our project:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: Futures不仅适用于I/O，还可以与任何类型的计算或数据一起使用。在这些示例中，我们将使用futures crate的0.2.x版本。在撰写本文时，该版本仍在alpha开发阶段，但预计很快就会发布。让我们看看futures是如何工作的。我们首先需要在`Cargo.toml`文件中将`futures`
    crate添加为依赖项，然后我们就可以在我们的项目的`main.rs`文件中开始编写一些代码：
- en: '[PRE0]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: In this example, we have a simulated complex computation that takes around 5
    seconds. This computation returns a `Future`, and we can therefore use useful
    methods to modify the result once it gets generated. These methods come from the
    `FutureExt` trait.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们有一个模拟的复杂计算，大约需要5秒钟。这个计算返回一个`Future`，因此我们可以使用有用的方法在结果生成后修改它。这些方法来自`FutureExt`特性。
- en: Then, the `block_on()` function will wait until the given future is no longer
    pending. You may think that this is exactly the same as when we were working with
    threads, but the interesting thing is that we are only using one thread here.
    The future will be computed once the main thread has some spare time, or when
    we call the `block_on()` function.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，`block_on()`函数将等待直到给定的未来不再挂起。您可能会认为这和我们在使用线程时完全一样，但有趣的是，我们这里只使用了一个线程。未来将在主线程有额外时间或我们调用`block_on()`函数时被计算。
- en: This, of course, does not make much sense for computationally intense applications,
    since we will in any case have to do the computation in the main thread, but it
    makes a lot of sense for I/O access. We can think of a `Future` as the asynchronous
    version of a `Result`.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，对于计算密集型应用程序来说，这并没有太多意义，因为我们无论如何都不得不在主线程中进行计算，但对于I/O访问来说，这非常有意义。我们可以将`Future`视为`Result`的异步版本。
- en: As you can see in the `FutureExt` trait documentation at [https://docs.rs/futures/0.2.0-alpha/futures/trait.FutureExt.html](https://docs.rs/futures/0.2.0-alpha/futures/trait.FutureExt.html),
    we have tons of combinators to use. In this case, we used the `map()` method,
    but we can also use other methods such as `and_then()`, `map_err()`, `or_else()`,
    or even joins between futures. All these methods will run asynchronously one after
    the other. Once you call the `block_on()` function, you will get the `Result`
    of the final future.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 如您在[https://docs.rs/futures/0.2.0-alpha/futures/trait.FutureExt.html](https://docs.rs/futures/0.2.0-alpha/futures/trait.FutureExt.html)的`FutureExt`特性文档中所见，我们有许多组合器可以使用。在这种情况下，我们使用了`map()`方法，但也可以使用其他方法，例如`and_then()`、`map_err()`、`or_else()`，甚至是在未来之间的连接。所有这些方法都会依次异步运行。一旦您调用`block_on()`函数，您将得到最终未来的`Result`。
- en: Future combinators
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 未来组合器
- en: And now that we mentioned joins, it is actually possible to have two co-dependent
    futures. Maybe we have information from two files, we generate one future reading
    from each file, and then we want to combine the information from them. We don't
    need to block the thread for that; we can use the `join()` method, and the logic
    behind it will make sure that once the closure we write gets called, both futures
    will have received the final value.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们提到了连接，实际上是有可能存在两个相互依赖的未来。也许我们有两个文件的信息，我们为每个文件生成一个读取未来的操作，然后我们想要结合它们的信息。我们不需要阻塞线程来做这件事；我们可以使用`join()`方法，它背后的逻辑将确保一旦我们编写的闭包被调用，两个未来都将接收到最终值。
- en: This is really useful when creating concurrency dependency graphs. If you have
    many small computations that you want to parallelise, you can create a closure
    or a function for each of the parts, and then use `join()` and other methods,
    such as `and_then()`, to decide which computations need to run some of them in
    parallel while still receiving all the required data for each step. The `join()`
    method comes in five variants depending on how many futures you need for your
    next computation.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 这在创建并发依赖图时非常有用。如果您有很多小计算想要并行化，您可以为每个部分创建一个闭包或函数，然后使用`join()`和其他方法，例如`and_then()`，来决定哪些计算需要并行运行，同时仍然接收每个步骤所需的所有数据。`join()`方法有五种变体，取决于您下一次计算需要多少个未来。
- en: But simple futures is not the only thing this crate gives us. We can also use
    the `Stream` trait, which works similarly to the `Iterator` trait, but asynchronously.
    This is extremely useful for inputs that come one by one and are not just a one-time
    value. This happens with TCP, serial, or any connection that uses byte streams,
    for example.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 但简单的未来并不是这个crate给我们提供的唯一东西。我们还可以使用`Stream`特性，它的工作方式类似于`Iterator`特性，但异步。这对于逐个到来且不仅仅是单次值输入的情况非常有用。例如，这发生在TCP、串行或任何使用字节流的连接中。
- en: With this trait, and especially with the `StreamExt` trait, we have almost the
    same API as with iterators, and we can create a complete iterator that can, for
    example, retrieve HTTP data from a TCP connection byte by byte and asynchronously.
    This has many applications in web servers, and we have already seen crates in
    the community migrating to asynchronous APIs.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这个特质，尤其是使用`StreamExt`特质，我们几乎有与迭代器相同的API，我们可以创建一个完整的迭代器，例如，可以逐字节异步地从TCP连接中检索HTTP数据。这在Web服务器中有许多应用，我们已经在社区中看到了迁移到异步API的crate。
- en: The crate also offers an asynchronous version of the `Write` trait. With the
    `Sink` and the `SinkExt` traits you can send data to any output object. This could
    be a file, a connection, or even some kind of streaming computation. `Sink` and
    `Stream` work great together, since the `send_all()` method in the `SinkExt` trait
    lets you send a whole `Stream` to the `Sink`. You could, for example, asynchronously
    read a file byte by byte, do some computation for each of them or in chunks, and
    then write the result in another file just by using these combinators.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 这个crate还提供了一个`Write`特质的异步版本。通过`Sink`和`SinkExt`特质，你可以向任何输出对象发送数据。这可能是一个文件、一个连接，甚至是一种流计算。`Sink`和`Stream`配合得很好，因为`SinkExt`特质中的`send_all()`方法允许你将整个`Stream`发送到`Sink`。例如，你可以异步地逐字节读取文件，对每个字节或块进行一些计算，然后只需使用这些组合器将这些结果写入另一个文件。
- en: 'Let''s see an example. We will be using the `futures-timer` crate, and unfortunately
    it''s not yet available for futures 0.2.0\. So, let''s update our `Cargo.toml`
    file with the following `[dependencies]` section:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看一个例子。我们将使用`futures-timer` crate，不幸的是它目前还不适用于futures 0.2.0。所以，让我们用以下`[dependencies]`部分更新我们的`Cargo.toml`文件：
- en: '[PRE1]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Then, let''s write the following code in our `main.rs` file:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，让我们在我们的`main.rs`文件中编写以下代码：
- en: '[PRE2]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: If you execute cargo run for this example, it will generate five new lines with
    the `New interval` text, one every second. The Interval just returns a `()` every
    time the configured interval times out. We then only take the first five and run
    the closure inside the `for_each` loop. As you can see, the `Stream` and `StreamExt`
    traits works almost the same way as the `Iterator` trait.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你为这个示例执行cargo run，它将生成五条新的`New interval`文本行，每秒一条。Interval每次配置的间隔超时时都会返回一个`()`。然后我们只取前五个，并在`for_each`循环中运行闭包。正如你所看到的，`Stream`和`StreamExt`特质几乎与`Iterator`特质以相同的方式工作。
- en: Asynchronous I/O in Rust
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Rust中的异步I/O
- en: When it comes to I/O operations, there is a go-to crate. It's called `tokio`,
    and it handles asynchronous input and output operations seamlessly. This crate
    is based in MIO. MIO, from Metal IO, is a base crate that provides a really low-level
    interface to asynchronous programming. It generates an event queue, and you can
    use a loop to gather all the events one by one, asynchronously.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 当涉及到I/O操作时，有一个首选的crate。它被称为`tokio`，它可以无缝地处理异步输入和输出操作。这个crate基于MIO。MIO，即Metal
    IO，是一个基础crate，它提供了一个非常底层的异步编程接口。它生成一个事件队列，你可以使用循环逐个收集所有事件，异步地。
- en: As we saw earlier, these events can be anything from *a TCP message was received* to
    *the file you requested is partially ready*. There are tutorials to create small
    TCP servers in MIO, for example, but the idea of MIO is not using the crate directly,
    but using a facade. The most known and useful facade is the `tokio` crate. This
    crate, by itself, only gives you some small primitives, but it opens the doors
    to many asynchronous interfaces. You have, for example, `tokio-serial`, `tokio-jsonrpc`,
    `tokio-http2`, `tokio-imap`, and many, many more.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们之前所见，这些事件可以是任何东西，从*接收到的TCP消息*到*你请求的文件部分准备好*。MIO中有创建小型TCP服务器的教程，例如，但MIO的理念不是直接使用crate，而是使用一个外观。最知名且最有用的外观是`tokio`
    crate。这个crate本身只提供了一些小的原语，但它打开了通往许多异步接口的大门。例如，你有`tokio-serial`、`tokio-jsonrpc`、`tokio-http2`、`tokio-imap`以及许多许多更多。
- en: Not only that, you have also utilities such as `tokio-retry` that will automatically
    retry the I/O operation if an error happens. Tokio is really easy to use, it has
    an extremely low footprint, and it enables you to create incredibly fast services
    with its asynchronous operations. As you probably have already noticed, it is
    mostly centred around communication. This is due to all the helpers and capabilities
    it provides for these cases. The core crate also has file reading capabilities,
    so you should be covered for any I/O-bound operation, as we will see.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 不仅如此，你还有像 `tokio-retry` 这样的实用工具，如果发生错误，它会自动重试 I/O 操作。Tokio 非常容易使用，它具有极低的内存占用，并且通过其异步操作，你可以创建出极快的服务。正如你可能已经注意到的，它主要围绕通信展开。这是由于它为这些情况提供了所有这些辅助功能和能力。核心包也具有文件读取功能，因此对于任何
    I/O 密集型操作，你应该已经有所覆盖，正如我们将看到的。
- en: 'We will see first how to develop a small TCP echo server using Tokio. You can
    find similar tutorials on the Tokio website ([https://tokio.rs/](https://tokio.rs/)),
    and it is worthwhile to follow all of them. Let''s therefore start by adding `tokio`
    as a dependency to the `Cargo.toml` file. Then, we will use the `TcpListener`
    from the `tokio` crate to create a small server. This structure binds a TCP socket
    listener to a given address, and it will asynchronously execute a given function
    for each of the incoming connections. In that function, we will asynchronously
    read any potential data that we could find in the socket and return it, doing
    an `echo`. Let''s see what it looks like:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先将看到如何使用 Tokio 开发一个小型的 TCP 回显服务器。你可以在 Tokio 网站上找到类似的教程（[https://tokio.rs/](https://tokio.rs/)），并且值得跟随所有的教程。因此，让我们首先将
    `tokio` 添加为 `Cargo.toml` 文件中的依赖项。然后，我们将使用 `tokio` 包中的 `TcpListener` 来创建一个小型服务器。这个结构将
    TCP 套接字监听器绑定到指定的地址，并且它将为每个传入的连接异步执行一个给定的函数。在这个函数中，我们将异步读取套接字中可能存在的任何数据并将其返回，执行一个
    `echo`。让我们看看它是什么样子：
- en: '[PRE3]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Let's analyze the code. The listener creates an asynchronous stream of incoming
    connections with the `incoming()` method. For each of them, we check whether it
    was an error and print a message accordingly, and then, for the correct ones,
    we get the socket and get a writer and a reader by using the `split()` method.
    Then, Tokio gives us a `Copy` future that gets created with the `tokio::io::copy()`
    function. This future represents data that gets copied from a reader to a writer
    asynchronously.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们分析一下代码。监听器使用 `incoming()` 方法创建一个异步的传入连接流。对于每一个，我们检查它是否是一个错误，并相应地打印一条消息，然后，对于正确的连接，我们通过使用
    `split()` 方法获取套接字，并获取一个写入器和读取器。然后，Tokio 给我们一个由 `tokio::io::copy()` 函数创建的 `Copy`
    未来。这个未来表示异步地从读取器复制到写入器的数据。
- en: We could have written that future ourselves by using the `AsyncRead` and `AsyncWrite`
    traits, but it's great to see that Tokio already has that example future. Since
    the behavior we want is to return back whatever the connection was sending, this
    will work perfectly. We then add some extra code that will be executed after the
    reader returns **End of File** or **EOF** (when the connection gets closed). It
    will just print the number of bytes that were copied, and it will handle any potential
    errors that may appear.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用 `AsyncRead` 和 `AsyncWrite` 特性自己编写这个未来，但看到 Tokio 已经有了这个示例未来是非常好的。由于我们想要的行为是返回连接发送的任何内容，这将完美地工作。然后，我们添加了一些额外的代码，这些代码将在读取器返回
    **End of File** 或 **EOF**（当连接关闭时）后执行。它将打印复制的字节数，并处理可能出现的任何潜在错误。
- en: Then, in order for the future to perform its task, something needs to execute
    it. This is where Tokio executors come in—we call `tokio::spawn()`, which will
    execute the future in the default executor. What we just created is a stream of
    things to do when a connection comes, but we now need to actually run the code.
    For that, Tokio has the `tokio::run()` function, which starts the whole Tokio
    runtime process and starts accepting connections.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，为了使未来能够执行其任务，需要有一些东西来执行它。这就是 Tokio 执行器的用武之地——我们调用 `tokio::spawn()`，它将在默认执行器中执行未来。我们刚刚创建了一个在连接到来时要做的事情的流，但现在我们需要实际运行代码。为此，Tokio
    有 `tokio::run()` 函数，它启动整个 Tokio 运行时进程并开始接受连接。
- en: The main future we created, the stream of incoming connections, will be executed
    at that point and will block the main thread. Since the server is always waiting
    for new connections, it will just block indefinitely. Still, this does not mean
    that the execution of the futures is synchronous. The thread will go idle without
    consuming CPU, and when a connection comes, the thread will be awakened and the
    future executed. In the future itself, while sending the received data back, it
    will not block the execution if there is no more data. This enables the running
    of many connections in only one thread. In a production environment, you will
    probably want to have similar behavior in multiple threads, so that each thread
    can handle multiple connections.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 我们创建的主要未来，即传入连接的流，将在那个点执行并将阻塞主线程。由于服务器始终在等待新的连接，它将无限期地阻塞。尽管如此，这并不意味着未来的执行是同步的。线程将空闲下来而不消耗
    CPU，当连接到来时，线程将被唤醒并执行未来。在未来的本身，在发送接收到的数据回传时，如果没有更多数据，它将不会阻塞执行。这使在一个线程中运行多个连接成为可能。在生产环境中，你可能希望在多个线程中拥有类似的行为，这样每个线程就可以处理多个连接。
- en: It's now time to test it. You can start the server by running `cargo run` and
    you can connect to it with a TCP tool such as Telnet. In the case of Telnet, it
    buffers the sent data line by line, so you will need to send a whole line to receive
    the echo back. There is another area where Tokio is especially useful—parsing
    frames. If you want to create your own communication protocol, for example, you
    may want to get chunks of those TCP bytes as frames, and then convert them to
    your type of data.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是时候测试它了。你可以通过运行 `cargo run` 来启动服务器，并且可以使用如 Telnet 这样的 TCP 工具来连接它。在 Telnet
    的情况下，它会逐行缓冲发送的数据，因此你需要发送一整行才能接收到回显。Tokio 在另一个领域特别有用——解析帧。如果你想创建自己的通信协议，例如，你可能希望将那些
    TCP 字节分成帧，然后将它们转换为你的数据类型。
- en: Creating Tokio codecs
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建 Tokio 编解码器
- en: 'In Tokio, we have the concept of a codec. A codec is a type that divides a
    slice of bytes into frames. Each frame will contain certain information parsed
    from the stream of bytes. In our case, we will read the input of the TCP connection
    and divide it into chunks each time we find the `a` letter. A production-ready
    codec will probably be more complex, but this example will give us a good enough
    base to implement our own codecs. We will need to implement two traits from the
    `tokio-io` crate, so we will need to add it to the `[dependencies]` section of
    our `Cargo.toml` file and import it with `extern crate tokio_io;`. We will need
    to do the same with the `bytes` crate. Now, let''s start writing the code:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Tokio 中，我们有编解码器的概念。编解码器是一种类型，它将字节数组分割成帧。每个帧将包含从字节数据流中解析出的某些信息。在我们的例子中，我们将读取
    TCP 连接的输入，并在找到字母 `a` 时将其分割成块。一个生产就绪的编解码器可能更复杂，但这个例子将为我们提供一个足够好的基础来实现自己的编解码器。我们需要实现
    `tokio-io` crate 中的两个特性，因此我们需要将其添加到 `Cargo.toml` 文件的 `[dependencies]` 部分并使用 `extern
    crate tokio_io;` 来导入它。我们还需要对 `bytes` crate 做同样的事情。现在，让我们开始编写代码：
- en: '[PRE4]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: This is a lot of code; let's analyse it carefully. We created a structure, named
    `ADividerCodec`, and we implemented the `Decode` trait for it. This code has two
    methods. The first and most important one is the `decode()` method. It receives
    a buffer containing data coming from the connection and it needs to return either
    some data or none. In this case, it will try to find the position of the `a` letter,
    in lower case. If it finds it, it will return all the bytes that were read until
    then. It also removes new lines, just to make the printing more clear.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码有很多；让我们仔细分析一下。我们创建了一个结构，命名为 `ADividerCodec`，并为它实现了 `Decode` 特性。这段代码有两个方法。第一个也是最重要的方法是
    `decode()` 方法。它接收一个包含来自连接的数据的缓冲区，并需要返回一些数据或没有数据。在这种情况下，它将尝试找到小写字母 `a` 的位置。如果找到了，它将返回读取到的所有字节。它还删除了换行符，以便打印更加清晰。
- en: It creates a string with those bytes, so it will fail if we send non-UTF-8 bytes.
    Once we take bytes from the front of the buffer, the next index should point to
    the first element in the buffer. If there was no `a` in the buffer, it will just
    update the index to the last element that was read, and just return `None`, since
    there isn't a full frame ready. The `decode_eof()` method will do a similar thing
    when the connection gets closed. We use strings as the output of the codec, but
    you can use any structure or enumeration to represent your data or commands, for
    example.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 它创建了一个包含这些字节的字符串，所以如果我们发送非UTF-8字节，它将失败。一旦我们从缓冲区的开头取出字节，下一个索引应该指向缓冲区中的第一个元素。如果没有`a`在缓冲区中，它将只更新索引到最后读取的元素，并返回`None`，因为没有准备好完整的帧。当连接关闭时，`decode_eof()`方法将执行类似操作。我们使用字符串作为编解码器的输出，但你也可以使用任何结构或枚举来表示你的数据或命令，例如。
- en: 'We also need to implement the `Encode` trait so that we can use the `framed()`
    method from Tokio. This just represents how the data would be encoded in a new
    byte array if we wanted to use bytes again. We will just get the bytes of the
    strings and append an `a` to it. We will lose new line information, though. Let''s
    see what it looks like:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要实现`Encode`特质，这样我们就可以使用Tokio的`framed()`方法。这仅仅表示如果我们想再次使用字节，数据将如何编码在一个新的字节数组中。我们只需获取字符串的字节并将一个`a`附加到它。不过，我们会丢失换行信息。让我们看看它是什么样子：
- en: '[PRE5]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'To see how it works, let''s implement a simple `main()` function and use Telnet
    to send some text with `a` letters in it:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 为了了解它是如何工作的，让我们实现一个简单的`main()`函数，并使用Telnet发送包含`a`字母的文本：
- en: '[PRE6]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'We could send this text, for example:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以发送这样的文本，例如：
- en: '![](img/10b83c36-d695-4ec2-885d-b104891e1a15.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/10b83c36-d695-4ec2-885d-b104891e1a15.png)'
- en: 'The output in the server will be similar to this:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 服务器中的输出将类似于这个：
- en: '![](img/63cb8680-f15c-4fe7-a3a1-afee297e94cc.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/63cb8680-f15c-4fe7-a3a1-afee297e94cc.png)'
- en: Note that I didn't close the connection, so the last part of the last sentence
    was still in the buffer.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我没有关闭连接，所以最后一句话的最后部分仍然在缓冲区中。
- en: WebSockets in Rust
  id: totrans-84
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Rust中的WebSocket
- en: If you work in web development, you know that WebSockets are one of the most
    useful protocols to speed up communication with the client. Using them allows
    your server to send information to the client without the latter requesting it,
    therefore avoiding one extra request. Rust has a great crate that allows the implementation
    of WebSockets, named `websocket`.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你从事Web开发，你知道WebSocket是加速与客户端通信的最有用的协议之一。使用它们允许你的服务器在客户端请求之前向客户端发送信息，从而避免一个额外的请求。Rust有一个非常好的crate，允许实现WebSocket，名为`websocket`。
- en: 'We will analyze a small, asynchronous WebSocket echo server example to see
    how it works. We will need to add `websocket`, `futures`, and `tokio-core` to
    the `[dependencies]` section of our `Cargo.toml` file. The following example has
    been retrieved and adapted from the asynchronous server example in the `websocket`
    crate. It uses the Tokio reactor core, which means that it requires a core object
    and its handle. The WebSocket requires this behavior since it''s not a simple
    I/O operation, which means that it requires some wrappers, such as connection
    upgrades to WebSockets. Let''s see how it works:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将分析一个小的、异步的WebSocket回声服务器示例，以了解它是如何工作的。我们需要将`websocket`、`futures`和`tokio-core`添加到我们的`Cargo.toml`文件的`[dependencies]`部分。以下示例是从`websocket`
    crate中的异步服务器示例检索并改编的。它使用Tokio反应器核心，这意味着它需要一个核心对象及其句柄。WebSocket需要这种行为，因为它不是一个简单的I/O操作，这意味着它需要一些包装器，例如连接升级到WebSocket。让我们看看它是如何工作的：
- en: '[PRE7]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Most of the code, as you can see, is really similar to the code used in the
    previous examples. The first change that we see is that for each connection, before
    actually accepting the connection, it will check if the socket can be upgraded
    to the `rust-websocket` protocol. Then, it will upgrade the connection protocol
    to that protocol and accept the connection. For each connection, it will receive
    a handle to the client and some headers. All this is done asynchronously, of course.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，大部分代码与之前示例中使用的代码非常相似。我们首先看到的变化是，对于每个连接，在实际上接受连接之前，它会检查套接字是否可以升级到`rust-websocket`协议。然后，它将连接协议升级到该协议并接受连接。对于每个连接，它将接收客户端句柄和一些头信息。当然，所有这些操作都是异步完成的。
- en: We discard the headers, and we divide the client into a sink and a stream. A
    sink is the asynchronous equivalent to a synchronous writer, in `futures` terminology.
    It starts taking bytes from the stream until it closes, and, for each of them,
    it replies with the same message. It will then call the `forward()` method, which
    consumes all the messages in the stream, and then it sends a connection closed
    message. The future we just created is then spawned using the handle we took from
    the core. This means that, for each connection, this whole future will be run.
    The Tokio core then runs the whole server task.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 我们丢弃了头部信息，并将客户端分为一个sink和一个stream。在`futures`术语中，sink是同步写者的异步等价物。它从流中开始读取字节直到关闭，并且对每个字节，它都会回复相同的信息。然后它会调用`forward()`方法，该方法消耗流中的所有消息，然后发送一个连接关闭消息。我们刚刚创建的future将使用我们从核心中获取的处理程序来启动。这意味着对于每个连接，这个整个future都将被执行。然后Tokio核心运行整个服务器任务。
- en: If you get the example client implementation from the crate's Git repository
    ([https://github.com/cyderize/rust-websocket/blob/master/examples/async-client.rs](https://github.com/cyderize/rust-websocket/blob/master/examples/async-client.rs)),
    you will be able to see how the server replies to whatever the client sends. Once
    you understand this code, you will be able to create any WebSocket server you
    need.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你从crate的Git仓库中获取示例客户端实现（[https://github.com/cyderize/rust-websocket/blob/master/examples/async-client.rs](https://github.com/cyderize/rust-websocket/blob/master/examples/async-client.rs)），你将能够看到服务器如何回应客户端发送的内容。一旦你理解了这段代码，你将能够创建任何你需要的WebSocket服务器。
- en: Understanding the new Generators
  id: totrans-91
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解新的生成器
- en: A new feature is coming to Rust in 2018—asynchronous generators. Generators
    are functions that can yield elements before returning from the function and resume
    executing later. This is great for the loops that we have seen in this chapter.
    With generators, we could directly replace many of the callbacks with the new
    `async`/`await` syntax.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 2018年，Rust将迎来一个新特性——异步生成器。生成器是可以在返回函数之前产生元素并在稍后继续执行的功能。这对于我们在本章中看到的循环来说非常棒。有了生成器，我们可以直接用新的`async`/`await`语法替换许多回调。
- en: 'This is still an unstable feature that can only be used in nightly, so it may
    be that the code you write becomes obsolete before stabilization. Let''s see a
    simple example of a generator:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 这仍然是一个不稳定的功能，只能在nightly中使用，所以你写的代码在稳定之前可能会变得过时。让我们看看一个简单的生成器示例：
- en: '[PRE8]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'You will need to execute `rustup override add nightly` to run the example.
    If you run it, you will see this output:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要执行`rustup override add nightly`来运行示例。如果你运行它，你将看到以下输出：
- en: '![](img/8beec889-41e0-4c17-beb8-c0946385aa98.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8beec889-41e0-4c17-beb8-c0946385aa98.png)'
- en: 'The interesting thing here is that the generator function can perform any computation,
    and you can resume the computation once a partial result gets yielded, without
    needing buffers. You can test this by doing the following—instead of yielding
    something from the generator, just use it to print in the console. Let''s see
    an example:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有趣的是，生成器函数可以执行任何计算，一旦部分结果被产生，你就可以恢复计算，而不需要缓冲区。你可以通过以下方式来测试这一点——不是从生成器中产生任何东西，而是用它来在控制台打印。让我们看一个例子：
- en: '[PRE9]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'If you run this example, you will see the following output:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你运行这个示例，你将看到以下输出：
- en: '![](img/842e17d8-1283-4ec7-b691-b31ef64df46b.png)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![](img/842e17d8-1283-4ec7-b691-b31ef64df46b.png)'
- en: As you can see, the function pauses its execution when it gets to a `yield`
    statement. If there is any data in that yield statement, the caller will be able
    to retrieve it. Once the generator is resumed, the rest of the function gets executed,
    until a `yield` or a `return` statement.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，当函数执行到`yield`语句时，它会暂停其执行。如果在`yield`语句中有任何数据，调用者将能够检索它。一旦生成器被恢复，函数的其余部分将继续执行，直到遇到`yield`或`return`语句。
- en: 'This, of course, is of great advantage for the `futures` we saw earlier. This
    is why the `futures-await` crate was created. This crate uses generators to make
    the implementation of asynchronous futures much easier. Let''s rewrite the TCP
    echo server we created before using this crate. We will need to add the `0.2.0`
    version of the `futures-await` to the `[dependencies]` section of our `Cargo.toml`
    file and then start using a bunch of nightly features. Let''s see some example
    code:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，这对我们之前看到的`futures`非常有优势。这就是为什么创建了`futures-await`crate。这个crate使用生成器使异步`futures`的实现变得容易得多。让我们用这个crate重写我们之前创建的TCP回显服务器。我们需要将`futures-await`的`0.2.0`版本添加到我们的`Cargo.toml`文件的`[dependencies]`部分，然后开始使用一些nightly特性。让我们看看一些示例代码：
- en: '[PRE10]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: This example will have two asynchronous functions that could, for example, be
    retrieving information from the network. They get called by the `add_data()` function,
    which will wait for them to return before adding them up and returning a result.
    If you run it, you will see that the result is `Ok(3)`. The line importing the
    `futures_await` crate as `futures` makes sense because the `futures-await` crate
    is just a small wrapper around the futures crate, and all the usual structures,
    functions, and traits are available.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 这个例子将包含两个异步函数，例如，它们可以从网络上检索信息。它们由`add_data()`函数调用，该函数将在将它们相加并返回结果之前等待它们返回。如果你运行它，你会看到结果是`Ok(3)`。导入`futures_await`
    crate作为`futures`的行是有意义的，因为`futures-await` crate只是futures crate的一个小包装，所有常用的结构、函数和特性都是可用的。
- en: The whole generators and `async`/`await` syntax is still being heavily worked
    on, but the Rust 2018 roadmap says it should be stabilized before the end of the
    year.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 整个生成器和`async`/`await`语法仍在积极开发中，但Rust 2018路线图表示它应该在年底前稳定下来。
- en: Summary
  id: totrans-106
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this last chapter of the book, you learned to use asynchronous programming
    to avoid creating too many threads. You can now use just the right amount of threads
    and still run the workload in parallel and efficiently in networking applications.
    To be able to do that, you first learned about the futures crate, which give us
    the minimum primitives to use when working with asynchronous programming in Rust.
    You then learned how the MIO-based Tokio works, and created your first servers.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在这本书的最后一章中，你学习了如何使用异步编程来避免创建过多的线程。现在你可以使用恰好数量的线程，同时在网络应用程序中并行且高效地运行工作负载。为了能够做到这一点，你首先学习了关于futures
    crate的知识，它为我们提供了在Rust中进行异步编程时所需的最基本原语。然后，你了解了基于MIO的Tokio是如何工作的，并创建了你的第一个服务器。
- en: Before understanding external crates, you learned about WebSockets and grasped
    the Tokio core reactor syntax. Finally, you learned about the new generators syntax
    and how the `futures` crate is being adapted to make use of this new syntax. Make
    sure to stay up to date about the news on when this great compiler feature will
    be stabilized.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在了解外部crate之前，你学习了WebSockets并掌握了Tokio核心反应器语法。最后，你学习了新的生成器语法以及`futures` crate是如何适应这种新语法的。确保关注关于这个伟大的编译器特性何时稳定的最新消息。
- en: Now that the book came to an end, we can see that high performance can be achieved
    in Rust in multiple and complimentary ways. We can first start by improving our
    sequential code as we saw in the first chapters. These improvements come from
    various techniques, starting from a proper compiler configuration and ending in
    small tips and tricks with the code. As we saw, some tools will help us in this
    labour.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 现在书已经结束，我们可以看到在Rust中可以通过多种互补的方式来实现高性能。我们可以首先从改善我们在第一章中看到的顺序代码开始。这些改进来自各种技术，从适当的编译器配置开始，到代码中的小技巧和窍门结束。正如我们所见，一些工具将帮助我们完成这项工作。
- en: We can then use metaprogramming to improve both the maintainability of the code
    and the performance, by reducing the amount of work the software has to do at
    runtime. We saw that new ways of metaprogramming are arriving this year to Rust.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以使用元编程来提高代码的可维护性和性能，通过减少软件在运行时必须执行的工作量。我们看到今年有新的元编程方式进入Rust。
- en: Finally, the last step to make things faster is to run tasks concurrently, as
    we saw in the last two chapters. Depending on the requirements of our project,
    we will use multithreading or/and asynchronous programming.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，使事物更快的一步是并发运行任务，正如我们在最后两章中看到的。根据我们项目的需求，我们将使用多线程或/和异步编程。
- en: You should now be able to improve the performance of your Rust applications
    and even to start learning deeper concepts of high performance programming. It
    has been a pleasure to guide you through these topics in the Rust programming
    language, and I hope you enjoyed the read.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你应该能够提高你的Rust应用程序的性能，甚至开始学习高性能编程的更深入概念。我很高兴能引导你通过Rust编程语言中的这些主题，希望你喜欢阅读。
