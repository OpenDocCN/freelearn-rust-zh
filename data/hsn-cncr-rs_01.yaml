- en: Preliminaries – Machine Architecture and Getting Started with Rust
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 预备知识 – 机器架构和Rust入门
- en: In this chapter, we'll work through the preliminaries of the book, making sure
    to cover the basics necessary to frame the remainder of the book. This book is
    about parallel programming in the Rust programing language. It's essential, then,
    to understand modern computing hardware at a high level. We'll need a sense of
    how a modern CPU operates, how memory buses influence the CPU's ability to perform
    work and what it means for a computer to be able to do multiple things at once.
    In addition, we'll discuss validating your Rust installation, and cover generating
    executables for the two CPU architectures that this book will be concerned with.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将处理本书的预备知识，确保涵盖构建本书其余部分所需的基本内容。本书是关于Rust编程语言中的并行编程。因此，了解现代计算硬件的高级概念是至关重要的。我们需要了解现代CPU的工作方式，内存总线如何影响CPU执行工作的能力，以及对于计算机能够同时做很多事情意味着什么。此外，我们将讨论验证您的Rust安装，并涵盖为本书关注的两种CPU架构生成可执行文件。
- en: 'By the close of this chapter, we will have:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，我们将：
- en: Discussed a high-level model of CPU operations
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 讨论了CPU操作的概要模型
- en: Discussed a high-level model of computer memory
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 讨论了计算机内存的概要模型
- en: Had a preliminary discussion of the Rust memory model
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对Rust内存模型进行了初步讨论
- en: Investigated generating runnable Rust programs for x86 and ARM
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调查了为x86和ARM生成可运行的Rust程序
- en: Investigated debugging these programs
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调查了这些程序的调试
- en: Technical requirements
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: This chapter requires any kind of modern computer on which Rust can be installed.
    The exact details are covered in depth below. The interested reader might choose
    to invest in an ARM development board. I have used a Raspberry Pi 3 Model B while
    writing. The Valgrind suite of tools are used below. Many operating systems bundle
    Valgrind packages, but you can find further installation instructions for your
    system at [valgrind.org](http://valgrind.org/). The `gdb` and `lldb` tools are
    used, often installed along with the gcc and llvm compiler toolchains.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 本章需要任何可以安装Rust的现代计算机。具体细节将在下面详细说明。感兴趣的读者可以选择投资ARM开发板。我在写作时使用了Raspberry Pi 3
    Model B。下面使用了Valgrind工具套件。许多操作系统捆绑了Valgrind包，但您可以在[http://valgrind.org/](http://valgrind.org/)找到您系统的进一步安装说明。使用了`gdb`和`lldb`工具，这些工具通常与gcc和llvm编译器工具链一起安装。
- en: 'You can find the source code for this book''s projects on GitHub: [https://github.com/PacktPublishing/Hands-On-Concurrency-with-Rust](https://github.com/PacktPublishing/Hands-On-Concurrency-with-Rust).
    This chapter has no relevant source code.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在GitHub上找到本书项目的源代码：[https://github.com/PacktPublishing/Hands-On-Concurrency-with-Rust](https://github.com/PacktPublishing/Hands-On-Concurrency-with-Rust)。本章没有相关的源代码。
- en: The machine
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器
- en: In this book, independent of the specific Rust techniques, we'll attempt to
    teach a kind of *mechanical sympathy* with the modern parallel computer. There
    are two model kinds of parallelism we'll touch on—concurrent memory operations
    and data parallelism. We'll spend most of our time in this book on concurrent
    memory operations, the kind of parallelism in which multiple CPUs contend to manipulate
    a shared, addressable memory. Data parallelism, where the CPU is able to operate
    with a single or multiple instructions on multiple words at a time concurrently,
    will be touched on, but the details are CPU specific, and the necessary intrinsics
    are only now becoming available in the base language as this book goes to press.
    Fortunately, Rust, as a systems language with modern library management, will
    easily allow us to pull in an appropriate library and emit the correct instructions,
    or we could inline the assembly ourselves.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在这本书中，无论具体是哪种Rust技术，我们都会尝试教授一种与现代并行计算机的**机械亲和力**。我们将涉及两种模型类型的并行性——并发内存操作和数据并行性。在这本书的大部分时间里，我们将专注于并发内存操作，这种并行性中，多个CPU争夺操作共享的、可寻址的内存。数据并行性，即CPU能够同时使用单一或多个指令对多个字进行操作，也会涉及到，但具体细节是CPU特定的，并且随着这本书的出版，必要的内建函数才刚刚在基础语言中变得可用。幸运的是，作为具有现代库管理的系统语言，Rust将使我们能够轻松地引入适当的库并发出正确的指令，或者我们可以自己内联汇编。
- en: 'Literature on the abstract construction of algorithms for parallel machines
    must choose a machine model to operate under. The parallel random access machine
    (PRAM) is common in the literature. In this book, we will focus on two concrete
    machine architectures:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 关于并行机器算法的抽象构造的文献必须选择一个机器模型来操作。在文献中，并行随机访问机（PRAM）很常见。在这本书中，我们将关注两种具体的机器架构：
- en: x86
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: x86
- en: ARM
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ARM
- en: These machines were chosen because they are common and because they each have
    specific properties that will be important when we get to [Chapter 6](d42acb0b-a05e-4068-894f-81365d147bf4.xhtml),
    *Atomics – the Primitives of Synchronization*. Actual machines deviate from the
    the PRAM model in important ways. Most obviously, actual machines have a limited
    number of CPUs and a bounded amount of RAM. Memory locations are not uniformly
    accessible from each CPU; in fact, cache hierarchies have a significant impact
    on the performance of computer programs. None of this is to say that PRAM is an
    absurd simplification, nor is this true of any other model you'll find in literature.
    What should be understood is that as we work, we'll need to draw lines of abstraction out
    of necessity, where further detail does not improve our ability to solve problems
    well. We also have to understand how our abstractions, suited to our own work,
    relate to the abstractions of others so that we can learn and share. In this book,
    we will concern ourselves with empirical methods for understanding our machines,
    involving careful measurement, examination of assembly code, and experimentation
    with alternative implementations. This will be combined with an abstract model
    of our machines, more specific to today's machines than PRAM, but still, in the
    details, focusing on total cache layers, cache sizes, bus speeds, microcode versions,
    and so forth. The reader is encouraged to add more specificity should the need
    arise and should they feel so emboldened.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 这些机器被选择是因为它们很常见，并且它们各自具有在[第6章](d42acb0b-a05e-4068-894f-81365d147bf4.xhtml)，“原子——同步的基本原理”中非常重要的特定属性。实际机器在重要方面偏离了PRAM模型。最明显的是，实际机器具有有限的CPU数量和有限的RAM量。内存位置不是从每个CPU均匀可访问的；实际上，缓存层次对计算机程序的性能有重大影响。这并不是说PRAM是一种荒谬的简化，任何你在文献中找到的其他模型也是如此。应该理解的是，随着我们的工作，我们将需要出于必要而绘制抽象的线条，因为进一步的细节并不能提高我们解决问题的能力。我们还必须理解我们的抽象如何适合我们的工作，以及它们如何与其他人的抽象相关联，以便我们可以学习和分享。在这本书中，我们将关注理解我们机器的经验方法，包括仔细的测量、汇编代码的检查和替代实现的实验。这将被结合我们机器的抽象模型，比PRAM更具体，但在细节上仍然关注总缓存层、缓存大小、总线速度、微代码版本等等。鼓励读者在需要时添加更多具体性，如果他们感到有信心这么做。
- en: The CPU
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: CPU
- en: The CPU is a device that interprets a stream of instructions, manipulating storage
    and other devices connected to it in the process. The simplest model of a CPU,
    and the one that is often introduced first in undergrad computer science, is that
    a CPU receives an instruction from some nebulous place, performs the interpretation,
    receives the next instruction, interprets that, and so forth. The CPU maintains
    an internal pace via an oscillator circuit, and all instructions take a defined
    number of oscillator pulses—or *clock cycles*—to execute. In some CPU models,
    every instruction will take the same number of clock cycles to execute, and in
    others the cycle count of instructions will vary. Some CPU instructions modify
    registers, have very low latency with specialized but exceedingly finite memory
    locations built into the CPU. Other CPU instructions modify the main memory, RAM.
    Other instructions move or copy information between registers and RAM or vice
    versa. RAM—whose read/write latency is much higher than that of registers but
    is much more plentiful—and other storage devices, such as SSDs, are connected
    to the CPU by specialized buses.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: CPU是一种解释指令流并在这个过程中操作与其连接的存储和其他设备的设备。CPU的最简单模型，也是通常在本科计算机科学中首先介绍的是，CPU从一个模糊的地方接收一条指令，执行解释，接收下一条指令，解释它，以此类推。CPU通过振荡电路维持内部节奏，所有指令都需要一定数量的振荡脉冲——或者称为*时钟周期*——来执行。在某些CPU模型中，每条指令将执行相同数量的时钟周期，而在其他模型中，指令的周期数将有所不同。一些CPU指令修改寄存器，具有非常低的延迟，并且CPU中内置了专门但极其有限的内存位置。其他CPU指令修改主存储器，RAM。其他指令在寄存器和RAM之间或反之移动或复制信息。RAM——其读写延迟远高于寄存器，但数量更多——以及其他存储设备，如SSD，通过专用总线连接到CPU。
- en: The exact nature of these buses, their bandwidth and transmission latency, varies
    between machine architectures. On some systems, every location in the RAM is addressable—meaning
    that it can be read or written to—in constant time from the available CPUs. In
    other systems, this is not the case—some RAM is CPU-local and some is CPU-remote.
    Some instructions control special hardware interrupts that cause memory ranges
    to be written to other bus-connected storage devices. Mostly, these devices are
    exceedingly slow, compared to the RAM, which is itself slow compared to the registers.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 这些总线的确切性质、它们的带宽和传输延迟，在不同机器架构之间是不同的。在一些系统中，RAM中的每个位置都是可寻址的——这意味着它可以在恒定时间内从可用的CPU中读取或写入。在其他系统中，情况并非如此——一些RAM是CPU本地的，而一些是CPU远程的。一些指令控制特殊的硬件中断，导致内存范围被写入其他总线连接的存储设备。大多数情况下，与RAM相比，这些设备极其缓慢，而与寄存器相比，RAM本身也较慢。
- en: All of this is to explain that in the simplest model of a CPU, where instructions
    are executed serially, instructions may well end up stalling for many clock cycles
    while waiting for reads or writes to be executed. To that end, it's important
    to understand that almost all CPUs—and especially the CPUs we'll concern ourselves
    with in this book—perform out-of-order executions of their instructions. Just
    so long as a CPU can prove that two sequences of instructions access the memory
    distinctly—that is, they do not interfere with each other—then the CPU is free
    and will probably reorder instructions. This is one of the things that makes C's
    undefined behavior concerning uninitialized memory so interesting. Perhaps your
    program's future has already filled in the memory, or perhaps not. Out-of-order
    execution makes reasoning about a processor's behavior difficult, but its benefit
    is that CPUs can execute programs much faster by deferring a sequence of instructions
    that is stalled on some kind of memory access.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些都是为了解释在CPU的最简单模型中，即指令按顺序执行的情况下，指令可能会在等待读取或写入执行的过程中停滞许多时钟周期。为此，重要的是要理解几乎所有的CPU——特别是我们将在本书中关注的CPU——都会执行指令的乱序执行。只要CPU能够证明两条指令序列对内存的访问是明显不同的——也就是说，它们不会相互干扰——那么CPU就是自由的，并且很可能会重新排序指令。这正是C语言关于未初始化内存的未定义行为如此有趣的原因之一。也许你的程序已经填充了内存，也许没有。乱序执行使得推理处理器的行为变得困难，但它的好处是CPU可以通过延迟在某种内存访问上停滞的指令序列来更快地执行程序。
- en: In the same spirit, most modern CPUs—and especially the CPUs we'll concern ourselves
    with in this book—perform *branch prediction*. Say that branches in our programs
    tend to branch the same way at execution time—for example, say we have a feature-flag
    test that is configured to be enabled for the lifetime of a program. CPUs that
    perform branch prediction will *speculatively execute* one side of a branch that
    tends to branch in a certain way while they wait on other stalled instruction
    pipelines' instructions. When the branch instruction sequence catches up to its
    branch test, and if the test goes the predicted way, there's already been a great
    deal of work done and the instruction sequence can skip well ahead. Unfortunately,
    if the branch was mispredicted, then all this prior work must be torn down and
    thrown away, and the correct branch will have to be computed, which is quite expensive.
    It's for this reason that you'll find that programmers who worry about the nitty-gritty
    performance characteristics of their programs will tend to fret about branches
    and try to remove them.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 同样地，大多数现代CPU——特别是我们将在本书中关注的CPU——执行*分支预测*。假设我们的程序中的分支在执行时倾向于以相同的方式分支——例如，假设我们有一个配置为在程序生命周期内启用的功能标志测试。执行分支预测的CPU将在等待其他停滞的指令流水线指令时，*推测性地执行*分支的一侧，该分支倾向于以某种方式分支。当分支指令序列赶上分支测试时，如果测试结果与预测一致，那么已经完成了很多工作，指令序列可以跳得很远。不幸的是，如果分支预测错误，那么所有这些先前的工作都必须被拆解并丢弃，并且必须计算正确的分支，这相当昂贵。这就是为什么你会发现，那些担心他们程序性能细节的程序员往往会担心分支，并试图移除它们。
- en: All of this is quite power-hungry, reordering instructions to avoid stalls or
    racing ahead to perform computations that may be thrown away. Power-hungry implies
    hot, which implies cooling, which implies more power expenditure. All of which
    is not necessarily great for the sustainability of technological civilization,
    depending on how the electricity for all this is generated and where the waste
    heat is dumped. To that end, many modern CPUs integrate some kind of power-scaling
    features. Some CPUs will lengthen the time between their clock pulses, meaning
    they execute fewer instructions in a certain span of time than they might otherwise
    have. Other CPUs race ahead as fast as they normally would and then shut themselves
    off for a spell, drawing minimal electricity and cooling in the meantime. The
    exact method by which to build and run a power-efficient CPU is well beyond the
    scope of this book. What's important to understand is that, as a result of all
    this, your program's execution speed will vary from run to run, all other things
    being equal, as the CPU decides whether or not it's time to save power. We'll
    see this in the next chapter when we manually set power-saving settings.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些都非常耗电，需要重新排序指令以避免停顿，或者提前执行可能会被丢弃的计算。耗电意味着发热，意味着需要冷却，这意味着更多的电力消耗。所有这些对于技术文明的可持续性来说并不一定好，这取决于所有这些电力的产生方式和废热的排放地点。为此，许多现代CPU集成了某种类型的电源调节功能。一些CPU会延长其时钟脉冲之间的时间，这意味着在一段时间内它们执行的指令比它们可能执行的要少。其他CPU会像平时一样快速前进，然后关闭一段时间，同时消耗最少的电力和冷却。构建和运行高效能CPU的确切方法远远超出了本书的范围。重要的是要理解，由于所有这些，在其他条件相同的情况下，你的程序执行速度会因运行而异，因为CPU会决定是否需要节省电力。我们将在下一章中看到这一点，当我们手动设置省电设置时。
- en: Memory and caches
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 内存和缓存
- en: The memory storage of a CPU, alluded to in the last section, is fairly minimal.
    It is limited to the handful of words in general-purpose registers, plus the special-purpose
    registers in some limited cases. Registers are very fast, owing to their construction
    and on-die location, but they are *not* suited for storage. Modern machines connect
    CPUs over a bus or buses to the *main memory*, a very large block of randomly
    addressable bytes. This random addressability is important as it means that, unlike
    other kinds of storage, the cost to retrieve the 0^(th) byte from RAM is not distinct
    from retrieving the 1,000,000,000^(th) byte. We programmers don't have to do any
    goofy trickery to ensure that our structures appear in the front of the RAM in
    order to be faster to retrieve or modify, whereas physical location in storage
    is a pressing concern for spinning hard disks and tape drives. Exactly how our
    CPUs interact with the memory varies between platforms, and the discussion that
    follows is heavily indebted to Mark Batty's description in his 2014 book, *The
    C11 and C++11* *Concurrency Model*.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: CPU的内存存储，在上一个章节中提到，相当有限。它仅限于通用寄存器中的一小部分单词，以及在有限情况下的专用寄存器。寄存器由于构造和在芯片上的位置而非常快，但它们并不适合存储。现代机器通过总线或总线将CPU连接到*主内存*，这是一个非常大的随机可寻址字节的块。这种随机可寻址很重要，因为它意味着，与其他类型的存储不同，从RAM中检索第0个字节的成本与检索第1,000,000,000个字节的成本是相同的。我们程序员不需要做任何愚蠢的技巧来确保我们的结构出现在RAM的前面，以便更快地检索或修改，而物理位置在存储中对于旋转硬盘和磁带驱动器来说是一个紧迫的问题。我们的CPU如何与内存交互在不同的平台上有所不同，接下来的讨论在很大程度上得益于Mark
    Batty在2014年出版的《C11和C++11并发模型》一书中对描述的借鉴。
- en: In a machine that exposes a sequentially consistent model of memory access,
    every memory load or store must be made in lockstep with one another, including
    in systems with multiple CPUs or multiple threads of execution per CPU. This limits
    important optimizations—consider the challenge of working around memory stalls
    in a sequentially consistent model—and so neither of the processors we'll be considering
    in this book offer this model. It *will* show up in literature by name because
    of the ease of reasoning about this model, and is worth knowing about, especially
    when studying atomics literature.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个暴露顺序一致内存访问模型的机器中，每个内存加载或存储操作都必须与其他操作同步进行，包括在具有多个CPU或每个CPU有多个执行线程的系统中的情况。这限制了重要的优化——考虑在顺序一致模型中绕过内存停顿的挑战——因此，本书中考虑的处理器都不提供这种模型。它*会*以名称出现在文献中，因为这种模型易于推理，值得了解，尤其是在研究原子文献时。
- en: The x86 platform behaves as if it were sequentially consistent, excepting that
    every thread of execution maintains a FIFO buffer for writes prior to their being
    flushed to the main memory. In addition, there is a global lock for the coordination
    of atomic reads and writes between threads of execution. There's a lot to unpack
    here. Firstly, I use the words *load* and *store* interchangeably with *read* and
    *write*, as does most literature. There is also a variant distinction between
    plain load/store and *atomic* load/store. Atomic loads/stores are special in that
    their effects can be coordinated between threads of execution, allowing for coordination
    with varying degrees of guarantees. The x86 processor platform provides fence
    instructions that force the flush of write buffers, stalling other threads of
    execution attempting to access the written range of main memory until the flush
    is completed. This is the purpose of the global lock. Without atomicity, writes
    will be flushed willy-nilly. On x86 platforms, writes to an addressable location
    in the memory are coherent, meaning they are globally ordered, and reads will
    see values from that location in the order of the writes. Compared to ARM, the
    way this works on x86 is very simple—writes happen directly to main memory.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: x86平台表现得像顺序一致，除了每个执行线程在写入被刷新到主内存之前都维护一个FIFO缓冲区。此外，还有一个全局锁用于协调执行线程之间的原子读和写操作。这里有很多东西需要解释。首先，我使用*load*和*store*与*read*和*write*互换使用，正如大多数文献所做的那样。还有平载荷/存储和*原子*载荷/存储之间的变体区别。原子载荷/存储是特殊的，因为它们的效果可以在执行线程之间进行协调，从而允许以不同级别的保证进行协调。x86处理器平台提供了强制刷新写入缓冲区的栅栏指令，这会阻止其他尝试访问已写入主内存范围的线程执行，直到刷新完成。这就是全局锁的作用。如果没有原子性，写入将会随意刷新。在x86平台上，对内存中可寻址位置的写入是一致的，这意味着它们是全局有序的，并且读取将按照写入的顺序看到该位置上的值。与ARM相比，x86上实现这一功能的方式非常简单——写入直接写入主内存。
- en: 'Let''s look at an example. Taking inspiration from Batty''s *excellent* dissertation,
    consider a setup where a parent thread sets two variables, *x* and *y*, to 0,
    then spawns two threads called, say, `A` and `*B*`. Thread `A` is responsible
    for setting *x* and then *y* to 1, whereas thread `B` is responsible for loading
    the value of `*x*` into a thread-local variable called `thr_x` and `*y*` into
    a thread-local variable called `thr_y`. This looks something like the following:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一个例子。从Batty的*优秀*论文中汲取灵感，考虑一个场景，其中父线程将两个变量*x*和*y*设置为0，然后创建了两个线程，比如叫做`A`和`*B*`。线程`A`负责将*x*设置为，然后*y*设置为1，而线程`B`负责将`*x*`的值加载到一个名为`thr_x`的线程局部变量中，将`*y*`的值加载到一个名为`thr_y`的线程局部变量中。这看起来可能如下所示：
- en: '[PRE0]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'In this specific example, `thr_x == 1` and `thr_y == 1`. Had the flushes been
    ordered differently by the CPU, this outcome would have been different. For instance,
    look at the following:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个特定的例子中，`thr_x == 1` 和 `thr_y == 1`。如果CPU按照不同的顺序执行刷新操作，这个结果就会不同。例如，看看以下内容：
- en: '[PRE1]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The consequence of this is that `thr_x == 0 `and `thr_y == 1`. Without any
    other coordination, the only other valid interleaving is `thr_x == 0 `and  `thr_y
    == 0`. That is, as a result of the write buffer on x86, the write of `*x*` in
    thread A can never be reordered to occur after the write of `y: thr_x == 1 `and `thr_y
    == 0`. This kind of stinks, unless you enjoy this little program as a parlor trick.
    We want determinism out of our programs. To that end, x86 provides different fence
    and lock instructions that control how and when threads flush their local write buffers,
    and how and when threads may read byte ranges from the main memory. The exact
    interplay here is… complicated. We''ll come back to it in great detail in [Chapter
    3](605ce307-29ed-4b5a-961e-8d327467b84f.xhtml),  *The Rust Memory Model – Ownership,
    References, and Manipulation* and [Chapter 6](d42acb0b-a05e-4068-894f-81365d147bf4.xhtml),
    *Atomics – the Primitives of Synchronization*. Suffice it to say that, for now,
    there''s an `SFENCE` instruction available that forces a sequential consistency.
    We can employ this instruction as follows:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '这种情况的结果是`thr_x == 0`和`thr_y == 1`。在没有其他协调的情况下，唯一的其他有效交错是`thr_x == 0`和`thr_y
    == 0`。也就是说，由于x86上的写缓冲区，线程A中`*x*`的写入永远不会重新排序到在`y: thr_x == 1`和`thr_y == 0`的写入之后发生。除非你喜欢将这个小程序作为客厅魔术，否则这真的很糟糕。我们希望程序具有确定性。为此，x86提供了不同的栅栏和锁指令，这些指令控制线程何时以及如何刷新它们的本地写缓冲区，以及何时以及如何从主内存中读取字节数据。这里的精确交互是复杂的。我们将在第3章[《Rust内存模型——所有权、引用和操作》](605ce307-29ed-4b5a-961e-8d327467b84f.xhtml)和第6章[《原子操作——同步的原始操作》](d42acb0b-a05e-4068-894f-81365d147bf4.xhtml)中详细讨论这个问题。简单来说，现在有一个`SFENCE`指令可用，它可以强制实现顺序一致性。我们可以如下使用这个指令：'
- en: '[PRE2]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: From this, we get `thr_x == 1` and `thr_y == 1`. The ARM processor is a little
    different—1/0 is a valid interleaving. There is no global lock to the ARM, no
    fences, and no write buffer. In ARM, a string of instructions—called a propagation
    list, for reasons that will soon be clear—is maintained in an *uncommitted* state,
    meaning that the thread that originated the instructions will see them as *in-flight*,
    but they will not have been propagated to other threads. These *uncommitted* instructions
    may have been performed—resulting in side-effects in the memory—or not, allowing
    for speculative execution and the other performance tricks discussed in the previous
    section. Specifically, reads may be satisfied from a thread's local propagation
    list, but not writes. Branch instructions cause the propagation list that led
    to the branch instruction to be committed, potentially out of the order from that
    specified by the programmer. The memory subsystem keeps track of which propagation
    list has been sent to which thread, meaning that it is possible for a thread's
    private loads and stores to be out of order and for committed loads and stores
    to appear out of order between threads. Coherency is maintained on ARM with more
    active participation from the memory subsystem.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 由此，我们得到`thr_x == 1`和`thr_y == 1`。ARM处理器略有不同——1/0是一个有效的交错。ARM没有全局锁，没有栅栏，也没有写缓冲区。在ARM中，一系列指令——称为传播列表，原因将在后面阐明——处于未提交状态，这意味着发起指令的线程会将其视为正在执行，但它们尚未传播到其他线程。这些未提交的指令可能已经执行——导致内存中的副作用，或者没有执行，允许进行推测执行和在前一节中讨论的其他性能技巧。具体来说，读取可能从线程的本地传播列表中满足，但写入则不行。分支指令会导致导致分支指令的传播列表被提交，可能不是程序员指定的顺序。内存子系统会跟踪哪些传播列表被发送到哪些线程，这意味着线程的私有加载和存储可能是不按顺序的，而提交的加载和存储在线程之间可能看起来是不按顺序的。在ARM上，通过内存子系统的更积极参与来维护一致性。
- en: Whereas on x86, the main memory is something that has actions done to it, on
    ARM, the memory subsystem responds to requests and may invalidate previous, uncommitted
    requests. A write request involves a read-response event, by which it is uniquely
    identified, and a read request must reference a write.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在x86架构中，主内存是执行操作的对象，而在ARM架构中，内存子系统会对请求做出响应，并且可能会使之前的未提交请求失效。写请求涉及一个读响应事件，通过这个事件可以唯一识别，而读请求必须引用一个写操作。
- en: This sets up a *data-dependency* chain. Responses to reads may be invalidated
    at a later time, but not writes. Each location receives a *coherence-commitment*
    ordering, which records a global order of writes, built up per-thread as propagation
    lists are propagated to threads.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这设置了一个*数据依赖链*。读响应可能在稍后失效，但写操作则不行。每个位置都会收到一个*一致性提交*排序，它记录了全局的写操作顺序，这个顺序是按照线程将传播列表传播到线程时构建的。
- en: 'This is very complicated. The end result is that writes to a thread''s view
    of the memory may be done out of programmer order, writes committed to main memory
    may also be done out of order, and reads can be requested out of programmer order.
    Therefore, the following code is perfectly valid, owing to the lack of branches
    in our example:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 这非常复杂。最终结果是，对线程视图中的内存的写入可能不是按照程序员顺序进行的，提交到主内存的写入也可能不是按顺序进行的，并且读取请求也可能不是按程序员顺序进行的。因此，以下代码是完美的，因为我们示例中没有分支：
- en: '[PRE3]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: ARM provides instructions for control of dependencies, called barriers. There
    are three types of dependency in ARM. The address dependency means a load is used
    to compute the address for access to the memory. The control dependency means
    that the program flow that leads to memory access depends on a load. We're already
    familiar with the data dependency.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: ARM提供了控制依赖关系的指令，称为屏障。ARM中有三种依赖类型。地址依赖意味着使用加载操作来计算访问内存的地址。控制依赖意味着导致内存访问的程序流程依赖于一个加载操作。我们已经熟悉数据依赖。
- en: While there is a lot of main memory available, it's not particularly fast. Well,
    let's clarify that. Fast here is a relative term. A photon in a vacuum will go
    about 30.5 centimeters in 1 nanosecond, meaning that in ideal circumstances, I,
    on the west coast of the United States, ought to be able to send a message to
    the east coast of the United States and receive a response in about 80 milliseconds.
    Of course, I'm ignoring request-processing time, the realities of the internet,
    and other factors; we're just dealing with ballpark figures, here. Consider that
    80 milliseconds is 80,000,000 nanoseconds. A read access from a CPU to the main
    memory is around 100 nanoseconds, give or take your specific computer architecture,
    the details of your chips, and other factors. All this is to clarify that, when
    we say, not particularly fast, we're working outside normal human time scales.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然有大量的主内存可用，但它并不特别快。好吧，让我们澄清一下。这里的“快”是一个相对术语。在真空中，光子每1纳秒大约可以传播30.5厘米，这意味着在理想情况下，我位于美国西海岸，应该能够向美国东海岸发送一条消息，并在大约80毫秒内收到回复。当然，我在忽略请求处理时间、互联网的现实以及其他因素；我们只是在处理大致的数字。考虑到80毫秒是8,000,000纳秒。从CPU到主内存的读取操作大约需要100纳秒，具体取决于你的特定计算机架构、芯片的细节以及其他因素。所有这些都是为了澄清，当我们说“并不特别快”时，我们是在正常人类时间尺度之外工作的。
- en: It is difficult, sometimes, to keep from misjudging things as fast enough. Say,
    we have a 4 GHz processor. How many clock cycles do we get per nanosecond? Turns
    out, it's 4\. Say, we have an instruction that needs to access main memory—which,
    remember, takes 100 nanoseconds—and happens to be able to do its work in exactly
    4 cycles, or one nanosecond. That instruction will then be stalled for 99 nanoseconds
    while it waits, meaning we're potentially losing out on 99 instructions that could
    have been executed by the CPU. The CPU will make up some of that loss with its
    optimization tricks. These only go so far, unless our computation is very, very
    lucky.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 有时很难避免误判事物是否足够快。比如说，我们有一个4 GHz的处理器。每纳秒我们有多少个时钟周期？结果是4个。比如说，我们有一个需要访问主内存的指令——记住，这需要100纳秒——并且恰好能在4个周期内，或者1纳秒内完成其工作。那么这条指令将在等待时停滞99纳秒，这意味着我们可能失去了99条本可以由CPU执行的指令。CPU将通过其优化技巧弥补一些损失。这些技巧只能走这么远，除非我们的计算非常、非常幸运。
- en: In an effort to avoid the performance impact of the main memory on computation,
    processor manufacturers introduced *caching* between the processor and the main
    memory. Many machines these days have three layers of *data cache,* as well as
    an *instruction cache*, called dCACHE and iCACHE, which are tools we'll be using
    later. You will see dCACHE often consists of three layers these days, each layer
    being successively larger than the last, but also slower for cost or power concerns.
    The lowest, smallest layer is called L1, the next L2, and so forth. CPUs read
    into caches from the main memory in working blocks—or simply blocks—that are the
    size of the cache being read into. Memory access will preferentially be done on
    the L1 cache, then L2, then L3, and so forth, with time penalties at each level
    for missing and block reads. Cache hits, however, are significantly faster than
    going directly to the main memory. L1 dCACHE references are 0.5 nanoseconds, or
    fast enough that our hypothetical 4-cycle instruction is 8* times* slower than
    the memory access it requires. L2 dCACHE references are 7 nanoseconds, still a
    fair sight better than the main memory. Of course, the exact numbers will vary
    from system to system, and we'll do quite a bit in the next chapter to measure
    them directly. Cache coherency—maintaining a high ratio of hits to misses—is a
    significant component of building fast software on modern machines. We'll never
    get away from the CPU cache in this book.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免主内存对计算性能的影响，处理器制造商在处理器和主内存之间引入了*缓存*。如今，许多机器都有三层*数据缓存*，以及一个*指令缓存*，称为dCACHE和iCACHE，这些工具我们将在后面使用。您会发现dCACHE现在通常由三层组成，每一层都比上一层大，但出于成本或功耗的考虑也较慢。最低、最小的层被称为L1，接下来是L2，以此类推。CPU从主内存中以工作块——或者简单地说是块——的形式读取到缓存中，这些块的大小与被读取的缓存大小相同。内存访问将优先在L1缓存上进行，然后是L2，然后是L3，以此类推，每个级别的缺失和块读取都会带来时间上的惩罚。然而，缓存命中却比直接访问主内存快得多。L1
    dCACHE引用为0.5纳秒，足够快，以至于我们假设的4周期指令比所需的内存访问慢8倍。L2 dCACHE引用为7纳秒，仍然比主内存好得多。当然，具体的数字会因系统而异，我们将在下一章中做很多工作来直接测量它们。缓存一致性——保持高命中率与缺失率的比例——是构建现代机器上快速软件的一个重要组成部分。在这本书中，我们永远无法摆脱CPU缓存。
- en: Memory model
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 内存模型
- en: The details of a processor's handling of memory is both complicated and very
    specific to that processor. Programming languages—and Rust is no exception here—invent
    a *memory model* to paper over the details of all supported processors while,
    ideally, leaving the programmer enough freedom to exploit the specifics of each
    processor. Systems languages also tend to allow absolute freedom in the form of
    escape hatches from the language memory model, which is exactly what Rust has
    in terms of *unsafe*.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 处理器处理内存的细节既复杂又非常特定于该处理器。编程语言——在这里Rust也不例外——发明了一种*内存模型*来掩盖所有支持的处理器的细节，同时，理想情况下，给程序员足够的自由来利用每个处理器的特定功能。系统语言也倾向于以绝对自由的形式允许从语言内存模型中逃脱，这正是Rust在*不安全*方面的特点。
- en: With regard to its memory model, Rust is very much inspired by C++. The atomic
    orderings exposed in Rust are those of LLVM's, which are those of C++11\. This
    is a fine thing—any literature to do with either C++ or LLVM will be immediately
    applicable to Rust. Memory order is a complex topic, and it's often quite helpful
    to lean on material written for C++ when learning. This is *especially* important
    when studying up on lock-free/wait-free structures—which we'll see later in this
    book—as literature on those topics often deals with it in terms of C++. Literature
    written with C11 in mind is also suitable, if maybe a little less straightforward
    to translate.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在其内存模型方面，Rust深受C++的启发。Rust中暴露的原子排序是LLVM的，也就是C++11的。这是一件好事——任何与C++或LLVM相关的文献都将立即适用于Rust。内存顺序是一个复杂的话题，当学习时，依赖为C++编写的材料通常非常有帮助。这在研究无锁/等待自由结构——我们将在本书后面看到——时尤为重要，因为关于这些主题的文献通常用C++来讨论。考虑到C11编写的文献也适用，尽管可能不太直接。
- en: Now, this is not to say that the C++ programmer will be immediately comfortable
    in concurrent Rust. The digs will be familiar, but not quite right. This is because
    Rust's memory model also includes a notion of reference consumption. In Rust,
    a thing in memory must be used zero or one times, but no more. This, incidentally,
    is an application of a version of linear-type theory called *affine typing*, if
    you'd like to read up more on the subject. Now, the consequence of restricting
    memory access in this way is that Rust is able to guarantee at compile-time safe
    memory access—threads cannot reference the same location in memory at the same
    time without coordination; out-of-order access in the same thread are not allowed,
    and so forth. Rust code is *memory safe* without relying on a garbage collector.
    In this book's estimation, memory safety is a good win, even though the restrictions
    that are introduced do complicate implementing certain kinds of structures that
    are more straightforward to build in C++ or similar languages.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 现在并不是说C++程序员会立即在并发Rust中感到舒适。这些概念会熟悉，但并不完全正确。这是因为Rust的内存模型还包括一个关于引用消耗的概念。在Rust中，内存中的某个对象必须使用零次或一次，但不能更多。顺便提一下，这是线性类型理论中一种称为*仿射类型*的版本的应用，如果您想了解更多关于这个主题的内容。现在，以这种方式限制内存访问的后果是，Rust能够在编译时保证安全的内存访问——线程不能在不协调的情况下同时引用内存中的同一位置；同一线程中的无序访问是不允许的，等等。Rust代码*内存安全*，无需依赖垃圾回收器。根据本书的评估，内存安全是一个很好的胜利，尽管引入的限制确实使得某些在C++或类似语言中更易于构建的结构实现变得更加复杂。
- en: This is a topic we'll cover in much greater detail in [Chapter 3](605ce307-29ed-4b5a-961e-8d327467b84f.xhtml),
    *The Rust Memory Model – Ownership, References and Manipulation*.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个我们将在[第3章](605ce307-29ed-4b5a-961e-8d327467b84f.xhtml)中更详细讨论的主题，*Rust内存模型——所有权、引用和操作*。
- en: Getting set up
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: Now that we have a handle on the machines, this book will deal with what we
    need to get synchronized on our Rust compiler. There are three channels of Rust
    to choose from—stable, beta, and nightly. Rust operates on a six-week release
    cycle. Every day the nightly channel is rolled over, containing all the new patches
    that have landed on the master branch since the day before. The nightly channel
    is special, compared to beta and stable, in that it is the only version of the
    compiler where nightly features are able to be compiled. Rust is very serious
    about backward compatibility. Proposed changes to the language are baked in nightly,
    debated by the community, and lived with for some time before they're promoted
    out of nightly only status and into the language proper. The beta channel is rolled
    over from the current nightly channel every six weeks. The stable channel is rolled
    over from beta at the same time, every six weeks.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经掌握了机器，这本书将处理我们需要在Rust编译器上同步的内容。Rust有三种频道可供选择——稳定版、测试版和夜间版。Rust遵循六周发布周期。每天夜间频道都会更新，包含自前一天以来master分支上所有新提交的补丁。与测试版和稳定版相比，夜间频道是特殊的，因为它是唯一一个能够编译夜间功能的编译器版本。Rust对向后兼容性非常认真。语言变更建议在夜间版本中实施，由社区讨论，并在一段时间内使用后，才会从夜间版本状态提升到语言本身。测试版每六周从当前夜间版滚动更新。稳定版也同时从测试版滚动更新，每六周一次。
- en: This means that a new stable version of the compiler is at most only ever six
    weeks old. Which channel you choose to work with is up to you and your organization.
    Most teams I'm aware of work with nightly and ship stable, as many important tools
    in the ecosystem—such as clippy and rustfmt—are only available with nightly features,
    but the stable channel offers, well, a stable development target. You'll find
    that many libraries in the crate ecosystem work to stay on stable for this reason.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着编译器的新稳定版本最多只有六周的历史。您选择哪个频道来工作取决于您和组织。我所了解的大多数团队都使用nightly版本并发布稳定版本，因为生态系统中的许多重要工具——如clippy和rustfmt——仅通过nightly功能可用，但稳定频道提供了稳定的开发目标。您会发现，出于这个原因，许多库在crate生态系统中都努力保持稳定。
- en: 'Unless otherwise noted,  we''ll focus on the stable channel in this book. We''ll
    need two targets installed—one for our x86 machine and the other for our ARMv7\.
    Your operating system may package Rust for you—kudos!—but the community tends
    to recommend the use of `rustup`, especially when managing multiple, version-pinned
    targets. If you''re unfamiliar with `rustup`, you can find a persuasive explanation
    of and instructions for its use at [rustup.rs](https://www.rustup.rs/). If you''re
    installing a Rust target for use on a machine on which `rustup` is run, it will
    do the necessary triplet detections. Assuming that your machine has an x86 chip
    in it and is running Linux, then the following two commands will have equivalent
    results:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 除非另有说明，否则本书将专注于稳定渠道。我们需要安装两个目标——一个用于我们的x86机器，另一个用于我们的ARMv7。您的操作系统可能已经为您打包了Rust——恭喜！——但社区倾向于推荐使用`rustup`，尤其是在管理多个、版本固定的目标时。如果您不熟悉`rustup`，可以在[rustup.rs](https://www.rustup.rs/)找到对其使用和说明的令人信服的解释。如果您正在为在运行`rustup`的机器上使用的Rust目标进行安装，它将执行必要的三元组检测。假设您的机器中有一个x86芯片并且正在运行Linux，那么以下两个命令将产生相同的结果：
- en: '[PRE4]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Both will instruct `rustup` to track the target `x86_64-unknown-linux-gnu`
    and install the stable channel version of Rust. If you''re running OS X or Windows,
    a slightly different triplet will be installed by the first variant, but it''s
    the chip that really matters. The second target, we''ll need to be more precise
    with:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个命令都将指示`rustup`跟踪目标`x86_64-unknown-linux-gnu`并安装Rust的稳定渠道版本。如果您正在运行OS X或Windows，第一个变体将安装一个稍微不同的三元组，但芯片才是真正重要的。第二个目标，我们需要更精确一些：
- en: '[PRE5]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Now you have the ability to generate x86 binaries for your development machine,
    for x86 (which is probably the same thing), and for an ARMv7 running Linux, the
    readily available RaspberryPi 3\. If you intend to generate executables for the
    ARMv7—which is recommended, if you have or can obtain the chip—then you''ll also
    need to install an appropriate cross-compiler to link. On a Debian-based development
    system, you can run the following:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您可以为您的开发机器、x86（这可能是同一件事）以及运行Linux的ARMv7（如现成的RaspberryPi 3）生成x86二进制文件。如果您打算为ARMv7生成可执行文件——如果您有或可以获取芯片，则建议这样做——那么您还需要安装适当的交叉编译器来链接。在基于Debian的开发系统上，您可以运行以下命令：
- en: '[PRE6]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Instructions will vary by operating system, and, honestly, this can be the
    trickiest part of getting a cross-compiling project set up. Don''t despair. If
    push comes to shove, you could always compile on host. Compilation will just be
    pokey. The final setup step before we get into the interesting part is to tell
    cargo how to link our ARMv7 target. Now, please be aware that cross-compilation
    is an active area of work in the Rust community at the time of writing. The following
    configuration file fiddling may have changed a little between this book being
    published and your reading of it. Apologies. The Rust community documentation
    will surely help patch up some of the differences. Anyway, add the following—or
    similar, depending on your operating system—to `~/.cargo/config`:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 指令将因操作系统而异，老实说，这可能是设置交叉编译项目最棘手的部分。不要绝望。如果迫不得已，您总是可以在主机上编译。编译将会很慢。在我们进入有趣的部分之前的最后一步设置是告诉cargo如何链接我们的ARMv7目标。现在，请注意，在本书写作时，交叉编译是Rust社区的一个活跃的研究领域。以下配置文件的调整可能在这本书出版和您阅读它之间有所变化。抱歉。Rust社区文档肯定会帮助弥补一些差异。无论如何，根据您的操作系统，将以下内容——或类似内容——添加到`~/.cargo/config`：
- en: '[PRE7]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: If `~/.cargo/config` doesn't exist, go ahead and create it with the preceding
    contents.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 如果不存在`~/.cargo/config`，请使用前面的内容创建它。
- en: The interesting part
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 有趣的部分
- en: 'Let''s create a default cargo project and confirm that we can emit the appropriate
    assembly for our machines. Doing this will be one of the important pillars of
    this book. Now, choose a directory on disk to place the default project and navigate
    there. This example will use `~/projects`, but the exact path doesn''t matter.
    Then, generate the default project:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们创建一个默认的cargo项目，并确认我们能否为我们的机器生成适当的汇编代码。这样做将是本书的一个重要支柱。现在，选择磁盘上的一个目录来放置默认项目，并导航到那里。这个例子将使用`~/projects`，但确切路径无关紧要。然后，生成默认项目：
- en: '[PRE8]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Go ahead and reward yourself with some x86 assembler:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 好吧，用一些x86汇编代码来奖励自己吧：
- en: '[PRE9]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Please be aware that if your compilation of a Rust binary on OS X x86 will not
    run on Linux x86, and vice versa. This is due to the differences in the interfaces
    of the operating systems themselves. You're better off compiling on your x86 Linux
    machine or your x86 OS X machine and running the binaries there. That's the approach
    I take with the material presented in this book.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，如果您在 OS X x86 上编译 Rust 二进制文件，则它可能无法在 Linux x86 上运行，反之亦然。这是由于操作系统自身接口的差异造成的。您最好在
    x86 Linux 机器或 x86 OS X 机器上编译，并在那里运行二进制文件。这正是本书中展示的材料所采取的方法。
- en: 'That said, reward yourself with some ARMv7 assembler:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 话虽如此，用一些 ARMv7 汇编代码奖励一下自己吧：
- en: '[PRE10]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Of course, if you want to build release versions, you need only to give `cargo`
    the `--release` flag:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，如果您想构建发布版本，只需给 `cargo` 传递 `--release` 标志即可：
- en: '[PRE11]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: It's interesting—and instructive!—to compare the differences in the generated
    code. Notably, the release compilation will strip debugging entirely. Speaking
    of which, let's talk debuggers.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 比较生成的代码差异很有趣——并且富有教育意义！值得注意的是，发布编译将完全删除调试信息。说到调试器，让我们来谈谈调试器。
- en: Debugging Rust programs
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 调试 Rust 程序
- en: 'Depending on your language background, the debugging situation in Rust may
    be very familiar and comfortable, or it might strike you as a touch bare bones.
    Rust relies on the commonly used debugging tools that other programming languages
    have to hand—`gdb` or `lldb`. Both will work, though historically, `lldb` has
    had some issues, and it''s only since about mid-2016 that either tool has supported
    unmangled Rust. Let''s try `gdb` on `hello_world` from the previous section:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 根据您的语言背景，Rust 中的调试情况可能会非常熟悉和舒适，或者可能会让您觉得有点简陋。Rust 依赖于其他编程语言常用的调试工具——`gdb` 或
    `lldb`。两者都可以工作，尽管从历史上看，`lldb` 一直存在一些问题，并且直到大约 2016 年中旬，这两个工具才支持未混淆的 Rust。让我们尝试在上一节中的
    `hello_world` 上使用 `gdb`：
- en: '[PRE12]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Let''s also try `lldb`:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '让我们也尝试一下 `lldb`:'
- en: '[PRE13]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Either debugger is viable, and you're warmly encouraged to choose the one that
    suits your debugging style. This book will lean toward the use of `lldb` because
    of vague authorial preference.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 任何一个调试器都是可行的，并且强烈建议您选择适合您调试风格的那个。这本书将倾向于使用 `lldb`，因为作者有模糊的个人偏好。
- en: 'The other suite of tooling you''ll commonly see in Rust development—and elsewhere
    in this book—is `valgrind`. Rust being memory safe, you might wonder when `valgrind`
    would find use. Well, whenever you use `unsafe`. The `unsafe` keyword in Rust
    is fairly uncommon in day-to-day code, but does appear when squeezing out extra
    percentage points from hot code paths now and again. Note that `unsafe` blocks
    will absolutely appear in this book. If we run `valgrind` on `hello_world`, we''ll
    get no leaks, as expected:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Rust 开发（以及本书的其他部分）中，您通常会看到的另一个工具集是 `valgrind`。由于 Rust 是内存安全的，您可能会想知道 `valgrind`
    何时会被使用。好吧，每当您使用 `unsafe` 时。Rust 中的 `unsafe` 关键字在日常代码中并不常见，但有时会出现在从热点代码路径中挤出额外百分点的场景中。请注意，`unsafe`
    块将绝对会出现在这本书中。如果我们对 `hello_world` 运行 `valgrind`，我们会得到预期的无泄漏结果：
- en: '[PRE14]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Profiling memory use in Rust programs is an important day-to-day task when
    writing performance-critical projects. For this, we use Massif, the heap profiler:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Rust 程序中分析内存使用是编写性能关键型项目时的一项重要日常任务。为此，我们使用 Massif，堆分析器：
- en: '[PRE15]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Profiling the cache is also an important routine task. For this, we use `cachegrind`,
    the cache and branch-prediction profiler:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 分析缓存也是一个重要的常规任务。为此，我们使用 `cachegrind`，缓存和分支预测分析器：
- en: '[PRE16]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Each of these will be used throughout the book and on much more interesting
    projects than `hello_world`. But `hello_world` is the first cross-compilation
    achieved in this text, and that's no small thing.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 这些工具将在整本书中以及许多比 `hello_world` 更有趣的项目中使用。但 `hello_world` 是在这篇文章中实现的第一个交叉编译，这可不是一件小事。
- en: Summary
  id: totrans-83
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we've discussed the preliminaries of this book, the machine
    architecture of modern CPUs, and the way loads and stores of memory may be interleaved
    for surprising results, illustrating the need for some kind of synchronization
    for our computations. That need for synchronization will drive much of the discussion
    of this book. We also discussed installing Rust, the channels of the compiler
    itself, and our intention to focus on the *stable* channel. We also compiled a
    simple program for both x86 and ARM systems. We also discussed debugging and performance
    analysis of our simple program, mostly as a proof-of-concept of the tools. The
    next chapter, [Chapter 2](8c61da2f-08c8-40be-89d4-d8afa8510850.xhtml), *Sequential
    Rust Performance and Testing*, will explore this area in much more depth.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们讨论了本书的预备知识、现代CPU的机器架构以及内存的加载和存储可能如何交织出令人惊讶的结果，说明了我们需要某种同步来处理计算的需求。这种同步的需求将推动本书的大部分讨论。我们还讨论了安装Rust、编译器的通道以及我们专注于*稳定*通道的意图。我们还为x86和ARM系统编译了一个简单的程序。我们还讨论了我们简单程序的调试和性能分析，这主要是作为工具的证明概念。下一章，[第二章](8c61da2f-08c8-40be-89d4-d8afa8510850.xhtml)，*顺序Rust性能和测试*，将更深入地探讨这个领域。
- en: Further reading
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: At the end of each chapter, we'll include a list of bibliographic materials,
    things that are warmly recommended for readers wishing to dive further into the
    topic discussed in the chapter, links to relevant Rust community discussions,
    or links to the documentation of important tools. Bibliographic material may appear
    in multiple chapters because if something's important, it bears repeating.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在每一章的结尾，我们将包括一个参考文献列表，这些参考文献强烈推荐给希望进一步深入研究章节中讨论的主题的读者，相关Rust社区讨论的链接，或重要工具的文档链接。参考文献可能出现在多个章节中，因为如果某件事很重要，它值得重复。
- en: '*An Introduction to Parallel Algorithms*, 1992, Joseph JaJa. A fine textbook
    that introduces important abstract models. The book is significantly focused on
    abstract implementations of algorithms from an era when cache coherency and instruction
    pipelines were less important, so do be aware of that if you pull a copy.'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*并行算法导论*，1992年，约瑟夫·贾贾。这是一本优秀的教科书，介绍了重要的抽象模型。这本书显著关注算法的抽象实现，那时缓存一致性和指令流水线不太重要，所以如果你要找一本，请注意这一点。'
- en: '*What Every Programmer Should Know About Memory*, 2006, Ulrich Drepper. A classic,
    detailed description of how memory works in modern computers, despite being twelve
    years old at the time of writing this book.'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*程序员应了解的内存知识*，2006年，乌尔里希·德雷珀。这是一本经典书籍，详细描述了现代计算机中内存的工作原理，尽管这本书是在写作本书时十二年前的作品。'
- en: '*Computer Architecture: A Quantitative Approach*, 2011, John Hennessy and David
    Patterson. A classic somewhat more geared toward computer architects than software
    engineers. Still, this is well worth studying in depth, even if you do skip over
    the circuit diagrams here and there.'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*计算机架构：定量方法*，2011年，约翰·亨尼西和戴维·帕特森。这是一本经典书籍，更多地面向计算机架构师而不是软件工程师。尽管如此，即使你跳过其中的电路图，深入研究这本书也是值得的。'
- en: '*The C11 and C++11 Concurrency Model*, 2014, Mark Batty. Batty formalizes the
    C++11/C11 memory model, which if you can get up to speed with his logic language,
    is an excellent way to learn the memory model and its consequences.'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*C11和C++11并发模型*，2014年，马克·巴蒂。巴蒂形式化了C++11/C11内存模型，如果你能掌握他的逻辑语言，这是一种学习内存模型及其后果的极好方式。'
- en: '*LLVM Atomic Instructions and Concurrency Guide*, available at [https://llvm.org/docs/Atomics.html](https://llvm.org/docs/Atomics.html).[ ](https://llvm.org/docs/Atomics.html)Rust
    has specifically documented its concurrency memory model as being that of LLVM.
    This guide—and the documentation it links to—will be well-trod territory for any
    Rust programmer reading this book.'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*LLVM原子指令和并发指南*，可在[https://llvm.org/docs/Atomics.html](https://llvm.org/docs/Atomics.html)找到。[ ](https://llvm.org/docs/Atomics.html)Rust特别记录了其并发内存模型为LLVM模型。本指南及其链接的文档将是阅读本书的任何Rust程序员的熟悉领域。'
- en: '*Cache Speculation Side-Channels*, 2018, ARM. Speculative execution of branches
    leads to surprising information leaks, it turns out. This paper by ARM gives a
    very clear discussion of speculative execution on ARM, as well as tidy examples.'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*缓存推测侧信道*，2018年，ARM。分支推测执行导致令人惊讶的信息泄露。ARM的这篇论文对ARM上的推测执行进行了非常清晰的讨论，以及整洁的示例。'
- en: '*std::memory_order*, available at [http://en.cppreference.com/w/cpp/atomic/memory_order](http://en.cppreference.com/w/cpp/atomic/memory_order).
    While this document covers the memory order defined in C++, its examples of the
    consequences of the C++ memory-ordering guarantees are both straightforward and
    illustrative.'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*std::memory_order* 可在 [http://en.cppreference.com/w/cpp/atomic/memory_order](http://en.cppreference.com/w/cpp/atomic/memory_order)
    查找。虽然这份文档涵盖了 C++ 中定义的内存顺序，但其关于 C++ 内存顺序保证后果的示例既直接又具有说明性。'
- en: '*Valgrind User Manual*, available at [http://valgrind.org/docs/manual/manual.html](http://valgrind.org/docs/manual/manual.html).
    We''ll be making extensive use of `Valgrind`, and it''s well worth it for any
    systems programmer to be familiar with these tools. The documentation necessarily
    touches on some of the same material as this book, and may help illuminate things
    under a different light.'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Valgrind 用户手册* 可在 [http://valgrind.org/docs/manual/manual.html](http://valgrind.org/docs/manual/manual.html)
    查找。我们将广泛使用 `Valgrind`，对于任何系统程序员来说，熟悉这些工具都是非常值得的。文档不可避免地触及了与本书相同的一些材料，并可能有助于从不同的角度阐明问题。'
- en: '*Compiler Explorer*, available at [https://rust.godbolt.org/](https://rust.godbolt.org/). *Compiler
    Explorer* is not a paper so much as a well-designed web tool. It allows easy cross-compilation,
    and refers to simplified explanations of instructions.'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*编译器探索器* 可在 [https://rust.godbolt.org/](https://rust.godbolt.org/) 查找。*编译器探索器*
    更多的是一个设计精良的在线工具，而不是一份论文。它允许轻松进行交叉编译，并提供指令的简化解释。'
