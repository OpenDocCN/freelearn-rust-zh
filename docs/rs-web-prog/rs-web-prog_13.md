# 13

# 清洁 Web 应用仓库的最佳实践

在整本书中，我们一直在逐步构建我们的应用程序，并添加自动化脚本和工具来帮助我们测试和部署应用程序。然而，尽管这条路径对学习工具和概念很有用，但前几章中我们项目的结构并不适用于生产环境。

在本章中，我们将创建一个新的仓库，将我们的 Rust 代码提升到该仓库中，然后为我们的应用程序构建清洁的数据库迁移、测试和优化的 Docker 构建，以便可以顺利部署。

在本章中，我们将涵盖以下主题：

+   清洁仓库的一般布局

+   从环境变量获取我们的配置

+   设置本地开发数据库

+   在 Postman 测试中管理变量

+   构建 distroless 微型服务器 Docker 镜像

+   构建清洁的测试管道

+   使用 GitHub Actions 构建持续集成

到本章结束时，你将能够构建一个包含脚本、Docker 构建和测试的仓库结构，这将使开发变得顺畅，并易于添加新功能。你还将能够为应用程序构建**distroless** Docker 镜像，使它们更安全，并将我们的服务器镜像大小从 1.5 GB 降低到 45 MB！

# 技术要求

在本章中，我们将参考在*第九章*中定义的代码部分，*测试我们的应用程序端点和组件*。这可以在以下 URL 中找到：[`github.com/PacktPublishing/Rust-Web-Programming-2nd-Edition/tree/main/chapter09`](https://github.com/PacktPublishing/Rust-Web-Programming-2nd-Edition/tree/main/chapter09)。

本章的代码可以在[`github.com/PacktPublishing/Rust-Web-Programming-2nd-Edition/tree/main/chapter13`](https://github.com/PacktPublishing/Rust-Web-Programming-2nd-Edition/tree/main/chapter13)找到。

# 清洁仓库的一般布局

当谈到清洁布局时，我们必须在仓库中有单一焦点的目录，就像我们模块化的独立代码一样。在本章采用的清洁方法中，我们的仓库将具有以下布局：

```rs
├── Cargo.toml
├── README.md
├── .dockerignore
├── .gitignore
├── .github
│   . . .
├── builds
│   . . .
├── database
│   . . .
├── docker-compose.yml
├── scripts
│   . . .
├── src
│   . . .
└── tests
    . . .
```

这些文件和目录有以下职责：

+   `Cargo.toml`: 定义 Rust 构建的需求。

+   `README.md`: 访问时在 GitHub 页面上渲染，告诉读者项目的内容以及如何与项目交互。

+   `.dockerignore`: 告诉 Docker 构建在复制目录和文件到 Docker 镜像时忽略什么。

+   `.gitignore`: 告诉 git 在提交代码到 git 仓库时忽略什么。

+   `.github`: 一个存放 GitHub Actions 工作流程的目录。

+   `builds`: 一个目录，根据芯片架构存放不同的 Docker 构建。

+   `database`: 一个存放处理数据库迁移所需的所有脚本和 Docker 构建的目录。

+   `docker-compose.yml`: 定义了运行开发构建所需的容器。

+   `scripts`: 一个存放运行开发服务器或测试所需的 Bash 脚本的目录。

+   `src`: 一个存放构建服务器所需所有 Rust 代码的目录。

+   `tests`: 一个存放`docker-compose`配置和 Postman 集合的目录，以实现完全集成的测试。我们必须记住，单元测试是在`src`目录中编写的，并且在执行 Cargo 中的`test`命令时条件编译。在标准构建和发布构建中，单元测试被排除。

现在我们已经知道了我们的仓库结构是什么样的，我们可以添加一些规则和文件来确保我们的构建和 git 提交以完全正确的方式进行。在项目开始时就做这件事是个好主意，以避免意外地将不想要的代码添加到 git 历史或 Docker 构建中。

首先，我们将从`.gitignore`文件开始，该文件定义了以下规则：

```rs
/target/
Cargo.lock
# These are backup files generated by rustfmt
**/*.rs.bk
# jetbrains
.idea
# mac
.DS_Store
```

在这里，我们可以看到我们避开了`target`目录中的任何内容，当执行 Rust 构建和测试时，这个目录会被填满很多文件。这些文件对项目的开发没有任何贡献，并且会迅速增加你项目的大小。如果你喜欢使用 JetBrains 或者使用 Mac，我已经添加了`.idea`和`.DS_Store`，因为这些文件可能会悄悄地进入仓库；它们不是运行任何 Web 应用程序代码所必需的。

现在，让我们看看我们的`.dockerignore`文件，它有以下规则：

```rs
./tests
./target
./scripts
./database
.github
```

这些规则应该是有意义的。我们不希望将我们的构建文件、脚本、数据库迁移或 GitHub 工作流程添加到我们的 Docker 构建中。

我们现在已经定义了所有关于仓库的规则。在我们进入下一节之前，我们不妨定义一下我们应用程序的一般布局。在这里，我们可以使用以下命令将现有的待办事项应用程序的源 Rust 代码从现有仓库提升到我们的新仓库：

```rs
cp -r web_app/src ./clean_web_app/src
```

如果你已经在运行前面的命令之前在干净的 app 仓库中创建了一个`src`目录，你必须删除干净 app 仓库中的`src`目录；否则，你将有两个`src`目录，其中复制的`src`位于现有的`src`内部。我们的`Cargo.toml`文件与现有的 Web 应用程序有相同的依赖项；然而，我们可以使用以下代码更改其名称：

```rs
[package]
name = "clean_app"
version = "0.1.0"
edition = "2021"
```

让我们检查以下`test`命令是否可以提升我们的代码：

```rs
cargo test
```

这应该给我们以下输出：

```rs
running 9 tests
test to_do::structs::base::base_tests::new ... ok
test to_do::structs::done::done_tests::new ... ok
test to_do::structs::pending::pending_tests::new ... ok
test jwt::jwt_tests::get_key ... ok
test jwt::jwt_tests::decode_incorrect_token ... ok
test jwt::jwt_tests::encode_decode ... ok
test jwt::jwt_tests::test_no_token_request ... ok
test jwt::jwt_tests::test_false_token_request ... ok
test jwt::jwt_tests::test_passing_token_request ... ok
```

这个输出显示我们的代码已编译，并且我们的`Cargo.toml`文件定义正确。现在我们已经确认了我们的单元测试已经通过，这让我们有了一些保证，我们的代码正在工作。然而，我们如何定义我们的配置，在将应用程序部署到云时，会给我们带来一些障碍。在下一节中，我们将通过使用环境变量来配置我们的 Web 应用程序，来简化我们的部署。

# 从环境变量获取我们的配置

到目前为止，我们一直在从 YML 文件中加载配置变量。这有几个问题。首先，我们必须将这些文件移动到我们的部署位置。此外，文件与 Kubernetes 等编排工具不高效。Kubernetes 使用 ConfigMaps，这实际上为它们运行的每个容器定义了环境变量。环境变量也与 Secret Manager 和 AWS 凭证等工具很好地协同工作。我们还可以直接在`docker-compose`中直接覆盖环境变量。考虑到所有这些优势，我们将把配置值从文件切换到环境变量。为了映射我们从文件中实现了配置变量的位置，我们只需要删除我们的`src/config.rs`文件和`main.rs`文件中该`config`模块的模块声明。然后，我们可以再次运行`cargo test`命令以获得以下输出：

```rs
--> src/database.rs:12:12
   |
12 | use crate::config::Config;
   |            ^^^^^^ could not find `config` in the crate root
error[E0432]: unresolved import `crate::config`
 --> src/jwt.rs:9:12
  |
9 | use crate::config::Config;
  |            ^^^^^^ could not find `config` in the crate root
error[E0432]: unresolved import `crate::config`
 --> src/counter.rs:4:12
  |
4 | use crate::config::Config;
  |            ^^^^^^ could not find `config` in the crate root
```

在这里，我们在`jwt`、`database`和`counter`模块中使用了`config`。这是有意义的，因为我们使用这些模块时必须连接到外部结构。为了修复破坏性的导入，我们只需要将配置引用替换为环境变量引用。为了演示这一点，我们可以使用`src/counter.rs`文件。首先，我们必须删除以下代码行：

```rs
...
use crate::config::Config;
...
let config = Config::new();
let redis_url = config.map.get("REDIS_URL")
                          .unwrap().as_str()
                          .unwrap().to_owned();
...
```

然后，我们必须用以下代码替换前面的代码行：

```rs
...
use std::env;
...
let redis_url = env::var("REDIS_URL").unwrap();
...
```

我们也可以按照这种格式为`JWT`和`database`模块进行操作。在`JWT`模块中，有一个不是字符串的变量，必须将其转换为整数，即`expire minutes`。这可以通过以下代码行完成：

```rs
let minutes = env::var("EXPIRE_MINUTES").unwrap()
                                        .parse::<i64>()
                                        .unwrap();
```

如果我们现在运行`cargo test`命令，我们将得到以下输出：

```rs
running 9 tests
test jwt::jwt_tests::encode_decode ... FAILED
test jwt::jwt_tests::get_key ... FAILED
test jwt::jwt_tests::decode_incorrect_token ... FAILED
test to_do::structs::pending::pending_tests::new ... ok
test to_do::structs::base::base_tests::new ... ok
test to_do::structs::done::done_tests::new ... ok
test jwt::jwt_tests::test_passing_token_request ... FAILED
test jwt::jwt_tests::test_no_token_request ... ok
test jwt::jwt_tests::test_false_token_request ... FAILED
```

我们的测试运行了，所以我们知道编译代码是成功的。然而，一些 JWT 测试失败了。如果我们继续向下滚动日志，我们将看到以下错误：

```rs
---- jwt::jwt_tests::encode_decode stdout ----
thread 'jwt::jwt_tests::encode_decode' panicked at
'called `Result::unwrap()` on an `Err` value: NotPresent',
src/jwt.rs:52:50
```

这告诉我们我们的环境变量不存在。考虑到这个问题出现在`JWT`模块中，我们可以确信它也会在`database`和`counter`模块中失败。因此，在我们运行或测试我们的应用程序之前，我们需要定义这些环境变量。我们可以通过构建一个包含以下代码的`scripts/run_unit_tests.sh`脚本来为我们的应用程序构建一个带有环境变量的测试管道：

```rs
#!/usr/bin/env bash
# navigate to directory
SCRIPTPATH="$( cd "$(dirname "$0")" ; pwd -P )"
cd $SCRIPTPATH
cd ..
export SECRET_KEY="secret"
export EXPIRE_MINUTES=60
cargo test
```

在这里，我们导航到根目录，导出环境变量，然后运行`test`命令。运行前面的脚本会导致所有单元测试通过。

注意

虽然我喜欢尽可能多地将内容放入 Bash 脚本中，因为它像文档一样让其他开发者看到所有移动的部分，但还有其他方法。例如，你可能会发现前面概述的方法很笨拙，因为这个方法与运行标准的`cargo test`命令不同。其他方法包括以下：

- 手动将变量注入到测试中

- 使用`dotenv`crate 从文件中加载环境变量（https://github.com/dotenv-rs/dotenv）

- 为环境变量设置合理的默认值

你会如何创建运行开发服务器的脚本？这可能是一个尝试自己编写脚本的绝佳时机。如果你已经尝试编写了脚本，你的 `scripts/run_dev_server.sh` 脚本应该看起来像以下代码：

```rs
#!/usr/bin/env bash
# navigate to directory
SCRIPTPATH="$( cd "$(dirname "$0")" ; pwd -P )"
cd $SCRIPTPATH
cd ..
export SECRET_KEY="secret"
export EXPIRE_MINUTES=60
export DB_URL="postgres://username:password@localhost:5433/to_do"
export REDIS_URL="redis://127.0.0.1/"
cargo run
```

然而，如果我们尝试运行前面的脚本，它将会崩溃，因为我们无法连接到 Redis 数据库。我们需要在 `docker-compose.yml` 文件中定义我们的开发服务，以下代码：

```rs
version: "3.7"
services:
  postgres:
    container_name: 'to-do-postgres'
    image: 'postgres:11.2'
    restart: always
    ports:
      - '5433:5432'
    environment:
      - 'POSTGRES_USER=username'
      - 'POSTGRES_DB=to_do'
      - 'POSTGRES_PASSWORD=password'
  redis:
      container_name: 'to-do-redis'
      image: 'redis:5.0.5'
      ports:
        - '6379:6379'
```

现在我们已经定义了开发服务，我们可以启动 `docker-compose` 并运行 `run_dev_server.sh` 脚本，从而使开发服务器运行。然而，如果我们尝试执行任何请求，服务器将会崩溃。这是因为我们没有在数据库上执行迁移。在下一节中，我们将对开发数据库执行迁移。

# 设置本地开发数据库

当谈到迁移时，有一个优势是将我们使用的编程语言与迁移解耦。在过去，我不得不从一种语言切换到另一种语言，并希望迁移的实现没有与语言耦合。这也是一个部署问题。例如，在 Kubernetes 中，部署新的服务器或更新可能需要运行迁移。理想情况下，你希望通过我们所说的 *init Pods* 自动运行迁移。这是一个在主服务器部署之前启动并执行的容器。这个 init Pod 可以执行数据库迁移命令。然而，如果 init Pod 需要像 Rust 这样的东西来执行迁移，这可能会大大增加 init Pod 的大小。因此，我构建了一个仅依赖于 `psql` 和 `wget` 库的开源 Bash 工具。它可以创建新的迁移并使数据库升级或降级。然而，必须强调的是，这个工具并不适用于所有用途。引用我编写的迁移工具的文档（[`github.com/yellow-bird-consult/build_tools/tree/develop#use-yb-database-migrations-if-you-have-the-following`](https://github.com/yellow-bird-consult/build_tools/tree/develop#use-yb-database-migrations-if-you-have-the-following)），如果你有以下情况，你应该选择在项目中使用迁移工具：

+   **轻量级的迁移吞吐量**：迁移没有时间戳；它们只是简单地编号。工具的设计简单，便于跟踪正在发生的事情。在微服务中的轻量级应用是一个理想的环境。

+   **经过充分测试的代码**：没有防护措施。如果你的 SQL 脚本中存在错误，你的数据库将会被部分运行的迁移所损害。在实施数据库生产环境的迁移之前，你应该在 Docker 数据库上设置测试环境。

+   **你打算自己编写 SQL**：因为这个工具完全与任何编程语言解耦，你必须为每个迁移编写自己的 SQL 脚本。这并不像你想象的那么可怕，并且给你更多的控制权。

+   **你想要完全控制**：SQL 迁移和简单的实现实际上是在一个 Bash 脚本中定义的。这种简单的实现给你 100%的控制权。没有任何东西阻止你打开你的数据库在 GUI 中并直接更改版本号或手动运行迁移的特定部分。

既然我们已经知道了我们将要面对什么，我们可以导航到`database`目录并使用以下命令安装迁移工具：

```rs
wget -O - https://raw.githubusercontent.com/yellow-bird-consult
/build_tools/develop/scripts/install.sh | bash
```

这将在你的家目录中安装几个 Bash 脚本。你可能需要刷新你的终端来获取命令别名。并非所有操作系统都支持命令别名。如果你的命令别名有效，我们可以使用以下命令创建一组新的迁移：

```rs
yb db init
```

然而，如果别名不起作用，你可以通过 Bash 脚本来运行所有命令，因为每个 Bash 脚本都是 100%自包含的。我们只需使用以下命令传递相同的参数：

```rs
bash ~/yb_tools/database.sh db init
```

使用`init`命令，我们得到以下结构：

```rs
├── database_management
│   └── 1
│       ├── down.sql
│       └── up.sql
```

这与柴油迁移工具相同，但只是用纯数字表示。我们有两个来自待办应用的迁移，因此我们可以使用以下命令来创建它们：

```rs
cp -r database_management/1 database_management/2
```

一旦我们完成这个操作，我们就可以创建我们的迁移文件。`database_management/1/up.sql`文件使用以下代码创建`to_do`表：

```rs
CREATE TABLE to_do (
  id SERIAL PRIMARY KEY,
  title VARCHAR NOT NULL,
  status VARCHAR NOT NULL,
  date timestamp NOT NULL DEFAULT NOW()
)
```

`database_management/1/down.sql`文件使用以下代码删除`to_do`表：

```rs
DROP TABLE to_do
```

`database_management/2/up.sql`文件使用以下代码创建`user`表并将所有现有项目链接到一个占位符用户：

```rs
CREATE TABLE users (
    id SERIAL PRIMARY KEY,
    username VARCHAR NOT NULL,
    email VARCHAR NOT NULL,
    password VARCHAR NOT NULL,
    unique_id VARCHAR NOT NULL,
    UNIQUE (email),
    UNIQUE (username)
);
INSERT INTO users (username, email, password, unique_id)
VALUES ('placeholder', 'placeholder email',
'placeholder password', 'placeholder unique id');
ALTER TABLE to_do ADD user_id integer default 1
CONSTRAINT user_id REFERENCES users NOT NULL;
```

`database_management/2/down.sql`文件使用以下代码删除`users`表：

```rs
ALTER TABLE to_do DROP COLUMN user_id;
DROP TABLE users
```

我们现在已经准备好了迁移。然而，我们需要连接到我们的数据库以获取信息和执行迁移。我们可以启动我们的`docker-compose`来启动开发数据库并使其运行。一旦完成，我们必须在环境变量中定义我们的数据库 URL。迁移工具会在环境变量中查找 URL。然而，如果当前工作目录中有一个`.env`文件，迁移工具也会加载这个文件中的所有变量。在我们的`database_management/.env`文件中，我们可以使用以下代码定义数据库 URL：

```rs
DB_URL="postgres://username:password@localhost:5433/to_do"
```

现在我们数据库正在运行，并且我们已经定义了 URL，我们可以使用以下命令获取数据库当前的迁移级别：

```rs
# with alias
yb db get
# without alias
bash ~/yb_tools/database.sh db get
```

目前，我们应该得到一个`-1`。这意味着数据库上根本没有任何迁移版本表。如果有，但数据库上没有执行任何迁移，版本将是`0`。如果有任何迁移，则响应将是当前所在的迁移编号。当使用构建工具执行数据库上的命令时，我们可以使用以下`db`命令：

+   `set`: 如果没有迁移版本表，则创建一个迁移版本表

+   `up`: 通过应用`up.sql`脚本向上迁移一个版本

+   `down`: 通过应用`down.sql`脚本向下迁移一个版本

+   `new`: 如果你在最新版本上，则创建一个新的迁移文件夹

+   `rollup`: 如果没有迁移版本表，则创建一个新的迁移版本表，然后从数据库的当前版本开始循环`database_management`目录中的所有版本

我们将使用以下命令运行`rollup`命令：

```rs
# with alias
yb db rollup
# without alias
bash ~/yb_tools/database.sh db rollup
```

这将在数据库上执行迁移。如果你运行`get`命令，你会看到数据库的版本现在是`2`。我们的数据库现在已准备好被我们的应用程序查询。

注意

迁移也可以使用`sqlx-cli` crate 来实现，该 crate 可以在以下链接找到：https://crates.io/crates/sqlx-cli。

然而，需要 Cargo 来安装`sqlx-cli`，这将使执行这些迁移的 init Pods 创建变得复杂。

不同于随机地发出请求，在下一节中，我们将细化我们的 Postman 测试，以便我们可以运行一系列请求并检查我们的应用程序是否以我们想要的方式运行。

# 在 Postman 测试中管理变量

在*第九章*中，*测试我们的应用程序端点和组件*，我们构建了一个 Postman 集合。然而，它有点粗糙，因为我们不得不依赖 Python 将新令牌加载到 Newman 集合中。虽然使用 Python 作为进程之间的粘合代码是一项有用的技能，但我们的旧版本使用 Python 准备 Newman 集合并不是最干净的方法。在我们的集合开始时，我们将添加两个新的请求。第一个请求将创建一个用户，以下是一些参数：

![图 13.1 – 创建用户 Postman 请求](img/Figure_13.1_B18722.jpg)

图 13.1 – 创建用户 Postman 请求

使用创建用户请求，我们在 Postman 的**测试**选项卡中得到了以下 JavaScript：

```rs
pm.test("response is created", function () {
    pm.response.to.have.status(201);
});
```

通过这个，我们的集合的第一个请求将创建用户，如果请求未成功，将抛出一个错误。然后，我们可以为我们的集合创建第二个请求，该请求是登录，以下是一些参数：

![图 13.2 – 登录 Postman 请求](img/Figure_13.2_B18722.jpg)

图 13.2 – 登录 Postman 请求

使用这个请求，我们必须检查响应并将集合变量设置为令牌，这是通过在 Postman 的**测试**选项卡中运行以下 JavaScript 来完成的：

```rs
var result = pm.response.json()
pm.test("response is ok", function () {
    pm.response.to.have.status(200);
});
pm.test("response returns token", function () {
    pm.collectionVariables.set("login_token", result["token"]);
})
```

一旦我们设置了我们的收集变量，我们就能在整个收集过程中引用我们的令牌。为此，我们必须更新整个收集的授权，以确保我们的新令牌值能传播到所有我们的请求中。要访问授权设置，请点击一个`create`请求的头部以获取以下内容：

![图 13.3 – 请求头部](img/Figure_13.3_B18722.jpg)

图 13.3 – 请求头部

在上一张截图的右侧，我们可以看到一个**转到授权**按钮。如果我们点击这个按钮，我们会得到以下内容：

![图 13.4 – 配置授权](img/Figure_13.4_B18722.jpg)

图 13.4 – 配置授权

我们可以看到值已经更改为`{{login_token}}`。如果我们保存并然后导出收集 JSON 文件到我们仓库中的`tests`目录，属于`{{login_token}}`的值将被插入到收集 JSON 文件中。

现在我们有一个 Postman 收集，在登录请求后无需依赖 Python 将流程粘合在一起，它会自动更新一个新令牌。这要干净得多；然而，我们想要确保我们的测试管道的其余部分尽可能地模仿生产设置。在下一节中，我们将构建包含我们的应用程序的 Docker 镜像，其大小是之前章节中服务器镜像大小的几分之一。

# 构建无依赖的微型服务器 Docker 镜像

在前面的章节中，我们的服务器 Docker 镜像大约在 1.5 GB 左右。这相当大，当我们想要在服务器或其他开发者上分发我们的 Rust 镜像时并不理想。请注意，当镜像运行时，我们可以在 Docker 容器中访问一个 shell。这在开发中很有用，但在生产中并不理想，因为如果有人设法访问 Docker 容器，他们就能在其中四处查看并运行命令。如果服务器的权限没有锁定，黑客甚至可以在你的集群上开始运行命令。我见过通过这种方法发生的加密劫持，其中黑客利用 AWS 账户所有者的成本启动了大量挖矿 Pods。

我们将通过使用 distroless 镜像来解决这些问题。这些 distroless 镜像体积小巧，没有 shell。因此，如果有人设法访问我们的服务器，他们将无法做任何事情，因为没有 shell。我们将能够将我们的镜像大小从 1.5 GB 减少到 45 MB！这是我们想要的。然而，在我们开始构建我们的 distroless 镜像之前，我们必须知道 distroless 镜像上几乎没有东西。这意味着如果我们编译我们的应用程序并将其放入 distroless 镜像中，它将无法工作。例如，如果我们连接到数据库，我们需要在 distroless 镜像中包含`libpq`库。由于 distroless 镜像不包含库，镜像将无法运行，因为我们的静态二进制文件将无法定位到`libpq`库。

我们知道我们的 1.5 GB 镜像可以运行，因为它包含了所有东西，甚至厨房用具。我们可以使用我们的 1.5 GB 来检查静态二进制文件在镜像中包含的依赖项。我们可以通过移动到我们的`deployment`目录来实现，我们在那里编写了代码来部署我们的应用程序到 AWS，并在那里启动`docker-compose`。一旦这个运行起来，我们可以使用以下命令来检查我们的容器：

```rs
docker container ls
```

这将给出以下输出：

```rs
CONTAINER ID   IMAGE                 . . .
0ae94ab0bbc5   nginx:latest          . . .
6b49526250e3   deployment_rust_app.  . . .
9f4dcdc8a455   redis:5.0.5           . . .
```

您的 ID 将不同，但我们将使用这些 ID 通过以下命令 SSH 进入我们的 Rust 应用程序：

```rs
docker exec -it 6b49526250e3 /bin/bash
```

这将打开一个交互式 shell，以便我们可以导航 Docker 容器。在这里，我们必须记住，静态二进制文件——即 Rust 服务器——被称为`web_app`，并且它位于根目录中，所以我们不需要在容器内任何地方移动。我们可以使用以下命令列出依赖项：

```rs
ldd web_app
```

这将给出以下输出：

```rs
linux-vdso.so.1 (0x0000ffffb8a9d000)
libpq.so.5 => /usr/lib/aarch64-linux-gnu/libpq.so.5
libgcc_s.so.1 => /lib/aarch64-linux-gnu/libgcc_s.so.1
libpthread.so.0 => /lib/aarch64-linux-gnu/libpthread.so.0
libm.so.6 => /lib/aarch64-linux-gnu/libm.so.6
. . .
```

总共有 29 个依赖项。在列表的左侧是库的名称。在列表的右侧是库的路径。我们可以看到，数据库`libpq`库需要与其他库一起使用。您的路径可能不同。这是因为我在运行这个镜像的 MacBook M1 上，它有一个 ARM 芯片架构。如果您没有这个，那么您的路径将是`x86_64-linux-gnu`而不是`aarch64-linux-gnu`。这是可以的——我们将在 GitHub 在线仓库中提供两个 Docker 文件。

在我们的 Docker 构建过程中，我们必须将这些库复制到我们的 distroless 镜像中。在我们的`clean_web_app/builds`目录中，我们必须创建两个文件：`aarch64_build`和`x86_64_build`。这两个文件本质上都是相同的 Dockerfile，但库的引用不同。在撰写本文时，我希望有一种更智能的方法可以在一个 Dockerfile 中实现不同芯片的构建；然而，Docker 构建在传递变量方面非常糟糕，因为每个步骤都是隔离的，并且条件逻辑最多只能有限地使用。直接使用两个不同的文件会更简单。此外，如果构建在未来发生变化，那么两个不同芯片的构建将是解耦的。在我们的`clean_web_app/builds/arch_build`文件中，我们必须获取 Rust 镜像，安装数据库库，复制要编译的应用程序代码，并定义我们正在进行的构建类型：

```rs
FROM rust:1.62.1 as build
RUN apt-get update
RUN apt-get install libpq5 -y
WORKDIR /app
COPY . .
ARG ENV="PRODUCTION"
RUN echo "$ENV"
```

我们可以看到，环境默认设置为`"PRODUCTION"`。如果发生意外且环境未定义，则默认应为`"PRODUCTION"`。在测试构建中意外花费更长的时间编译要好于意外将非生产服务器部署到生产环境中。然后，如果它是生产环境，我们使用发布标志进行编译，如果不是使用发布标志编译，则将静态二进制文件切换到发布目录：

```rs
RUN if [ "$ENV" = "PRODUCTION" ] ; then cargo build --release ; \
else cargo build ; fi
RUN if [ "$ENV" = "PRODUCTION" ] ; then echo "no need to copy" ; \
else mkdir /app/target/release/ && cp /app/target/debug/clean_app \
/app/target/release/clean_app ; fi
```

到目前为止，我们的应用程序已经编译完成。我们涵盖的所有内容都与我们所使用的芯片类型无关，因此`x86_64_build`文件将包含我们在`aarch64_build`文件中刚刚展示的相同代码。对于这两个构建文件，我们也可以使用以下代码获取我们的 distroless 镜像：

```rs
FROM gcr.io/distroless/cc-debian10
```

现在，这是构建脚本不同的地方。在 ARM 芯片构建中，我们必须从之前的 Rust 镜像中复制所需的库到我们的 distroless 镜像中，如下所示：

```rs
COPY --chown=1001:1001 --from=build \
/usr/lib/aarch64-linux-gnu/libpq.so.5 \
/lib/aarch64-linux-gnu/libpq.so.5
. . .
COPY --chown=1001:1001 --from=build \
/lib/aarch64-linux-gnu/libcom_err.so.2 \
/lib/aarch64-linux-gnu/libcom_err.so.2
```

将它们全部包含在内将仅仅为本书提供无用的膨胀，而且，这些文件都可在本书的 GitHub 仓库中找到。然而，我们必须注意，每个复制的第一部分的目录是我们探索我们大型应用程序 Docker 镜像时列出的目录。第二部分是相同的路径；然而，如果路径开头有`/usr/lib/`，则缩短为`/lib/`。distroless 镜像中没有 shell 或用户。

一旦所有库都已复制，我们必须将我们的 Web 应用程序的静态二进制文件复制到镜像的根目录，暴露端口，并使用以下代码定义入口点，即静态二进制文件：

```rs
COPY --from=build /app/target/release/clean_app \
/usr/local/bin/clean_app
EXPOSE 8000
ENTRYPOINT ["clean_app"]
```

使用这种方法，我们的 distroless 镜像就完成了。目前，两个构建都已存储起来，我们将根据芯片类型在构建的 bash 脚本中获取它们。

注意

我们不必手动构建我们的 distroless 应用程序。相反，我们可以通过以下链接使用 Apko：[`github.com/chainguard-dev/apko`](https://github.com/chainguard-dev/apko)。

你可以将你选择的构建复制到存储库根目录下的 `Dockerfile` 文件名下。然后运行以下命令：

```rs
docker build . -t clean_app
```

当你列出你的 Docker 镜像时，你会看到这个镜像大小为 46.5 MB！这比 1.5 GB 减少了大量。在下一节中，我们将将这些构建文件包含在测试管道中。

# 构建一个干净的测试管道

当涉及到测试我们的应用程序时，我们希望将其打包到我们希望部署到服务器上的 Docker 镜像中，就像在服务器上一样在数据库上运行迁移，并运行一系列 Postman 请求和测试来模拟用户发起一系列请求。这可以通过 `scripts/run_full_release_test.sh` 文件中的一个 Bash 脚本来编排。首先，我们必须使用以下代码找出我们正在运行的芯片：

```rs
#!/usr/bin/env bash
# navigate to directory
SCRIPTPATH="$( cd "$(dirname "$0")" ; pwd -P )"
cd $SCRIPTPATH
if [ "$(uname -m)" = "arm64" ]
then
    cp ../builds/aarch64_build ../Dockerfile
else
    cp ../builds/x86_64_build ../Dockerfile
fi
```

在这里，我们根据芯片类型拉取正确的构建。根据你使用的计算机，这可能会不同。我使用的是 Mac M1，所以当我在终端中调用 `uname -m` 命令时，我得到一个 `arm64` 输出。如果你不是使用 arch 或 ARM 芯片，你不需要条件逻辑。相反，你只需要拉取 `x86_64_build` 文件。然后，我们必须移动到 `tests` 目录，并使用以下代码构建我们的 `docker-compose`：

```rs
cd ../tests
# build the images and network
docker-compose build --no-cache
docker-compose up -d
# wait until rust server is running
sleep 5
```

现在，我们可以运行我们的测试，并使用以下代码清理镜像：

```rs
# run the api tests
newman run to_do_items.postman_collection.json
# destroy the container and image
docker-compose down
docker image rm test_server
docker image rm init_test_db
docker image rm test_postgres
rm ../Dockerfile
```

在运行此代码之前，我们需要在我们的 `tests` 目录中构建我们的 `docker-compose`。我们的 `tests/docker-compose.yml` 文件具有以下结构：

```rs
version: "3.7"
services:
    test_server:
      . . .
    test_postgres:
      . . .
    test_redis:
      . . .
    init_test_db:
        . . .
```

首先，我们将关注测试服务器。鉴于我们正在运行测试，我们需要指向构建，将 `NOT PRODUCTION` 参数传递给构建，定义服务器要使用的环境变量，然后在启动之前等待 Redis 数据库处于运行状态。我们可以用以下代码来完成：

```rs
test_server:
  container_name: test_server
  image: test_auth_server
  build:
    context: ../
    args:
      ENV: "NOT_PRODUCTION"
  restart: always
  environment:
    - 'DB_URL=postgres://username:password@test_postgres:54
          32/to_do'
    - 'SECRET_KEY=secret'
    - 'EXPIRE_MINUTES=60'
    - 'REDIS_URL=redis://test_redis/'
  depends_on:
      test_redis:
        condition: service_started
  ports:
    - "8000:8000"
  expose:
    - 8000
```

如我们所见，`docker-compose` 是一个强大的工具。几个标签就可以实现一些复杂的编排。然后，我们可以使用以下代码移动到我们的数据库和 Redis 容器：

```rs
test_postgres:
  container_name: 'test_postgres'
  image: 'postgres'
  restart: always
  ports:
    - '5433:5432'
  environment:
    - 'POSTGRES_USER=username'
    - 'POSTGRES_DB=to_do'
    - 'POSTGRES_PASSWORD=password'
test_redis:
  container_name: 'test_redis'
  image: 'redis:5.0.5'
  ports:
    - '6379:6379'
```

这些数据库没有什么新意。然而，在最后一个服务中，我们创建了一个短暂的 init 容器，只是为了在服务器上运行迁移：

```rs
init_test_db:
    container_name: init_test_db
    image: init_test_db
    build:
      context: ../database
    environment:
      - 'DB_URL=postgres://username:password@test_postgres:
            5432/to_do'
    depends_on:
        test_postgres:
          condition: service_started
    restart: on-failure
```

如我们所见，在我们的 init 容器进行数据库迁移并关闭之前，必须在 `database` 目录中进行 Docker 构建。这意味着我们的 init 容器必须安装 `psql`，我们的迁移工具，以及 `rollup` 命令作为入口点。最初，我们在 `database/Dockerfile` 文件中使用以下代码安装我们需要的：

```rs
FROM postgres
RUN apt-get update \
  && apt-get install -y wget \
  && wget -O - https://raw.githubusercontent.com/\
  yellow-bird-consult/build_tools/develop/scripts/\
  install.sh | bash \
  && cp ~/yb_tools/database.sh ./database.sh
```

在这里，我们可以看到我们从 `postgres` Docker 镜像中获取了 `psql` 库。然后，我们安装 `wget` 并使用它来安装我们的迁移构建工具。最后，我们将 `database.sh` Bash 脚本从主目录复制到镜像的根目录，这样我们就不必担心别名问题。一旦我们配置了安装，我们必须将迁移 SQL 文件从当前目录复制到镜像的根目录，并将迁移命令定义为入口点：

```rs
WORKDIR .
ADD . .
CMD ["bash", "./database.sh", "db", "rollup"]
```

这将正常工作；然而，我们必须定义一个包含以下内容的 `database/.dockerignore` 文件，以避免环境变量被传递到镜像中：

```rs
.env
```

如果我们不阻止这个环境变量被复制到镜像中，那么我们通过 `docker-compose` 传递到初始化容器的任何变量都可能被覆盖。

我们现在已经准备好了所有需要的东西，所以我们只需要运行我们的 `scripts/run_full_release.sh` 脚本。这将产生一个关于构建镜像、启动 `docker-compose` 和通过 Newman 运行 API 测试的详细输出。最后的输出应该看起来像这样：

![图 13.5_B18722](img/Figure_13.5_B18722.jpg)

图 13.5 – 完整测试运行的结果

我们可以看到所有测试都已运行并通过。我们的 distroless 构建工作正常，我们的数据库初始化容器也进行了迁移。没有什么能阻止我们将这个基础设施部署到 AWS，区别在于指向 Docker Hub 上的镜像而不是本地构建。考虑到我们的 distroless 服务器很小，从 Docker Hub 拉取镜像并启动它将会非常快。

我们现在已经拥有了构建 GitHub 仓库持续集成的所有成分，以确保在创建拉取请求时运行测试。在下一节和最后一节中，我们将通过 **GitHub Actions** 配置持续集成。

# 使用 GitHub Actions 构建持续集成

当涉及到确保代码质量得到维护时，拥有一个每次拉取请求完成时都会运行的持续集成管道会很有用。我们可以通过 GitHub Actions 来实现这一点。必须注意的是，使用 GitHub Actions，你每个月可以获得几分钟的免费时间；然后，你必须为超出部分付费。所以，要小心，并留意你使用 GitHub Actions 的时间。

GitHub Actions 在执行任务时提供了灵活性。我们可以在合并或创建拉取请求以及创建问题时运行工作流程，还有更多。我们还可以选择使用分支的类型。在这个例子中，我们将仅关注任何分支上的拉取请求以运行单元测试和完整的集成测试。

要构建一个名为 `tests` 的工作流程，我们需要创建一个名为 `.github/workflows/run-tests.yml` 的文件。在这个文件中，我们将使用以下代码定义单元和集成测试的一般概述：

```rs
name: run tests
on: [pull_request]
jobs:
  run-unit-tests:
    . . .
  run-integration-test:
    . . .
```

在这里，我们定义了工作流程的名称和触发工作流程的条件，即所有分支的拉取请求。然后，我们定义了两个作业——一个用于运行单元测试，另一个用于运行集成测试。

每个作业都有步骤。我们也可以为我们的步骤定义依赖关系。我们可以使用以下代码定义我们的单元测试作业：

```rs
run-unit-tests:
    runs-on: ubuntu-latest
    timeout-minutes: 10
    steps:
      - uses: actions/checkout@v2
      - uses: actions-rs/toolchain@v1
        with:
          toolchain: stable
      - name: run the unit test
        run: |
          export SECRET_KEY="secret"
          export EXPIRE_MINUTES=60
          cargo test
```

在这里，我们使用了 `checkout` 动作。如果我们不使用 `checkout` 动作，我们将无法访问 GitHub 代码库中的任何文件。然后，我们导出单元测试运行所需的环境变量，然后使用 Cargo 运行单元测试。此外，请注意，我们定义了一个超时。定义超时很重要，以防万一某些操作陷入循环，你不会在一个作业中浪费所有时间。

现在，让我们继续到我们的集成测试作业：

```rs
run-integration-test:
    runs-on: ubuntu-latest
    timeout-minutes: 10
    steps:
      - uses: actions/checkout@v2
      - name: create environment build and run newman
        run: |
          cd tests
          cp ../builds/server_build ../Dockerfile
          docker-compose build --no-cache
          docker-compose up -d
          sleep 5
      - uses: actions/checkout@master
      - uses: matt-ball/newman-action@master
        with:
          collection:
              ./tests/cerberus.postman_collection.json
```

在这里，我们进入 `tests` 目录，获取服务器构建 Docker 文件，启动 `docker-compose`，然后使用 `newman` 动作运行 Newman 测试。如果我们发起一个拉取请求，动作将显示在拉取请求中。如果我们点击 GitHub Actions 按钮，我们可以访问状态和结果，如下面的截图所示：

![图 13.6 – GitHub Actions 选项](img/Figure_13.6_B18722.jpg)

图 13.6 – GitHub Actions 选项

然后，我们可以点击测试来查看作业的步骤，如下面的截图所示：

![图 13.7 – GitHub Actions 作业视图](img/Figure_13.7_B18722.jpg)

图 13.7 – GitHub Actions 作业视图

现在，如果我们点击作业中的某个步骤，它将展开。我们将看到我们的 Newman 测试是有效的：

![图 13.8 – Newman 步骤结果](img/Figure_13.8_B18722.jpg)

图 13.8 – Newman 步骤结果

如我们所见，我们的持续集成工作正常！现在，随着我们的代码库既干净又实用，我们已经完成了这一章。

# 摘要

我们终于完成了在 Rust 中构建一个 Web 应用程序的结构，并围绕应用程序构建基础设施，以便于新功能的持续开发和轻松集成。我们已经将我们的代码库结构化成一个干净且易于使用的版本，其中目录具有各自的功能。就像在结构良好的代码中一样，我们的结构良好的代码库可以让我们轻松地将测试和脚本添加到代码库中，也可以轻松移除。然后，我们使用纯 bash 来管理数据库迁移，没有任何代码依赖，这样我们就可以在任何应用程序上使用我们的迁移，无论使用的是哪种语言。接着，我们构建了初始化容器来自动化数据库迁移，即使部署在服务器或集群上也能工作。我们还优化了服务器的 Docker 构建，使其更加安全，并将大小从 1.5 GB 减少到 45 MB。之后，我们将构建和测试集成到一个自动化的管道中，当新代码合并到 GitHub 代码库时，该管道会被触发。

这自然地结束了构建 Web 应用程序并将其部署到服务器上的过程。在接下来的章节中，我们将更深入地探讨使用 Rust 进行 Web 编程，查看底层框架，以便我们可以在 TCP 套接字上构建自定义协议。这将使您能够构建用于 Web 服务器或甚至本地进程的底层应用程序。在下一章中，我们将探讨 Tokio 框架，它是异步程序（如 TCP 服务器）的构建块。

# 进一步阅读

+   数据库迁移文档和仓库：[`github.com/yellow-bird-consult/build_tools`](https://github.com/yellow-bird-consult/build_tools)

+   GitHub Actions 文档：[`docs.github.com/en/actions/guides`](https://docs.github.com/en/actions/guides)

# 问题

1.  bash 迁移工具使用增量单个数字整数来表示迁移。这种方法的重大缺点是什么？

1.  为什么无发行版服务器更安全？

1.  我们是如何在运行需要刷新令牌的新曼测试时移除对 Python 的需求的？

1.  使用环境变量作为配置值的优点是什么？

# 答案

1.  使用增量单个数字整数会使迁移容易发生冲突。因此，如果一个开发者在一个分支上编写迁移，而另一个开发者同时在另一个分支上编写迁移，当他们合并时，将会有迁移冲突。GitHub 应该能够处理这个问题，但重要的是要尽量减少迁移流量，合理规划数据库变更，并保持使用迁移的服务规模较小。然而，如果您对此有顾虑，请使用其他更重但具有更多安全措施的迁移工具。

1.  无发行版服务器没有外壳。这意味着如果黑客设法访问我们的服务器容器，他们无法运行任何命令或检查容器的内容。

1.  在登录请求中，我们在测试脚本中获取服务器返回的令牌，并将其分配给一个可以被其他请求访问的集合变量，从而消除了对 Python 的依赖。

1.  当我们将应用程序部署到云端时，环境变量更容易实现。例如，Kubernetes 的 ConfigMaps 使用环境变量将变量传递到 Docker 容器中。通过使用环境变量，在 AWS 上实现 Secrets Manager 等服务也更为简便。

# 第六部分：使用底层网络应用程序探索协议编程和异步概念

网络编程已经发展到了不仅仅是与数据库交互的简单应用。在本部分，我们通过介绍异步 Rust 的基础知识、Tokio 和 Hyper，来涵盖更高级的概念。通过 Tokio 和 Hyper，我们利用异步 Rust 和 actor 模型来实现异步设计，例如在不同线程之间传递 actor 的消息、在 Redis 中排队任务以便多个工作者消费，以及使用 Tokio 的帧和 TCP 端口处理字节流。在本部分结束时，你将能够在你的服务器上实现更复杂的事件处理解决方案来处理更复杂的问题。你还将具备如何实现异步 Rust 的实际知识，这是一个新兴领域。

本部分包括以下章节：

+   *第十四章*，*探索 Tokio 框架*

+   *第十五章*，*使用 Tokio 接受 TCP 流量*

+   *第十六章*，*在 TCP 之上构建协议*

+   *第十七章*，*使用 Hyper 框架实现 Actors 和异步*

+   *第十八章*，*使用 Redis 排队任务*
