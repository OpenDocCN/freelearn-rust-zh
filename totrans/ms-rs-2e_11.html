<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Logging</h1>
                </header>
            
            <article>
                
<p>Logging is an important, yet overlooked, practice in the software development life cycle. It is often integrated as an afterthought on facing the consequences of latent invalid states and errors that accumulate over time in software systems. Any moderate sized project should have logging support from the initial days of development.</p>
<p>In this chapter, we'll get to know why setting up logging in an application is important, the need for a logging framework, how to approach logging, and what crates are available in the Rust ecosystem to enable programmers to leverage the power of logging in their applications.</p>
<p>In this chapter, we will cover the following topics:</p>
<ul>
<li>What is logging and why do we need it?</li>
<li>The need for logging frameworks</li>
<li>Logging frameworks and their features</li>
<li>Exploring logging crates in Rust</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">What is logging and why do we need it?</h1>
                </header>
            
            <article>
                
<div class="packt_quote">"Generally, a program should say nothing unless and until it has something to say."                                                                                                                                                                                                                                                                  - Kernighan and Plauger</div>
<p>Before we talk about the importance of logging, let's define the term so that we have a better context for it. Logging is the practice of making an application record its activity at runtime to any output, where the individual record is called an <strong>event log</strong><em> </em>or simply a <strong>log</strong>. This is often associated with a timestamp describing when the event occurred. The event could be anything that changes the state of the program internally or externally. Logs help you in gaining insights on an application's runtime behavior over the course of time, or in getting more context on the application state when debugging a bug. They also find their use in generating analytics reports for business purposes. This is to say that the degree of utility logging provides to a user depends mainly on the application and consumers' needs.</p>
<p class="mce-root">Now, in an application without any kind of logging integration, there are limited options for us to know about the behavior of our program at runtime. We could use external utilities such as <em>htop</em> in Linux to monitor our program, but this gives us a view of the program from the outside and provides limited information regarding the internals.</p>
<p class="mce-root">Information from within a program while it's running is useful for debugging purposes or can be used for runtime performance analysis. In the case of fatal failures in our program, we can get to know about the whereabouts of our program when it crashes. At the very least, the program will leave a stack trace, thus providing a bit of context on where the program went wrong. However, there are classes of bugs and events that do not cause immediate problems but later turn into fatal errors, especially in long running systems. In these cases, event logs can help quickly narrow down the issue in the program. That's where adding logging capabilities to a program becomes tremendously helpful.</p>
<p class="mce-root">Systems that benefit greatly from logging and need to rely on event logs are web services, network servers, stream processing services, and similar long running systems. In these systems, individual event logs combined with subsequent logs over the course of time, when ingested and put into analysis by a log aggregation service, can provide useful statistics about the system.</p>
<p class="mce-root">For a commercial application such as a shopping website, you can leverage log analytics to get business insights, leading to better sales. In network servers, you can find useful activity logs to track any malicious attempts made to the server such as a distributed denial of service (DDoS) attack. Developers can assess the performance of their web API endpoints by getting request-response latency figures from the collected API request logs.</p>
<p class="mce-root">Logs also serve as an important debugging context and can minimize the time that's taken in performing root cause analysis during a debugging session, where you have time constraints to fix issues that happen in production.</p>
<p class="mce-root">Sometimes, logging is the only way to do this because debuggers are not always available or applicable. This is usually the case in distributed systems and multi-threaded applications. Anyone who has done a fair amount of development within these systems is quite aware of why logging is such an important part of the software development pipeline.</p>
<p>There are three broad categories of users who benefit greatly from the practice of application logging:</p>
<ul>
<li><strong>System administrators</strong>: They need to monitor server logs for any malfunction, for example, a hard disk crash or network failures.</li>
<li><strong>Developers</strong>: During development, integrating logs in the project can help cut down development time by a lot and can later be used to get insights into the way users use their application.</li>
<li><strong>Network security teams</strong>: In the case of any attack on a remote server, the security folks benefit greatly from logging as they can get to know how a certain attack was carried out by tracing the event logs that the victim server logged.</li>
</ul>
<p>Being a functional component in software development practices, and providing great value in the long run, integrating logging in a system demands dedicated frameworks, and we'll see why in the next section.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The need for logging frameworks</h1>
                </header>
            
            <article>
                
<p>We now know why logs are important. The next question however is how do we integrate logging capabilities in our application? The simplest and most straightforward way to get your application to log events is to have a bunch of print statements sprinkled in code at the required places. This way, we easily get our event logs to the standard output on our Terminal console, which gets our job done, but there's more to be desired. In quite a few cases, we also want our logs to persist for analysis at a later point in time. So, if we want to collect the output from our print statements to a file, we have to look for additional ways such as piping the output to a file using the shell output redirection facility, which is basically plumbing a different set of tools to get to the goal of getting logs from our application to different outputs. As it turns out, there are limitations to this approach.</p>
<p>You don't get to filter or turn off your print statements for cases where you don't need to log for a particular module. For that, you either have to comment them out or remove them and redeploy your services. Another limitation is that when your logging commands become large, you have to write and maintain shell scripts for collecting logs for multiple outputs. All of this gets unwieldy and less maintainable very quickly. Using a print statement is a quick and dirty logging practice and is not a very scalable solution. What we need is a better and more customizable architecture for application logging. The scalable and cleaner way is to have a dedicated logger that removes all of these limitations, and that is why logging frameworks exist. In addition to basic logging needs, these frameworks also provide additional features such as log file rotations when reaching a certain size limit, setting logging frequency, granular log configuration per module, and much more.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Logging frameworks and their key features</h1>
                </header>
            
            <article>
                
<p>There are a wide variety of logging frameworks offered by mainstream languages. Some notable ones to mention include <em>Log4j</em> from Java, <em>Serilog</em> from C#, and <em>Bunyan</em> from Node.js. From the time of proliferation of these frameworks, and from their use cases, there are similarities in what features a logging framework should provides to its users. The following are the most desirable properties that logging frameworks should have:</p>
<ul>
<li><strong>Fast</strong>: Logging frameworks must ensure that they are not doing expensive operations when logging and should be able to process efficiently using as few CPU cycles as possible. For instance, in Java, if your log statements contain objects with lots of <kbd>to_string()</kbd> calls to them to just interpolate the object within the log message, then that's an expensive operation. This is considered an inefficient practice in Java.</li>
<li><strong>Configurable outputs</strong><span>: It's very limiting to have the ability to log messages only to standard output. It stays only until the shell session and you need to manually paste the logs to a file to use them later. Logging frameworks should provide the ability to support multiple outputs, such as a file or even a network socket.</span></li>
<li><strong>Log levels:</strong> <span>The prominent feature of logging frameworks that makes them stand out from normal print-based logging is</span> the ability to control what and when things get logged. <span>This is usually implemented using the idea of</span> <em>log levels</em><span>. A log level is a configurable filter that's usually implemented as a type that is checked for before sending the log output anywhere. The levels are usually in the following order, from lowest priority to highest priority:</span>
<ul>
<li><strong>Error</strong>: This level is suitable for logging events that are critical and those that may lead to invalid outputs from the application.</li>
<li><strong>Warn</strong>: This level is suitable for events for which you have taken measures, but also want to know when it happens to take actions later if they occur frequently.</li>
<li><strong>Info</strong>: This level can be used for normal events such as printing the application version, user logins, connection successful messages, and so on.</li>
<li><strong>Debug</strong>: As the name suggests, this is used to support debugging. It is useful for monitoring the values of variables and how they get manipulated in different code paths when debugging.</li>
<li><strong>Trace</strong>: This level is used when you want a step-by-step execution of your algorithm or any non-trivial function that you wrote. Method invocations with parameter and return values are things that can be put as trace logs.</li>
</ul>
</li>
</ul>
<p>Some of these names might differ slightly across frameworks, but the priorities they signify are mostly the same. In major logging frameworks, these levels are set by the logger during its initialization and any subsequent logging invocations check for the set level and filters out the logs accordingly. For example, a <kbd>Logger</kbd> object with the call to <kbd>Logger.set_level(INFO)</kbd> would allow all logs using levels above <kbd>Info</kbd> to be logged, while ignoring <kbd>Debug</kbd> and <kbd>Trace</kbd> logs.</p>
<ul>
<li><strong>Log filtering</strong>: It should be easy to log only the desired places in code and to turn off other logs based on the severity/importance of events.</li>
<li><strong>Log Rotation</strong><span>: When logging to a file, it is imminent that prolonged logging will fill up disk space. A logging framework should provide facilities to limit the log file size and allow for the deletion of older log files.</span></li>
<li><strong>Asynchronous logging</strong><span>: Logging invocations on the main thread have the possibility of blocking the main code from making progress. Even though an efficient logger would do as little as possible, it still does a blocking I/O call between the actual code. As such, it is desirable that most logging invocations are offloaded to a dedicated logger thread.</span></li>
<li><strong>Log message attributes</strong><span>: Another thing worth mentioning are the attributes on log messages that get sent to the logging API. At a minimum, a logging framework should provide the following attributes to log messages:</span>
<ul>
<li><strong>Timestamp</strong>: The time at which the event happened</li>
<li><strong>Log Severity</strong>: The importance of the message, for example, Error, Warning, Information, Debug, and so on</li>
<li><strong>Event location</strong>: The place in the source code where the event happened</li>
<li><strong>Message</strong>: The actual event message that describes what happened</li>
</ul>
</li>
</ul>
<p>Depending on these features, there are differences in how logging frameworks approach logging. Let's explore them next.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Approaches to logging</h1>
                </header>
            
            <article>
                
<p>When integrating logging in an application, we need to decide what information to log and how granular it should be. If there are too many logs, we lose the ability of easily finding relevant information in the sea of noise and if there's not enough log messages, we risk missing that one important event. We also need to think about how to organize information in our log message so that it becomes easier to search and analyze it later. These questions lead to logging frameworks that are broadly divided into two categories: unstructured logging and structured logging.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Unstructured logging</h1>
                </header>
            
            <article>
                
<p>The usual way to approach logging is the practice of logging events as plain strings and shoving any fields from required values into the log message by converting them into strings. This form of logging is called unstructured logging as the information in the log message doesn't have any predefined structure or order. Unstructured logging serves well for most use cases, but it has its downsides too.</p>
<p>After collecting log messages, a common use case with them is to be able search for them for a particular event at a later point in time. However, the retrieval of unstructured logs from a collection of logs can be a pain. The problem with unstructured log messages is that they don't have any predictable format and it becomes quite resource heavy for a log aggregation service to sift through all of the raw log messages using simple text matching queries. You need to write regular expressions that match on a chunk of text or grep them from the command line to get that particular event. With an increasing amount of logs, this approach eventually becomes a bottleneck in getting useful information from log files. The other approach is to log messages that have a predefined structure and for that we have structured logging.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Structured logging</h1>
                </header>
            
            <article>
                
<p>Structured logging is a scalable and better alternative to unstructured logging. As the name suggests, structured logging defines a structure and formatting to your log messages and every log message is guaranteed to have this format. The advantage of this is that it becomes very easy for log aggregation services to build a search index and present any particular event to the user, regardless of the amount of messages they have. There are quite a few structured logging frameworks such as Serilog in C# that provide support for structured logging. These frameworks provide a plugin-based log output abstraction called <em>Sinks. </em>Sinks are how you direct where you want your logs to be sent. A Sink can be your Terminal, a file, a database, or a log aggregation service such as logstash.</p>
<p>Structured logging frameworks know how to serialize a certain object and can do so in a proper format. They also automate the formatting of log messages by providing hierarchical log outputs, depending on which component the log is emitted from. The downside to structured logging is that it can be a bit time-consuming to integrate it into your application as you have to decide on the hierarchy and the format of your logs beforehand.</p>
<p>It's often a trade-off when choosing between structured logging and unstructured logging. Complex projects that log heavily can benefit from structured logging as they can get semantic and efficiently searchable logs from their modules, while small to moderate size projects can make do with unstructured logging. Ultimately, it's the application's needs that should decide how you integrate logging in your application. In the next section, we'll explore a couple of unstructured logging frameworks as well as structure logging frameworks in Rust that you can use for getting your application to log events.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Logging in Rust</h1>
                </header>
            
            <article>
                
<p>Rust has quite a few flexible and extensive logging solutions. Like popular logging frameworks in other languages, the logging ecosystem here is split into two parts:</p>
<ul>
<li><strong>Logging facade</strong>: This part is implemented by the <kbd>log</kbd> crate and provides an implementation agnostic logging API. While other frameworks implement logging APIs as functions or methods on some object, the log crate provides us with macro-based logging APIs, which are categorized by log levels to log events to a configured log output.</li>
<li><strong>Logging implementations</strong><span>: These are community developed crates that provide actual logging implementation in terms of where the output goes and how it happens. There are many such crates, such as</span> <kbd>env_logger</kbd><span>,</span> <kbd>simple_logger</kbd><span>,</span> <kbd>log4rs</kbd><span>, and </span><kbd>fern</kbd><span>. We'll visit a couple of them in a moment. Crates that come under this category are meant to be used only by binary crates, that is, executables.</span></li>
</ul>
<p>This separation of concerns between the logging API and the underlying mechanism by which logs go to an output is done so that developers don't need to change their log statements in code and can easily swap the underlying logging implementation on an as-needed basis.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">log – Rust's logging facade</h1>
                </header>
            
            <article>
                
<p>The <kbd>log</kbd> crate comes from the <em>rust-lang nursery</em> organization on GitHub and is managed by the community at <a href="https://github.com/rust-lang-nursery/log">https://github.com/rust-lang-nursery/log</a>. It provides separate macros for logging at different log levels such as <kbd>error!</kbd>, <kbd>warn!</kbd>, <kbd>info!</kbd>, <kbd>debug!</kbd>, and <kbd>trace!</kbd>, in the order of the most priority to the least priority. These macros are major points of interaction for consumers of this crate. They internally call the <kbd>log!</kbd> macro in this crate, which does all the bookkeeping such as checking for the log level and formatting log messages. The core component of this crate is the <kbd>log</kbd> trait that other backend crates implement. The trait defines operations that are required for a logger and has other APIs, such as for checking whether logging is enabled or for flushing any buffered logs.</p>
<p>The log crate also provides a maximum log level constant called <kbd>STATIC_MAX_LEVEL</kbd>, which can be configured project wide at compile time. With this constant, you can set the log level of an application statically using cargo feature flags, which allows for the compile time filtering of logs for the application and all of its dependencies. These level filters can be set in <kbd>Cargo.toml</kbd> separately for debug and release builds: <kbd>max_level_&lt;LEVEL&gt;</kbd> (debug) and <kbd>release_max_level_&lt;LEVEL&gt;</kbd> (release). In binary projects, you can specify the dependency on the <kbd>log</kbd> crate with compile time log levels as follows:</p>
<pre>[dependencies]<br/>log = "0.4.6", features = ["release_max_level_error", "max_level_debug"] }</pre>
<p>It's a good practice to set this constant to a desired value as, by default, the level is set to <kbd>Off</kbd>. It also allows the log macros to optimize away any log invocations at disabled levels. Libraries should only link to the <kbd>log</kbd> crate and not any logger implementation crate as binary crates should have control over what to log and how to log it. Using this crate solely in your application won't produce any log output as you need to use logging crates such as <kbd>env_logger</kbd> or <kbd>log4rs</kbd> along with it.</p>
<p>To see the <kbd>log</kbd> crate in action, we'll build a library crate by running <kbd>cargo new user_auth --lib</kbd> and adding <kbd>log</kbd> as a dependency in our <kbd>Cargo.toml</kbd> file:</p>
<pre># user_auth/Cargo.toml<br/><br/>[dependencies]<br/>log = "0.4.6"</pre>
<p>This crate simulates a dummy user sign-in API. Our <kbd>lib.rs</kbd> file has a <kbd>User</kbd> struct, which has a method called <kbd>sign_in</kbd>:</p>
<pre>// user_auth/lib.rs<br/><br/>use log::{info, error};<br/><br/>pub struct User {<br/>    name: String,<br/>    pass: String<br/>}<br/><br/>impl User {<br/>    pub fn new(name: &amp;str, pass: &amp;str) -&gt; Self {<br/>        User {name: name.to_string(), pass: pass.to_string()}<br/>    }<br/><br/>    pub fn sign_in(&amp;self, pass: &amp;str) {<br/>        if pass != self.pass {<br/>            info!("Signing in user: {}", self.name);<br/>        } else {<br/>            error!("Login failed for user: {}", self.name);<br/>        }<br/>    }<br/>}</pre>
<p>In the <kbd>sign_in</kbd> method, we have a couple of log invocations on whether the sign in succeeded or failed. We'll use this library crate together with a binary crate thats creates a <kbd>User</kbd> instance and calls the <kbd>sign_in</kbd> method. Since depending on the <kbd>log</kbd> crate itself won't produce any log output, we'll use the <kbd>env_logger</kbd> as the logging backend for this example. Let's explore <kbd>env_logger</kbd> first.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The env_logger</h1>
                </header>
            
            <article>
                
<p><kbd>env_logger</kbd> is a simple logging implementation that allows you to control logs to <kbd>stdout</kbd> or <kbd>stderr</kbd> through the <kbd>RUST_LOG</kbd> environment variable. The values of this environment variable are comma-separated logger strings that correspond to module names and log levels. To demonstrate <kbd>env_logger</kbd>, we'll create a new binary crate by running <kbd>cargo new env_logger_demo</kbd> and specifying dependencies for <kbd>log</kbd>, <kbd>env_logger</kbd>, and our <kbd>user_auth</kbd> library, which we created in the previous section. Here's our <kbd>Cargo.toml</kbd> file:</p>
<pre># env_logger_demo/Cargo.toml<br/><br/>[dependencies]<br/>env_logger = "0.6.0"<br/>user_auth = { path = "../user_auth" }<br/>log = { version = "0.4.6", features = ["release_max_level_error", "max_level_trace"] }</pre>
<p>Here's our <kbd>main.rs</kbd> file:</p>
<pre>// env_logger_demo/src/main.rs<br/><br/>use log::debug;<br/><br/>use user_auth::User;<br/><br/>fn main() {<br/>    env_logger::init();<br/>    debug!("env logger demo started");<br/>    let user = User::new("bob", "super_sekret");<br/>    user.sign_in("super_secret");<br/>    user.sign_in("super_sekret");<br/>}</pre>
<p>We create our <kbd>User</kbd> instance and call <kbd>sign_in</kbd>, passing in our password. The first sign in attempt is a failed one, which will get logged as an error. We can run it by setting the <kbd>RUST_LOG</kbd> environment variable, followed by <kbd>cargo run</kbd>:</p>
<pre>RUST_LOG=user_auth=info,env_logger_demo=info cargo run</pre>
<p>We set the logs from the <kbd>user_auth</kbd> crate to <kbd>info</kbd> and the levels above it, while logs from our <kbd>env_logger_demo</kbd> crate are set to <kbd>debug</kbd> and above.</p>
<p>Running this gives us the following output:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/d1d12879-ec6b-44aa-8b5a-5ec66e5cd8bf.png"/></p>
<p>The <kbd>RUST_LOG</kbd> accepts the <kbd>RUST_LOG=path::to_module=log_level[,]</kbd> pattern, where <kbd>path::to_module</kbd> specifies the logger and should be a path to any module with the crate name as the base. The <kbd>log_level</kbd> is any of the log levels that are defined in the log crate. <kbd>[,]</kbd> at the end indicates that we can optionally have as many of these logger specifications separated by a comma.</p>
<p>An alternative way to run the preceding program is by setting the environment variable within the code itself using the <kbd>set_var</kbd> method from the <kbd>env</kbd> module in the standard library:</p>
<pre><span>std::env::set_var("RUST_LOG", "user_auth=info,env_logger_demo=info cargo run");<br/>env_logger::init();</span></pre>
<p>This produces the same output as before. Next, let's take a look at a more complex and highly configurable logging crate.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">log4rs</h1>
                </header>
            
            <article>
                
<p>The <kbd>log4rs</kbd> crate, as the name suggests, is inspired by the popular <kbd>log4j</kbd> library from Java. This crate is much more powerful than <kbd>env_logger</kbd> and allows for granular logger configuration via YAML files.</p>
<p>We'll build two crates to demonstrate integrating logging via the <kbd>log4rs</kbd> crate. One will be a library crate, <kbd>cargo new my_lib --lib</kbd>, and the other will be our binary crate, <kbd>cargo new my_app</kbd>, which uses <kbd>my_lib</kbd>. A cargo workspace directory, called <kbd>log4rs_demo</kbd>, contains both of our crates.</p>
<p>Our <kbd>my_lib</kbd> crate has the following contents in the <kbd>lib.rs</kbd> file:</p>
<pre>// log4rs_demo/my_lib/lib.rs<br/><br/>use log::debug;<br/><br/>pub struct Config;<br/><br/>impl Config {<br/>    pub fn load_global_config() {<br/>        debug!("Configuration files loaded");<br/>    }<br/>}</pre>
<p>It has a struct called <kbd>Config</kbd> with a dummy method called <kbd>load_global_config</kbd>, which logs a message at the debug level. Next, our <kbd>my_app</kbd> crate contains the following contents in the <kbd>main.rs</kbd> file:</p>
<pre class="mce-root">// log4rs_demo/my_app/src/main.rs<br/><br/>use log::error;<br/><br/>use my_lib::Config;<br/><br/>fn main() {<br/>    log4rs::init_file("config/log4rs.yaml", Default::default()).unwrap();<br/>    error!("Sample app v{}", env!("CARGO_PKG_VERSION"));<br/>    Config::load_global_config();<br/>}</pre>
<p>In the preceding code, we initialize our <kbd>log4rs</kbd> logger via the <kbd>init_file</kbd> method, passing in the path to the <kbd>log4rs.yaml</kbd> config file. Next, we log a dummy error message, thus printing the app version. Following that, we call <kbd>load_global_config</kbd>, which logs another message. The following is the content of the <kbd>log4rs.yaml</kbd> configuration file:</p>
<pre># log4rs_demo/config/log4rs.yaml<br/><br/>refresh_rate: 5 seconds<br/><br/>root:<br/>  level: error<br/>  appenders:<br/>    - stdout<br/>appenders:<br/>  stdout:<br/>    kind: console<br/>  my_lib_append:<br/>    kind: file<br/>    path: "log/my_lib.log"<br/>    encoder:<br/>      pattern: "{d} - {m}{n}"<br/><br/>loggers:<br/>  my_lib:<br/>    level: debug<br/>    appenders:<br/>      - my_lib_append</pre>
<p>Let's go through this line by line. The first line, <kbd>refresh_rate</kbd>, specifies the time interval after which <kbd>log4rs</kbd> reloads the configuration file to account for any changes that are made to this file. This means that we can modify any value in our YAML file and <kbd>log4rs</kbd> will dynamically reconfigure its loggers for us. Then, we have the <kbd>root</kbd> logger, which is the parent of all loggers. We specify the default level as <kbd>error</kbd> and the appender as <kbd>stdout</kbd>, which is defined below it.</p>
<p>Next, we have the <kbd>appenders</kbd> section. Appenders are places where logs go. We have specified two appenders: <kbd>stdout</kbd>, which is of <kbd>console</kbd> type, and <kbd>my_lib_append</kbd>, which is a <kbd>file</kbd> appender, which includes information about the path of the file and the log pattern to use under the <kbd>encoder</kbd> section.</p>
<p>Next, there is the section of <kbd>loggers</kbd> where we can define loggers based on the crates or modules with different levels. We defined a logger called <kbd>my_lib</kbd>, which corresponds to our <kbd>my_lib</kbd> crate, with the <kbd>debug</kbd> level and appender as <kbd>my_lib_append</kbd>. This means that any logs from the <kbd>my_lib</kbd> crate will go to the <kbd>my_lib.log</kbd> file, as specified by the <kbd>my_lib_append</kbd> appender.</p>
<p>By running <kbd>cargo run</kbd> in the <kbd>log4rs_demo</kbd> directory, we get the following output:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/613c23dc-a436-4634-ab2e-e1cfab50130e.png"/></p>
<p>That was a brief intro to <kbd>log4rs</kbd>. If you want to explore more on configuring these logs, head over to the documentation page at <a href="https://docs.rs/log4rs">https://docs.rs/log4rs</a>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Structured logging using slog</h1>
                </header>
            
            <article>
                
<p>All of the aforementioned crates are quite useful and are ideal for most use cases, but they do not support structured logging. In this section, we'll see how structured logging can be integrated into our application using the <kbd>slog</kbd> crate, one of the few popular structured logging crates in the Rust ecosystem. For this demo, we'll create a new project by running <kbd>cargo new slog_demo</kbd>, which simulates a shooting game.</p>
<p>We'll need the following dependencies in our <kbd>Cargo.toml</kbd> file:</p>
<pre># slog_demo/Cargo.toml<br/><br/>[dependencies]<br/>rand = "0.5.5"<br/>slog = "2.4.1"<br/>slog-async = "2.3.0"<br/>slog-json = "2.2.0"</pre>
<p>The <kbd>slog</kbd> framework is ideal for moderate to big projects where there is lot of interplay between modules as it helps to integrate detailed logs for the long-term monitoring of events. It works on the idea of providing hierarchical and composable logging configuration in the application and allows for semantic event logging. There are two important concepts under <kbd>slog</kbd> that you need to be aware of to successfully use the crate: <em>Loggers</em> and <em>Drains</em>. Logger objects are used to log events while a Drain is an abstraction specifying a place where the log messages go and how they get there. This can be your standard output, a file, or a network socket. Drains are similar to what you would call a <kbd>Sink</kbd> in the <em>Serilog</em> framework in C#.</p>
<p>Our demo simulates game events from dummy game entities based on their actions. The entities have a parent-child relationship in the game, where we can attach the hierarchical logging capability in them quite easily with <kbd>slog</kbd> framework's structural logging configuration. We'll get to know about this when we see the code. At the root level, we have the <kbd>Game</kbd> instance, for which we can define a root logger to provide a baseline context in our log messages, such as the game name and version. So, we'll create a root logger attached to the <kbd>Game</kbd> instance. Next, we have the <kbd>Player</kbd> and <kbd>Enemy</kbd> types, which are child entities to the <kbd>Game</kbd>. These become child loggers of the root logger. Then, we have weapons for both the enemy and the player, which become the child logger for the player and the enemy logger. As you can see, setting up <kbd>slog</kbd> is a bit more involved than the previous frameworks we looked at.</p>
<p>Along with <kbd>slog</kbd> as the base crate, we'll also use the following crates in our demo:</p>
<ul>
<li><kbd>slog-async</kbd>: Provides an asynchronous logging drain that decouples logging calls from the main thread.</li>
<li><kbd>slog-json</kbd><span>: A drain that outputs messages to any</span> <kbd>Writer</kbd> <span>as JSON. We'll use</span> <kbd>stdout()</kbd> <span>as the</span> <kbd>Writer</kbd> <span><span>instance for this demo.</span></span> </li>
</ul>
<p>Let's take a look at our <kbd>main.rs</kbd> file:</p>
<pre>// slog_demo/main.rs<br/><br/>#[macro_use]<br/>extern crate slog;<br/><br/>mod enemy;<br/>mod player;<br/>mod weapon;<br/><br/>use rand::Rng;<br/>use std::thread;<br/>use slog::Drain;<br/>use slog::Logger;<br/>use slog_async::Async;<br/>use std::time::Duration;<br/>use crate::player::Player;<br/>use crate::enemy::Enemy;<br/><br/>pub trait PlayingCharacter {<br/>    fn shoot(&amp;self);<br/>}<br/><br/>struct Game {<br/>    logger: Logger,<br/>    player: Player,<br/>    enemy: Enemy<br/>}<br/><br/>impl Game {<br/>    fn simulate(&amp;mut self) {<br/>        info!(self.logger, "Launching game!");<br/>        let enemy_or_player: Vec&lt;&amp;dyn PlayingCharacter&gt; = vec![&amp;self.enemy, &amp;self.player];<br/>        loop {<br/>            let mut rng = rand::thread_rng();<br/>            let a = rng.gen_range(500, 1000);<br/>            thread::sleep(Duration::from_millis(a));<br/>            let player = enemy_or_player[{<br/>                if a % 2 == 0 {1} else {0}<br/>            }];<br/>            player.shoot();<br/>        }<br/>    }<br/>}</pre>
<p>In the preceding code, we have a bunch of <kbd>use</kbd> statements, followed by our <kbd>PlayingCharacter</kbd> trait, which is implemented by our <kbd>Player</kbd> and <kbd>Enemy</kbd> structs. Our <kbd>Game</kbd> struct has a <kbd>simulate</kbd> method, which simply loops and randomly sleeps, thereby selecting at random either the player or the enemy before calling the <kbd>shoot</kbd> method on them. Let's continue down the same file:</p>
<pre>// slog_demo/src/main.rs<br/><br/>fn main() {<br/>    let drain = slog_json::Json::new(std::io::stdout()).add_default_keys()<br/>                                                       .build()<br/>                                                       .fuse();<br/>    let async_drain = Async::new(drain).build().fuse();<br/>    let game_info = format!("v{}", env!("CARGO_PKG_VERSION"));<br/>    let root_log_context = o!("Super Cool Game" =&gt; game_info);<br/>    let root_logger = Logger::root(async_drain, root_log_context);<br/>    let mut game = Game { logger: root_logger.clone(),<br/>                          player: Player::new(&amp;root_logger, "Bob"),<br/>                          enemy: Enemy::new(&amp;root_logger, "Malice") };<br/>    game.simulate()<br/>}</pre>
<p>In <kbd>main</kbd>, we first create our <kbd>drain</kbd> using <kbd>slog_json::Json</kbd>, which can log messages as JSON objects, followed by passing it to another drain, <kbd>Async</kbd>, which will offload all log invocations to a separate thread. Then, we create our <kbd>root_logger</kbd> by passing in our <kbd>drain</kbd> with an initial context for our log messages using the convenient <kbd>o!</kbd> macro. In this macro, we simply print the name and version of our game using the <kbd>CARGO_PKG_VERSION</kbd> environment variable. Next, our <kbd>Game</kbd> struct takes our root logger and <kbd>enemy</kbd> and <kbd>player</kbd> instances. To the <kbd>Player</kbd> and <kbd>Enemy</kbd> instances, we pass a reference to the <kbd>root_logger</kbd>, using which they create their child loggers. Then, we call <kbd>simulate</kbd> on our game instance.</p>
<p>The following is the content of <kbd>player.rs</kbd>:</p>
<pre>// slog_demo/src/player.rs<br/><br/>use slog::Logger;<br/><br/>use weapon::PlasmaCannon;<br/>use PlayingCharacter;<br/><br/>pub struct Player {<br/>    name: String,<br/>    logger: Logger,<br/>    weapon: PlasmaCannon<br/>}<br/><br/>impl Player {<br/>    pub fn new(logger: &amp;Logger, name: &amp;str) -&gt; Self {<br/>        let player_log = logger.new(o!("Player" =&gt; format!("{}", name)));<br/>        let weapon_log = player_log.new(o!("PlasmaCannon" =&gt; "M435"));<br/>        Self {<br/>            name: name.to_string(),<br/>            logger: player_log,<br/>            weapon: PlasmaCannon(weapon_log),<br/>        }<br/>    }<br/>}</pre>
<p>Here, our <kbd>new</kbd> method on <kbd>Player</kbd> gets the root <kbd>logger</kbd>, to which it adds its own context with the <kbd>o!</kbd> macro. We also create a logger for <kbd>weapon</kbd> and pass the player logger to it, which add its own information such as the ID of the weapon. Finally, we return our configured <kbd>Player</kbd> instance:</p>
<pre>impl PlayingCharacter for Player {<br/>    fn shoot(&amp;self) {<br/>        info!(self.logger, "{} shooting with {}", self.name, self.weapon);<br/>        self.weapon.fire();<br/>    }<br/>}</pre>
<p>We also implement the <kbd>PlayingCharacter</kbd> trait for our <kbd>Player</kbd>.</p>
<p>Next is our <kbd>enemy.rs</kbd> file, which is identical to everything we had in <kbd>player.rs</kbd>:</p>
<pre>// slog_demo/src/enemy.rs<br/><br/>use weapon::RailGun;<br/>use PlayingCharacter;<br/>use slog::Logger;<br/><br/>pub struct Enemy {<br/>    name: String,<br/>    logger: Logger,<br/>    weapon: RailGun<br/>}<br/><br/>impl Enemy {<br/>    pub fn new(logger: &amp;Logger, name: &amp;str) -&gt; Self {<br/>        let enemy_log = logger.new(o!("Enemy" =&gt; format!("{}", name)));<br/>        let weapon_log = enemy_log.new(o!("RailGun" =&gt; "S12"));<br/>        Self { <br/>            name: name.to_string(),<br/>            logger: enemy_log,<br/>            weapon: RailGun(weapon_log)<br/>        }<br/>    }<br/>}<br/><br/>impl PlayingCharacter for Enemy {<br/>    fn shoot(&amp;self) {<br/>        warn!(self.logger, "{} shooting with {}", self.name, self.weapon);<br/>        self.weapon.fire();<br/>    }<br/>}</pre>
<p>Then, we have our <kbd>weapon.rs</kbd> file, which contains two weapons that are used by the enemy and player instances:</p>
<pre>// slog_demo/src/weapon.rs<br/><br/>use slog::Logger;<br/>use std::fmt;<br/><br/>#[derive(Debug)]<br/>pub struct PlasmaCannon(pub Logger);<br/><br/>impl PlasmaCannon {<br/>    pub fn fire(&amp;self) {<br/>        info!(self.0, "Pew Pew !!");<br/>    }<br/>}<br/><br/>#[derive(Debug)]<br/>pub struct RailGun(pub Logger);<br/><br/>impl RailGun {<br/>    pub fn fire(&amp;self) {<br/>        info!(self.0, "Swoosh !!");<br/>    }<br/>}<br/><br/>impl fmt::Display for PlasmaCannon {<br/>    fn fmt(&amp;self, f: &amp;mut fmt::Formatter) -&gt; fmt::Result {<br/>        write!(f, stringify!(PlasmaCannon))<br/>    }<br/>}<br/><br/>impl fmt::Display for RailGun {<br/>    fn fmt(&amp;self, f: &amp;mut fmt::Formatter) -&gt; fmt::Result {<br/>        write!(f, stringify!(RailGun))<br/>    }<br/>}</pre>
<p>That's all that is required for our game simulation. We can now run it by invoking <kbd>cargo run</kbd>. Here's the output on my machine:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/1f3dabf7-78a6-43d3-bd3b-3b3001aa49c4.png"/></p>
<p>As you can see, our game entities send log messages, which are then formatted and output as JSON with the help of <kbd>slog</kbd> and its drains. Similar to the JSON drain we used previously, there are many such drains that have been built by the community for <kbd>slog</kbd>. We can have a drain that outputs log messages directly to a log aggregation service, which knows how to handle JSON data and can easily index them for the efficient retrieval of logs. The pluggable and composable nature of <kbd>slog</kbd> makes it stand out from other logging solutions. With this demo, we have come to the end of the logging story in Rust. However, there are other more interesting logging frameworks for you to explore, and you can find them at <a href="http://www.arewewebyet.org/topics/logging/">http://www.arewewebyet.org/topics/logging/</a>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In this chapter, we learned about the importance of logging in software development and the ways of approaching it, including what characteristics to look for when choosing a logging framework. We also got to know about unstructured and structured logging, their pros and cons, and explored the available crates in the Rust ecosystem to integrate logging into our applications.</p>
<p>The next chapter will be about network programming, where we will explore the built-in facilities and crates that Rust provides to create efficient applications that communicate with one another.</p>


            </article>

            
        </section>
    </body></html>