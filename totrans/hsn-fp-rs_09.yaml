- en: Performance, Debugging, and Metaprogramming
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Writing fast efficient code can be something to be proud of. It also might be
    a waste of your employer's resources. In the performance section, we will explore
    how to tell the difference between the two and give best-practices, processes,
    and guidelines to keep your application slim.
  prefs: []
  type: TYPE_NORMAL
- en: In the debugging section, we offer tips to help find and resolve bugs faster.
    We also introduce the concept of defensive coding, which describes techniques
    and habits to prevent or isolate potential issues.
  prefs: []
  type: TYPE_NORMAL
- en: In the metaprogramming section, we explain macros and other features that are
    similar to macros. Rust has a fairly sophisticated metaprogramming system that
    allows the user or libraries to extend the language with automatic code generation
    or custom syntax forms.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will learn the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Recognizing and applying good performant code practices
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Diagnosing and improving performance bottlenecks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Recognizing and applying good defensive coding practices
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Diagnosing and resolving software bugs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Recognizing and applying metaprogramming techniques
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A recent version of Rust is necessary to run the examples provided:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://www.rust-lang.org/en-US/install.html](https://www.rust-lang.org/en-US/install.html)'
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter''s code is available on GitHub:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/PacktPublishing/Hands-On-Functional-Programming-in-RUST](https://github.com/PacktPublishing/Hands-On-Functional-Programming-in-RUST)'
  prefs: []
  type: TYPE_NORMAL
- en: Specific installation and build instructions are also included in each chapter's
    `README.md` file.
  prefs: []
  type: TYPE_NORMAL
- en: Writing faster code
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Premature optimization is the root of all evil
  prefs: []
  type: TYPE_NORMAL
- en: – Donald Knuth
  prefs: []
  type: TYPE_NORMAL
- en: A good software design tends to create faster programs, while a bad software
    design tends to create slower programs. If you find yourself asking, "W*hy is
    my program slow?, then first ask yourself, Is my program disorderly?*"
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we describe some performance tips. These are generally good
    habits when programming in Rust that will coincidentally lead to improved performance.
    If your program is slow, then first check to see whether you are violating one
    of these principles.
  prefs: []
  type: TYPE_NORMAL
- en: Compiling with release mode
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This is a really simple suggestion that you should know about if you are at
    all concerned about performance.
  prefs: []
  type: TYPE_NORMAL
- en: 'Rust normally compiles in debug mode, which is slow:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Rust optionally compiles in release mode, which is fast:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is a comparison using debug mode for a toy program:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'The following is the release mode:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Release mode is 98% more efficient with regard to CPU usage for this example.
  prefs: []
  type: TYPE_NORMAL
- en: Doing less work
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Faster programs do less. All optimization is a process of searching for work
    that doesn't need to be done, and then not doing it.
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, the smallest programs fewer resources less. All space optimization
    is a process of searching for resources that don't need to be used, and then not
    using them.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, don''t collect an iterator when you don''t need the result, consider
    the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Needlessly collecting the result of the iterator makes the code 27% slower compared
    to code that just drops the result.
  prefs: []
  type: TYPE_NORMAL
- en: 'Memory allocation is similar. Well-designed code preferring pure functions
    and avoiding side-effects will tend to minimize memory usage. In contrast, messy
    code can lead to old data hanging around. Rust memory safety does not extend to
    preventing memory leaks. Leaks are considered safe code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: The `forget` function is seldom used. Similarly, memory leaks are permitted
    but sufficiently discouraged that they are somewhat uncommon. Rust memory management
    tends to be such that by the time you cause a memory leak you are probably waist-deep
    in other poor design decisions.
  prefs: []
  type: TYPE_NORMAL
- en: However, unsused memory is not uncommon. If you don't keep track of what variables
    you are actively using, then old variables will likely remain in scope. This is
    not the typical definition of a memory leak; however, unused data is a similar
    waste of resources.
  prefs: []
  type: TYPE_NORMAL
- en: Optimizing the code that needs it – profiling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Don't optimize code that doesn't need to be optimized. It's a waste of your
    time and probably poor software engineering. Save yourself the trouble and identify
    performance problems accurately before attempting to optimize the program.
  prefs: []
  type: TYPE_NORMAL
- en: For a code rarely executed, performance is not affected
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'It is very common that you will initialize some resource and use it multiple
    times. Optimizing `initialization` of resources may be misdirected. You should
    consider focusing on improving the work efficiency. This is done as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Multiples of small numbers are also small numbers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The reverse may also be true. Sometimes the low frequency of `work` is overwhelmed
    by frequent and expensive `initialization`. Knowing which problem you have will
    let you know where to start looking to improve:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Measuring first, to optimize it
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are a lot of options for profiling. Here are some that we recommend.
  prefs: []
  type: TYPE_NORMAL
- en: The `flame` crate is one option to manually profile an application. Here we
    create the nested procedures `a`, `b`, and `c`. Each function creates a profiling
    context corresponding do that method. After running the profiler we will see proportionally
    how much time was spent for each call to each function.
  prefs: []
  type: TYPE_NORMAL
- en: 'Starting with function `a`, this procedure creates a new profiling context,
    sleeps for one second, then calls `b` three times:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Function `b` is nearly identical to `a`, and further calls into function `c`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Function `c` profiles itself and sleeps, but does not call any further nested
    function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'The `main` entrypoint sets up the flame graph library and calls a three times,
    then saves the flamegraph to a file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: After running this program, the `flame-graph.html` file will contain a visualization
    of what program sections took what percentage of resources. The `flame` crate
    is easy to install, requires some manual code manipulation, but produces a cool-looking
    graph.
  prefs: []
  type: TYPE_NORMAL
- en: '`cargo profiler` is a tool that extends `cargo` to do performance profiling
    without any code changes. Here is a random program that we will profile:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'To profile the application we run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'This will run the program and collect information regarding which functions
    were most used. This profiler also has another option to profile memory usage.
    The output will look like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: This clearly shows us that the most time is spent in iterator and vector creation.
    Running this command may make the program execute much more slowly than normal,
    but it also saves writing any code before profiling.
  prefs: []
  type: TYPE_NORMAL
- en: Putting the fridge next to the computer
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you take a snack break while coding, then it would be convenient to have
    a fridge and microwave next to the computer. If you travel to the kitchen for
    a snack, then it will take a little longer to satisfy your appetite. If your kitchen
    is empty and you need to make a grocery run, then the break is even further extended.
    If your grocery store is empty and you need to drive to a farm to harvest vegetables,
    then your work environment is clearly not designed for snacking purposes.
  prefs: []
  type: TYPE_NORMAL
- en: This strange analogy illustrates the necessary trade-off between time and space.
    This relation is not quite a physical law for our purposes, but almost. The rule
    is that traveling, or communicating, over longer distances is directly proportional
    to time spent. More distance (d) in one direction also means an increase in available
    space of quadratic (d²) or cubic (d³) scale. In other words building the fridge
    farther away provides more space for a larger fridge.
  prefs: []
  type: TYPE_NORMAL
- en: 'Bringing this story back to a technical context, here are some latency numbers
    that every programmer should know (~2012: [https://gist.github.com/jboner/2841832](https://gist.github.com/jboner/2841832)):'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Request** | **Time** |'
  prefs: []
  type: TYPE_TB
- en: '| L1 cache reference | 0.5 ns |'
  prefs: []
  type: TYPE_TB
- en: '| Branch mispredict | 5 ns |'
  prefs: []
  type: TYPE_TB
- en: '| L2 cache reference | 7 ns |'
  prefs: []
  type: TYPE_TB
- en: '| Mutex lock/unlock | 25 ns |'
  prefs: []
  type: TYPE_TB
- en: '| Main memory reference | 100 ns |'
  prefs: []
  type: TYPE_TB
- en: '| Compress 1 Kb with Zippy | 3000 ns |'
  prefs: []
  type: TYPE_TB
- en: '| Send 1 Kb over 1 Gbps network | 10000 ns |'
  prefs: []
  type: TYPE_TB
- en: '| Read 4 Kb randomly from SSD | 150000 ns |'
  prefs: []
  type: TYPE_TB
- en: '| Read 1 Mb sequentially from memory | 250000 ns |'
  prefs: []
  type: TYPE_TB
- en: '| Round trip within same datacenter | 500000 ns |'
  prefs: []
  type: TYPE_TB
- en: '| Send packet CA &#124; Netherlands &#124; CA | 150000000 ns |'
  prefs: []
  type: TYPE_TB
- en: Here, we can see in specific numbers that if you want a donut and some coffee
    then you could eat 300,000,000 donuts from the fridge next to your computer before
    taking your first bite from a Danish.
  prefs: []
  type: TYPE_NORMAL
- en: Capping the Big O
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Big *O* notation is a computer science term used to group functions with respect
    to how fast they grow as the input value gets larger. This term is most often
    used with respect to algorithm runtime or space requirement.
  prefs: []
  type: TYPE_NORMAL
- en: 'When using this term in software engineering, we are usually concerned with
    one of these four cases:'
  prefs: []
  type: TYPE_NORMAL
- en: Constant
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Logarithmic growth
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Polynomial growth
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exponential growth
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When we are concerned with application performance, it is good to consider the
    Big *O* efficiency of the logic you are using. Depending on which of the preceding
    four cases you are dealing with, the appropriate response to optimization strategies
    may change.
  prefs: []
  type: TYPE_NORMAL
- en: Constanting no growth
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Constant time operations are the indivisible units of runtime performance. In
    the previous section, we provided a table of common operations and how long each
    one takes. These are, for our purposes as programmers, basically physical constants.
    You can't optimize the speed of light to make it go faster.
  prefs: []
  type: TYPE_NORMAL
- en: 'Not all constant time operations are irreducible, however. If you have a procedure
    that does a fixed number of operations on fixed-size data, then it will be constant
    time. That does not mean that the procedure is automatically efficient. When trying
    to optimize constant time procedures, ask yourself these two questions:'
  prefs: []
  type: TYPE_NORMAL
- en: Can any of the work be avoided?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Is the fridge too far from the computer?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Here is a program consisting of emphasizing constant time operations:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, let''s profile this program:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: We see that the heavy memory allocation is fairly expensive. As for the memory
    access and floating point calculation, it is seemingly overwhelmed by the expense
    of the loop that executes them multiple times. Unless there is a clear culprit
    for poor performance in a constant time procedure, then optimizing this code may
    not be straightforward.
  prefs: []
  type: TYPE_NORMAL
- en: Logarithmic growth
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Logarithmic algorithms are the pride of computer science. If your *O*(*n*) for
    *n*=5 code could have been written with an *O*(*log n*) algorithm, then surely
    at least one person will point this out.
  prefs: []
  type: TYPE_NORMAL
- en: A binary search is O(*log n*). A sort is typically *O*(*n log n*). Everything
    with a log in it is better. This fondness is not misplaced. Logarithmic growth
    has an amazing property—growth slows down as the input value increases.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a program emphasizing logarithmic growth. We initialize a vector with
    random numbers having size of 1000 or 10000\. Then we use the builtin library
    to sort and perform 100 binary search operations. First let''s capture the time
    for sort and search for the 1000 case:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we profile the 10000 case:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: After running this and examining the flamegraphs, we can see that sorting for
    a vector that is 10 times larger takes barely 10 times as much time—`O(n log n)`.
    Search performance is hardly affected at all—`O(log n)`. So for practical uses,
    logarithmic growth is almost negligible.
  prefs: []
  type: TYPE_NORMAL
- en: When trying to optimize logarithmic code, follow the same approach as for constant
    time optimization. Logarithmic complexity is usually not a good target for optimization,
    particularly considering that logarithmic complexity is a strong indicator of
    good algorithm design.
  prefs: []
  type: TYPE_NORMAL
- en: Polynomial growth
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Most algorithms are polynomial.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you have one `for` loop, then your complexity is *O*(*n*). This is shown
    in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'If you have two `for` loops, then your complexity is *O*(*n*²):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Higher polynomials are somewhat less common. Sometimes code accidentally becomes
    a higher polynomial, which you should be careful about; otherwise, let's just
    consider both the previous cases.
  prefs: []
  type: TYPE_NORMAL
- en: 'Linear complexity is very common. Any time you process the entirety of data
    in a collection, the complexity will be linear. The running time of a linear algorithm
    will be approximately the number of items (*n*) processed, multiplied by the time
    to process individual items (*c*). If you want to make a linear algorithm go faster,
    you need to:'
  prefs: []
  type: TYPE_NORMAL
- en: Reduce the number of items processed (n)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reduce the constant time associated with processing an item (*c*)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'If the time to process an item is not constant or approximately constant, then
    your overall time complexity is now recursively dependent on that processing time.
    This is shown with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Higher polynomial complexity is also common but may indicate that your algorithm
    is poorly designed. In the preceding description, we mentioned that the linear
    processing time can become dependent on the time to process individual items.
    If your program is designed carelessly, then it is very easy to string together
    three or four linear algorithms and unintentionally create an *O*(*n*⁴) monster.
  prefs: []
  type: TYPE_NORMAL
- en: 'Higher polynomials are proportionally slower. In the case of algorithms that
    naively require high polynomial calculations, it is often the case that the algorithm
    can be pruned to remove calculations that are redundant or entirely unnecessary.
    Consider the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: When you need to use higher polynomial algorithms, use a library! This stuff
    gets complicated fast and improving these algorithms is the main job of academic
    Computer Scientists. If you are performance-tuning a common algorithm and not
    expecting to publish your results, then you may likely be duplicating work.
  prefs: []
  type: TYPE_NORMAL
- en: Exponential growth
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Exponential performance in engineering is almost always a bug or a dead end.
    This is the wall that separates algorithms that we use from algorithms that we
    would like to use but can't due to performance reasons.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exponential growth in programs is often accompanied by the term `bomb`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: This program is only *O*(2^n) and therefore barely even exponential!
  prefs: []
  type: TYPE_NORMAL
- en: Referencing data is faster
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There is a rule of thumb that referencing data is faster than copying data.
    Similarly, copying data is faster than cloning. This is not always true, but it
    is a good rule to consider when trying to improve program performance.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a function that alternatively uses data by reference, copied, intrinsic
    cloned, or custom cloned:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Here we declare array of `1024` elements. Then using the flamegraph profiling
    library we apply the above functions to measure the differences between reference,
    copy and clone performance:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: Looking at the runtime of this application, we see that the referenced data
    uses only a small sliver of the resources compared to copying or cloning this
    data. The default clone and copy traits unsurprisingly give a similar performance.
    The custom clone is really slow. It does semantically the same thing as all the
    others, but it is not as optimized at a low level.
  prefs: []
  type: TYPE_NORMAL
- en: Preventing bugs with defensive coding
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You don’t need to fix bugs that never happen. Preventative medicine is good
    software engineering that will save you time in the long run.
  prefs: []
  type: TYPE_NORMAL
- en: Using Option and Result instead of panic!
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In many other languages, exception handling is performed through `try…catch`
    blocks. Rust does not automatically provide this functionality, instead it encourages
    the programmer to explicitly localize all error handling.
  prefs: []
  type: TYPE_NORMAL
- en: In many Rust contexts, if you don’t want to deal with error handling, you always
    have the option to use `panic!`. This will immediately end the program and provide
    a short error message. Don't do this. Panicking is usually just a way of avoiding
    the responsibility of handling errors.
  prefs: []
  type: TYPE_NORMAL
- en: Instead, use either the `Option` or `Result` types to communicate error or exceptional
    conditions. `Option` indicates that no value is available. The `None` value of
    `Option` should indicate that there is no value but that everything is okay and
    expected.
  prefs: []
  type: TYPE_NORMAL
- en: The `Result` type is used to communicate whether or not there was an error in
    processing. `Result` types can be used in combination with the `?` syntax to propagate
    errors while avoiding introducing too much extra syntax. The `?` operation will
    return errors from the function, if any, and therefore the function must have
    a `Result` return type.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here we create two functions that return `Option` or `Result` to handle exceptional
    circumstances. Note the use of the try `?` syntax when handling `Result` return
    values. This syntax will pass through `Ok` values or immediately return any `Err`
    from that function. For this reason, any function using ? must also return a compatible
    `Result` type:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: '`Result` types are very common when interacting with external resources such
    as files:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: Using typesafe interfaces instead of stringly typed interfaces
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Enumerations in Rust are less error-prone than using numbers or strings. Whenever
    possible, write the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Similarly, you can write a stringly enumeration:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'It is better to use the following enum type:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'This way, functions accepting the enumeration will be typesafe:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Enums also fit naturally with pattern matching for the same reason. Pattern
    matching against an enumeration does not require a final error case like the integer
    or string typed case would:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: Using the heartbeat pattern for long running processes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When you want to create a long running process, it is nice to be able to recover
    from program errors that crash or terminate the process. Perhaps the process runs
    out of stack space or encounters a `panic!` from some code path. For any number
    of reasons, a process might get terminated and will need to be restarted.
  prefs: []
  type: TYPE_NORMAL
- en: To accommodate this desire, there are many tools that will watch a program for
    you and restart it if it dies or stops responding to health checks. Here, we recommend
    a completely self-contained version of this pattern that is based on Rust concurrency.
  prefs: []
  type: TYPE_NORMAL
- en: 'The goal is to create a parent process that acts as a monitor and oversees
    one or more workers. The process tree should look something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'When a child dies or stops responding to health checks, the parent should kill
    or otherwise clean up the process resources, then start a new process to replace
    it. Here is an example of this behavior, starting with a subprocess that sometimes
    dies:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'This worker process is highly unreliable and lives no longer than eight seconds.
    However, if we wrap it with a heartbeat monitor, then we can make it more reliable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: Now, the running processes will get restarted if they die unexpectedly. Optionally,
    the parent can check the health status of each child process and restart unresponsive
    workers.
  prefs: []
  type: TYPE_NORMAL
- en: Validating input and output
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Preconditions and postconditions are a great way to lock down program behavior
    and find bugs or invalid states before they get out of hand.
  prefs: []
  type: TYPE_NORMAL
- en: If you use macros to do this, then the preconditions and postconditions can
    optionally be run only in debug mode, and removed from production code. The built-in
    `debug_assert!` macro does this. However, using assertions for return values is
    not particularly elegant and, if you forget to check a branch with a return statement,
    then your postcondition won't be checked.
  prefs: []
  type: TYPE_NORMAL
- en: '`debug_assert!` is not a good choice for the validation of anything dependent
    on external data or otherwise nondeterministic behavior. When you want to check
    preconditions or postconditions in production code, you should instead use `Result`
    or `Option` values to handle exceptional behavior.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some examples of preconditions and postconditions in Rust:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: Notice that the user input is out of our control. The best option for validating
    user input is to return an `Error` condition if the input is invalid.
  prefs: []
  type: TYPE_NORMAL
- en: Finding and fixing bugs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Debugging tools are quite platform dependent. Here we will explain `lldb`, which
    is available, and macOS and other Unix-like systems.
  prefs: []
  type: TYPE_NORMAL
- en: 'To start debugging, you will need to compile the program with debugging symbols
    turned on. The normal `cargo debug build` is usually sufficient:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'After the program has been compiled, start the debugger:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: Here we reference the `debugs/deps/program_name-GITHASH` copy of the program.
    This is necessary for now just because of how lldb works.
  prefs: []
  type: TYPE_NORMAL
- en: 'After running `lldb`, you will see some information scroll past on startup.
    Then, you should be dropped into a LLDB Command Prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, set a breakpoint. We will set a breakpoint to stop at function `a`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that our breakpoint is set, run the `r` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'After stopping at the breakpoint, LLDB will print some context for where the
    code is stopped at. Now we can inspect the program. Let''s print what variables
    are defined in this function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'We can similarly print any variable in scope:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'When we want to continue the program, type `c` to continue:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: The program exits here because we did not set any more breakpoints. This method
    of debugging is nice because it allows you to inspect a running program without
    constantly adding `println!` statements and recompiling. If nothing else works,
    that is still an option though.
  prefs: []
  type: TYPE_NORMAL
- en: Metaprogramming
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Metaprogramming in Rust has two forms—macros and procedural macros. Both of
    these utilities accept an abstract syntax tree as new input and output symbols
    to be compiled. Procedural macros are very similar to normal macros but with fewer
    restrictions on how they work and how they are defined.
  prefs: []
  type: TYPE_NORMAL
- en: 'Macros defined with the `macro_rules!` syntax are defined recursively by matching
    the input syntax to produce output. It is crucial to understand that macro matching
    happens *after* parsing. This means the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Macros must follow certain rules when creating new syntax forms
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The AST is decorated with information regarding each node's grammar category
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Macros can match individual tokens, or a macro can match (and capture) an entire
    grammar category. The Rust grammar categories are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`tt`: This is a token tree (which is a token output from the lexer before parsing)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ident`: This is an identifier'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`expr`: This is an expression'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ty`: This is a type'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`stmt`: This is a statement'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`block`: These are the braces containing a block of statements'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`item`: This is a top-level definition such as a function or a struct'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pat`: This is the match part of a pattern match expression, also called the
    **left hand side**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`path`: This is a path such as `std::fs::File`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`meta`: This is a meta item that goes inside either `#[...]` or `#![...]` syntax
    forms'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Using these patterns we can create macros to match various groups of syntax
    expressions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, let''s apply the macros to some different input:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'As we can see from the example, token trees are, for the most part, not restricted
    to normal Rust grammar, only to the Rust lexer. The lexer is aware of opening
    and closing `() [] {}` bracketed forms. This is why tokens are structured in a
    token tree rather than a token list. This also means that all tokens inside macro
    calls will be stored as token trees and not processed any further until the macro
    is invoked; as long as we create a syntax compatible with Rust token trees, then
    other syntax innovations should usually be permitted. This rule applies also to
    the other grammar categories: grammar categories are just a short hand to match
    certain pattern of tokens that happen to correspond to Rust syntax forms.'
  prefs: []
  type: TYPE_NORMAL
- en: Just matching single tokens or grammar categories probably won't be very useful
    for a macro. To make use of macros in a practical context, we will need to make
    use of macro grammar sequences and grammar alternative*s*. A grammar sequence
    is a request to match more than one token or grammar category in the same rule.
    A grammar alternative is a separate rule within the same macro that matches a
    different syntax. Grammar sequences and alternatives can also be combined in the
    same macro. Additionally, there is a special syntax form to match *many* tokens
    or grammar categories.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are corresponding examples to illustrate these patterns:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'If you''ve paid attention to the generated code for all of these macros, you
    might have noticed that all production rules have created expressions. Macro input
    can be tokens, but output must be a contextually well-formed Rust syntax. For
    this reason, you cannot write `macro_rules!` as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'The specific error from the compiler is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: The key phrase here is `f!`, which is likely invalid in an expression context.
    Each pattern of `macro_rules!` output must be a well-formed expression. The preceding
    example will create well-formed Rust syntax in the end, but its intermediate results
    are fragmented expressions. This awkwardness is one of the several reasons to
    use procedural macros, which are much like `macro_rules!` but programmed directly
    in Rust rather than through the special `macro_rules!` syntax.
  prefs: []
  type: TYPE_NORMAL
- en: Procedural macros are programmed in Rust, but are also used to compile Rust
    programs. How does that work? Procedural macros must be isolated into their own
    modules and compiled separately; they are basically a compiler plugin.
  prefs: []
  type: TYPE_NORMAL
- en: 'To start our procedural macro, let''s create a new subproject:'
  prefs: []
  type: TYPE_NORMAL
- en: Make a `procmacro` directory inside the project root
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Inside the `procmacro` directory, create a `Cargo.toml` file with the following
    contents:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'Inside the `procmacro` directory, create a `src/lib.rs` file with the following
    contents:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'This `f!` macro now implements the preceding semantics without any of the complaints.
    Using the macro looks like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: The interface of a procedural macro is really simple. There is a `TokenStream`
    as input and a `TokenStream` as output. The `proc_macro` and `syn` crates also
    provide utilities to parse tokens or to easily create token streams using the
    `quote!` macro. To use procedural macros, there is some additional setup and boilerplate,
    but after getting past these hurdles the interface is fairly straightforward now.
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, there are many more detailed grammar categories available to procedural
    macros through the `syn` crate. There are 163 categories ([https://dtolnay.github.io/syn/syn/#macros](https://dtolnay.github.io/syn/syn/#macros))
    right now! These include the same vague syntax trees from recursive macros, but
    also very specific syntax forms. These categories correspond to the full Rust
    grammar, therefore permitting very expressive macro syntax without having to create
    your own parser.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s make a procedural macro that uses some of these syntax categories. First
    we make a new procedural macro folder, just like preceding `procmacro`; this one
    we will name `procmacro2`. Now we define the AST that will hold all of the program
    information if the user input is valid:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'The `MiscSyntax` struct will contain all information gathered from our macro.
    That macro and its syntax is what we should define now:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'The `do_parse!` macro helps simplify the use of the parser combinators from
    the `syn` crate. The `id: expr >>` syntax corresponds to the monadic bind operation,
    and `expr >>` syntax is also a form of a monadic bind.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we utilize these definitions to parse input, generate output, and expose
    the macro:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'When using this macro, it really is a bunch of random syntax. This emphasizes
    how macros are not limited to valid Rust syntax, which looks like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: Procedural macros are very powerful and helpful if Rust syntax becomes annoying
    for your purposes. For specific contexts it is possible to create very semantically
    dense code using macros that would otherwise require lots of boilerplate and copy-paste
    coding.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we introduced many applied and practical considerations for
    Rust programming. Performance and debugging are certainly not problems that are
    exclusive to Functional Programming. Here we tried to introduce tips that are
    generally applicable but also highly compatible with functional programming.
  prefs: []
  type: TYPE_NORMAL
- en: Metaprogramming in Rust may be considered a functional feature by itself. Logic
    programming and thereby derived functionality are closely associated with functional
    programming principles. The recursive, context-free nature of macros also lends
    itself to a functional perspective.
  prefs: []
  type: TYPE_NORMAL
- en: This is also the last chapter in the book. We hope you have enjoyed the book
    and we welcome any feedback. If you are looking for further reading, you might
    want to research some of the topics presented in the final three chapters of the
    book. There is an enormous amount of material available on these subjects and
    any path taken will surely further improve your understanding of Rust and functional programming.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: How is release mode different from debug mode?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How long will an empty loop take to run?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is linear time in *Big O* notation?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Name a function that grows faster than exponential growth.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is faster, a disk read or a network read?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How would you return a `Result` with multiple error conditions?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is a token tree?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is an abstract syntax tree?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Why do procedural macros need to be compiled separately?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
