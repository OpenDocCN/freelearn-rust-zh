<html><head></head><body>
		<div><h1 id="_idParaDest-181" class="chapter-number"><a id="_idTextAnchor182"/>9</h1>
			<h1 id="_idParaDest-182"><a id="_idTextAnchor183"/>Testing Our Application Endpoints and Components</h1>
			<p>Our to-do Rust application now fully works. We are happy with our first version as it manages authentication, different users, and their to-do lists, and logs our processes for inspection. However, a web developer’s job is never done.</p>
			<p>While we have now come to the end of adding features to our application, we know that the journey does not stop here. In future iterations beyond this book, we may want to add teams, new statuses, multiple lists per user, and so on. However, as we add these features, we must ensure that our old application’s behavior stays the same unless we actively change it. This is done by building tests.</p>
			<p>In this chapter, we’ll build tests that check our existing behavior, laying down traps that will throw errors that report to us if the app’s behavior changes without us actively changing it. This prevents us from breaking the application and pushing it to a server after adding a new feature or altering the code.</p>
			<p>In this chapter, we will cover the following topics:</p>
			<ul>
				<li>Building our unit tests</li>
				<li>Building JWT unit tests</li>
				<li>Writing functional API tests in Postman</li>
				<li>Automating Postman tests with Newman</li>
				<li>Building an entire automated testing pipeline</li>
			</ul>
			<p>By the end of this chapter, we will understand how to build unit tests in Rust, inspecting our structs in detail with a range of edge cases. If our structs behave in a way we do not expect, our unit tests will report it to us.</p>
			<h1 id="_idParaDest-183"><a id="_idTextAnchor184"/>Technical requirements</h1>
			<p>In this chapter, we’ll build on the code built in <a href="B18722_08.xhtml#_idTextAnchor168"><em class="italic">Chapter 8</em></a>, <em class="italic">Building RESTful Services</em>. This can be found at <a href="https://github.com/PacktPublishing/Rust-Web-Programming-2nd-Edition/tree/main/chapter08/caching">https://github.com/PacktPublishing/Rust-Web-Programming-2nd-Edition/tree/main/chapter08/caching</a>.</p>
			<p>Node and NPM are also needed for installing and running the automated API tests, which can be found at <a href="https://nodejs.org/en/download/">https://nodejs.org/en/download/</a>.</p>
			<p>We will also be running a part of the automated testing pipeline in Python. Python can be downloaded and installed at <a href="https://www.python.org/downloads/">https://www.python.org/downloads/</a>.</p>
			<p>You can find the full source code used in this chapter here: <a href="https://github.com/PacktPublishing/Rust-Web-Programming-2nd-Edition/tree/main/chapter09">https://github.com/PacktPublishing/Rust-Web-Programming-2nd-Edition/tree/main/chapter09</a>.</p>
			<h1 id="_idParaDest-184"><a id="_idTextAnchor185"/>Building our unit tests</h1>
			<p>In this section, we will <a id="_idIndexMarker864"/>explore the concept of unit tests and how to build unit test modules that contain tests as functions. Here, we are not going to achieve 100% unit test coverage for our application. There are places in our application that can be covered by our functional tests, such as API endpoints and JSON serialization. However, unit tests are still important in some parts of our application.</p>
			<p>Unit tests enable us to look at some of our processes in more detail. As we saw with our logging in <a href="B18722_08.xhtml#_idTextAnchor168"><em class="italic">Chapter 8</em></a>, <em class="italic">Building RESTful Services</em>, a functional test might work the way we want it to end-to-end, but there might be edge cases and behaviors that we do not want. This was seen in the previous chapter, where we saw our application make two <code>GET</code> calls when one was enough.</p>
			<p>In our unit tests, we will break down the processes one by one, mock certain parameters, and test the outcomes. These tests are fully isolated. The advantage of this is that we get to test a range of parameters quickly, without having to run a full process each time. This also helps us pinpoint exactly where the application is failing and with what configuration. Unit testing is also useful for test-driven development, where we build the components of a feature bit by bit, running the unit tests and altering the components as and when the test outcomes require.</p>
			<p>In big, complex systems, this saves a lot of time as you do not have to spin up the app and run the full system to spot a typo or failure to account for an edge case.</p>
			<p>However, before we get too excited, we must acknowledge that unit testing is a tool, not a lifestyle, and there are some fallbacks to using it. The tests are only as good as their mocks. If we do not mock realistic interactions, then a unit test could pass but the application could fail. Unit tests are important, but they also must be accompanied by functional tests.</p>
			<p>Rust is still a new language, so at this point, unit testing support is not as advanced as with other languages such as Python or Java. For instance, with Python, we can mock any object from any file with ease at any point in the test. With these mocks, we can define outcomes and monitor interactions. While Rust does not have these mocks so readily available, this does not mean we cannot unit test.</p>
			<p><em class="italic">A bad craftsman always blames their tools</em>. The craftsmanship behind successful unit testing is constructing our code in such a way that individual code pieces won’t depend on each other, giving the pieces will have as much autonomy as possible. Because of this lack of dependency, testing <a id="_idIndexMarker865"/>can easily be performed without the necessity of having a complex mocking system.</p>
			<p>First, we can test our to-do structs. As you’ll remember, we have the <code>done</code> and <code>pending</code> structs, which inherit a <code>base</code> struct. We can start by unit testing the struct that has no dependencies and then move down to other structs that have dependencies. In our <code>src/to_do/structs/base.rs</code> file, we can define our unit tests for the <code>base</code> struct at the bottom of the file with the following code:</p>
			<pre class="source-code">
#[cfg(test)]
mod base_tests {
    use super::Base;
    use super::TaskStatus;
    #[test]
    fn new() {
        let expected_title = String::from("test title");
        let expected_status = TaskStatus::DONE;
        let new_base_struct = Base{
            title: expected_title.clone(),
            status: TaskStatus::DONE
        };
        assert_eq!(expected_title,
                   new_base_struct.title);
        assert_eq!(expected_status,
                   new_base_struct.status);
    }
}</pre>
			<p>In the preceding code, we merely create a struct and assess the fields of that struct, ensuring that they are what we expect them to be. We can see that we created our <code>test</code> module, which is annotated with a <code>#[cfg(test)]</code> attribute. The <code>#[cfg(test)]</code> attribute is a conditional check where the code is only active if we run <code>cargo test</code>. If we do not run <code>cargo test</code>, the code annotated with <code>#[cfg(test)]</code> is not compiled.</p>
			<p>nside the module, we will import the <code>Base</code> struct from the file outside of the <code>base_tests</code> module, which is still in the file. In the Rust world, it is typical to import what we are testing using <code>super</code>. There is a well-established standard to have the testing code right under the code that is being tested in the same file. We will then test the <code>Base::new</code> function<a id="_idIndexMarker866"/> by decorating our <code>new</code> function with a <code>#[</code><code>test]</code> attribute.</p>
			<p>This is the first time we have covered <a id="_idIndexMarker867"/>attributes. An <strong class="bold">attribute</strong> is simply metadata applied to modules and functions. This metadata aids the compiler by giving it information. In this case, it is telling the compiler that this module is a test module and that the function is an individual test.</p>
			<p>However, if we run the preceding code, it would not work. This is because the <code>Eq</code> trait is not implemented in the <code>TaskStatus</code> enum, meaning that we cannot execute the following line of code:</p>
			<pre class="source-code">
assert_eq!(expected_status, new_base_struct.status);</pre>
			<p>This also means that we cannot use the <code>==</code> operator between two <code>TaskStatus</code> enums. Therefore, before we try and run our test, we will have to implement the <code>Eq</code> trait on the <code>TaskStatus</code> enum in the <code>src/to_do/structs/enums.rs</code> file with the following code:</p>
			<pre class="source-code">
#[derive(Clone, Eq, Debug)]
pub enum TaskStatus {
    DONE,
    PENDING
}</pre>
			<p>We can see that we have implemented the <code>Eq</code> and <code>Debug</code> traits, which are needed for the <code>assert_eq!</code> macro. However, our test still will not run because we have not defined the rules around equating two <code>TaskStatus</code> enums. We could implement the <code>PartialEq</code> trait by simply adding the <code>PartialEq</code> trait to our derive annotation. However, we should <a id="_idIndexMarker868"/>explore how to write our own custom logic. To define the equating rules, we implement the <code>eq</code> function under the <code>PartialEq</code> trait with the following code:</p>
			<pre class="source-code">
impl PartialEq for TaskStatus {
    fn eq(&amp;self, other: &amp;Self) -&gt; bool {
        match self {
            TaskStatus::DONE =&gt; {
                match other {
                    &amp;TaskStatus::DONE =&gt; return true,
                    &amp;TaskStatus::PENDING =&gt; false
                }
            },
            TaskStatus::PENDING =&gt; {
                match other {
                    &amp;TaskStatus::DONE =&gt; return false,
                    &amp;TaskStatus::PENDING =&gt; true
                }
            }
        }
    }
}</pre>
			<p>Here, we can see that we manage to confirm if the <code>TaskStatus</code> enum is equal to the other <code>TaskStatus</code> enum being compared using two match statements. It seems more intuitive to use the <code>==</code> operator in the <code>eq</code> function; however, using the <code>==</code> operator calls the <code>eq</code> function resulting in an infinite loop. The code will still compile if you use the <code>==</code> operator in the <code>eq</code> function but if you run it you will get the following unhelpful error:</p>
			<pre class="console">
fatal runtime error: stack overflow</pre>
			<p>We have now essentially created a new <code>base</code> struct and then checked to see if the fields are what we expected. To run this, run the <code>cargo test</code> functionality, pointing it to the file we want <a id="_idIndexMarker869"/>to test, which is denoted by the following command:</p>
			<pre class="console">
cargo test to_do::structs::base</pre>
			<p>We will get the following output:</p>
			<pre class="console">
running 1 test
test to_do::structs::base::base_tests::new ... ok
test result: ok. 1 passed; 0 failed; 0 ignored; 0 measured; 0
filtered out; finished in 0.00s</pre>
			<p>We can see that our test was run and that it passed. Now, we’ll move on to writing tests for the rest of the module, which are the <code>Done</code> and <code>Pending</code> structs. Now is the time to see if you can write a basic unit test in the <code>src/to_do/structs/done.rs</code> file. If you have attempted to write a unit test for the <code>Done</code> struct in the <code>src/to_do/structs/done.rs</code> file, your code should look like the following code:</p>
			<pre class="source-code">
#[cfg(test)]
mod done_tests {
    use super::Done;
    use super::TaskStatus;
    #[test]
    fn new() {
        let new_base_struct = Done::new("test title");
        assert_eq!(String::from("test title"),
                   new_base_struct.super_struct.title);
        assert_eq!(TaskStatus::DONE,
                   new_base_struct.super_struct.status);
    }
}</pre>
			<p>We can run both<a id="_idIndexMarker870"/> tests with the following command:</p>
			<pre class="console">
cargo test</pre>
			<p>This gives the following output:</p>
			<pre class="console">
running 2 tests
test to_do::structs::base::base_tests::new ... ok
test to_do::structs::done::done_tests::new ... ok
test result: ok. 2 passed; 0 failed; 0 ignored; 0
measured; 0 filtered out; finished in 0.00s</pre>
			<p>Running <code>cargo test</code> runs all the tests across all Rust files. We can see that all our tests have now run and passed.</p>
			<p>Now that we have done some basic testing, let’s look at the other modules that we can test. Our JSON serialization and views can be tested in our functional tests with <strong class="bold">Postman</strong>. Our <a id="_idIndexMarker871"/>database <a id="_idIndexMarker872"/>models do not have any advanced functionality that we have purposefully defined.</p>
			<h1 id="_idParaDest-185"><a id="_idTextAnchor186"/>Building JWT unit tests</h1>
			<p>All our models do is<a id="_idIndexMarker873"/> read and write to the database. This has been shown to work. The only module left that we’ll unit test is the <code>auth</code> module. Here, we have some logic that has multiple outcomes based on the inputs. We also must do some mocking as some of the functions accept <code>actix_web</code> structs, which have certain fields and functions. Luckily for us, <code>actix_web</code> has a test module that enables us to mock requests.</p>
			<h2 id="_idParaDest-186"><a id="_idTextAnchor187"/>Building a configuration for tests</h2>
			<p>Before we start<a id="_idIndexMarker874"/> building our unit tests for the JWT, we must remember that there is a dependency on the <code>config</code> file to get the secret key. Unit tests must be isolated. They should not need to have the correct parameters passed into them to work. They should work every time in isolation. Because of this, we are going to have to build a <code>new</code> function for our <code>Config</code> struct in our <code>src/config.rs</code> file. The outline for the coding tests will look like the following code:</p>
			<pre class="source-code">
impl Config {
    // existing function reading from file
    #[cfg(not(test))]
    pub fn new() -&gt; Config {
        . . .
    }
    // new function for testing
    #[cfg(test)]
    pub fn new() -&gt; Config {
        . . .
    }
}</pre>
			<p>The preceding outline shows that there are two <code>new</code> functions. Our new <code>new</code> function gets compiled if tests are being run, and the old <code>new</code> function gets compiled if the server is running as normal. Our test <code>new</code> function has the standard values hardcoded in with the following<a id="_idIndexMarker875"/> code:</p>
			<pre class="source-code">
let mut map = HashMap::new();
map.insert(String::from("DB_URL"),
           serde_yaml::from_str(
           "postgres://username:password@localhost:5433/
           to_do").unwrap());
map.insert(String::from("SECRET_KEY"),
           serde_yaml::from_str("secret").unwrap());
map.insert(String::from("EXPIRE_MINUTES"),
           serde_yaml::from_str("120").unwrap());
map.insert(String::from("REDIS_URL"),
           serde_yaml::from_str("redis://127.0.0.1/")
           .unwrap());
return Config {map}</pre>
			<p>These default functions are the same as our development <code>config</code> file; however, we know that these variables are going to be consistent. We do not need to pass in anything when running the tests and we do not run the risk of reading another file. Now that our tests have been configured, we can define the requirements, including the configuration for our JWT tests.</p>
			<h2 id="_idParaDest-187"><a id="_idTextAnchor188"/>Defining the requirements for JWT tests</h2>
			<p>Now that we <a id="_idIndexMarker876"/>have secured our <code>Config</code> struct for tests, we can go to our <code>src/jwt.rs</code> file and define the imports for our tests with the following code:</p>
			<pre class="source-code">
#[cfg(test)]
mod jwt_tests {
    use std::str::FromStr;
    use super::{JwToken, Config};
    use actix_web::{HttpRequest, HttpResponse,
                    test::TestRequest, web, App};
    use actix_web::http::header::{HeaderValue,
                                  HeaderName, ContentType};
    use actix_web::test::{init_service, call_service};
    use actix_web;
    use serde_json::json;
    use serde::{Deserialize, Serialize};
    #[derive(Debug, Serialize, Deserialize)]
    pub struct ResponseFromTest {
        pub user_id: i32,
        pub exp_minutes: i32
    }
    . . .
}</pre>
			<p>With the preceding code, we can import a range of <code>actix_web</code> structs and functions to enable us to create fake HTTP requests and send them to a fake application to test how the <code>JwToken</code> struct works during the HTTP request process. We will also define a <code>ResponseFromTest</code> struct that can be processed to and from JSON to extract the user ID from the HTTP request as the <code>JwToken</code> struct houses the user ID. The <code>ResponseFromTest</code> struct is the HTTP response we are expecting to have so we are closely mocking the response object.</p>
			<p>Now that we have <a id="_idIndexMarker877"/>imported all that we need, we can define the outline of our tests with the following code:</p>
			<pre class="source-code">
#[cfg(test)]
mod jwt_tests {
    . . .
    #[test]
    fn get_key() {
        . . .
    }
    #[test]
    fn get_exp() {
        . . .
    }
    #[test]
    fn decode_incorrect_token() {
        . . .
    }
    #[test]
    fn encode_decode() {
        . . .
    }
    async fn test_handler(token: JwToken,
                          _: HttpRequest) -&gt; HttpResponse {
        . . .
    }
    #[actix_web::test]
    async fn test_no_token_request() {
        . . .
    }
    #[actix_web::test]
    async fn test_passing_token_request() {
        . . .
    }
    #[actix_web::test]
    async fn test_false_token_request() {
        . . .
    }
}</pre>
			<p>Here, we can see that we test the getting of the key and the encoding and decoding of the token. They are native functions to the <code>JwToken</code> struct and, with what we have covered previously, you should be able to write them yourself. The other functions are decorated with <code>#[actix_web::test]</code>. This means that we are going to create fake HTTP<a id="_idIndexMarker878"/> requests to test how our <code>JwToken</code> implements the <code>FromRequest</code> trait. Now, there is nothing stopping us from writing the tests, which we will cover in the next section.</p>
			<h2 id="_idParaDest-188"><a id="_idTextAnchor189"/>Building basic function tests for JWT</h2>
			<p>We will start with<a id="_idIndexMarker879"/> the most basic test, getting the key, which takes the following form:</p>
			<pre class="source-code">
#[test]
fn get_key() {
    assert_eq!(String::from("secret"), JwToken::get_key());
}</pre>
			<p>We must remember that <code>"secret"</code> is the hardcoded key defined in the <code>Config::new</code> function for test implementations. If the test <code>Config::new</code> function works, the aforementioned test will work. Getting the expiry can also be important. Because we directly rely on the expiration minutes to be extracted from <code>config</code>, the following test will ensure that we are returning 120 minutes:</p>
			<pre class="source-code">
#[test]
fn get_exp() {
    let config = Config::new();
    let minutes = config.map.get("EXPIRE_MINUTES")
                      .unwrap().as_i64().unwrap();
    assert_eq!(120, minutes);
}</pre>
			<p>We can now move<a id="_idIndexMarker880"/> on to test how invalid tokens are handled with the following test:</p>
			<pre class="source-code">
#[test]
fn decode_incorrect_token() {
    let encoded_token: String =
        String::from("invalid_token");
    match JwToken::from_token(encoded_token) {
        Err(message) =&gt; assert_eq!("InvalidToken",
                                    message),
        _ =&gt; panic!(
            "Incorrect token should not be able to be
             encoded"
             )
    }
}</pre>
			<p>Here, we pass in an <code>"invalid_token"</code> string that should fail the decoding process because it is clearly not a valid token. We will then match the outcome. If the outcome is an error, we will then assert that the message is that the error is a result of an invalid token. If there is any other output apart from an error, then we throw an error failing the test because we expect the decode to fail.</p>
			<p>Now that we have written two tests for our <code>JwToken</code> struct functions, this is a good time for you to attempt to write the test for encoding and decoding a token. If you have attempted to write<a id="_idIndexMarker881"/> the encoding and decoding test, it should look like the following code:</p>
			<pre class="source-code">
#[test]
fn encode_decode() {
    let test_token = JwToken::new(5);
    let encoded_token = test_token.encode();
    let new_token =
        JwToken::from_token(encoded_token).unwrap();
    assert_eq!(5, new_token.user_id);
}</pre>
			<p>The preceding test essentially boils down the login and authenticated request process around the token. We create a new token with a user ID, encode the token, and then decode the token testing to see if the data we passed into the token is the same as we get out when we decode it. If we don’t, then the test will fail.</p>
			<p>Now that we have finished testing the functions for the <code>JwToken</code> struct, we can move on to testing how the <code>JwToken</code> struct implements the <code>FromRequest</code> trait. Before we do this, we must define a basic view function that will merely handle the authentication of <code>JwToken</code> and then returns the user ID from the token with the following code:</p>
			<pre class="source-code">
async fn test_handler(token: JwToken,
                      _: HttpRequest) -&gt; HttpResponse {
    return HttpResponse::Ok().json(json!({"user_id":
                                           token.user_id,
                                          "exp_minutes":
                                           60}))
}</pre>
			<p>This is nothing new, in fact, this outline is also how we define our views in our application. With<a id="_idIndexMarker882"/> our basic tests defined, we can move on to building tests for web requests.</p>
			<h2 id="_idParaDest-189"><a id="_idTextAnchor190"/>Building tests for web requests</h2>
			<p>We can now <a id="_idIndexMarker883"/>test our test view to see how it <a id="_idIndexMarker884"/>handles a request with no token in the header with the following code:</p>
			<pre class="source-code">
#[actix_web::test]
async fn test_no_token_request() {
    let app = init_service(App::new().route("/", web::get()
                               .to(test_handler))).await;
    let req = TestRequest::default()
        .insert_header(ContentType::plaintext())
        .to_request();
    let resp = call_service(&amp;app, req).await;
    assert_eq!("401", resp.status().as_str());
}</pre>
			<p>In the preceding code, we can see that we can create a fake server and attach our <code>test_handler</code> test view to it. We can then create a fake request that does not have any token in the header. We will then call the server with the fake request, then assert that the response code of the request is unauthorized. We can now create a test that inserts a valid token with the following code:</p>
			<pre class="source-code">
#[actix_web::test]
async fn test_passing_token_request() {
    let test_token = JwToken::new(5);
    let encoded_token = test_token.encode();
    let app = init_service(App::new().route("/", web::get()
                               .to(test_handler))).await;
    let mut req = TestRequest::default()
        .insert_header(ContentType::plaintext())
        .to_request();
    let header_name = HeaderName::from_str("token")
                                            .unwrap();
    let header_value = HeaderValue::from_str(encoded_token
                                             .as_str())
                                             .unwrap();
    req.headers_mut().insert(header_name, header_value);
    let resp: ResponseFromTest = actix_web::test::
        call_and_read_body_json(&amp;app, req).await;
    assert_eq!(5, resp.user_id);
}</pre>
			<p>Here, we can see <a id="_idIndexMarker885"/>that <a id="_idIndexMarker886"/>we create a valid token. We can create our fake server and attach our <code>test_handler</code> function to that fake server. We will then create a request that can be mutated. Then, we will insert the token into the header and call the fake server with the fake request, using the <code>call_and_read_body_json</code> function. It must be noted that when we call the <code>call_and_read_body_json</code> function, we declare that the type returned under the <code>resp</code> variable name to be <code>ResponseFromTest</code>. We then assert that the user ID is from the request response.</p>
			<p>Now that we have seen how to create a fake HTTP request with a header, this is a good opportunity for you to try and build the test that makes a request with a fake token that cannot be decoded. If you have attempted this, it should look like the following code:</p>
			<pre class="source-code">
#[actix_web::test]
async fn test_false_token_request() {
    let app = init_service(App::new().route("/", web::get()
                  .to(test_handler))).await;
    let mut req = TestRequest::default()
        .insert_header(ContentType::plaintext())
        .to_request();
    let header_name = HeaderName::from_str("token")
        .unwrap();
    let header_value = HeaderValue::from_str("test")
        .unwrap();
    req.headers_mut().insert(header_name, header_value);
    let resp = call_service(&amp;app, req).await;
    assert_eq!("401", resp.status().as_str());
}</pre>
			<p>Looking at the following code, we can see that we inserted a false token into the header using the approach <a id="_idIndexMarker887"/>laid out in the passing token<a id="_idIndexMarker888"/> request test with the unauthorized assertion used in the test with no token provided. If we run all the tests now, we should get the following printout:</p>
			<pre class="console">
running 9 tests
test to_do::structs::base::base_tests::new ... ok
test to_do::structs::done::done_tests::new ... ok
test to_do::structs::pending::pending_tests::new ... ok
test jwt::jwt_tests::get_key ... ok
test jwt::jwt_tests::decode_incorrect_token ... ok
test jwt::jwt_tests::encode_decode ... ok
test jwt::jwt_tests::test_no_token_request ... ok
test jwt::jwt_tests::test_false_token_request ... ok
test jwt::jwt_tests::test_passing_token_request ... ok
test result: ok. 9 passed; 0 failed; 0 ignored;
0 measured; 0 filtered out; finished in 0.00s</pre>
			<p>From the preceding output, our <code>jwt</code> and <code>to_do</code> modules are now fully unit-tested. Considering that Rust is still a new language, we have managed to painlessly unit test our code because we structured our code in a modular fashion.</p>
			<p>The <code>tests</code> crate that <code>actix_web</code> provided enabled us to test edge cases quickly and easily. In this section, we tested how our functions processed requests with missing tokens, false tokens, and correct tokens. We have seen first-hand how Rust enables us to run unit tests on our code.</p>
			<p>Everything is configured with <code>cargo</code>. We do not have to set up paths, install extra modules, or configure environment variables. All we must do is define modules with the <code>test</code> attribute <a id="_idIndexMarker889"/>and <a id="_idIndexMarker890"/>run the <code>cargo test</code> command. However, we must remember that our views and JSON serialization code are not unit-tested. This is where we switch to Postman to test our API endpoints.</p>
			<h1 id="_idParaDest-190"><a id="_idTextAnchor191"/>Writing tests in Postman</h1>
			<p>In this section, we <a id="_idIndexMarker891"/>will be implementing functional integration tests using Postman to test our API endpoints. This will test our JSON processing and database access. To do this, we will follow these steps:</p>
			<ol>
				<li>We are going to have to create a test user for our Postman tests. We can do this with the JSON body shown as follows:<pre class="source-code">
{</pre><pre class="source-code">
    "name": "maxwell",</pre><pre class="source-code">
    "email": "maxwellflitton@gmail.com",</pre><pre class="source-code">
    "password": "test"</pre><pre class="source-code">
}</pre></li>
				<li>We need to add a <code>POST</code> request to the <code>http://127.0.0.1:8000/v1/user/create</code> URL. Once we have done this, we can use our login endpoint for our Postman tests. Now that we have created our test user, we must get the token from the response header of the <code>POST</code> request to the <code>http://127.0.0.1:8000/v1/auth/login</code> URL with the JSON request body:<pre class="source-code">
{</pre><pre class="source-code">
    "username": "maxwell",</pre><pre class="source-code">
    "password": "test"</pre><pre class="source-code">
}</pre></li>
			</ol>
			<p>This gives us<a id="_idIndexMarker892"/> the following Postman layout:</p>
			<div><div><img src="img/Figure_9.1_B18722.jpg" alt="Figure 9.1 – Creating a new use Postman request"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.1 – Creating a new use Postman request</p>
			<p>With this token, we have all the information needed to create our Postman collection. Postman is a collection of API requests. In this collection, we can bunch all our to-do item API calls together using the user token as authentication. The result of the call is as follows:</p>
			<p class="IMG---Figure"> </p>
			<div><div><img src="img/Figure_9.2_B18722.jpg" alt="Figure 9.2 – Creating new use Postman response"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.2 – Creating new use Postman response</p>
			<ol>
				<li value="3">We can create <a id="_idIndexMarker893"/>our collection with the following Postman button, that is, <strong class="bold">+ </strong><strong class="bold">New Collection</strong>:</li>
			</ol>
			<div><div><img src="img/Figure_9.3_B18722.jpg" alt="Figure 9.3 – Creating new Postman collection"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.3 – Creating new Postman collection</p>
			<ol>
				<li value="4">Once we have <a id="_idIndexMarker894"/>clicked this, we must make sure that our user token is defined for the collection, as all to-do item API calls need the token. This can be done by using the <strong class="bold">Authorization</strong> configuration for our API calls, as seen in the following screenshot:</li>
			</ol>
			<div><div><img src="img/Figure_9.4_B18722.jpg" alt="Figure 9.4 – Defining AUTH credentials in a new Postman collection"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.4 – Defining AUTH credentials in a new Postman collection</p>
			<p>We can see that we <a id="_idIndexMarker895"/>have merely copied and pasted our token into the value with <strong class="bold">token</strong> as the key, which will be inserted into the header of the requests. This should now be passed in all our requests in the collection. This collection is now stored on the left-hand side navigation bar under the <strong class="bold">Collections</strong> tab.</p>
			<ol>
				<li value="5">We have now configured our collection and can now add requests under the collection by clicking the grayed-out <strong class="bold">Add Request</strong> button shown in this screenshot:</li>
			</ol>
			<p class="IMG---Figure"> </p>
			<div><div><img src="img/Figure_9.5_B18722.jpg" alt="Figure 9.5 – Creating a new request for our Postman collection"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.5 – Creating a new request for our Postman collection</p>
			<p>Now, we must think<a id="_idIndexMarker896"/> about our approach to testing the flow of testing as this has to be self-contained.</p>
			<h2 id="_idParaDest-191"><a id="_idTextAnchor192"/>Writing ordered requests for tests</h2>
			<p>Our requests <a id="_idIndexMarker897"/>will take the following order:</p>
			<ol>
				<li value="1"><strong class="bold">Create</strong>: Create a to-do item, then check the return to see if it is stored correctly.</li>
				<li><strong class="bold">Create</strong>: Create another to-do item, checking the return to see if the previous one is stored and that the process can handle two items.</li>
				<li><strong class="bold">Create</strong>: Create another to-do item with the same title as one of the other items, checking the response to ensure that our application is not storing duplicate to-do items with the same title.</li>
				<li><strong class="bold">Edit</strong>: Edit an item, checking the response to see if the edited item has been changed to <em class="italic">done</em> and that it is stored in the correct list.</li>
				<li><strong class="bold">Edit</strong>: Edit the second item to see if the <em class="italic">edit</em> effect is permanent and that the <em class="italic">done</em> list supports both items.</li>
				<li><strong class="bold">Edit</strong>: Edit an item that is not present in the application to see if the application handles this correctly.</li>
				<li><strong class="bold">Delete</strong>: Delete one to-do item to see if the response no longer returns the deleted to-do item, meaning that it is no longer stored in the database.</li>
				<li><strong class="bold">Delete</strong>: Delete the final to-do item, checking the response to see if there are no items left, showing that the <em class="italic">delete</em> action is permanent.</li>
			</ol>
			<p>We need to run the <a id="_idIndexMarker898"/>preceding tests for them to work as they rely on the previous action being correct. When we create a request for the collection, we must be clear about what the request is doing, which step it is on, and what type of request it is. For instance, creating our first <em class="italic">create</em> test will look like the following:</p>
			<div><div><img src="img/Figure_9.6_B18722.jpg" alt="Figure 9.6 – Creating our first Postman create request"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.6 – Creating our first Postman create request</p>
			<p>As we can see, the <a id="_idIndexMarker899"/>step is appended with the type by an underscore. We then put the description of the test from the list in the <strong class="bold">Request description (Optional)</strong> field. When defining the request, you may realize that the API key is not in the header of the request.</p>
			<p>This is because it is in the hidden autogenerated headers of the request. Our first request must be a <code>POST</code> request with the <code>http://127.0.0.1:8000/v1/item/create/washing</code> URL.</p>
			<p>This creates the to-do item <em class="italic">washing</em>. However, before we click the <strong class="bold">Send</strong> button, we must move over to the <strong class="bold">Tests</strong> tab in our Postman request, just to the left of the <strong class="bold">Settings</strong> tab, to write our tests as seen in the following screenshot:</p>
			<div><div><img src="img/Figure_9.7_B18722.jpg" alt="Figure 9.7 – Accessing the tests script in Postman"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.7 – Accessing the tests script in Postman</p>
			<p>Our tests must be written in JavaScript. However, we can get access to Postman’s <code>test</code> library by typing <code>pm</code> into the test script. First, at the top of the test script, we need to process the request, which is done with this code:</p>
			<pre class="source-code">
var result = pm.response.json()</pre>
			<p>With the preceding line, we can access the response JSON throughout the test script. To comprehensively test our request, we need to follow these steps:</p>
			<ol>
				<li value="1">First, we need to check the basic content of the response. Our first test is to check to see<a id="_idIndexMarker900"/> if the response is <code>200</code>. This can be done with the following code:<pre class="source-code">
pm.test("response is ok", function () {</pre><pre class="source-code">
    pm.response.to.have.status(200);</pre><pre class="source-code">
});</pre></li>
			</ol>
			<p>Here, we define the test description. Then, the function that the test runs is defined.</p>
			<ol>
				<li value="2">Then, we check the length of data in the response. After the preceding test, we will define our test to check if the pending item has a length of one via the following code:<pre class="source-code">
pm.test("returns one pending item", function(){</pre><pre class="source-code">
    if (result["pending_items"].length !== 1){</pre><pre class="source-code">
        throw new Error(</pre><pre class="source-code">
        "returns the wrong number of pending items");</pre><pre class="source-code">
    }</pre><pre class="source-code">
})</pre></li>
			</ol>
			<p>In the preceding code, we do a simple check of the length and throw an error if the length is not one as we only expect one pending item in the <code>pending_items</code> list.</p>
			<ol>
				<li value="3">Then, we inspect<a id="_idIndexMarker901"/> the title and status of the pending item in the following code:<pre class="source-code">
pm.test("Pending item has the correct title", function(){</pre><pre class="source-code">
    if (result["pending_items"][0]["title"] !==</pre><pre class="source-code">
        "washing"){</pre><pre class="source-code">
        throw new Error(</pre><pre class="source-code">
        "title of the pending item is not 'washing'");</pre><pre class="source-code">
    }</pre><pre class="source-code">
})</pre><pre class="source-code">
pm.test("Pending item has the correct status",</pre><pre class="source-code">
         function()</pre><pre class="source-code">
    {</pre><pre class="source-code">
        if (result["pending_items"][0]["status"] !==</pre><pre class="source-code">
            "PENDING"){</pre><pre class="source-code">
            throw new Error(</pre><pre class="source-code">
            "status of the pending item is not</pre><pre class="source-code">
                'pending'");</pre><pre class="source-code">
    }</pre><pre class="source-code">
})</pre></li>
			</ol>
			<p>In the preceding code, we throw an error if the status or title does not match what we want. Now we have satisfied our tests for the pending items, we can move on to the tests for the done items.</p>
			<ol>
				<li value="4">Seeing as our done items should be zero, the tests have the following definition:<pre class="source-code">
pm.test("returns zero done items", function(){</pre><pre class="source-code">
    if (result["done_items"].length !== 0){</pre><pre class="source-code">
        throw new Error(</pre><pre class="source-code">
        "returns the wrong number of done items");</pre><pre class="source-code">
    }</pre><pre class="source-code">
})</pre></li>
			</ol>
			<p>In the preceding code, we are merely ensuring that the <code>done_items</code> array has a length of zero.</p>
			<ol>
				<li value="5">Now, we must check the counts of our done and pending items. This is done in the following <a id="_idIndexMarker902"/>code:<pre class="source-code">
pm.test("checking pending item count", function(){</pre><pre class="source-code">
    if (result["pending_item_count"] !== 1){</pre><pre class="source-code">
        throw new Error(</pre><pre class="source-code">
        "pending_item_count needs to be one");</pre><pre class="source-code">
    }</pre><pre class="source-code">
})</pre><pre class="source-code">
pm.test("checking done item count", function(){</pre><pre class="source-code">
    if (result["done_item_count"] !== 0){</pre><pre class="source-code">
        throw new Error(</pre><pre class="source-code">
        "done_item_count needs to be zero");</pre><pre class="source-code">
    }</pre><pre class="source-code">
})</pre></li>
			</ol>
			<p>Now that our tests are built, we can make the request by clicking the <strong class="bold">SEND</strong> button in Postman to get the following output for the tests:</p>
			<div><div><img src="img/Figure_9.8_B18722.jpg" alt="Figure 9.8 – Postman tests output"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.8 – Postman tests output</p>
			<p>We can see that our test descriptions and the status of the test are highlighted. If you get an error <a id="_idIndexMarker903"/>the status will be red with a <strong class="bold">FAIL</strong>. Now that our first create test has been done, we can create our second create test.</p>
			<h2 id="_idParaDest-192"><a id="_idTextAnchor193"/>Creating a test for an HTTP request</h2>
			<p>We can <a id="_idIndexMarker904"/>then create the <code>2_create</code> test with<a id="_idIndexMarker905"/> this URL: <code>http://127.0.0.1:8000/v1/item/create/cooking</code>. This is a good opportunity to try and build the test yourself with the testing methods that we have explored in the previous step. If you have attempted to build the tests, they should look like the following code:</p>
			<pre class="source-code">
var result = pm.response.json()
pm.test("response is ok", function () {
    pm.response.to.have.status(200);
});
pm.test("returns two pending item", function(){
    if (result["pending_items"].length !== 2){
        throw new Error(
        "returns the wrong number of pending items");
    }
})
pm.test("Pending item has the correct title", function(){
    if (result["pending_items"][0]["title"] !== "washing"){
        throw new Error(
        "title of the pending item is not 'washing'");
    }
})
pm.test("Pending item has the correct status", function(){
    if (result["pending_items"][0]["status"] !==
        "PENDING"){
        throw new Error(
        "status of the pending item is not 'pending'");
    }
})
pm.test("Pending item has the correct title", function(){
    if (result["pending_items"][1]["title"] !== "cooking"){
        throw new Error(
        "title of the pending item is not 'cooking'");
    }
})
pm.test("Pending item has the correct status", function(){
    if (result["pending_items"][1]["status"] !==
        "PENDING"){
        throw new Error(
        "status of the pending item is not 'pending'");
    }
})
pm.test("returns zero done items", function(){
    if (result["done_items"].length !== 0){
        throw new Error(
        "returns the wrong number of done items");
    }
})
pm.test("checking pending item count", function(){
    if (result["pending_item_count"].length === 1){
        throw new Error(
        "pending_item_count needs to be one");
    }
})
pm.test("checking done item count", function(){
    if (result["done_item_count"].length === 0){
        throw new Error(
        "done_item_count needs to be zero");
    }
})</pre>
			<p>We can see that we have added a couple of extra tests on the second pending item. The preceding tests also directly apply to the <code>3_create</code> test as a duplicate creation will be the same as we will be using the same URL as <code>2_create</code>.</p>
			<p>The preceding tests require a fair amount of repetition in these tests, slightly altering the length of arrays, item counts, and attributes within these arrays. This is a good opportunity to practice basic Postman tests. If you need to cross-reference your tests with mine, you can assess them in the JSON file at the following URL: <a href="https://github.com/PacktPublishing/Rust-Web-Programming-2nd-Edition/blob/main/chapter09/building_test_pipeline/web_app/scripts/to_do_items.postman_collection.json">https://github.com/PacktPublishing/Rust-Web-Programming-2nd-Edition/blob/main/chapter09/building_test_pipeline/web_app/scripts/to_do_items.postman_collection.json</a>.</p>
			<p>In this section, we <a id="_idIndexMarker906"/>have put in a series of steps for <a id="_idIndexMarker907"/>Postman to test when an API call is made. This is not just useful for our application. Postman can hit any API on the internet it has access to. Therefore, you can use Postman tests to monitor live servers and third-party APIs.</p>
			<p>Now, running all these tests can be arduous if it must be done manually every time. We can automate the running and checking of all the tests in this collection <a id="_idIndexMarker908"/>using <strong class="bold">Newman</strong>. If we automate these collections, we can run tests at certain times every day on live servers and third-party APIs we rely on, alerting us to when our servers or the third-party API breaks.</p>
			<p>Newman will give us a good foundation for further development in this area. In the next section, we’ll export the collection and run all the API tests in the exported collection in sequence using Newman.</p>
			<h1 id="_idParaDest-193"><a id="_idTextAnchor194"/>Automating Postman tests with Newman</h1>
			<p>To automate <a id="_idIndexMarker909"/>the series of tests, in this section, we<a id="_idIndexMarker910"/> will export our to-do item Postman collection in the correct sequence. But first, we must export the collection as a JSON file. This can be done by clicking on our collection in Postman on the left-hand navigation bar and clicking the grayed-out <strong class="bold">Export</strong> button, as seen in the following screenshot:</p>
			<div><div><img src="img/Figure_9.9_B18722.jpg" alt="Figure 9.9 – Exporting our Postman collection"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.9 – Exporting our Postman collection</p>
			<p>Now that we have exported the collection, we can quickly inspect it to see how the file is structured. The <a id="_idIndexMarker911"/>following code defines the header<a id="_idIndexMarker912"/> of the suite of tests:</p>
			<pre class="source-code">
"info": {
    "_postman_id": "bab28260-c096-49b9-81e6-b56fc5f60e9d",
    "name": "to_do_items",
    "schema": "https://schema.getpostman.com
    /json/collection/v2.1.0/collection.json",
    "_exporter_id": "3356974"
},</pre>
			<p>The preceding code tells Postman what schema is needed to run the tests. If the code is imported into Postman, the ID and name will be visible. The file then goes on to define the individual tests via the code given as follows:</p>
			<pre class="source-code">
"item": [
    {
        "name": "1_create",
        "event": [
            {
                "listen": "test",
                "script": {
                    "exec": [
                        "var result = pm.response.json()",
                        . . .
                    ],
                    "type": "text/javascript"
                }
            }
        ],
        "request": {
            "method": "POST",
            "header": [
                {
                    "key": "token",
                    "value": "eyJhbGciOiJIUzI1NiJ9
                    .eyJ1c2VyX2lkIjo2fQ.
                    uVo7u877IT2GEMpB_gxVtxhMAYAJD8
                    W_XiUoNvR7_iM",
                    "type": "text",
                    "disabled": true
                }
            ],
            "url": {
                "raw": "http://127.0.0.1:8000/
                v1/item/create/washing",
                "protocol": "http",
                "host": ["127", "0", "0", "1"],
                "port": "8000",
                "path": ["v1", "item", "create", "washing"]
            },
            "description": "create a to-do item,
            and then check the
            return to see if it is stored correctly "
        },
        "response": []
    },</pre>
			<p>From the preceding code, we can see that our tests, method, URL, headers, and more are all defined in <a id="_idIndexMarker913"/>an <a id="_idIndexMarker914"/>array. A quick inspection of the <code>item</code> array will show that the tests will be executed in the order that we want.</p>
			<p>Now, we can simply run it with Newman. We can install Newman with the following command:</p>
			<pre class="console">
npm install -g newman</pre>
			<p class="callout-heading">Note</p>
			<p class="callout">It must be noted that the preceding command is a global install, which can sometimes have issues. To avoid this, you can setup a <code>package.json</code> file with the following contents:</p>
			<pre class="source-code">
{
  "name": "newman testing",
  "description": "",
  "version": "0.1.0",
  "scripts": {
    "test": "newman run to_do_items.
             postman_collection.json"
  },
  "dependencies": {
    "newman": "5.3.2"
  }
}</pre>
			<p class="callout">With this <code>package.json</code>, we have defined the test command and the Newman dependency. We can install our dependencies locally with the following command:</p>
			<pre class="source-code">
npm install</pre>
			<p class="callout">This then installs all we need under the <code>node_modules</code> directory. Instead of running the Newman test command directly, we can use the test command defined in <code>package.json</code> with the following command:</p>
			<pre class="source-code">
npm run test</pre>
			<p>Now that we<a id="_idIndexMarker915"/> have<a id="_idIndexMarker916"/> installed Newman, we can run the collection of tests against the exported collection JSON file with this command:</p>
			<pre class="console">
newman run to_do_items.postman_collection.json</pre>
			<p>The preceding command runs all the tests and gives us a status report. Each description is printed out and the status is also denoted by the side of the test. The following is a typical printout of an API test being assessed:</p>
			<pre class="console">
→ 1_create
    POST http://127.0.0.1:8000/v1/item/create/washing
    [200 OK, 226B, 115ms]
    ✓ response is ok
    ✓ returns one pending item
    ✓ Pending item has the correct title
    ✓ Pending item has the correct status
    ✓ returns zero done items
    ✓ checking pending item count
    ✓ checking done item count</pre>
			<p>The preceding<a id="_idIndexMarker917"/> output<a id="_idIndexMarker918"/> gives us the name, method, URL, and response. Here, all of them passed. If one did not, then the test description would sport a <em class="italic">cross</em> instead of a <em class="italic">tick</em>. We also get the following summary:</p>
			<div><div><img src="img/Figure_9.10_B18722.jpg" alt="Figure 9.10 – Newman summary"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.10 – Newman summary</p>
			<p>We can see that all our tests passed. With this, we have managed to automate our functional testing, enabling us to test a full workflow with minimal effort. However, what we have done is not maintainable. For instance, our token will expire, meaning that if we run tests<a id="_idIndexMarker919"/> later <a id="_idIndexMarker920"/>in the month, they will fail. In the next section, we will build an entire automated pipeline that will build our server, update our token, and run our tests.</p>
			<h1 id="_idParaDest-194"><a id="_idTextAnchor195"/>Building an entire automated testing pipeline</h1>
			<p>When it comes to <a id="_idIndexMarker921"/>development and testing, we need an environment that can be torn down and recreated easily. There is nothing worse than building up data in a database on your local machine to be able to develop further features using that data. However, the database container might be deleted by accident, or you may write some code that corrupts the data. Then, you must spend a lot of time recreating the data before you can get back to where you were. If the system is complex and there is missing documentation, you might forget the steps needed to recreate your data. If you are not comfortable with destroying your local database and starting again when developing and testing, there is something wrong and it is only a matter of time before you get caught out. In this section, we are going to create a single Bash script that carries out the following actions:</p>
			<ol>
				<li value="1">Starts database Docker containers in the background.</li>
				<li>Compiles the Rust server.</li>
				<li>Runs unit tests.</li>
				<li>Starts running the Rust server.</li>
				<li>Runs migrations to the database running in Docker.</li>
				<li>Makes an HTTP request to create a user.</li>
				<li>Makes an HTTP request to log in and get a token.</li>
				<li>Updates the Newman JSON file with the token from the login.</li>
				<li>Runs the Newman tests.</li>
				<li>Removes the files produced in this whole process.</li>
				<li>Stops the Rust server from running.</li>
				<li>Stops and destroy the Docker containers that were running for the whole process.</li>
			</ol>
			<p>There are a lot of <a id="_idIndexMarker922"/>steps laid out in the preceding list. Glancing at this list, it would seem intuitive to break the code blocks that we are going to explore into steps; however, we are going to run nearly all the steps in one Bash script. A lot of the preceding steps outlined can be achieved in one line of Bash code each. It would be excessive to break the code down into steps. Now that we have all the steps needed, we can set up our testing infrastructure. First, we need to set up a <code>scripts</code> directory alongside the <code>src</code> directory in the root of <code>web_app</code>. Inside the <code>scripts</code> directory, we then need to have a <code>run_test_pipeline.sh</code> script that will run the main testing process. We also need to put our Newman JSON <code>config</code> file in the <code>scripts</code> directory.</p>
			<p>We will use <code>bash</code> to orchestrate the entire testing pipeline, which is the best tool for orchestrating testing tasks. In our <code>srcipts/run_test_pipeline.sh</code> script, we will start out with the following code:</p>
			<pre class="source-code">
#!/bin/bash
# move to directory of the project
SCRIPTPATH="$( cd "$(dirname "$0")" ; pwd -P )"
cd $SCRIPTPATH
cd ..</pre>
			<p>In the preceding code, we told the computer that the code block is a Bash script with the <code>#!/bin/bash</code> shebang line. Bash scripts run from the current working directory of where the Bash script it called from. We can call the script from multiple directories so we need to ensure that we get the directory of where the script is housed, which is the <code>scripts</code> directory, assign that to a variable called <code>SCRIPTPATH</code>, move to that directory, and then move out one with the <code>cd..</code> command to be in the main directory where the Docker, config, and <a id="_idIndexMarker923"/>Cargo files are. We can then spin up our Docker containers in the background with the <code>-d</code> flag and loop until the database is accepting connections with the following code:</p>
			<pre class="source-code">
# spin up docker and hold script until accepting connections
docker-compose up -d
until pg_isready -h localhost -p 5433 -U username
do
  echo "Waiting for postgres"
  sleep 2;
done</pre>
			<p>Now that our Docker containers are running, we can now move on to building our Rust server. First, we can compile the Rust server and run our unit tests with the following code:</p>
			<pre class="console">
cargo build
cargo test</pre>
			<p>Once the unit tests have been run, we can then run our server in the background with the following code:</p>
			<pre class="source-code">
# run server in background
cargo run config.yml &amp;
SERVER_PID=$!
sleep 5</pre>
			<p>With <code>&amp;</code> at the end of the command, the <code>cargo run config.yml</code> runs in the background. We then get the process ID of the <code>cargo run config.yml</code> command and assign it to the variable <code>SERVER_PID</code>. We then sleep for 5 seconds to be sure that the server is ready to accept connections. Before we make any API calls to our server, we must run our migrations to the database with the following code:</p>
			<pre class="console">
diesel migration run</pre>
			<p>We then move<a id="_idIndexMarker924"/> back into our <code>scripts</code> directory and make an API call to our server that creates a user:</p>
			<pre class="source-code">
# create the user
curl --location --request POST 'http://localhost:8000/v1/user/create' \
--header 'Content-Type: application/json' \
--data-raw '{
    "name": "maxwell",
    "email": "maxwellflitton@gmail.com",
    "password": "test"
}'</pre>
			<p>If you are wondering how to use <code>curl</code> to make HTTP requests in Bash, you can autogenerate them using your Postman tool. On the right-hand side of the Postman tool, you can see a <strong class="bold">Code</strong> button, as shown in the following screenshot:</p>
			<div><div><img src="img/Figure_9.11_B18722.jpg" alt="Figure 9.11 – Code generation tool"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.11 – Code generation tool</p>
			<p>Once you have clicked on the code tag, there is a drop-down menu where you can select from a range of languages. Once you have selected the language you want, your API call will be displayed in <a id="_idIndexMarker925"/>a code snippet for your chosen language, which you can then copy and paste.</p>
			<p>Now that we have created our user, we can log in and store the token in the <code>fresh_token.json</code> file with the following code; however, it must be noted that <code>curl</code> first needs to be installed:</p>
			<pre class="source-code">
# login getting a fresh token
echo $(curl --location --request GET 'http://localhost:8000/v1/auth/login' \
--header 'Content-Type: application/json' \
--data-raw '{
    "username": "maxwell",
    "password": "test"
}') &gt; ./fresh_token.json</pre>
			<p>What is happening here is that we can wrap the result of the API call into a variable with <code>$(...)</code>. We then echo this and write it to the file using <code>echo $(...) &gt; ./fresh_token.json</code>. We can then insert the fresh token into the Newman data and run the Newman API tests with the following code:</p>
			<pre class="source-code">
TOKEN=$(jq '.token' fresh_token.json)
jq '.auth.apikey[0].value = '"$TOKEN"''
to_do_items.postman_collection.json &gt; test_newman.json
newman run test_newman.json</pre>
			<p>Our testing is now done. We can clean up the files created when running the tests, destroy the Docker<a id="_idIndexMarker926"/> containers, and stop our server running with the following code:</p>
			<pre class="source-code">
rm ./test_newman.json
rm ./fresh_token.json
# shut down rust server
kill $SERVER_PID
cd ..
docker-compose down</pre>
			<p class="callout-heading">Note</p>
			<p class="callout"><code>curl</code> and <code>jq</code> both need to be installed before we can run the Bash script. If you are using Linux, you might need to run the following command:</p>
			<pre class="source-code">
sudo chmod +x ./run_test_pipeline.sh</pre>
			<p>We can then run our testing script with the following command:</p>
			<pre class="console">
sh run_test_pipeline.sh</pre>
			<p>Showing the whole printout would just needlessly fill up the book. However, we can see the end of the test printout in the following screenshot:</p>
			<div><div><img src="img/Figure_9.12_B18722.jpg" alt="Figure 9.12 – The testing pipeline output"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.12 – The testing pipeline output</p>
			<p>Here, the printout<a id="_idIndexMarker927"/> makes it clear that the Newman tests have run and passed. After the tests were completed, the server was shut down and the Docker containers that were supporting the server were stopped and removed. If you want to write this log to a <code>txt</code> file, you can do so with the following command:</p>
			<pre class="console">
sh run_test_pipeline.sh &gt; full_log.txt</pre>
			<p>There you have it! A fully working test pipeline that automates the setting up, testing, and clean-up of our server. Because we have written it in a simple Bash test pipeline, we could integrate<a id="_idIndexMarker928"/> these steps in automation pipelines such as Travis, Jenkins, or GitHub Actions. These pipeline tools fire automatically when a <code>pull</code> request and merges are performed.</p>
			<h1 id="_idParaDest-195"><a id="_idTextAnchor196"/>Summary</h1>
			<p>In this chapter, we went through the workflows and components of our application, breaking them down so we could pick the right tools for the right part. We used unit testing so we could inspect several edge cases quickly to see how each function and struct interacted with others.</p>
			<p>We also directly inspected our custom structs with unit tests. We then used the <code>actix_web</code> test structs to mock requests to see how the functions that use the structs and process the requests work. However, when we came to the main API views module, we switched to Postman.</p>
			<p>This is because our API endpoints were simple. They created, edited, and deleted to-do items. We could directly assess this process by making API calls and inspecting the responses. Out of the box we managed to assess the JSON processing for accepting and returning data. We were also able to assess the querying, writing, and updating of the data in the database with these Postman tests.</p>
			<p>Postman enabled us to test a range of processes quickly and efficiently. We even sped up this testing process by automating it via Newman. However, it must be noted that this approach is not a one-size-fits-all approach. If the API view functions become more complex, with more moving parts, such as communicating with another API or service, then the Newman approach would have to be redesigned. Environment variables that trigger mocking such processes would have to be considered so we can quickly test a range of edge cases.</p>
			<p>Mocking objects will be needed if the system grows as the dependencies of our structs will grow. This is where we create a fake struct or function and define the output for a test. To do this, we will need an external crate such as <code>mockall</code>. The documentation on this crate is covered in the <em class="italic">Further reading</em> section of this chapter.</p>
			<p>Our application now fully runs and has a range of tests. Now, all we have left is to deploy our application on a server.</p>
			<p>In the next chapter, we will set up a server on <strong class="bold">Amazon</strong> <strong class="bold">Web</strong> <strong class="bold">Services</strong> (<strong class="bold">AWS</strong>), utilizing <em class="italic">Docker</em> to deploy our application on a server. We will cover the process of setting up the AWS configuration, running tests, and then deploying our application on our server if the tests pass.</p>
			<h1 id="_idParaDest-196"><a id="_idTextAnchor197"/>Questions</h1>
			<ol>
				<li value="1">Why do we bother with unit tests if we can just manually play with the application?</li>
				<li>What is the difference between unit tests and functional tests?</li>
				<li>What are the advantages of unit tests?</li>
				<li>What are the disadvantages of unit tests?</li>
				<li>What are the advantages of functional tests?</li>
				<li>What are the disadvantages of functional tests?</li>
				<li>What is a sensible approach to building unit tests?</li>
			</ol>
			<h1 id="_idParaDest-197"><a id="_idTextAnchor198"/>Answers</h1>
			<ol>
				<li value="1">When it comes to manual testing, you may forget to run a certain procedure. Running tests standardizes our standards and enables us to integrate them into continuous integration tools to ensure new code will not break the server as continuous integration can block new code merges if the code fails.</li>
				<li>Unit tests isolate individual components such as functions and structs. These functions and structs are then assessed with a range of fake inputs to assess how the component interacts with different inputs. Functional tests assess the system, hitting API endpoints, and checking the response.</li>
				<li>Unit tests are lightweight and do not need an entire system to run. They can test a whole set of edge cases quickly. Unit tests can also isolate exactly where the error is.</li>
				<li>Unit tests are essentially isolated tests with made-up inputs. If the type of input is changed in the system but not updated in the unit test, then this test will essentially pass when it should fail. Unit tests also do not assess how the system runs.</li>
				<li>Functional tests ensure that the entire infrastructure works together as it should. For instance, there could be an issue with how we configure and connect to the database. With unit tests, such problems can be missed. Also, although mocking ensures isolated tests, unit test mocks might be out of date. This means that a mocked function might return data that the updated version does not. As a result, the unit test will pass but the functional tests will not as they test everything.</li>
				<li>Functional tests need to have the infrastructure to run like a database. There also must be a setup and teardown function. For instance, a functional test will affect the data stored in the database. At the end of the test, the database needs to be wiped before running the test again. This can increase the complications and can require “glue” code between different operations.</li>
				<li>We start off with testing structs and functions that do not have any dependencies. Once these have been tested, we know that we are comfortable with them. We then move on to the functions and structs that have the dependencies we previously tested. Using this approach, we know that the current test we are writing does not fail due to a dependency.</li>
			</ol>
			<h1 id="_idParaDest-198"><a id="_idTextAnchor199"/>Further reading</h1>
			<ul>
				<li>Mockall documentation: <a href="https://docs.rs/mockall/0.9.0/mockall/">https://docs.rs/mockall/0.9.0/mockall/</a></li>
				<li>Github Actions documentation: <a href="https://github.com/features/actions">https://github.com/features/actions</a></li>
				<li>Travis documentation: <a href="https://docs.travis-ci.com/user/for-beginners/&#13;">https://docs.travis-ci.com/user/for-beginners/</a></li>
				<li>Circle CI documentation: <a href="https://circleci.com/docs/">https://circleci.com/docs/</a></li>
				<li>Jenkins documentation: <a href="https://www.jenkins.io/doc/">https://www.jenkins.io/doc/</a></li>
			</ul>
		</div>
	</body></html>