<html><head></head><body>
		<div id="_idContainer106">
			<h1 id="_idParaDest-181" class="chapter-number"><a id="_idTextAnchor182"/>9</h1>
			<h1 id="_idParaDest-182"><a id="_idTextAnchor183"/>Testing Our Application Endpoints and Components</h1>
			<p>Our to-do Rust application now fully works. We are happy with our first version as it manages authentication, different users, and their to-do lists, and logs our processes for inspection. However, a web developer’s job is <span class="No-Break">never done.</span></p>
			<p>While we have now come to the end of adding features to our application, we know that the journey does not stop here. In future iterations beyond this book, we may want to add teams, new statuses, multiple lists per user, and so on. However, as we add these features, we must ensure that our old application’s behavior stays the same unless we actively change it. This is done by <span class="No-Break">building tests.</span></p>
			<p>In this chapter, we’ll build tests that check our existing behavior, laying down traps that will throw errors that report to us if the app’s behavior changes without us actively changing it. This prevents us from breaking the application and pushing it to a server after adding a new feature or altering <span class="No-Break">the code.</span></p>
			<p>In this chapter, we will cover the <span class="No-Break">following topics:</span></p>
			<ul>
				<li>Building our <span class="No-Break">unit tests</span></li>
				<li>Building JWT <span class="No-Break">unit tests</span></li>
				<li>Writing functional API tests <span class="No-Break">in Postman</span></li>
				<li>Automating Postman tests <span class="No-Break">with Newman</span></li>
				<li>Building an entire automated <span class="No-Break">testing pipeline</span></li>
			</ul>
			<p>By the end of this chapter, we will understand how to build unit tests in Rust, inspecting our structs in detail with a range of edge cases. If our structs behave in a way we do not expect, our unit tests will report it <span class="No-Break">to us.</span></p>
			<h1 id="_idParaDest-183"><a id="_idTextAnchor184"/>Technical requirements</h1>
			<p>In this chapter, we’ll build on the code built in <a href="B18722_08.xhtml#_idTextAnchor168"><span class="No-Break"><em class="italic">Chapter 8</em></span></a>, <em class="italic">Building RESTful Services</em>. This can be found <span class="No-Break">at </span><a href="https://github.com/PacktPublishing/Rust-Web-Programming-2nd-Edition/tree/main/chapter08/caching"><span class="No-Break">https://github.com/PacktPublishing/Rust-Web-Programming-2nd-Edition/tree/main/chapter08/caching</span></a><span class="No-Break">.</span></p>
			<p>Node and NPM are also needed for installing and running the automated API tests, which can be found <span class="No-Break">at </span><a href="https://nodejs.org/en/download/"><span class="No-Break">https://nodejs.org/en/download/</span></a><span class="No-Break">.</span></p>
			<p>We will also be running a part of the automated testing pipeline in Python. Python can be downloaded and installed <span class="No-Break">at </span><a href="https://www.python.org/downloads/"><span class="No-Break">https://www.python.org/downloads/</span></a><span class="No-Break">.</span></p>
			<p>You can find the full source code used in this chapter <span class="No-Break">here: </span><a href="https://github.com/PacktPublishing/Rust-Web-Programming-2nd-Edition/tree/main/chapter09"><span class="No-Break">https://github.com/PacktPublishing/Rust-Web-Programming-2nd-Edition/tree/main/chapter09</span></a><span class="No-Break">.</span></p>
			<h1 id="_idParaDest-184"><a id="_idTextAnchor185"/>Building our unit tests</h1>
			<p>In this section, we will <a id="_idIndexMarker864"/>explore the concept of unit tests and how to build unit test modules that contain tests as functions. Here, we are not going to achieve 100% unit test coverage for our application. There are places in our application that can be covered by our functional tests, such as API endpoints and JSON serialization. However, unit tests are still important in some parts of <span class="No-Break">our application.</span></p>
			<p>Unit tests enable us to look at some of our processes in more detail. As we saw with our logging in <a href="B18722_08.xhtml#_idTextAnchor168"><span class="No-Break"><em class="italic">Chapter 8</em></span></a>, <em class="italic">Building RESTful Services</em>, a functional test might work the way we want it to end-to-end, but there might be edge cases and behaviors that we do not want. This was seen in the previous chapter, where we saw our application make two <strong class="source-inline">GET</strong> calls when one <span class="No-Break">was enough.</span></p>
			<p>In our unit tests, we will break down the processes one by one, mock certain parameters, and test the outcomes. These tests are fully isolated. The advantage of this is that we get to test a range of parameters quickly, without having to run a full process each time. This also helps us pinpoint exactly where the application is failing and with what configuration. Unit testing is also useful for test-driven development, where we build the components of a feature bit by bit, running the unit tests and altering the components as and when the test <span class="No-Break">outcomes require.</span></p>
			<p>In big, complex systems, this saves a lot of time as you do not have to spin up the app and run the full system to spot a typo or failure to account for an <span class="No-Break">edge case.</span></p>
			<p>However, before we get too excited, we must acknowledge that unit testing is a tool, not a lifestyle, and there are some fallbacks to using it. The tests are only as good as their mocks. If we do not mock realistic interactions, then a unit test could pass but the application could fail. Unit tests are important, but they also must be accompanied by <span class="No-Break">functional tests.</span></p>
			<p>Rust is still a new language, so at this point, unit testing support is not as advanced as with other languages such as Python or Java. For instance, with Python, we can mock any object from any file with ease at any point in the test. With these mocks, we can define outcomes and monitor interactions. While Rust does not have these mocks so readily available, this does not mean we cannot <span class="No-Break">unit test.</span></p>
			<p><em class="italic">A bad craftsman always blames their tools</em>. The craftsmanship behind successful unit testing is constructing our code in such a way that individual code pieces won’t depend on each other, giving the pieces will have as much autonomy as possible. Because of this lack of dependency, testing <a id="_idIndexMarker865"/>can easily be performed without the necessity of having a complex <span class="No-Break">mocking system.</span></p>
			<p>First, we can test our to-do structs. As you’ll remember, we have the <strong class="source-inline">done</strong> and <strong class="source-inline">pending</strong> structs, which inherit a <strong class="source-inline">base</strong> struct. We can start by unit testing the struct that has no dependencies and then move down to other structs that have dependencies. In our <strong class="source-inline">src/to_do/structs/base.rs</strong> file, we can define our unit tests for the <strong class="source-inline">base</strong> struct at the bottom of the file with the <span class="No-Break">following code:</span></p>
			<pre class="source-code">
#[cfg(test)]
mod base_tests {
    use super::Base;
    use super::TaskStatus;
    #[test]
    fn new() {
        let expected_title = String::from("test title");
        let expected_status = TaskStatus::DONE;
        let new_base_struct = Base{
            title: expected_title.clone(),
            status: TaskStatus::DONE
        };
        assert_eq!(expected_title,
                   new_base_struct.title);
        assert_eq!(expected_status,
                   new_base_struct.status);
    }
}</pre>
			<p>In the preceding code, we merely create a struct and assess the fields of that struct, ensuring that they are what we expect them to be. We can see that we created our <strong class="source-inline">test</strong> module, which is annotated with a <strong class="source-inline">#[cfg(test)]</strong> attribute. The <strong class="source-inline">#[cfg(test)]</strong> attribute is a conditional check where the code is only active if we run <strong class="source-inline">cargo test</strong>. If we do not run <strong class="source-inline">cargo test</strong>, the code annotated with <strong class="source-inline">#[cfg(test)]</strong> is <span class="No-Break">not compiled.</span></p>
			<p>nside the module, we will import the <strong class="source-inline">Base</strong> struct from the file outside of the <strong class="source-inline">base_tests</strong> module, which is still in the file. In the Rust world, it is typical to import what we are testing using <strong class="source-inline">super</strong>. There is a well-established standard to have the testing code right under the code that is being tested in the same file. We will then test the <strong class="source-inline">Base::new</strong> function<a id="_idIndexMarker866"/> by decorating our <strong class="source-inline">new</strong> function with a <strong class="source-inline">#[</strong><span class="No-Break"><strong class="source-inline">test]</strong></span><span class="No-Break"> attribute.</span></p>
			<p>This is the first time we have covered <a id="_idIndexMarker867"/>attributes. An <strong class="bold">attribute</strong> is simply metadata applied to modules and functions. This metadata aids the compiler by giving it information. In this case, it is telling the compiler that this module is a test module and that the function is an <span class="No-Break">individual test.</span></p>
			<p>However, if we run the preceding code, it would not work. This is because the <strong class="source-inline">Eq</strong> trait is not implemented in the <strong class="source-inline">TaskStatus</strong> enum, meaning that we cannot execute the following line <span class="No-Break">of code:</span></p>
			<pre class="source-code">
assert_eq!(expected_status, new_base_struct.status);</pre>
			<p>This also means that we cannot use the <strong class="source-inline">==</strong> operator between two <strong class="source-inline">TaskStatus</strong> enums. Therefore, before we try and run our test, we will have to implement the <strong class="source-inline">Eq</strong> trait on the <strong class="source-inline">TaskStatus</strong> enum in the <strong class="source-inline">src/to_do/structs/enums.rs</strong> file with the <span class="No-Break">following code:</span></p>
			<pre class="source-code">
#[derive(Clone, Eq, Debug)]
pub enum TaskStatus {
    DONE,
    PENDING
}</pre>
			<p>We can see that we have implemented the <strong class="source-inline">Eq</strong> and <strong class="source-inline">Debug</strong> traits, which are needed for the <strong class="source-inline">assert_eq!</strong> macro. However, our test still will not run because we have not defined the rules around equating two <strong class="source-inline">TaskStatus</strong> enums. We could implement the <strong class="source-inline">PartialEq</strong> trait by simply adding the <strong class="source-inline">PartialEq</strong> trait to our derive annotation. However, we should <a id="_idIndexMarker868"/>explore how to write our own custom logic. To define the equating rules, we implement the <strong class="source-inline">eq</strong> function under the <strong class="source-inline">PartialEq</strong> trait with the <span class="No-Break">following code:</span></p>
			<pre class="source-code">
impl PartialEq for TaskStatus {
    fn eq(&amp;self, other: &amp;Self) -&gt; bool {
        match self {
            TaskStatus::DONE =&gt; {
                match other {
                    &amp;TaskStatus::DONE =&gt; return true,
                    &amp;TaskStatus::PENDING =&gt; false
                }
            },
            TaskStatus::PENDING =&gt; {
                match other {
                    &amp;TaskStatus::DONE =&gt; return false,
                    &amp;TaskStatus::PENDING =&gt; true
                }
            }
        }
    }
}</pre>
			<p>Here, we can see that we manage to confirm if the <strong class="source-inline">TaskStatus</strong> enum is equal to the other <strong class="source-inline">TaskStatus</strong> enum being compared using two match statements. It seems more intuitive to use the <strong class="source-inline">==</strong> operator in the <strong class="source-inline">eq</strong> function; however, using the <strong class="source-inline">==</strong> operator calls the <strong class="source-inline">eq</strong> function resulting in an infinite loop. The code will still compile if you use the <strong class="source-inline">==</strong> operator in the <strong class="source-inline">eq</strong> function but if you run it you will get the following <span class="No-Break">unhelpful error:</span></p>
			<pre class="console">
fatal runtime error: stack overflow</pre>
			<p>We have now essentially created a new <strong class="source-inline">base</strong> struct and then checked to see if the fields are what we expected. To run this, run the <strong class="source-inline">cargo test</strong> functionality, pointing it to the file we want <a id="_idIndexMarker869"/>to test, which is denoted by the <span class="No-Break">following command:</span></p>
			<pre class="console">
cargo test to_do::structs::base</pre>
			<p>We will get the <span class="No-Break">following output:</span></p>
			<pre class="console">
running 1 test
test to_do::structs::base::base_tests::new ... ok
test result: ok. 1 passed; 0 failed; 0 ignored; 0 measured; 0
filtered out; finished in 0.00s</pre>
			<p>We can see that our test was run and that it passed. Now, we’ll move on to writing tests for the rest of the module, which are the <strong class="source-inline">Done</strong> and <strong class="source-inline">Pending</strong> structs. Now is the time to see if you can write a basic unit test in the <strong class="source-inline">src/to_do/structs/done.rs</strong> file. If you have attempted to write a unit test for the <strong class="source-inline">Done</strong> struct in the <strong class="source-inline">src/to_do/structs/done.rs</strong> file, your code should look like the <span class="No-Break">following code:</span></p>
			<pre class="source-code">
#[cfg(test)]
mod done_tests {
    use super::Done;
    use super::TaskStatus;
    #[test]
    fn new() {
        let new_base_struct = Done::new("test title");
        assert_eq!(String::from("test title"),
                   new_base_struct.super_struct.title);
        assert_eq!(TaskStatus::DONE,
                   new_base_struct.super_struct.status);
    }
}</pre>
			<p>We can run both<a id="_idIndexMarker870"/> tests with the <span class="No-Break">following command:</span></p>
			<pre class="console">
cargo test</pre>
			<p>This gives the <span class="No-Break">following output:</span></p>
			<pre class="console">
running 2 tests
test to_do::structs::base::base_tests::new ... ok
test to_do::structs::done::done_tests::new ... ok
test result: ok. 2 passed; 0 failed; 0 ignored; 0
measured; 0 filtered out; finished in 0.00s</pre>
			<p>Running <strong class="source-inline">cargo test</strong> runs all the tests across all Rust files. We can see that all our tests have now run <span class="No-Break">and passed.</span></p>
			<p>Now that we have done some basic testing, let’s look at the other modules that we can test. Our JSON serialization and views can be tested in our functional tests with <strong class="bold">Postman</strong>. Our <a id="_idIndexMarker871"/>database <a id="_idIndexMarker872"/>models do not have any advanced functionality that we have <span class="No-Break">purposefully defined.</span></p>
			<h1 id="_idParaDest-185"><a id="_idTextAnchor186"/>Building JWT unit tests</h1>
			<p>All our models do is<a id="_idIndexMarker873"/> read and write to the database. This has been shown to work. The only module left that we’ll unit test is the <strong class="source-inline">auth</strong> module. Here, we have some logic that has multiple outcomes based on the inputs. We also must do some mocking as some of the functions accept <strong class="source-inline">actix_web</strong> structs, which have certain fields and functions. Luckily for us, <strong class="source-inline">actix_web</strong> has a test module that enables us to <span class="No-Break">mock requests.</span></p>
			<h2 id="_idParaDest-186"><a id="_idTextAnchor187"/>Building a configuration for tests</h2>
			<p>Before we start<a id="_idIndexMarker874"/> building our unit tests for the JWT, we must remember that there is a dependency on the <strong class="source-inline">config</strong> file to get the secret key. Unit tests must be isolated. They should not need to have the correct parameters passed into them to work. They should work every time in isolation. Because of this, we are going to have to build a <strong class="source-inline">new</strong> function for our <strong class="source-inline">Config</strong> struct in our <strong class="source-inline">src/config.rs</strong> file. The outline for the coding tests will look like the <span class="No-Break">following code:</span></p>
			<pre class="source-code">
impl Config {
    // existing function reading from file
    #[cfg(not(test))]
    pub fn new() -&gt; Config {
        . . .
    }
    // new function for testing
    #[cfg(test)]
    pub fn new() -&gt; Config {
        . . .
    }
}</pre>
			<p>The preceding outline shows that there are two <strong class="source-inline">new</strong> functions. Our new <strong class="source-inline">new</strong> function gets compiled if tests are being run, and the old <strong class="source-inline">new</strong> function gets compiled if the server is running as normal. Our test <strong class="source-inline">new</strong> function has the standard values hardcoded in with the <span class="No-Break">following</span><span class="No-Break"><a id="_idIndexMarker875"/></span><span class="No-Break"> code:</span></p>
			<pre class="source-code">
let mut map = HashMap::new();
map.insert(String::from("DB_URL"),
           serde_yaml::from_str(
           "postgres://username:password@localhost:5433/
           to_do").unwrap());
map.insert(String::from("SECRET_KEY"),
           serde_yaml::from_str("secret").unwrap());
map.insert(String::from("EXPIRE_MINUTES"),
           serde_yaml::from_str("120").unwrap());
map.insert(String::from("REDIS_URL"),
           serde_yaml::from_str("redis://127.0.0.1/")
           .unwrap());
return Config {map}</pre>
			<p>These default functions are the same as our development <strong class="source-inline">config</strong> file; however, we know that these variables are going to be consistent. We do not need to pass in anything when running the tests and we do not run the risk of reading another file. Now that our tests have been configured, we can define the requirements, including the configuration for our <span class="No-Break">JWT tests.</span></p>
			<h2 id="_idParaDest-187"><a id="_idTextAnchor188"/>Defining the requirements for JWT tests</h2>
			<p>Now that we <a id="_idIndexMarker876"/>have secured our <strong class="source-inline">Config</strong> struct for tests, we can go to our <strong class="source-inline">src/jwt.rs</strong> file and define the imports for our tests with the <span class="No-Break">following code:</span></p>
			<pre class="source-code">
#[cfg(test)]
mod jwt_tests {
    use std::str::FromStr;
    use super::{JwToken, Config};
    use actix_web::{HttpRequest, HttpResponse,
                    test::TestRequest, web, App};
    use actix_web::http::header::{HeaderValue,
                                  HeaderName, ContentType};
    use actix_web::test::{init_service, call_service};
    use actix_web;
    use serde_json::json;
    use serde::{Deserialize, Serialize};
    #[derive(Debug, Serialize, Deserialize)]
    pub struct ResponseFromTest {
        pub user_id: i32,
        pub exp_minutes: i32
    }
    . . .
}</pre>
			<p>With the preceding code, we can import a range of <strong class="source-inline">actix_web</strong> structs and functions to enable us to create fake HTTP requests and send them to a fake application to test how the <strong class="source-inline">JwToken</strong> struct works during the HTTP request process. We will also define a <strong class="source-inline">ResponseFromTest</strong> struct that can be processed to and from JSON to extract the user ID from the HTTP request as the <strong class="source-inline">JwToken</strong> struct houses the user ID. The <strong class="source-inline">ResponseFromTest</strong> struct is the HTTP response we are expecting to have so we are closely mocking the <span class="No-Break">response object.</span></p>
			<p>Now that we have <a id="_idIndexMarker877"/>imported all that we need, we can define the outline of our tests with the <span class="No-Break">following code:</span></p>
			<pre class="source-code">
#[cfg(test)]
mod jwt_tests {
    . . .
    #[test]
    fn get_key() {
        . . .
    }
    #[test]
    fn get_exp() {
        . . .
    }
    #[test]
    fn decode_incorrect_token() {
        . . .
    }
    #[test]
    fn encode_decode() {
        . . .
    }
    async fn test_handler(token: JwToken,
                          _: HttpRequest) -&gt; HttpResponse {
        . . .
    }
    #[actix_web::test]
    async fn test_no_token_request() {
        . . .
    }
    #[actix_web::test]
    async fn test_passing_token_request() {
        . . .
    }
    #[actix_web::test]
    async fn test_false_token_request() {
        . . .
    }
}</pre>
			<p>Here, we can see that we test the getting of the key and the encoding and decoding of the token. They are native functions to the <strong class="source-inline">JwToken</strong> struct and, with what we have covered previously, you should be able to write them yourself. The other functions are decorated with <strong class="source-inline">#[actix_web::test]</strong>. This means that we are going to create fake HTTP<a id="_idIndexMarker878"/> requests to test how our <strong class="source-inline">JwToken</strong> implements the <strong class="source-inline">FromRequest</strong> trait. Now, there is nothing stopping us from writing the tests, which we will cover in the <span class="No-Break">next section.</span></p>
			<h2 id="_idParaDest-188"><a id="_idTextAnchor189"/>Building basic function tests for JWT</h2>
			<p>We will start with<a id="_idIndexMarker879"/> the most basic test, getting the key, which takes the <span class="No-Break">following form:</span></p>
			<pre class="source-code">
#[test]
fn get_key() {
    assert_eq!(String::from("secret"), JwToken::get_key());
}</pre>
			<p>We must remember that <strong class="source-inline">"secret"</strong> is the hardcoded key defined in the <strong class="source-inline">Config::new</strong> function for test implementations. If the test <strong class="source-inline">Config::new</strong> function works, the aforementioned test will work. Getting the expiry can also be important. Because we directly rely on the expiration minutes to be extracted from <strong class="source-inline">config</strong>, the following test will ensure that we are returning <span class="No-Break">120 minutes:</span></p>
			<pre class="source-code">
#[test]
fn get_exp() {
    let config = Config::new();
    let minutes = config.map.get("EXPIRE_MINUTES")
                      .unwrap().as_i64().unwrap();
    assert_eq!(120, minutes);
}</pre>
			<p>We can now move<a id="_idIndexMarker880"/> on to test how invalid tokens are handled with the <span class="No-Break">following test:</span></p>
			<pre class="source-code">
#[test]
fn decode_incorrect_token() {
    let encoded_token: String =
        String::from("invalid_token");
    match JwToken::from_token(encoded_token) {
        Err(message) =&gt; assert_eq!("InvalidToken",
                                    message),
        _ =&gt; panic!(
            "Incorrect token should not be able to be
             encoded"
             )
    }
}</pre>
			<p>Here, we pass in an <strong class="source-inline">"invalid_token"</strong> string that should fail the decoding process because it is clearly not a valid token. We will then match the outcome. If the outcome is an error, we will then assert that the message is that the error is a result of an invalid token. If there is any other output apart from an error, then we throw an error failing the test because we expect the decode <span class="No-Break">to fail.</span></p>
			<p>Now that we have written two tests for our <strong class="source-inline">JwToken</strong> struct functions, this is a good time for you to attempt to write the test for encoding and decoding a token. If you have attempted to write<a id="_idIndexMarker881"/> the encoding and decoding test, it should look like the <span class="No-Break">following code:</span></p>
			<pre class="source-code">
#[test]
fn encode_decode() {
    let test_token = JwToken::new(5);
    let encoded_token = test_token.encode();
    let new_token =
        JwToken::from_token(encoded_token).unwrap();
    assert_eq!(5, new_token.user_id);
}</pre>
			<p>The preceding test essentially boils down the login and authenticated request process around the token. We create a new token with a user ID, encode the token, and then decode the token testing to see if the data we passed into the token is the same as we get out when we decode it. If we don’t, then the test <span class="No-Break">will fail.</span></p>
			<p>Now that we have finished testing the functions for the <strong class="source-inline">JwToken</strong> struct, we can move on to testing how the <strong class="source-inline">JwToken</strong> struct implements the <strong class="source-inline">FromRequest</strong> trait. Before we do this, we must define a basic view function that will merely handle the authentication of <strong class="source-inline">JwToken</strong> and then returns the user ID from the token with the <span class="No-Break">following code:</span></p>
			<pre class="source-code">
async fn test_handler(token: JwToken,
                      _: HttpRequest) -&gt; HttpResponse {
    return HttpResponse::Ok().json(json!({"user_id":
                                           token.user_id,
                                          "exp_minutes":
                                           60}))
}</pre>
			<p>This is nothing new, in fact, this outline is also how we define our views in our application. With<a id="_idIndexMarker882"/> our basic tests defined, we can move on to building tests for <span class="No-Break">web requests.</span></p>
			<h2 id="_idParaDest-189"><a id="_idTextAnchor190"/>Building tests for web requests</h2>
			<p>We can now <a id="_idIndexMarker883"/>test our test view to see how it <a id="_idIndexMarker884"/>handles a request with no token in the header with the <span class="No-Break">following code:</span></p>
			<pre class="source-code">
#[actix_web::test]
async fn test_no_token_request() {
    let app = init_service(App::new().route("/", web::get()
                               .to(test_handler))).await;
    let req = TestRequest::default()
        .insert_header(ContentType::plaintext())
        .to_request();
    let resp = call_service(&amp;app, req).await;
    assert_eq!("401", resp.status().as_str());
}</pre>
			<p>In the preceding code, we can see that we can create a fake server and attach our <strong class="source-inline">test_handler</strong> test view to it. We can then create a fake request that does not have any token in the header. We will then call the server with the fake request, then assert that the response code of the request is unauthorized. We can now create a test that inserts a valid token with the <span class="No-Break">following code:</span></p>
			<pre class="source-code">
#[actix_web::test]
async fn test_passing_token_request() {
    let test_token = JwToken::new(5);
    let encoded_token = test_token.encode();
    let app = init_service(App::new().route("/", web::get()
                               .to(test_handler))).await;
    let mut req = TestRequest::default()
        .insert_header(ContentType::plaintext())
        .to_request();
    let header_name = HeaderName::from_str("token")
                                            .unwrap();
    let header_value = HeaderValue::from_str(encoded_token
                                             .as_str())
                                             .unwrap();
    req.headers_mut().insert(header_name, header_value);
    let resp: ResponseFromTest = actix_web::test::
        call_and_read_body_json(&amp;app, req).await;
    assert_eq!(5, resp.user_id);
}</pre>
			<p>Here, we can see <a id="_idIndexMarker885"/>that <a id="_idIndexMarker886"/>we create a valid token. We can create our fake server and attach our <strong class="source-inline">test_handler</strong> function to that fake server. We will then create a request that can be mutated. Then, we will insert the token into the header and call the fake server with the fake request, using the <strong class="source-inline">call_and_read_body_json</strong> function. It must be noted that when we call the <strong class="source-inline">call_and_read_body_json</strong> function, we declare that the type returned under the <strong class="source-inline">resp</strong> variable name to be <strong class="source-inline">ResponseFromTest</strong>. We then assert that the user ID is from the <span class="No-Break">request response.</span></p>
			<p>Now that we have seen how to create a fake HTTP request with a header, this is a good opportunity for you to try and build the test that makes a request with a fake token that cannot be decoded. If you have attempted this, it should look like the <span class="No-Break">following code:</span></p>
			<pre class="source-code">
#[actix_web::test]
async fn test_false_token_request() {
    let app = init_service(App::new().route("/", web::get()
                  .to(test_handler))).await;
    let mut req = TestRequest::default()
        .insert_header(ContentType::plaintext())
        .to_request();
    let header_name = HeaderName::from_str("token")
        .unwrap();
    let header_value = HeaderValue::from_str("test")
        .unwrap();
    req.headers_mut().insert(header_name, header_value);
    let resp = call_service(&amp;app, req).await;
    assert_eq!("401", resp.status().as_str());
}</pre>
			<p>Looking at the following code, we can see that we inserted a false token into the header using the approach <a id="_idIndexMarker887"/>laid out in the passing token<a id="_idIndexMarker888"/> request test with the unauthorized assertion used in the test with no token provided. If we run all the tests now, we should get the <span class="No-Break">following printout:</span></p>
			<pre class="console">
running 9 tests
test to_do::structs::base::base_tests::new ... ok
test to_do::structs::done::done_tests::new ... ok
test to_do::structs::pending::pending_tests::new ... ok
test jwt::jwt_tests::get_key ... ok
test jwt::jwt_tests::decode_incorrect_token ... ok
test jwt::jwt_tests::encode_decode ... ok
test jwt::jwt_tests::test_no_token_request ... ok
test jwt::jwt_tests::test_false_token_request ... ok
test jwt::jwt_tests::test_passing_token_request ... ok
test result: ok. 9 passed; 0 failed; 0 ignored;
0 measured; 0 filtered out; finished in 0.00s</pre>
			<p>From the preceding output, our <strong class="source-inline">jwt</strong> and <strong class="source-inline">to_do</strong> modules are now fully unit-tested. Considering that Rust is still a new language, we have managed to painlessly unit test our code because we structured our code in a <span class="No-Break">modular fashion.</span></p>
			<p>The <strong class="source-inline">tests</strong> crate that <strong class="source-inline">actix_web</strong> provided enabled us to test edge cases quickly and easily. In this section, we tested how our functions processed requests with missing tokens, false tokens, and correct tokens. We have seen first-hand how Rust enables us to run unit tests on <span class="No-Break">our code.</span></p>
			<p>Everything is configured with <strong class="source-inline">cargo</strong>. We do not have to set up paths, install extra modules, or configure environment variables. All we must do is define modules with the <strong class="source-inline">test</strong> attribute <a id="_idIndexMarker889"/>and <a id="_idIndexMarker890"/>run the <strong class="source-inline">cargo test</strong> command. However, we must remember that our views and JSON serialization code are not unit-tested. This is where we switch to Postman to test our <span class="No-Break">API endpoints.</span></p>
			<h1 id="_idParaDest-190"><a id="_idTextAnchor191"/>Writing tests in Postman</h1>
			<p>In this section, we <a id="_idIndexMarker891"/>will be implementing functional integration tests using Postman to test our API endpoints. This will test our JSON processing and database access. To do this, we will follow <span class="No-Break">these steps:</span></p>
			<ol>
				<li>We are going to have to create a test user for our Postman tests. We can do this with the JSON body shown <span class="No-Break">as follows:</span><pre class="source-code">
{</pre><pre class="source-code">
    "name": "maxwell",</pre><pre class="source-code">
    "email": "maxwellflitton@gmail.com",</pre><pre class="source-code">
    "password": "test"</pre><pre class="source-code">
}</pre></li>
				<li>We need to add a <strong class="source-inline">POST</strong> request to the <strong class="source-inline">http://127.0.0.1:8000/v1/user/create</strong> URL. Once we have done this, we can use our login endpoint for our Postman tests. Now that we have created our test user, we must get the token from the response header of the <strong class="source-inline">POST</strong> request to the <strong class="source-inline">http://127.0.0.1:8000/v1/auth/login</strong> URL with the JSON <span class="No-Break">request body:</span><pre class="source-code">
{</pre><pre class="source-code">
    "username": "maxwell",</pre><pre class="source-code">
    "password": "test"</pre><pre class="source-code">
}</pre></li>
			</ol>
			<p>This gives us<a id="_idIndexMarker892"/> the following <span class="No-Break">Postman layout:</span></p>
			<div>
				<div id="_idContainer094" class="IMG---Figure">
					<img src="image/Figure_9.1_B18722.jpg" alt="Figure 9.1 – Creating a new use Postman request"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.1 – Creating a new use Postman request</p>
			<p>With this token, we have all the information needed to create our Postman collection. Postman is a collection of API requests. In this collection, we can bunch all our to-do item API calls together using the user token as authentication. The result of the call is <span class="No-Break">as follows:</span></p>
			<p class="IMG---Figure"> </p>
			<div>
				<div id="_idContainer095" class="IMG---Figure">
					<img src="image/Figure_9.2_B18722.jpg" alt="Figure 9.2 – Creating new use Postman response"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.2 – Creating new use Postman response</p>
			<ol>
				<li value="3">We can create <a id="_idIndexMarker893"/>our collection with the following Postman button, that is, <strong class="bold">+ </strong><span class="No-Break"><strong class="bold">New Collection</strong></span><span class="No-Break">:</span></li>
			</ol>
			<div>
				<div id="_idContainer096" class="IMG---Figure">
					<img src="image/Figure_9.3_B18722.jpg" alt="Figure 9.3 – Creating new Postman collection"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.3 – Creating new Postman collection</p>
			<ol>
				<li value="4">Once we have <a id="_idIndexMarker894"/>clicked this, we must make sure that our user token is defined for the collection, as all to-do item API calls need the token. This can be done by using the <strong class="bold">Authorization</strong> configuration for our API calls, as seen in the <span class="No-Break">following screenshot:</span></li>
			</ol>
			<div>
				<div id="_idContainer097" class="IMG---Figure">
					<img src="image/Figure_9.4_B18722.jpg" alt="Figure 9.4 – Defining AUTH credentials in a new Postman collection"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.4 – Defining AUTH credentials in a new Postman collection</p>
			<p>We can see that we <a id="_idIndexMarker895"/>have merely copied and pasted our token into the value with <strong class="bold">token</strong> as the key, which will be inserted into the header of the requests. This should now be passed in all our requests in the collection. This collection is now stored on the left-hand side navigation bar under the <span class="No-Break"><strong class="bold">Collections</strong></span><span class="No-Break"> tab.</span></p>
			<ol>
				<li value="5">We have now configured our collection and can now add requests under the collection by clicking the grayed-out <strong class="bold">Add Request</strong> button shown in <span class="No-Break">this screenshot:</span></li>
			</ol>
			<p class="IMG---Figure"> </p>
			<div>
				<div id="_idContainer098" class="IMG---Figure">
					<img src="image/Figure_9.5_B18722.jpg" alt="Figure 9.5 – Creating a new request for our Postman collection"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.5 – Creating a new request for our Postman collection</p>
			<p>Now, we must think<a id="_idIndexMarker896"/> about our approach to testing the flow of testing as this has to <span class="No-Break">be self-contained.</span></p>
			<h2 id="_idParaDest-191"><a id="_idTextAnchor192"/>Writing ordered requests for tests</h2>
			<p>Our requests <a id="_idIndexMarker897"/>will take the <span class="No-Break">following order:</span></p>
			<ol>
				<li value="1"><strong class="bold">Create</strong>: Create a to-do item, then check the return to see if it is <span class="No-Break">stored correctly.</span></li>
				<li><strong class="bold">Create</strong>: Create another to-do item, checking the return to see if the previous one is stored and that the process can handle <span class="No-Break">two items.</span></li>
				<li><strong class="bold">Create</strong>: Create another to-do item with the same title as one of the other items, checking the response to ensure that our application is not storing duplicate to-do items with the <span class="No-Break">same title.</span></li>
				<li><strong class="bold">Edit</strong>: Edit an item, checking the response to see if the edited item has been changed to <em class="italic">done</em> and that it is stored in the <span class="No-Break">correct list.</span></li>
				<li><strong class="bold">Edit</strong>: Edit the second item to see if the <em class="italic">edit</em> effect is permanent and that the <em class="italic">done</em> list supports <span class="No-Break">both items.</span></li>
				<li><strong class="bold">Edit</strong>: Edit an item that is not present in the application to see if the application handles <span class="No-Break">this correctly.</span></li>
				<li><strong class="bold">Delete</strong>: Delete one to-do item to see if the response no longer returns the deleted to-do item, meaning that it is no longer stored in <span class="No-Break">the database.</span></li>
				<li><strong class="bold">Delete</strong>: Delete the final to-do item, checking the response to see if there are no items left, showing that the <em class="italic">delete</em> action <span class="No-Break">is permanent.</span></li>
			</ol>
			<p>We need to run the <a id="_idIndexMarker898"/>preceding tests for them to work as they rely on the previous action being correct. When we create a request for the collection, we must be clear about what the request is doing, which step it is on, and what type of request it is. For instance, creating our first <em class="italic">create</em> test will look like <span class="No-Break">the following:</span></p>
			<div>
				<div id="_idContainer099" class="IMG---Figure">
					<img src="image/Figure_9.6_B18722.jpg" alt="Figure 9.6 – Creating our first Postman create request"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.6 – Creating our first Postman create request</p>
			<p>As we can see, the <a id="_idIndexMarker899"/>step is appended with the type by an underscore. We then put the description of the test from the list in the <strong class="bold">Request description (Optional)</strong> field. When defining the request, you may realize that the API key is not in the header of <span class="No-Break">the request.</span></p>
			<p>This is because it is in the hidden autogenerated headers of the request. Our first request must be a <strong class="source-inline">POST</strong> request with the <span class="No-Break"><strong class="source-inline">http://127.0.0.1:8000/v1/item/create/washing</strong></span><span class="No-Break"> URL.</span></p>
			<p>This creates the to-do item <em class="italic">washing</em>. However, before we click the <strong class="bold">Send</strong> button, we must move over to the <strong class="bold">Tests</strong> tab in our Postman request, just to the left of the <strong class="bold">Settings</strong> tab, to write our tests as seen in the <span class="No-Break">following screenshot:</span></p>
			<div>
				<div id="_idContainer100" class="IMG---Figure">
					<img src="image/Figure_9.7_B18722.jpg" alt="Figure 9.7 – Accessing the tests script in Postman"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.7 – Accessing the tests script in Postman</p>
			<p>Our tests must be written in JavaScript. However, we can get access to Postman’s <strong class="source-inline">test</strong> library by typing <strong class="source-inline">pm</strong> into the test script. First, at the top of the test script, we need to process the request, which is done with <span class="No-Break">this code:</span></p>
			<pre class="source-code">
var result = pm.response.json()</pre>
			<p>With the preceding line, we can access the response JSON throughout the test script. To comprehensively test our request, we need to follow <span class="No-Break">these steps:</span></p>
			<ol>
				<li value="1">First, we need to check the basic content of the response. Our first test is to check to see<a id="_idIndexMarker900"/> if the response is <strong class="source-inline">200</strong>. This can be done with the <span class="No-Break">following code:</span><pre class="source-code">
pm.test("response is ok", function () {</pre><pre class="source-code">
    pm.response.to.have.status(200);</pre><pre class="source-code">
});</pre></li>
			</ol>
			<p>Here, we define the test description. Then, the function that the test runs <span class="No-Break">is defined.</span></p>
			<ol>
				<li value="2">Then, we check the length of data in the response. After the preceding test, we will define our test to check if the pending item has a length of one via the <span class="No-Break">following code:</span><pre class="source-code">
pm.test("returns one pending item", function(){</pre><pre class="source-code">
    if (result["pending_items"].length !== 1){</pre><pre class="source-code">
        throw new Error(</pre><pre class="source-code">
        "returns the wrong number of pending items");</pre><pre class="source-code">
    }</pre><pre class="source-code">
})</pre></li>
			</ol>
			<p>In the preceding code, we do a simple check of the length and throw an error if the length is not one as we only expect one pending item in the <span class="No-Break"><strong class="source-inline">pending_items</strong></span><span class="No-Break"> list.</span></p>
			<ol>
				<li value="3">Then, we inspect<a id="_idIndexMarker901"/> the title and status of the pending item in the <span class="No-Break">following code:</span><pre class="source-code">
pm.test("Pending item has the correct title", function(){</pre><pre class="source-code">
    if (result["pending_items"][0]["title"] !==</pre><pre class="source-code">
        "washing"){</pre><pre class="source-code">
        throw new Error(</pre><pre class="source-code">
        "title of the pending item is not 'washing'");</pre><pre class="source-code">
    }</pre><pre class="source-code">
})</pre><pre class="source-code">
pm.test("Pending item has the correct status",</pre><pre class="source-code">
         function()</pre><pre class="source-code">
    {</pre><pre class="source-code">
        if (result["pending_items"][0]["status"] !==</pre><pre class="source-code">
            "PENDING"){</pre><pre class="source-code">
            throw new Error(</pre><pre class="source-code">
            "status of the pending item is not</pre><pre class="source-code">
                'pending'");</pre><pre class="source-code">
    }</pre><pre class="source-code">
})</pre></li>
			</ol>
			<p>In the preceding code, we throw an error if the status or title does not match what we want. Now we have satisfied our tests for the pending items, we can move on to the tests for the <span class="No-Break">done items.</span></p>
			<ol>
				<li value="4">Seeing as our done items should be zero, the tests have the <span class="No-Break">following definition:</span><pre class="source-code">
pm.test("returns zero done items", function(){</pre><pre class="source-code">
    if (result["done_items"].length !== 0){</pre><pre class="source-code">
        throw new Error(</pre><pre class="source-code">
        "returns the wrong number of done items");</pre><pre class="source-code">
    }</pre><pre class="source-code">
})</pre></li>
			</ol>
			<p>In the preceding code, we are merely ensuring that the <strong class="source-inline">done_items</strong> array has a length <span class="No-Break">of zero.</span></p>
			<ol>
				<li value="5">Now, we must check the counts of our done and pending items. This is done in the <span class="No-Break">following </span><span class="No-Break"><a id="_idIndexMarker902"/></span><span class="No-Break">code:</span><pre class="source-code">
pm.test("checking pending item count", function(){</pre><pre class="source-code">
    if (result["pending_item_count"] !== 1){</pre><pre class="source-code">
        throw new Error(</pre><pre class="source-code">
        "pending_item_count needs to be one");</pre><pre class="source-code">
    }</pre><pre class="source-code">
})</pre><pre class="source-code">
pm.test("checking done item count", function(){</pre><pre class="source-code">
    if (result["done_item_count"] !== 0){</pre><pre class="source-code">
        throw new Error(</pre><pre class="source-code">
        "done_item_count needs to be zero");</pre><pre class="source-code">
    }</pre><pre class="source-code">
})</pre></li>
			</ol>
			<p>Now that our tests are built, we can make the request by clicking the <strong class="bold">SEND</strong> button in Postman to get the following output for <span class="No-Break">the tests:</span></p>
			<div>
				<div id="_idContainer101" class="IMG---Figure">
					<img src="image/Figure_9.8_B18722.jpg" alt="Figure 9.8 – Postman tests output"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.8 – Postman tests output</p>
			<p>We can see that our test descriptions and the status of the test are highlighted. If you get an error <a id="_idIndexMarker903"/>the status will be red with a <strong class="bold">FAIL</strong>. Now that our first create test has been done, we can create our second <span class="No-Break">create test.</span></p>
			<h2 id="_idParaDest-192"><a id="_idTextAnchor193"/>Creating a test for an HTTP request</h2>
			<p>We can <a id="_idIndexMarker904"/>then create the <strong class="source-inline">2_create</strong> test with<a id="_idIndexMarker905"/> this URL: <strong class="source-inline">http://127.0.0.1:8000/v1/item/create/cooking</strong>. This is a good opportunity to try and build the test yourself with the testing methods that we have explored in the previous step. If you have attempted to build the tests, they should look like the <span class="No-Break">following code:</span></p>
			<pre class="source-code">
var result = pm.response.json()
pm.test("response is ok", function () {
    pm.response.to.have.status(200);
});
pm.test("returns two pending item", function(){
    if (result["pending_items"].length !== 2){
        throw new Error(
        "returns the wrong number of pending items");
    }
})
pm.test("Pending item has the correct title", function(){
    if (result["pending_items"][0]["title"] !== "washing"){
        throw new Error(
        "title of the pending item is not 'washing'");
    }
})
pm.test("Pending item has the correct status", function(){
    if (result["pending_items"][0]["status"] !==
        "PENDING"){
        throw new Error(
        "status of the pending item is not 'pending'");
    }
})
pm.test("Pending item has the correct title", function(){
    if (result["pending_items"][1]["title"] !== "cooking"){
        throw new Error(
        "title of the pending item is not 'cooking'");
    }
})
pm.test("Pending item has the correct status", function(){
    if (result["pending_items"][1]["status"] !==
        "PENDING"){
        throw new Error(
        "status of the pending item is not 'pending'");
    }
})
pm.test("returns zero done items", function(){
    if (result["done_items"].length !== 0){
        throw new Error(
        "returns the wrong number of done items");
    }
})
pm.test("checking pending item count", function(){
    if (result["pending_item_count"].length === 1){
        throw new Error(
        "pending_item_count needs to be one");
    }
})
pm.test("checking done item count", function(){
    if (result["done_item_count"].length === 0){
        throw new Error(
        "done_item_count needs to be zero");
    }
})</pre>
			<p>We can see that we have added a couple of extra tests on the second pending item. The preceding tests also directly apply to the <strong class="source-inline">3_create</strong> test as a duplicate creation will be the same as we will be using the same URL <span class="No-Break">as </span><span class="No-Break"><strong class="source-inline">2_create</strong></span><span class="No-Break">.</span></p>
			<p>The preceding tests require a fair amount of repetition in these tests, slightly altering the length of arrays, item counts, and attributes within these arrays. This is a good opportunity to practice basic Postman tests. If you need to cross-reference your tests with mine, you can assess them in the JSON file at the following <span class="No-Break">URL: </span><a href="https://github.com/PacktPublishing/Rust-Web-Programming-2nd-Edition/blob/main/chapter09/building_test_pipeline/web_app/scripts/to_do_items.postman_collection.json"><span class="No-Break">https://github.com/PacktPublishing/Rust-Web-Programming-2nd-Edition/blob/main/chapter09/building_test_pipeline/web_app/scripts/to_do_items.postman_collection.json</span></a><span class="No-Break">.</span></p>
			<p>In this section, we <a id="_idIndexMarker906"/>have put in a series of steps for <a id="_idIndexMarker907"/>Postman to test when an API call is made. This is not just useful for our application. Postman can hit any API on the internet it has access to. Therefore, you can use Postman tests to monitor live servers and <span class="No-Break">third-party APIs.</span></p>
			<p>Now, running all these tests can be arduous if it must be done manually every time. We can automate the running and checking of all the tests in this collection <a id="_idIndexMarker908"/>using <strong class="bold">Newman</strong>. If we automate these collections, we can run tests at certain times every day on live servers and third-party APIs we rely on, alerting us to when our servers or the third-party <span class="No-Break">API breaks.</span></p>
			<p>Newman will give us a good foundation for further development in this area. In the next section, we’ll export the collection and run all the API tests in the exported collection in sequence <span class="No-Break">using Newman.</span></p>
			<h1 id="_idParaDest-193"><a id="_idTextAnchor194"/>Automating Postman tests with Newman</h1>
			<p>To automate <a id="_idIndexMarker909"/>the series of tests, in this section, we<a id="_idIndexMarker910"/> will export our to-do item Postman collection in the correct sequence. But first, we must export the collection as a JSON file. This can be done by clicking on our collection in Postman on the left-hand navigation bar and clicking the grayed-out <strong class="bold">Export</strong> button, as seen in the <span class="No-Break">following screenshot:</span></p>
			<div>
				<div id="_idContainer102" class="IMG---Figure">
					<img src="image/Figure_9.9_B18722.jpg" alt="Figure 9.9 – Exporting our Postman collection"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.9 – Exporting our Postman collection</p>
			<p>Now that we have exported the collection, we can quickly inspect it to see how the file is structured. The <a id="_idIndexMarker911"/>following code defines the header<a id="_idIndexMarker912"/> of the suite <span class="No-Break">of tests:</span></p>
			<pre class="source-code">
"info": {
    "_postman_id": "bab28260-c096-49b9-81e6-b56fc5f60e9d",
    "name": "to_do_items",
    "schema": "https://schema.getpostman.com
    /json/collection/v2.1.0/collection.json",
    "_exporter_id": "3356974"
},</pre>
			<p>The preceding code tells Postman what schema is needed to run the tests. If the code is imported into Postman, the ID and name will be visible. The file then goes on to define the individual tests via the code given <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
"item": [
    {
        "name": "1_create",
        "event": [
            {
                "listen": "test",
                "script": {
                    "exec": [
                        "var result = pm.response.json()",
                        . . .
                    ],
                    "type": "text/javascript"
                }
            }
        ],
        "request": {
            "method": "POST",
            "header": [
                {
                    "key": "token",
                    "value": "eyJhbGciOiJIUzI1NiJ9
                    .eyJ1c2VyX2lkIjo2fQ.
                    uVo7u877IT2GEMpB_gxVtxhMAYAJD8
                    W_XiUoNvR7_iM",
                    "type": "text",
                    "disabled": true
                }
            ],
            "url": {
                "raw": "http://127.0.0.1:8000/
                v1/item/create/washing",
                "protocol": "http",
                "host": ["127", "0", "0", "1"],
                "port": "8000",
                "path": ["v1", "item", "create", "washing"]
            },
            "description": "create a to-do item,
            and then check the
            return to see if it is stored correctly "
        },
        "response": []
    },</pre>
			<p>From the preceding code, we can see that our tests, method, URL, headers, and more are all defined in <a id="_idIndexMarker913"/>an <a id="_idIndexMarker914"/>array. A quick inspection of the <strong class="source-inline">item</strong> array will show that the tests will be executed in the order that <span class="No-Break">we want.</span></p>
			<p>Now, we can simply run it with Newman. We can install Newman with the <span class="No-Break">following command:</span></p>
			<pre class="console">
npm install -g newman</pre>
			<p class="callout-heading">Note</p>
			<p class="callout">It must be noted that the preceding command is a global install, which can sometimes have issues. To avoid this, you can setup a <strong class="source-inline">package.json</strong> file with the <span class="No-Break">following contents:</span></p>
			<pre class="source-code">
{
  "name": "newman testing",
  "description": "",
  "version": "0.1.0",
  "scripts": {
    "test": "newman run to_do_items.
             postman_collection.json"
  },
  "dependencies": {
    "newman": "5.3.2"
  }
}</pre>
			<p class="callout">With this <strong class="source-inline">package.json</strong>, we have defined the test command and the Newman dependency. We can install our dependencies locally with the <span class="No-Break">following command:</span></p>
			<pre class="source-code">
npm install</pre>
			<p class="callout">This then installs all we need under the <strong class="source-inline">node_modules</strong> directory. Instead of running the Newman test command directly, we can use the test command defined in <strong class="source-inline">package.json</strong> with the <span class="No-Break">following command:</span></p>
			<pre class="source-code">
npm run test</pre>
			<p>Now that we<a id="_idIndexMarker915"/> have<a id="_idIndexMarker916"/> installed Newman, we can run the collection of tests against the exported collection JSON file with <span class="No-Break">this command:</span></p>
			<pre class="console">
newman run to_do_items.postman_collection.json</pre>
			<p>The preceding command runs all the tests and gives us a status report. Each description is printed out and the status is also denoted by the side of the test. The following is a typical printout of an API test <span class="No-Break">being assessed:</span></p>
			<pre class="console">
→ 1_create
    POST http://127.0.0.1:8000/v1/item/create/washing
    [200 OK, 226B, 115ms]
    ✓ response is ok
    ✓ returns one pending item
    ✓ Pending item has the correct title
    ✓ Pending item has the correct status
    ✓ returns zero done items
    ✓ checking pending item count
    ✓ checking done item count</pre>
			<p>The preceding<a id="_idIndexMarker917"/> output<a id="_idIndexMarker918"/> gives us the name, method, URL, and response. Here, all of them passed. If one did not, then the test description would sport a <em class="italic">cross</em> instead of a <em class="italic">tick</em>. We also get the <span class="No-Break">following summary:</span></p>
			<div>
				<div id="_idContainer103" class="IMG---Figure">
					<img src="image/Figure_9.10_B18722.jpg" alt="Figure 9.10 – Newman summary"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.10 – Newman summary</p>
			<p>We can see that all our tests passed. With this, we have managed to automate our functional testing, enabling us to test a full workflow with minimal effort. However, what we have done is not maintainable. For instance, our token will expire, meaning that if we run tests<a id="_idIndexMarker919"/> later <a id="_idIndexMarker920"/>in the month, they will fail. In the next section, we will build an entire automated pipeline that will build our server, update our token, and run <span class="No-Break">our tests.</span></p>
			<h1 id="_idParaDest-194"><a id="_idTextAnchor195"/>Building an entire automated testing pipeline</h1>
			<p>When it comes to <a id="_idIndexMarker921"/>development and testing, we need an environment that can be torn down and recreated easily. There is nothing worse than building up data in a database on your local machine to be able to develop further features using that data. However, the database container might be deleted by accident, or you may write some code that corrupts the data. Then, you must spend a lot of time recreating the data before you can get back to where you were. If the system is complex and there is missing documentation, you might forget the steps needed to recreate your data. If you are not comfortable with destroying your local database and starting again when developing and testing, there is something wrong and it is only a matter of time before you get caught out. In this section, we are going to create a single Bash script that carries out the <span class="No-Break">following actions:</span></p>
			<ol>
				<li value="1">Starts database Docker containers in <span class="No-Break">the background.</span></li>
				<li>Compiles the <span class="No-Break">Rust server.</span></li>
				<li>Runs <span class="No-Break">unit tests.</span></li>
				<li>Starts running the <span class="No-Break">Rust server.</span></li>
				<li>Runs migrations to the database running <span class="No-Break">in Docker.</span></li>
				<li>Makes an HTTP request to create <span class="No-Break">a user.</span></li>
				<li>Makes an HTTP request to log in and get <span class="No-Break">a token.</span></li>
				<li>Updates the Newman JSON file with the token from <span class="No-Break">the login.</span></li>
				<li>Runs the <span class="No-Break">Newman tests.</span></li>
				<li>Removes the files produced in this <span class="No-Break">whole process.</span></li>
				<li>Stops the Rust server <span class="No-Break">from running.</span></li>
				<li>Stops and destroy the Docker containers that were running for the <span class="No-Break">whole process.</span></li>
			</ol>
			<p>There are a lot of <a id="_idIndexMarker922"/>steps laid out in the preceding list. Glancing at this list, it would seem intuitive to break the code blocks that we are going to explore into steps; however, we are going to run nearly all the steps in one Bash script. A lot of the preceding steps outlined can be achieved in one line of Bash code each. It would be excessive to break the code down into steps. Now that we have all the steps needed, we can set up our testing infrastructure. First, we need to set up a <strong class="source-inline">scripts</strong> directory alongside the <strong class="source-inline">src</strong> directory in the root of <strong class="source-inline">web_app</strong>. Inside the <strong class="source-inline">scripts</strong> directory, we then need to have a <strong class="source-inline">run_test_pipeline.sh</strong> script that will run the main testing process. We also need to put our Newman JSON <strong class="source-inline">config</strong> file in the <span class="No-Break"><strong class="source-inline">scripts</strong></span><span class="No-Break"> directory.</span></p>
			<p>We will use <strong class="source-inline">bash</strong> to orchestrate the entire testing pipeline, which is the best tool for orchestrating testing tasks. In our <strong class="source-inline">srcipts/run_test_pipeline.sh</strong> script, we will start out with the <span class="No-Break">following code:</span></p>
			<pre class="source-code">
#!/bin/bash
# move to directory of the project
SCRIPTPATH="$( cd "$(dirname "$0")" ; pwd -P )"
cd $SCRIPTPATH
cd ..</pre>
			<p>In the preceding code, we told the computer that the code block is a Bash script with the <strong class="source-inline">#!/bin/bash</strong> shebang line. Bash scripts run from the current working directory of where the Bash script it called from. We can call the script from multiple directories so we need to ensure that we get the directory of where the script is housed, which is the <strong class="source-inline">scripts</strong> directory, assign that to a variable called <strong class="source-inline">SCRIPTPATH</strong>, move to that directory, and then move out one with the <strong class="source-inline">cd..</strong> command to be in the main directory where the Docker, config, and <a id="_idIndexMarker923"/>Cargo files are. We can then spin up our Docker containers in the background with the <strong class="source-inline">-d</strong> flag and loop until the database is accepting connections with the <span class="No-Break">following code:</span></p>
			<pre class="source-code">
# spin up docker and hold script until accepting connections
docker-compose up -d
until pg_isready -h localhost -p 5433 -U username
do
  echo "Waiting for postgres"
  sleep 2;
done</pre>
			<p>Now that our Docker containers are running, we can now move on to building our Rust server. First, we can compile the Rust server and run our unit tests with the <span class="No-Break">following code:</span></p>
			<pre class="console">
cargo build
cargo test</pre>
			<p>Once the unit tests have been run, we can then run our server in the background with the <span class="No-Break">following code:</span></p>
			<pre class="source-code">
# run server in background
cargo run config.yml &amp;
SERVER_PID=$!
sleep 5</pre>
			<p>With <strong class="source-inline">&amp;</strong> at the end of the command, the <strong class="source-inline">cargo run config.yml</strong> runs in the background. We then get the process ID of the <strong class="source-inline">cargo run config.yml</strong> command and assign it to the variable <strong class="source-inline">SERVER_PID</strong>. We then sleep for 5 seconds to be sure that the server is ready to accept connections. Before we make any API calls to our server, we must run our migrations to the database with the <span class="No-Break">following code:</span></p>
			<pre class="console">
diesel migration run</pre>
			<p>We then move<a id="_idIndexMarker924"/> back into our <strong class="source-inline">scripts</strong> directory and make an API call to our server that creates <span class="No-Break">a user:</span></p>
			<pre class="source-code">
# create the user
curl --location --request POST 'http://localhost:8000/v1/user/create' \
--header 'Content-Type: application/json' \
--data-raw '{
    "name": "maxwell",
    "email": "maxwellflitton@gmail.com",
    "password": "test"
}'</pre>
			<p>If you are wondering how to use <strong class="source-inline">curl</strong> to make HTTP requests in Bash, you can autogenerate them using your Postman tool. On the right-hand side of the Postman tool, you can see a <strong class="bold">Code</strong> button, as shown in the <span class="No-Break">following screenshot:</span></p>
			<div>
				<div id="_idContainer104" class="IMG---Figure">
					<img src="image/Figure_9.11_B18722.jpg" alt="Figure 9.11 – Code generation tool"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.11 – Code generation tool</p>
			<p>Once you have clicked on the code tag, there is a drop-down menu where you can select from a range of languages. Once you have selected the language you want, your API call will be displayed in <a id="_idIndexMarker925"/>a code snippet for your chosen language, which you can then copy <span class="No-Break">and paste.</span></p>
			<p>Now that we have created our user, we can log in and store the token in the <strong class="source-inline">fresh_token.json</strong> file with the following code; however, it must be noted that <strong class="source-inline">curl</strong> first needs to <span class="No-Break">be installed:</span></p>
			<pre class="source-code">
# login getting a fresh token
echo $(curl --location --request GET 'http://localhost:8000/v1/auth/login' \
--header 'Content-Type: application/json' \
--data-raw '{
    "username": "maxwell",
    "password": "test"
}') &gt; ./fresh_token.json</pre>
			<p>What is happening here is that we can wrap the result of the API call into a variable with <strong class="source-inline">$(...)</strong>. We then echo this and write it to the file using <strong class="source-inline">echo $(...) &gt; ./fresh_token.json</strong>. We can then insert the fresh token into the Newman data and run the Newman API tests with the <span class="No-Break">following code:</span></p>
			<pre class="source-code">
TOKEN=$(jq '.token' fresh_token.json)
jq '.auth.apikey[0].value = '"$TOKEN"''
to_do_items.postman_collection.json &gt; test_newman.json
newman run test_newman.json</pre>
			<p>Our testing is now done. We can clean up the files created when running the tests, destroy the Docker<a id="_idIndexMarker926"/> containers, and stop our server running with the <span class="No-Break">following code:</span></p>
			<pre class="source-code">
rm ./test_newman.json
rm ./fresh_token.json
# shut down rust server
kill $SERVER_PID
cd ..
docker-compose down</pre>
			<p class="callout-heading">Note</p>
			<p class="callout"><strong class="source-inline">curl</strong> and <strong class="source-inline">jq</strong> both need to be installed before we can run the Bash script. If you are using Linux, you might need to run the <span class="No-Break">following command:</span></p>
			<pre class="source-code">
sudo chmod +x ./run_test_pipeline.sh</pre>
			<p>We can then run our testing script with the <span class="No-Break">following command:</span></p>
			<pre class="console">
sh run_test_pipeline.sh</pre>
			<p>Showing the whole printout would just needlessly fill up the book. However, we can see the end of the test printout in the <span class="No-Break">following screenshot:</span></p>
			<div>
				<div id="_idContainer105" class="IMG---Figure">
					<img src="image/Figure_9.12_B18722.jpg" alt="Figure 9.12 – The testing pipeline output"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.12 – The testing pipeline output</p>
			<p>Here, the printout<a id="_idIndexMarker927"/> makes it clear that the Newman tests have run and passed. After the tests were completed, the server was shut down and the Docker containers that were supporting the server were stopped and removed. If you want to write this log to a <strong class="source-inline">txt</strong> file, you can do so with the <span class="No-Break">following command:</span></p>
			<pre class="console">
sh run_test_pipeline.sh &gt; full_log.txt</pre>
			<p>There you have it! A fully working test pipeline that automates the setting up, testing, and clean-up of our server. Because we have written it in a simple Bash test pipeline, we could integrate<a id="_idIndexMarker928"/> these steps in automation pipelines such as Travis, Jenkins, or GitHub Actions. These pipeline tools fire automatically when a <strong class="source-inline">pull</strong> request and merges <span class="No-Break">are performed.</span></p>
			<h1 id="_idParaDest-195"><a id="_idTextAnchor196"/>Summary</h1>
			<p>In this chapter, we went through the workflows and components of our application, breaking them down so we could pick the right tools for the right part. We used unit testing so we could inspect several edge cases quickly to see how each function and struct interacted <span class="No-Break">with others.</span></p>
			<p>We also directly inspected our custom structs with unit tests. We then used the <strong class="source-inline">actix_web</strong> test structs to mock requests to see how the functions that use the structs and process the requests work. However, when we came to the main API views module, we switched <span class="No-Break">to Postman.</span></p>
			<p>This is because our API endpoints were simple. They created, edited, and deleted to-do items. We could directly assess this process by making API calls and inspecting the responses. Out of the box we managed to assess the JSON processing for accepting and returning data. We were also able to assess the querying, writing, and updating of the data in the database with these <span class="No-Break">Postman tests.</span></p>
			<p>Postman enabled us to test a range of processes quickly and efficiently. We even sped up this testing process by automating it via Newman. However, it must be noted that this approach is not a one-size-fits-all approach. If the API view functions become more complex, with more moving parts, such as communicating with another API or service, then the Newman approach would have to be redesigned. Environment variables that trigger mocking such processes would have to be considered so we can quickly test a range of <span class="No-Break">edge cases.</span></p>
			<p>Mocking objects will be needed if the system grows as the dependencies of our structs will grow. This is where we create a fake struct or function and define the output for a test. To do this, we will need an external crate such as <strong class="source-inline">mockall</strong>. The documentation on this crate is covered in the <em class="italic">Further reading</em> section of <span class="No-Break">this chapter.</span></p>
			<p>Our application now fully runs and has a range of tests. Now, all we have left is to deploy our application on <span class="No-Break">a server.</span></p>
			<p>In the next chapter, we will set up a server on <strong class="bold">Amazon</strong> <strong class="bold">Web</strong> <strong class="bold">Services</strong> (<strong class="bold">AWS</strong>), utilizing <em class="italic">Docker</em> to deploy our application on a server. We will cover the process of setting up the AWS configuration, running tests, and then deploying our application on our server if the <span class="No-Break">tests pass.</span></p>
			<h1 id="_idParaDest-196"><a id="_idTextAnchor197"/>Questions</h1>
			<ol>
				<li value="1">Why do we bother with unit tests if we can just manually play with <span class="No-Break">the application?</span></li>
				<li>What is the difference between unit tests and <span class="No-Break">functional tests?</span></li>
				<li>What are the advantages of <span class="No-Break">unit tests?</span></li>
				<li>What are the disadvantages of <span class="No-Break">unit tests?</span></li>
				<li>What are the advantages of <span class="No-Break">functional tests?</span></li>
				<li>What are the disadvantages of <span class="No-Break">functional tests?</span></li>
				<li>What is a sensible approach to building <span class="No-Break">unit tests?</span></li>
			</ol>
			<h1 id="_idParaDest-197"><a id="_idTextAnchor198"/>Answers</h1>
			<ol>
				<li value="1">When it comes to manual testing, you may forget to run a certain procedure. Running tests standardizes our standards and enables us to integrate them into continuous integration tools to ensure new code will not break the server as continuous integration can block new code merges if the <span class="No-Break">code fails.</span></li>
				<li>Unit tests isolate individual components such as functions and structs. These functions and structs are then assessed with a range of fake inputs to assess how the component interacts with different inputs. Functional tests assess the system, hitting API endpoints, and checking <span class="No-Break">the response.</span></li>
				<li>Unit tests are lightweight and do not need an entire system to run. They can test a whole set of edge cases quickly. Unit tests can also isolate exactly where the <span class="No-Break">error is.</span></li>
				<li>Unit tests are essentially isolated tests with made-up inputs. If the type of input is changed in the system but not updated in the unit test, then this test will essentially pass when it should fail. Unit tests also do not assess how the <span class="No-Break">system runs.</span></li>
				<li>Functional tests ensure that the entire infrastructure works together as it should. For instance, there could be an issue with how we configure and connect to the database. With unit tests, such problems can be missed. Also, although mocking ensures isolated tests, unit test mocks might be out of date. This means that a mocked function might return data that the updated version does not. As a result, the unit test will pass but the functional tests will not as they <span class="No-Break">test everything.</span></li>
				<li>Functional tests need to have the infrastructure to run like a database. There also must be a setup and teardown function. For instance, a functional test will affect the data stored in the database. At the end of the test, the database needs to be wiped before running the test again. This can increase the complications and can require “glue” code between <span class="No-Break">different operations.</span></li>
				<li>We start off with testing structs and functions that do not have any dependencies. Once these have been tested, we know that we are comfortable with them. We then move on to the functions and structs that have the dependencies we previously tested. Using this approach, we know that the current test we are writing does not fail due to <span class="No-Break">a dependency.</span></li>
			</ol>
			<h1 id="_idParaDest-198"><a id="_idTextAnchor199"/>Further reading</h1>
			<ul>
				<li>Mockall <span class="No-Break">documentation: </span><a href="https://docs.rs/mockall/0.9.0/mockall/"><span class="No-Break">https://docs.rs/mockall/0.9.0/mockall/</span></a></li>
				<li>Github Actions <span class="No-Break">documentation: </span><a href="https://github.com/features/actions"><span class="No-Break">https://github.com/features/actions</span></a></li>
				<li>Travis <span class="No-Break">documentation: </span><a href="https://docs.travis-ci.com/user/for-beginners/&#13;"><span class="No-Break">https://docs.travis-ci.com/user/for-beginners/</span></a></li>
				<li>Circle CI <span class="No-Break">documentation: </span><a href="https://circleci.com/docs/"><span class="No-Break">https://circleci.com/docs/</span></a></li>
				<li>Jenkins <span class="No-Break">documentation: </span><a href="https://www.jenkins.io/doc/"><span class="No-Break">https://www.jenkins.io/doc/</span></a></li>
			</ul>
		</div>
	</body></html>