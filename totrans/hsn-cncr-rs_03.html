<html><head></head><body><div><h1 class="header-title">The Rust Memory Model – Ownership, References and Manipulation</h1>
                
            
            
                
<p>In the previous chapter, <a href="8c61da2f-08c8-40be-89d4-d8afa8510850.xhtml" target="_blank">Chapter 2</a>, <em>Sequential Rust Performance and Testing</em>, we discussed factors that contribute or detract from the serial performance of a Rust program. We did not explicitly address concurrent performance for want of sufficient information about the way Rust's abstract memory model interacts with the real memory hierarchy of a machine. In this chapter, we'll discuss Rust's memory model, how to control the layout of types in memory, how types are aliased, and how Rust's memory safety works. We'll dig into the standard library to understand how this plays out in practice. This chapter will also examine common crates in the ecosystem that will be of interest to us later in this book. Please be aware that by the time you read this chapter, the <kbd>rustc</kbd> implementation will have changed, potentially making our code listings here no longer square with the naming patterns in <kbd>rustc</kbd> itself. If you wish to follow along, please check out Rust at SHA <kbd>da569fa9ddf8369a9809184d43c600dc06bd4b4d</kbd>.</p>
<p>By the close of this chapter, we will have:</p>
<ul>
<li>Investigated how Rust lays objects out in memory</li>
<li>Discussed the various ways Rust points to memory and their guarantees</li>
<li>Discussed how Rust allocates and deallocates memory</li>
<li>Discussed how Rust denotes stack and heap allocations </li>
<li>Investigated the internal implementation of <kbd>Option</kbd>, <kbd>Cell</kbd>, <kbd>CellRef</kbd> , <kbd>Rc</kbd> and <kbd>Vec</kbd>.</li>
</ul>


            

            
        
    </div>



  
<div><h1 class="header-title">Technical requirements</h1>
                
            
            
                
<p class="mce-root">This chapter requires a working Rust installation. The details of verifying your installation are covered in <a href="5f3aec9d-fd53-48ff-9ba8-43ce13e91cff.xhtml" target="_blank">Chapter 1</a>, <em>Preliminaries – Machine Architecture and Getting Started with Rust</em>. No additional software tools are required.</p>
<p class="mce-root">You can find the source code for this book's projects on GitHub: <a href="https://github.com/PacktPublishing/Hands-On-Concurrency-with-Rust">https://github.com/PacktPublishing/Hands-On-Concurrency-with-Rust</a>. This chapter has its source code under <kbd>Chapter03</kbd>.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Memory layout</h1>
                
            
            
                
<p>Rust has a handful of mechanisms to lay out compound types in memory. They are as follows:</p>
<ul>
<li>Arrays</li>
<li>Enums</li>
<li>Structs</li>
<li>Tuples</li>
</ul>
<p>Exactly how these are laid out in memory depends on the representation chosen. By default, everything in Rust is <kbd>repr(Rust)</kbd>. All <kbd>repr(Rust)</kbd> types are aligned on byte boundaries to the power of two. Every type is at least one byte in memory, then two, then four, and so forth. Primitives—<kbd>u8</kbd>, <kbd>usize</kbd>, <kbd>bool</kbd>, and <kbd>&amp;T</kbd>—are aligned to their size. In Rust, representation structures have alignment according to the largest field. Consider the following struct:</p>
<pre style="padding-left: 30px">struct AGC {
  elapsed_time2: u16,
  elapsed_time1: u16,
  wait_list_upper: u32,
  wait_list_lower: u16,
  digital_autopilot: u16,
  fine_scale: u16
}</pre>
<p><kbd>AGC</kbd> is aligned to <kbd>u32</kbd> with padding inserted as appropriate to match that 32-bit alignment. Rust will re-order fields to achieve maximal packing. Enums are different, being subject to a host of optimizations, most notably null pointer optimization. See the following enumeration:</p>
<pre style="padding-left: 30px">enum AGCInstruction {
  TC,
  TCF,
  CCS(u8),
  B(u16),
  BZF,
}</pre>
<p>This will be laid out as follows:</p>
<pre style="padding-left: 30px">struct AGCInstructionRepr {
  data: u16,
  tag: u8,
}</pre>
<p>The <kbd>data</kbd> field is wide enough to accommodate the largest inner value and the <kbd>tag</kbd> allows discrimination between variants. Where this gets complicated is in the case of an enum that holds a non-nullable pointer, and other variants cannot refer to the same. <kbd>Option&lt;&amp;T&gt;</kbd> means if a null pointer is discovered when dereferencing the option Rust can assume that the <kbd>None</kbd> variant was discovered. Rust will optimize away the tag for <kbd>Option&lt;&amp;T&gt;</kbd>.</p>
<p>Rust supports other representations. <kbd>repr(C) </kbd> lays out types in memory in a manner that C would do and is often used in FFI projects, as we'll see later in this book. <kbd>repr(packed)</kbd> lays types out in memory like <kbd>repr(Rust)</kbd> except that no padding is added, and alignment occurs only to the byte. This representation is likely to cause unaligned loads and a severe effect on performance of common CPUs, certainly the two CPU architectures we concern ourselves with in this book. The remaining representations have to do with forcing the size of fieldless enumerations—that is, enumerations that have no data in their variants—and these are useful for forcing the size of such an enum with an eye towards ABI compatability.</p>
<p>Rust allocations happen by default on the hardware stack, as is common for other low-level languages. Heap allocations must be performed explicitly by the programmer or be done implicitly when creating a new type that holds some sort of internal storage. There are complications here. By default, Rust types obey move semantics: the bits of the type are moved as appropriate between contexts. For example:</p>
<pre style="padding-left: 30px">fn project_flights() -&gt; Vec&lt;(u16, u8)&gt; {
    let mut t = Vec::new();
    t.push((1968, 2));
    t.push((1969, 4));
    t.push((1970, 1));
    t.push((1971, 2));
    t.push((1972, 2));
    t
}

fn main() {
    let mut total: u8 = 0;
    let flights = project_flights();
    for &amp;(_, flights) in flights.iter() {
        total += flights;
    }
    println!("{}", total);
}</pre>
<p>The <kbd>project_flights</kbd> function allocates a new <kbd>Vec&lt;(u16, u8)&gt;</kbd> on the heap, populates it, and then returns ownership of the heap-allocated vector to the caller. This does not mean that the bits of <kbd>t</kbd> are copied from the stack frame of <kbd>project_flights</kbd> but, instead, that the pointer  <kbd>t</kbd> is returned from the <kbd>project_flights</kbd> stack to <kbd>main</kbd>. It is possible to achieve copy semantics in Rust through the use of the <kbd>Copy</kbd> trait. <kbd>Copy</kbd> types will have their bits copied in memory from one place to the other. Rust primitive types are <kbd>Copy</kbd>—copying them is as fast as moving them, especially when the type is smaller than the native pointer. It's possible to implement <kbd>Copy</kbd> for your own type unless your type implements <kbd>Drop</kbd>, the trait that defines how a type deallocates itself. This restriction eliminates—in Rust code not using <kbd>unsafe</kbd> —the possibility of double frees. The following code block derives <kbd>Copy</kbd> for two user-defined types and is an example of a poor random generator:</p>
<pre style="padding-left: 30px">#[derive(Clone, Copy, PartialEq, Eq)]
enum Project {
    Apollo,
    Gemini,
    Mercury,
}

#[derive(Clone, Copy)]
struct Mission {
    project: Project,
    number: u8,
    duration_days: u8,
}

fn flight() -&gt; Mission {
    Mission {
        project: Project::Apollo,
        number: 8,
        duration_days: 6,
    }
}

fn main() {
    assert_eq!(::std::mem::size_of::&lt;Mission&gt;(), 3);
    let mission = flight();
    if mission.project == Project::Apollo &amp;&amp; mission.number == 8 {
        assert_eq!(mission.duration_days, 6);
    }
}</pre>


            

            
        
    </div>



  
<div><h1 class="header-title">Pointers to memory</h1>
                
            
            
                
<p>Rust defines several kinds of pointers, each with a specific purpose. <kbd>&amp;T</kbd> is a shared reference and there may be many duplicates of that shared reference. The owner of <kbd>&amp;T</kbd> does not necessarily, own <kbd>T</kbd> and may not modify it. Shared references are immutable. Mutable references—written <kbd>&amp;mut T</kbd>—also do not imply that the other  <kbd>&amp;mut T</kbd> owns <kbd>T</kbd> necessarily but the reference may be used to mutate <kbd>T</kbd>. There may be only one reference for any <kbd>T</kbd> with a <kbd>&amp;mut T</kbd>. This complicates some code but means that Rust is able to prove that two variables do not overlap in memory, unlocking a variety of optimization opportunities absent from C/C++. Rust references are designed so that the compiler is able to prove the liveness of the referred to type: references cannot dangle. This is not true of Rust's raw pointer types—<kbd>*const T</kbd> and <kbd>*mut T</kbd>—which work analogously to C pointers: they are, strictly, an address in memory and no guarantees about the data at that address are made. As such, many operations on raw pointers require the <kbd>unsafe</kbd> keyword and they are almost always seen solely in the context of performance-sensitive code or FFI interfaces. Put another way, a raw pointer may be null; a reference may never be null.</p>
<p>The rules around references often cause difficulty in situations where an immutable borrow is accidentally made of a mutable reference. The Rust documentation uses the following small program to illustrate the difficulty:</p>
<pre style="padding-left: 30px">fn main() {
    let mut x: u8 = 5;
    let y: &amp;mut u8 = &amp;mut x;

    *y += 1;

    println!("{}", x);
}</pre>
<p>The <kbd>println!</kbd> macro takes its arguments by reference, implicitly here, creating a <kbd>&amp;x</kbd>. The compiler rejects this program as <kbd>y: &amp;mut u8</kbd> is invalid. Were this program to compile, we would be subject to a race between the update of <kbd>y</kbd> and the read of <kbd>x</kbd>, depending on the CPU and memory ordering. The exclusive nature of references could be potentially limiting when working with structures. Rust allows programs to split borrows for a structure, providing that the disjoint fields cannot be aliased.</p>
<p>We demonstrate this in the following brief program:</p>
<pre style="padding-left: 30px">use std::fmt;

enum Project {
    Apollo,
    Gemini,
    Mercury,
}

impl fmt::Display for Project {
    fn fmt(&amp;self, f: &amp;mut fmt::Formatter) -&gt; fmt::Result {
        match *self {
            Project::Apollo =&gt; write!(f, "Apollo"),
            Project::Mercury =&gt; write!(f, "Mercury"),
            Project::Gemini =&gt; write!(f, "Gemini"),
        }
    }
}

struct Mission {
    project: Project,
    number: u8,
    duration_days: u8,
}

fn main() {
    let mut mission = Mission {
        project: Project::Gemini,
        number: 2,
        duration_days: 0,
    };
    let proj: &amp;Project = &amp;mission.project;
    let num: &amp;mut u8 = &amp;mut mission.number;
    let dur: &amp;mut u8 = &amp;mut mission.duration_days;

    *num = 12;
    *dur = 3;

    println!("{} {} flew for {} days", proj, num, dur);
}</pre>
<p>This same trick is difficult to impossible for general container types. Consider a map where two keys map to the same referenced <kbd>T</kbd>. Or, for now, a slice:</p>
<pre style="padding-left: 30px">use std::fmt;

enum Project {
    Apollo,
    Gemini,
    Mercury,
}

impl fmt::Display for Project {
    fn fmt(&amp;self, f: &amp;mut fmt::Formatter) -&gt; fmt::Result {
        match *self {
            Project::Apollo =&gt; write!(f, "Apollo"),
            Project::Mercury =&gt; write!(f, "Mercury"),
            Project::Gemini =&gt; write!(f, "Gemini"),
        }
    }
}

struct Mission {
    project: Project,
    number: u8,
    duration_days: u8,
}

fn main() {
    let mut missions: [Mission; 2] = [
        Mission {
            project: Project::Gemini,
            number: 2,
            duration_days: 0,
        },
        Mission {
            project: Project::Gemini,
            number: 12,
            duration_days: 2,
        },
    ];

    let gemini_2 = &amp;mut missions[0];
    let _gemini_12 = &amp;mut missions[1];

    println!(
        "{} {} flew for {} days",
        gemini_2.project, gemini_2.number, gemini_2.duration_days
    );
}</pre>
<p>This program fails to compile with the following error:</p>
<pre><strong>&gt; rustc borrow_split_array.rs
error[E0499]: cannot borrow `missions[..]` as mutable more than once at a time
  --&gt; borrow_split_array.rs:40:27
   |
39 |     let gemini_2 = &amp;mut missions[0];
   |                         ----------- first mutable borrow occurs here
40 |     let _gemini_12 = &amp;mut missions[1];
   |                           ^^^^^^^^^^^ second mutable borrow occurs here
...
46 | }
   | - first borrow ends here

error: aborting due to previous error</strong></pre>
<p>We, the programmers<em>,</em> know that this was safe—<kbd>gemini_2</kbd> and <kbd>gemini_12</kbd> don't overlap in memory—but it's not possible for the compiler to prove this. What if we had done the following:</p>
<pre style="padding-left: 30px">use std::fmt;

enum Project {
    Apollo,
    Gemini,
    Mercury,
}

impl fmt::Display for Project {
    fn fmt(&amp;self, f: &amp;mut fmt::Formatter) -&gt; fmt::Result {
        match *self {
            Project::Apollo =&gt; write!(f, "Apollo"),
            Project::Mercury =&gt; write!(f, "Mercury"),
            Project::Gemini =&gt; write!(f, "Gemini"),
        }
    }
}

struct Mission {
    project: Project,
    number: u8,
    duration_days: u8,
}

fn main() {
    let gemini_2 = Mission {
        project: Project::Gemini,
        number: 2,
        duration_days: 0,
    };

    let mut missions: [&amp;Mission; 2] = [&amp;gemini_2, &amp;gemini_2];

    let m0 = &amp;mut missions[0];
    let _m1 = &amp;mut missions[1];

    println!(
        "{} {} flew for {} days",
        m0.project, m0.number, m0.duration_days
    );
}</pre>
<p>By definition, <kbd>missions[0]</kbd> and <kbd>missions[1]</kbd> overlap in memory. We, the programmers, know we're breaking the aliasing rules and the compiler, being conservative, assumes that the rules are being broken.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Allocating and deallocating memory</h1>
                
            
            
                
<p>Deallocation happens in one of two ways, depending on whether the type is allocated on the stack or the heap. If it's on the stack, the type is deallocated when the stack frame itself ceases to exist. Each Rust stack frame comes into the world fully allocated but uninitialized and exits the world when its associated function exits. Heap allocated types are deallocated when the last valid binding moves out of scope, either through the natural flow of the program or by an explicit <kbd>std::mem::drop</kbd> being called by the programmer. The implementation of <kbd>drop</kbd> is as follows:</p>
<pre style="padding-left: 30px">fn drop&lt;T&gt;(_x: T) { }</pre>
<p>The value <kbd>_x</kbd> is moved into <kbd>drop</kbd> —meaning there are no other borrows of <kbd>_x</kbd>—and then immediately falls out of scope when <kbd>drop</kbd> exits. An explicit <kbd>drop</kbd> is not able to remove items from scope, however, so subtle interactions with structures where the Rust compiler is not able to prove non-overlapping aliases and the like will happen. The <kbd>drop</kbd> documentation discusses several cases and it is worth reviewing that material.</p>
<p>Any Rust type that can be deallocated—meaning it is not <kbd>Copy</kbd>—will implement the <kbd>Drop</kbd> trait, a trait whose sole function is <kbd>drop(&amp;mut self)</kbd>. <kbd>Drop::drop</kbd> cannot be called explicitly and is called when the type goes out of scope or is invocable by <kbd>std::mem::drop</kbd>, as discussed  previously.</p>
<p>So far in this chapter, we've discussed the layout of types in memory and allocation on the heap but without fully discussing how allocation itself works in the Rust memory model. The simplest way of forcing a heap allocation is with <kbd>std::boxed::Box</kbd>. In fact, the Rust documentation for <kbd>Box</kbd>—which is also just called box—describes it as the simplest form of heap allocation in Rust. That is, a <kbd>Box&lt;T&gt;</kbd> allocates enough space on the heap for a type <kbd>T</kbd> and acts as the owner of that allocation. When the box is dropped, the drop of <kbd>T</kbd> occurs. Here's the definition of <kbd>Box&lt;T&gt;</kbd> straight from the standard library, in the file <kbd>src/liballoc/boxed.rs</kbd>:</p>
<pre style="padding-left: 30px">pub struct Box&lt;T: ?Sized&gt;(Unique&lt;T&gt;);</pre>


            

            
        
    </div>



  
<div><h1 class="header-title">The size of a type</h1>
                
            
            
                
<p>There's two important things here we have not come across yet in this book—<kbd>Sized</kbd> and <kbd>Unique</kbd>. First, <kbd>Sized</kbd>, or more properly, <kbd>std::marker::Sized</kbd>. <kbd>Sized</kbd>, is a Rust <kbd>trait</kbd> that bounds a type to have a known size at compile time. Almost everything in Rust has an implicit <kbd>Sized</kbd> bound, which we can inspect. For instance:</p>
<pre style="padding-left: 30px">use std::mem;

#[allow(dead_code)]
enum Project {
    Mercury { mission: u8 },
    Gemini { mission: u8 },
    Apollo { mission: u8 },
    Shuttle { mission: u8 },
}

fn main() {
    assert_eq!(1, mem::size_of::&lt;u8&gt;());
    assert_eq!(2, mem::size_of::&lt;Project&gt;());

    let ptr_sz = mem::size_of::&lt;usize&gt;();
    assert_eq!(ptr_sz, mem::size_of::&lt;&amp;Project&gt;());

    let vec_sz = mem::size_of::&lt;usize&gt;() * 2 + ptr_sz;
    assert_eq!(vec_sz, mem::size_of::&lt;Vec&lt;Project&gt;&gt;());
}</pre>
<p><kbd>u8</kbd> is a single byte, Project is the byte to distinguish the enum variants plus the inner mission byte, pointers are the size of a machine word–a <kbd>usize-</kbd> and a <kbd>Vec&lt;T&gt;</kbd> is guaranteed to be a pointer and two <kbd>usize</kbd> fields no matter the size of <kbd>T</kbd>. There's something interesting going on with <kbd>Vec&lt;T&gt;</kbd> and we'll get into it in depth later in this chapter. Note that we said almost everything in Rust has an implicit <kbd>Sized</kbd> bound. Rust supports <em>dynamically sized types</em>, these being types that have no known size or alignment. Rust requires known size and alignment and so all DSTs must exist behind a reference or pointer. A slice—a view into contiguous memory—is one such type. In the following program, the compiler will not be able to determine the size of the slice of values:</p>
<pre style="padding-left: 30px">use std::time::{SystemTime, UNIX_EPOCH};

fn main() {
    let values = vec![0, 1, 2, 3, 4, 5, 7, 8, 9, 10];
    let cur: usize = SystemTime::now()
        .duration_since(UNIX_EPOCH)
        .unwrap()
        .as_secs() as usize;
    let cap: usize = cur % values.len();

    let slc: &amp;[u8] = &amp;values[0..cap];

    println!("{:?}", slc);
}</pre>
<p><em>Slices are a view into a block of memory represented as a pointer and a length</em>, as the documentation for the primitive type slice puts it. The trick is that the length is determined at runtime. The following program will compile:</p>
<pre style="padding-left: 30px">fn main() {
    let values = vec![0, 1, 2, 3, 4, 5, 7, 8, 9, 10];
    let slc: &amp;[u8] = &amp;values[0..10_000];

    println!("{:?}", slc);
}</pre>
<p>However, the previous code will panic at runtime:</p>
<pre><strong>&gt; ./past_the_end thread <br/>'main' panicked at 'index 10000 out of range for slice of length 10', libcore/slice/mod.rs:785:5 note: Run with `RUST_BACKTRACE=1` for a backtrace.</strong></pre>
<p>Rust allows programmers to include DSTs as the last field of a <kbd>struct</kbd>, like so:</p>
<pre style="padding-left: 30px">struct ImportantThing {
  tag: u8,
  data: [u8],
}</pre>
<p>However, this causes the struct itself to become a DST.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Static and dynamic dispatch</h1>
                
            
            
                
<p>Trait objects likewise have no statically known size in Rust. Trait objects are the mechanism by which Rust performs dynamic dispatch. Preferentially, Rust is a static dispatch language as there are increased opportunities for inlining and optimization—the compiler simply knows more. Consider the following code:</p>
<pre style="padding-left: 30px">use std::ops::Add;

fn sd_add&lt;T: Add&lt;Output=T&gt;&gt;(x: T, y: T) -&gt; T {
    x + y
}

fn main() {
    assert_eq!(48, sd_add(16 as u8, 32 as u8));
    assert_eq!(48, sd_add(16 as u64, 32 as u64));
}</pre>
<p>Here, we define a function, <kbd>sd_add&lt;T: Add&lt;Output=T&gt;&gt;(x: T, y: T) -&gt; T</kbd>. Rust, like C++, will perform monomorphization at compile time, emitting two <kbd>sd_add</kbd> functions, one for <kbd>u8</kbd> and the other for <kbd>u64</kbd>. Like C++, this potentially increases the code size of a Rust program and slows compilation but at the benefit of allowing inlining at the caller site, potentially more efficient implementations owing to type specialization, and fewer branches.</p>
<p>When static dispatch is not desirable, the programmer can construct trait objects to perform dynamic dispatch. Trait objects do not have a known size—indeed, they can be any <kbd>T</kbd> that implements the trait—and so, like slices, must exist behind a kind of pointer. Dynamic dispatch will not see much use in this book. The reader is warmly encouraged to consult the documentation for <kbd>std::raw::TraitObject</kbd> for full details on Rust's trait object notion.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Zero sized types</h1>
                
            
            
                
<p>Rust also supports <em>zero sized types</em> or ZSTs; structs with no fields, the unit type <kbd>()</kbd>, or arrays with no size are all zero sized. The fact that the type has no size is a boon to optimization and dead-tree removal. Rust APIs often include return types like so: <kbd>Result&lt;(), a_mod::ErrorKind&gt;</kbd>. This type signals that while the function may error, its return value in the happy path is the unit type. These types are somewhat rare in practice but unsafe, and Rust must be aware of them. Many allocators return null when asked to allocate zero bytes—making the allocation of a ZST indistinguishable from the allocator being unable to find free memory—and pointer offsets from a ZST are of zero offset. Both of these considerations will be important in this chapter.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Boxed types</h1>
                
            
            
                
<p>That's the trait <kbd>Sized</kbd>, but what does <kbd>?Sized</kbd> mean? The <kbd>?</kbd> flags the relevant trait as optional. So, a box is a type in Rust parameterized over some other type <kbd>T</kbd> which may or may not have a size. A box is a kind of a pointer to heap allocated storage. Let's look into its implementation further. What of <kbd>Unique&lt;T&gt;</kbd>? This type is a signal to the Rust compiler that some <kbd>*mut T</kbd> is non-null and that the unique is the sole owner of <kbd>T</kbd>, even though <kbd>T</kbd> was allocated outside the <kbd>Unique</kbd>. <kbd>Unique</kbd> is defined like so:</p>
<pre style="padding-left: 30px">pub struct Unique&lt;T: ?Sized&gt; {
    pointer: NonZero&lt;*const T&gt;,
    // NOTE: this marker has no consequences for variance, but is<br/>    // necessary for dropck to understand that we logically <br/>    // own a `T`.
    _marker: PhantomData&lt;T&gt;,
}</pre>
<p><kbd>NonZero&lt;T&gt;</kbd> is a struct that the <kbd>rustc</kbd> source describes as a wrapper type for raw pointers and integers that will never be <kbd>NULL</kbd> or <kbd>0</kbd> that might allow certain optimizations. It's annotated in a special way to admit those null pointer optimizations discussed elsewhere in this chapter. Unique is also of interest for its use of <kbd>PhantomData&lt;T&gt;</kbd>. <kbd>PhantomData</kbd> is, in fact, a zero sized type, defined as <kbd>pub struct PhantomData&lt;T:?Sized&gt;;</kbd>. This type instructs the Rust compiler to consider <kbd>PhantomData&lt;T&gt;</kbd> as owning <kbd>T</kbd> even though, ultimately, there's nowhere for <kbd>PhantomData</kbd> to store its newfound <kbd>T</kbd>. This works well for <kbd>Unique&lt;T&gt;</kbd>, which must take ownership of <kbd>&lt;T&gt;</kbd> by maintaining a non-zero constant pointer to <kbd>T</kbd> but does not, itself, have <kbd>T</kbd> stored anywhere other than in the heap. A box is then, a unique, non-null pointer to a thing allocated somewhere in memory but not inside the storage space of the box.</p>
<p>The internals of box are compiler intrinsics: they sit at the interplay of the allocator and are a special consideration in Rust's borrow checker. With that in mind, we will avoid chasing down the internal details of <kbd>Box</kbd> as they will change from compiler version to compiler version and this book is explicitly not a <kbd>rustc</kbd> internals book. For our purposes, however, it is worth considering the API exposed by box. The key functions are:</p>
<ul>
<li><kbd>fn from_raw(raw: *mut T) -&gt; Box&lt;T&gt;</kbd></li>
<li><kbd>fn from_unique(u: Unique&lt;T&gt;) -&gt; Box&lt;T&gt;</kbd></li>
<li><kbd>fn into_raw(b: Box&lt;T&gt;) -&gt; *mut T</kbd></li>
<li><kbd>fn into_unique(b: Box&lt;T&gt;) -&gt; Unique&lt;T&gt;</kbd></li>
<li><kbd>fn leak&lt;'a&gt;(b: Box&lt;T&gt;) -&gt; &amp;'a mut T</kbd></li>
</ul>
<p>Both <kbd>from_raw</kbd> and <kbd>from_unique</kbd> are unsafe. Conversion from a raw pointer is unsafe if a raw pointer is <em>boxed</em> more than once or if a box is made from a pointer that overlaps with another, as examples. There are other possibilities. Conversion from a <kbd>Unique&lt;T&gt;</kbd> is unsafe as the <kbd>T</kbd> may or may not be owned by  <kbd>Unique</kbd>, resulting in a possibility of the box not being the sole owner of its memory. The <kbd>into_*</kbd> functions, however, are safe in the sense that the resulting pointers will be valid but the caller will not have full responsibility for managing the lifetime of the memory. The <kbd>Box</kbd> documentation notes that the caller can release the memory themselves or convert the pointer back into the type they came from and allow Rust to do it for them. The latter is the approach this book will take. Finally, there's <kbd>leak</kbd>. Leak is a fun one and is not available on stable channel but is worth discussing for applications that will ship to embedded targets. A common memory management strategy for embedded systems is to pre-allocate all necessary memory and only operate on that memory for the lifetime of the program. In Rust, this is trivially accomplished if you desire uninitialized memory of a constant size: arrays and other primitive types. In the event you desire heap allocations at the start of your program, the situation is more complicated. That's where leak comes in: it causes memory to leak from a box—a heap allocation—to wherever you please. When the leaked memory is intended to live for the lifetime of the program—into the <kbd>static</kbd> lifetime—there's no issue. An example  is as follows, straight from the docs for <kbd>leak:</kbd></p>
<pre style="padding-left: 30px">#![feature(box_leak)]

fn main() {
    let x = Box::new(41);
    let static_ref: &amp;'static mut usize = Box::leak(x);
    *static_ref += 1;
    assert_eq!(*static_ref, 42);
}</pre>
<p>Here, we see a new <kbd>usize</kbd> allocated on the heap, leaked into <kbd>static_ref</kbd>—a mutable reference of static lifetime—and then fiddled with through the remaining lifetime of the program.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Custom allocators</h1>
                
            
            
                
<p>It is possible to plug in one's own allocator to Rust, as can be done in C++ or similar system-level programming languages. By default, on most targets, Rust uses jemalloc with a backup alternative to the system-provided allocator. In embedded applications, there may not <em>be</em> a system, let alone an allocator, and the interested reader is recommended to peruse RFC 1183 (<a href="https://github.com/rust-lang/rfcs/blob/master/text/1183-swap-out-jemalloc.md">https://github.com/rust-lang/rfcs/blob/master/text/1183-swap-out-jemalloc.md</a>), RFC 1398 (<a href="https://github.com/rust-lang/rfcs/pull/1398">https://github.com/rust-lang/rfcs/pull/1398</a>), and related RFCs. As of writing this, an interface for plugging in custom allocators to stable Rust is under active discussion and any such capability is only available in nightly Rust. We will not make use of custom allocators in this book.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Implementations</h1>
                
            
            
                
<p>In <a href="8c61da2f-08c8-40be-89d4-d8afa8510850.xhtml" target="_blank">Chapter 2</a>, <em>Sequential Rust Performance and Testing,</em> we very briefly dipped into the implementation of <kbd>std::collections::HashMap</kbd>. Let's continue with that approach of dissecting the standard library, paying special attention to the concerns of memory that pop up.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Option</h1>
                
            
            
                
<p>Let's examine <kbd>Option&lt;T&gt;</kbd>. We've already discussed <kbd>Option&lt;T&gt;</kbd> in this chapter; that it's subject to <em>null pointer optimization</em> on account of its empty <kbd>None</kbd> variant in particular. <kbd>Option</kbd> is as simple as you might imagine, being defined in <kbd>src/libcore/option.rs</kbd>:</p>
<pre style="padding-left: 30px">#[derive(Clone, Copy, PartialEq, PartialOrd, Eq, Ord, Debug, Hash)]
#[stable(feature = "rust1", since = "1.0.0")]
pub enum Option&lt;T&gt; {
    /// No value
    #[stable(feature = "rust1", since = "1.0.0")]
    None,
    /// Some value `T`
    #[stable(feature = "rust1", since = "1.0.0")]
    Some(#[stable(feature = "rust1", since = "1.0.0")] T),
}</pre>
<p>As is often the case with Rust internals, there are a great deal of flags around to control when and where new features land in which channel and how documentation is generated. A slightly tidier expression of <kbd>Option&lt;T&gt;</kbd> is:</p>
<pre style="padding-left: 30px">#[derive(Clone, Copy, PartialEq, PartialOrd, Eq, Ord, Debug, Hash)]
pub enum Option&lt;T&gt; {
    None,
    Some(T),
}</pre>
<p>This is refreshingly simple, much like how you may have implemented an option type yourself up on first thinking of it. <kbd>Option</kbd> is the owner of its inner <kbd>T</kbd> and is able to pass out references to that inner data per the usual restrictions. As an example:</p>
<pre>    pub fn as_mut(&amp;mut self) -&gt; Option&lt;&amp;mut T&gt; {
        match *self {
            Some(ref mut x) =&gt; Some(x),
            None =&gt; None,
        }
    }</pre>
<p>Rust exposes a special trait type inside each <kbd>trait: Self</kbd>. It desugars simply to the referent trait type, in this case, <kbd>Option&lt;T&gt;</kbd>. The <kbd>&amp;mut self</kbd> is shorthand for <kbd>self: &amp;mut Self</kbd>, as is <kbd>&amp;self</kbd> for <kbd>self: &amp;Self</kbd> . <kbd>as_mut</kbd>  is then allocating a new option whose inner type is a mutable reference to the original inner type. Now, consider the humble <kbd>map</kbd>:</p>
<pre>    pub fn map&lt;U, F: FnOnce(T) -&gt; U&gt;(self, f: F) -&gt; Option&lt;U&gt; {
        match self {
            Some(x) =&gt; Some(f(x)),
            None =&gt; None,
        }
    }</pre>
<p>Rust allows closures as arguments to functions. In this way, Rust is similar to higher-level and, especially, functional programming languages. Unlike these higher-level programming languages, Rust has restrictions on closures in terms of the way <em>variable capture</em> occurs and with regard to call totals and mutability. Here, we see the <kbd>FnOnce</kbd> trait being used, restricting the closure being passed in as <kbd>f</kbd> to the map function as being single-use. The function traits, all defined in <kbd>std::ops</kbd>, are:</p>
<ul>
<li><kbd>Fn</kbd></li>
<li><kbd>FnMut</kbd></li>
<li><kbd>FnOnce</kbd></li>
</ul>
<p>The first trait, <kbd>Fn</kbd>, is described by the Rust documentation as being a <em>call operator that takes an immutable receiver</em>. This is maybe a little obscure until we look at the definition of <kbd>Fn</kbd> in <kbd>src/libcore/ops/function.rs</kbd>:</p>
<pre style="padding-left: 30px">pub trait Fn&lt;Args&gt;: FnMut&lt;Args&gt; {
    /// Performs the call operation.
    #[unstable(feature = "fn_traits", issue = "29625")]
    extern "rust-call" fn call(&amp;self, args: Args) -&gt; Self::Output;
}</pre>
<p>Now it's more obscure! But, we can work that back. <kbd>Args</kbd> is distinct from <kbd>std::env::Args</kbd> but plays a similar role of being a placeholder for function arguments, save at a type-level. <kbd>: FnMut&lt;Args&gt;</kbd> means that the <kbd>FnMut&lt;Args&gt;</kbd> is a <em>supertrait</em> of <kbd>Fn&lt;Args&gt;:</kbd> all of the methods available to <kbd>FnMut</kbd> are available to <kbd>Fn</kbd> when used as a trait object. Recall that trait objects find use in dynamic dispatch, discussed previously. This also means that any instance of <kbd>Fn</kbd> can be used where an <kbd>FnMut</kbd> is expected, in cases of static dispatch. Of particular interest to understanding <kbd>Fn</kbd> is:</p>
<pre style="padding-left: 30px">extern "rust-call" fn call(&amp;self, args: Args) -&gt; Self::Output;</pre>
<p>We'll approach this in parts. Firstly, <kbd>extern "rust-call"</kbd>. Here, we are defining an inline extern block that uses the <kbd>"rust-call"</kbd> ABI. Rust supports many ABIs, three of which are cross-platform and guaranteed to be supported no matter the platform:</p>
<ul>
<li><kbd>extern "Rust" fn</kbd>, implicit for all Rust functions unless otherwise specified</li>
<li><kbd>extern "C" fn</kbd>, often used in FFI and shorthanded to <kbd>extern fn</kbd> </li>
<li><kbd>extern "system" fn</kbd>, equivalent to <kbd>extern "C" fn</kbd> save for some special platforms</li>
</ul>
<p><kbd>"rust-call"</kbd> does not appear in that list because it is a rust-specific ABI, which also includes:</p>
<ul>
<li><kbd>extern "rust-intrinsic" fn</kbd>, specific to <kbd>rustc</kbd> intrinsics</li>
<li><kbd>extern "rust-call" fn</kbd>, the ABI for all <kbd>Fn::call</kbd> functions</li>
<li><kbd>extern "platform-intrinsic" fn</kbd>, which the documentation notes as being something the programmer should never have to deal with</li>
</ul>
<p>Here, we're signalling to the Rust compiler that the function is to be treated with a special call ABI. This particular <kbd>extern</kbd> is important when writing traits that implement the <kbd>Fn</kbd> trait, as box will when the unstable <kbd>fnbox</kbd> feature flag is enabled:</p>
<pre style="padding-left: 30px">impl&lt;'a, A, R&gt; FnOnce&lt;A&gt; for Box&lt;FnBox&lt;A, Output = R&gt; + 'a&gt; {
    type Output = R;

    extern "rust-call" fn call_once(self, args: A) -&gt; R {
        self.call_box(args)
    }
}</pre>
<p>Secondly, <kbd>fn call(&amp;self, args: Args)</kbd>. The implementing type is taken in as an immutable reference, in addition to the passed args; this is the immutable receiver mentioned in the documentation. The final piece here is <kbd>-&gt; Self::Output</kbd>, the returned type after the call operator is used. This associated type defaults to <kbd>Self</kbd> but can be set by the implementer.</p>
<p><kbd>FnMut</kbd> is similar to <kbd>Fn</kbd> save that it takes <kbd>&amp;mut self</kbd> rather than <kbd>&amp;self</kbd>, and <kbd>FnOnce</kbd> is its supertrait:</p>
<pre style="padding-left: 30px">pub trait FnMut&lt;Args&gt;: FnOnce&lt;Args&gt; {
    /// Performs the call operation.
    #[unstable(feature = "fn_traits", issue = "29625")]
    extern "rust-call" fn call_mut(&amp;mut self, args: Args) <br/>        -&gt; Self::Output;
}</pre>
<p>Only <kbd>FnOnce</kbd> deviates in its definition:</p>
<pre>pub trait FnOnce&lt;Args&gt; {
    /// The returned type after the call operator is used.
    #[stable(feature = "fn_once_output", since = "1.12.0")]
    type Output;

    /// Performs the call operation.
    #[unstable(feature = "fn_traits", issue = "29625")]
    extern "rust-call" fn call_once(self, args: Args) -&gt; Self::Output;
}</pre>
<p>Here, we see where <kbd>Self::Output</kbd> makes its appearance as an associated type and note that the implementations of <kbd>FnOnce</kbd> are in terms of <kbd>call_once</kbd> rather than <kbd>call.</kbd> Also, we now know that <kbd>FnOnce</kbd> is a supertrait of <kbd>FnMut</kbd>, which is a supertrait of <kbd>Fn</kbd> and it just so happens that this property is transitive: if an <kbd>FnOnce</kbd> is called for an <kbd>Fn</kbd>, it can be used. Much of the exact implementation of the function traits are kept internal to the compiler, the details of which kind of jump around some as internals change. In fact, the <kbd>"rust-call"</kbd>, <kbd>extern</kbd> means that <kbd>Fn traits</kbd> cannot be implemented outside of special, compiler-specific contexts; the exact feature flags that need to be enabled in a nightly build, their use, and upcoming changes are not documented. Happily, closures and function pointers implement function traits implicitly. For example:</p>
<pre style="padding-left: 30px">fn mlen(input: &amp;str) -&gt; usize {
    input.len()
}

fn main() {
    let v: Option&lt;&amp;str&gt; = Some("hope");

    assert_eq!(v.map(|s| s.len()), v.map(mlen));
}</pre>
<p>The compiler is good enough to figure out the details for us.</p>
<p>Conceptually, <kbd>Result&lt;T&gt;</kbd> is a type similar to <kbd>Option&lt;T&gt;</kbd>, save that it is able to communicate an extra piece of information in its <kbd>Err</kbd> variant. In fact, the implementation in <kbd>src/libcore/result.rs</kbd> is awfully similar to the way we'd likely write this at first though, as with <kbd>Option</kbd>:</p>
<pre style="padding-left: 30px">pub enum Result&lt;T, E&gt; {
    /// Contains the success value
    #[stable(feature = "rust1", since = "1.0.0")]
    Ok(#[stable(feature = "rust1", since = "1.0.0")] T),

    /// Contains the error value
    #[stable(feature = "rust1", since = "1.0.0")]
    Err(#[stable(feature = "rust1", since = "1.0.0")] E),
}</pre>


            

            
        
    </div>



  
<div><h1 class="header-title">Cell and RefCell</h1>
                
            
            
                
<p>So far in this chapter, the mutable references we've been discussing have a property called, by Rust, inherited mutability. That is, values are made mutable when we inherit their ownership or the exclusive right—via a <kbd>&amp;mut</kbd>—to mutate the value. Inherited mutability is preferred in Rust as it is statically enforcable—any defects in our program with regards to memory mutation will be caught at compilation time. Rust does provide facilities for interior mutability,  that being mutability that is available for pieces of an immutable type. The documentation calls interior mutability something of a last resort but, while not common, it is not exactly rare in practice, either. The two options for interior mutability in Rust are <kbd>Cell&lt;T&gt;</kbd> and <kbd>RefCell&lt;T&gt;</kbd>.</p>
<p>Let's consider <kbd>Cell&lt;T&gt;</kbd>. How is it used? As suggested, <kbd>Cell&lt;T&gt;</kbd> is useful when some field or fields of an otherwise immutable structure need to be mutable and the <kbd>T</kbd> you're concerned with is <kbd>T: Copy</kbd>. Consider a graph structure where a search operation is performed. This is logically immutable—the graph structure does not need to be modified during search. But, also consider the case where we would like to record the total number of traversals along the graph's edges. Our options are to violate the logical immutability of the graph search, require storage outside of the graph, or insert an interior, mutable counter into the graph. Which choice is best will depend on the specific situation. Here is a significantly less complicated example of <kbd>Cell&lt;T&gt;</kbd>, compared to a graph search:</p>
<pre style="padding-left: 30px">use std::cell::Cell;

enum Project {
    Apollo,
    Gemini,
    Mercury,
}

struct Mission {
    project: Project,
    number: u8,
    duration_days: Cell&lt;u8&gt;,
}

fn main() {
    let mission = Mission {
        project: Project::Mercury,
        number: 7,
        duration_days: Cell::new(255),
    };

    mission.duration_days.set(0);
    assert_eq!(0, mission.duration_days.get());
}</pre>
<p>Of course, that's a bit contrived. Interior mutability shows up when the situation is non-trivial, generally speaking. Note that <kbd>Cell&lt;u8&gt;</kbd> had to be manipulated with <kbd>get</kbd> and <kbd>set</kbd> methods, contrary to the normal process of setting and reading directly or through a pointer. Let's dig into the implementation of <kbd>Cell&lt;T&gt;</kbd>, defined in <kbd>src/libcore/cell.rs</kbd>:</p>
<pre style="padding-left: 30px">pub struct Cell&lt;T&gt; {
    value: UnsafeCell&lt;T&gt;,
}</pre>
<p>As is common in Rust internals, a safe interface hides an unsafe inner core, as we saw in <a href="8c61da2f-08c8-40be-89d4-d8afa8510850.xhtml" target="_blank">Chapter 2</a>, <em>Sequential Rust Performance and Testing</em>, with <kbd>HashMap</kbd>. What is the definition of <kbd>UnsafeCell</kbd>?</p>
<pre style="padding-left: 30px">pub struct UnsafeCell&lt;T: ?Sized&gt; {
    value: T,
}</pre>
<p>Of particular note is an implementation that follows shortly afterward:</p>
<pre style="padding-left: 30px">impl&lt;T: ?Sized&gt; !Sync for UnsafeCell&lt;T&gt; {}</pre>
<p>We will discuss <kbd>Sync</kbd> in the following chapter in greater detail. Suffice it to say, for now, any type that is threadsafe must implement <kbd>Sync</kbd>—and many do automatically—and by disabling the <kbd>Sync</kbd> trait for <kbd>UnsafeCell&lt;T&gt;</kbd>—which is what <kbd>!Sync</kbd> means—the type is specifically being marked as not thread-safe. That is, any thread may be manipulating the data owned by <kbd>UnsafeCell</kbd> at any time. As we've previously discussed, Rust is able to make a good deal of optimizations off the back of the knowledge that <kbd>&amp;T</kbd> is guaranteed to also not be mutable somewhere and that <kbd>&amp;mut T</kbd> is unique. <kbd>UnsafeCell&lt;T&gt;</kbd> is the <em>only</em> method Rust provides to turn these compiler optimizations off; it is possible to dip into an unsafe block and transmute <kbd>&amp;T</kbd> to <kbd>&amp;mut T</kbd>, but this is specifically called out as undefined behavior. They key to <kbd>UnsafeCell&lt;T&gt;</kbd> is that it is possible for a client to retrieve multiple mutable references to the interior data, even if the <kbd>UnsafeCell&lt;T&gt;</kbd> is itself mutable. It is up to the caller to ensure that there is <em>only</em> one mutable reference at any time. The implementation of <kbd>UnsafeCell</kbd> —stripped of its comments for clarity's sake—is brief:</p>
<pre style="padding-left: 30px">impl&lt;T&gt; UnsafeCell&lt;T&gt; {
    pub const fn new(value: T) -&gt; UnsafeCell&lt;T&gt; {
        UnsafeCell { value: value }
    }

    pub unsafe fn into_inner(self) -&gt; T {
        self.value
    }
}

impl&lt;T: ?Sized&gt; UnsafeCell&lt;T&gt; {
    pub fn get(&amp;self) -&gt; *mut T {
        &amp;self.value as *const T as *mut T
    }
}</pre>
<p>This brings us back to <kbd>Cell&lt;T&gt;</kbd>. We know that <kbd>Cell&lt;T&gt;</kbd> is built on top of an unsafe abstraction and we will have to take care not to violate the <kbd>&amp;mut T</kbd> uniqueness constraint. How is this done? First, construction of <kbd>Cell&lt;T&gt;</kbd> is straightforward, as you may expect:</p>
<pre style="padding-left: 30px">impl&lt;T&gt; Cell&lt;T&gt; {
    pub const fn new(value: T) -&gt; Cell&lt;T&gt; {
        Cell {
            value: UnsafeCell::new(value),
        }
    }</pre>
<p>The <kbd>const fn</kbd> is likely a surprise, on account of it being a nightly-only feature as of writing this book. In Rust, a constant function is evaluated at compile time. The benefit to the programmer of this particular definition is that the result of <kbd>Cell::new</kbd> can be assigned to a constant variable, one which will exist for the lifetime of the program. Both <kbd>as_ptr</kbd> and <kbd>get_mut</kbd> are different views of the underlying <kbd>T</kbd>, one a raw mutable pointer and the other a mutable reference:</p>
<pre>    pub fn as_ptr(&amp;self) -&gt; *mut T {
        self.value.get()
    }

    pub fn get_mut(&amp;mut self) -&gt; &amp;mut T {
        unsafe {
            &amp;mut *self.value.get()
        }
    }

    pub fn into_inner(self) -&gt; T {
        unsafe { self.value.into_inner() }
    }</pre>
<p>Note that while the internals of <kbd>get_mut</kbd> are unsafe, the borrow checker is brought to bear on the problem of keeping <kbd>&amp;mut T</kbd> unique and so <kbd>Cell::get_mut</kbd> can itself be safe. <kbd>Cell::as_ptr</kbd> is not marked as unsafe—it's safe to receive a raw pointer in Rust—but any caller will have to do deferencing of that raw pointer in an unsafe block: it's possible that there will be more than one raw, mutable pointer floating around. Setting a new value into the cell is done in terms of replacement, discussed ahead, but with careful attention made towards forcefully dropping the <kbd>T</kbd> pulled from the cell:</p>
<pre>    pub fn set(&amp;self, val: T) {
        let old = self.replace(val);
        drop(old);
    }</pre>
<p><kbd>Cell::swap</kbd> and <kbd>Cell::replace</kbd> are done in terms of the lower-level memory manipulation tools from <kbd>std::ptr</kbd> and <kbd>std::mem</kbd>. <kbd>swap</kbd> is intended to replace the interior of one cell with another. Its definition is as follows:</p>
<pre>    pub fn swap(&amp;self, other: &amp;Self) {
        if ptr::eq(self, other) {
            return;
        }
        unsafe {
            ptr::swap(self.value.get(), other.value.get());
        }
    }</pre>
<p><kbd>swap</kbd> is done in terms of <kbd>std::ptr::swap</kbd>, a function documented as copying the memory through the raw pointers passed to it as arguments<em>.</em> You'll note that <kbd>Cell::swap</kbd> is careful to avoid the <kbd>swap</kbd> if the passed <kbd>other</kbd> is equivalent to <kbd>self</kbd>. The reason for this becomes clear when we take a peek at the definition of <kbd>std::ptr::swap</kbd>, defined in <kbd>src/libcore/ptr.rs</kbd>:</p>
<pre style="padding-left: 30px">pub unsafe fn swap&lt;T&gt;(x: *mut T, y: *mut T) {
    // Give ourselves some scratch space to work with
    let mut tmp: T = mem::uninitialized();

    // Perform the swap
    copy_nonoverlapping(x, &amp;mut tmp, 1);
    copy(y, x, 1); // `x` and `y` may overlap
    copy_nonoverlapping(&amp;tmp, y, 1);

    // y and t now point to the same thing, but we need to completely <br/>    forget `tmp`
    // because it's no longer relevant.
    mem::forget(tmp);
}</pre>
<p>The exact details of <kbd>copy_nonoverlapping</kbd> and copy are unimportant here, except in noting that swapping does require allocation of uninitialized space and copying back and forth from that space. It's wise to avoid the work if you don't have to do it. <kbd>Cell::replace</kbd> works along similar lines:</p>
<pre>    pub fn replace(&amp;self, val: T) -&gt; T {
        mem::replace(unsafe { &amp;mut *self.value.get() }, val)
    }
}</pre>
<p><kbd>std::mem::replace</kbd> takes a <kbd>&amp;mut T</kbd> and a <kbd>T</kbd> and then replaces the value at <kbd>&amp;mut T</kbd> with the passed in <kbd>val</kbd>, returning the old value and dropping neither. The definition of <kbd>std::mem::replace</kbd> is in <kbd>src/libcore/mem.rs</kbd> and is as follows:</p>
<pre style="padding-left: 30px">pub fn replace&lt;T&gt;(dest: &amp;mut T, mut src: T) -&gt; T {
    swap(dest, &amp;mut src);
    src
}</pre>
<p>Chasing the definition of <kbd>swap</kbd> in the same module, we find it is as follows:</p>
<pre style="padding-left: 30px">pub fn swap&lt;T&gt;(x: &amp;mut T, y: &amp;mut T) {
    unsafe {
        ptr::swap_nonoverlapping(x, y, 1);
    }
}</pre>
<p><kbd>std::ptr::swap_nonoverlapping</kbd> is as follows:</p>
<pre style="padding-left: 30px">pub unsafe fn swap_nonoverlapping&lt;T&gt;(x: *mut T, y: *mut T, count: usize) {
    let x = x as *mut u8;
    let y = y as *mut u8;
    let len = mem::size_of::&lt;T&gt;() * count;
    swap_nonoverlapping_bytes(x, y, len)
}</pre>
<p>Finally, the private <kbd>std::ptr::swap_nonoverlapping_bytes</kbd> is as follows:</p>
<pre style="padding-left: 30px">unsafe fn swap_nonoverlapping_bytes(x: *mut u8, y: *mut u8, len: usize) {
    // The approach here is to utilize simd to swap x &amp; y efficiently. <br/>    // Testing reveals that swapping either 32 bytes or 64 bytes at<br/>    // a time is most efficient for intel Haswell E processors. <br/>    // LLVM is more able to optimize if we give a struct a <br/>    // #[repr(simd)], even if we don't actually use this struct<br/>    // directly.
    //
    // FIXME repr(simd) broken on emscripten and redox
    // It's also broken on big-endian powerpc64 and s390x.  #42778
    #[cfg_attr(not(any(target_os = "emscripten", target_os = "redox",
                       target_endian = "big")),
               repr(simd))]
    struct Block(u64, u64, u64, u64);
    struct UnalignedBlock(u64, u64, u64, u64);

    let block_size = mem::size_of::&lt;Block&gt;();

    // Loop through x &amp; y, copying them `Block` at a time
    // The optimizer should unroll the loop fully for most types
    // N.B. We can't use a for loop as the `range` impl calls <br/>    // `mem::swap` recursively
    let mut i = 0;
    while i + block_size &lt;= len {
        // Create some uninitialized memory as scratch space
<br/>        // Declaring `t` here avoids aligning the stack when this loop <br/>        // is unused
        let mut t: Block = mem::uninitialized();
        let t = &amp;mut t as *mut _ as *mut u8;
        let x = x.offset(i as isize);
        let y = y.offset(i as isize);

        // Swap a block of bytes of x &amp; y, using t as a temporary <br/>        // buffer. This should be optimized into efficient SIMD <br/>        // operations where available
        copy_nonoverlapping(x, t, block_size);
        copy_nonoverlapping(y, x, block_size);
        copy_nonoverlapping(t, y, block_size);
        i += block_size;
    }

    if i &lt; len {
        // Swap any remaining bytes
        let mut t: UnalignedBlock = mem::uninitialized();
        let rem = len - i;

        let t = &amp;mut t as *mut _ as *mut u8;
        let x = x.offset(i as isize);
        let y = y.offset(i as isize);

        copy_nonoverlapping(x, t, rem);
        copy_nonoverlapping(y, x, rem);
        copy_nonoverlapping(t, y, rem);
    }
}</pre>
<p>Whew! That's some rabbit hole. Ultimately, what we've discovered here is that <kbd>std::mem::replace</kbd> is defined in terms of block copies from one non-overlapping location in memory to another, a process which the Rust developers have tried to make as efficient as possible by exploiting LLVM's ability to optimize a bitwise operation on common processors in terms of SIMD instructions. Neat.</p>
<p>What of <kbd>RefCell&lt;T&gt;</kbd>? It too is a safe abstraction over <kbd>UnsafeCell&lt;T&gt;</kbd> except that the copy restriction of <kbd>Cell&lt;T&gt;</kbd> is lifted. This makes the implementation a touch more complicated, as we'll see:</p>
<pre style="padding-left: 30px">pub struct RefCell&lt;T: ?Sized&gt; {
    borrow: Cell&lt;BorrowFlag&gt;,
    value: UnsafeCell&lt;T&gt;,
}</pre>
<p>Like <kbd>Cell, RefCell</kbd> has an inner unsafe value, that much is the same. What's fun here is <kbd>borrow: Cell&lt;BorrowFlag&gt;</kbd>. <kbd>RefCell&lt;T&gt;</kbd> is a client of <kbd>Cell&lt;T&gt;</kbd>, which makes good sense considering that the immutable <kbd>RefCell</kbd> is going to need interior mutability to track the total number of borrows of its inner data. <kbd>BorrowFlag</kbd> is defined like so:</p>
<pre style="padding-left: 30px">// Values [1, MAX-1] represent the number of `Ref` active
// (will not outgrow its range since `usize` is the size <br/>// of the address space)
type BorrowFlag = usize;
const UNUSED: BorrowFlag = 0;
const WRITING: BorrowFlag = !0;</pre>
<p>The implementation of <kbd>RefCell&lt;T&gt;</kbd> is like to that of <kbd>Cell&lt;T&gt;</kbd>. <kbd>RefCell::replace</kbd> is also implemented in terms of <kbd>std::mem::replace</kbd>, <kbd>RefCell::swap</kbd> in terms of <kbd>std::mem::swap</kbd>. Where things get interesting are the functions new to <kbd>RefCell</kbd>,  which are those to do with borrowing. We'll look at <kbd>try_borrow</kbd> and <kbd>try_borrow_mut</kbd> first as they're used in the implementations of the other borrowing functions. <kbd>try_borrow</kbd> is defined like so:</p>
<pre>    pub fn try_borrow(&amp;self) -&gt; Result&lt;Ref&lt;T&gt;, BorrowError&gt; {
        match BorrowRef::new(&amp;self.borrow) {
            Some(b) =&gt; Ok(Ref {
                value: unsafe { &amp;*self.value.get() },
                borrow: b,
            }),
            None =&gt; Err(BorrowError { _private: () }),
        }
    }</pre>
<p>With <kbd>BorrowRef</kbd> being as follows:</p>
<pre>struct BorrowRef&lt;'b&gt; {
    borrow: &amp;'b Cell&lt;BorrowFlag&gt;,
}

impl&lt;'b&gt; BorrowRef&lt;'b&gt; {
    #[inline]
    fn new(borrow: &amp;'b Cell&lt;BorrowFlag&gt;) -&gt; Option&lt;BorrowRef&lt;'b&gt;&gt; {
        match borrow.get() {
            WRITING =&gt; None,
            b =&gt; {
                borrow.set(b + 1);
                Some(BorrowRef { borrow: borrow })
            },
        }
    }
}

impl&lt;'b&gt; Drop for BorrowRef&lt;'b&gt; {
    #[inline]
    fn drop(&amp;mut self) {
        let borrow = self.borrow.get();
        debug_assert!(borrow != WRITING &amp;&amp; borrow != UNUSED);
        self.borrow.set(borrow - 1);
    }
}</pre>
<p><kbd>BorrowRef</kbd> is a structure that holds a reference to the borrow field of <kbd>RefCell&lt;T&gt;</kbd>. Creating a new <kbd>BorrowRef</kbd> depends on the value of that borrow; if the value is <kbd>WRITING</kbd> then no <kbd>BorrowRef</kbd> is created—<kbd>None</kbd> gets returned—and otherwise the total number of borrows are incremented. This achieves the mutual exclusivity of writing needed while allowing for multiple readers—it's not possible for <kbd>try_borrow</kbd> to hand out a reference when a write reference is out for the same data. Now, let's consider <kbd>try_borrow_mut</kbd>:</p>
<pre>    pub fn try_borrow_mut(&amp;self) -&gt; Result&lt;RefMut&lt;T&gt;, BorrowMutError&gt; {
        match BorrowRefMut::new(&amp;self.borrow) {
            Some(b) =&gt; Ok(RefMut {
                value: unsafe { &amp;mut *self.value.get() },
                borrow: b,
            }),
            None =&gt; Err(BorrowMutError { _private: () }),
        }
    }</pre>
<p>Again, we find an implementation in terms of another type, <kbd>BorrowRefMut</kbd>:</p>
<pre style="padding-left: 30px">struct BorrowRefMut&lt;'b&gt; {
    borrow: &amp;'b Cell&lt;BorrowFlag&gt;,
}

impl&lt;'b&gt; Drop for BorrowRefMut&lt;'b&gt; {
    #[inline]
    fn drop(&amp;mut self) {
        let borrow = self.borrow.get();
        debug_assert!(borrow == WRITING);
        self.borrow.set(UNUSED);
    }
}

impl&lt;'b&gt; BorrowRefMut&lt;'b&gt; {
    #[inline]
    fn new(borrow: &amp;'b Cell&lt;BorrowFlag&gt;) -&gt; Option&lt;BorrowRefMut&lt;'b&gt;&gt; {
        match borrow.get() {
            UNUSED =&gt; {
                borrow.set(WRITING);
                Some(BorrowRefMut { borrow: borrow })
            },
            _ =&gt; None,
        }
    }
}</pre>
<p>The key, as with <kbd>BorrowRef</kbd>, is in <kbd>BorrowRefMut::new</kbd>. Here, we can see that if the inner borrow from <kbd>RefCell</kbd> is unused then the borrow is set to write, excluding any potential read references. Likewise, if there is a read reference in existence, the creation of a mutable reference will fail. And so, exclusive mutable references and multiple immutable references are held at runtime by abstracting over an unsafe structure that allows for the breaking of that guarantee.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Rc</h1>
                
            
            
                
<p>Now, let's consider one last single-item container before we get into a multi-item container. We'll look into <kbd>Rc&lt;T&gt;</kbd>, described by the Rust documentation as being a single-threaded reference-counting pointer. Reference counting pointers are distinct from the usual Rust references in that, while they are allocated on the heap as a <kbd>Box&lt;T&gt;</kbd>, cloning a reference counter pointer does not cause a new heap allocation, bitwise copy. Instead, a counter inside the <kbd>Rc&lt;T&gt;</kbd> is incremented, somewhat analogously as to the way <kbd>RefCell&lt;T&gt;</kbd> works. The drop of an <kbd>Rc&lt;T&gt;</kbd> reduces that internal counter and when the counter's value is equal to zero, the heap allocation is released. Let's take a peek inside <kbd>src/liballoc/rc.s</kbd>:</p>
<pre style="padding-left: 30px">pub struct Rc&lt;T: ?Sized&gt; {
    ptr: Shared&lt;RcBox&lt;T&gt;&gt;,
    phantom: PhantomData&lt;T&gt;,
}</pre>
<p>We've already encountered <kbd>PhantomData&lt;T&gt;</kbd> in this chapter, so we know that <kbd>Rc&lt;T&gt;</kbd> will not directly hold the allocation of <kbd>T</kbd>, but the compiler will behave as if it does. Also, we know that <kbd>T</kbd> may or may not be sized. The pieces we need to catch up on then are <kbd>RcBox&lt;T&gt;</kbd> and <kbd>Shared&lt;T&gt;.</kbd> Let's inspect <kbd>Shared&lt;T&gt;</kbd> first. Its full name is <kbd>std::ptr::Shared&lt;T&gt;</kbd> and it's the same kind of pointer as <kbd>*mut X</kbd> except that it is non-zero. There are two variants for creating a new <kbd>Shared&lt;T&gt;</kbd>, <kbd>const unsafe fn new_unchecked(ptr: *mut X) -&gt; Self</kbd> and  <kbd>fn new(ptr: *mut X) -&gt; Option&lt;Self&gt;</kbd>. In the first variant, the caller is responsible for ensuring that the pointer is non-null, and in the second the nulled nature of the pointer is checked, like so:</p>
<pre>    pub fn new(ptr: *mut T) -&gt; Option&lt;Self&gt; {
        NonZero::new(ptr as *const T).map(|nz| Shared { pointer: nz })
    }</pre>
<p>We find the definition and implementation of <kbd>NonZero&lt;T&gt;</kbd> in <kbd>src/libcore/nonzero.rs </kbd> like so:</p>
<pre style="padding-left: 30px">pub struct NonZero&lt;T: Zeroable&gt;(T);

impl&lt;T: Zeroable&gt; NonZero&lt;T&gt; {
    /// Creates an instance of NonZero with the provided value.
    /// You must indeed ensure that the value is actually "non-zero".
    #[unstable(feature = "nonzero",
               reason = "needs an RFC to flesh out the design",
               issue = "27730")]
    #[inline]
    pub const unsafe fn new_unchecked(inner: T) -&gt; Self {
        NonZero(inner)
    }

    /// Creates an instance of NonZero with the provided value.
    #[inline]
    pub fn new(inner: T) -&gt; Option&lt;Self&gt; {
        if inner.is_zero() {
            None
        } else {
            Some(NonZero(inner))
        }
    }

    /// Gets the inner value.
    pub fn get(self) -&gt; T {
        self.0
    }
}</pre>
<p><kbd>Zeroable</kbd> is an unstable trait, which is pretty straightforward:</p>
<pre>pub unsafe trait Zeroable {
    fn is_zero(&amp;self) -&gt; bool;
}</pre>
<p>Every pointer type implements an <kbd>is_null() -&gt; bool</kbd> and this trait defers to that function, and <kbd>NonZero::new</kbd> defers to <kbd>Zeroable::is_zero</kbd>. The presence of a <kbd>Shared&lt;T&gt;</kbd>, then, gives the programmer the same freedom as <kbd>*mut T</kbd> but with added guarantees about the pointer's nullable situation. Jumping back up to <kbd>Rc::new</kbd>:</p>
<pre style="padding-left: 30px">pub fn new(value: T) -&gt; Rc&lt;T&gt; {
    Rc {
        // there is an implicit weak pointer owned by all the strong
        // pointers, which ensures that the weak destructor never frees
        // the allocation while the strong destructor is running, even
        // if the weak pointer is stored inside the strong one.
        ptr: Shared::from(Box::into_unique(box RcBox {
            strong: Cell::new(1),
            weak: Cell::new(1),
            value,
        })),
        phantom: PhantomData,
    }
}</pre>
<p><kbd>Box::into_unique</kbd> converts a <kbd>Box&lt;T&gt;</kbd> into a <kbd>Unique&lt;T&gt;</kbd>—discussed previously in this chapter—which is then converted into a <kbd>Shared&lt;T&gt;</kbd>. This chain preserves the non-null guarantee needed and ensures uniqueness. Now, what about strong and weak in <kbd>RcBox</kbd>? <kbd>Rc&lt;T&gt;</kbd> provides a method, <kbd>Self::downgrade(&amp;self) -&gt; Weak&lt;T&gt;</kbd>, that produces a non-owning pointer, a pointer which does not guarantee the liveness of the referenced data and does not extend its lifetime. This is called a <em>weak reference</em>. Dropping a <kbd>Weak&lt;T&gt;</kbd>, likewise, does not imply that <kbd>T</kbd> is dropped. The trick here is that a strong reference does extend the liveness of the underlying <kbd>T</kbd>—the drop of <kbd>T</kbd> is only called when the internal counter of <kbd>Rc&lt;T&gt;</kbd> hits zero. For the most part, things rarely require a weak reference, except when a cycle of references exist. Suppose a graph structure were to be constructed where each node holds an <kbd>Rc&lt;T&gt;</kbd> to its connected nodes and a cycle exists in the graph. Calling drop on the current node will recursively call drop on the connected nodes, which will recurse again onto the current node and so forth. Were the graph to store a vector of all nodes and have each node store weak references to connections, then a drop of the vector would cause a drop of all nodes, cycles or not. We can see how this works in practice by inspecting the <kbd>Drop</kbd> implementation of <kbd>Rc&lt;T&gt;</kbd>:</p>
<pre style="padding-left: 30px">unsafe impl&lt;#[may_dangle] T: ?Sized&gt; Drop for Rc&lt;T&gt; {
    fn drop(&amp;mut self) {
        unsafe {
            let ptr = self.ptr.as_ptr();

            self.dec_strong();
            if self.strong() == 0 {
                // destroy the contained object
                ptr::drop_in_place(self.ptr.as_mut());

                // remove the implicit "strong weak" pointer<br/>                // now that we've destroyed the contents.
                self.dec_weak();

                if self.weak() == 0 {
                    Heap.dealloc(ptr as *mut u8, <br/>                    Layout::for_value(&amp;*ptr));
                }
            }
        }
    }
}</pre>
<p>This is trimmed some for clarity but the notion is as we've described—when the total number of strong references is zero, a full deallocation occurs. The referenced <kbd>Heap</kbd> and <kbd>Layout</kbd> are compiler internals and won't be discussed further here, but the interested reader is warmly encouraged to go spelunking on their own. Recall that in <kbd>Rc&lt;T&gt;::new</kbd>, both strong and weak counters started at <kbd>1</kbd>. To avoid invalidating the weak pointers, the actual <kbd>T</kbd> is only deallocated if there are no strong or weak pointers available. Let's have a look at <kbd>Drop for Weak&lt;T&gt;</kbd>, again trimmed some for clarity:</p>
<pre>impl&lt;T: ?Sized&gt; Drop for Weak&lt;T&gt; {
    fn drop(&amp;mut self) {
        unsafe {
            let ptr = self.ptr.as_ptr();

            self.dec_weak();
            // the weak count starts at 1, and will only go to<br/>            // zero if all the strong pointers have disappeared.
            if self.weak() == 0 {
                Heap.dealloc(ptr as *mut u8, Layout::for_value(&amp;*ptr));
            }
        }
    }
}</pre>
<p>As expected, the <kbd>T</kbd> can only be deallocated when the weak pointer total falls to zero, which is only possible if there are no strong pointers left. That's <kbd>Rc&lt;T&gt;</kbd>—a handful of important traits, a specialized box, and a few compiler internals.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Vec</h1>
                
            
            
                
<p>As our last subject in this chapter, let's consider <kbd>Vec&lt;T&gt;</kbd>. The Rust vector is a growable array, that is, an area of contiguous, homogeneous storage that can be grown through reallocation as the need arises, or it cane be shrunk. The advantage compared to array is in not needing to know ahead of time exactly what size of storage you need, plus all the benefits of a slicable structure and additional functions in the type API. <kbd>Vec&lt;T&gt;</kbd> is an extremely common Rust structure, so much so that its actual name is <kbd>std::vec::Vec&lt;T&gt;</kbd> but Rust imports the type by default. Rust programs are full of vectors and it stands to reason we'd do well to understand how it interacts with the memory it holds.</p>
<p><kbd>Vec&lt;T&gt;</kbd> is defined in <kbd>src/liballoc/vec.rs</kbd> and is defined as follows:</p>
<pre style="padding-left: 30px">pub struct Vec&lt;T&gt; {
    buf: RawVec&lt;T&gt;,
    len: usize,
}</pre>
<p>The Rust documentation declares that a <kbd>Vec&lt;T&gt;</kbd> will be laid out as a pointer, a capacity of <kbd>usize</kbd>, and a length of <kbd>usize.</kbd> The order of these fields is completely unspecified. As we've already discussed, Rust will reorder fields as it sees fit. Moreover, the pointer is guaranteed to be non-null, allowing for a null-pointer optimization. Previously, we saw the usual trick of Rust: define a higher-level structure in terms of a lower-level—or raw – structure, or even in terms of a fully unsafe structure. We see the length <kbd>usize</kbd> already, called <kbd>len</kbd>. This means there's a distinct difference between capacity and length, the distinction of which we'll come back to as we dig into <kbd>RawVec&lt;T&gt;</kbd>. Let's take a peek at <kbd>RawVec&lt;T&gt;</kbd>, defined in <kbd>src/liballoc/raw_vec.rs</kbd>:</p>
<pre style="padding-left: 30px">pub struct RawVec&lt;T, A: Alloc = Heap&gt; {
    ptr: Unique&lt;T&gt;,
    cap: usize,
    a: A,
}</pre>
<p>What we have is a pointer to a <kbd>Unique&lt;T&gt;</kbd>, a <kbd>*mut T</kbd> with added guarantees that the <kbd>RawVec&lt;T&gt;</kbd> is the only possessor of the allocation and that the pointer is not null. The <kbd>cap</kbd> is the capacity of the raw vector. <kbd>a: A</kbd> is the allocator, <kbd>Heap</kbd> by default. Rust does allow for allocators to be swapped, so long as the implementation obeys—as of writing this book—the <kbd>std::heap::Alloc</kbd> trait. Swapping allocators is an unstable feature of Rust, available only in the nightly channel, but one that is stable enough to see common use in the embedded Rust community's libraries. In this book, we won't use anything other than the default allocator, but the reader is warmly encouraged to explore the topic in more detail. Allocator aside, there's the pointers, length, and capacity that the Rust documentation promised. Let's pop back to <kbd>Vec&lt;T&gt;</kbd> and take a look at <kbd>new</kbd>:</p>
<pre>    pub fn new() -&gt; Vec&lt;T&gt; {
        Vec {
            buf: RawVec::new(),
            len: 0,
        }
    }</pre>
<p>Now, the new of raw <kbd>vec</kbd>:</p>
<pre>    pub fn new() -&gt; Self {
        Self::new_in(Heap)
    }</pre>
<p>This defers creation to <kbd>new_in</kbd>, a function on the same <kbd>trait</kbd>:</p>
<pre>    pub fn new_in(a: A) -&gt; Self {
        // !0 is usize::MAX. This branch should be stripped <br/>        // at compile time.
        let cap = if mem::size_of::&lt;T&gt;() == 0 { !0 } else { 0 };

        // Unique::empty() doubles as "unallocated" and "zero-sized<br/>        // allocation"
        RawVec {
            ptr: Unique::empty(),
            cap,
            a,
        }
    }</pre>
<p>The <kbd>cap</kbd> computation is interesting. It's possible to store a <kbd>T</kbd> in <kbd>Vec&lt;T&gt;</kbd>—and by extension <kbd>RawVec&lt;T&gt;</kbd>—that has zero size. The implementers knew this and came up with a fun solution: if the size of the type is zero, set the capacity to <kbd>usize::MAX</kbd>, else 0. It's not possible to cram <kbd>usize::MAX</kbd> elements into a vector since we'd run out of memory one allocation prior to hitting the cap and it's now possible to discriminate the case of zero-sized types without having to introduce an enumeration or a flag variable. Tidy trick. If we bounce back to vector and inspect <kbd>with_capacity</kbd>, we'll find that defers to <kbd>RawVec::with_capacity</kbd>, which defers to <kbd>RawVec::allocate_in</kbd>:</p>
<pre>    fn allocate_in(cap: usize, zeroed: bool, mut a: A) -&gt; Self {
        unsafe {
            let elem_size = mem::size_of::&lt;T&gt;();

            let alloc_size = <br/>            cap.checked_mul(elem_size).expect("capacity overflow");
            alloc_guard(alloc_size);

            // handles ZSTs and `cap = 0` alike
            let ptr = if alloc_size == 0 {
                mem::align_of::&lt;T&gt;() as *mut u8
            } else {
                let align = mem::align_of::&lt;T&gt;();
                let result = if zeroed {
                    a.alloc_zeroed(Layout::from_size_align(<br/>                        alloc_size, align).unwrap())
                } else {
                    a.alloc(Layout::from_size_align(<br/>                        alloc_size, align).unwrap())
                };
                match result {
                    Ok(ptr) =&gt; ptr,
                    Err(err) =&gt; a.oom(err),
                }
            };

            RawVec {
                ptr: Unique::new_unchecked(ptr as *mut _),
                cap,
                a,
            }
        }
    }</pre>
<p>There's a lot going on here, but it's important, so let's break it into small pieces. Firstly, see the following:</p>
<pre>            let elem_size = mem::size_of::&lt;T&gt;();

            let alloc_size = <br/>            cap.checked_mul(elem_size).expect("capacity overflow");
            alloc_guard(alloc_size);</pre>
<p>At the head of the function, the size of the element is computed and the total allocation requested by the caller is confirmed to be no more than the available system memory. Note that <kbd>checked_mul</kbd> ensures we don't overflow usize and accidentally allocate too little memory. Finally, a function called <kbd>alloc_guard</kbd> is called. That is as follows:</p>
<pre>fn alloc_guard(alloc_size: usize) {
    if mem::size_of::&lt;usize&gt;() &lt; 8 {
        assert!(
            alloc_size &lt;= ::core::isize::MAX as usize,
            "capacity overflow"
        );
    }
}</pre>
<p>This is a guarantee check. Remember that usize and isize are the signed and unsigned size of the system pointer. To understand this guard, we must understand the answer to two questions:</p>
<ol type="1">
<li>On a given machine, how much memory can I allocate?</li>
<li>On a given machine, how much memory can I address?</li>
</ol>
<p>It's possible to allocate usize bytes from the operating system but here, Rust is checking that the allocation size is less than the maximum isize. The Rust reference (<a href="https://doc.rust-lang.org/stable/reference/types.html#machine-dependent-integer-types">https://doc.rust-lang.org/stable/reference/types.html#machine-dependent-integer-types</a>) explains why:</p>
<div><p>"The isize type is a signed integer type with the same number of bits as the platform's pointer type. The theoretical upper bound on object and array size is the maximum isize value. This ensures that isize can be used to calculate differences between pointers into an object or array and can address every byte within an object along with one byte past the end."</p>
</div>
<p>Combined with the capacity check from <kbd>checked_mul</kbd>, we know that the allocation is properly sized and that it's addressable along the whole of itself:</p>
<pre>            let ptr = if alloc_size == 0 {
                mem::align_of::&lt;T&gt;() as *mut u8
            } else {</pre>
<p>In the event that the desired capacity is zero <em>or</em> the size of <kbd>T</kbd> is zero, the implementation coerces the minimum alignment of <kbd>T</kbd> into a pointer to bytes, the <kbd>*mut u8</kbd>. This pointer is, well, it points nowhere useful but the implementation has avoided an allocation when there is nothing that could be allocated, whether there will never be anything to allocate because of zero-sized types or not. This is good, and all the implementation will have to do is be aware that when the capacity is zero, or if the type size is zero, the pointer cannot be dereferenced. Right:</p>
<pre>            } else {
                let align = mem::align_of::&lt;T&gt;();
                let result = if zeroed {
                    a.alloc_zeroed(Layout::from_size_align(alloc_size, <br/>                        align).unwrap())
                } else {
                    a.alloc(Layout::from_size_align(alloc_size, <br/>                        align).unwrap())
                };
                match result {
                    Ok(ptr) =&gt; ptr,
                    Err(err) =&gt; a.oom(err),
                }
            };</pre>
<p>This branch is hit when there's memory to be allocated. Notably, two sub-possibilities, controlled by the <kbd>zeroed</kbd> argument: either memory is zeroed or it is left uninitialized. <kbd>Vec&lt;T&gt;</kbd> does not expose this option to the end user but we know from inspection that memory starts off uninitialized, an optimization for non-trivial allocations:</p>
<pre>            RawVec {
                ptr: Unique::new_unchecked(ptr as *mut _),
                cap,
                a,
            }
        }
    }</pre>
<p>The lack of an initialization flag is kind of tricky in some cases. Consider <kbd>std::io::Read::read_exact</kbd>. This function takes a <kbd>&amp;mut [u8]</kbd> and it's common enough to create this slice from a specially created vec. This code will <em>not</em> read 1024 bytes:</p>
<pre style="padding-left: 30px">use std::io;
use std::io::prelude::*;
use std::fs::File;

let mut f = File::open("foo.txt")?;
let mut buffer = Vec:with_capacity(1024);

f.read_exact(&amp;mut buffer)?;</pre>
<p>Why? The slice that we pass in is actually of zero length! Rust dereferences are allowed on a type by two traits: <kbd>std::ops::Deref</kbd> and <kbd>std::ops::DerefMut</kbd>, depending on your desire for an immutable or mutable slide. The <kbd>Deref</kbd>  trait is defined as follows:</p>
<pre style="padding-left: 30px">pub trait Deref {
    type Target: ?Sized;
    fn deref(&amp;self) -&gt; &amp;Self::Target;
}</pre>
<p>And the mutable version analogously. When we slice our vector as in the preceding code block, we're calling this <kbd>DerefMut::deref</kbd>:</p>
<pre style="padding-left: 30px">impl&lt;T&gt; ops::DerefMut for Vec&lt;T&gt; {
    fn deref_mut(&amp;mut self) -&gt; &amp;mut [T] {
        unsafe {
            let ptr = self.buf.ptr();
            assume(!ptr.is_null());
            slice::from_raw_parts_mut(ptr, self.len)
        }
    }
}</pre>
<p>This is the very important part: <kbd>slice::from_raw_parts_mut(ptr, self.len)</kbd>. Vector slices are built by length, not capacity. The capacity of a vector serves to distinguish how much memory has been allocated versus how much memory has been initialized, either to zeros or some other inserted values. This is an important difference. It's possible to initialize memory ourselves:</p>
<pre style="padding-left: 30px">let mut buffer: Vec&lt;u8&gt; = Vec::with_capacity(1024);
for _ in 0..1024 {
  buffer.push(0);
}
assert_eq!(1024, buffer.len());</pre>
<p>Or to rely on the <kbd>Vec</kbd> API to convert from a fixed-size array:</p>
<pre style="padding-left: 30px">let buffer = [0; 1024];
let buffer = &amp;mut buffer.to_vec();
assert_eq!(1024, buffer.len());
}</pre>
<p>Either will work. Which you choose depends on if you know the size of the buffer ahead of time or not.</p>
<p>Befitting such an important type, there are a good many API functions on <kbd>Vec&lt;T&gt;</kbd>. In the remainder of this chapter, we'll occupy ourselves with two mutations: <kbd>push</kbd> and <kbd>insert</kbd>. The <kbd>push</kbd> function is a constant operation, modulo any reallocations necessary to cope with the case of our capacity limit being reached. Here's the <kbd>push</kbd> function:</p>
<pre>    pub fn push(&amp;mut self, value: T) {
        // This will panic or abort if we would allocate &gt; isize::MAX bytes
        // or if the length increment would overflow for zero-sized types.
        if self.len == self.buf.cap() {
            self.buf.double();
        }
        unsafe {
            let end = self.as_mut_ptr().offset(self.len as isize);
            ptr::write(end, value);
            self.len += 1;
        }
    }</pre>
<p>If you'll recall, <kbd>self.buf</kbd> is the underlying <kbd>RawVec&lt;T&gt;</kbd>. The documentation for <kbd>Vec&lt;T&gt;</kbd> notes that when reallocation is required, the underlying memory will be doubled, which, it turns out, is handled by <kbd>RawVec&lt;T&gt;::double</kbd>. That function is fairly long and, as you might suspect, is a bunch of arithmetic to compute the new, doubled size matched with a realloc when there's an existing allocation, else when there's a new allocation. That is worth listing:</p>
<pre>                None =&gt; {
                    // skip to 4 because tiny Vec's are dumb; <br/>                    // but not if that would cause overflow
                    let new_cap = if elem_size &gt; (!0) / 8 { <br/>                                      1 <br/>                                  } else { <br/>                                      4 <br/>                                  };
                    match self.a.alloc_array::&lt;T&gt;(new_cap) {
                        Ok(ptr) =&gt; (new_cap, ptr),
                        Err(e) =&gt; self.a.oom(e),
                    }
                }</pre>
<p><kbd>Alloc::alloc_array</kbd> allocates space for contiguous memory, which is suitable to hold <kbd>new_cap</kbd> number of elements the size of <kbd>T</kbd>, returning the pointer to the first address of this newly allocated space. Here then, is the contiguous memory promised in the documentation of <kbd>Vec&lt;T&gt;</kbd>! Back in <kbd>Vec&lt;T&gt;</kbd>, now that the capacity is twice that of what it was, at least, the value <kbd>T</kbd> can be inserted:</p>
<pre>        unsafe {
            let end = self.as_mut_ptr().offset(self.len as isize);
            ptr::write(end, value);
            self.len += 1;
        }</pre>
<p>Rust pointers are handy in that their offset function takes into account the size of <kbd>T</kbd>; there's no need to do additional multiplication as the caller. The implementation is determining the first of the unused <kbd>T</kbd> sized spaces in the contiguous allocation—denoted end—and then writes the moved <kbd>T</kbd> onto that address. The fact that the space is unused is important<em>, </em><kbd>std::ptr::write</kbd> does not deallocate any memory that may have originally existed at the written-to pointer. If you <kbd>ptr::write</kbd> over the top of a live reference, wacky things will happen.</p>
<p>Finally, <kbd>insert</kbd>. The <kbd>insert</kbd> function of <kbd>Vec&lt;T&gt;</kbd> allows for the insertion of <kbd>T</kbd> at any valid index in the vector. If the insertion is to the end of the vector, the method is functionally equivalent to pushing, though mechanically different, as we'll see shortly. If, however, insertion occurs somewhere inside of the vector, all elements to the right of the insertion index are shifted over once, a non-trivial operation depending on the size of the allocation. Here's the full listing of <kbd>insert</kbd>:</p>
<pre>    pub fn insert(&amp;mut self, index: usize, element: T) {
        let len = self.len();
        assert!(index &lt;= len);

        // space for the new element
        if len == self.buf.cap() {
            self.buf.double();
        }

        unsafe {
            // infallible
            // The spot to put the new value
            {
                let p = self.as_mut_ptr().offset(index as isize);
                // Shift everything over to make space. (Duplicating the
                // `index`th element into two consecutive places.)
                ptr::copy(p, p.offset(1), len - index);
                // Write it in, overwriting the first copy of the `index`th
                // element.
                ptr::write(p, element);
            }
            self.set_len(len + 1);
        }
    }</pre>
<p>The index checking and potential buffering is straightforward at this point in the chapter. In the unsafe block, <kbd>p</kbd> is the proper offset for insertion. The two important lines are:</p>
<pre style="padding-left: 60px">ptr::copy(p, p.offset(1), len - index);
ptr::write(p, element);</pre>
<p>When a value is inserted into a vector, no matter the location, all the memory starting from <kbd>p</kbd> to the end of the list is copied over the top of the memory, starting at <kbd>p+1</kbd>. Once this is done, the inserted value is written over the top of <kbd>p</kbd>. This is a non-trivial operation and can become incredibly slow, especially if the allocation to be shifted is fairly large. Performance-focused Rust will use <kbd>Vec::insert</kbd> sparingly, if at all. <kbd>Vec&lt;T&gt;</kbd> will almost surely make an appearance.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Summary</h1>
                
            
            
                
<p>In this chapter, we covered the layout of Rust objects in memory, the way references work across both safe and unsafe Rust, and have addressed the various allocation strategies of a Rust program. We did a deep-dive on types in the Rust standard library to make these concepts concrete and it is hoped that the reader will now feel comfortable further exploring the compiler and will do so with confidence.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Further reading</h1>
                
            
            
                
<p class="mce-root">The memory model of a programming language is a broad topic. Rust's, as of writing this book, must be understood from the inspection of the Rust documentation, the rustc source code, and research into LLVM. That is, Rust's memory model is not formally documented, though there are rumblings in the community of providing it. Independent of that, it is also important for the working programmer to understand the underlying machine. There's a staggering amount of material to be covered.</p>
<p class="mce-root">These notes are a small start, focusing especially on the Rust documentation that relates most to this chapter:</p>
<ul>
<li><em>High Performance Code 201: Hybrid Data Structures</em>, Chandler Carruth, available at <a href="https://www.youtube.com/watch?v=vElZc6zSIXM&amp;index=5&amp;list=PLKW_WLANyJtqQ6IWm3BjzHZvrFxFSooey">https://www.youtube.com/watch?v=vElZc6zSIXM&amp;index=5&amp;list=PLKW_WLANyJtqQ6IWm3BjzHZvrFxFSooey</a>. This, in point of fact, is a talk from CppCon 2016. Carruth is an engaging speaker and is a member of the LLVM team focused on compiler performance. This talk is especially interesting from the point of view of building information-dense data structures that interact well with CPU caches. While the talk is in C++, the techniques apply directly to Rust.</li>
<li><em>Cache-oblivious Algorithms</em>, Matteo Frigo, Charles Leiserson, Harald Prokop, and Sridhar Ramachandran. This paper introduces the concept of building data structures that are cache oblivious, or, native to machines with memory hierarchies and interact with them well, in addition to a machine model to analyze such data structures.</li>
<li><em>Cache-Oblivious Algorithms and Data Structures</em>, Erik Demaine. This paper is a classic in the cache-oblivious space, building on the work presented in the last by Frigo et al and summarizing existing work. This is a highly recommended read, especially in conjunction with the previous paper. It is well worth scanning the bibliography as well.</li>
<li><em>The Stack and the Heap</em>, available at <a href="https://doc.rust-lang.org/book/first-edition/the-stack-and-the-heap.html">https://doc.rust-lang.org/book/first-edition/the-stack-and-the-heap.html</a>. This chapter from the first edition of the Rust book explains the difference between the hardware stack and heap, allocations to each, and the implications for Rust. This chapter has gone into further detail in some areas, but the Rust book's chapter is warmly recommended for anyone needing a refresher or a more gentle climb.</li>
<li><em>Splitting Borrows</em>, available at <a href="https://doc.rust-lang.org/beta/nomicon/borrow-splitting.html">https://doc.rust-lang.org/beta/nomicon/borrow-splitting.html</a>. The Nomicon is a Rust book intended to teach low-level Rust programming, not unlike this book. While it is a work-in-progress, the information in it is invaluable. <em>Splitting Borrows</em> explains the reasoning behind a common issue with new Rust developers: performing multiple mutable borrows out of a vector or array. The fact that this works with <em>structs</em> is often a source of great confusion and anguish.</li>
<li><em>Rust Reference</em>, available at <a href="https://doc.rust-lang.org/reference/">https://doc.rust-lang.org/reference/</a>. Like any established programming language, the Rust Reference is invaluable for understanding the subtle details of the language itself, which have been hashed out in mailing lists and over chat for years. The reference in its current form can be a touch hard to search—it used to be one long page—but it's hoped the situation will be improved upon by the time our book here has gone to press.</li>
<li><em>Closures: Anonymous Functions that can Capture their Environment</em>, available at <a href="http://doc.rust-lang.org/1.23.0/book/second-edition/ch13-01-closures.html">http://doc.rust-lang.org/1.23.0/book/second-edition/ch13-01-closures.html</a>. Rust closures have some subtle implications to them that can be hard to internalize for new Rust developers. This chapter in the second edition of the Rust Book is excellent in this regard.</li>
<li><em>External blocks</em>, available at <a href="https://doc.rust-lang.org/reference/items/external-blocks.html">https://doc.rust-lang.org/reference/items/external-blocks.html</a>. External blocks are relatively rare in this book—and, perhaps, in most of the Rust code you're likely to see—but there's a fair few of them available. It is well worth having a passing knowledge of this document's existence.</li>
<li><em>Hacker's Delight</em>, Henry Warren Jr.This book is a classic. Many of the tricks present in the book are now available as simple instructions on some chips, such as x86, but you'll see the occasional delight here or there in the <kbd>rustc</kbd> source code, the <kbd>swap_nonoverlapping_bytes</kbd> trick especially.</li>
</ul>
<p class="mce-root"/>


            

            
        
    </div>



  </body></html>