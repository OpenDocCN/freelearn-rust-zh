["```rs\ncargo install --force --path .\n```", "```rs\n    mio = {version = \"0.8\", features = [\"net\", \"os-poll\"]}\n    ```", "```rs\nsrc\n  |-- runtime\n       |-- executor.rs\n       |-- reactor.rs\n  |-- future.rs\n  |-- http.rs\n  |-- main.rs\n  |-- runtime.rs\n```", "```rs\nmod future;\nmod http;\nmod runtime;\nuse crate::http::Http;\nuse future::{Future, PollState};\nuse runtime::Waker;\nfn main() {\n    let mut executor = runtime::init();\n    executor.block_on(async_main());\n}\ncoroutine fn async_main() {\n    println!(\"Program starting\");\n    let txt = Http::get(\"/600/HelloAsyncAwait\").wait;\n    println!(\"{txt}\");\n    let txt = Http::get(\"/400/HelloAsyncAwait\").wait;\n    println!(\"{txt}\");\n}\n```", "```rs\ncorofy ./src/main.rs ./src/main.rs\n```", "```rs\n64: fn poll(&mut self, waker: &Waker)\n82: match f1.poll(waker)\n102: match f2.poll(cargo run.\n\t\t\tYou should see the following output (the output has been abbreviated to save a little bit of space):\n\n```", "```rs\n\n\t\t\tNote\n\t\t\tRemember that we need `delayserver` running in a terminal window so that we get a response to our HTTP GET requests. See the *Technical requirements* section for more information.\n\t\t\tNow that we’ve got the boilerplate out of the way, it’s time to start making the improvements we talked about.\n\t\t\tImproving our base example\n\t\t\tWe want to see how we can improve our state machine so that it allows us to hold variables across wait points. To do that, we need to store them somewhere and restore the variables that are needed when we enter each state in our state machine.\n\t\t\tTip\n\t\t\tPretend that these rewrites are done by `corofy` (or the compiler). Even though `corofy` can’t do these rewrites, it’s possible to automate this process as well.\n\t\t\tOr coroutine/wait program looks like this:\n\n```", "```rs\n\n\t\t\tWe want to change it so that it looks like this:\n\n```", "```rs\n\n\t\t\tIn this version, we simply create a `counter` variable at the top of our `async_main` function and increase the counter for each response we receive from the server. At the end, we print out how many responses we received.\n\t\t\tNote\n\t\t\tFor brevity, I won’t present the entire code base going forward; instead, I will only present the relevant additions and changes. Remember that you can always refer to the same example in this book’s GitHub repository.\n\t\t\tThe way we implement this is to add a new field called `stack` to our `Coroutine0` struct:\n\t\t\tch09/a-coroutines-variables/src/main.rs\n\n```", "```rs\n\n\t\t\tThe stack fields hold a `Stack0` struct that we also need to define:\n\t\t\tch09/a-coroutines-variables/src/main.rs\n\n```", "```rs\n\n\t\t\tThis struct will only hold one field since we only have one variable. The field will be of the `Option<usize>` type. We also derive the `Default` trait for this struct so that we can initialize it easily.\n\t\t\tNote\n\t\t\tFutures created by async/await in Rust store this data in a slightly more efficient manner. In our example, we store every variable in a separate struct since I think it’s easier to reason about, but it also means that the more variables we need to store, the more space our coroutine will need. It will grow linearly with the number of different variables that need to be stored/restored between state changes. This could be a lot of data. For example, if we have 100 state changes that each need one distinct `i64`-sized variable to be stored to the next state, that would require a struct that takes up 100 * 8b = 800 bytes in memory.\n\t\t\tRust optimizes this by implementing coroutines as enums, where each state only holds the data it needs to restore in the *next* state. This way, the size of a coroutine is not dependent on the *total number of variables*; it’s only dependent on the *size of the largest state that needs to be saved/restored*. In the preceding example, the size would be reduced to 8 bytes since the largest space any single state change needed is enough to hold one `i64`-sized variable. The same space will be reused over and over.\n\t\t\tThe fact that this design allows for this optimization is significant and it’s an advantage that stackless coroutines have over stackful coroutines when it comes to memory efficiency.\n\t\t\tThe next thing we need to change is the `new` method on `Coroutine0`:\n\t\t\tch09/a-coroutines-variables/src/main.rs\n\n```", "```rs\n\n\t\t\tThe default value for `stack` is not relevant to us since we’ll overwrite it anyway.\n\t\t\tThe next few steps are the ones of most interest to us. In the `Future` implementation for `Coroutine0`, we’ll pretend that `corofy` added the following code to initialize, store, and restore the stack variables for us. Let’s take a look at what happens on the first call to `poll` now:\n\t\t\tch09/a-coroutines-variables/src/main.rs\n\n```", "```rs\n\n\t\t\tOkay, so there are some important changes here that I’ve highlighted. Let’s go through them:\n\n\t\t\t\t*   The first thing we do when we’re in the `Start` state is add a segment at the top where we initialize our stack. One of the things we do is *hoist* all variable declarations for the relevant code section (in this case, before the first `wait` point) to the top of the function.\n\t\t\t\t*   In our example, we also initialize the variables to their initial value, which in this case is `0`.\n\t\t\t\t*   We also added a comment stating that we should save the stack, but since all that happens before the first wait point is the initialization of `counter`, there is nothing to store here.\n\n\t\t\tLet’s take a look at what happens after the first wait point:\n\t\t\tch09/a-coroutines-variables/src/main.rs\n\n```", "```rs\n\n\t\t\tHmm, this is interesting. I’ve highlighted the changes we need to make.\n\t\t\t The first thing we do is to *restore* the stack by taking ownership over the counter (`take()`replaces the value currently stored in `self.stack.counter` with `None` in this case) and writing it to a variable with the same name that we used in the code segment (`counter`). Taking ownership and placing the value back in later is not an issue in this case and it mimics the code we wrote in our coroutine/wait example.\n\t\t\tThe next change is simply the segment that takes all the code after the first wait point and pastes it in. In this case, the only change is that the `counter` variable is increased by `1`.\n\t\t\tLastly, we save the stack state back so that we hold onto its updated state between the wait points.\n\t\t\tNote\n\t\t\tIn [*Chapter 5*](B20892_05.xhtml#_idTextAnchor092), we saw how we needed to store/restore the register state in our fibers. Since [*Chapter 5*](B20892_05.xhtml#_idTextAnchor092) showed an example of a *stackful coroutine* implementation, we didn’t have to care about stack state at all since all the needed state was stored in the stacks we created.\n\t\t\tSince our coroutines are *stackless*, we don’t store the entire call stack for each coroutine, but we do need to store/restore the parts of the stack that will be used *across wait points*. Stackless coroutines still need to save some information from the stack, as we’ve done here.\n\t\t\tWhen we enter the `State0::Wait2` state, we start the same way:\n\t\t\tch09/a-coroutines-variables/src/main.rs\n\n```", "```rs\n\n\t\t\tSince there are no more wait points in our program, the rest of the code goes into this segment and since we’re done with `counter` at this point, we can simply `drop` it by letting it go out of scope. If our variable held onto any resources, they would be released here as well.\n\t\t\tWith that, we’ve given our coroutines the power of saving variables across wait points. Let’s try to run it by writing `cargo run`.\n\t\t\tYou should see the following output (I’ve removed the parts of the output that remain unchanged):\n\n```", "```rs\n\n\t\t\tOkay, so our program works and does what’s expected. Great!\n\t\t\tNow, let’s take a look at an example that needs to store *references* across wait points since that’s an important aspect of having our coroutine/wait functions behave like “normal” functions.\n\t\t\tImproving our example 2 – references\n\t\t\tLet’s set everything up for our next version of this example:\n\n\t\t\t\t*   Create a new folder called `b-coroutines-references` and copy everything from `a-coroutines-variables` over to it\n\t\t\t\t*   You can change the name of the project so that it corresponds with the folder by changing the `name` attribute in the `package` section in `Cargo.toml`, but it’s not something you need to do for the example to work\n\n\t\t\tNote\n\t\t\tYou can find this example in this book’s GitHub repository in the `ch10/b-coroutines-references` folder.\n\t\t\tThis time, we’ll learn how to store references to variables in our coroutines by using the following coroutine/wait example program:\n\n```", "```rs\n\n\t\t\tSo, in this example, we create a `buffer` variable of the `String` type that we initialize with some text, and we take a `&mut` reference to that and store it in a `writer` variable.\n\t\t\tEvery time we receive a response, we write the response to the buffer through the `&mut` reference we hold in `writer` before we print the buffer to the terminal at the end of the program.\n\t\t\tLet’s take a look at what we need to do to get this working.\n\t\t\tThe first thing we do is pull in the `fmt::Write` trait so that we can write to our buffer using the `writeln!` macro.\n\t\t\tAdd this to the top of `main.rs`:\n\t\t\tch09/b-coroutines-references/src/main.rs\n\n```", "```rs\n\n\t\t\tNext, we need to change our `Stack0` struct so that it represents what we must store across wait points in our updated example:\n\t\t\t ch09/b-coroutines-references/src/main.rs\n\n```", "```rs\n\n\t\t\tAn important thing to note here is that `writer` can’t be `Option<&mut String>` since we know it will be referencing the buffer field in the same struct. A struct where a field takes a reference on `&self` is called a **self-referential** struct and there is no way to represent that in Rust since the lifetime of the self-reference is impossible to express.\n\t\t\tThe solution is to cast the `&mut` self-reference to a pointer instead and ensure that we manage the lifetimes correctly ourselves.\n\t\t\tThe only other thing we need to change is the `Future::poll` implementation:\n\t\t\tch09/b-coroutines-references/src/main.rs\n\n```", "```rs\n\n\t\t\tOkay, so this looks a bit odd. The first line we change is pretty straightforward. We initialize our `buffer` variable to a new `String` type, just like we did at the top of our coroutine/wait program.\n\t\t\tThe next line, however, looks a bit dangerous.\n\t\t\tWe cast the `&mut` reference to our `buffer` to a `*``mut` pointer.\n\t\t\tImportant\n\t\t\tYes, I know we could have chosen another way of doing this since we can take a reference to buffer everywhere we need to instead of storing it in its variable, but that’s only because our example is very simple. Imagine that we use a library that needs to borrow data that’s local to the async function and we somehow have to manage the lifetimes manually like we do here but in a much more complex scenario.\n\t\t\tThe `self.stack.buffer.as_mut().unwrap()` line returns a `&mut` reference to the `buffer` field. Since `self.stack.writer` is of the `Option<*mut String>` type, the reference will be *coerced* to a pointer (meaning that Rust does this cast implicitly by inferring it from the context).\n\t\t\tNote\n\t\t\tWe take `*mut String` here since we deliberately don’t want a *string slice* (`&str`), which is often what we get (and want) when using a reference to a `String` type in Rust.\n\t\t\tLet’s take a look at what happens after the first wait point:\n\t\t\tch09/b-coroutines-references/src/main.rs\n\n```", "```rs\n\n\t\t\tThe first change we make is regarding how we restore our stack. We need to restore our `writer` variable so that it holds a `&mut String` type that points to our buffer. To do this, we have to write some `unsafe` code that dereferences our pointer and lets us take a `&mut` reference to our `buffer`.\n\t\t\tNote\n\t\t\tCasting a reference to a pointer is safe. The unsafe part is dereferencing the pointer.\n\t\t\tNext, we add the line of code that writes the response. We can keep this the same as how we wrote it in our coroutine/wait function.\n\t\t\tLastly, we save the stack state back since we need both variables to live across the wait point.\n\t\t\tNote\n\t\t\tWe don’t have to take ownership over the pointer stored in the `writer` field to use it since we can simply copy it, but to be somewhat consistent, we take ownership over it, just like we did in the first example. It also makes sense since if there is no need to store the pointer for the next await point, we can simply let it go out of scope by not storing it back.\n\t\t\tThe last part is when we’ve reached `Wait2` and our future returns `PollState::Ready`:\n\n```", "```rs\n\n\t\t\tIn this segment, we restore both variables since we write the last response through our writer variable, and then print everything that’s stored in our `buffer` to the terminal.\n\t\t\tI want to point out that the `println!(\"{}\", buffer);` line takes a reference in the original coroutine/wait example, even though it might look like we pass in `an` `owned` `String`. Therefore, it makes sense that we restore the buffer to a `&String` type, and not the owned version. Transferring ownership would also invalidate the pointer in our `writer` variable.\n\t\t\tThe last thing we do is `drop` the data we don’t need anymore. Our `self.stack.writer` field is already set to `None` since we took ownership over it when we restored the stack at the start, but we need to take ownership over the `String` type that `self.stack.buffer` holds as well so that it gets dropped at the end of this scope too. If we didn’t do that, we would hold on to the memory that’s been allocated to our `String` until the entire coroutine is dropped (which could be much later).\n\t\t\tNow, we’ve made all our changes. If the rewrites we did previously were implemented in `corofy`, our coroutine/wait implementation could, in theory, support much more complex use cases.\n\t\t\tLet’s take a look at what happens when we run our program by writing `cargo run`:\n\n```", "```rs\n\n\t\t\tPuh, great. All that dangerous `unsafe` turned out to work just fine, didn’t it? Good job. Let’s make one small improvement before we finish.\n\t\t\tImproving our example 3 – this is… not… good…\n\t\t\tPretend you haven’t read this section title and enjoy the fact that our previous example compiled and showed the correct result.\n\t\t\tI think our coroutine implementation is so good now that we can look at some optimizations instead. There is one optimization in our executor in particular that I want to do immediately.\n\t\t\tBefore we get ahead of ourselves, let’s set everything up:\n\n\t\t\t\t*   Create a new folder called `c-coroutines-problem` and copy everything from `b-coroutines-references` over to it\n\t\t\t\t*   You can change the name of the project so that it corresponds with the folder by changing the `name` attribute in the `package` section in `Cargo.toml`, but it’s not something you need to do for the example to work\n\n\t\t\tTip\n\t\t\tThis example is located in this book’s GitHub repository in the `ch``09``/c-coroutines-problem` folder.\n\t\t\tWith that, everything has been set up.\n\t\t\tBack to the optimization. You see, new insights into the workload our runtime will handle in real life indicate that most futures will return `Ready` on the first poll. So, in theory, we can just poll the future we receive in `block_on` once and it will resolve immediately most of the time.\n\t\t\tLet’s navigate to `src/runtime/executor.rs` and take a look at how we can take advantage of this by adding a few lines of code.\n\t\t\tIf you navigate to our `Executor::block_on` function, you’ll see that the first thing we do is `spawn` the future before we poll it. Spawning the future means that we allocate space for it in the heap and store the pointer to its location in a `HashMap` variable.\n\t\t\tSince the future will most likely return `Ready` on the first `poll`, this is unnecessary work that could be avoided. Let’s add this little optimization at the start of the `block_on` function to take advantage of this:\n\n```", "```rs\n\n\t\t\tNow, we simply poll the future immediately, and if the future resolves on the first poll, we return since we’re all done. This way, we only spawn the future if it’s something we need to wait on.\n\t\t\tYes, this assumes we never reach `usize::MAX` for our IDs, but let’s pretend this is only a proof of concept. Our `Waker` will be discarded and replaced by a new one if the future is spawned and polled again anyway, so that shouldn’t be a problem.\n\t\t\tLet’s try to run our program and see what we get:\n\n```", "```rs\n\n\t\t\tWait, what?!?\n\t\t\tThat doesn’t sound good! Okay, that’s probably a kernel bug in Linux, so let’s try it on Windows instead:\n\n```", "```rs\n\n\t\t\tThat sounds even worse!! What happened here?\n\t\t\tLet’s take a closer look at exactly what happened with our async system when we made our small optimization.\n\t\t\tDiscovering self-referential structs\n\t\t\tWhat happened is that we created a self-referential struct, initialized it so that it took a pointer to itself, and then moved it. Let’s take a closer look:\n\n\t\t\t\t1.  First, we received a future object as an argument to `block_on`. This is not a problem since the future isn’t self-referential yet, so we can move it around wherever we want to without issues (this is also why moving futures before they’re polled is perfectly fine using proper async/await).\n\t\t\t\t2.  Then, we polled the future once. The optimization we did made one essential change. The future was located on the stack (inside the stack frame of our `block_on` function) when we polled it the first time.\n\t\t\t\t3.  When we polled the future the first time, we initialized the variables to their initial state. Our `writer` variable took a pointer to our `buffer` variable (stored as a part of our coroutine) and made it *self-referential* at this point.\n\t\t\t\t4.  The first time we polled the future, it returned `NotReady`\n\t\t\t\t5.  Since it returned `NotReady`, we spawned the future, which moves it into the tasks collection with the `HashMap<usize, Box<dyn Future<Output = String>>>` type in our `Executor`. The future is now placed in `Box`, which moves it to the heap.\n\t\t\t\t6.  The next time we poll the future, we restore the stack by dereferencing the pointer we hold for our `writer` variable. However, there’s a big problem: the pointer is now pointing to the old location on the stack where the future was located at the first poll.\n\t\t\t\t7.  That can’t end well, and it doesn’t in our case.\n\n\t\t\tYou’ve now seen firsthand the problem with self-referential structs, how this applies to futures, and why we need something that prevents this from happening.\n\t\t\tA **self-referential struct** is a struct that takes a reference to *self* and stores it in a field. Now, the term *reference* here is a little bit unprecise since there is no way to take a reference to *self* in Rust and store that reference in *self*. To do this in safe Rust, you have to cast the reference to a *pointer* (remember that references are just pointers with a special meaning in the programming language).\n\t\t\tNote\n\t\t\tWhen we create visualizations in this chapter, we’ll disregard *padding*, even though we know structs will likely have some padding between fields, as we discussed in [*Chapter 4*](B20892_04.xhtml#_idTextAnchor081).\n\t\t\tWhen this value is moved to another location in memory, the pointer is not updated and points to the “old” location.\n\t\t\tIf we take a look at a move from one location on the stack to another one, it looks something like this:\n\t\t\t![Figure 9.1 – Moving a self-referential struct](img/B20892_09_11.jpg)\n\n\t\t\tFigure 9.1 – Moving a self-referential struct\n\t\t\tIn the preceding figure, we can see the memory addresses to the left with a representation of the stack next to it. Since the pointer was not updated when the value was moved, it now points to the old location, which can cause serious problems.\n\t\t\tNote\n\t\t\tIt can be very hard to detect these issues, and creating simple examples where a move like this causes serious issues is surprisingly difficult. The reason for this is that even though we move everything, the old values are not zeroed or overwritten immediately. Often, they’re still there, so dereferencing the preceding pointer would *probably* produce the correct value. The problem only arises when you change the value of `x` in the new location, and expect `y` to point to it. Dereferencing `y` still produces a valid value in this case, but it’s the *wrong* value.\n\t\t\tOptimized builds often optimize away needless moves, which can make bugs even harder to detect since most of the program will seem to work just fine, even though it contains a serious bug.\n\t\t\tWhat is a move?\n\t\t\tA *move* in Rust is one of those concepts that’s unfamiliar to many programmers coming from C#, Javascript, and similar garbage-collected languages, and different from what you’re used to for C and C++ programmers. The definition of *move* in Rust is closely related to its ownership system.\n\t\t\tMoving means transferring ownership. In Rust, a *move* is the default way of passing values around and it happens every time you change ownership over an object. If the object you move only consists of copy types (types that implement the `Copy` trait), this is as simple as copying the data over to a new location on the stack.\n\t\t\tFor non-copy types, a move will copy all copy types that it contains over just like in the first example, but now, it will also copy **pointers** to resources such as heap allocations. The moved-from object is left **inaccessible** to us (for example, if you try to use the moved-from object, the compilation will fail and let you know that the object has moved), so there is only one owner over the allocation at any point in time.\n\t\t\tIn contrast to *cloning*, it does not recreate any resources and make a clone of them.\n\t\t\tOne more important thing is that the compiler makes sure that `drop` is never called on the moved-from object so that the only thing that can free the resources is the new object that took ownership over everything.\n\t\t\t*Figure 9**.2* provides a simplified visual overview of the difference between move, clone, and copy (we’ve excluded any internal padding of the struct in this visualization). Here, we assume that we have a struct that holds two fields – a copy type, `a`, which is an `i64` type, and a non-copy type, `b`, which is a `Vec<u8>` type:\n\t\t\t![Figure 9.2 – Move, clone, and copy](img/B20892_10_2.jpg)\n\n\t\t\tFigure 9.2 – Move, clone, and copy\n\t\t\tA move will in many ways be like a deep copy of everything in our struct that’s located on the stack. This is problematic when you have a pointer that points to `self`, like we have with self-referential structs, since `self` will start at a new memory address after the move but the pointer to `self` won’t be adjusted to reflect that change.\n\t\t\tMost of the time, when programming Rust, you probably won’t think a lot about moves since it’s part of the language you never explicitly use, but it’s important to know what it is and what it does.\n\t\t\tNow that we’ve got a good understanding of what the problem is, let’s take a closer look at how Rust solves this by using its type system to prevent us from moving structs that rely on a stable place in memory to function correctly.\n\t\t\tPinning in Rust\n\t\t\tThe following diagram shows a slightly more complex self-referential struct so that we have something visual to help us understand:\n\t\t\t![Figure 9.3 – Moving a self-referential struct with three fields](img/B20892_10_3.jpg)\n\n\t\t\tFigure 9.3 – Moving a self-referential struct with three fields\n\t\t\tAt a very high level, pinning makes it possible to rely on data that has a stable memory address by disallowing any operation that might move it:\n\t\t\t![Figure 9.4 – Moving a pinned struct](img/B20892_09_41.jpg)\n\n\t\t\tFigure 9.4 – Moving a pinned struct\n\t\t\tThe concept of pinning is pretty simple. The complex part is how it’s implemented in the language and how it’s used.\n\t\t\tPinning in theory\n\t\t\tPinning is a part of Rust’s standard library and consists of two parts: the type, **Pin**, and the marker-trait, **Unpin**. Pinning is only a language construct. There is no special kind of location or memory that you move values to so they get pinned. There is no syscall to ask the operating system to ensure a value stays the same place in memory. It’s only a part of the type system that’s designed to prevent us from being able to move a value.\n\t\t\t`Pin` does not remove the need for `unsafe` – it just gives the user of `unsafe` a guarantee that the value has a stable location in memory, so long as the user that pinned the value only uses *safe* Rust. This allows us to write self-referential types that are safe. It makes sure that all operations that can lead to problems must use `unsafe`.\n\t\t\tBack to our coroutine example, if we were to move the struct, we’d have to write `unsafe` Rust. That is how Rust upholds its safety guarantee. If you somehow know that the future you created never takes a self-reference, you could choose to move it using `unsafe`, but the blame now falls on you if you get it wrong.\n\t\t\tBefore we dive a bit deeper into pinning, we need to define several terms that we’ll need going forward.\n\t\t\tDefinitions\n\t\t\tHere are the definitions we must understand:\n\n\t\t\t\t*   `std::pin` module. `Pin` wrap types that implement the `Deref` trait, which in practical terms means that it wraps *references and* *smart pointers*.\n\t\t\t\t*   `Unpin`, *pinning will have no effect on that type*. You read that right – no effect. The type will still be wrapped in `Pin` but you can simply take it out again.\n\n    The impressive thing is that almost everything implements `Unpin` by default, and if you manually want to mark a type as `!Unpin`, you have to add a marker trait called `PhantomPinned` to your type. Having a type, `T`, implement `!Unpin` is the only way for something such as `Pin<&mut T>` to have any effect.\n\n\t\t\t\t*   **Pinning a type that’s !Unpin** will guarantee that the value remains at the same location in memory until it gets dropped, so long as you stay in safe Rust.\n\t\t\t\t*   `self`. For example, they often look like `fn foo(self:` `Pin<&mut self>)`.\n\t\t\t\t*   `Pin<&mut T>` where `T` has one field, `a`, that can be moved freely and one that can’t be moved, `b`, you can do the following:\n    *   Write a *pin projection* for `a` with the `fn a(self: Pin<&mut self>) -> &A` signature. In this case, we say that pinning is *not structural*.\n    *   Write a projection for `b` that looks like `fn b(self: Pin<&mut self>) -> Pin<&mut B>`, in which case we say that pinning is *structural* for `b` since it’s pinned when the struct, `T`, is pinned.\n\n\t\t\tWith the most important definitions out of the way, let’s look at the two ways we can pin a value.\n\t\t\tPinning to the heap\n\t\t\tNote\n\t\t\tThe small code snippets we’ll present here can be found in this book’s GitHub repository in the `ch``09``/d-pin` folder. The different examples are implemented as different methods that you comment/uncomment in the `main` function.\n\t\t\tLet’s write a small example to illustrate the different ways of pinning a value:\n\t\t\tch09/d-pin/src/main.rs\n\n```", "```rs\n\n\t\t\tSo, we want to be able to create an instance using `MaybeSelfRef::default()` that we can move around as we wish, but then at some point *initialize* it to a state where it references itself; moving it would cause problems.\n\t\t\tThis is very much like futures that are not self-referential until they’re polled, as we saw in our previous example. Let's write the `impl` block for `MaybeSelfRef` and take a look at the code::\n\t\t\tch09/d-pin/src/main.rs\n\n```", "```rs\n\n\t\t\tAs you can see, `MaybeStelfRef` will only be self-referential after we call `init` on it.\n\t\t\tWe also define one more method that casts the pointer stored in `b` to `Option<&mut usize>`, which is a mutable reference to `a`.\n\t\t\tOne thing to note is that both our functions require `unsafe`. Without `Pin`, the only method requiring unsafe would be `b` since we dereference a pointer there. Acquiring a mutable reference to a pinned value always require `unsafe`, since there is nothing preventing us from moving the pinned value at that point.\n\t\t\tPinning to the heap is usually done by pinning a `Box`. There is even a convenient method on `Box` that allows us to get `Pin<Box<...>>`. Let’s look at a short example:\n\t\t\tch09/d-pin/src/main.rs\n\n```", "```rs\n\n\t\t\tHere, we pin `MaybeSelfRef` to the heap and initialize it. We print out the value of `a` and then mutate the data through the self-reference in `b`, and set its value to `2`. If we look at the output, we’ll see that everything looks as expected:\n\n```", "```rs\n\n\t\t\tThe pinned value can never move and as *users* of `MaybeSelfRef`, we didn’t have to write any `unsafe` code. Rust can guarantee that we never (in safe Rust) get a mutable reference to `MaybeSelfRef` since `Box` took ownership of it.\n\t\t\tHeap pinning being safe is not so surprising since, in contrast to the stack, a heap allocation will be stable throughout the program, regardless of where we create it.\n\t\t\tImportant\n\t\t\tThis is the preferred way to pin values in Rust. Stack pinning is for those cases where you don’t have a heap to work with or can’t accept the cost of that extra allocation.\n\t\t\tLet’s take a look at stack pinning while we’re at it.\n\t\t\tPinning to the stack\n\t\t\tPinning to the stack can be somewhat difficult. In [*Chapter 5*](B20892_05.xhtml#_idTextAnchor092), we saw how the stack worked and we know that it grows and shrinks as values are popped and pushed to the stack.\n\t\t\tSo, if we’re going to pin to the stack, we have to pin it somewhere “high” on the stack. This means that if we pin a value to the stack inside a function call, we can’t return from that function, and expect the value to still be pinned there. That would be impossible.\n\t\t\tPinning to the stack is hard since we pin by taking `&mut T`, and we have to guarantee that we won’t move `T` until it’s dropped. If we’re not careful, this is easy to get wrong. Rust can’t help us here, so it’s up to us to uphold that guarantee. This is why stack pinning is `unsafe`.\n\t\t\tLet’s look at the same example using stack pinning:\n\t\t\tch09/d-pin/src/main.rs\n\n```", "```rs\n\n\t\t\tThe noticeable difference here is that it’s `unsafe` to pin to the stack, so now, we need `unsafe` both as users of `MaybeSelfRef` and as implementors.\n\t\t\tIf we run the example with `cargo run`, the output will be the same as in our first example:\n\n```", "```rs\n\n\t\t\tThe reason stack pinning requires `unsafe` is that it’s rather easy to accidentally break the guarantees that `Pin` is supposed to provide. Let’s take a look at this example:\n\t\t\tch09/d-pin/src/main.rs\n\n```", "```rs\n\n\t\t\tIn this example, we create two instances of `MaybeSelfRef` called `x` and `y`. Then, we create a scope where we pin `x` and set the value of `x.a` to `2` by dereferencing the self-reference in `b`, as we did previously.\n\t\t\tNow, when we exit the scope, `x` isn’t pinned anymore, which means we can take a mutable reference to it without needing `unsafe`.\n\t\t\tSince this is safe Rust and we should be able to do what we want, we swap `x` and `y`.\n\t\t\tThe output prints out the pointer address of the `a` field of both structs and the value of the pointer stored in `b`.\n\t\t\tWhen we look at the output, we should see the problem immediately:\n\n```", "```rs\n\n\t\t\tAlthough the pointer values will differ from run to run, it’s pretty evident that `y` doesn’t hold a pointer to `self` anymore.\n\t\t\tRight now, it points somewhere in `x`. This is very bad and will cause the exact memory safety issues Rust is supposed to prevent.\n\t\t\tNote\n\t\t\tFor this reason, the standard library has a `pin!` macro that helps us with safe stack pinning. The macro uses `unsafe` under the hood but makes it impossible for us to reach the pinned value again.\n\t\t\tNow that we’ve seen all the pitfalls of stack pinning, my clear recommendation is to avoid it unless you need to use it. If you have to use it, then use the `pin!` macro so that you avoid the issues we’ve described here.\n\t\t\tTip\n\t\t\tIn this book’s GitHub repository, you’ll find a function called `stack_pinning_macro()` in the `ch``09``/d-pin/src/main.rs` file. This function shows the preceding example but using Rust’s `pin!` macro.\n\t\t\tPin projections and structural pinning\n\t\t\tBefore we leave the topic of pinning, we’ll quickly explain what pin projections and structural pinning are. Both sound complex, but they are very simple in practice. The following diagram shows how these terms are connected:\n\t\t\t![Figure 9.5 – Pin projection and structural pinning](img/B20892_09_51.jpg)\n\n\t\t\tFigure 9.5 – Pin projection and structural pinning\n\t\t\tStructural pinning means that if a struct is pinned, so is the field. We expose this through pin projections, as we’ll see in the following code example.\n\t\t\tIf we continue with our example and create a struct called `Foo` that holds both `MaybeSelfRef` (field `a`) and a `String` type (field `b`), we could write two projections that return a pinned version of `a` and a regular mutable reference to `b`:\n\t\t\tch09/d-pin/src/main.rs\n\n```", "```rs\n\n\t\t\tNote that these methods will only be callable when `Foo` is pinned. You won’t be able to call either of these methods on a regular instance of `Foo`.\n\t\t\tPin projections do have a few subtleties that you should be aware of, but they’re explained in quite some detail in the official documentation (https://doc.rust-lang.org/stable/std/pin/index.html), so I’ll refer you there for more information about the precautions you must take when writing projections.\n\t\t\tNote\n\t\t\tSince pin projections can be a bit error-prone to create yourself, there is a popular create for making pin projections called **pin_project** (https://docs.rs/pin-project/latest/pin_project/). If you ever end up having to make pin projections, it’s worth checking out.\n\t\t\tWith that, we’ve pretty much covered all the advanced topics in async Rust. However, before we go on to our last chapter, let’s see how pinning will prevent us from making the big mistake we made in the last iteration of our coroutine example.\n\t\t\tImproving our example 4 – pinning to the rescue\n\t\t\tFortunately, the changes we need to make are small, but before we continue and make the changes, let’s create a new folder and copy everything we had in our previous example over to that folder:\n\n\t\t\t\t*   Copy the entire `c-coroutines-problem` folder and name the new copy `e-coroutines-pin`\n\t\t\t\t*   Open `Cargo.toml` and rename the name of the package `e-coroutines-pin`\n\n\t\t\tTip\n\t\t\tYou’ll find the example code we’ll go through here in this book’s GitHub repository under the `ch``09``/e-coroutines-pin` folder.\n\t\t\tNow that we have a new folder set up, let’s start making the necessary changes. The logical place to start is our `Future` definition in `future.rs`.\n\t\t\tfuture.rs\n\t\t\tThe first thing we’ll do is pull in `Pin` from the standard library at the very top:\n\t\t\tch09/e-coroutines-pin/src/future.rs\n\n```", "```rs\n\n\t\t\tThe only other change we need to make is in the definition of `poll` in our `Future` trait:\n\n```", "```rs\n\n\t\t\tThat’s pretty much it.\n\t\t\tHowever, the implications of this change are noticeable pretty much everywhere poll is called, so we need to fix that as well.\n\t\t\tLet’s start with `http.rs`.\n\t\t\thttp.rs\n\t\t\tThe first thing we need to do is pull in `Pin` from the standard library. The start of the file should look like this:\n\t\t\tch09/e-coroutines-pin/src/http.rs\n\n```", "```rs\n\n\t\t\tThe only other place we need to make some changes is in the `Future` implementation for `HttpGetFuture`, so let’s locate that. We’ll start by changing the arguments in `poll`:\n\t\t\tch09/e-coroutines-pin/src/http.rs\n\n```", "```rs\nlet id = self.id;\n        if self.stream.is_none() {\n            println!(\"FIRST POLL - START OPERATION\");\n            self.write_request();\n            let stream = (&mut self).stream.as_mut().unwrap();\n            runtime::reactor().register(stream, Interest::READABLE, id);\n            runtime::reactor().set_waker(waker, self.id);\n        }\n```", "```rs\nlet s = String::from_utf8_lossy(&self.buffer).to_string();\nruntime::reactor().deregister(self.stream.as_mut().unwrap(), id);\nbreak PollState::Ready(s);\n```", "```rs\nmod future;\nmod http;\nmod runtime;\nuse future::{Future, PollState};\nuse runtime::Waker;\nuse std::{fmt::Write, PhantomPinned marker and Pin.\n\t\t\tThe next thing we need to change is in our `State0` enum. The futures we hold between states are now pinned:\n\t\t\tch09/e-coroutines-pin/src/main.rs\n\n```", "```rs\n\n\t\t\tNext up is an important change. We need to make our coroutines `!Unpin` so that they can’t be moved once they have been pinned. We can do this by adding a marker trait to our `Coroutine0` struct:\n\t\t\tch09/e-coroutines-pin/src/main.rs\n\n```", "```rs\n\n\t\t\tWe also need to add the `PhantomPinned` marker to our new function:\n\t\t\tch09/e-coroutines-pin/src/main.rs\n\n```", "```rs\n\n\t\t\tThe last thing we need to change is the `poll` method. Let’s start with the function signature:\n\t\t\tch09/e-coroutines-pin/src/main.rs\n\n```", "```rs\nlet this = unsafe { self.get_unchecked_mut() };\n        loop {\n            match this.state {\n                State0::Start => {\n                    // initialize stack (hoist declarations - no stack yet)\n                    this.stack.buffer = Some(String::from(\"\\nBUFFER:\\n----\\n\"));\n                    this.stack.writer = Some(this.stack.buffer.as_mut().unwrap());\n                    // ---- Code you actually wrote ----\n                    println!(\"Program starting\");\n...\n```", "```rs\nlet fut1 = Box::pin(http::Http::get(\"/600/HelloAsyncAwait\"));\nlet fut2 = Box::main.rs where we need to make changes is in the locations where we poll our child futures since we now have to go through the Pin type to get a mutable reference:\n\t\t\tch09/e-coroutines-pin/src/main.rs\n\n```", "```rs\n...\n    thread::{self, Thread}, pin::Pin,\n};\n```", "```rs\ntype Task = Pin<Box<dyn Future<Output = String>>>;\n```", "```rs\ne.tasks.borrow_mut().insert(id, Box::pin(future));\n```", "```rs\nerror[E0599]: no method named `poll` found for struct `Pin<Box<dyn future::Future<Output = String>>>` in the current scope\n  --> src\\runtime\\executor.rs:89:30\n```", "```rs\nmatch future.cargo run, you should get the expected output back and not have to worry about the coroutine/wait generated futures being moved again (the output has been abbreviated slightly):\n\n```", "```rs\n\n\t\t\tYou now have self-referential coroutines that can safely store both data and references across wait points. Congratulations!\n\t\t\tEven though making these changes took up quite a few pages, the changes themselves were part pretty trivial for the most part. Most of the changes were due to `Pin` having a different API than what we had when using references before.\n\t\t\tThe good thing is that this sets us up nicely for migrating our whole runtime over to futures created by async/await instead of our own futures created by coroutine/wait with very few changes.\n\t\t\tSummary\n\t\t\tWhat a ride, huh? If you’ve got to the end of this chapter, you’ve done a fantastic job, and I have good news for you: you pretty much know everything about how Rust’s futures work and what makes them special already. All the complicated topics are covered.\n\t\t\tIn the next, and last, chapter, we’ll switch over from our hand-made coroutines to proper async/await. This will seem like a breeze compared to what you’ve gone through so far.\n\t\t\tBefore we continue, let’s stop for a moment and take a look at what we’ve learned in this chapter.\n\t\t\tFirst, we expanded our coroutine implementation so that we could store variables across wait points. This is pretty important if our coroutine/wait syntax is going to rival regular synchronous code in readability and ergonomics.\n\t\t\tAfter that, we learned how we could store and restore variables that held references, which is just as important as being able to store data.\n\t\t\tNext, we saw firsthand something that we’ll *never* see in Rust unless we implement an asynchronous system, as we did in this chapter (which is quite the task just to prove a single point). We saw how moving coroutines that hold self-references caused serious memory safety issues, and exactly why we need something to prevent them.\n\t\t\tThat brought us to pinning and self-referential structs, and if you didn’t know about these things already, you do now. In addition to that, you should at least know what a pin projection is and what we mean by structural pinning.\n\t\t\tThen, we looked at the differences between pinning a value to the stack and pinning a value to the heap. You even saw how easy it was to break the `Pin` guarantee when pinning something to the stack and why you should be very careful when doing just that.\n\t\t\tYou also know about some tools that are widely used to tackle both pin projections and stack pinning and make both much safer and easier to use.\n\t\t\tNext, we got firsthand experience with how we could use pinning to prevent the issues we had with our coroutine implementation.\n\t\t\tIf we take a look at what we’ve built so far, that’s pretty impressive as well. We have the following:\n\n\t\t\t\t*   A coroutine implementation we’ve created ourselves\n\t\t\t\t*   Coroutine/wait syntax and a preprocessor that helps us with the boilerplate for our coroutines\n\t\t\t\t*   Coroutines that can safely store both data and references across wait points\n\t\t\t\t*   An efficient runtime that stores, schedules, and polls the tasks to completion\n\t\t\t\t*   The ability to spawn new tasks onto the runtime so that one task can spawn hundreds of new tasks that will run concurrently\n\t\t\t\t*   A reactor that uses `epoll`/`kqueue`/IOCP under the hood to efficiently wait for and respond to new events reported by the operating system\n\n\t\t\tI think this is pretty cool.\n\t\t\tWe’re not quite done with this book yet. In the next chapter, you’ll see how we can have our runtime run futures created by async/await instead of our own coroutine implementation with just a few changes. This enables us to leverage all the advantages of async Rust. We’ll also take some time to discuss the state of async Rust today, the different runtimes you’ll encounter, and what we might expect in the future.\n\t\t\tAll the heavy lifting is done now. Well done!\n\n```", "```rs\n\n```", "```rs\n\n```", "```rs\n\n```"]