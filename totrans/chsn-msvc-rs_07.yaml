- en: Reliable Integration with Databases
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Persistent microservices have to store and load data. If you want to keep this
    data organized and reliable, you should use a database. Rust has third-party crates
    that support popular databases, and in this chapter, you''ll learn about how to
    use different databases with Rust, including the following:'
  prefs: []
  type: TYPE_NORMAL
- en: PostgreSQL
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: MySQL
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Redis
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: MongoDB
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: DynamoDB
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will create utilities that will allow you to insert or remove data to and
    from the database, and to query the data held in the database.
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you'll need database instances to run our examples. The most
    effective way to run and work with a database for testing purposes is to use Docker.
    You can install databases locally, but seeing as we'll also need Docker for the
    remaining chapters, it's best to install and use it from this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will use the following official images from Docker Hub:'
  prefs: []
  type: TYPE_NORMAL
- en: '`postgres:11`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`mysql:8`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`redis:5`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`mongo:4`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`amazon/dynamodb-local:latest`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'You can get to know more about these images on the Docker Hub repository pages:
    [https://hub.docker.com/](https://hub.docker.com/).'
  prefs: []
  type: TYPE_NORMAL
- en: 'We will also use the `DynamoDB` database, which is provided as part of Amazon
    Web Services: [https://aws.amazon.com/dynamodb/](https://aws.amazon.com/dynamodb/).'
  prefs: []
  type: TYPE_NORMAL
- en: If you want to interact with databases to check whether our examples work successfully,
    you'll also have to install the corresponding clients for each database.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can find all of the examples for this chapter in the `Chapter07` folder
    on GitHub: [https://github.com/PacktPublishing/Hands-On-Microservices-with-Rust-2018/](https://github.com/PacktPublishing/Hands-On-Microservices-with-Rust-2018/).'
  prefs: []
  type: TYPE_NORMAL
- en: PostgreSQL
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: PostgreSQL is a reliable and mature database. In this section, we will explore
    how to start an instance of this database in a container, and how to connect to
    it from Rust using third-party crates. We will look at simple interactions with
    this database, and at the use of connection pools to get extra performance. We
    will start an instance of the database with Docker and create a tool to add records
    to a table and to query the list of added records before printing them to a console.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up a test database
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To create our database, you can use Docker, which automatically pulls all the
    necessary layers of the images containing the preinstalled PostgreSQL database.
    It's important to note that PostgreSQL has official images on Docker Hub, and
    you should opt to use these instead of unofficial ones, because the latter have
    a greater risk of malicious updates.
  prefs: []
  type: TYPE_NORMAL
- en: 'We need to start a container with a PostgreSQL database instance. You can do
    this using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: What does this command do? It starts a container from the `postgres` image (the
    latest version) and uses port `5432` on the localhost to forward it to the inner
    port, `5432`, of the container (that is, the port exposed by the image). We also
    set a name with the `--name` argument. We give the container the name `test-pg`.
    You can use this name later to stop the container. The `--rm` flag will remove
    the anonymous volumes associated with the container when it's stopped. So that
    we can interact with the database from a Terminal, we've added `-it` flags.
  prefs: []
  type: TYPE_NORMAL
- en: 'The database instance will start and print something like the following to
    the Terminal:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'The database is now ready for use. You can check it with the `psql` client,
    if you have it locally. The default parameters of the image are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'If you don''t need the database anymore, you can use the following command
    to shut it down:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: But don't shut it down yet—let's connect to it with Rust.
  prefs: []
  type: TYPE_NORMAL
- en: Simple interaction with a database
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The easiest way to interact with a database is to create a single connection directly to
    the database. Simple interaction is a straightforward database connection that
    doesn't use connection pools or other abstractions to maximize performance.
  prefs: []
  type: TYPE_NORMAL
- en: 'To connect to a PostgreSQL database, we can use two crates: `postgres` or `r2d2_postgres`.
    The first is a generic connection driver. The second, `r2d2_postgres`, is a crate
    for the `r2d2` connection pools crate. We will start by using the `postgres` crate
    directly, without a pool from the `r2d2` crate, and work on a simple utility to
    create a table, before adding commands to manipulate the data in that table.'
  prefs: []
  type: TYPE_NORMAL
- en: Adding dependencies
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s create a new project with all the necessary dependencies. We will create
    a binary utility for managing users in a database. Create a new binary crate:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, add the dependencies:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'But wait! Cargo doesn''t contain an `add` command. I''ve installed `cargo-edit`
    tool for managing dependencies. You can do this with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: The preceding command installs the `cargo-edit` tool. If you don't install it,
    your local `cargo` won't have an `add` command. Install the `cargo-edit` tool
    and add the `postgres` dependency. You can also add dependencies manually by editing
    the `Cargo.toml` file, but as we are going to create more complex projects, the
    `cargo-edit` tool can be used to save us time.
  prefs: []
  type: TYPE_NORMAL
- en: 'The Cargo tool can be found here: [https://github.com/killercup/cargo-edit](https://github.com/killercup/cargo-edit).
    This tool contains three useful commands to manage dependencies: `add` to add
    a dependency, `rm` to remove an unnecessary dependency, and `upgrade` to upgrade
    versions of dependencies to their latest versions. Furthermore, with the awesome
    Edition 2018 of Rust, you don''t need to use an `extern crate ...` declaration.
    You can simply add or remove any crates and all of them will be available immediately
    in every module. But what about if you add a crate that you don''t need, and end
    up forgetting about it? Since the Rust compiler allows unused crates, you can
    add the following crate-wide attribute, `#![deny(unused_extern_crates)]`, to your
    crate. This is necessary in case you accidentally add a crate that you won''t
    use.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Also, add the `clap` crate. We need it for parsing arguments for our tool.
    Add the usages of all the necessary types, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: All necessary dependencies have been installed, and our types have been imported,
    so we can create the first connection to a database.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a connection
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Before you can execute any query on a database, you have to establish a connection
    with the database you started in a container. Create a new `Connection` instance
    with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'The created `Connection` instance has `execute` and `query` methods. The first
    method is used to execute SQL statements; the second is used to query data with
    SQL. Since we want to manage users, let''s add three functions that we''ll use
    with our `Connection` instance: `create_table`, `create_user`, and `list_users`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The first function, `create_table`, creates a table for users:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: This function uses a `Connection` instance to execute a statement to create
    a `users` table. Since we don't need a result, we can simply `drop` it with the `map` command
    on `Result`. As you can see, we use an immutable reference to a connection, because
    `Connection` contains a reference to a shared struct, so we don't need to change
    this value to interact with a database.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are a lot of discussions about which approach to use: immutable references
    with runtime locks and Mutexes, or mutable references even if we need runtime
    locks. Some crates use the first approach, while others use the second. In my
    opinion, it''s good to fit your approach to the environment in which it will be
    called. In some cases, it''s more convenient to avoid mutable references, but
    in most cases, it''s safer to require mutability for an interface object, such
    as `Connection` from the `postgres` crate. The developers of the crate also have
    a plan to move to mutable references. You can read more about it here: [https://github.com/sfackler/rust-postgres/issues/346](https://github.com/sfackler/rust-postgres/issues/346).'
  prefs: []
  type: TYPE_NORMAL
- en: 'The next function is `create_user`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: This function also uses the `execute` method of `Connection` to insert a value,
    but it also adds parameters to a call to fill the provided statement with values
    (the `create_table` function leaves these parameters empty). The result of the
    execution is dropped and we keep `Error` only. You may need the returning value
    if the request returns an identifier of an inserted record.
  prefs: []
  type: TYPE_NORMAL
- en: The last function, `list_users`, queries a database to get a list of users from
    the `users` table.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: This function, `list_users`, uses the `query` method of `Connection`. We use
    a simple `SELECT` SQL statement here, convert it into an iterator of rows, and
    extract pairs of names and email addresses of the users.
  prefs: []
  type: TYPE_NORMAL
- en: Wrapping with a tool
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We've prepared all queries, so now we can join them in a binary tool with a
    command-line interface. In the following code, we will parse some parameters with
    the `clap` crate, and run functions to manage users with an established `Connection`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our tool will support three commands. Declare their names as constants:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we can create the `main` function using the `clap` crate to parse our
    command-line arguments:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: The `main` function returns `postgres::Error` in case of failure, because all
    operations we will do relate to our Postgres database connection. We create a `clap::App` 
    instance here, and add a `--database` argument to let users change the address
    of the connection. We also added three subcommands, `create`, `add`, and `list`,
    along with extra arguments to the `add` command that requires the name and email
    address of a user so that we can insert this into a database.
  prefs: []
  type: TYPE_NORMAL
- en: 'To create a `Connection` instance, we use a database argument to extract a
    connection URL provided by a user with the `--db` command-line argument, and if
    it isn''t provided, we will use the default URL value, `postgres://postgres@localhost:5432`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: We used a `Connection::connect` method with an address, and set the `TlsMode`
    parameter to `TlsMode::None`, because we don't use TLS in our demo. We created
    a `Connection` instance named `conn` to call our functions to interact with our
    database.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, we can add branches for subcommands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: The first branch matches the `crate` subcommand  and creates a table by calling
    the `create_table` function.
  prefs: []
  type: TYPE_NORMAL
- en: The second branch is for the `add` subcommand. It extracts pairs of required
    arguments for the name and email of a user, and calls the `create_user` function
    to create a user record with the provided values. We use `unwrap` to extract it,
    because both arguments are required.
  prefs: []
  type: TYPE_NORMAL
- en: The penultimate branch handles the `list` command and takes a list of users
    with the `list_users` function call. After the value has been taken, it is used
    in a `for` loop to print all the records of the users to the console.
  prefs: []
  type: TYPE_NORMAL
- en: The last branch is unreachable because we set `AppSettings::SubcommandRequired`
    to `clap::App`, but we leave it in for consistency. It is especially useful if
    you want to provide a default behavior when a subcommand value hasn't been set.
  prefs: []
  type: TYPE_NORMAL
- en: Compiling and running
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'At the beginning of this chapter, we started an instance of the PostgreSQL
    database that we will use to check our tool. Compile the example we created with
    Cargo and print the available subcommands with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Cargo looks like a cute tool for managing the database of an application. Let''s
    create a table with it, like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'This command creates a `users` table. If you try to run it again, you will
    get an error:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'If you check your tables with the `psql` client, you will see the table that
    resides in our database:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'To add a new user, call the `add` subcommand with the following parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'We added three users, which you can see in the list if you enter the `list`
    subcommand:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: In the following example, we will use a pool of database connections to add
    multiple users in parallel.
  prefs: []
  type: TYPE_NORMAL
- en: Connection pools
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The tool we created uses a single connection to a database. It works fine for
    a small amount of queries. If you want to run multiple queries in parallel, you'll
    have to use connection pools. In this section, we improve the tool with the `import`
    command, which imports bulk user data from a CSV file. We will use a `Pool` type
    from the `r2d2` crate, add a command that will read users from a file, and execute
    statements to add users to a table in parallel.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a pool
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To create a connection pool, we will use the `r2d2` crate that can hold multiple
    connections and provide one for us from the pool. This crate is generic, so you''ll
    need a specific implementation for every database to connect to it. The `r2d2`
    crate can connect to the following databases using adapter crates:'
  prefs: []
  type: TYPE_NORMAL
- en: PostgreSQL
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Redis
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: MySQL
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: SQLite
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Neo4j
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Diesel ORM
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: CouchDB
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: MongoDB
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ODBC
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For our example, we need the `r2d2-postgres` adapter crate to connect to the
    PostgreSQL database. Add it to our dependencies with the `r2d2` crate:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: We also keep the `postgres` dependency, and add `failure` for error-handling
    and `rayon` to execute SQL statements in parallel. We also added a set of `serde`
    crates to deserialize `User` records from the CSV file, along with the `csv` crate
    to read that file.
  prefs: []
  type: TYPE_NORMAL
- en: 'You will be much more comfortable using Rust structs that represent data records
    in a database. Let''s add a `User` type that represents a user record in a database
    with the following struct:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Since we have our special `User` type, we can improve the `create_user` and
    `list_users` functions to use this new type:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'It hasn''t changed dramatically: we still use the same `Connection` type, but
    we use the fields from the `User` struct to fill our `create` statements and extract
    values from our `get list` query. The `create_table` function has not changed.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Add a constant for the `import` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, add it as a `SubCommand` to `App`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Almost all branches have changed and we should explore those changes. The `add`
    command creates a `User` instance to call the `create_user` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'The `list` subcommand returns a list of `User` struct instances. We have to
    take this change into account:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: The `import` command is more complex, so let's discuss this in more detail in
    the following section.
  prefs: []
  type: TYPE_NORMAL
- en: Parallel imports with the rayon crate
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Since we have a pool of connections, we can run multiple requests to a database
    in parallel. We will read users from a standard input stream in CSV format. Let''s
    add a branch to the `match` expression we declared before, for the `import` subcommand,
    and open `stdin` with `csv::Reader`. After that, we will use the `deserialize`
    method of the reader, which returns an iterator of deserialized instances to our
    desired type. In our case, we deserialize the CSV data to a list of `User` structs
    and push them to a vector:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: Rayon
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To run requests in parallel, we''ll use the `rayon` crate, which provides a
    parallel iterator with the `par_iter` method. The parallel iterator divides a
    list into separate tasks that run across a pool of threads:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: The parallel iterator returns items much like a traditional iterator. We can
    get a connection from the pool using the `Pool::get` method, and call the `create_user`
    function with a reference to a connection. We also ignore results here, and if
    any request fails, it will be skipped silently, as in the demonstration, we cannot
    take care of values that have not been inserted. Since we use multiple connections,
    we can't use transactions to roll back changes if any statement does fail.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `rayon` crate looks really impressive and simple to use. You may ask: *could
    you use this crate in microservices?* The answer is: *yes!* But remember that
    to collect data, you have to call the `for_each` method, which blocks the current
    thread until all tasks are completed. If you call it in reactor''s context (which
    we discussed in [Chapter 5](ed541ef5-4701-4e70-aabf-14882b4cecb3.xhtml), *Understanding
    Asynchronous Operations with  Futures Crate*) in asynchronous `Future`, it will
    block the reactor for a while.'
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will rewrite this example for a MySQL database.
  prefs: []
  type: TYPE_NORMAL
- en: MySQL
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'MySQL is one of the most popular databases, so Rust naturally has crates to
    interact with it. There are two good crates that I recommend that you use: the `mysql`
    crate and its asynchronous version, the `mysql_async` crate.'
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we'll rewrite the previous example of managing users with support
    for a MySQL database. We'll also bootstrap a local instance of the database in
    a container, and create a command-line utility that connects to a database instance,
    sends queries to create table, and allows us to add and remove users. We will
    use the latest example for PostgreSQL, which uses the `r2d2` pool.
  prefs: []
  type: TYPE_NORMAL
- en: Database for tests
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To bootstrap the database, we also will use a Docker image. You can install
    MySQL locally, but a container is a more flexible approach that doesn't clog the
    system, and you can easily start an empty database for testing purposes in seconds.
  prefs: []
  type: TYPE_NORMAL
- en: 'There is an official image, `mysql`, of the MySQL database that you can find
    here: [https://hub.docker.com/_/mysql](https://hub.docker.com/_/mysql). You can
    load and run the container using these images with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: There are two necessary parameters that you can set with environment variables.
    First, the `MYSQL_ROOT_PASSWORD` environment variable sets a password for the
    root user. Second, the `MYSQL_DATABASE` environment variable sets the name of
    a default database that will be created on the first start of a container. We
    named our container `test-mysql` and forwarded the local port `3306` to port `3306`
    inside our container.
  prefs: []
  type: TYPE_NORMAL
- en: 'To make sure that our container has started, you can use the `mysql` client,
    if it''s installed locally:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: The preceding command connects to `127.0.0.1` (to avoid using sockets) on port
    `3306`, with user as `root`. The `-p` argument asks for a password for the connection.
    We set a password for our testing container because the database images require
    it.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our database is ready to use. You can also stop it with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: Connecting with the r2d2 adapter
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous section, we used a connecting pool from the `r2d2` crate with
    a PostgreSQL database. There is also a connection manager for MySQL in the `r2d2-mysql`
    crate that allows you to use a MySQL connection with the `r2d2` crate. The `r2d2-mysql`
    crate is based on the `mysql` crate. Using the pool is also simple, just as we
    did for the PostgreSQL database, but here, we use the `MysqlConnectionManager`
    as a type parameter for `r2d2::Pool`. Let's modify all functions with queries
    to use a pool from our MySQL database.
  prefs: []
  type: TYPE_NORMAL
- en: Adding dependencies
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'First, we have to add dependencies to establish a connection to MySQL. We use
    all the same dependencies as in the previous example, but have replaced `postgres`
    with the `mysql` crate, and `r2d2_postgres` with the `r2d2_mysql` crate:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: We still need the `csv`, `rayon`, `r2d2`, and `serde` family crates.
  prefs: []
  type: TYPE_NORMAL
- en: 'You also have to declare other types to use them in the code, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: Database interaction functions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now, we can replace our `Connection` instance from the `postgres` crate with `Conn` from
    the `mysql` crate to provide our interaction functions. The first function, `create_table`,
    uses a mutable reference to a `Conn` instance:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: Also, we used the `query` method of the `Conn` connection object to send a query.
    This method doesn't expect parameters. We still ignore the successful result of
    a query and `drop` it with `map`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The next function, `create_user`, has transformed into the following form:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: We use the `prep_exec` method of `Conn`, which expects a tuple of parameters
    that we have extracted from `User` struct fields. As you can see, we used the `?`
    char to specify where to insert the value.
  prefs: []
  type: TYPE_NORMAL
- en: 'The last function, `list_users`, collects users from a query. It''s more complex
    than the version for PostgreSQL. We used the `query` method which returns a `QueryResult`
    type that implements the `Iterator` trait. We use this property to convert the
    result in to an iterator, and try to fold values to a vector in the `try_fold`
    method of the `Iterator` implementation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'For the `try_fold` method call, we provide a closure that expects two arguments:
    the first is a vector that we pass with the `try_fold` call, while the second
    is a `Row` instance. We use `try_fold` to return `Error` if any row conversion
    to user fails.'
  prefs: []
  type: TYPE_NORMAL
- en: We use the `get_opt` method of the `Row` object to get a value of a corresponding
    type, and use the `?` operator to extract it from a result, or return `Error`
    with `try_fold`. In every iteration, we return a vector with a new, appended value.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a connection pool
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We will reuse the arguments parser from the previous example, but will rewrite
    the code that establish a connection, because we're using MySQL instead of PostgreSQL
    now. First, we replaced the database link with the `mysql` scheme. We will use
    the same parameters for the connection as those that we used to bootstrap the
    MySQL server instance.
  prefs: []
  type: TYPE_NORMAL
- en: 'We convert the address string to the `Opts` - options of a connections, the
    type of mysql crate that''s used to set parameters for connections. But `MysqlConnectionManager`
    expects us to provide an `OptsBuilder` object. Look at the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: Now, we can create `MysqlConnectionManager` using `builder`, and we can create
    `r2d2::Pool` with a `manager` instance. We also get a mutable `conn` reference to
    a connection to provide it for subcommands.
  prefs: []
  type: TYPE_NORMAL
- en: 'The good news is that it''s enough to start. We don''t need to change anything
    in our branches, except the type of reference. Now, we have to pass a mutable
    reference to the connection:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'Try to start and check how the tool works. We will provide it a CSV file with
    content in the following format:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'If you want to check whether the database has really changed, try importing
    user data from our CSV file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'You can use the `mysql` client to print the `users` table:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: It works! As you can see, users were added in an unpredictable order, because
    we used multiple connections and real concurrency. Now you have knowledge of how
    to use SQL databases. It's time to look at interacting with NoSQL databases through
    the `r2d2` crate.
  prefs: []
  type: TYPE_NORMAL
- en: Redis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When writing microservices, you may sometimes need a data store that can keep
    values by keys; for example, if you want to store session, you can store a protected
    identifier of the session and keep additional information about users in a persistent
    cache. It's not a problem if a session's data is lost; on the contrary, it is
    a best practice to clean sessions periodically in case a user's session identifier
    is stolen.
  prefs: []
  type: TYPE_NORMAL
- en: Redis is a popular in-memory data structure store for this use case. It can
    be used as a database, as a message broker, or as a cache. In the following section,
    we will run a Redis instance with Docker and create a command-line tool that helps
    manage a users' sessions in Redis.
  prefs: []
  type: TYPE_NORMAL
- en: Bootstrap database for tests
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Redis has an official image, `redis`, on Docker Hub. To create and run a container,
    use the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: This command runs a container from the `redis` image with the name `test-redis`,
    and forwards local port `6379` to the internal port `6379` of the container.
  prefs: []
  type: TYPE_NORMAL
- en: 'An interesting fact about Redis is that it uses a very plain and simple interaction
    protocol. You can even use `telnet` to interact with Redis:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: The native client is more comfortable to use, but it expects the same commands
    as the raw protocol.
  prefs: []
  type: TYPE_NORMAL
- en: 'To shut down a container running Redis, use this command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: Let's create a tool to manage sessions in Redis.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a connection pool
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have started a Redis instance in a Docker container, so now, we can start
    creating a command-line tool to allow us to connect to that database instance
    and put some information into it. This utility will be different from the ones
    we created for PostgreSQL and MySQL, because Redis doesn't use the SQL language.
    We will use specific API methods that are available in Redis.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we will create a new binary crate and add functions that set
    or get data from Redis using `r2d2::Pool`. After this, we will call them in response
    to subcommands that a user specified as command-line arguments for the command.
  prefs: []
  type: TYPE_NORMAL
- en: Dependencies
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Create a new binary crate and add all of the necessary dependencies to the `Cargo.toml`
    file of that crate:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: We added the dependencies that we used in the previous examples of this chapter—`clap`,
    `failure`, and `r2d2`. Also, we need the `redis` and `r2d2_redis` crates, which
    contain a connection manager for Redis so that we can use it with `Pool` from the `r2d2`
    crate.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, let''s import the types we need to create a tool:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: Note the usage of some types. We imported `Connection` as a main connection
    type, which we will use to connect to a Redis instance. We also imported `RedisConnectionManager`
    from the `r2d2_redis` crate. This type allows `Pool` to create new connections.
    The last thing you should note is the `Command` trait. This trait contains methods
    that reflect the Redis client API. The names of methods are the same (but in lowercase),
    as you can see in the Redis protocol. We tested it manually in a previous section.
    The `Command` trait, implemented by a `Connection` struct, allows you to call
    methods of the Redis API.
  prefs: []
  type: TYPE_NORMAL
- en: Redis supports a lot of commands. You can find a full list at [https://redis.io/commands](https://redis.io/commands).
    The `redis` crate provides most of them as methods of the `Command` trait.
  prefs: []
  type: TYPE_NORMAL
- en: Adding commands and interaction functions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The tool that we are creating for Redis will support three commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '`add` - adds a new session record'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`remove` - removes a session record by key (that is, by username)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`list` - prints all session records'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We need constants for the name of every subcommand to prevent mistakes in strings
    in the code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: This list also contains the `SESSION` constant as the name of the `HashMap`
    in Redis. Now, we can declare functions to manipulate session data.
  prefs: []
  type: TYPE_NORMAL
- en: Data manipulation functions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Our example needs three functions. The first function, `add_session`, adds
    an association between the token and user ID:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: This function only calls the `hset` method of a `Connection` and sets the `uid`
    value by the `token` key in the `SESSIONS` map. It returns `RedisError` if something
    is wrong with a set operation.
  prefs: []
  type: TYPE_NORMAL
- en: 'The next function, `remove_session`, is also pretty simple and calls the `hdel`
    method of `Connection`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: This function deletes a record with the `token` key from the `SESSIONS` map.
  prefs: []
  type: TYPE_NORMAL
- en: 'The last function, `list_sessions`, returns all token-uid pairs as a `HashMap`
    instance from the `SESSION` map. It uses the `hgetall` method of `Connection`,
    which calls the `HGETALL` method in Redis:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, all functions map to raw Redis commands, which looks pretty
    simple. But all functions do a good job in the background too, converting values
    to their corresponding Rust types.
  prefs: []
  type: TYPE_NORMAL
- en: Now, we can create an arguments parser for the session tool.
  prefs: []
  type: TYPE_NORMAL
- en: Parsing arguments
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Since our command supports three subcommands, we have to add them to a `clap::App`
    instance:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: As in previous examples, this can also use the `--database` argument with a
    link to a Redis connection. It supports two subcommands. The `add` subcommand
    expects a session `TOKEN` and the `UID` of the user. The `remove` command expects
    a session `TOKEN` only to remove it from a map. The `list` command doesn't expect
    any parameters and prints a list of sessions.
  prefs: []
  type: TYPE_NORMAL
- en: Imagine the structure of data in this example as a cache for sessions that holds
    associations between `token` and `uid`. After authorization, we can send the token
    as a secure cookie and extract the user's `uid` for the provided token for every
    microservice to achieve loose coupling between microservices. We will explore
    this concept in detail later.
  prefs: []
  type: TYPE_NORMAL
- en: Now, we are ready to connect to Redis with `r2d2::Pool`.
  prefs: []
  type: TYPE_NORMAL
- en: Connecting to Redis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The `r2d2` connection to Redis looks similar to other databases:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: We get the address from the `--database` argument, but if it isn't set, we will
    use the default value, `redis://127.0.0.1/`. After that, we will create a new
    `RedisConnectionManager` instance and pass it to the `Pool::new` method.
  prefs: []
  type: TYPE_NORMAL
- en: Executing subcommands
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We use the structure of branches to match subcommands from our previous examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: For the `add` subcommand, we extract the `TOKEN` and `UID` values from arguments
    and pass them to the `add_session` function with a reference to a `Connector`.
    For the `remove` subcommand, we extract only the `TOKEN` value and call the `remove_session`
    function with its corresponding parameters. For the `list` subcommand, we call
    the `list_session` function as is, because we don't need any extra parameters
    to get all values from a map. This returns a vector of pairs. The first item of
    the pair contains `token`, and the second contains `uid`. We print the values
    using a fixed width specifier of `{:20}`.
  prefs: []
  type: TYPE_NORMAL
- en: Testing our Redis example
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s compile and test the tool. We will add three sessions of users:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'To print the list, run the `list` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'With this, you will see all the sessions you have created:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: 'We''ve learned how to use Redis. It''s useful to store messages for caching
    something. Next in line is the last NoSQL database we''ll look at: MongoDB.'
  prefs: []
  type: TYPE_NORMAL
- en: MongoDB
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'MongoDB is a popular NoSQL database that has great features and good performance.
    It''s really good for data that changes structure quickly, such as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Operational intelligence (logs and reports)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Product data management (product catalog, hierarchies, and categories)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Content management systems (posts, comments, and other records)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will create an example that stores the activities of a user.
  prefs: []
  type: TYPE_NORMAL
- en: Bootstrapping a database for testing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We will use the official Docker image to bootstrap a MongoDB instance. You
    can do it simply with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: This command runs a container with the name `test-mongo` from the `mongo` image,
    and forwards the local port `27017` to the same internal port of the container.
    The data that container produces will be removed after container shutdown.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you have a `mongo` client, you can use it to connect to an instance of database
    inside the container:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: 'When you need to shut down the container, use the `stop` subcommand of `docker` and
    specify the `name` of the container:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: It can also be terminated with *Ctrl *+ *C* if you attached the container to
    a Terminal with `-it` arguments, as I did previously.
  prefs: []
  type: TYPE_NORMAL
- en: Now, we can look how to connect to a database using `mongo` and the `r2d2-mongo`
    crate.
  prefs: []
  type: TYPE_NORMAL
- en: Connecting to a database using the r2d2 pool
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'By tradition, we will use a `Pool` from the `r2d2` crate, but in this example
    (as in the Redis example), we don''t use multiple connections at once. Add all
    of the necessary dependencies to a new binary crate:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: The list is not small. Besides the crates you already familiar with, we've added the
    `bson`, `chrono`, and `url` crates. The first crate we need to work with data
    in the database; the second, to use the `Utc` type; and the last to split URL
    strings into pieces.
  prefs: []
  type: TYPE_NORMAL
- en: 'Import all the necessary types, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: 'This user''s logging tool will support two commands: `add` to add a record,
    and `list` to print a list of all records. Add the following necessary constants:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: 'To set and get structured data, we need to declare an `Activity` struct that
    will be used to create a BSON document and to restore it from BSON data, because
    MongoDB uses this format for data interaction. The `Activity` struct has three
    fields, `user_id`, `activity`, and `datetime`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: Interaction functions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Since we have a declared structure, we can add functions to work with databases.
    The first function we will add is `add_activity` which adds an activity record
    to a database:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: This function only converts the `Activity` struct into a BSON document, and
    does this by extracting fields from a struct and construct BSON document with
    the same fields. We can derive the `Serialize` trait for the structure and use
    automatic serialization, but I used the `doc!` macro for demonstration purposes
    to show you that you can add a free-form document that can be constructed on the
    fly.
  prefs: []
  type: TYPE_NORMAL
- en: To add `Activity`, we get a collection called `activities` from a `Database`
    instance by reference to the `collection()` method, and call the `insert_one`
    method of `Collection` to add a record.
  prefs: []
  type: TYPE_NORMAL
- en: The next method is `list_activities`. This method uses a `Database` instance
    to find all values in the *activities* collection. We use the `find()` method
    of `Collection` to get data, but make sure to set filter (the first argument)
    to `None`, and options (the second argument) to `None`, to get all of the values
    from a collection.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can tweak these parameters for filtering, or to limit the quantity of records
    you retrieve:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: To convert every record returned by the `find` query as a BSON document, we
    can use the `bson::from_bson` method, since we have derived the `Deserialize`
    trait for the `Activity` struct. The `try_fold` method lets us interrupt folding
    if conversion should fail. We push all successfully converted values to the vector
    that we provided as the first argument to the `try_fold` method call. Now, we
    can parse arguments so that we can prepare a pool to use for calling declared
    interaction functions.
  prefs: []
  type: TYPE_NORMAL
- en: Parsing arguments
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Our tool expects two subcommands: `add` and `list`. Let''s add them to a `clap::App`
    instance. Like all previous examples, we also added a `--database` argument to
    set the connection URL. Look at the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: 'The `add` subcommand expects two parameters: `USER_ID` and `ACTIVITY`. Both
    are represented as `String` type values in the `Activity` struct. We will require
    these arguments, but we''ll get any provided values without any restrictions.
    The `list` subcommand has no extra arguments.'
  prefs: []
  type: TYPE_NORMAL
- en: Creating a connections pool
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To connect to a database, we extract the connection URL from the `--database`
    command-line argument. If it isn''t set, we use the `mongodb://localhost:27017/admin`
    default value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: 'But we also parse it to the `Url` struct. This is necessary because MongoDB
    connections expect options sets to be collected by separate values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding code, we create a new `ConnectionOptionsBuilder` instance and
    populate it with values from a parsed `Url` instance. We set `host`, `port`, and
    the `db` name. As you can see, we skip the first character of the path so that
    we can use it as the name of the database. Call the `build` method to build the `ConnectionOptions`
    struct. Now, we can create a `MongodbConnectionManager` instance and use it to
    create a `Pool` instance. But, in this example, we called the `builder` method,
    instead of `new`, to show you how you can set the number of connections in a `Pool`
    instance. We set this to `4`. After that, we called the `build` method to create
    a `Pool` instance. As in previous examples, we call the `get` method of a `Pool`
    to get a `Database` connection object from a pool.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing subcommands
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The implementation of subcommands is simple. For the `add` subcommand, we extract
    two arguments, `USER_ID` and `ACTIVITY`, and use them to create an `Activity`
    struct instance. We also get the current time with the `Utc::now` method and save
    it to a `datetime` field of `Activity`. Finally, we call the `add_activity` method to
    add the `Activity` instance to the MongoDB database:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: The list subcommand calls the `list_activities` function, and then iterates
    over all records to print them to a Terminal. The logging tool is finished – we
    can test it now.
  prefs: []
  type: TYPE_NORMAL
- en: Testing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Compile and run the tool with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: 'Print a list of added records with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: 'This will print the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: 'You can also check the result with the `mongo` client:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: You did it! It works well! Now, you know how to use all popular databases with
    Rust. In the next chapter, we will improve on this knowledge with **o****bject-relational
    mapping** (**ORM**), which helps to simplify database structure declaration, interaction,
    and migrations.
  prefs: []
  type: TYPE_NORMAL
- en: DynamoDB
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We used local database instances in this chapter. The disadvantage of maintaining
    databases yourself is that you also have to take care of scalability yourself.
    There are a lot of services that provide popular databases that automatically
    scale to meet your needs. But not every database can grow without limits: traditional
    SQL databases often experience speed performance issues when tables become huge.
    For large datasets, you should choose to use key-value databases (such as NoSQL)
    that provide scalability by design. In this section, we will explore the usage
    of `DynamoDB`, which was created by Amazon, to provide an easily scalable database
    as a service.'
  prefs: []
  type: TYPE_NORMAL
- en: To use AWS services, you need the AWS SDK, but there is no official SDK for
    Rust, so we will use the `rusoto` crate, which provides the AWS API in Rust. Let's
    start by porting the tool, which we created earlier in this chapter, to `DynamoDB`.
    First, we should create a table in the `DynamoDB` instance.
  prefs: []
  type: TYPE_NORMAL
- en: Bootstrapping a database for testing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Since AWS services are paid-for, it''s better to bootstrap a local instance
    of the `DynamoDB` database for development or testing your application. There
    is an image of `DynamoDB` on Docker Hub. Run the instance with this command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs: []
  type: TYPE_PRE
- en: This command creates an instance of a database and forwards port `8000` of a
    container to a local port with the same number.
  prefs: []
  type: TYPE_NORMAL
- en: 'To work with this database instance, you need the AWS CLI tool. This can be
    installed using the instructions from [https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-install.html](https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-install.html).
    On Linux, I use the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs: []
  type: TYPE_PRE
- en: 'This command doesn''t need administration privileges to be installed. After
    I installed the tool, I created a user with programmatic access, as detailed here:
    [https://console.aws.amazon.com/iam/home#/users$new?step=details](https://console.aws.amazon.com/iam/home#/users%24new?step=details).
    You can read more about creating a user account to access the AWS API here: [https://docs.aws.amazon.com/IAM/latest/UserGuide/getting-started_create-admin-group.html](https://docs.aws.amazon.com/IAM/latest/UserGuide/getting-started_create-admin-group.html).'
  prefs: []
  type: TYPE_NORMAL
- en: 'When you have a user for programmatic access, you can configure the AWS CLI
    using the `configure` subcommand:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs: []
  type: TYPE_PRE
- en: The subcommand asks you for your user credentials, default region, and desired
    output format. Fill in those fields as appropriate.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we can create a table using the AWS CLI tool. Enter the following command
    into the console:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs: []
  type: TYPE_PRE
- en: 'This command creates a table from a declaration in JSON format from the `table.json`
    file in the local database, with an endpoint of `localhost:8000`. This is the
    address of the container we have started. Look at the contents of this table declaration
    file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs: []
  type: TYPE_PRE
- en: 'This file contains a declaration of a table with two required attributes:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Uid` - This stores user identifiers. This attribute will be used as a partition
    key.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`TimeStamp` - This stores a timestamp when location data is produced. This
    attribute will be used as a sorting key to order records.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'You can check whether the database instance contains this new table with the
    following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE81]'
  prefs: []
  type: TYPE_PRE
- en: 'It prints the list of tables that the database instance contains, but our list
    is rather short, as we only have one table:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs: []
  type: TYPE_PRE
- en: The database is prepared. Now, we will create a tool to add records to this
    table using Rust.
  prefs: []
  type: TYPE_NORMAL
- en: Connecting to DynamoDB
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will create a tool to add records to a table in our `DynamoDB`
    database, and also print all records from the table. First, we need to add all
    of the necessary crates.
  prefs: []
  type: TYPE_NORMAL
- en: Adding dependencies
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To work with the AWS API, we will use the `rusoto` crate. Actually, it isn't
    a single crate, but a set of crates where every single crate covers some functionality
    of the AWS API. The basic crate is `rusoto_core`, which contains the `Region`
    struct that represents an address of the AWS API endpoint. `Region` is often necessary
    for other crates. Also, the `rusoto_core` crate re-exports the `rusoto_credential`
    crate, which contains types for loading and managing AWS credentials to access
    the API.
  prefs: []
  type: TYPE_NORMAL
- en: 'To interact with the `DynamoDB` database, we need to add the `rusoto_dynamodb`
    dependency. The full list looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE83]'
  prefs: []
  type: TYPE_PRE
- en: We also added the `chrono` dependency to generate timestamps and convert them
    to ISO-8601 format strings. We use the `clap` crate to parse command-line arguments,
    and the `failure` crate to return a generic `Error` type from the `main` function.
  prefs: []
  type: TYPE_NORMAL
- en: 'We need the following types in our code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE84]'
  prefs: []
  type: TYPE_PRE
- en: It's worth paying attention to types that are imported from the `rusoto_core` and
    `rusoto_dynamodb` crates. We imported the `Region` struct, which is used to set
    the location of the AWS endpoint. The `DynamoDb` trait, `DynamoDbClient`, is used
    to get access to a database. `AttributeValue` is a type used to represent values
    stored in DynamoDB's tables. `QueryInput` is a struct to prepare `query` and `UpdateItemInput`
    is a struct to prepare an `update_item` request.
  prefs: []
  type: TYPE_NORMAL
- en: Let's add functions to interact with the `DynamoDB` database.
  prefs: []
  type: TYPE_NORMAL
- en: Interaction functions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, we will create a tool that stores location records to a database
    and query location points for a specific user. To represent a location in the
    code, we declare the following `Location` struct:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE85]'
  prefs: []
  type: TYPE_PRE
- en: This struct keeps `user_id`, which represents the partition key, and `timestamp`,
    which represents the sort key.
  prefs: []
  type: TYPE_NORMAL
- en: '`DynamoDB` is a key-value storage, where every record has a unique key. When
    you declare tables, you have to decide which attributes will be the key of a record.
    You can choose up to two keys. The first is required and represents a partition
    key that''s used to distribute data across database partitions. The second key
    is optional and represents an attribute that''s used to sort items in a table.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The `rusoto_dynamodb` crate contains an `AttributeValue` struct, which is used
    in queries and results to insert or extract data from tables. Since every record
    (that is, every item) of a table is a set of attribute names to attribute values,
    we will add the `from_map` method to convert the `HashMap` of attributes to our
    `Location` type:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE86]'
  prefs: []
  type: TYPE_PRE
- en: 'We need four attributes: `Uid`,  `TimeStamp`, `Longitude`, and `Latitude`.
    We extract every attribute from the map and convert it into a `Location` instance
    using the `attr_to_string` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE87]'
  prefs: []
  type: TYPE_PRE
- en: 'The `AttributeValue` struct contains multiple fields for different types of
    values:'
  prefs: []
  type: TYPE_NORMAL
- en: '`b` - A binary value represented by `Vec<u8>`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`bool` - A boolean value with the `bool` type'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`bs` - A binary set, but represented as `Vec<Vec<u8>>`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`l` - A list of attributes of a `Vec<AttributeValue>` type'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`m` - A map of attributes of a `HashMap<String, AttributeValue>` type'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`n` - A number stored as a `String` type to keep the exact value without any
    precision loss'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ns` - A set of numbers as a `Vec<String>`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`null` - Used to represent a null value and stored as `bool`, which means the
    value is null'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`s` - A string, of the `String` type'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ss` - A set of strings, of the `Vec<String>` type'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You might notice that there is no data type for timestamps. This is true, as
    `DynamoDB` uses strings for most types of data.
  prefs: []
  type: TYPE_NORMAL
- en: 'We use the `s` field to work with string values that we''ll add with the `add_location`
    function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE88]'
  prefs: []
  type: TYPE_PRE
- en: 'This function expects two parameters: a reference to a database client, and
    a `Location` instance to store. We have to prepare data manually to get it as
    an attributes map for storage, because `DynamoDbClient` takes values of the `AttributeValue`
    type only. The attributes included in the key are inserted into the `HashMap`,
    with values extracted from the `Location` instance and converted into `AttributeValue`
    using the `s_attr` function, which has the following declaration:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE89]'
  prefs: []
  type: TYPE_PRE
- en: After we've filled the `key` map, we can set other attributes with expressions.
    To set attributes to an item, we have to specify them in `DynamoDB` syntax, along
    the lines of `SET Longitude = :x, Latitude = :y`. This expression means that we
    add two attributes with the names `Longitude` and `Latitude`. In the preceding
    expression, we used the placeholders of `:x` and `:y`, which will be replaced
    with real values that we pass in from the `HashMap`.
  prefs: []
  type: TYPE_NORMAL
- en: 'More information about expressions can be found here: [https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Expressions.html](https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Expressions.html).'
  prefs: []
  type: TYPE_NORMAL
- en: When all of the data prepared, we fill the `UpdateItemInput` struct and set
    `table_name` to `"Locations"`, because it requires this as an argument for the
    `update_item` method of `DynamoDbClient`.
  prefs: []
  type: TYPE_NORMAL
- en: The `update_item` method returns `RusotoFuture`, which implements the `Future`
    trait that we explored in [Chapter 5](ed541ef5-4701-4e70-aabf-14882b4cecb3.xhtml), *Understanding
    Asynchronous Operations with Futures Crate*. You can use the `rusoto` crate in
    asynchronous applications. Since we don't use a reactor or asynchronous operations
    in this example, we will call the `sync` method of `RusotoFuture`, which blocks
    the current thread and waits for `Result`.
  prefs: []
  type: TYPE_NORMAL
- en: 'We have implemented a method to create new data items to the table and now
    we need a function to retrieve data from this table. The following `list_locations`
    function gets a list of `Location` for a specific user from the `Locations` table:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE90]'
  prefs: []
  type: TYPE_PRE
- en: The `list_locations` function expects a reference to the `DynamoDbClient` instance
    and a string with if of user. If there are items in the table for the requested
    user, they are returned as a `Vec` of items, converted into the `Location` type.
  prefs: []
  type: TYPE_NORMAL
- en: In this function, we use the `query` method of `DynamoDbClient`, which expects
    a `QueryInput` struct as an argument. We fill it with the name of the table, the
    condition of the key expression, and values to fill that expression. We use a
    simple `Uid = :uid` expression that queries items with the corresponding value
    of the `Uid` partition key. We use a `:uid` placeholder and create a `HashMap` instance
    with a `:uid` key and a `user_id` value, which is converted into `AttributeValue`
    with the `s_attr` function call.
  prefs: []
  type: TYPE_NORMAL
- en: Now, we have two functions to insert and query data. We will use them to implement
    a command-line tool to interact with `DynamoDB`. Let's start with parsing arguments
    for our tool.
  prefs: []
  type: TYPE_NORMAL
- en: Parsing command-line arguments
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'AWS is divided by regions, where each has its own endpoint to connect to services.
    Our tool will support two arguments to set a region and endpoint:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE91]'
  prefs: []
  type: TYPE_PRE
- en: 'We add both to `App` instance. The tool will support two commands to add a
    new item and to print all items. The first subcommand is `add` and it expects
    three arguments: `USER_ID`, `LONGITUDE`, and `LATITUDE`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE92]'
  prefs: []
  type: TYPE_PRE
- en: 'The `list` subcommand requires `USER_ID` in arguments only:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE93]'
  prefs: []
  type: TYPE_PRE
- en: 'Add all of the preceding code to the `main` function. We can use these arguments
    to create a `Region` instance that we can use for a connection with `DynamoDB`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE94]'
  prefs: []
  type: TYPE_PRE
- en: 'The code works according to the following logic: if a user sets the `--endpoint-url`
    parameter, we create a `Region` with a custom name and provide an `endpoint` value.
    If `endpoint` is not set, we try to parse the `--region` parameter to the `Region`
    instance, or just use the `us-east-1` value by default.'
  prefs: []
  type: TYPE_NORMAL
- en: AWS takes the region value seriously, and if you create a table in one region,
    you can't access that table from another region. We used a custom name for the
    region, but for production tools, it's better to use the `~/.aws/config` file
    or provide the flexibility to customize these settings.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we can use the `Region` value to create a `DynamoDbClient` instance:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE95]'
  prefs: []
  type: TYPE_PRE
- en: 'The `DynamoDbClient` struct is used for sending queries to our `DynamoDB` instance.
    We will use this instance in the implementation of our commands. Do you remember
    the `match` expression that parses command-line arguments? Add this implementation
    for the `add` subcommand first, which puts a new item in a table, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE96]'
  prefs: []
  type: TYPE_PRE
- en: The implementation is simple—we extract all provided arguments, generate a timestamp
    using the `Utc::now` call, and convert it into a `String` type in the ISO-8601
    format. Lastly, we fill the `Location` instance and call the `add_location` function
    that we declared before.
  prefs: []
  type: TYPE_NORMAL
- en: 'Have you ever wondered why databases use the ISO-8601 format to represent dates,
    which look like `YEAR-MONTH-DATE HOUR:MINUTE:SECOND`? That''s because dates stored
    in strings in this format are ordered chronologically if sorted alphabetically.
    It''s very convenient: you can sort dates to get the earliest on top and the latest
    at the bottom.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We still need to implement the `list` subcommand:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE97]'
  prefs: []
  type: TYPE_PRE
- en: This command extracts `USER_ID` arguments and calls the `list_locations` function
    with the provided `user_id` value. Finally, we iterate over all locations and
    print them to the Terminal.
  prefs: []
  type: TYPE_NORMAL
- en: The implementation is finished and we can try it now.
  prefs: []
  type: TYPE_NORMAL
- en: Testing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To test the tool, start the `DynamoDB` instance with Docker and create a table,
    like we did before in this chapter. Let''s add four locations of two users:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE98]'
  prefs: []
  type: TYPE_PRE
- en: 'We also set the `--endpoint-url` argument to target our client to a local `DynamoDB`
    instance. When all records have been added, we can use the `list` subcommand to
    print all of the values of the specified user:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE99]'
  prefs: []
  type: TYPE_PRE
- en: 'This command prints something like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE100]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, we retrieved all of the values in a sorted order, because we
    use the `TimeStamp` attribute as a sorting key of the table. Now, you know enough
    to create microservices that uses databases, but if you use the SQL database,
    you can add an extra abstraction layer and work with records of a database as
    native Rust structs, without writing glue code. In the next chapter, we will examine
    this approach with object-relational mappings.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we've covered a lot to do with databases. We started by creating
    a plain connection to PostgreSQL. After that, we added a pool of connections with the
    `r2d2` crate and used the `rayon` crate to execute SQL statements in parallel.
    We created a tool to manage our `users` database, and reimplemented it for our
    MySQL database.
  prefs: []
  type: TYPE_NORMAL
- en: We have also mastered some ways of interacting with NoSQL databases, in particular,
    Redis and MongoDB.
  prefs: []
  type: TYPE_NORMAL
- en: The last database we explored was DynamoDB, which is part of Amazon Web Services
    and can be scaled very easily.
  prefs: []
  type: TYPE_NORMAL
- en: For all examples, we run database instances in containers, because it's the
    simplest way to test interactions with databases. We haven't use database connections
    in microservices yet, because it requires a separate thread to avoid blocking.
    We will learn how to use background tasks with asynchronous code later, in [Chapter
    10](ba240208-414e-4dd4-bba8-8bd2658949cd.xhtml), *Background Tasks and Thread
    Pools in Microservices*.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will explore a different approach to using databases—object-relational
    mapping with the `diesel` crate.
  prefs: []
  type: TYPE_NORMAL
