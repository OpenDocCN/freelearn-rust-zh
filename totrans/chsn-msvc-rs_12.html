<html><head></head><body>
        

                            
                    <h1 class="header-title">Scalable Microservices Architecture</h1>
                
            
            
                
<p>This chapter describes the scalability of microservices. In this chapter, we will learn how to create microservices that use messages for passing interaction with other microservices. You will get acquainted with RabbitMQ message broker and how to use it in Rust with `lapin` crate.</p>
<p>We will cover the following concepts related to microservices scalability in this chapter:</p>
<ul>
<li>Scalable microservices design</li>
<li>How to avoid bottlenecks in your app</li>
<li>What are message brokers?</li>
<li>How to use RabbitMQ with Rust</li>
</ul>


            

            
        
    

        

                            
                    <h1 class="header-title">Technical requirements</h1>
                
            
            
                
<p class="mce-root">To build scalable microservices you, need an infrastructure or resources to run multiple microservices in parallel. But for demonstration purposes, we will use Docker, which provides the ability to run multiple instances of our applications. We also need Docker to start a RabbitMQ instance.</p>
<p class="mce-root">To build all the examples, you will need version 1.31 of the Rust compiler.</p>
<p>You can get all the code for the examples in this chapter from the project on GitHub: <a href="https://github.com/PacktPublishing/Hands-On-Microservices-with-Rust/tree/master/Chapter12">https:/</a><a href="https://github.com/PacktPublishing/Hands-On-Microservices-with-Rust/tree/master/Chapter12">/github.com/PacktPublishing/Hands-On-Microservices-with-Rust/tree/master/Chapter12</a>.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Scalable architecture</h1>
                
            
            
                
<p>We avoid monoliths, and microservices can handle more requests per second if you develop them in the right way, but using microservices doesn't mean you have a scalable application effortlessly. It makes any part of an application flexible for scaling, and you have to write loosely coupled microservices that can run in many instances.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Basic ideas</h1>
                
            
            
                
<p class="mce-root">To make an application scalable, you can choose one of two approaches.</p>
<p>In the first case, you can start more copies of the whole application. You may think it's impossible, but imagine a service that earns money from ads and provides a service to convert images into PDFs. This service can be scaled this way, and you can handle as many requests as the customers need, if you have enough hardware, of course.</p>
<p>The second approach is to split the application into separate services that handle the same types of task, and you can run as many instances of the services as you want. For example, your application is an online store and you have issues with load on servers with images or static assets. This problem is simple to solve, because you can use a <strong>content delivery network</strong> (<strong>CDN</strong>) or buy an extra server where you can put the necessary static files, run NGINX, and add this server to the DNS records of your domain. But for microservices, you can't always use this approach. This requires ingenuity. But the recipe is clear. You have to achieve loose coupling for your microservices when you add extra microservices to handle specific tasks or to speed up some processes by caching, or using other tricks.</p>
<p>To have a more abstract services interaction layer, you can use message brokers that know nothing about your application, but provide the ability to send messages from one microservice to another and return the result.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Message brokers and queues</h1>
                
            
            
                
<p>Message brokers translate messages from one application to another. Clients of message brokers use APIs to send messages that are serialized to a specific format and subscribe to queues to be notified about all the new messages. There is the <strong>AMQP</strong> (short for <strong>Advanced Message Queuing Protocol</strong>) protocol, which provides a common API that's compatible with different products.</p>
<p>The main concept of message brokers is the queue. It is an abstraction that represents an entity used to collect messages until they will be consumed by clients.</p>
<p>Why is the concept of message brokers cool? Because it's the simplest way to achieve loose coupling for services and maintain the possibility of smooth updates. You can use a common message format and write microservices to read specific types of messages. It helps you to reroute all paths of messages. For examples, you can add a specific handler for the specific message type, or set a balancing rule to load more powerful services.</p>
<p>There are a lot of message brokers that can be used, depending on your needs. Some popular products are described in the following sections.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">RabbitMQ</h1>
                
            
            
                
<p>RabbitMQ is the most popular message broker. This message broker supports the AMQP protocol. It's fast and reliable. It also facilitates the creation of short-lifetime queues for implementing client-server interactions based on messages. We will use this message broker to create an example of a scalable application.</p>
<p class="mce-root"/>


            

            
        
    

        

                            
                    <h1 class="header-title">Kafka</h1>
                
            
            
                
<p>Apache Kafka was originally created by LinkedIn and was donated to the Apache Software Foundation. It's implemented with Scala and works like a log that commits all information and provides access to it. It differs from traditional AMQP brokers, because it maintains a commit log that helps to achieve durable message storage.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Application bottlenecks</h1>
                
            
            
                
<p>Any part of an application can be a bottleneck. At first, you may have issues with the infrastructure used by microservices, such as databases or message brokers. Scaling these parts is a complex concept, but here we will only touch upon the bottlenecks of microservices.</p>
<p>When you create a microservice, you may encounter problems with the quantity of requests it can handle. It depends on multiple factors. You can use a concept such as the actors model to spread a load across threads and event loops.</p>
<p>If you have issues with CPU performance, you can create a separate worker that handles CPU-intensive tasks and schedules tasks with message brokers to achieve loose coupling, because you can add more workers at any time to handle more requests.</p>
<p>It you have I/O-intensive tasks, you can use load balancers to direct load to a specific service, but your microservice should be replaceable and shouldn't keep a persistent state, but can load it from a database. It allows you to use products such as Kubernetes to scale your applications automatically.</p>
<p>You should also split large tasks into small and separate microservices by logical domain. For example, create a separate microservice for handling accounts and another to render and show shopping carts in the online store. You can also add another microservice that processes payments, and they interact with each other with messages transferred by a message broker.</p>
<p>Let's create an application that can be scaled by running extra instances of some of its components.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Scalable application with Rust and RabbitMQ</h1>
                
            
            
                
<p>In this section, we will write an application that decodes QR codes from images to textual strings. We will create two services—one to handle incoming requests and for decoding tasks, and the second is a worker that will receive tasks and decode images to strings and return the result to a server. To implement interaction between services, we will use RabbitMQ. For the server and worker implementations, we will use the Actix framework. Before we start coding, let's start a RabbitMQ instance with Docker.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Bootstrap message broker for testing</h1>
                
            
            
                
<p>To start RabbitMQ, we will use the official image for Docker from DockerHub, located here: <a href="https://hub.docker.com/_/rabbitmq/">https://hub.docker.com/_/rabbitmq/</a>. We have already used Docker to start instances of databases. Starting RabbitMQ is similar:</p>
<pre><strong>docker run -it --rm --name test-rabbit -p 5672:5672 rabbitmq:3</strong></pre>
<p>We started a container called <kbd>test-rabbit</kbd> and forward port <kbd>5672</kbd> to the same port of the container. RabbitMQ images also exposes ports <kbd>4369</kbd>, <kbd>5671</kbd>, and <kbd>25672</kbd>. If you want to use the advanced features of the message broker, you need to open these ports too.</p>
<p>If you want to start an instance of RabbitMQ and have access to it from other containers, you can set the <kbd>--hostname</kbd> arguments for the <kbd>run</kbd> command and use the provided name from other containers to connect to the RabbitMQ instance.</p>
<p>When a message broker instance starts, you may need to get some statistics from it. The <kbd>rabbitmqctl</kbd> command can be executed inside the container using the <kbd>exec</kbd> command from Docker:</p>
<pre><strong>docker exec -it test-rabbit rabbitmqctl</strong></pre>
<p>It prints the available commands. Add any of them to the command, like this:</p>
<pre><strong>docker exec -it test-rabbit rabbitmqctl trace_on</strong></pre>
<p>The preceding command activates tracing all the messages pushed to queues, which you can see with the following command:</p>
<pre><strong>docker exec -it test-rabbit rabbitmqctl list_exchanges</strong></pre>
<p>It prints the following:</p>
<pre>Listing exchanges for vhost / ...<br/>amq.headers    headers<br/>amq.direct    direct<br/>amq.topic    topic<br/>amq.rabbitmq.trace    topic<br/>    direct<br/>amq.fanout    fanout<br/>amq.match    headers</pre>
<p>Now, we can create a microservice that uses the message broker for interaction with the worker.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Dependencies</h1>
                
            
            
                
<p class="mce-root">Create a new library crate (in which we will add two binaries later) called <kbd>rabbit-actix</kbd>:</p>
<pre>[package]<br/>name = "rabbit-actix"<br/>version = "0.1.0"<br/>edition = "2018"</pre>
<p>As you can see, we are using the 2018 edition of Rust. We need a pretty big pile of crates:</p>
<pre>[dependencies]<br/>actix = "0.7"<br/>actix-web = "0.7"<br/>askama = "0.7"<br/>chrono = "0.4"<br/>env_logger = "0.6"<br/>image = "0.21"<br/>indexmap = "1.0"<br/>failure = "0.1"<br/>futures = "0.1"<br/>log = "0.4"<br/>queens-rock = "0.1"<br/>rmp-serde = "0.13"<br/>serde = "1.0"<br/>serde_derive = "1.0"<br/>serde_json = "1.0"<br/>tokio = "0.1"<br/>uuid = "0.7"</pre>
<p class="CDPAlignLeft CDPAlign">It's important to note that we use the <kbd>actix</kbd> framework with the <kbd>actix-web</kbd> crate. If you are not familiar with this crate, you can read more about it in <a href="5b7dd2c1-d623-4422-83a7-e05681230ee9.xhtml" target="_blank">Chapter 11</a>, <em>Involving Concurrency with Actors and Actix Crate</em>. We also use the <kbd>image</kbd> crate to work with image formats, because this crate is used by <kbd>queens-rock</kbd> and implements a decoder for QR codes. We also use the <kbd>askama</kbd> crate to render HTML pages with posted tasks, and we use the <kbd>indexmap</kbd> crate to get an ordered hash map that keeps elements insertion order. To create unique names for the tasks, we will use the UUID4 format, which is implemented in the <kbd>uuid</kbd> crate.</p>
<p>To interact with RabbitMQ, we will use the <kbd>lapin-futures</kbd> crate, but we renamed it <kbd>lapin</kbd> because there are two implementations of this crate. The one that we use is based on the <kbd>futures</kbd> crate, and there is also the<strong> </strong><kbd>lapin-async</kbd> crate version based on the <kbd>mio</kbd> crate. We will use the <kbd>lapin-futures</kbd> crate first, and name it <kbd>lapin</kbd>:</p>
<pre>[dependencies.lapin]<br/>version = "0.15"<br/>package = "lapin-futures"</pre>
<p>Add the first binary with a server implementation pointing to the <kbd>src/server.rs</kbd> file:</p>
<pre>[[bin]]<br/>name = "rabbit-actix-server"<br/>path = "src/server.rs"<br/>test = false</pre>
<p>Add the second binary for a worker that will be implemented in the <kbd>src/worker.rs</kbd> file:</p>
<pre>[[bin]]<br/>name = "rabbit-actix-worker"<br/>path = "src/worker.rs"<br/>test = false</pre>
<p>We already use the <kbd>askama</kbd> crate as a dependency for the main code, but we also need it as a dependency for the <kbd>build.rs</kbd> script. Add this:</p>
<pre>[build-dependencies]<br/>askama = "0.7"</pre>
<p>The preceding dependency needs to rebuild templates to embed them into code. Add the following code to a new <kbd>build.rs</kbd> script:</p>
<pre>fn main() {<br/>    askama::rerun_if_templates_changed();<br/>}</pre>
<p>All the dependencies are prepared, and we can create an abstract type to interact with queues in a message broker.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Abstract queue interaction actor</h1>
                
            
            
                
<p>Add the <kbd>src/queue_actor.rs</kbd> actor, and let's create an actor that uses an abstract handler to process incoming messages and can send new messages to a queue. It also has to create all the necessary queues in RabbitMQ and subscribe to new events in the corresponding queue.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Dependencies</h1>
                
            
            
                
<p>To create an actor, we need the following dependencies:</p>
<pre>use super::{ensure_queue, spawn_client};<br/>use actix::fut::wrap_future;<br/>use actix::{Actor, Addr, AsyncContext, Context, Handler, Message, StreamHandler, SystemRunner};<br/>use failure::{format_err, Error};<br/>use futures::Future;<br/>use lapin::channel::{BasicConsumeOptions, BasicProperties, BasicPublishOptions, Channel};<br/>use lapin::error::Error as LapinError;<br/>use lapin::message::Delivery;<br/>use lapin::types::{FieldTable, ShortString};<br/>use log::{debug, warn};<br/>use serde::{Deserialize, Serialize};<br/>use tokio::net::TcpStream;<br/>use uuid::Uuid;<br/><br/>pub type TaskId = ShortString;</pre>
<p>First, we use the <kbd>ensure_queue</kbd> function from the super module, which creates a new queue, but we will implement it later in this chapter. <kbd>spawn_client</kbd> lets us create a new <kbd>Client</kbd> connected to a message broker. We will use the <kbd>wrap_future</kbd> function, which converts any <kbd>Future</kbd> object into an <kbd>ActorFuture</kbd>, which can be spawned in the <kbd>Context</kbd> environment of the Actix framework.</p>
<p>Let's explore the types from the <kbd>lapin</kbd> crate. The <kbd>Channel</kbd> struct represents a connection channel with the RabbitMQ instance. <kbd>BasicConsumeOptions</kbd> represents options used for the <kbd>basic_consume</kbd> method of the <kbd>Channel</kbd> call to subscribe to new events in a queue. <kbd>BasicProperties</kbd> types are used as parameters for the <kbd>basic_publish</kbd> method call of the <kbd>Channel</kbd> type for add properties such as correlation IDs to distinct recipients of the message, or set the required quality level for delivery. <kbd>BasicPublishOptions</kbd> is used for the <kbd>basic_publish</kbd> call to set extra options for a message publishing activity.</p>
<p>We also need the <kbd>Error</kbd> type from the <kbd>lapin</kbd> crate, but we renamed it <kbd>LapinError</kbd> because we also use the generic  <kbd>Error</kbd> from the <kbd>failure</kbd> crate. The <kbd>Delivery</kbd> struct represents an incoming message delivered from a queue. The <kbd>FieldTable</kbd> type is used as a parameter for the <kbd>basic_consume</kbd> method call of the <kbd>Channel</kbd> type. The <kbd>ShortString</kbd> type is a simple alias to a <kbd>String</kbd> that is used as a name of a queue in the <kbd>lapin</kbd> crate. The <kbd>Uuid</kbd> type is imported from the <kbd>uuid</kbd> crate to generate unique correlation IDs for messages to identify the origin of a message.</p>
<p>Now, we can declare the abstract handler for our messages.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Abstract messages handler</h1>
                
            
            
                
<p>Create the <kbd>QueueHandler</kbd> struct in the <kbd>queue_actor.rs</kbd> file:</p>
<pre>pub trait QueueHandler: 'static {<br/>     type Incoming: for&lt;'de&gt; Deserialize&lt;'de&gt;;<br/>     type Outgoing: Serialize;<br/> <br/>     fn incoming(&amp;self) -&gt; &amp;str;<br/>     fn outgoing(&amp;self) -&gt; &amp;str;<br/>     fn handle(<br/>         &amp;self,<br/>         id: &amp;TaskId,<br/>         incoming: Self::Incoming,<br/>     ) -&gt; Result&lt;Option&lt;Self::Outgoing&gt;, Error&gt;;<br/> }</pre>
<p><kbd>QueueHandler</kbd> is a trait that has two associated types and three methods. It requires a <kbd>static</kbd> lifetime for types that will implement the <kbd>QueueHandler</kbd> trait, because instances of this trait will be used as fields of actors that have a static lifetime as well.</p>
<p>This trait has the <kbd>Incoming</kbd> associated type, which represents the incoming message type and requires the type to implement the <kbd>Deserialize</kbd> trait to be deserializable, because RabbitMQ transfers byte arrays only and you have to decide which format to use for serialization. The <kbd>Outgoing</kbd> associated type has to implement the <kbd>Serialize</kbd> trait to be serializable as a bytes array to be sent as an outgoing message.</p>
<p><kbd>The QueueHandler</kbd>  trait also has <kbd>incoming</kbd> and <kbd>outgoing</kbd> methods. The first returns the name of a queue to consume incoming messages. The second method returns the name of a queue in which an actor will write sending messages. There is also a <kbd>handle</kbd> method, which takes a reference to <kbd>TaskId</kbd> and incoming messages of the <kbd>Self::Incoming</kbd> associated type. The method returns a <kbd>Result</kbd> with an optional <kbd>Self::Outgoing</kbd> instance. If the implementation returns <kbd>None</kbd> then no messages will be sent to the outgoing channel. However, you can use a special <kbd>SendMessage</kbd> type to send a message later. We will declare this type later, after we add the actor's struct.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Actor</h1>
                
            
            
                
<p>Add a new struct called <kbd>QueueActor</kbd> and add a type parameter that implements the <kbd>QueueHandler</kbd> trait:</p>
<pre>pub struct QueueActor&lt;T: QueueHandler&gt; {<br/>     channel: Channel&lt;TcpStream&gt;,<br/>     handler: T,<br/> }</pre>
<p>The struct has a reference to a connection <kbd>Channel</kbd> to RabbitMQ. We build it over <kbd>TcpStream</kbd>. The struct also has a <kbd>handler</kbd> field that contains an instance of a handler that implements <kbd>QueueHandler</kbd>.</p>
<p>This struct also has to implement the <kbd>Actor</kbd> trait to become an actor. We also added a <kbd>started</kbd> method. It remains empty, but it's a good place to create all the queues. For example, you can create a message type that will attach a <kbd>Stream</kbd> of messages to this actor. With this approach, you can start consuming any queue at any time:</p>
<pre>impl&lt;T: QueueHandler&gt; Actor for QueueActor&lt;T&gt; {<br/>     type Context = Context&lt;Self&gt;;<br/> <br/>     fn started(&amp;mut self, _: &amp;mut Self::Context) {}<br/> }</pre>
<p>We will initialize all the queues in the <kbd>new</kbd> method to interrupt actor creation if something goes wrong:</p>
<pre>impl&lt;T: QueueHandler&gt; QueueActor&lt;T&gt; {<br/>     pub fn new(handler: T, mut sys: &amp;mut SystemRunner) -&gt; Result&lt;Addr&lt;Self&gt;, Error&gt; {<br/>         let channel = spawn_client(&amp;mut sys)?;<br/>         let chan = channel.clone();<br/>         let fut = ensure_queue(&amp;chan, handler.outgoing());<br/>         sys.block_on(fut)?;<br/>         let fut = ensure_queue(&amp;chan, handler.incoming()).and_then(move |queue| {<br/>             let opts = BasicConsumeOptions {<br/>                 ..Default::default()<br/>             };<br/>             let table = FieldTable::new();<br/>             let name = format!("{}-consumer", queue.name());<br/>             chan.basic_consume(&amp;queue, &amp;name, opts, table)<br/>         });<br/>         let stream = sys.block_on(fut)?;<br/>         let addr = QueueActor::create(move |ctx| {<br/>             ctx.add_stream(stream);<br/>             Self { channel, handler }<br/>         });<br/>         Ok(addr)<br/>     }<br/> }</pre>
<p>We call the <kbd>spawn_client</kbd> function, which we will implement later, to create a <kbd>Client</kbd> that's connected to a message broker. The function returns a <kbd>Channel</kbd> instance, which is created by the connected <kbd>Client</kbd>. We use <kbd>Channel</kbd> to ensure the queue we need exists, or create it with <kbd>ensure_queue</kbd>. This method is implemented later in this chapter. We use the result of the <kbd>QueueHandler::outgoing</kbd> method to get the name of the queue to create.</p>
<p>This method expects <kbd>SystemRunner</kbd> to execute <kbd>Future</kbd> objects immediately by calling the <kbd>block_on</kbd> method. It lets us get a <kbd>Result</kbd> and interrupts other activities if the method call fails.</p>
<p>After that, we create a queue using the name we get with the <kbd>QueueHandler::incoming</kbd> method call. We will consume messages from this queue and use the <kbd>basic_consume</kbd> method of a <kbd>Channel</kbd> that starts listening for new messages. To call <kbd>basic_consume</kbd>, we also created default values of the <kbd>BasicConsumeOptions</kbd> and <kbd>FieldTable</kbd> types. <kbd>basic_consume</kbd> returns a <kbd>Future</kbd> that will be resolved to a <kbd>Stream</kbd> value. We use the <kbd>block_on</kbd> method call of the <kbd>SystemRunner</kbd> instance to execute this <kbd>Future</kbd> to get a <kbd>Stream</kbd> instance to attach it to <kbd>QueueActor</kbd>. We create the <kbd>QueueActor</kbd> instance using the <kbd>create</kbd> method call, which expects a closure, which in turn takes a reference to a <kbd>Context</kbd>.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Handling an incoming stream</h1>
                
            
            
                
<p>We used the <kbd>basic_consume</kbd> method of a <kbd>Channel</kbd> to create a <kbd>Stream</kbd> that returns <kbd>Delivery</kbd> objects from a queue. Since we want to attach that <kbd>Stream</kbd> to the actor, we have to implement <kbd>StreamHandler</kbd> for the <kbd>QueueActor</kbd> type:</p>
<pre>impl&lt;T: QueueHandler&gt; StreamHandler&lt;Delivery, LapinError&gt; for QueueActor&lt;T&gt; {<br/>     fn handle(&amp;mut self, item: Delivery, ctx: &amp;mut Context&lt;Self&gt;) {<br/>         debug!("Message received!");<br/>         let fut = self<br/>             .channel<br/>             .basic_ack(item.delivery_tag, false)<br/>             .map_err(drop);<br/>         ctx.spawn(wrap_future(fut));<br/>         match self.process_message(item, ctx) {<br/>             Ok(pair) =&gt; {<br/>                 if let Some((corr_id, data)) = pair {<br/>                     self.send_message(corr_id, data, ctx);<br/>                 }<br/>             }<br/>             Err(err) =&gt; {<br/>                 warn!("Message processing error: {}", err);<br/>             }<br/>         }<br/>     }<br/> }</pre>
<p>Our <kbd>StreamHandler</kbd> implementation expects a <kbd>Delivery</kbd> instance. RabbitMQ expects that a client will send an acknowledgement when it consumes the delivered message. We do it with the <kbd>basic_ack</kbd> method call of a <kbd>Channel</kbd> instance stored as a field of <kbd>QueueActor</kbd>. This method call returns a <kbd>Future</kbd> instance that we will <kbd>spawn</kbd> in a <kbd>Context</kbd> to send an acknowledgement that the message was received.</p>
<p>RabbitMQ requires a consumer to notify with every message that is processed. If a consumer doesn't do this, then the message is left hanging in the queue. But you can set the <kbd>no_ack</kbd> field of the <kbd>BasicConsumeOptions</kbd> struct to <kbd>true</kbd> and the message will be marked as delivered as soon as the consumer reads it. But if your application fails before the message is processed, you will lose the message. It's only suitable for non-critical messages.</p>
<p>We use the <kbd>process_message</kbd> method that we will implement later to process a message using the <kbd>QueueHandler</kbd> instance. If this method returns a not <kbd>None</kbd> value, we will use it as a response message and send it to an outgoing queue using the <kbd>send_message</kbd> method, which we will also implement later in this chapter. But now we will add a message to initiate an outgoing message.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Sending a new message</h1>
                
            
            
                
<p><kbd>QueueActor</kbd> has to send a new message, because we will use this actor to send tasks to a worker. Add the corresponding struct:</p>
<pre>pub struct SendMessage&lt;T&gt;(pub T);</pre>
<p>Implement the <kbd>Message</kbd> trait for this type:</p>
<pre>impl&lt;T&gt; Message for SendMessage&lt;T&gt; {<br/>     type Result = TaskId;<br/> }</pre>
<p>We need to set the <kbd>Result</kbd> type to <kbd>TaskId</kbd>, because we will generate a new task ID for a new message to process the response with a handler later. If you are not familiar with the Actix framework and message, return to <a href="5b7dd2c1-d623-4422-83a7-e05681230ee9.xhtml">Chapter 11</a>, <em>In</em><em>volving Concurrency with Actors and Actix Crate</em>.</p>
<p>The <kbd>Handler</kbd> of this message type will generate a new UUID and convert it into a <kbd>String</kbd>. Then, the method will use the <kbd>send_message</kbd> method to send a message to an outgoing queue:</p>
<pre>impl&lt;T: QueueHandler&gt; Handler&lt;SendMessage&lt;T::Outgoing&gt;&gt; for QueueActor&lt;T&gt; {<br/>     type Result = TaskId;<br/> <br/>     fn handle(&amp;mut self, msg: SendMessage&lt;T::Outgoing&gt;, ctx: &amp;mut Self::Context) -&gt; Self::Result {<br/>         let corr_id = Uuid::new_v4().to_simple().to_string();<br/>         self.send_message(corr_id.clone(), msg.0, ctx);<br/>         corr_id<br/>     }<br/> }</pre>
<p>Now, we have to implement the <kbd>process_message</kbd> and <kbd>send_message</kbd> methods of <kbd>QueueActor</kbd>.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Utility methods</h1>
                
            
            
                
<p>Let's add the <kbd>process_message</kbd> method, which processes incoming <kbd>Delivery</kbd> items:</p>
<pre>impl&lt;T: QueueHandler&gt; QueueActor&lt;T&gt; {<br/>     fn process_message(<br/>         &amp;self,<br/>         item: Delivery,<br/>         _: &amp;mut Context&lt;Self&gt;,<br/>     ) -&gt; Result&lt;Option&lt;(ShortString, T::Outgoing)&gt;, Error&gt; {<br/>         let corr_id = item<br/>             .properties<br/>             .correlation_id()<br/>             .to_owned()<br/>             .ok_or_else(|| format_err!("Message has no address for the response"))?;<br/>         let incoming = serde_json::from_slice(&amp;item.data)?;<br/>         let outgoing = self.handler.handle(&amp;corr_id, incoming)?;<br/>         if let Some(outgoing) = outgoing {<br/>             Ok(Some((corr_id, outgoing)))<br/>         } else {<br/>             Ok(None)<br/>         }<br/>     }<br/> }</pre>
<p>First, we have to get a unique ID associated with a message. If you remember, we used the UUID in this case. We stored it in the correlation ID field of the message.</p>
<p>A correlation ID represents a value that is associated with a message as a tag for the response. This information is used to implement <strong>Remote Procedure Calls</strong> (<strong>RPC</strong>s) over RabbitMQ. If you skipped <a href="fd4bf12a-bb05-469b-a230-163cee412261.xhtml">Chapter 6</a>, <em>Reactive Microservices - Increasing Capacity and Performance</em>, you can return to it to read more about RPCs.</p>
<p>We use JSON format for our messages, and we parse using <kbd>serde_json</kbd> to create incoming data that is stored in the <kbd>data</kbd> field of the <kbd>Delivery</kbd> instance. If a deserialization was successful, we take the value of the <kbd>Self::Incoming</kbd> type. Now, we have all the information we need to call the <kbd>handle</kbd> method of the <kbd>QueueHandler</kbd> instance—the correlation ID and a deserialized incoming message. The handler returns a <kbd>Self::Outgoing</kbd> message instance, but we won't serialize it immediately for sending, because it will use the <kbd>send_message</kbd> method that we used to process incoming messages. Let's implement it.</p>
<p>The <kbd>send_message</kbd> method takes a correlation ID and an outgoing value to prepare and send a message:</p>
<pre>impl&lt;T: QueueHandler&gt; QueueActor&lt;T&gt; {<br/>     fn send_message(&amp;self, corr_id: ShortString, outgoing: T::Outgoing, ctx: &amp;mut Context&lt;Self&gt;) {<br/>         let data = serde_json::to_vec(&amp;outgoing);<br/>         match data {<br/>             Ok(data) =&gt; {<br/>                 let opts = BasicPublishOptions::default();<br/>                 let props = BasicProperties::default().with_correlation_id(corr_id);<br/>                 debug!("Sending to: {}", self.handler.outgoing());<br/>                 let fut = self<br/>                     .channel<br/>                     .basic_publish("", self.handler.outgoing(), data, opts, props)<br/>                     .map(drop)<br/>                     .map_err(drop);<br/>                 ctx.spawn(wrap_future(fut));<br/>             }<br/>             Err(err) =&gt; {<br/>                 warn!("Can't encode an outgoing message: {}", err);<br/>             }<br/>         }<br/>     }<br/> }</pre>
<p>First, the method serializes a value to binary data. If the value is serialized to JSON successfully, we prepare options and properties to call the <kbd>basic_publish</kbd> method of a <kbd>Channel</kbd> to send a message to an outgoing queue. It's worth noting that we associated the provided correlation ID to the <kbd>BasicProperties</kbd> struct that's used with the <kbd>basic_publish</kbd> call. Publishing a message returns a <kbd>Future</kbd> instance, which we have to spawn in the context of an <kbd>Actor</kbd>. If we can't serialize a value, we will log an error.</p>
<p>Now, we can finish implementing the library part of the crate by adding the <kbd>spawn_client</kbd> and <kbd>ensure_queue</kbd> functions.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Crate</h1>
                
            
            
                
<p>Add the following imports to the <kbd>src/lib.rs</kbd> source file:</p>
<pre>pub mod queue_actor;<br/> <br/>use actix::{Message, SystemRunner};<br/>use failure::Error;<br/>use futures::Future;<br/>use lapin::channel::{Channel, QueueDeclareOptions};<br/>use lapin::client::{Client, ConnectionOptions};<br/>use lapin::error::Error as LapinError;<br/>use lapin::queue::Queue;<br/>use lapin::types::FieldTable;<br/>use serde_derive::{Deserialize, Serialize};<br/>use tokio::net::TcpStream;</pre>
<p>You are familiar with some types. Let's discuss some of the new ones. <kbd>Client</kbd> represents a client that connects to RabbitMQ. The <kbd>Channel</kbd> type will be created as a result of a connection and is returned by a <kbd>Client</kbd>. <kbd>QueueDeclareOptions</kbd> is used as a parameter for the <kbd>queue_declare</kbd> method call of a <kbd>Channel</kbd>. <kbd>ConnectionOptions</kbd> is necessary to establish a connection, but we will use default values. <kbd>Queue</kbd> represents a queue in RabbitMQ.</p>
<p>We need two queues: one for requests and one for responses. We will specify the destination of messages with the correlation ID. Add the following constants to be used as the names of queues:</p>
<pre>pub const REQUESTS: &amp;str = "requests";<br/>pub const RESPONSES: &amp;str = "responses";</pre>
<p>To spawn a <kbd>Client</kbd> and create a <kbd>Channel</kbd>, we will add the <kbd>spawn_client</kbd> function, which creates a <kbd>Client</kbd> and produces a <kbd>Channel</kbd> from it:</p>
<pre>pub fn spawn_client(sys: &amp;mut SystemRunner) -&gt; Result&lt;Channel&lt;TcpStream&gt;, Error&gt; {<br/>    let addr = "127.0.0.1:5672".parse().unwrap();<br/>    let fut = TcpStream::connect(&amp;addr)<br/>        .map_err(Error::from)<br/>        .and_then(|stream| {<br/>            let options = ConnectionOptions::default();<br/>            Client::connect(stream, options).from_err::&lt;Error&gt;()<br/>        });<br/>    let (client, heartbeat) = sys.block_on(fut)?;<br/>    actix::spawn(heartbeat.map_err(drop));<br/>    let channel = sys.block_on(client.create_channel())?;<br/>    Ok(channel)<br/>}</pre>
<p>The implementation of the preceding function is simple enough. We create a <kbd>TcpStream</kbd> from a constant address with the <kbd>connect</kbd> method call. You can make the address parameter configurable if necessary. The <kbd>connect</kbd> method returns a <kbd>Future</kbd> that we use to create a combinator that maps to a new <kbd>Client</kbd> connected to RabbitMQ. We use <kbd>block_on</kbd> of <kbd>SystemRunner</kbd> to execute that <kbd>Future</kbd> immediately. It returns a <kbd>Client</kbd> and a <kbd>Heartbeat</kbd> instance. The <kbd>Client</kbd> instance is used to create an instance of <kbd>Channel</kbd>. The <kbd>Heartbeat</kbd> instance is a task that pings RabbitMQ with a connection that has to be spawned as a concurrent activity in the event loop. We use <kbd>actix::spawn</kbd> to run it, because we don't have the <kbd>Context</kbd> of an <kbd>Actor</kbd>.</p>
<p>Finally, we call the <kbd>create_channel</kbd> method of a <kbd>Client</kbd> to create a <kbd>Channel</kbd>. But the method returns a <kbd>Future</kbd>, which we also execute with the <kbd>block_on</kbd> method. Now, we can return the created <kbd>Channel</kbd> and implement the <kbd>ensure_queue</kbd> method, which expects that <kbd>Channel</kbd> instance as a parameter.</p>
<p>The <kbd>ensure_queue</kbd> method creates the option to call the <kbd>queue_declare</kbd> method, which creates a queue inside RabbitMQ:</p>
<pre>pub fn ensure_queue(<br/>    chan: &amp;Channel&lt;TcpStream&gt;,<br/>    name: &amp;str,<br/>) -&gt; impl Future&lt;Item = Queue, Error = LapinError&gt; {<br/>    let opts = QueueDeclareOptions {<br/>        auto_delete: true,<br/>        ..Default::default()<br/>    };<br/>    let table = FieldTable::new();<br/>    chan.queue_declare(name, opts, table)<br/>}</pre>
<p>We fill <kbd>QueueDeclareOptions</kbd> with default parameters, but set the <kbd>auto_delete</kbd> field to <kbd>true</kbd>, because we want the created queues to be deleted when an application ends. It's suitable for testing purposes. In this method, we won't execute a <kbd>Future</kbd> that is returned by the <kbd>queue_declare</kbd> method immediately. We return it as is to enable the calling environment to make a combinator with the returned <kbd>Queue</kbd> value.</p>
<p>We have implemented all the necessary parts to create a server and a worker. Now, we need to declare request and response types to use them in a worker and in a server.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Request and response</h1>
                
            
            
                
<p>The request type called <kbd>QrRequest</kbd> contains data about the QR image:</p>
<pre>#[derive(Clone, Debug, Deserialize, Serialize)]<br/>pub struct QrRequest {<br/>    pub image: Vec&lt;u8&gt;,<br/>}</pre>
<p>It implements the <kbd>Message</kbd> trait from <kbd>actix</kbd>, which is to be set as an associated type of <kbd>QueueHandler</kbd>:</p>
<pre>impl Message for QrRequest {<br/>    type Result = ();<br/>}</pre>
<p>The response type is represented by the <kbd>QrResponse</kbd> enumeration:</p>
<pre>#[derive(Clone, Debug, Deserialize, Serialize)]<br/>pub enum QrResponse {<br/>    Succeed(String),<br/>    Failed(String),<br/>}</pre>
<p>It contains two variants: <kbd>Succeed</kbd> for successful results and <kbd>Failed</kbd> for errors. It is similar to the <kbd>Result</kbd> type of the standard library, but we decided to add our own type to have a chance to override the serialization behavior when we need it. But we can construct this response from a <kbd>Result</kbd> instance by implementing the <kbd>From</kbd> trait. It's useful because we can use a function to construct a value that returns the <kbd>Result</kbd> type. Look at the implementation here:</p>
<pre>impl From&lt;Result&lt;String, Error&gt;&gt; for QrResponse {<br/>    fn from(res: Result&lt;String, Error&gt;) -&gt; Self {<br/>        match res {<br/>            Ok(data) =&gt; QrResponse::Succeed(data),<br/>            Err(err) =&gt; QrResponse::Failed(err.to_string()),<br/>        }<br/>    }<br/>}</pre>
<p><kbd>QrResponse</kbd> also has to implement the <kbd>Message</kbd> trait:</p>
<pre>impl Message for QrResponse {<br/>    type Result = ();<br/>}</pre>
<p>The library crate is ready to be used to create a worker and a server. Let's start by implementing a worker.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Worker</h1>
                
            
            
                
<p>The worker will consume all the messages from the requests queue and try to decode them as QR images to strings.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Dependencies</h1>
                
            
            
                
<p>We need the following types for the implementation of a worker:</p>
<pre>use actix::System;<br/>use failure::{format_err, Error};<br/>use image::GenericImageView;<br/>use log::debug;<br/>use queens_rock::Scanner;<br/>use rabbit_actix::queue_actor::{QueueActor, QueueHandler, TaskId};<br/>use rabbit_actix::{QrRequest, QrResponse, REQUESTS, RESPONSES};</pre>
<p>We imported all the necessary types earlier in this chapter. We also imported two types for decoding QR images. <kbd>GenericImageView</kbd> provides the <kbd>to_luma</kbd> method to convert an image into grayscale. The <kbd>Scanner</kbd> method is a decoder of QR codes provided as grayscale images.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Handler</h1>
                
            
            
                
<p>We need to create an empty struct, because our worker doesn't have a state and will only transform incoming messages:</p>
<pre>struct WokerHandler {}</pre>
<p>We use the <kbd>WorkerHandler</kbd> struct as the handler for the queue and use it with <kbd>QueueActor</kbd> later. Implement the <kbd>QueueHandler</kbd> trait, which is required by <kbd>QueueActor</kbd>:</p>
<pre>impl QueueHandler for WokerHandler {<br/>    type Incoming = QrRequest;<br/>    type Outgoing = QrResponse;<br/><br/>    fn incoming(&amp;self) -&gt; &amp;str {<br/>        REQUESTS<br/>    }<br/>    fn outgoing(&amp;self) -&gt; &amp;str {<br/>        RESPONSES<br/>    }<br/>    fn handle(<br/>        &amp;self,<br/>        _: &amp;TaskId,<br/>        incoming: Self::Incoming,<br/>    ) -&gt; Result&lt;Option&lt;Self::Outgoing&gt;, Error&gt; {<br/>        debug!("In: {:?}", incoming);<br/>        let outgoing = self.scan(&amp;incoming.image).into();<br/>        debug!("Out: {:?}", outgoing);<br/>        Ok(Some(outgoing))<br/>    }<br/>}</pre>
<p>Since this handler takes requests and prepares responses, we set <kbd>QrRequest</kbd> as the <kbd>Incoming</kbd> type and <kbd>QrResponse</kbd> as the <kbd>Outgoing</kbd> type. The <kbd>incoming</kbd> method returns the value of the <kbd>REQUESTS</kbd> constant that we will use as a name for incoming queues. The <kbd>outgoing</kbd> method returns the <kbd>RESPONSES</kbd> constant, which is used as the name for the queue of outgoing messages.</p>
<p>The <kbd>handle</kbd> method of <kbd>QueueHandler</kbd> takes a request and calls the <kbd>scan</kbd> method with data. Then, it converts the <kbd>Result</kbd> into a <kbd>QrResponse</kbd> and returns it. Let's implement the <kbd>scan</kbd> method, which decodes images:</p>
<pre>impl WokerHandler {<br/>    fn scan(&amp;self, data: &amp;[u8]) -&gt; Result&lt;String, Error&gt; {<br/>        let image = image::load_from_memory(data)?;<br/>        let luma = image.to_luma().into_vec();<br/>        let scanner = Scanner::new(<br/>            luma.as_ref(),<br/>            image.width() as usize,<br/>            image.height() as usize,<br/>        );<br/>        scanner<br/>            .scan()<br/>            .extract(0)<br/>            .ok_or_else(|| format_err!("can't extract"))<br/>            .and_then(|code| code.decode().map_err(|_| format_err!("can't decode")))<br/>            .and_then(|data| {<br/>                data.try_string()<br/>                    .map_err(|_| format_err!("can't convert to a string"))<br/>            })<br/>    }<br/>}</pre>
<p>The implementation of the function is not important from a microservices point of view, and I will describe it shortly—it loads an <kbd>Image</kbd> from the provided bytes, converts the <kbd>Image</kbd> to grayscale with the <kbd>to_luma</kbd> method, and provides the returned value as an argument for a <kbd>Scanner</kbd>. Then, it uses the <kbd>scan</kbd> method to decode the QR code and extracts the first <kbd>Code</kbd> converted to a <kbd>String</kbd>.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">main function</h1>
                
            
            
                
<p>Now, we can add a <kbd>main</kbd> function to spawn an actor with the decoding worker:</p>
<pre>fn main() -&gt; Result&lt;(), Error&gt; {<br/>    env_logger::init();<br/>    let mut sys = System::new("rabbit-actix-worker");<br/>    let _ = QueueActor::new(WokerHandler {}, &amp;mut sys)?;<br/>    let _ = sys.run();<br/>    Ok(())<br/>}</pre>
<p>This method starts a <kbd>System</kbd> and creates an instance of <kbd>QueueActor</kbd> with an instance of <kbd>WorkerHandler</kbd>. That's all. It's really simple—with <kbd>QueueActor</kbd>, it's enough to implement <kbd>QueueHandler</kbd> to make a processor to a queue. Let's create a server in a similar way.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Server</h1>
                
            
            
                
<p>To implement a server, we don't just implement <kbd>QueueHandler</kbd>. We also have to implement handlers for HTTP requests. We will also use the <kbd>actix</kbd> and <kbd>actix-web</kbd> crates.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Dependencies</h1>
                
            
            
                
<p>Add the following types to the <kbd>server.rs</kbd> file:</p>
<pre>use actix::{Addr, System};<br/>use actix_web::dev::Payload;<br/>use actix_web::error::MultipartError;<br/>use actix_web::http::{self, header, StatusCode};<br/>use actix_web::multipart::MultipartItem;<br/>use actix_web::{<br/>    middleware, server, App, Error as WebError, HttpMessage, HttpRequest, HttpResponse,<br/>};<br/>use askama::Template;<br/>use chrono::{DateTime, Utc};<br/>use failure::Error;<br/>use futures::{future, Future, Stream};<br/>use indexmap::IndexMap;<br/>use log::debug;<br/>use rabbit_actix::queue_actor::{QueueActor, QueueHandler, SendMessage, TaskId};<br/>use rabbit_actix::{QrRequest, QrResponse, REQUESTS, RESPONSES};<br/>use std::fmt;<br/>use std::sync::{Arc, Mutex};</pre>
<p>You should be familiar with all the types, because we used most of them in the previous chapters, excluding <kbd>MultipartItem</kbd> and <kbd>MultipartError</kbd>. Both of these types are used to extract uploaded files from POST requests.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Shared state</h1>
                
            
            
                
<p>We will also add the <kbd>SharedTasks</kbd> type alias, which represents an <kbd>IndexMap</kbd> wrapped with <kbd>Mutex</kbd> and <kbd>Arc</kbd>. We will use this type to store all the tasks and statuses for them:</p>
<pre>type SharedTasks = Arc&lt;Mutex&lt;IndexMap&lt;String, Record&gt;&gt;&gt;;</pre>
<p><kbd>Record</kbd> is a struct that contains the unique identifier of the task, and is used as the correlation ID for the message. It also has a <kbd>timestamp</kbd> that denotes when the task was posted, and a <kbd>Status</kbd> that represents the status of the task:</p>
<pre>#[derive(Clone)]<br/>struct Record {<br/>    task_id: TaskId,<br/>    timestamp: DateTime&lt;Utc&gt;,<br/>    status: Status,<br/>}</pre>
<p><kbd>Status</kbd> is an enumeration that has two variants: <kbd>InProgress</kbd>, when a task is sent to a worker; and <kbd>Done</kbd>, when a worker returns a response as a <kbd>QrResponse</kbd> value:</p>
<pre>#[derive(Clone)]<br/>enum Status {<br/>    InProgress,<br/>    Done(QrResponse),<br/>}</pre>
<p>We need to implement the <kbd>Display</kbd> trait for <kbd>Status</kbd>, because we will use it to render the HTML template. Implement the trait:</p>
<pre>impl fmt::Display for Status {<br/>    fn fmt(&amp;self, f: &amp;mut fmt::Formatter) -&gt; fmt::Result {<br/>        match self {<br/>            Status::InProgress =&gt; write!(f, "in progress"),<br/>            Status::Done(resp) =&gt; match resp {<br/>                QrResponse::Succeed(data) =&gt; write!(f, "done: {}", data),<br/>                QrResponse::Failed(err) =&gt; write!(f, "failed: {}", err),<br/>            },<br/>        }<br/>    }<br/>}</pre>
<p>We will show three statuses: in progress, succeed, and failed.</p>
<p>Our server needs a shared state. We will use the <kbd>State</kbd> struct with a map of tasks and an address of <kbd>QueueActor</kbd> and <kbd>ServerHandler</kbd>:</p>
<pre>#[derive(Clone)]<br/>struct State {<br/>    tasks: SharedTasks,<br/>    addr: Addr&lt;QueueActor&lt;ServerHandler&gt;&gt;,<br/>}</pre>
<p>Now, we can implement <kbd>ServerHandler</kbd> and spawn an actor with it.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Server handler</h1>
                
            
            
                
<p>To consume responses from a worker, our server has to start <kbd>QueueActor</kbd> with a handler that will update the shared state of a server. Create a <kbd>ServerHandler</kbd> struct that keeps a copy of the <kbd>SharedTasks</kbd> reference:</p>
<pre>struct ServerHandler {<br/>    tasks: SharedTasks,<br/>}</pre>
<p>Implement the <kbd>QueueHandler</kbd> for this struct:</p>
<pre>impl QueueHandler for ServerHandler {<br/>    type Incoming = QrResponse;<br/>    type Outgoing = QrRequest;<br/><br/>    fn incoming(&amp;self) -&gt; &amp;str {<br/>        RESPONSES<br/>    }<br/>    fn outgoing(&amp;self) -&gt; &amp;str {<br/>        REQUESTS<br/>    }<br/>    fn handle(<br/>        &amp;self,<br/>        id: &amp;TaskId,<br/>        incoming: Self::Incoming,<br/>    ) -&gt; Result&lt;Option&lt;Self::Outgoing&gt;, Error&gt; {<br/>        self.tasks.lock().unwrap().get_mut(id).map(move |rec| {<br/>            rec.status = Status::Done(incoming);<br/>        });<br/>        Ok(None)<br/>    }<br/>}</pre>
<p>The handler of the server has to use the <kbd>RESPONSES</kbd> queue to consume responses, and <kbd>REQUESTS</kbd> as the outgoing queue to send requests. Correspondingly, set <kbd>QrResponse</kbd> to the <kbd>Incoming</kbd> type and <kbd>QrRequest</kbd> to the <kbd>Outgoing</kbd> type.</p>
<p>The <kbd>handle</kbd> method locks a <kbd>Mutex</kbd> stored in the <kbd>tasks</kbd> field to get access to <kbd>IndexMap</kbd> and update the <kbd>status</kbd> field of <kbd>Record</kbd> if the record exists for a corresponding task ID. The ID of the task will be automatically extracted by <kbd>QueueActor</kbd> and is provided to this method by an immutable reference. It's time to implement all the necessary HTTP handlers.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Requests handlers</h1>
                
            
            
                
<p>We need three handlers for requests: an index page to show the name of the microservice, a handler for rendering all tasks and their statuses, and an uploading handler for posing new tasks with QR codes.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Index handler</h1>
                
            
            
                
<p><kbd>index_handler</kbd> returns some text with the name of this microservice:</p>
<pre>fn index_handler(_: &amp;HttpRequest&lt;State&gt;) -&gt; HttpResponse {<br/>    HttpResponse::Ok().body("QR Parsing Microservice")<br/>}</pre>


            

            
        
    

        

                            
                    <h1 class="header-title">Tasks handler</h1>
                
            
            
                
<p><kbd>tasks_handler</kbd> locks a <kbd>Mutex</kbd> with <kbd>IndexMap</kbd> to iterate over all <kbd>Record</kbd> values to render them as a part of the <kbd>Tasks</kbd> struct:</p>
<pre>fn tasks_handler(req: HttpRequest&lt;State&gt;) -&gt; impl Future&lt;Item = HttpResponse, Error = WebError&gt; {<br/>    let tasks: Vec&lt;_&gt; = req<br/>        .state()<br/>        .tasks<br/>        .lock()<br/>        .unwrap()<br/>        .values()<br/>        .cloned()<br/>        .collect();<br/>    let tmpl = Tasks { tasks };<br/>    future::ok(HttpResponse::Ok().body(tmpl.render().unwrap()))<br/>}</pre>
<p>If you remember, we added the <kbd>askama</kbd> crate to render templates. Create a <kbd>templates</kbd> folder in the root of project and add a <kbd>tasks.html</kbd> file with some HTML code that contains at least the following rendering table:</p>
<pre>&lt;table&gt;<br/>    &lt;thead&gt;<br/>        &lt;tr&gt;<br/>            &lt;th&gt;Task ID&lt;/th&gt;<br/>            &lt;th&gt;Timestamp&lt;/th&gt;<br/>            &lt;th&gt;Status&lt;/th&gt;<br/>        &lt;/tr&gt;<br/>    &lt;/thead&gt;<br/>    &lt;tbody&gt;<br/>        {% for task in tasks %}<br/>        &lt;tr&gt;<br/>            &lt;td&gt;{{ task.task_id }}&lt;/td&gt;<br/>            &lt;td&gt;{{ task.timestamp }}&lt;/td&gt;<br/>            &lt;td&gt;{{ task.status }}&lt;/td&gt;<br/>        &lt;/tr&gt;<br/>        {% endfor %}<br/>    &lt;/tbody&gt;<br/>&lt;/table&gt;</pre>
<p>This is a part of the full template that you can find in the examples folder for this book, but the preceding code contains code for rendering a table with all the tasks extracted from the <kbd>Tasks</kbd> struct, which is  implemented as follows:</p>
<pre>#[derive(Template)]<br/>#[template(path = "tasks.html")]<br/>struct Tasks {<br/>    tasks: Vec&lt;Record&gt;,<br/>}</pre>
<p>Derive the <kbd>Template</kbd> type for this struct and attach the template with the <kbd>template</kbd> attribute. <kbd>askama</kbd> will embed the template into your code. That's very convenient.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Upload handler</h1>
                
            
            
                
<p><kbd>upload_handler</kbd> is a bit complex, because it takes POST requests with a form that contains the uploaded image:</p>
<pre>fn upload_handler(req: HttpRequest&lt;State&gt;) -&gt; impl Future&lt;Item = HttpResponse, Error = WebError&gt; {<br/>    req.multipart()<br/>        .map(handle_multipart_item)<br/>        .flatten()<br/>        .into_future()<br/>        .and_then(|(bytes, stream)| {<br/>            if let Some(bytes) = bytes {<br/>                Ok(bytes)<br/>            } else {<br/>                Err((MultipartError::Incomplete, stream))<br/>            }<br/>        })<br/>        .map_err(|(err, _)| WebError::from(err))<br/>        .and_then(move |image| {<br/>            debug!("Image: {:?}", image);<br/>            let request = QrRequest { image };<br/>            req.state()<br/>                .addr<br/>                .send(SendMessage(request))<br/>                .from_err()<br/>                .map(move |task_id| {<br/>                    let record = Record {<br/>                        task_id: task_id.clone(),<br/>                        timestamp: Utc::now(),<br/>                        status: Status::InProgress,<br/>                    };<br/>                    req.state().tasks.lock().unwrap().insert(task_id, record);<br/>                    req<br/>                })<br/>        })<br/>        .map(|req| {<br/>            HttpResponse::build_from(&amp;req)<br/>                .status(StatusCode::FOUND)<br/>                .header(header::LOCATION, "/tasks")<br/>                .finish()<br/>        })<br/>}</pre>
<p>The implementation gets a <kbd>Stream</kbd> of <kbd>MultipartItem</kbd>, the value of which could be either <kbd>Filed</kbd> or <kbd>Nested</kbd>. We use the following function to collect all items in a single uniform <kbd>Stream</kbd> of <kbd>Vec&lt;u8&gt;</kbd> objects:</p>
<pre>pub fn handle_multipart_item(<br/>    item: MultipartItem&lt;Payload&gt;,<br/>) -&gt; Box&lt;Stream&lt;Item = Vec&lt;u8&gt;, Error = MultipartError&gt;&gt; {<br/>    match item {<br/>        MultipartItem::Field(field) =&gt; {<br/>            Box::new(field.concat2().map(|bytes| bytes.to_vec()).into_stream())<br/>        }<br/>        MultipartItem::Nested(mp) =&gt; Box::new(mp.map(handle_multipart_item).flatten()),<br/>    }<br/>}</pre>
<p>Then, we extract the first item with the <kbd>into_future</kbd> method. If the value exists, we map it to <kbd>QrRequest</kbd> and use the address of <kbd>QueueActor</kbd> to <kbd>send</kbd> a request to a worker.</p>
<p>You may ask whether it is possible if a worker returns a result if the ID of task wasn't set. Potentially, it's possible. If you want to have a reliable changing of <kbd>State</kbd>, you should implement an actor that works with the <kbd>State</kbd> instance exclusively.</p>
<p>Finally, the handler constructs a <kbd>HttpResponse</kbd> value that redirects the client to the <kbd>/tasks</kbd> path.</p>
<p>Now, we can connect each part in a single function.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">main function</h1>
                
            
            
                
<p>We have already created functions that create app instances of <kbd>actix</kbd> in <a href="5b7dd2c1-d623-4422-83a7-e05681230ee9.xhtml">Chapter 11</a>, <em>In</em><em>volving Concurrency with Actors and Actix Crate</em>. Return to that chapter if you don't remember how to attach handlers and a state to an application, and look at the <kbd>main</kbd> function, as follows:</p>
<pre>fn main() -&gt; Result&lt;(), Error&gt; {<br/>    env_logger::init();<br/>    let mut sys = System::new("rabbit-actix-server");<br/>    let tasks = Arc::new(Mutex::new(IndexMap::new()));<br/>    let addr = QueueActor::new(<br/>        ServerHandler {<br/>            tasks: tasks.clone(),<br/>        },<br/>        &amp;mut sys,<br/>    )?;<br/><br/>    let state = State {<br/>        tasks: tasks.clone(),<br/>        addr,<br/>    };<br/>    server::new(move || {<br/>        App::with_state(state.clone())<br/>            .middleware(middleware::Logger::default())<br/>            .resource("/", |r| r.f(index_handler))<br/>            .resource("/task", |r| {<br/>                r.method(http::Method::POST).with_async(upload_handler);<br/>            })<br/>            .resource("/tasks", |r| r.method(http::Method::GET).with_async(tasks_handler))<br/>    })<br/>    .bind("127.0.0.1:8080")<br/>    .unwrap()<br/>    .start();<br/><br/>    let _ = sys.run();<br/>    Ok(())<br/>}</pre>
<p>This function creates a <kbd>System</kbd> instance with a new method that returns a <kbd>SystemRunner</kbd> instance, which we will use to start <kbd>QueueActor</kbd> with <kbd>ServerHandler</kbd> inside. Then, it creates a <kbd>State</kbd> instance with the address of the spawned actor and fills the <kbd>App</kbd> object with all the necessary handlers.</p>
<p>When we start a <kbd>SystemRunner</kbd>, it creates an actor and connects to RabbitMQ to create all the necessary queues and starts consuming the responses.</p>
<p>A good practice is to create the same queues from all the applications that use it, because you can't know which part will be started first—the server or the worker. That's why we implemented the creation of all the queues in the <kbd>new</kbd> method of <kbd>QueueAction</kbd>. All queues will be available before any piece of code uses them.</p>
<p>We are ready to test this example.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Testing</h1>
                
            
            
                
<p class="mce-root">Let's build and run the server and worker of the application. You should start a container with a RabbitMQ instance, as we did in this chapter in the <em>Bootstrap message broker for testing</em> section. Then, use <kbd>cargo build</kbd> to build all the parts.</p>
<p>When compilation has finished, start a server instance:</p>
<pre>RUST_LOG=rabbit_actix_server=debug ./target/debug/rabbit-actix-server</pre>
<p>Also, start a worker instance with the following command:</p>
<pre>RUST_LOG=rabbit_actix_worker=debug ./target/debug/rabbit-actix-worker</pre>
<p>When both parts have started, you can explore RabbitMQ with the <kbd>rabbitmqctl</kbd> command and explore your queues:</p>
<pre><strong>docker exec -it test-rabbit rabbitmqctl list_queues</strong></pre>
<p>It prints both the queues that were created by the actors:</p>
<pre>Timeout: 60.0 seconds ...<br/>Listing queues for vhost / ...<br/>responses    0<br/>requests    0</pre>
<p>If you want to see all connected consumers, you can do that with the following command:</p>
<pre><strong>docker exec -it test-rabbit rabbitmqctl list_consumers</strong></pre>
<p>It prints <kbd>responses-consumer</kbd>, which represents a server instance, and <kbd>requests-consumer</kbd>, which represents a worker instance:</p>
<pre class="mce-root">Listing consumers on vhost / ...<br/>responses  &lt;rabbit@f137a225a709.3.697.0&gt;  responses-consumer   true    0    []<br/>requests   &lt;rabbit@f137a225a709.3.717.0&gt;  requests-consumer    true    0    []</pre>
<p class="mce-root">Now that everything is connected to RabbitMQ, we can open <kbd>http://localhost:8080/tasks</kbd> in a browser. You will see an empty table and a form to upload a QR code. Choose a file and upload it using the form. It will refresh the page and you will see your task in progress:</p>
<p> </p>
<p class="CDPAlignCenter CDPAlign"><img src="img/d48e3f3d-fc8c-45ec-b298-d526a231ab5c.png"/></p>
<p>If the worker works properly and if you refresh the page after short period of time, you will see the decoded QR code:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/239f03f8-e6da-434f-81a2-598cf7ba722b.png"/></p>
<p>As you can see, the server and worker interact with a message that was delivered by RabbitMQ.</p>
<p>Let's discuss the benefits and drawbacks of this solution.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">How to scale this application</h1>
                
            
            
                
<p>The example we created in this chapter uses two parts that work separately and use RabbitMQ to exchange tasks and results.</p>
<p>Scaling this application is very easy—you just need to start as many workers as you want, and they don't have to work on the same server. You can run workers on a distributed cluster of servers. If your workers can't handle a load, you can start extra workers that will consume waiting tasks immediately and start the decoding process.</p>
<p>But this system has a potential bottleneck – the message broker. For this example, you can simply handle it if you start extra independent message brokers; for example, RabbitMQ support multiple instances with its clustering feature. Your server can have multiple connections with multiple message brokers, but you can't spawn as many servers as you want because they will have different sets of tasks.</p>
<p>Is it possible to share a list of tasks? Yes, you can use a traditional database or storage, such as Redis, but it becomes another bottleneck, because it's hard to use the same database instance for millions of clients.</p>
<p>How can we handle the bottleneck with a database? You can split the tasks list by client and keep the list for a specific client on one instance of storage. If you want to provide a feature where your clients share tasks with each other, you can create shared lists and store them in a database, which won't have a heavy load in this case.</p>
<p>As you can see, scaling is an undefined process, and you have to do some experimenting to achieve the desired result. But in any case, you should strive for separate tasks across microservices and use messages or RPCs to get loose coupling for your application, as well as good performance.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Summary</h1>
                
            
            
                
<p>In this chapter, we discussed the important topic of scalable microservices. We started with the basics and continued with implementing two services that use RabbitMQ as a message broker to interact with each other. The example we created decodes QR codes to be processed by a separate worker. The benefit of the implemented application is that you can start as many workers as you want.</p>
<p>In the next chapter, we will learn how to test and debug microservices using unit tests, integration tests, and debuggers.</p>


            

            
        
    </body></html>