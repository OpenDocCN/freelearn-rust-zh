<html><head></head><body>
		<div id="_idContainer025">
			<h1 id="_idParaDest-93" class="chapter-number"><a id="_idTextAnchor092"/>5</h1>
			<h1 id="_idParaDest-94"><a id="_idTextAnchor093"/>Creating Our Own Fibers</h1>
			<p>In this chapter, we take a deep dive into a very popular way of handling concurrency. There is no better way of getting a fundamental understanding of the subject than doing it yourself. Fortunately, even though the topic is a little complex, we only need around 200 lines of code to get a fully working example in <span class="No-Break">the end.</span></p>
			<p>What makes the topic complex is that it requires quite a bit of fundamental understanding of how CPUs, operating systems, and assembly work. This complexity is also what makes this topic so interesting. If you explore and work through this example in detail, you will be rewarded with an eye-opening understanding of topics you might only have heard about or only have a rudimentary understanding of. You will also get the chance to get to know a few aspects of the Rust language that you haven’t seen before, expanding your knowledge of both Rust and programming <span class="No-Break">in general.</span></p>
			<p>We start off by introducing a little background knowledge that we need before we start writing code. Once we have that in place, we’ll start with some small examples that will allow us to show and discuss the most technical and difficult parts of our example in detail so we can introduce the topics gradually. Lastly, we’ll build on the knowledge we’ve gained and create our main example, which is a working example of fibers implemented <span class="No-Break">in Rust.</span></p>
			<p>As a bonus, you’ll get two expanded versions of the example in the repository to inspire you to go on and change, adapt, and build upon what we’ve created to make it <span class="No-Break">your own.</span></p>
			<p>I’ll list the main topics here so you can refer to them <span class="No-Break">later on:</span></p>
			<ul>
				<li>How to use the repository alongside <span class="No-Break">the book</span></li>
				<li><span class="No-Break">Background information</span></li>
				<li>An example we can <span class="No-Break">build upon</span></li>
				<li><span class="No-Break">The stack</span></li>
				<li>Implementing our <span class="No-Break">own fibers</span></li>
				<li><span class="No-Break">Final thoughts</span></li>
			</ul>
			<p class="callout-heading">Note</p>
			<p class="callout">In this chapter, we’ll use the terms “fibers” and “green threads” to refer to this exact implementation of stackful coroutines. The term “threads” in this chapter, which is used in the code we write, will refer to the green threads/fibers we implement in our example and not <span class="No-Break">OS threads.</span></p>
			<h1 id="_idParaDest-95"><a id="_idTextAnchor094"/>Technical requirements</h1>
			<p>To run the examples, you will need a computer running on a CPU using the x86-64 instruction set. Most popular desktop, server, and laptop CPUs out there today use this instruction set, as do most modern CPUs from Intel and AMD (which are most CPU models from these manufacturers produced in the last <span class="No-Break">10–15 years).</span></p>
			<p>One caveat is that the modern M-series Macs use the ARM ISA (instruction set), which won’t be compatible with the examples we write here. However, older Intel-based Macs do, so you should be able to use a Mac to follow along if you don’t have the <span class="No-Break">latest version.</span></p>
			<p>If you don’t have a computer using this instruction set available, you have a few options to install Rust and run <span class="No-Break">the examples:</span></p>
			<ul>
				<li>Mac users on M-series chips can use Rosetta (which ships with newer MacOS versions) and get the examples working with just four simple steps. You’ll find the instructions in the repository <span class="No-Break">under </span><span class="No-Break"><strong class="source-inline">ch05/How-to-MacOS-M.md</strong></span><span class="No-Break">.</span></li>
				<li><a href="https://mac.getutm.app/">https://mac.getutm.app/</a><a href="https://mac.getutm.app/Rent"/> (some even have a free layer) a remote server running Linux on x86-64. I have experience with Linode’s offering (<a href="https://www.linode.com"/>/), but there are many more options <span class="No-Break">out there.</span></li>
			</ul>
			<p>To follow along with the examples in the book, you also need a Unix-based operating system. The example code will work natively on any Linux and BSD operating system (such as Ubuntu or macOS) as long as it’s running on an <span class="No-Break">x86-64 CPU.</span></p>
			<p>If you’re on Windows, there is a version of the example in the repository that works natively with Windows too, but to follow along with the book, my clear recommendation is to set up <strong class="bold">Windows Subsystem for Linux</strong> (<strong class="bold">WSL</strong>) (<a href="https://learn.microsoft.com/en-us/windows/wsl/install">https://learn.microsoft.com/en-us/windows/wsl/install</a>), install Rust, and follow along using Rust <span class="No-Break">on WSL.</span></p>
			<p>I personally use VS Code as my editor, as it makes it very easy to switch between using a Linux version on WSL and Windows—simply press <em class="italic">Ctrl</em> + <em class="italic">Shift</em> + <em class="italic">P</em> and search for <strong class="source-inline">the Reopen folder </strong><span class="No-Break"><strong class="source-inline">in WSL</strong></span><span class="No-Break">.</span></p>
			<h1 id="_idParaDest-96"><a id="_idTextAnchor095"/>How to use the repository alongside the book</h1>
			<p>The recommended way<a id="_idIndexMarker316"/> to read this chapter is to have the repository open alongside the book. In the repository, you’ll find three different folders that correspond to the examples we go through in <span class="No-Break">this chapter:</span></p>
			<ul>
				<li><span class="No-Break"><strong class="source-inline">ch05/a-stack swap</strong></span></li>
				<li><span class="No-Break"><strong class="source-inline">ch05/b-show-stack</strong></span></li>
				<li><span class="No-Break"><strong class="source-inline">ch05/c-fibers</strong></span></li>
			</ul>
			<p>In addition, you will get two more examples that I refer to in the book but that should be explored in <span class="No-Break">the repository:</span></p>
			<ul>
				<li><strong class="source-inline">ch05/d-fibers-closure</strong>: This is an extended version of the first example that might inspire you to do more complex things yourself. The example tries to mimic the API used in the Rust standard library <span class="No-Break">using </span><span class="No-Break"><strong class="source-inline">std::thread::spawn</strong></span><span class="No-Break">.</span></li>
				<li><strong class="source-inline">ch05/e-fibers-windows</strong>: This is a version of the example that we go through in this book that works on both Unix-based systems and Windows. There is a quite detailed explanation in the README of the changes we make for the example work on Windows. I consider this recommended reading if you want to dive deeper into the topic, but it’s not important to understand the main concepts we go through in <span class="No-Break">this chapter.</span></li>
			</ul>
			<h1 id="_idParaDest-97"><a id="_idTextAnchor096"/>Background information</h1>
			<p>We are going to interfere with and control the CPU directly. This is not very portable since there are many kinds of CPUs out there. While the overall implementation will be the same, there is a small but important part of the implementation that will be very specific to the CPU architecture we’re programming for. Another aspect that limits the portability of our code is that operating systems have different ABIs that we need to adhere to, and those same pieces of code will have to change based on the different ABIs. Let’s explain exactly what we mean here before we go further so we know we’re on the <span class="No-Break">same page.</span></p>
			<h2 id="_idParaDest-98"><a id="_idTextAnchor097"/>Instruction sets, hardware architectures, and ABIs</h2>
			<p>Okay, before <a id="_idIndexMarker317"/>we start, we need to know the differences between an <strong class="bold">application binary interface</strong> (<strong class="bold">ABI</strong>), a <strong class="bold">CPU architecture</strong>, and an <strong class="bold">instruction set architecture</strong> (<strong class="bold">ISA</strong>). We <a id="_idIndexMarker318"/>need this to write our own stack and make the <a id="_idIndexMarker319"/>CPU jump over to it. Fortunately, while this might sound complex, we only need to know a few specific things for our example to run. The information presented here is useful in many more circumstances than just our example, so it’s worthwhile to cover it in <span class="No-Break">some detail.</span></p>
			<p>An ISA describes an abstract model of a CPU that defines how the CPU is controlled by the software it runs. We often simply refer to this as the <em class="italic">instruction set</em>, and it defines what instructions the <a id="_idIndexMarker320"/>CPU can execute, what registers <a id="_idIndexMarker321"/>programmers can use, how the hardware manages memory, etc. Examples<a id="_idIndexMarker322"/> of ISAs are <strong class="bold">x86-64</strong>, <strong class="bold">x86</strong>, and the <strong class="bold">ARM ISA</strong> (used in Mac <span class="No-Break">M-series chips).</span></p>
			<p>ISAs are broadly classified into two subgroups, <strong class="bold">complex instruction set computers</strong> (<strong class="bold">CISC</strong>) and <strong class="bold">reduced instruction set computers</strong> (<strong class="bold">RISC</strong>), based<a id="_idIndexMarker323"/> on their complexity. CISC<a id="_idIndexMarker324"/> architectures offer a lot of different instructions that the hardware must know how to execute, resulting in some instructions that are very specialized and rarely used by programs. RISC architectures accept fewer instructions but require some operations to be handled by software that could be directly handled by the hardware in a CISC architecture. The x86-64 instruction set we’ll focus on is an example of a <span class="No-Break">CISC architecture.</span></p>
			<p>To add a little complexity (you know, it’s not fun if it’s too easy), there are different names that refer to the same ISA. For example, the x86-64 instruction set is also referred to as the AMD64 instruction set and the Intel 64 instruction set, so no matter which one you encounter, just know that they refer to the same thing. In our book, we’ll simply call it the x86-64 <span class="No-Break">instruction set.</span></p>
			<p class="callout-heading">Tip</p>
			<p class="callout">To find the architecture on your current system, run one of the following commands in <span class="No-Break">your terminal:</span></p>
			<p class="callout">On Linux and MacOS: <strong class="source-inline">arch</strong> or <span class="No-Break"><strong class="source-inline">uname -m</strong></span></p>
			<p class="callout">On Windows <span class="No-Break">PowerShell: </span><span class="No-Break"><strong class="source-inline">$env:PROCESSOR_ARCHITECTURE</strong></span></p>
			<p class="callout">On Windows Command Prompt: <span class="No-Break"><strong class="source-inline">echo %PROCESSOR_ARCHITECTURE%</strong></span></p>
			<p>The instruction set just defines how a program can interface with the CPU. The concrete implementation of an ISA can vary between different manufacturers, and a specific implementation is referred to as a CPU architecture, such as Intel Core processors. However, in practice, these terms are often used interchangeably since they all perform the same functions from a programmer’s perspective and there is seldom a need to target a specific implementation of <span class="No-Break">an ISA.</span></p>
			<p>The ISA specifies the minimum set of instructions the CPU must be able to execute. Over time, there have been extensions to this instruction set, such as <strong class="bold">Streaming SIMD Extensions</strong> (<strong class="bold">SSE</strong>), that <a id="_idIndexMarker325"/>add more instructions and registers that programmers can take <span class="No-Break">advantage of.</span></p>
			<p>For the examples in this chapter, we will target the x86-64 ISA, a popular architecture used in most desktop computers and <span class="No-Break">servers today.</span></p>
			<p>So, we know that a processor architecture presents an interface that programmers can use. Operating system implementors use this infrastructure to create <span class="No-Break">operating systems.</span></p>
			<p>Operating systems such as Windows and Linux define an ABI that specifies a set of rules that the programmer has to adhere to for their programs to work correctly on that platform. Examples of operating <a id="_idIndexMarker326"/>system ABI’s are <strong class="bold">System V ABI</strong> (Linux) and <strong class="bold">Win64</strong> (Windows). The <a id="_idIndexMarker327"/>ABI specifies how the operating system expects a stack to be set up, how you should call a function, how you create a file that will load and run as a program, the name of the function that will be called once the program has <span class="No-Break">loaded, etc.</span></p>
			<p>A very important part of the ABI that operating systems must specify is its <strong class="bold">calling convention</strong>. The <a id="_idIndexMarker328"/>calling convention defines how the stack is used and how functions <span class="No-Break">are called.</span></p>
			<p>Let’s illustrate this with an example of how Linux and Windows handle arguments to a function on x86-64; for example, a function with a signature such as <strong class="source-inline">fn foo(a: i64, </strong><span class="No-Break"><strong class="source-inline">b: i64)</strong></span><span class="No-Break">.</span></p>
			<p>The x86-64 ISA defines 16 general-purpose registers. These are registers the CPU provides for programmers to use for whatever they see fit. Note that <em class="italic">programmers</em> here include the ones that write the operating system, and they can lay additional restrictions on what registers you can use for what when you create a program to run on their operating system. In our specific example, Windows and Unix-based systems have different requirements for where to place the arguments for <span class="No-Break">a function:</span></p>
			<ul>
				<li>Linux specifies that a function that takes two arguments should place the first argument to the function in the <strong class="source-inline">rdi</strong> register and the second one in the <span class="No-Break"><strong class="source-inline">rsi</strong></span><span class="No-Break"> register</span></li>
				<li>Windows requires that the first two arguments be passed in the registers <strong class="source-inline">rcx</strong> <span class="No-Break">and </span><span class="No-Break"><strong class="source-inline">rdx</strong></span></li>
			</ul>
			<p>This is just one of many ways in which a program that is written for one platform won’t work on another. Usually, these details are the concern of compiler developers, and the compiler will handle the different calling conventions when you compile for a <span class="No-Break">specific platform.</span></p>
			<p>So to sum it up, CPUs implement an instruction set. The instruction set defines what instructions the CPU can execute and the infrastructure it should provide to programmers (such as registers). An operating system uses this infrastructure in different ways, and it provides additional rules that a programmer must obey to run their program correctly on their platform. Most of the time, the only programmers that need to care about these details are the ones who write operating systems or compilers. However, when we write low-level code ourselves, we need to know about the ISA <em class="italic">and</em> the OS ABI to have our code <span class="No-Break">work correctly.</span></p>
			<p>Since we need to write this kind of code to implement our own fibers/green threads, we must potentially write different code for each OS ABI/ISA combination that exists. That means one for Windows/x86-64, one for Windows/ARM, one for MacOS/x86-64, one for <span class="No-Break">Macos/M, etc.</span></p>
			<p>As you understand, this<a id="_idIndexMarker329"/> is also one major contributor to the complexity of using fibers/green threads for handling concurrency. It has a lot of advantages once it’s correctly implemented for an ISA/OS ABI combination, but it requires a lot of work to get <span class="No-Break">it right.</span></p>
			<p>For the purpose of the examples in this book, we will only focus on one such combination: the System V ABI <span class="No-Break">for x86-64.</span></p>
			<p class="callout-heading">Note!</p>
			<p class="callout">In the accompanying repository, you will find a version of the main example for this chapter for Windows x86-64. The changes we have to make to make it work on Windows are explained in <span class="No-Break">the README.</span></p>
			<h2 id="_idParaDest-99"><a id="_idTextAnchor098"/>The System V ABI for x86-64</h2>
			<p>As <a id="_idIndexMarker330"/>mentioned earlier, this architecture of the CPU features a set of 16 general-purpose 64-bit registers, 16 SSE registers with 128-bit width, and 8 floating point registers with <span class="No-Break">80-bit width:</span></p>
			<p class="IMG---Figure"> </p>
			<div>
				<div id="_idContainer022" class="IMG---Figure">
					<img src="image/B20892_05_1.jpg" alt="Figure 5.1 – x86-64 CPU registers"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.1 – x86-64 CPU registers</p>
			<p>There are <a id="_idIndexMarker331"/>architectures that build upon this base and extend it, such as the<a id="_idIndexMarker332"/> Intel <strong class="bold">Advanced Vector Extensions</strong> (<strong class="bold">AVX</strong>), which provide an additional 16 registers of 256 bits in width. Let’s take a look at a page from the System V <span class="No-Break">ABI specification:</span></p>
			<div>
				<div id="_idContainer023" class="IMG---Figure">
					<img src="image/B20892_05_2.jpg" alt="Figure 5.2 – Register usage"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.2 – Register usage</p>
			<p><span class="No-Break"><em class="italic">Figure 5</em></span><em class="italic">.1</em> shows<a id="_idIndexMarker333"/> an overview of the general-purpose registers in the x86-64 architecture. Out of special interest for us right now are the registers marked as <em class="italic">callee saved</em>. These<a id="_idIndexMarker334"/> are the registers we need to keep track of our context across function calls. It includes the next instructions to run, the base pointer, the stack pointer, and so on. While the registers themselves are defined by the ISA, the rules on what is considered callee saved are defined by the System V ABI. We’ll get to know this more in <span class="No-Break">detail later.</span></p>
			<p class="callout-heading">Note</p>
			<p class="callout">Windows has a slightly different convention. On Windows, the register XMM6:XMM15 is also calle-saved and must be saved and restored if our functions use them. The code we write in this first example runs fine on Windows since we don’t really adhere to any ABI yet and just focus on how we’ll instruct the CPU to do what <span class="No-Break">we want.</span></p>
			<p>If we want to<a id="_idIndexMarker335"/> issue a very specific set of commands to the CPU directly, we need to write small pieces of code in assembly. Fortunately, we only need to know some very basic assembly instructions for our first mission. Specifically, we need to know how to move values to and <span class="No-Break">from registers:</span></p>
			<pre class="console">
mov rax, rsp</pre>			<h2 id="_idParaDest-100"><a id="_idTextAnchor099"/>A quick introduction to Assembly language</h2>
			<p>First and foremost, <strong class="bold">Assembly</strong> language<a id="_idIndexMarker336"/> isn’t particularly portable since it’s the lowest level of human-readable instructions we can write to the CPU, and the instructions we write in assembly will vary from architecture to architecture. Since we will only write assembly targeting the x86-64 architecture going forward, we only need to learn a few instructions for this <span class="No-Break">particular architecture.</span></p>
			<p>Before we go too deep into <a id="_idIndexMarker337"/>the specifics, you need to know that there are two popular dialects <a id="_idIndexMarker338"/>used in assembly: the <strong class="bold">AT&amp;T dialect</strong> and the <span class="No-Break"><strong class="bold">Intel dialect</strong></span><span class="No-Break">.</span></p>
			<p>The Intel dialect is the standard when writing inline assembly in Rust, but in Rust, we can specify that we want to use the AT&amp;T dialect instead if we want to. Rust has its own take on how to do inline assembly that at first glance looks foreign to anyone used to inline assembly in C. It’s well thought through though, and I’ll spend a bit of time explaining it in more detail as we go through the code, so both readers with experience with the C-type inline assembly and readers who have no experience should be able to <span class="No-Break">follow along.</span></p>
			<p class="callout-heading">Note</p>
			<p class="callout">We will use the Intel dialect in <span class="No-Break">our examples.</span></p>
			<p>Assembly has strong backward compatibility guarantees. That’s why you will see that the same registers are addressed in different ways. Let’s look at the rax register we used as an example as <span class="No-Break">an explanation:</span></p>
			<pre class="console">
rax    # 64 bit register (8 bytes)
eax    # 32 low bits of the "rax" register
ax     # 16 low bits of the "rax" register
ah     # 8 high bits of the "ax" part of the "rax" register
al     # 8 low bits of the "ax" part of the "rax" register</pre>			<p>As you can see, this is basically like watching the history of CPUs evolve in front of us. Since most CPUs today are 64 bits, we will use the 64-bit versions in <span class="No-Break">our code.</span></p>
			<p>The word size<a id="_idIndexMarker339"/> in the assembly also has historical reasons. It stems from the time when the CPU had 16-bit data buses, so a word is 16 bits. This is relevant because you will see many instructions suffixed with <strong class="source-inline">q</strong> (quad word) or <strong class="source-inline">l</strong> (long word). So, a <strong class="source-inline">movq</strong> would mean a move of 4 * 16 bits, which is <span class="No-Break">64 bits.</span></p>
			<p>A plain <strong class="source-inline">mov</strong> will use the size of the register you target on most modern assemblers. This is the one you will see most used in both AT&amp;T and the Intel dialect when writing inline assembly, and it’s the one we will use in <span class="No-Break">our code.</span></p>
			<p>One more thing to note is that<a id="_idIndexMarker340"/> the <strong class="bold">stack alignment</strong> on x86-64 is 16 bytes. Just remember this <span class="No-Break">for later.</span></p>
			<h1 id="_idParaDest-101"><a id="_idTextAnchor100"/>An example we can build upon</h1>
			<p>This is a short example where we will create our own stack and make our CPU return out of its current execution context and over to the stack we just created. We will build on these concepts in the <span class="No-Break">following chapters.</span></p>
			<h2 id="_idParaDest-102"><a id="_idTextAnchor101"/>Setting up our project</h2>
			<p>First, let’s start a <a id="_idIndexMarker341"/>new project by creating a folder named <strong class="source-inline">a-stack-swap</strong>. Enter the new folder and run <span class="No-Break">the following:</span></p>
			<pre class="source-code">
cargo init</pre>			<p class="callout-heading">Tip</p>
			<p class="callout">You can also navigate to the folder called <strong class="source-inline">ch05/a-stack-swap</strong> in the accompanying repository and see the whole <span class="No-Break">example there.</span></p>
			<p>In our <strong class="source-inline">main.rs</strong>, we start by importing the <span class="No-Break"><strong class="source-inline">asm!</strong></span><span class="No-Break"> macro:</span></p>
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">ch05/a-stack-swap/src/main.rs</p>
			<pre class="source-code">
use core::arch::asm;</pre>			<p>Let’s set a<a id="_idIndexMarker342"/> small stack size of only 48 bytes here so that we can print the stack and look at it before we switch contexts after we get the first example <span class="No-Break">to work:</span></p>
			<pre class="source-code">
const SSIZE: isize = 48;</pre>			<p class="callout-heading">Note</p>
			<p class="callout">There seems to be an issue in macOS using such a small stack. The minimum for this code to run is a stack size of 624 bytes. The code works on the Rust Playground, at <a href="https://play.rust-lang.org">https://play.rust-lang.org</a>, if you want to follow this exact example (however, you’ll need to wait roughly 30 seconds for it to time out due to our loop in <span class="No-Break">the end).</span></p>
			<p>Then let’s add a struct that represents our CPU state. We’ll only focus on the register that stores the stack pointer for now since that is all <span class="No-Break">we need:</span></p>
			<pre class="source-code">
#[derive(Debug, Default)]
#[repr(C)]
struct ThreadContext {
    rsp: u64,
}</pre>			<p>In later examples, we will use all the registers marked as <em class="italic">callee saved</em> in the specification document I linked to. These are the registers described in the System V x86-64 ABI that we’ll need to save our context, but right now, we only need one register to make the CPU jump over to <span class="No-Break">our stack.</span></p>
			<p>Note that this needs to be <strong class="source-inline">#[repr(C)]</strong> because of how we access the data in our assembly. Rust doesn’t have a stable language ABI, so there is no way for us to be sure that this will <a id="_idIndexMarker343"/>be represented in memory with <strong class="source-inline">rsp</strong> as the first 8 bytes. C has a stable language ABI and that’s exactly what this attribute tells the compiler to use. Granted, our struct only has one field right now, but we will add <span class="No-Break">more later.</span></p>
			<p>For this very simple example, we will define a function that just prints out a message and then <span class="No-Break">loops forever:</span></p>
			<pre class="source-code">
fn hello() -&gt; ! {
    println!("I LOVE WAKING UP ON A NEW STACK!");
    loop {}
}</pre>			<p>Next up is our inline assembly, where we switch over to our <span class="No-Break">own stack:</span></p>
			<pre class="source-code">
unsafe fn gt_switch(new: *const ThreadContext) {
    asm!(
        "mov rsp, [{0} + 0x00]",
        "ret",
        in(reg) new,
    );
}</pre>			<p>At first glance, you might think that there is nothing special about this piece of code, but let’s stop and consider what happens here for <span class="No-Break">a moment.</span></p>
			<p>If we refer back to <span class="No-Break"><em class="italic">Figure 5</em></span><em class="italic">.1</em>, we’ll see that <strong class="source-inline">rsp</strong> is the register that stores the <strong class="bold">stack pointer</strong> that the CPU uses to figure out the current location on <span class="No-Break">the stack.</span></p>
			<p>Now, what we actually want to do if we want the CPU to swap to a different stack is to set the register for the stack pointer (<strong class="source-inline">rsp</strong>) to the top of our new stack and set the instruction pointer (<strong class="source-inline">rip</strong>) on the CPU to point to the <span class="No-Break">address </span><span class="No-Break"><strong class="source-inline">hello</strong></span><span class="No-Break">.</span></p>
			<p>The instruction pointer, or program counter as it’s sometimes called on different architectures, points to the <em class="italic">next</em> instruction to run. If we can manipulate it directly, the CPU would fetch the instruction pointed to by the <strong class="source-inline">rip</strong> register and execute the first instruction we wrote in our <strong class="source-inline">hello</strong> function. The CPU will then push/pop data on the new stack using the address pointed to by the stack pointer and simply leave our old stack as <span class="No-Break">it was.</span></p>
			<p>Now, this is where it gets a little difficult. On the x86-64 instruction set, there is no way for us to manipulate <strong class="source-inline">rip</strong> directly, so we have to use a <span class="No-Break">little trick.</span></p>
			<p>The first <a id="_idIndexMarker344"/>thing we do is set up the new stack and write the address to the function we want to run at a 16-byte offset from the top of the stack (the ABI dictates a 16-byte stack alignment, so the top of our stack frame must start at a 16-byte offset). We’ll see how to create a continuous piece of memory a little later, but it’s a rather <span class="No-Break">straightforward process.</span></p>
			<p>Next, we pass the address of the first byte in which we stored this address on our newly created stack to the <strong class="source-inline">rsp</strong> register (the address we set to <strong class="source-inline">new.rsp</strong> will point to an address located on our own stack, which in turn is an address that leads to the <strong class="source-inline">hello</strong> function). <span class="No-Break">Got it?</span></p>
			<p>The <strong class="source-inline">ret</strong> keyword transfers program control to what would normally be the return address located on top of the stack frame it’s currently in. Since we placed the address to <strong class="source-inline">hello</strong> on our new stack and set the <strong class="source-inline">rsp</strong> register to point to our new stack, the CPU will think <strong class="source-inline">rsp</strong> now points to the return address of the function it’s currently running, but instead, it’s pointing to a location on our <span class="No-Break">new stack.</span></p>
			<p>When the CPU executes the <strong class="source-inline">ret</strong> instruction it will pop the first value of the stack (which is conveniently the address to our <strong class="source-inline">hello</strong> function) and place that address in the rip register for us. On the next cycle, the CPU will fetch the instructions located at that function pointer and start executing those instructions. Since <strong class="source-inline">rsp</strong> now points to our new stack, it will use that stack <span class="No-Break">going forward.</span></p>
			<p class="callout-heading">Note</p>
			<p class="callout">If you feel a little confused right now, that’s very understandable. These details are hard to understand and get right, and it takes time to get comfortable with how it works. As we’ll see later in this chapter, there is a little more data that we need to save and restore (right now, we don’t have a way to resume the stack we just swapped from), but the technical details on how the stack swap happens are the same as <span class="No-Break">described previously.</span></p>
			<p>Before we explain how we set up the new stack, we’ll use this opportunity to go line by line and explain how the inline assembly <span class="No-Break">macro works.</span></p>
			<h2 id="_idParaDest-103"><a id="_idTextAnchor102"/>An introduction to Rust inline assembly macro</h2>
			<p>We’ll use <a id="_idIndexMarker345"/>the body of our <strong class="source-inline">gt_switch</strong> function as a starting point by going through everything step <span class="No-Break">by step.</span></p>
			<p>If you haven’t used inline assembly before, this might look foreign, but we’ll use an extended version of the example later to switch contexts, so we need to understand what’s <span class="No-Break">going on.</span></p>
			<p><strong class="source-inline">unsafe</strong> is a keyword that indicates that Rust cannot enforce the safety guarantees in the function we write. Since we are manipulating the CPU directly, this is most definitely unsafe. The function will also take a pointer to an instance of our <strong class="source-inline">ThreadContext</strong> from which we will only read <span class="No-Break">one field:</span></p>
			<pre class="console">
unsafe gt_switch(new: *const ThreadContext)</pre>			<p>The next line is the <strong class="source-inline">asm!</strong> macro in the Rust standard library. It will check our syntax and provide an error message if it encounters something that doesn’t look like valid Intel (by default) <span class="No-Break">assembly syntax.</span></p>
			<pre class="source-code">
asm!(</pre>			<p>The first thing the macro takes as input is the <span class="No-Break">assembly template:</span></p>
			<pre class="source-code">
"mov rsp, [{0} + 0x00]",</pre>			<p>This is a simple instruction that moves the value stored at <strong class="source-inline">0x00</strong> offset (that means no offset at all in hex) from the memory location at <strong class="source-inline">{0}</strong> to the <strong class="source-inline">rsp</strong> register. Since the <strong class="source-inline">rsp</strong> register usually stores a pointer to the most recently pushed value on the stack, we effectively push the address to <strong class="source-inline">hello</strong> on top of the current stack so that the CPU will return to that address instead of resuming where it left off in the previous <span class="No-Break">stack frame.</span></p>
			<p class="callout-heading">Note</p>
			<p class="callout">Note that we don’t need to write <strong class="source-inline">[{0} + 0x00]</strong> when we don’t want an offset from the memory location. Writing <strong class="source-inline">mov rsp, [{0}]</strong> would be perfectly fine. However, I chose to introduce how we do an offset here as we’ll need it later on when we want to access more fields in our <span class="No-Break"><strong class="source-inline">ThreadContext</strong></span><span class="No-Break"> struct.</span></p>
			<p>Note that the <strong class="bold">Intel syntax</strong> is a<a id="_idIndexMarker346"/> little backward. You might be tempted to think <strong class="source-inline">mov a, b</strong> means “move what’s at <strong class="source-inline">a</strong> to <strong class="source-inline">b</strong>”, but the Intel dialect usually dictates that the destination register is first and the source <span class="No-Break">is second.</span></p>
			<p>To make this<a id="_idIndexMarker347"/> confusing, this is the opposite of what’s typically the case with<a id="_idIndexMarker348"/> the <strong class="bold">AT&amp;T syntax</strong>, where reading it as “move <strong class="source-inline">a</strong> to <strong class="source-inline">b</strong>” is the correct thing to do. This is one of the fundamental differences between the two dialects, and it’s useful to be <span class="No-Break">aware of.</span></p>
			<p>You will not see <strong class="source-inline">{0}</strong> used like this in normal assembly. This is part of the assembly template and is a placeholder for the value passed as the first parameter to the macro. You’ll notice that this closely matches how string templates are formatted in Rust using <strong class="source-inline">println!</strong> or the like. The parameters are numbered in ascending order starting from 0. We only have one input parameter here, which corresponds <span class="No-Break">to </span><span class="No-Break"><strong class="source-inline">{0}</strong></span><span class="No-Break">.</span></p>
			<p>You don’t really have to index your parameters like this; writing <strong class="source-inline">{}</strong> in the correct order would suffice (as you would do using the <strong class="source-inline">println!</strong> macro). However, using an index improves readability and I would strongly recommend doing it <span class="No-Break">that way.</span></p>
			<p>The <strong class="source-inline">[]</strong> basically means “get what’s at this memory location”, you can think of it as the same as dereferencing <span class="No-Break">a pointer.</span></p>
			<p>Let’s try to sum up what we do here <span class="No-Break">with words:</span></p>
			<p>Move what’s at the <strong class="source-inline">+ 0x00</strong> offset from the memory location that <strong class="source-inline">{compiler_chosen_general_purpose_register}</strong> points to to the <span class="No-Break"><strong class="source-inline">rsp</strong></span><span class="No-Break"> register.</span></p>
			<p>The next line is the <strong class="source-inline">ret</strong> keyword, which instructs the CPU to pop a memory location off the stack and then makes an unconditional jump to that location. In effect, we have hijacked our CPU and made it return to <span class="No-Break">our stack.</span></p>
			<p>Next up is the first non-assembly argument to the <strong class="source-inline">asm!</strong> macro is our <span class="No-Break">input parameter:</span></p>
			<pre class="source-code">
in(reg) new,</pre>			<p>When we write <strong class="source-inline">in(reg)</strong>, we let the compiler decide on a general-purpose register to store the value of <strong class="source-inline">new</strong>. <strong class="source-inline">out(reg)</strong> means that the register is an output, so if we write <strong class="source-inline">out(reg) new</strong>, we need <strong class="source-inline">new</strong> to be <strong class="source-inline">mut</strong> so we can write a value to it. You’ll also find other versions such as <strong class="source-inline">inout</strong> <span class="No-Break">and </span><span class="No-Break"><strong class="source-inline">lateout</strong></span><span class="No-Break">.</span></p>
			<h3>Options</h3>
			<p>The last <a id="_idIndexMarker349"/>thing we need to introduce to get a minimal understanding of Rust’s inline assembly for now is the <strong class="source-inline">options</strong> keyword. After the input and output parameters, you’ll often see something like <strong class="source-inline">options(att_syntax)</strong>, which specifies that the assembly is written with the AT&amp;T syntax instead of the Intel syntax. Other options include <strong class="source-inline">pure</strong>, <strong class="source-inline">nostack</strong>, and <span class="No-Break">several others.</span></p>
			<p>I’ll refer you to the documentation for you to read about them since they’re explained in <span class="No-Break">detail there:</span></p>
			<p><a href="https://doc.rust-lang.org/nightly/reference/inline-assembly.html#options"><span class="No-Break">https://doc.rust-lang.org/nightly/reference/inline-assembly.html#options</span></a></p>
			<p>Inline assembly is quite complex, so we’ll take this step by step and introduce more details on how it works along the way through <span class="No-Break">our examples.</span></p>
			<h2 id="_idParaDest-104"><a id="_idTextAnchor103"/>Running our example</h2>
			<p>The last bit we <a id="_idIndexMarker350"/>need is the main function to run our example. I’ll present the whole function and we’ll walk through it step <span class="No-Break">by step:</span></p>
			<pre class="source-code">
fn main() {
    let mut ctx = ThreadContext::default();
    let mut stack = vec![0_u8; SSIZE as usize];
    unsafe {
        let stack_bottom = stack.as_mut_ptr().offset(SSIZE);
        let sb_aligned = (stack_bottom as usize &amp; !15) as *mut u8;
        std::ptr::write(sb_aligned.offset(-16) as *mut u64, hello as u64);
        ctx.rsp = sb_aligned.offset(-16) as u64;
        gt_switch(&amp;mut ctx);
    }
}</pre>			<p>So, in this function, we’re actually creating our new stack. <strong class="source-inline">hello</strong> is a pointer already (a function pointer), so we can cast it directly as an <strong class="source-inline">u64</strong> since all pointers on 64-bit systems <a id="_idIndexMarker351"/>will be, well, 64-bit. Then, we write this pointer to our <span class="No-Break">new stack.</span></p>
			<p class="callout-heading">Note</p>
			<p class="callout">We’ll talk more about the stack in the next segment, but one thing we need to know now is that the stack grows downwards. If our 48-byte stack starts at index <strong class="source-inline">0</strong> and ends on index <strong class="source-inline">47</strong>, index <strong class="source-inline">32</strong> will be the first index of a 16-byte offset from the start/base of <span class="No-Break">our stack.</span></p>
			<p>Make note that we write the pointer to an offset of 16 bytes from the base of <span class="No-Break">our stack.</span></p>
			<p class="callout-heading">What does the line let sb_aligned = (stack_bottom as usize &amp;! 15) as *mut u8; do?</p>
			<p class="callout">When we ask for memory like we do when creating a <strong class="source-inline">Vec&lt;u8&gt;</strong>, there is no guarantee that the memory we get is 16-byte-aligned when we get it. This line of code essentially rounds our memory address down to the nearest 16-byte-aligned address. If it’s already 16 byte-aligned, it does nothing. This way, we know that we end up at a 16-byte-aligned address if we simply subtract 16 from the base of <span class="No-Break">our stack.</span></p>
			<p>We cast the address to <strong class="source-inline">hello</strong> as a pointer to a <strong class="source-inline">u64</strong> instead of a pointer to a <strong class="source-inline">u8</strong>. We want to write to position “32, 33, 34, 35, 36, 37, 38, 39”, which is the 8-byte space we need to store our <strong class="source-inline">u64</strong>. If we don’t do this cast, we try to write a <strong class="source-inline">u64</strong> only to position 32, which is not what <span class="No-Break">we want.</span></p>
			<p>When we run the example by writing <strong class="source-inline">cargo run</strong> in our terminal, <span class="No-Break">we get:</span></p>
			<pre class="console">
Finished dev [unoptimized + debuginfo] target(s) in 0.58s
Running `target\debug\a-stack-swap`
I LOVE WAKING UP ON A NEW STACK!</pre>			<p class="callout-heading">Tip</p>
			<p class="callout">As we end the program in an endless loop, you’ll have to exit by pressing <em class="italic">Ctrl</em> +<em class="italic"> </em><span class="No-Break"><em class="italic">C</em></span><span class="No-Break">.</span></p>
			<p>OK, so what happened? We didn’t call the function <strong class="source-inline">hello</strong> at any point, but it <span class="No-Break">still executed.</span></p>
			<p>What <a id="_idIndexMarker352"/>happened is that we actually made the CPU jump over to our own stack, and since it thinks it returns from a function, it will read the address to <strong class="source-inline">hello</strong> and start executing the instructions it points to. We have taken the first step toward implementing a <span class="No-Break">context switch.</span></p>
			<p>In the next sections, we will talk about the stack in a bit more detail before we implement our fibers. It will be easier now that we have covered so much of <span class="No-Break">the basics.</span></p>
			<h1 id="_idParaDest-105"><a id="_idTextAnchor104"/>The stack</h1>
			<p>A stack is <a id="_idIndexMarker353"/>nothing more than a piece of <span class="No-Break">contiguous memory.</span></p>
			<p>This is important to know. A computer only has memory, it doesn’t have a special stack memory and a heap memory; it’s all part of the <span class="No-Break">same memory.</span></p>
			<p>The difference is how this memory is accessed and used. The stack supports simple push/pop instructions on a contiguous part of memory, that’s what makes it fast to use. The heap memory is allocated by a memory allocator on demand and can be scattered around in <span class="No-Break">different locations.</span></p>
			<p>We’ll not go through the differences between the stack and the heap here since there are numerous articles explaining them in detail, including a chapter in <em class="italic">The Rust Programming Language</em> <span class="No-Break">at </span><a href="https://doc.rust-lang.org/stable/book/ch04-01-what-is-ownership.html#the-stack-and-the-heap"><span class="No-Break">https://doc.rust-lang.org/stable/book/ch04-01-what-is-ownership.html#the-stack-and-the-heap</span></a><span class="No-Break">.</span></p>
			<h2 id="_idParaDest-106"><a id="_idTextAnchor105"/>What does the stack look like?</h2>
			<p>Let’s start with a<a id="_idIndexMarker354"/> simplified view of the stack. A 64-bit CPU will read 8 bytes at a time. Even though the natural way for us to see a stack is a long line of <strong class="source-inline">u8</strong> as shown in <span class="No-Break"><em class="italic">Figure 5</em></span><em class="italic">.2</em>, the CPU will treat it more like a long line of <strong class="source-inline">u64</strong> instead since it won’t be able to read less than 8 bytes when it makes a load or <span class="No-Break">a store.</span></p>
			<div>
				<div id="_idContainer024" class="IMG---Figure">
					<img src="image/B20892_05_3.jpg" alt="Figure 5.3 – The stack"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.3 – The stack</p>
			<p>When we pass a <a id="_idIndexMarker355"/>pointer, we need to make sure we pass in a pointer to either address <strong class="source-inline">0016</strong>, <strong class="source-inline">0008</strong>, or <strong class="source-inline">0000</strong> in <span class="No-Break">the example.</span></p>
			<p>The stack grows downwards, so we start at the top and work our <span class="No-Break">way down.</span></p>
			<p>When we <a id="_idIndexMarker356"/>set the <strong class="bold">stack pointer</strong> in a 16-byte aligned stack, we need to make sure to put our stack pointer to an address that is a <em class="italic">multiple</em> of 16. In the example, the only address that satisfies this requirement is <strong class="source-inline">0008</strong> (remember the stack starts on <span class="No-Break">the top).</span></p>
			<p>If we add the following lines of code to our example in the last chapter just before we do the switch <a id="_idIndexMarker357"/>in our <strong class="source-inline">main</strong> function, we can effectively print out our stack and have a look <span class="No-Break">at it:</span></p>
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">ch05/b-show-stack</p>
			<pre class="source-code">
for i in 0..SSIZE {
    println!("mem: {}, val: {}",
    sb_aligned.offset(-i as isize) as usize,
    *sb_aligned.offset(-i as isize))
}</pre>			<p>The output we get is <span class="No-Break">as follows:</span></p>
			<pre class="console">
mem: 2643866716720, val: 0
mem: 2643866716719, val: 0
mem: 2643866716718, val: 0
mem: 2643866716717, val: 0
mem: 2643866716716, val: 0
mem: 2643866716715, val: 0
mem: 2643866716714, val: 0
mem: 2643866716713, val: 0
mem: 2643866716712, val: 0
mem: 2643866716711, val: 0
mem: 2643866716710, val: 0
mem: 2643866716709, val: 127
mem: 2643866716708, val: 247
mem: 2643866716707, val: 172
mem: 2643866716706, val: 15
mem: 2643866716705, val: 29
mem: 2643866716704, val: 240
mem: 2643866716703, val: 0
mem: 2643866716702, val: 0
mem: 2643866716701, val: 0
mem: 2643866716700, val: 0
mem: 2643866716699, val: 0
...
mem: 2643866716675, val: 0
mem: 2643866716674, val: 0
mem: 2643866716673, val: 0
I LOVE WAKING UP ON A NEW STACK!</pre>			<p>I’ve printed <a id="_idIndexMarker358"/>out the memory addresses as <strong class="source-inline">u64</strong> here, so it’s easier to parse if you’re not very familiar <span class="No-Break">with hex.</span></p>
			<p>The first thing to note is that this is just a contiguous piece of memory, starting at address <strong class="source-inline">2643866716673</strong> and ending <span class="No-Break">at </span><span class="No-Break"><strong class="source-inline">2643866716720</strong></span><span class="No-Break">.</span></p>
			<p>The addresses <strong class="source-inline">2643866716704</strong> to <strong class="source-inline">2643866716712</strong> are of special interest to us. The first address is the address of our stack pointer, the value we write to the <strong class="source-inline">rsp</strong> register of the CPU. The range represents the values we wrote to the stack before we made <span class="No-Break">the switch.</span></p>
			<p class="callout-heading">Note</p>
			<p class="callout">The actual addresses you get will be different every time you run <span class="No-Break">the program.</span></p>
			<p>In other words, the values <strong class="source-inline">240, 205, 252, 56, 67, 86, 0, 0</strong> represent the pointer to our <strong class="source-inline">hello()</strong> function written as <span class="No-Break"><strong class="source-inline">u8</strong></span><span class="No-Break"> values.</span></p>
			<p class="callout-heading">Endianness</p>
			<p class="callout">An interesting side note here is that the order the CPU writes an <strong class="source-inline">u64</strong> as a set of 8 <strong class="source-inline">u8</strong> bytes is dependent on its endianness. In other words, a CPU can write our pointer address as <strong class="source-inline">240, 205, 252, 56, 67, 86, 0, 0</strong> if it’s little-endian or<strong class="source-inline"> 0, 0, 86, 67, 56, 252, 205, 240</strong> if it’s big-endian. Think of it like how Hebrew, Arabic, and Persian languages read and write from right to left, while Latin, Greek, and Indic languages read and write from left to right. It doesn’t really matter as long as you know it in advance, and the results will be <span class="No-Break">the same.</span></p>
			<p class="callout">The x86-64 architecture uses a little-endian format, so if you try to parse the data manually, you’ll have to bear this <span class="No-Break">in mind.</span></p>
			<p>As we write <a id="_idIndexMarker359"/>more complex functions, our extremely small 48-byte stack will soon run out of space. You see, as we run the functions we write in Rust, the CPU will now push and pop values on our new stack to execute our program and it’s left to the programmer to make sure they don’t overflow the stack. This brings us to our next topic: <span class="No-Break">stack sizes.</span></p>
			<h2 id="_idParaDest-107"><a id="_idTextAnchor106"/>Stack sizes</h2>
			<p>We <a id="_idIndexMarker360"/>touched upon this topic earlier in <a href="B20892_02.xhtml#_idTextAnchor043"><span class="No-Break"><em class="italic">Chapter 2</em></span></a>, but now that we’ve created our own stack and made our CPU jump over to it, you might get a better sense of the issue. One of the advantages of creating our own green threads is that we can freely choose how much space we reserve for <span class="No-Break">each stack.</span></p>
			<p>When you start a process in most modern operating systems, the standard stack size is normally 8 MB, but it can be configured differently. This is enough for most programs, but it’s up to the programmer to make sure we don’t use more than we have. This is the cause of the dreaded stack overflow that most of us <span class="No-Break">have experienced.</span></p>
			<p>However, when we can control the stacks ourselves, we can choose the size we want. 8 MB for each task is way more than we need when running simple functions in a web server, for example, so by reducing the stack size, we can have millions of fibers/green threads running on a machine. We run out of memory a lot sooner using stacks provided by the <span class="No-Break">operating system.</span></p>
			<p>Anyway, we <a id="_idIndexMarker361"/>need to consider how to handle the stack size, and most production systems such as <strong class="bold">Boost.Coroutine</strong> or the one you <a id="_idIndexMarker362"/>find in <strong class="bold">Go</strong> will use either segmented stacks or growable stacks. We will make this simple for ourselves and use a fixed stack size <span class="No-Break">going forward.</span></p>
			<h1 id="_idParaDest-108"><a id="_idTextAnchor107"/>Implementing our own fibers</h1>
			<p>Before <a id="_idIndexMarker363"/>we start, I want to make sure you understand that the code we write is quite unsafe and is not a “best practice” when writing Rust. I want to try to make this as safe as possible without introducing a lot of unnecessary complexity, but there is no way to avoid the fact that there will be a lot of unsafe code in this example. We will also prioritize focusing on <em class="italic">how</em> this works and explain it as simply as possible, which will be enough of a challenge in and of itself, so the focus on best practices and safety will have to take the back seat on <span class="No-Break">this one.</span></p>
			<p>Let’s start off by creating a whole new project called <strong class="source-inline">c-fibers</strong> and removing the code in <strong class="source-inline">main.rs</strong> so we start with a <span class="No-Break">blank sheet.</span></p>
			<p class="callout-heading">Note</p>
			<p class="callout">You will also find this example in the repository under the <strong class="source-inline">ch05/c-fibers</strong> folder. This example, as well as <strong class="source-inline">ch05/d-fibers-closure</strong> <strong class="source-inline">and</strong> <strong class="source-inline">ch05/e-fibers-windows</strong>, needs to be compiled using the nightly compiler since we use an unstable feature. You can do this in one of <span class="No-Break">two ways:</span></p>
			<p class="callout">• Override the default toolchain for the entire directory you’re in by writing <strong class="source-inline">rustup override set nightly</strong> (I personally prefer <span class="No-Break">this option).</span></p>
			<p class="callout">• Tell cargo to use the nightly toolchain every time you compile or run the program using <strong class="source-inline">cargo +nightly run</strong>. </p>
			<p class="callout">We’ll create a simple runtime with a very simple scheduler. Our fibers will save/restore their state so they can be stopped and resumed at any point during execution. Each fiber will represent a task that we want to progress concurrently, and we simply create a new fiber for each task we want <span class="No-Break">to run.</span></p>
			<p>We start off the example by enabling a specific feature we need, importing the <strong class="source-inline">asm</strong> macro, and defining a <span class="No-Break">few constants:</span></p>
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">ch05/c-fibers/main.rs</p>
			<pre class="source-code">
#![feature(naked_functions)]
use std::arch::asm;
const DEFAULT_STACK_SIZE: usize = 1024 * 1024 * 2;
const MAX_THREADS: usize = 4;
static mut RUNTIME: usize = 0;</pre>			<p>The feature<a id="_idIndexMarker364"/> we want to enable is called the <strong class="source-inline">naked_functions</strong> feature. Let’s explain what a naked function is <span class="No-Break">right away.</span></p>
			<p class="callout-heading">Naked functions</p>
			<p class="callout">If you remember when we talked about the operating system ABI and calling conventions earlier, you probably remember that each architecture and OS have different requirements. This is especially important when creating new stack frames, which is what happens when you call a function. So, the compiler knows about what each architecture/OS requires and adjusts layout, and parameter placement on the stack and saves/restores certain registers to make sure we satisfy the ABI on the platform we’re on. This happens both when we enter and exit a function and is often called a function <strong class="bold">prologue</strong> <span class="No-Break">and </span><span class="No-Break"><strong class="bold">epilogue</strong></span><span class="No-Break">.</span></p>
			<p class="callout">In Rust, we can enable this feature and mark a function as <strong class="source-inline">#[naked]</strong>. A naked function tells the compiler that we don’t want it to create a function prologue and epilogue and that we want to take care of this ourselves. Since we do the trick where we return over to a new stack and want to resume the old one at a later point we don’t want the compiler to think it manages the stack layout at these points. It worked in our first example since we never switched back to the original stack, but it won’t work <span class="No-Break">going forward.</span></p>
			<p>Our <strong class="source-inline">DEFAULT_STACK_SIZE</strong> is set to 2 MB, which is more than enough for our use. We also set <strong class="source-inline">MAX_THREADS</strong> to <strong class="source-inline">4</strong> since we don’t need more for <span class="No-Break">our example.</span></p>
			<p>The last static constant, <strong class="source-inline">RUNTIME</strong>, is a pointer to our runtime (yeah, I know, it’s not pretty with a mutable global variable, but it’s making it easier for us to focus on the important parts of the example <span class="No-Break">later on).</span></p>
			<p>The next thing<a id="_idIndexMarker365"/> we do is set up some data structures to represent the data we’ll be <span class="No-Break">working with:</span></p>
			<pre class="source-code">
pub struct Runtime {
    threads: Vec&lt;Thread&gt;,
    current: usize,
}
#[derive(PartialEq, Eq, Debug)]
enum State {
    Available,
    Running,
    Ready,
}
struct Thread {
    stack: Vec&lt;u8&gt;,
    ctx: ThreadContext,
    state: State,
}
#[derive(Debug, Default)]
#[repr(C)]
struct ThreadContext {
    rsp: u64,
    r15: u64,
    r14: u64,
    r13: u64,
    r12: u64,
    rbx: u64,
    rbp: u64,
}</pre>			<p><strong class="source-inline">Runtime</strong> is going <a id="_idIndexMarker366"/>to be our main entry point. We are basically going to create a very small runtime with a very simple scheduler and switch between our threads. The runtime holds an array of <strong class="source-inline">Thread</strong> structs and a <strong class="source-inline">current</strong> field to indicate which thread we are <span class="No-Break">currently running.</span></p>
			<p><strong class="source-inline">Thread</strong> holds data for a thread. The <strong class="bold">stack</strong> is similar to what we saw in our first example in earlier chapters. The <strong class="source-inline">ctx</strong> field is a context representing the data our CPU needs to resume where it left off on a stack and a <strong class="source-inline">state</strong> field that holds our <span class="No-Break">thread state.</span></p>
			<p><strong class="source-inline">State</strong> is an <strong class="bold">enum</strong> representing the states our threads can <span class="No-Break">be in:</span></p>
			<ul>
				<li><strong class="source-inline">Available</strong> means the thread is available and ready to be assigned a task <span class="No-Break">if needed</span></li>
				<li><strong class="source-inline">Running</strong> means the thread <span class="No-Break">is running</span></li>
				<li><strong class="source-inline">Ready</strong> means the thread is ready to move forward and <span class="No-Break">resume execution</span></li>
			</ul>
			<p><strong class="source-inline">ThreadContext</strong> holds data for the registers that the CPU needs to resume execution on <span class="No-Break">a stack.</span></p>
			<p class="callout-heading">Note</p>
			<p class="callout">The registers we save in our <strong class="source-inline">ThreadContext</strong> struct are the registers that are marked as <em class="italic">callee saved</em> in <span class="No-Break"><em class="italic">Figure 5</em></span><em class="italic">.1</em>. We need to save these since the ABI states that the <em class="italic">callee</em> (which will be our <strong class="source-inline">switch</strong> function from the perspective of the OS) needs to restore them before the <em class="italic">caller</em> <span class="No-Break">is resumed.</span></p>
			<p>Next up is how we<a id="_idIndexMarker367"/> initialize the data to a newly <span class="No-Break">created thread:</span></p>
			<pre class="source-code">
impl Thread {
    fn new() -&gt; Self {
        Thread {
            stack: vec![0_u8; DEFAULT_STACK_SIZE],
            ctx: ThreadContext::default(),
            state: State::Available,
        }
    }
}</pre>			<p>This is pretty easy. A new thread starts in the <strong class="source-inline">Available</strong> state, indicating it is ready to be assigned <span class="No-Break">a task.</span></p>
			<p>One thing I want to point out here is that we allocate our stack here. That is not needed and is not an optimal use of our resources since we allocate memory for threads we might need instead of allocating on first use. However, this lowers the complexity in the parts of our code that have a more important focus than allocating memory for <span class="No-Break">our stack.</span></p>
			<p class="callout-heading">Note</p>
			<p class="callout">Once a stack is allocated it must not move! No <strong class="source-inline">push()</strong> on the vector or any other methods that might trigger a reallocation. If the stack is reallocated, any pointers that we hold to it <span class="No-Break">are invalidated.</span></p>
			<p class="callout">It’s worth mentioning that <strong class="source-inline">Vec&lt;T&gt;</strong> has a method called <strong class="source-inline">into_boxed_slice()</strong>, which returns a reference to an allocated slice <strong class="source-inline">Box&lt;[T]&gt;</strong>. Slices can’t grow, so if we store that instead, we can avoid the reallocation problem. There are several other ways to make this safer, but we’ll not focus on those in <span class="No-Break">this example.</span></p>
			<h2 id="_idParaDest-109"><a id="_idTextAnchor108"/>Implementing the runtime</h2>
			<p>The first thing<a id="_idIndexMarker368"/> we need to do is to initialize a new runtime to a base state. The next code segments all belong to the <strong class="source-inline">impl Runtime</strong> block, and I’ll make sure to let you know when the block ends since it can be hard to spot the closing bracket when we divide it up as much as we <span class="No-Break">do here.</span></p>
			<p>The first thing we do is to implement a <strong class="source-inline">new</strong> function on our <span class="No-Break"><strong class="source-inline">Runtime</strong></span><span class="No-Break"> struct:</span></p>
			<pre class="source-code">
impl Runtime {
  pub fn new() -&gt; Self {
    let base_thread = Thread {
      stack: vec![0_u8; DEFAULT_STACK_SIZE],
      ctx: ThreadContext::default(),
      state: State::Running,
    };
    let mut threads = vec![base_thread];
    let mut available_threads: Vec&lt;Thread&gt; = (1..MAX_THREADS).map(|_| Thread::new()).collect();
    threads.append(&amp;mut available_threads);
    Runtime {
      threads,
      current: 0,
    }
  }</pre>			<p>When we instantiate our <strong class="source-inline">Runtime</strong>, we set up a base thread. This thread will be set to the <strong class="source-inline">Running</strong> state and will make sure we keep the runtime running until all tasks <span class="No-Break">are finished.</span></p>
			<p>Then, we instantiate the rest of the threads and set the current thread (the base thread) <span class="No-Break">to </span><span class="No-Break"><strong class="source-inline">0.</strong></span></p>
			<p>The next thing we <a id="_idIndexMarker369"/>do is admittedly a little bit hacky since we do something that’s usually a no-go in Rust. As I mentioned when we went through the constants, we want to access our runtime struct from anywhere in our code so that we can call yield on it at any point in our code. There are ways to do this safely, but the topic at hand is already complex, so even though we’re juggling with knives here, I will do everything I can to keep everything that’s not the main focal point of this example as simple as it <span class="No-Break">can be.</span></p>
			<p>After we call initialize on the Runtime, we have to make sure we don’t do anything that can invalidate the pointer we take to <strong class="source-inline">self</strong> once <span class="No-Break">it’s initialized.</span></p>
			<pre class="source-code">
    pub fn init(&amp;self) {
        unsafe {
            let r_ptr: *const Runtime = self;
            RUNTIME = r_ptr as usize;
        }
    }</pre>			<p>This is where we start running our runtime. It will continually call <strong class="source-inline">t_yield()</strong> until it returns <strong class="source-inline">false</strong>, which means that there is no more work to do and we can exit <span class="No-Break">the process:</span></p>
			<pre class="source-code">
    pub fn run(&amp;mut self) -&gt; ! {
        while self.t_yield() {}
        std::process::exit(0);
    }</pre>			<p class="callout-heading">Note</p>
			<p class="callout"><strong class="source-inline">yield</strong> is a reserved word in Rust, so we can’t name our function that. If that was not the case, it would be my preferred name for it over the slightly more <span class="No-Break">cryptic </span><span class="No-Break"><strong class="source-inline">t_yield</strong></span><span class="No-Break">.</span></p>
			<p>This is the <a id="_idIndexMarker370"/>return function that we call when a thread is finished. <strong class="source-inline">return</strong> is another reserved keyword in Rust, so we name this <strong class="source-inline">t_return()</strong>. Make a note that the user of our threads does not call this; we set up our stack so this is called when the task <span class="No-Break">is done:</span></p>
			<pre class="source-code">
    fn t_return(&amp;mut self) {
        if self.current != 0 {
            self.threads[self.current].state = State::Available;
            self.t_yield();
        }
    }</pre>			<p>If the calling thread is the <strong class="source-inline">base_thread</strong>, we won’t do anything. Our runtime will call <strong class="source-inline">t_yield</strong> for us on the base thread. If it’s called from a spawned thread, we know it’s finished since all threads will have a <strong class="source-inline">guard</strong> function on top of their stack (which we’ll show further down), and the only place where this function is called is on our <span class="No-Break"><strong class="source-inline">guard</strong></span><span class="No-Break"> function.</span></p>
			<p>We set its state to <strong class="source-inline">Available</strong>, letting the runtime know it’s ready to be assigned a new task, and then immediately call <strong class="source-inline">t_yield</strong>, which will schedule a new thread to <span class="No-Break">be run.</span></p>
			<p>So, finally, we get to the heart of our runtime: the <span class="No-Break"><strong class="source-inline">t_yield</strong></span><span class="No-Break"> function.</span></p>
			<p>The first part of this function is our scheduler. We simply go through all the threads and see if any are in the <strong class="source-inline">Ready</strong> state, which indicates that it has a task it is ready to make progress. This could be a database call that has returned in a <span class="No-Break">real-world application.</span></p>
			<p>If no <a id="_idIndexMarker371"/>thread is <strong class="source-inline">Ready</strong>, we’re all done. This is an extremely simple scheduler using only a round-robin algorithm. A real scheduler might have a much more sophisticated way of deciding what task to <span class="No-Break">run next.</span></p>
			<p>If we find a thread that’s ready to be run, we change the state of the current thread from <strong class="source-inline">Running</strong> <span class="No-Break">to </span><span class="No-Break"><strong class="source-inline">Ready</strong></span><span class="No-Break">.</span></p>
			<p>Let’s present the function before we go on to explain the last part <span class="No-Break">of it:</span></p>
			<pre class="source-code">
    #[inline(never)]
    fn t_yield(&amp;mut self) -&gt; bool {
        let mut pos = self.current;
        while self.threads[pos].state != State::Ready {
            pos += 1;
            if pos == self.threads.len() {
                pos = 0;
            }
            if pos == self.current {
                return false;
            }
        }
        if self.threads[self.current].state != State::Available {
            self.threads[self.current].state = State::Ready;
        }
        self.threads[pos].state = State::Running;
        let old_pos = self.current;
        self.current = pos;
        unsafe {
            let old: *mut ThreadContext = &amp;mut self.threads[old_pos].ctx;
            let new: *const ThreadContext = &amp;self.threads[pos].ctx;
            asm!("call switch", in("rdi") old, in("rsi") new, clobber_abi("C"));
        }
        self.threads.len() &gt; 0
    }</pre>			<p>The next thing we<a id="_idIndexMarker372"/> do is to call the function <strong class="source-inline">switch</strong>, which will save the current context (the old context) and load the new context into the CPU. The new context is either a new task or all the information the CPU needs to resume work on an <span class="No-Break">existing task.</span></p>
			<p>Our <strong class="source-inline">switch</strong> function, which we will cover a little further down, takes two arguments and is marked as <strong class="source-inline">#[naked]</strong>. Naked functions are not like normal functions. They don’t accept formal arguments, for example, so we can’t simply call it in Rust as a normal function like <span class="No-Break"><strong class="source-inline">switch(old, new)</strong></span><span class="No-Break">.</span></p>
			<p>You see, usually, when we call a function with two arguments, the compiler will place each argument in a register described by the calling convention for the platform. However, when we call a <strong class="source-inline">#[naked]</strong> function, we need to take care of this ourselves. Therefore, we pass in the address to our old and new <strong class="source-inline">ThreadContext</strong> using assembly. <strong class="source-inline">rdi</strong> is the register for the first argument in the System V ABI calling convention and <strong class="source-inline">rsi</strong> is the register used for the <span class="No-Break">second argument.</span></p>
			<p>The <strong class="source-inline">#[inline(never)]</strong> attribute prevents the compiler from simply substituting a call to our function with a copy of the function content wherever it’s called (this is what inlining means). This<a id="_idIndexMarker373"/> is almost never a problem on debug builds, but in this case, our program will fail if the compiler <strong class="bold">inlines</strong> this function in a release build. The issue manifests itself by the runtime exiting before all the tasks are finished. Since we store <strong class="source-inline">Runtime</strong> as a static <strong class="source-inline">usize</strong> that we then cast as a <strong class="source-inline">*mut</strong> pointer (which is almost guaranteed to cause UB), it’s <em class="italic">most likely</em> caused by the compiler making the wrong assumptions when this function is inlined and called by casting and dereferencing <strong class="source-inline">RUNTIME</strong> in one of the helper methods that will be outlined. Just make a note that this is probably avoidable if we change our design; it’s not something worth dwelling on for too long in this <span class="No-Break">specific case.</span></p>
			<p class="callout-heading">More inline assembly</p>
			<p class="callout">We need to explain the new concepts we introduced here. The assembly calls the function <strong class="source-inline">switch</strong> (the function is tagged with <strong class="source-inline">#[no_mangle]</strong> so we can call it by name). The <strong class="source-inline">in("rdi") old</strong> and <strong class="source-inline">in("rsi") new</strong> arguments place the value of <strong class="source-inline">old</strong> and <strong class="source-inline">new</strong> to the <strong class="source-inline">rdi</strong> and <strong class="source-inline">rsi</strong> registers, respectively. The System V ABI for x86-64 states that the <strong class="source-inline">rdi</strong> register holds the first argument to a function and <strong class="source-inline">rsi</strong> holds the <span class="No-Break">second argument.</span></p>
			<p class="callout">The <strong class="source-inline">clobber_abi("C")</strong> argument tells the compiler that it may not assume any that any general-purpose registers are preserved across the <strong class="source-inline">asm!</strong> block. The compiler will emit instructions to push the registers it uses to the stack and restore them when resuming after the <strong class="source-inline">asm!</strong> block. </p>
			<p class="callout">If you take one more look at the list in <span class="No-Break"><em class="italic">Figure 5</em></span><em class="italic">.1</em>, we already know that we need to take special care with registers that are marked as <em class="italic">callee saved</em>. When calling a normal function, the compiler will insert code* to save/restore all the non-callee-saved, or caller saved, registers before calling a function so it can resume with the correct state when the function returns. Since we marked the function we’re calling as <strong class="source-inline">#[naked]</strong>, we explicitly told the compiler to not insert this code, so the safest thing is to make sure the compiler doesn’t assume that it can rely on any register being untouched when it resumes after the call we make in our <span class="No-Break"><strong class="source-inline">asm!</strong></span><span class="No-Break"> block.</span></p>
			<p class="callout">*In some instances, the compiler will know that a register is untouched by the function call since it controls the register usage in both the caller and the callee and it will not emit any special instructions to save/restore registers they know will be untouched when the <span class="No-Break">function returns</span></p>
			<p>The <strong class="source-inline">self.threads.len() &gt; 0</strong>  line at the end is just a way for us to prevent the compiler <a id="_idIndexMarker374"/>from optimizing our code away. This happens to me on Windows but not on Linux, and it is a common problem when running benchmarks, for example. There are other ways of preventing the compiler from optimizing this code, but I chose the simplest way I could find. As long as it’s commented, it should be OK to do. The code never reaches this <span class="No-Break">point anyway.</span></p>
			<p>Next up is our <strong class="source-inline">spawn</strong> function. I’ll present the function first and guide you through <span class="No-Break">it after:</span></p>
			<pre class="source-code">
pub fn spawn(&amp;mut self, f: fn()) {
    let available = self
        .threads
        .iter_mut()
        .find(|t| t.state == State::Available)
        .expect("no available thread.");
    let size = available.stack.len();
    unsafe {
        let s_ptr = available.stack.as_mut_ptr().offset(size as isize);
        let s_ptr = (s_ptr as usize &amp; !15) as *mut u8;
        std::ptr::write(s_ptr.offset(-16) as *mut u64, guard as u64);
        std::ptr::write(s_ptr.offset(-24) as *mut u64, skip as u64);
        std::ptr::write(s_ptr.offset(-32) as *mut u64, f as u64);
        available.ctx.rsp = s_ptr.offset(-32) as u64;
    }
    available.state = State::Ready;
}
} // We close the `impl Runtime` block here</pre>			<p class="callout-heading">Note</p>
			<p class="callout">I promised to point out where we close the <strong class="source-inline">impl Runtime</strong> block, and we do that after the <strong class="source-inline">spawn</strong> function. The upcoming functions are “free” functions that don’t belong to <span class="No-Break">a struct.</span></p>
			<p>While I think <strong class="source-inline">t_yield</strong> is the logically interesting function in this example, I think <strong class="source-inline">spawn</strong> is the most interesting <span class="No-Break">one technically.</span></p>
			<p>The first thing <a id="_idIndexMarker375"/>to note is that the function takes one argument: <strong class="source-inline">f: fn()</strong>. This is simply a function pointer to the function we take as an argument. This function is the task we want to run concurrently with other tasks. If this was a library, this is the function that users actually pass to us and want our runtime to <span class="No-Break">handle concurrently.</span></p>
			<p>In this example, we take a simple function as an argument, but if we modify the code slightly we can also accept <span class="No-Break">a closure.</span></p>
			<p class="callout-heading">Tip</p>
			<p class="callout">In example <strong class="source-inline">ch05/d-fibers-closure</strong>, you can see a slightly modified example that accepts a closure instead, making it more flexible than the one we walk through here. I would really encourage you to check that one out once you’ve finished <span class="No-Break">this example.</span></p>
			<p>The rest of the function is where we set up our stack as we discussed in the previous chapter and make sure our stack looks like the one specified in the System V ABI <span class="No-Break">stack layout.</span></p>
			<p>When we spawn a new fiber (or userland thread), we first check if there are any available userland threads (threads in <strong class="source-inline">Available</strong> state). If we run out of threads, we panic in this scenario, but there are several (better) ways to handle that. We’ll keep things simple <span class="No-Break">for now.</span></p>
			<p>When we find an available thread, we get the stack length and a pointer to our <strong class="source-inline">u8</strong> <span class="No-Break">byte array.</span></p>
			<p>In the next <a id="_idIndexMarker376"/>segment, we have to use some unsafe functions. We’ll explain the functions we refer to here later, but this is where we set them up in our new stack so that they’re called in the right order for our runtime <span class="No-Break">to work.</span></p>
			<p>First, we make sure that the memory segment we’ll use is 16-byte-aligned. Then, we write the address to our <strong class="source-inline">guard</strong> function that will be called when the task we provide finishes and the <span class="No-Break">function returns.</span></p>
			<p>Second, we’ll write the address to a <strong class="source-inline">skip</strong> function, which is there just to handle the gap when we return from <strong class="source-inline">f</strong>, so that <strong class="source-inline">guard</strong> will get called on a 16-byte boundary. The next value we write to the stack is the address <span class="No-Break">to </span><span class="No-Break"><strong class="source-inline">f</strong></span><span class="No-Break">.</span></p>
			<p class="callout-heading">Why do we need the skip function?</p>
			<p class="callout">Remember how we explained how the stack works? We want the <strong class="source-inline">f</strong> function to be the first to run, so we set the base pointer to <strong class="source-inline">f</strong> and make sure it’s 16-byte aligned. We then push the address to the <strong class="source-inline">skip</strong> function and lastly the <strong class="source-inline">guard</strong> function. Since, <strong class="source-inline">skip</strong> is simply one instruction, <strong class="source-inline">ret</strong>, doing this makes sure that our call to <strong class="source-inline">guard</strong> is 16-byte aligned so that we adhere to the <span class="No-Break">ABI requirements.</span></p>
			<p>After we’ve written our function pointers to the stack, we set the value of <strong class="source-inline">rsp</strong>, which is the stack pointer to the address of our provided function, so we start executing that first when we are scheduled <span class="No-Break">to run.</span></p>
			<p>Lastly, we set the state to <strong class="source-inline">Ready</strong>, which means we have work to do and that we are ready to do it. Remember, it’s up to our scheduler to actually start up <span class="No-Break">this thread.</span></p>
			<p>We’re now finished implementing our <strong class="source-inline">Runtime</strong>, if you got all this, you basically understand how fibers/green threads work. However, there are still a few details needed to make it <span class="No-Break">all work.</span></p>
			<h2 id="_idParaDest-110"><a id="_idTextAnchor109"/>Guard, skip, and switch functions</h2>
			<p>There are a <a id="_idIndexMarker377"/>few functions we’ve referred to that are really important<a id="_idIndexMarker378"/> for our Runtime to actually work. Fortunately, all but one of them are extremely simple to understand. We’ll start with<a id="_idIndexMarker379"/> the <span class="No-Break"><strong class="source-inline">guard</strong></span><span class="No-Break"> function:</span></p>
			<pre class="source-code">
fn guard() {
    unsafe {
        let rt_ptr = RUNTIME as *mut Runtime;
        (*rt_ptr).t_return();
    };
}</pre>			<p>The <strong class="source-inline">guard</strong> function is called when the function that we passed in, <strong class="source-inline">f</strong>, has returned. When <strong class="source-inline">f</strong> returns, it means our task is finished, so we de-reference our <strong class="source-inline">Runtime</strong> and call <strong class="source-inline">t_return()</strong>. We could have made a function that does some additional work when a thread is finished, but right now, our <strong class="source-inline">t_return()</strong> function does all we need. It marks our thread as <strong class="source-inline">Available</strong> (if it’s not our base thread) and yields so we can resume work on a <span class="No-Break">different thread.</span></p>
			<p>Next is our <span class="No-Break"><strong class="source-inline">skip</strong></span><span class="No-Break"> function:</span></p>
			<pre class="source-code">
#[naked]
unsafe extern "C" fn skip() {
    asm!("ret", options(noreturn))
}</pre>			<p>There is not much happening in the <strong class="source-inline">skip</strong> function. We use the <strong class="source-inline">#[naked]</strong> attribute so that this function essentially compiles down to just <strong class="source-inline">ret</strong> instruction. <strong class="source-inline">ret</strong> will just pop off the next value from the stack and jump to whatever instructions that address points to. In our case, this is the <span class="No-Break"><strong class="source-inline">guard</strong></span><span class="No-Break"> function.</span></p>
			<p>Next up is a small helper function <span class="No-Break">named </span><span class="No-Break"><strong class="source-inline">yield_thread</strong></span><span class="No-Break">:</span></p>
			<pre class="console">
pub fn yield_thread() {
    unsafe {
        let rt_ptr = RUNTIME as *mut Runtime;
        (*rt_ptr).t_yield();
    };
}</pre>			<p>This helper function lets us call <strong class="source-inline">t_yield</strong> on our <strong class="source-inline">Runtime</strong> from an arbitrary place in our code <a id="_idIndexMarker380"/>without needing any references to it. This function is very unsafe, and it’s one of the places where we <a id="_idIndexMarker381"/>make big shortcuts to make our example slightly simpler to understand. If we call this and our Runtime is not initialized yet or the runtime is dropped, it will result in undefined behavior. However, making this safer is not a priority for us just to get our example up <span class="No-Break">and running.</span></p>
			<p>We are very close<a id="_idIndexMarker382"/> to the finish line; just one more function to go. The last bit we need is our <strong class="source-inline">switch</strong> function, and you already know the most important parts of it already. Let’s see how it looks and explain how it differs from our first stack <span class="No-Break">swap function:</span></p>
			<pre class="source-code">
#[naked]
#[no_mangle]
unsafe extern "C" fn switch() {
    asm!(
        "mov [rdi + 0x00], rsp",
        "mov [rdi + 0x08], r15",
        "mov [rdi + 0x10], r14",
        "mov [rdi + 0x18], r13",
        "mov [rdi + 0x20], r12",
        "mov [rdi + 0x28], rbx",
        "mov [rdi + 0x30], rbp",
        "mov rsp, [rsi + 0x00]",
        "mov r15, [rsi + 0x08]",
        "mov r14, [rsi + 0x10]",
        "mov r13, [rsi + 0x18]",
        "mov r12, [rsi + 0x20]",
        "mov rbx, [rsi + 0x28]",
        "mov rbp, [rsi + 0x30]",
        "ret", options(noreturn)
    );
}</pre>			<p>So, this is our <a id="_idIndexMarker383"/>full stack switch function. You probably remember from our first example that this is just a bit more elaborate. We first read out the values of all the registers we need and then set all the register values to the register values we saved when <a id="_idIndexMarker384"/>we suspended execution on the <span class="No-Break">new thread.</span></p>
			<p>This is essentially all we need to do to save and resume <span class="No-Break">the execution.</span></p>
			<p>Here we <a id="_idIndexMarker385"/>see the <strong class="source-inline">#[naked]</strong> attribute used again. Usually, every function has a prologue and an epilogue and we don’t want that here since this is all assembly and we want to handle everything ourselves. If we don’t include this, we will fail to switch back to our stack the <span class="No-Break">second time.</span></p>
			<p>You can also see us using the offset we introduced earlier <span class="No-Break">in practice:</span></p>
			<pre class="console">
0x00[rdi] # 0
0x08[rdi] # 8
0x10[rdi] # 16
0x18[rdi] # 24</pre>			<p>These are hex numbers indicating the offset from the memory pointer to which we want to read/write. I wrote down the base 10 numbers as comments, so as you can see, we only offset the pointer in 8-byte steps, which is the same size as the <strong class="source-inline">u64</strong> fields on our <span class="No-Break"><strong class="source-inline">ThreadContext</strong></span><span class="No-Break"> struct.</span></p>
			<p>This is also why it’s important to annotate <strong class="source-inline">ThreadContext</strong> with <strong class="source-inline">#[repr(C)]</strong>; it tells us that the data will be represented in memory in this exact way so we write to the right field. The Rust ABI makes no guarantee that they are represented in the same order in memory; however, the <span class="No-Break">C-ABI does.</span></p>
			<p>Finally, there is <a id="_idIndexMarker386"/>one new option added to the <strong class="source-inline">asm!</strong> block. <strong class="source-inline">option(noreturn)</strong> is a requirement when writing naked functions and we will receive a compile<a id="_idIndexMarker387"/> error if we don’t add it. Usually, the compiler will assume that a function call will return, but naked functions are not anything like the functions we’re used to. They’re more like labeled containers of assembly that we can call, so we don’t want the <a id="_idIndexMarker388"/>compiler to emit <strong class="source-inline">ret</strong> instructions at the end of the function or make any assumptions that we return to the previous stack frame. By using this option, we tell the compiler to treat the assembly block as if it never returns, and we make sure that we never fall through the assembly block by adding a <strong class="source-inline">ret</strong> <span class="No-Break">instruction ourselves.</span></p>
			<p>Next up is our <strong class="source-inline">main</strong> function, which is pretty straightforward, so I’ll simply present the <span class="No-Break">code here:</span></p>
			<pre class="source-code">
fn main() {
    let mut runtime = Runtime::new();
    runtime.init();
    runtime.spawn(|| {
        println!("THREAD 1 STARTING");
        let id = 1;
        for i in 0..10 {
            println!("thread: {} counter: {}", id, i);
            yield_thread();
        }
        println!("THREAD 1 FINISHED");
    });
    runtime.spawn(|| {
        println!("THREAD 2 STARTING");
        let id = 2;
        for i in 0..15 {
            println!("thread: {} counter: {}", id, i);
            yield_thread();
        }
        println!("THREAD 2 FINISHED");
    });
    runtime.run();
}</pre>			<p>As you see <a id="_idIndexMarker389"/>here, we initialize our runtime and spawn two threads: one that <a id="_idIndexMarker390"/>counts to 10 and<a id="_idIndexMarker391"/> yields between each count and one that counts to 15. When we <strong class="source-inline">cargo run</strong> our project, we should get the <span class="No-Break">following output:</span></p>
			<pre class="source-code">
Finished dev [unoptimized + debuginfo] target(s) in 2.17s
Running `target/debug/green_threads`
THREAD 1 STARTING
thread: 1 counter: 0
THREAD 2 STARTING
thread: 2 counter: 0
thread: 1 counter: 1
thread: 2 counter: 1
thread: 1 counter: 2
thread: 2 counter: 2
thread: 1 counter: 3
thread: 2 counter: 3
thread: 1 counter: 4
thread: 2 counter: 4
thread: 1 counter: 5
thread: 2 counter: 5
thread: 1 counter: 6
thread: 2 counter: 6
thread: 1 counter: 7
thread: 2 counter: 7
thread: 1 counter: 8
thread: 2 counter: 8
thread: 1 counter: 9
thread: 2 counter: 9
THREAD 1 FINISHED.
thread: 2 counter: 10
thread: 2 counter: 11
thread: 2 counter: 12
thread: 2 counter: 13
thread: 2 counter: 14
THREAD 2 FINISHED.</pre>			<p>Beautiful! Our <a id="_idIndexMarker392"/>threads alternate since they yield control on each count <a id="_idIndexMarker393"/>until <strong class="source-inline">THREAD 1</strong> finishes and <strong class="source-inline">THREAD 2</strong> counts the last numbers before it<a id="_idIndexMarker394"/> finishes <span class="No-Break">its task.</span></p>
			<h1 id="_idParaDest-111"><a id="_idTextAnchor110"/>Finishing thoughts</h1>
			<p>I want to round off this chapter by pointing out some of the advantages and disadvantages of this approach, which we went through in <a href="B20892_02.xhtml#_idTextAnchor043"><span class="No-Break"><em class="italic">Chapter 2</em></span></a>, since we now have first-hand experience with <span class="No-Break">this topic.</span></p>
			<p>First of all, the example we implemented here is an example of what we called a stackful coroutine. Each coroutine (or thread, as we call it in the example implementation) has its own stack. This also means that we can interrupt and resume execution at any point in time. It doesn’t matter if we’re in the middle of a stack frame (in the middle of executing a function); we can simply tell the CPU to save the state we need to the stack, return to a different stack and restore the state it needs there, and resume as if nothing <span class="No-Break">has happened.</span></p>
			<p>You can also see that we have to manage our stacks in some way. In our example, we just create a static stack (much like the OS does when we ask it for a thread, but smaller), but for this to be more efficient than using OS threads, we need to select a strategy to solve that <span class="No-Break">potential problem.</span></p>
			<p>If you look at our slightly expanded example in <strong class="source-inline">ch05/d-fibers-closure</strong>, you’ll notice that we can make the API pretty easy to use, much like the API used for <strong class="source-inline">std::thread::spawn</strong> in the standard library. The flipside is of course the complexity of implementing this correctly on all combinations of ISA/ABIs that we want to support, and while specific to Rust, it’s challenging to create a great and <em class="italic">safe</em> API over these kinds of stackful coroutines without any native language support <span class="No-Break">for it.</span></p>
			<p>To tie this into <a href="B20892_03.xhtml#_idTextAnchor063"><span class="No-Break"><em class="italic">Chapter 3</em></span></a>, where we discuss event queues and non-blocking calls, I want to point out that if you use fibers to handle concurrency, you would call yield after you’ve made a read interest in your non-blocking call. Typically, a runtime would supply these non-blocking calls, and the fact that we yield would be opaque to the user, but the fiber is suspended at that point. We would probably add one more state to our <strong class="source-inline">State</strong> enum called <strong class="source-inline">Pending</strong> or something else that signifies that the thread is waiting for some <span class="No-Break">external event.</span></p>
			<p>When the OS signals that the data is ready, we would mark the thread as <strong class="source-inline">State::Ready</strong> to resume and the scheduler would resume execution just like in <span class="No-Break">this example.</span></p>
			<p>While it requires a more sophisticated scheduler and infrastructure, I hope that you have gotten a good idea of how such a system would work <span class="No-Break">in practice.</span></p>
			<h1 id="_idParaDest-112"><a id="_idTextAnchor111"/>Summary</h1>
			<p>First of all, congratulations! You have now implemented a super simple but working example of fibers. You’ve set up your own stack and learned about ISAs, ABIs, calling conventions, and inline assembly <span class="No-Break">in Rust.</span></p>
			<p>It was quite the ride we had to take, but if you came this far and read through everything, you should give yourself a big pat on the back. This is not for the faint of heart, but you <span class="No-Break">pulled through.</span></p>
			<p>This example (and chapter) might take a little time to fully digest, but there is no rush for that. You can always go back to this example and read the code again to fully understand it. I really do recommend that you play around with the code yourself and get to know it. Change the scheduling algorithm around, add more context to the threads you create, and use <span class="No-Break">your imagination.</span></p>
			<p>You will probably experience that debugging problems in low-level code like this can be pretty hard, but that’s part of the learning process and you can always revert back to a <span class="No-Break">working version.</span></p>
			<p>Now that we have covered one of the largest and most difficult examples in this book, we’ll go on to learn about another popular way of handling concurrency by looking into how futures and async/await works in Rust. The rest of this book is in fact dedicated solely to learning about futures and async/await in Rust, and since we've gained so much fundamental knowledge at this point, it will be much easier for us to get a good and deep understanding of how they work. You've done a great job <span class="No-Break">so far!</span></p>
		</div>
	

		<div id="_idContainer026" class="Content">
			<h1 id="_idParaDest-113" lang="en-US" xml:lang="en-US"><a id="_idTextAnchor112"/>Part 3:Futures and async/await in Rust</h1>
			<p>This part will explain Futures and async/await in Rust from the ground up. Building upon the knowledge acquired thus far, we will construct a central example that will serve as a recurring theme in the subsequent chapters, eventually leading to the creation of a runtime capable of executing futures in Rust. Throughout this exploration, we will delve into concepts such as coroutines, runtimes, reactors, executors, wakers, and <span class="No-Break">much more.</span></p>
			<p>This part comprises the <span class="No-Break">following chapters:</span></p>
			<ul>
				<li><a href="B20892_06.xhtml#_idTextAnchor113"><em class="italic">Chapter 6</em></a><em class="italic">, Futures in Rust</em></li>
				<li><a href="B20892_07.xhtml#_idTextAnchor122"><em class="italic">Chapter 7</em></a><em class="italic">, Coroutines and async/await</em></li>
				<li><a href="B20892_08.xhtml#_idTextAnchor138"><em class="italic">Chapter 8</em></a><em class="italic">, Runtimes, Wakers, and the Reactor-Executor Pattern</em></li>
				<li><a href="B20892_09.xhtml#_idTextAnchor156"><em class="italic">Chapter 9</em></a><em class="italic">, Coroutines, Self-referential Structs, and Pinning</em></li>
				<li><a href="B20892_10.xhtml#_idTextAnchor178"><em class="italic">Chapter 10</em></a><em class="italic">, Create Your Own Runtime</em></li>
			</ul>
		</div>
		<div>
			<div id="_idContainer027" class="Basic-Graphics-Frame">
			</div>
		</div>
	</body></html>