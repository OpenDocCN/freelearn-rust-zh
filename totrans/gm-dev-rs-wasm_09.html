<html><head></head><body>
		<div><h1 id="_idParaDest-111"><em class="italic"><a id="_idTextAnchor166"/>Chapter 7</em>: Sound Effects and Music</h1>
			<p>Take a moment and think of the game Tetris. If you're like me, you're probably already humming its theme song, <em class="italic">Korobeiniki</em>, because that song is so synonymous with the game itself. Beyond the appeal of music, sound effects are crucial for creating an immersive experience. We play games with more than just the touch of a keyboard or joystick and the use of our eyes; we hear Mario jump or Sonic catch a ring. While our game may be playable, it's just not a game without some sound. To play sound in our game, we'll need to learn how to use the browser's Web Audio API for both short and long sounds.</p>
			<p>In this chapter, we will cover the following topics:</p>
			<ul>
				<li>Adding the Web Audio API to the engine</li>
				<li>Playing sound effects</li>
				<li>Playing long music</li>
			</ul>
			<p>By the end of this chapter, you won't just see RHB run, jump, and dodge obstacles, but you'll be able to hear him too after we add sound effects and music to our game. Let's get started!</p>
			<h1 id="_idParaDest-112"><a id="_idTextAnchor167"/>Technical requirements</h1>
			<p>The technical requirements are largely unchanged from the previous chapters. You will need the <code>sound</code> assets from the <code>sound</code> directory in the assets download at <a href="https://github.com/PacktPublishing/Game-Development-with-Rust-and-WebAssembly/wiki/Assets">https://github.com/PacktPublishing/Game-Development-with-Rust-and-WebAssembly/wiki/Assets</a>. </p>
			<p>All sounds are from open sound collections and are used with permission. See the <code>sounds/credits.txt</code> file for more information. The code for this chapter is available at <a href="https://github.com/PacktPublishing/Game-Development-with-Rust-and-WebAssembly/tree/chapter_7">https://github.com/PacktPublishing/Game-Development-with-Rust-and-WebAssembly/tree/chapter_7</a>. </p>
			<p>Check out the following video to see the Code in Action: <a href="https://bit.ly/3JUdA2R">https://bit.ly/3JUdA2R</a></p>
			<h1 id="_idParaDest-113"><a id="_idTextAnchor168"/>Adding the Web Audio API to the engine</h1>
			<p>In this section, we'll<a id="_idIndexMarker623"/> be using the browser's Web Audio API to <a id="_idIndexMarker624"/>add sound to our game. The API is incredibly full-featured, allowing for mixing audio sources and special effects, but we're just going to use it to play background music and sounds. In fact, the Web Audio API is its own book and, if you're interested, you can find one at <a href="https://webaudioapi.com/book/">https://webaudioapi.com/book/</a>. While it would be fun to add things such as spatialized audio to our game, we're going to focus on just adding some music and sound effects. I encourage you to experiment on your own when making your own, more complicated games.</p>
			<p>Once we've got an overview of the Web Audio API, we'll create a module to play sounds in Rust, load the sounds in the same way as we load our images, and finally, add that sound to th<a id="_idTextAnchor169"/>e engine.</p>
			<p>The Web Audio API is a relatively new technology that is meant to replace older technology for audio, such as QuickTime and Flash, as well as being a more flexible solution than using audio elements. It's supported by all the major browsers, with only old versions of Internet Explorer being a potential problem. Given that the last release of Internet Explorer was in 2013, with Windows using the Edge browser instead, your game is probably okay with sacrificing that market.</p>
			<p>The Web Audio API may initially look familiar when compared to Canvas. As with Canvas, you create a context that then provides an API for playing sounds. At that point, the similarity ends. Because the Web Audio API has all the features I mentioned earlier, it can be hard to figure out how to do the basic act of playing a sound. Unlike Canvas, there's no <code>drawImage</code> equivalent called <code>playSound</code> or something like that. Instead, you have to get the sound data, create <code>AudioBufferSourceNode</code>, connect it to a destination, and then finally start it. This enables some really impressive effects (such as the ones found at <a href="https://webaudiodemos.appspot.com/">https://webaudiodemos.appspot.com/</a>) but means that, for our game, we'll write the one-time code and forget all about it. In JavaScript, the code to load and prepare a sound for playback looks like the following:</p>
			<pre>const audioContext = new AudioContext();
let sound = await fetch("SFX_Jump_23.mp3");
let soundBuffer = await sound.arrayBuffer();
let decodedArray = await audioContext.decodeAudioData(soundBuffer);</pre>
			<p>It starts by creating a new <code>AudioContext</code>, which is built into the browser engine, then fetching a sound file from the server. The <code>fetch</code> call eventually returns a response, which we'll need to decode. We do this by first getting its <code>arrayBuffer</code>, which consumes it, and then we use the <code>audioContext</code> we created at the beginning to decode the buffer into a sound that can be played. Note how everything is asynchronous, which will cause us a little trouble in the Rust code as we map JavaScript promises to Rust futures. The previous code should only be done <em class="italic">once </em>for any sound resource since loading and decoding the file can take significant time.</p>
			<p>The following code will play a sound:</p>
			<pre>let trackSource = audioContext.createBufferSource();
trackSource.buffer = decodedArray;
trackSource.connect(audioContext.destination);
trackSource.start();</pre>
			<p>Ugh, that's not intuitive, but it's what we have. Fortunately, we can wrap it in a few simple functions that we'll be able to remember, and forget all about it. It creates the <code>AudioBufferSourceNode</code> we need with <code>createBufferSource</code>, assigns it the array that we decoded into audio data in the previous section, connects it to the <code>audioContext</code>, and finally, plays<a id="_idIndexMarker625"/> the sound with <code>start</code>. It's important to<a id="_idIndexMarker626"/> know that you cannot call <code>start</code> on <code>trackSource</code> twice, but fortunately, the creation of a buffer source is very fast and won't require us to cache it.</p>
			<p>That's great! We know the eight lines of code to play a sound in JavaScript, but how do we get this into our engi<a id="_idTextAnchor170"/>ne?</p>
			<h2 id="_idParaDest-114"><a id="_idTextAnchor171"/>Playing a sound in Rust</h2>
			<p>We're<a id="_idIndexMarker627"/> going <a id="_idIndexMarker628"/>to<a id="_idIndexMarker629"/> create a <code>sound</code> module that's very similar to our <code>browser</code> module, a series of functions that just delegate right to the underlying JavaScript. It will be a very bottom-up approach, where we'll create our utility functions and then create the final functions that use them. We'll start by focusing on the parts we need for a <code>play_sound</code> function.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">Remember that you want these functions to be very small – it's a <em class="italic">thin</em> layer between Rust and JavaScript – but also to change the interface to better match what you want to do. So, eventually, rather than talking about buffer sources and contexts, we'll want to call that <code>play_sound</code> function we wish existed in the first place.</p>
			<p>We'll start by creating the module in a file named <code>sound.rs</code> living alongside the rest of our modules in <code>src</code>. Don't forget to add a reference to it in <code>src/lib.rs</code>, as shown here:</p>
			<pre>#[macro_use]
mod browser;
mod engine;
mod game;
mod segments;
<strong class="bold">mod sound;</strong></pre>
			<p>That's<a id="_idIndexMarker630"/> the<a id="_idIndexMarker631"/> part I <a id="_idIndexMarker632"/>always forget. Our first function will create an <code>AudioContext</code> in a <em class="italic">Rusty</em> way as opposed to the JavaScript way we already saw, and that's as follows:</p>
			<pre>use anyhow::{anyhow, Result};
use web_sys::AudioContext;
pub fn create_audio_context() -&gt; Result&lt;AudioContext&gt; {
    AudioContext::new().map_err(|err| anyhow!
        ("Could not create audio context: {:#?}", err))
}</pre>
			<p>As usual, the Rust version of the code is more verbose than the JavaScript version. That's the price we pay for the positives of Rust. None of this code is particularly new; we're mapping <code>new AudioContext</code> to <code>AudioContext::new</code>, and we're mapping the <code>JsResult</code> error to an <code>anyhow</code> result that it might return, to be more Rust-friendly. This code doesn't compile though; take a moment and think about why. It's the infamous feature flags for <code>web-sys</code> in <code>Cargo.toml</code> that we haven't added <code>AudioContext</code> to, so <a id="_idIndexMarker633"/>let's<a id="_idIndexMarker634"/> add that <a id="_idIndexMarker635"/>now:</p>
			<pre>[dependencies.web-sys]
version = "0.3.55"
features = ["console",
           "Window",
           "Document",
           "HtmlCanvasElement",
           "CanvasRenderingContext2d",
           "Element",
           "HtmlImageElement",
           "Response",
           "Performance",
           "KeyboardEvent",
           "<strong class="bold">AudioContext</strong>"
           ]</pre>
			<p class="callout-heading">Note</p>
			<p class="callout">Documentation for the <code>AudioContext</code> bindings can be found at <a href="https://bit.ly/3tv5PsD">https://bit.ly/3tv5PsD</a>. Remember you can search the <code>web-sys</code> documentation for any JavaScript object to find its corresponding Rust library.</p>
			<p class="callout-heading">Tip</p>
			<p class="callout">Depending on your editor of choice, you may need to restart <code>rust-analyzer</code> to get correct compiler errors and code actions when adding a new file to the project (such as <code>sound.rs</code>) and/or adding feature flags to the <code>Cargo.toml</code> file.</p>
			<p>Now that we've set up the <code>sound</code> module, created the function to create <code>AudioContext</code>, and refreshed our memory on the process of adding a new feature to the <code>web-sys</code> dependency, we can go ahead and add a little more code to play sounds. Let's <a id="_idIndexMarker636"/>introduce all the remaining <a id="_idIndexMarker637"/>feature <a id="_idIndexMarker638"/>flags you'll need to add to <code>web-sys</code> in <code>Cargo.toml</code>:</p>
			<pre>[dependencies.web-sys]
version = "0.3.55"
features = ["console",
           "Window",
           "Document",
           "HtmlCanvasElement",
           "CanvasRenderingContext2d",
           "Element",
           "HtmlImageElement",
           "Response",
           "Performance",
           "KeyboardEvent",
           "AudioContext",
           "<strong class="bold">AudioBuffer</strong>",
           "<strong class="bold">AudioBufferSourceNode</strong>",
           "<strong class="bold">AudioDestinationNode</strong>",
           ]</pre>
			<p>The three features, <code>AudioBuffer</code>, <code>AudioBufferSourceNode</code>, and <code>AudioDestinationNode</code>, correspond to those same objects in the original JavaScript code. For instance, the <code>let trackSource = audioContext.createBufferSource();</code> function returned <code>AudioBufferSourceNode</code>. The <code>web-sys</code> authors have chosen to hide a large number of audio features under individual flags, so we need to name them one at a time.</p>
			<p class="callout-heading">Tip</p>
			<p class="callout">Remember to check the feature flags whenever you can't use a <code>web-sys</code> feature. It's always listed in the documentation with a note such as "This API requires the following crate features to be activated: <code>AudioContext</code>."</p>
			<p>Now that we have the features ready, we can add the rest of the code without worrying about <a id="_idIndexMarker639"/>those <a id="_idIndexMarker640"/>errors. Back <a id="_idIndexMarker641"/>in the <code>sound</code> module, the code will look like this:</p>
			<pre>use anyhow::{anyhow, Result};
use web_sys::{AudioBuffer, AudioBufferSourceNode, AudioContext, AudioDestinationNode, AudioNode};
...
fn create_buffer_source(ctx: &amp;AudioContext) -&gt; Result&lt;AudioBufferSourceNode&gt; {
    ctx.create_buffer_source()
        .map_err(|err| anyhow!("Error creating buffer 
            source {:#?}", err))
}
fn connect_with_audio_node(
    buffer_source: &amp;AudioBufferSourceNode,
    destination: &amp;AudioDestinationNode,
) -&gt; Result&lt;AudioNode&gt; {
    buffer_source
        .connect_with_audio_node(&amp;destination)
        .map_err(|err| anyhow!("Error connecting audio 
            source to destination {:#?}", err))
}</pre>
			<p>In this book, we've typically gone through the code one function at a time, but for these two it's not necessary. These functions correspond to the calls to <code>audioContext.createBufferSource</code> and <code>trackSource.connect(audioContext.destionation)</code> respectively. We've converted the code from the object-oriented style of JavaScript into a slightly more procedural format with the functions taking parameters, in part so that we can map errors from the <code>JsValue</code> types into proper Rust <code>Error</code> types via the <code>anyhow!</code> macro. </p>
			<p>Now that <a id="_idIndexMarker642"/>we<a id="_idIndexMarker643"/> have the three functions, we need to play a sound. We can go ahead and write the<a id="_idIndexMarker644"/> function that plays it right below them, shown here:</p>
			<pre>pub fn play_sound(ctx: &amp;AudioContext, buffer: &amp;AudioBuffer) -&gt; Result&lt;()&gt; {
    let track_source = create_buffer_source(ctx)?;
    track_source.set_buffer(Some(&amp;buffer));
    connect_with_audio_node(&amp;track_source, 
    &amp;ctx.destination())?;
        track_source
        .start()
        .map_err(|err| anyhow! 
            ("Could not start sound!{:#?}", err))
}</pre>
			<p>The <code>play_sound</code> function accepts <code>AudioContext</code> and <code>AudioBuffer</code> as parameters, then returns the result of the <code>start</code> call, with <code>JsValue</code> mapped to <code>Error</code>. We haven't created an <code>AudioBuffer</code> yet anywhere, so don't worry that you don't know how to as we'll cross that bridge when we come to it. What we have here is a function that is very similar to the original JavaScript for playing a sound, but with the additional error handling that comes with Rust, including using the <code>?</code> operator to make it easier to read, and a little bit of additional work around <code>None</code> in the <code>track_source.set_buffer(Some(&amp;buffer));</code> line, where we need to wrap a reference to <code>AudioBuffer</code> in <code>Some</code> because <code>track_source</code> has an optional buffer. In JavaScript, this is <code>null</code> or <code>undefined</code>, but in Rust, we need to use the <code>Option</code> type. Otherwise, both the JavaScript and Rust versions do the same thing to play a sound:</p>
			<ol>
				<li>Create <code>AudioBufferSource</code> from <code>AudioContext</code>.</li>
				<li>Set <code>AudioBuffer</code> on the source.</li>
				<li>Connect <code>AudioBufferSource</code> to the <code>AudioContext</code> destination.</li>
				<li>Call <code>start</code> to play the sound.</li>
			</ol>
			<p>This <a id="_idIndexMarker645"/>seems<a id="_idIndexMarker646"/> like <a id="_idIndexMarker647"/>a lot, but in reality, it's very fast, so there's not much use in caching <code>AudioBufferSource</code>, especially since you can only call <code>start</code> once. Now that we can play a sound, it's time to load a sound resource and decode it, so that we have an <code>AudioBuffer</code> to <a id="_idTextAnchor172"/>play. Let's do that now.</p>
			<h2 id="_idParaDest-115"><a id="_idTextAnchor173"/>Loading the sound</h2>
			<p>To load a <a id="_idIndexMarker648"/>sound from the server, we'll need to<a id="_idIndexMarker649"/> translate the following code, which you've already seen, into Rust:</p>
			<pre>let sound = await fetch("SFX_Jump_23.mp3");
let soundBuffer = await sound.arrayBuffer();
let decodedArray = await audioContext.decodeAudioData(soundBuffer);</pre>
			<p>Fetching the resource is something we can already do in our <code>browser</code> module, but we don't have a handy way to get its <code>arrayBuffer</code>, so we'll need to add that. We'll also need to create a Rust version of <code>decodeAudioData</code>. Let's start with the changes we need to add to <code>browser</code>, which are modifications to existing methods. We'll want to split the<a id="_idIndexMarker650"/> old <code>fetch_json</code> function, which looks like this:</p>
			<pre>pub async fn fetch_json(json_path: &amp;str) -&gt; Result&lt;JsValue&gt; {
    let resp_value = fetch_with_str(json_path).await?;
    let resp: Response = resp_value
        .dyn_into()
        .map_err(|element| anyhow!("Error converting {:#?} 
            to Response", element))?;
    JsFuture::from(
        resp.json()
            .map_err(|err| anyhow!("Could not get JSON from 
                response {:#?}", err))?,
    )
    .await
    .map_err(|err| anyhow!("error fetching json {:#?}", err
        ))
}</pre>
			<p>We need to split it into two functions that first fetch <code>Result&lt;Response&gt;</code>, then a second that converts it into JSON:</p>
			<pre>pub async fn fetch_response(resource: &amp;str) -&gt; Result&lt;Response&gt; {
    fetch_with_str(resource)
        .await?
        .dyn_into()
        .map_err(|err| anyhow!("error converting fetch to 
            Response {:#?}", err))
}
pub async fn fetch_json(json_path: &amp;str) -&gt; Result&lt;JsValue&gt; {
   <strong class="bold"> let resp = fetch_response(json_path).await?;</strong>
    JsFuture::from(
        resp.json()
            .map_err(|err| anyhow!("Could not get JSON from 
                response {:#?}", err))?,
    )
    .await
    .map_err(|err| anyhow!("error fetching JSON {:#?}", err
        ))
}</pre>
			<p>This is a<a id="_idIndexMarker651"/> classic case of <em class="italic">the second person pays for abstraction</em>, where we wrote the code we needed in <a href="B17151_02_Final_PG_ePub.xhtml#_idTextAnchor038"><em class="italic">Chapter 2</em></a>,<em class="italic"> Drawing Sprites</em>, to load<a id="_idIndexMarker652"/> JSON, but now we need a version of <code>fetch</code> that can handle multiple kinds of responses, specifically, sound files that will be accessible as an <code>ArrayBuffer</code> instead. That code will need <code>fetch_response</code> but will convert it into a different object. Let's write that code now, right below <code>fetch_json</code>:</p>
			<pre>pub async fn fetch_array_buffer(resource: &amp;str) -&gt; Result&lt;ArrayBuffer&gt; {
    let array_buffer = fetch_response(resource)
        .await?
        .array_buffer()
        .map_err(|err| anyhow!("Error loading array buffer 
            {:#?}", err))?;
    JsFuture::from(array_buffer)
        .await
        .map_err(|err| anyhow!("Error converting array 
            buffer into a future {:#?}", err))?
        .dyn_into()
        .map_err(|err| anyhow!("Error converting raw 
            JSValue to ArrayBuffer {:#?}", err))
}</pre>
			<p>Just as <code>fetch_json</code> does, this starts by calling <code>fetch_response</code> with the passed-in resource. Then, it<a id="_idIndexMarker653"/> calls the <code>array_buffer()</code> function on that response, which will return a promise that resolves to <code>ArrayBuffer</code>. Then, we convert from a promise to <code>JsFuture</code> as usual, in order to use the <code>await</code> syntax. Finally, we call <code>dyn_into</code> to convert the <code>JsValue</code> that all <code>Promise</code> types return into <code>ArrayBuffer</code>. I've skipped over it, but at each step, we use <code>map_err</code> to convert the <code>JsValue</code> errors into <code>Error</code> types. </p>
			<p>The <code>ArrayBuffer</code> type is a JavaScript type that isn't available to our code yet. It's a core JavaScript type, defined in the ECMAScript standard, and in order to use it directly, we need to add the <code>js-sys</code> crate. This is somewhat surprising, as we are already pulling in <code>wasm-bindgen</code> and <code>web-sys</code>, which are both dependent on JavaScript, so why do we need to pull in yet another crate for <code>ArrayBuffer</code>? This has to do with how the various crates are arranged. The <code>web-sys</code> crate has all the web APIs where <code>js-sys</code> is limited to code that is in the ECMAScript standard. Up to now, we haven't had to use anything in core JavaScript except what was exposed by <code>web-sys</code>, but this changes with <code>ArrayBuffer</code>.</p>
			<p>In order for this code to compile, you'll need to add <code>js-sys = "0.3.55"</code> to the list of dependencies in <code>Cargo.toml</code>. It is already in <code>dev-dependencies</code>, so you can just move it from there. You'll also need to add a <code>use</code> <code>js_sys::ArrayBuffer</code> declaration to import the <code>ArrayBuffer</code> struct<code>.</code></p>
			<p class="callout-heading">Tip</p>
			<p class="callout">The various libraries are likely to change in small ways after the publication of this book. If you have any difficulties with these dependencies, check the documentation at <a href="https://github.com/rustwasm/wasm-bindgen">https://github.com/rustwasm/wasm-bindgen</a>. </p>
			<p>Now<a id="_idIndexMarker654"/> that <a id="_idIndexMarker655"/>we can fetch a sound file and get it as an <code>ArrayBuffer</code>, we're ready to write our version of <code>await audioContext.decodeAudioData(soundBuffer)</code>. By now, you may have noticed that we're following the same pattern for wrapping every JavaScript function like this:</p>
			<ol>
				<li value="1">Convert any function that returns a promise, such as <code>decode_audio_data</code>, into <code>JsFuture</code> so you can use it in asynchronous Rust code.</li>
				<li>Map any errors from <code>JsValue</code> into your own error types; in this case, we're using <code>anyhow::Result</code> but you may want more specific errors.</li>
				<li>Use the <code>?</code> operator to propagate errors.</li>
				<li>Check for feature flags, particularly when using <code>web_sys</code> and you just <em class="italic">know</em> a library exists.</li>
			</ol>
			<p>To this, we'll add one more step.</p>
			<ol>
				<li value="5">Cast from <code>JsValue</code> types to more specific types using the <code>dyn_into</code> function.</li>
			</ol>
			<p>Following that same pattern, the Rust version of <code>decodeAudioData</code> goes in the <code>sound</code> module, like this:</p>
			<pre>pub async fn decode_audio_data(
    ctx: &amp;AudioContext,
    array_buffer: &amp;ArrayBuffer,
) -&gt; Result&lt;AudioBuffer&gt; {
    JsFuture::from(
        ctx.decode_audio_data(&amp;array_buffer)
            .map_err(|err| anyhow!("Could not decode audio from array buffer {:#?}", err))?,
    )
    .await
    .map_err(|err| anyhow!("Could not convert promise to 
        future {:#?}", err))?
    .dyn_into()
    .map_err(|err| anyhow!("Could not cast into AudioBuffer 
        {:#?}", err))
}</pre>
			<p>You'll <a id="_idIndexMarker656"/>need to <a id="_idIndexMarker657"/>make sure you add <code>use</code> declarations for <code>js_sys::ArrayBuffer</code> and <code>wasm_bindgen_futures::JsFuture</code>, and also <code>wasm_bindgen::JsCast</code> to bring the <code>dyn_into</code> function into scope. Once again instead of directly calling the method on <code>AudioContext</code>, in this case <code>decodeAudioData</code>, we've created a function that wraps the call. It borrows a reference to <code>AudioContext</code> as the first parameter and takes the <code>ArrayBuffer</code> type as the second parameter. This allows us to encapsulate the mapping of errors and casting of results into a function.</p>
			<p>This function then delegates to <code>ctx.decode_audio_data</code>, passing it <code>ArrayBuffer</code>, but if that's all it did we wouldn't really need it. It then takes any error from <code>ctx.decode_audio_data</code> and maps it to <code>Error</code> with <code>anyhow!</code>; in fact, as you can see, it will ultimately do this at every step in the process, pairing that with the <code>?</code> operator to propagate the error. It takes a promise from <code>decode_audio_data</code> and creates <code>JsFuture</code> from it, then immediately calls <code>await</code> to wait for completion, corresponding to the <code>await</code> call in JavaScript. After handling any errors converting the promise to <code>JsFuture</code>, we use the <code>dyn_into</code> function to cast it to <code>AudioBuffer</code>, ultimately handling any errors with that as well.</p>
			<p>That function is the most complicated of the wrapper functions, so let's reiterate the steps we did when translating from one line of JavaScript to nine lines of Rust:</p>
			<ol>
				<li value="1">Convert any function that returns a promise into <code>JsFuture</code> so you can use it in asynchronous Rust code.</li>
			</ol>
			<p>In this case, <code>decode_audio_data</code> returned a promise, and we converted it into <code>JsFuture</code> with <code>JsFuture::from</code>, then immediately called <code>await</code> on it.</p>
			<ol>
				<li value="2">Map<a id="_idIndexMarker658"/> any <a id="_idIndexMarker659"/>errors from <code>JsValue</code> into your own error type; in this case, we're using <code>anyhow::Result</code>, but you may want more specific errors.</li>
			</ol>
			<p>We did this three times, as every call seemed to return a <code>JsValue</code> version of the result, adding clarifying language to the error messages.</p>
			<ol>
				<li value="3">Cast from <code>JsValue</code> types to more specific types using the <code>dyn_into</code> function.</li>
			</ol>
			<p>We did this to convert the ultimate result of <code>decode_audio_data</code> from <code>JsValue</code> to <code>AudioBuffer</code>, and Rust's compiler could infer the appropriate type from the return value of the function.</p>
			<ol>
				<li value="4">Don't forget to use the <code>?</code> operator to propagate errors; note how this function does that twice.</li>
			</ol>
			<p>We used the <code>?</code> operator twice to make the function easier to read.</p>
			<ol>
				<li value="5">Check for feature flags, particularly when using <code>web_sys</code> and you just <em class="italic">know</em> a library exists.</li>
			</ol>
			<p><code>AudioBuffer</code> is feature flagged, but we added that back at the beginning.</p>
			<p>This process is a bit more complicated to explain than it is in practice. For the most part, you can follow the compiler and use tools such as <code>rust-analyzer</code> to do things such as automatically add <code>use</code> declarations.</p>
			<p>Now that we've got all the utilities, we need to play a sound. It's time to add that feature<a id="_idIndexMarker660"/> to <a id="_idIndexMarker661"/>the<a id="_idTextAnchor174"/> <code>engine</code> module so our game can use it.</p>
			<h2 id="_idParaDest-116"><a id="_idTextAnchor175"/>Adding audio to the engine</h2>
			<p>The<a id="_idIndexMarker662"/> functions<a id="_idIndexMarker663"/> we just <a id="_idIndexMarker664"/>created in the <code>sound</code> module could be used by the engine directly via delegation functions, but we don't want to make the game worry about <code>AudioContext</code>, <code>AudioBuffer</code>, and things like that. Just like <code>Renderer</code>, we'll create an <code>Audio</code> struct that encapsulates the details of that implementation. We'll also create a <code>Sound</code> struct to convert <code>AudioBuffer</code> into a friendlier type for the rest of the system. Those will be very small, as shown here:</p>
			<pre>#[derive(Clone)]
pub struct Audio {
    context: AudioContext,
}
#[derive(Clone)]
pub struct Sound {
    buffer: AudioBuffer,
}</pre>
			<p>These structs are added to the bottom of the <code>engine</code> module, but they can really be put anywhere in the file. Don't forget to import <code>AudioContext</code> and <code>AudioBuffer</code>! If you're finding yourself getting confused as <code>engine</code> and <code>game</code> get larger, you're welcome to break that up into multiple files with a <code>mod.rs</code> file and a directory, but to follow along, everything needs to end up in the <code>engine</code> module. I'm not going to do that because, while it makes the code a bit easier to navigate, it makes it harder to explain and follow along with. Breaking it up into smaller chunks later is an excellent exercise to make sure you understand the code we're writing.</p>
			<p>Now that we have a struct representing <code>Audio</code> holding <code>AudioContext</code>, and a corresponding <code>Sound</code> holding <code>AudioBuffer</code>, we can add <code>impl</code> to <code>Audio</code>, which uses the functions we wrote earlier to play a sound. Now, we'll want to add <code>impl</code> to the <code>Audio</code> struct to play<a id="_idIndexMarker665"/> sounds and load them. Let's start with the load<a id="_idIndexMarker666"/> implementation, which is <a id="_idIndexMarker667"/>probably the hardest, as seen here:</p>
			<pre>impl Audio {
    pub fn new() -&gt; Result&lt;Self&gt; {
        Ok(Audio {
            context: sound::create_audio_context()?,
        })
    }
    pub async fn load_sound(&amp;self, filename: &amp;str) -&gt;         Result&lt;Sound&gt; {
        let array_buffer = 
            browser::fetch_array_buffer(filename).await?;
        let audio_buffer = 
            sound::decode_audio_data(&amp;self.context, 
                &amp;array_buffer).await?;
        Ok(Sound {
            buffer: audio_buffer,
        })
    }
}</pre>
			<p>This <code>impl</code> will start with two methods, the familiar <code>new</code> method that creates an <code>Audio</code> struct with <code>AudioContext</code>. Pay attention to the fact that <code>new</code> returns a result in this case, because <code>create_audio_context</code> can fail. Then, we have the <code>load_sound</code> method, which also returns a result, this time of the <code>Sound</code> type, which is only three lines. This is a sign we did something right with the way we organized our functions in the <code>sound</code> and <code>browser</code> modules, as we can simply call our <code>fetch_array_buffer</code> and <code>decode_audio_data</code> functions to get <code>AudioBuffer</code> and then wrap it in a <code>Sound</code> struct. We return a result and propagate errors via <code>?</code>. If <a id="_idIndexMarker668"/>loading <a id="_idIndexMarker669"/>a <a id="_idIndexMarker670"/>sound was simple, then playing it is easy in this method on the <code>Audio</code> implementation:</p>
			<pre>impl Audio {
    ...
    pub fn play_sound(&amp;self, sound: &amp;Sound) -&gt; Result&lt;()&gt; {
        sound::play_sound(&amp;self.context, &amp;sound.buffer)
    }
}</pre>
			<p>For <code>play_sound</code>, we really just delegate, passing along <code>AudioContext</code> that <code>Audio</code> holds and <code>AudioBuffer</code> from the passed-in sound. </p>
			<p>We've written a module to play sounds in the API, added loading sounds to the browser, and finally created an audio portion of our game engine. That's enough to play a sound effect in the <a id="_idIndexMarker671"/>engine; now we need to add it<a id="_idIndexMarker672"/> to<a id="_idTextAnchor176"/><a id="_idIndexMarker673"/> our game, and here it's going to get complicated.</p>
			<h1 id="_idParaDest-117"><a id="_idTextAnchor177"/>Playing sound effects</h1>
			<p>Adding sound <a id="_idIndexMarker674"/>effects to our game is a challenge for several reasons:</p>
			<ul>
				<li>Effects must only occur once:</li>
			</ul>
			<p>We'll be adding a sound effect for jumping (<em class="italic">boing!</em>) and want to make sure that it only happens one time. Fortunately, we have something for that already, our state machine! We can use <code>RedHatBoyContext</code> to play a sound when something happens, something like this (don't add it yet):</p>
			<pre>impl RedHatBoyContext {
    ...
    fn play_jump_sound(audio: &amp;Audio) {
        audio.play_sound(self.sound)
    }
}</pre>
			<p>This leads directly into our second challenge.</p>
			<ul>
				<li>Playing audio on transitions:</li>
			</ul>
			<p>We want to play the sound at the moment of transition, but most transitions won't play a sound. Remember our state machine uses <code>transition</code> to transition from one event to another, and while we could pass in the audio there it would only be used by a small portion of the code in that method. It's a code smell, so we won't do that. <code>RedHatBoyContext</code> will have to own the audio and the sound. This isn't ideal, we'd prefer there to be only one audio in the system, but that's not workable with our state machine. That leads to our third problem.</p>
			<ul>
				<li><code>AudioContext</code> and <code>AudioBuffer</code> are not <code>Copy</code>:</li>
			</ul>
			<p>In order to use syntax such as <code>self.state = self.state.jump();</code> in the <code>RedHatBoy</code> implementation and have each state transition consume <code>RedHatBoyContext</code>, we needed <code>RedHatBoyContext</code> to be <code>Copy</code>. Unfortunately, <code>AudioContext</code> and <code>AudioBuffer</code> are not <code>Copy</code>, which means <code>Audio</code> and <code>Sound</code> cannot be <code>Copy</code> and, therefore, if <code>RedHatBoyContext</code> is going to hold audio and a sound, it cannot also be a copy. This stinks, but we can fix it by refactoring <code>RedHatBoyContext</code> and <code>RedHatBoy</code> to use the <code>clone</code> function as needed.</p>
			<p>Having <code>RedHatBoyContext</code> own an audio means that there will be more than one <code>Audio</code> object in the system potentially, where the other will play music. This is redundant but mostly harmless, so it's the solution we'll go with. It gets us moving forward with development, and in the end, the solution works well. When in doubt, choose the<a id="_idIndexMarker675"/> solution that ships.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">You may wonder why we don't store a reference to <code>Audio</code> in <code>RedHatBoyContext</code>. Ultimately, <code>Game</code> is static in our engine, and therefore, an <code>Audio</code> reference must be guaranteed to live as long as <code>Game</code> if it's stored as a reference on <code>RedHatBoyContext</code>.</p>
			<p class="callout">There are other options, including using the service locator pattern (<a href="https://bit.ly/3A4th2f">https://bit.ly/3A4th2f</a>) or passing in the audio into the <code>update</code> function as a parameter, but they all take longer to get us to our end goal of playi<a id="_idTextAnchor178"/>ng a sound, which is the real goal of this chapter. </p>
			<p>Before we can add a sound effect to the game, we're going to refactor the code to hold an <code>Audio</code> element. Then we'll play the sound effect.</p>
			<h2 id="_idParaDest-118"><a id="_idTextAnchor179"/>Refactoring RedHatBoyContext and RedHatBoy</h2>
			<p>We're<a id="_idIndexMarker676"/> going<a id="_idIndexMarker677"/> to prepare <code>RedHatBoyContext</code> and <code>RedHatBoy</code> to hold audio and a song before we actually do it because that will make it easier to add the sound. Let's start by making <code>RedHatBoyContext</code> just <code>clone</code>, as shown here:</p>
			<pre><strong class="bold">#[derive(Clone)]</strong>
struct RedHatBoyContext {
    frame: u8,
    position: Point,
    velocity: Point,
}</pre>
			<p>All we've done is removed the <code>Copy</code> trait from the <code>derive</code> declaration. This will cause compiler errors on <code>RedHatBoyStateMachine</code> and <code>RedHatBoyState&lt;S&gt;</code>, which both derive <code>Copy</code>, so you'll need to remove that declaration on those structures as well. Once you've done that, you'll see a bunch of errors like this:</p>
			<pre>nerror[E0507]: cannot move out of `self.state` which is behind a mutable reference
   --&gt; src/game.rs:134:22
    |
134 |         self.state_machine = self.state_machine.run();
    |                      ^^^^^^^^^^ move occurs because `self.state` has type `RedHatBoyStateMachine`, which does not implement the `Copy` trait</pre>
			<p>As expected, the calls to <code>self.state.&lt;method&gt;</code>, where the method takes <code>self</code>, all fail to compile, because <code>RedHatBoyStateMachine</code> doesn't implement <code>Copy</code> anymore. The solution, and we'll do this on every line with this compiler error, is to explicitly clone the state when we want to make the change. Here's the <code>run_right</code> function with the error:</p>
			<pre>impl RedHatBoy {
    ...
    fn run_right(&amp;mut self) {
        self.state_machine = self.state_machine.            transition(Event::Run);
    }</pre>
			<p>And, here it is with the fix:</p>
			<pre>impl RedHatBoy {
    ...
    fn run_right(&amp;mut self) {
        self.state_machine = self.state_machine
<strong class="bold">            clone().</strong>transition(Event::Run);
    }</pre>
			<p>Perhaps <a id="_idIndexMarker678"/>the<a id="_idIndexMarker679"/> most teeth-grindingly offensive instance of this is in the <code>transition</code> method, where we will get a move because of the <code>match</code> statement, shown here:</p>
			<pre>impl RedHatBoyStateMachine {
    fn transition(self, event: Event) -&gt; Self {
        match (self, event) {
            ...
            _ =&gt; <strong class="bold">self</strong>,
        }
    }</pre>
			<p>The trouble with this section is that <code>self</code> is moved into the <code>match</code> statement and cannot be returned in the default case. Trying to use <code>match</code> and <code>self</code> to get around the issue causes all of the typestate methods, such as <code>land_on</code> and <code>knock_out</code>, to fail because they need to consume <code>self</code>. The <em class="italic">cleanest</em> fix is shown here:</p>
			<pre>impl RedHatBoyStateMachine {
    fn transition(self, event: Event) -&gt; Self {
        match (self<strong class="bold">.clone()</strong>, event) {
             ...
             _ =&gt; self,
        }
    }</pre>
			<p>It's gross, I admit, but we are able to keep progressing.</p>
			<p class="callout-heading">Tip</p>
			<p class="callout">I know what you're thinking – performance! We're cloning on each transition! You're absolutely right, but do you know that the performance is adversely impacted? The first rule of performance is <em class="italic">measure first</em>, and until we measure this, we don't actually know if the final version of this code is a problem. I spent a lot of time trying to avoid this <code>clone</code> call because of performance concerns, and it turned out not to make much of a difference at all. Make it work, then make it fast.</p>
			<p>Once you<a id="_idIndexMarker680"/> fix <a id="_idIndexMarker681"/>that error a few times, you're ready to add the audio and the sound to <code>RedHatBoyContext</code>, but what sound will we play?</p>
			<h2 id="_idParaDest-119"><a id="_idTextAnchor180"/>Adding a sound effect </h2>
			<p>Using the Web <a id="_idIndexMarker682"/>Audio API, we can play any sound format that is supported by the <code>audio</code> HTML element, which includes all the common formats of WAV, MP3, MP4, and Ogg. In addition, in 2017, the MP3 license expired, so if you're concerned about that, don't be; you can use MP3 files for sounds without worry.</p>
			<p>Since the Web Audio API is compatible with so many audio formats, you can use sound from all over the internet, provided it's released under the appropriate license. The sound effect we'll be using for jumping is available at <a href="https://opengameart.org/content/8-bit-jump-1">https://opengameart.org/content/8-bit-jump-1</a> and is released under the <em class="italic">Creative Commons public domain</em> license, so we can use it without concern. You don't need to download that bundle and browse through it, although you can, but the jump sound is already bundled with this book's assets at <a href="https://github.com/PacktPublishing/Game-Development-with-Rust-and-WebAssembly/wiki/Assets">https://github.com/PacktPublishing/Game-Development-with-Rust-and-WebAssembly/wiki/Assets</a> in the <code>sounds</code> directory. The specific file we want is <code>SFX_Jump_23.mp3</code>. You'll want to copy that file into the <code>static</code> directory of your Rust project so that it will be available for your game.</p>
			<p>Now that <code>RedHatBoyContext</code> is ready to hold the <code>Audio</code> struct, and the <code>SFX_Jump_23.mp3</code> file is available to be loaded, we can start adding that code. Start with<a id="_idIndexMarker683"/> adding <code>Audio</code> and <code>Sound</code> to <code>RedHatBoyContext</code> as shown here:</p>
			<pre>#[derive(Clone)]
pub struct RedHatBoyContext {
    pub frame: u8,
    pub position: Point,
    pub velocity: Point,
    <strong class="bold">audio: Audio,</strong>
    <strong class="bold">jump_sound: Sound,</strong>
}</pre>
			<p>Remember to add <code>use</code> declarations for <code>Audio</code> and <code>Sound</code> to the <code>red_hat_boy_states</code> module. The code will stop compiling because <code>RedHatBoyContext</code> is being initialized without <code>audio</code> or <code>jump_sound</code>, so we'll need to add that. <code>RedHatBoyContext</code> is initialized in the <code>new</code> method of the <code>RedHatBoyState&lt;Idle&gt;</code> implementation so we'll change that method to take <code>Audio</code> and <code>Sound</code> objects that we'll pass into <code>RedHatBoyContext</code> as shown here:</p>
			<pre>impl RedHatBoyState&lt;Idle&gt; {
    fn new<strong class="bold">(audio: Audio, jump_sound: Sound</strong>) -&gt; Self {
        RedHatBoyState {
            game_object: RedHatBoyContext {
                frame: 0,
                position: Point {
                    x: STARTING_POINT,
                    y: FLOOR,
                },
                velocity: Point { x: 0, y: 0 },
                <strong class="bold">audio</strong>,
                <strong class="bold">jump_sound</strong>,
            },
            _state: Idle {},
        }
    }
}</pre>
			<p>We could create an <code>Audio</code> object here, but then the <code>new</code> method would need to return <code>Result&lt;Self&gt;</code> and I don't think that's appropriate. This will move the compiler error, because where we call <code>RedHatBoyState&lt;Idle&gt;::new</code> is now wrong. That is in <code>RedHatBoy::new</code>, which can now also take <code>Audio</code> and <code>Sound</code> objects and pass them through.</p>
			<p>This leads us to our infamous <code>initialize</code> function in our <code>Game</code> implementation, which fails to compile because it calls <code>RedHatBoy::new</code> without <code>Audio</code> or <code>Sound</code>. This is the<a id="_idIndexMarker684"/> appropriate place to load a file, both because it is <code>async</code> and because it returns a result. We'll create an <code>Audio</code> object in <code>initialize</code>, load up the sound we want, and pass it to the <code>RedHatBoy::new</code> function, as shown here:</p>
			<pre>#[async_trait(?Send)]
impl Game for WalkTheDog {
    async fn initialize(&amp;mut self) -&gt; Result&lt;Box&lt;dyn Game&gt;&gt; {
        match self {
            WalkTheDog::Loading =&gt; {
                ...
                <strong class="bold">let audio = Audio::new()?;</strong>
                <strong class="bold">let sound = audio.load_sound</strong>
<strong class="bold">                    ("SFX_Jump_23.mp3").await?;</strong>
                let rhb = RedHatBoy::new(
                    sheet,
                    engine::load_image("rhb.png").await?,
                    <strong class="bold">audio</strong>,
                    <strong class="bold">sound</strong>,
                );
                ...
            }</pre>
			<p>This will get the app compiling again, but we don't do anything with <code>audio</code> or <code>sound</code>. Remember that all this work was done because we wanted to make sure the sound is only <a id="_idIndexMarker685"/>played <em class="italic">once</em> when we jump, and the way to ensure that is to put the playing of the sound in the transition from <code>Running</code> to <code>Jumping</code>. Transitions are done in the various <code>From</code> implementations via methods on <code>RedHatBoyContext</code>. Let's write a small function called <code>play_jump_sound</code> on <code>RedHatBoyContext</code>, as shown here:</p>
			<pre>impl RedHatBoyContext {
    ...
    fn play_jump_sound(self) -&gt; Self {
        if let Err(err) = self.audio.play_sound
           (&amp;self.jump_sound) {
            log!("Error playing jump sound {:#?}", err);
        }
        self
    }
}</pre>
			<p>This function is written a little differently than the other transition side effect functions in this implementation, because <code>play_sound</code> returns a result, but in order to be consistent with the other transition methods, <code>play_jump_sound</code> really shouldn't. Fortunately, failing to play a sound, while annoying, isn't fatal, so we'll log the error and continue if the sound couldn't be played. The code now compiles, but we need to add the call to <code>play_jump_sound</code> to the transition. Look for <code>jump</code> on <code>RedHatBoyState&lt;Running&gt;</code> and modify that transition to call <code>play_jump_sound</code>, as <a id="_idIndexMarker686"/>shown here:</p>
			<pre>    impl RedHatBoyState&lt;Running&gt; {
        ...
        pub fn jump(self) -&gt; RedHatBoyState&lt;Jumping&gt; {
            RedHatBoyState {
                context: self
                    .context
                    .reset_frame()
                    .set_vertical_velocity(JUMP_SPEED)
                    <strong class="bold">.play_jump_sound(),</strong>
                _state: Jumping {},
            }
        }</pre>
			<p>When this compiles, run the game and you'll see, and hear, RHB jump onto a platform.</p>
			<div><div><img alt="Figure 7.1 – Can you hear it?" src="img/Figure_7.01_B17151.jpg"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.1 – Can you hear it?</p>
			<p class="callout-heading">Tip</p>
			<p class="callout">If, like most developers I know, you have 20+ browser tabs open right now, you may want to close them. It can slow down the browser's sound playback and make the sound timing off.</p>
			<p>Now that you've played one sound effect, consider adding more, for example, when RHB crashes<a id="_idIndexMarker687"/> into an obstacle, or lands cleanly, or slides. The choices are up to you! After you've had a <a id="_idTextAnchor181"/>little fun with sound effects, let's add some background music.</p>
			<h1 id="_idParaDest-120"><a id="_idTextAnchor182"/>Playing long music</h1>
			<p>You might<a id="_idIndexMarker688"/> think that playing music will mean detecting whether the sound is complete and restarting it. This is probably true for the browser's implementation, but fortunately, you don't have to do it. The Web Audio API already has a flag on the <code>AudioBufferSourceNode</code> loop that will play the sound on a loop until it is explicitly stopped. This will make playing background audio rather simple. We can add a flag to the <code>play_sound</code> function in the <code>sound</code> module for the <code>loop</code> parameter, as <a id="_idIndexMarker689"/>shown here:</p>
			<pre><strong class="bold">fn create_track_source(ctx: &amp;AudioContext, buffer: &amp;AudioBuffer) -&gt; Result&lt;AudioBufferSourceNode&gt; {</strong>
    <strong class="bold">let track_source = create_buffer_source(ctx)?;</strong>
    <strong class="bold">track_source.set_buffer(Some(&amp;buffer));</strong>
    <strong class="bold">connect_with_audio_node(&amp;track_source, </strong>
<strong class="bold">        &amp;ctx.destination())?;</strong>
    <strong class="bold">Ok(track_source)</strong>
<strong class="bold">}</strong>
<strong class="bold">pub enum LOOPING {</strong>
<strong class="bold">    NO,</strong>
<strong class="bold">    YES,</strong>
<strong class="bold">}</strong>
pub fn play_sound(ctx: &amp;AudioContext, buffer: &amp;AudioBuffer<strong class="bold">, looping: LOOPING)</strong> -&gt; Result&lt;()&gt; {
    let track_source = <strong class="bold">create_track_source</strong>(ctx, buffer)?;
    <strong class="bold">if matches!(looping, LOOPING::YES) {</strong>
<strong class="bold">        track_source.set_loop(true);</strong>
<strong class="bold">    }</strong>
    track_source
        .start()
        .map_err(|err| anyhow!("Could not start sound! 
            {:#?}", err))
}</pre>
			<p>This starts with the <code>create_track_source</code> function, which is actually a refactoring of the <code>play_sound</code> function. It takes the first three lines of it and extracts them into a separate function for readability. After that, we create a <code>LOOPING</code> enum and use it to check whether we should call <code>set_loop</code> on <code>track_source</code>. You might wonder why we don't just pass <code>bool</code> as the third parameter, and the answer is that it is going to be much easier to read the first line of code shown here than the second:</p>
			<pre>play_sound(ctx, buffer, LOOPING::YES)
play_sound(ctx, buffer, true)</pre>
			<p>Six months from now, when I don't know what that Boolean is for, I'll have to look it up, whereas the version with the enum is obvious. By adding this flag, our program stops compiling <a id="_idIndexMarker690"/>because <code>Audio</code> in the engine is still calling <code>play_sound</code> with two parameters. We can quickly fix that, as shown here:</p>
			<pre>impl Audio {
    ...
    pub fn play_sound(&amp;self, sound: &amp;Sound) -&gt; Result&lt;()&gt; {
        sound::play_sound(&amp;self.context, &amp;sound.buffer<strong class="bold">, </strong>
<strong class="bold">            sound::LOOPING::NO</strong>)
    }</pre>
			<p>We'll also add a new method to play background music, which is just playing a sound with looping turned on:</p>
			<pre>impl Audio {
    ...
    pub fn play_looping_sound(&amp;self, sound: &amp;Sound) -&gt; 
        Result&lt;()&gt; {
        sound::play_sound(&amp;self.context, &amp;sound.buffer, 
            sound::LOOPING::YES)
    }
}</pre>
			<p>I like how the engine has progressively less flexibility than the <code>sound</code> module. The <code>sound</code> and <code>browser</code> modules are wrappers around the browser functionality; the engine provides utilities to help you make a game. Now that the engine provides a way to play background music, we can actually add it to the game. In the assets, there's a second file in the <code>sounds</code> directory, <code>background_song.mp3</code>, which you can copy into the <code>static</code> directory of this project. Once you've done that, we can load and play the background<a id="_idIndexMarker691"/> music in our <code>Game::initialize</code> function:</p>
			<pre>#[async_trait(?Send)]
impl Game for WalkTheDog {
    async fn initialize(&amp;mut self) -&gt; Result&lt;Box&lt;dyn Game&gt;&gt; {
        match self {
            WalkTheDog::Loading =&gt; {
                ...
                let audio = Audio::new()?;
                let sound = audio.load_sound
                    ("SFX_Jump_23.mp3").await?;
               <strong class="bold"> let background_music = audio.load_sound</strong>
<strong class="bold">                    ("background_song.mp3").await?;</strong>
               <strong class="bold">     audio.play_looping_sound</strong>
<strong class="bold">                        (&amp;background_music)?;</strong>
                let rhb = RedHatBoy::new(
                    sheet,
                    engine::load_image("rhb.png").await?,
                    audio,
                    sound,
                );
                ...</pre>
			<p class="callout-heading">Tip</p>
			<p class="callout">Check out <a href="https://gamesounds.xyz/">https://gamesounds.xyz/</a> for royalty-free sounds for your games.</p>
			<p>Here, we load the second song, <code>background_song.mp3</code>, and play it immediately with <code>play_looping_sound</code>. On most browsers, you won't hear the music until you click the canvas to give it focus, so check that if you don't hear anything. One thing to note is that, even though that sound is going to go out of scope, the browser will happily keep playing it. We've passed along the song to the browser and it's in charge now. Nothing changes about the creation of <code>RedHatBoy</code> as the audio is moved into it, and it will eventually be in charge of playing sound effects for the game.</p>
			<p class="callout-heading">Tip</p>
			<p class="callout">You may want to mute your browser while developing, as each time the browser refreshes, the song will restart.</p>
			<p>There you <a id="_idIndexMarker692"/>have it! A proper game with music and soun<a id="_idTextAnchor183"/>d effects! Now to add a UI, so we can actually click <strong class="bold">New Game</strong> on it.</p>
			<h1 id="_idParaDest-121"><a id="_idTextAnchor184"/>Summary</h1>
			<p>In this chapter, you added sounds to your game using the Web Audio API and got an overview of the API itself. The Web Audio API is very broad and has a ton of features, and I'd encourage you to explore it. Your first challenge is to use the <code>gain</code> property to change the volume of the music, which is rather loud at the moment. The Web Audio API also supports features such as stereo surround sound and programmatically generated music. Have some fun and try it out!</p>
			<p>You also added a new module to the game, and further extended the game engine to support it. We even covered refactoring and made some trade-offs to ensure the game would finish without requiring a time-consuming <em class="italic">ideal</em> design. I encourage you to take some time to add more sound effects to the game; you have the skills now to make RHB <em class="italic">thud</em> when he lands or crashes into a rock. Speaking of crashing into rocks, you're probably sick of having to hit <em class="italic">refresh</em> every time you do that, so in the next chapter, we'll add a small UI with a wonderful <strong class="bold">New Game</strong> button.</p>
		</div>
	</body></html>