- en: '10'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Deploying Our Application on AWS
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In a lot of tutorials and educational materials, deployment is rarely covered.
    This is because there are a lot of moving parts, and the process can be fairly
    brittle. It may be more convenient to refer to other resources when mentioning
    deployment.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will cover enough to automate deployment on a server on
    **Amazon Web Services** (**AWS**) and then build and connect to a database from
    there. It must be stressed that deployment and cloud computing are big topics—there
    are whole books written on them.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will get to a point where we can deploy and run our application
    for others to use. Learning how to deploy applications on a server is the final
    step. This is where you will turn the application that you have been developing
    into a practical reality that can be used by others all over the world.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Setting up our build environment
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Managing our software with Docker
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deploying our application on AWS
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By the end of this chapter, you will be able to wrap your code up in Docker
    images and deploy it on a server instance on AWS so that it can be accessed by
    other users. You will also be able to configure infrastructure using **Terraform**,
    which is a tool used to define cloud computing infrastructure such as servers
    and databases as code. Once you have finished this chapter, you will have a few
    build scripts that create a build and deployment server using Terraform, pass
    the data from that Terraform build into config files, **SSH** into these servers,
    and run a series of commands resulting in database migrations and spinning up
    the Docker containers on our server.
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we’ll build on the code built in [*Chapter 9*](B18722_09.xhtml#_idTextAnchor182),
    *Testing Our Application Endpoints and Components*. This can be found at the following
    URL: [https://github.com/PacktPublishing/Rust-Web-Programming-2nd-Edition/tree/main/chapter09/building_test_pipeline](https://github.com/PacktPublishing/Rust-Web-Programming-2nd-Edition/tree/main/chapter09/building_test_pipeline).'
  prefs: []
  type: TYPE_NORMAL
- en: The code for this chapter can be found at [https://github.com/PacktPublishing/Rust-Web-Programming-2nd-Edition/tree/main/chapter10](https://github.com/PacktPublishing/Rust-Web-Programming-2nd-Edition/tree/main/chapter10).
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter also has the following requirements:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We will be using Terraform to automate the building of our servers. Because
    of this, we will need to install Terraform using the following URL: [https://learn.hashicorp.com/tutorials/terraform/install-cli](https://learn.hashicorp.com/tutorials/terraform/install-cli).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'When we are using Terraform, it will be making calls to the AWS infrastructure.
    We will need AWS authentication, which will be done using the AWS client. We will
    be using the AWS client in this chapter, which can be installed using the following
    URL: [https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html](https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You will also need a Docker Hub account so that we can package and deploy our
    application. This can be found at [https://hub.docker.com/](https://hub.docker.com/).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Since you will be deploying the application on a server, you will need to sign
    up for an AWS account. This can be done at the following URL: [https://aws.amazon.com/](https://aws.amazon.com/).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Setting up our build environment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far, we have been running our application with the `cargo run` command. This
    has been working well, but you might have noticed that our application is not
    very fast. In fact, it is relatively slow when we try to log in to the application.
    This seems to be counterintuitive as we are learning Rust to develop faster applications.
  prefs: []
  type: TYPE_NORMAL
- en: 'So far, it does not look very fast. This is because we are not running an optimized
    version of our application. We can do this by adding the `--release` tag. As a
    result, we run our optimized application using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we notice that the compilation takes a lot longer. Running this every
    time we alter the code, and during a development process, is not ideal; hence,
    we have been building and running in debug mode using the `cargo run` command.
    However, now that our optimized application is running, we can see that the login
    process is a lot faster. While we can run the server locally, our aim is to deploy
    our application on a server. To run our application on a server, we are going
    to have to build our application in a Docker image. To ensure that our Docker
    image build runs smoothly, we are going to use an online computing unit on AWS.
    Before we run our build process, we need to carry out the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Set up an AWS **Secure Shell** (**SSH**) key for **Elastic Compute** **Cloud**
    (**EC2**)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Set up the AWS client for our local computer
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Write a Terraform script that builds our build server
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Write a Python script that manages the build
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Write a Bash script that orchestrates the build on the server
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Once we have done the aforementioned steps, we will be able to run an automated
    pipeline that creates a build EC2 server on AWS and then build our Rust application.
    First, let us get started by creating an SSH key for our server.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up an AWS SSH key for an AWS EC2 instance
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'If we want to run commands on a server, we are going to have to connect to
    the server using the SSH protocol over the **Hypertext Transfer Protocol** (**HTTP**).
    However, we cannot have anyone accessing our server as it will not be secure.
    To stop anyone from connecting to our server and running any commands they want,
    we will only allow users to connect to our server if they have an SSH key. To
    create our key, we need to log in to the AWS console and navigate to our EC2 dashboard,
    which can be accessed via the search box, as seen in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.1 – Navigating to the EC2 dashboard with the search box](img/Figure_10.1_B18722.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.1 – Navigating to the EC2 dashboard with the search box
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: It must be noted that AWS might not look like the screenshots in this chapter
    as AWS keeps changing the UI. However, the fundamental concepts will be the same.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once we have navigated to the EC2 dashboard, we can navigate to **Key Pairs**
    in the **Network & Security** section of the panel on the left side of the view,
    as seen in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.2 – Navigating to Key Pairs](img/Figure_10.2_B18722.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.2 – Navigating to Key Pairs
  prefs: []
  type: TYPE_NORMAL
- en: 'Once we have navigated to the **Key Pairs** section, there will be a list of
    key pairs that you already own. If you have built EC2 instances before, you might
    already see some listed. If you have never built an EC2 instance before, then
    you will not have anything listed. On the top right of the screen, you can create
    a key by clicking on the **Create key pair** button shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.3 – Button to allow the creation of a key pair](img/Figure_10.3_B18722.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.3 – Button to allow the creation of a key pair
  prefs: []
  type: TYPE_NORMAL
- en: 'Once we have clicked on this button, we will see the following form:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.4 – Create key pair form](img/Figure_10.4_B18722.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.4 – Create key pair form
  prefs: []
  type: TYPE_NORMAL
- en: 'In the preceding screenshot, we can see that we have named our `remotebuild`
    key; we also state that our key has the `.pem` format and is of the `.ssh` directory.
    Inside the `.ssh` directory, we can create a `keys` directory with the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'The `"$HOME"` environment variable is always available in the Bash shell, and
    it denotes the home directory for the user. This means that other users who log
    in to the computer under a different username cannot access the SSH keys we downloaded
    if we store them in the directory that we have just created. We can now navigate
    to where our key has been downloaded and copy it to our `keys` directory with
    the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'We then must change the permissions for the key so that only the owner of the
    file can read the file with the 600 code for us to use the key for SSH purposes
    with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: We now have an SSH key stored in our `.ssh/keys` directory where we can access
    this key with the correct permissions in order to access the servers that we create.
    Now that we have this, we need programmatic access to our AWS services by setting
    up our AWS client.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up our AWS client
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We will be using Terraform to automate our server build. In order to do this,
    Terraform will make calls to the AWS infrastructure. This means that we must have
    the AWS client installed on our local machine. Before we configure our client,
    we need to get some programmatic user keys. If we do not obtain programmatic access,
    our code will not be authorized to build infrastructure on our AWS account. The
    first step of obtaining the user keys is navigating to the **IAM** section via
    the search box, as seen in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.5 – Navigating to the IAM section](img/Figure_10.5_B18722.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.5 – Navigating to the IAM section
  prefs: []
  type: TYPE_NORMAL
- en: 'Once we have navigated to the **IAM** section, we will get the following layout:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.6 – View of the IAM section](img/Figure_10.6_B18722.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.6 – View of the IAM section
  prefs: []
  type: TYPE_NORMAL
- en: 'We can see in the preceding screenshot that my user has **multi-factor authentication**
    (**MFA**), and I keep my access key rotated. If you are new to AWS, this checklist
    might not be satisfactory, and it is suggested that you follow the security recommendations
    that AWS gives you. We now must access the **Users** option on the left-hand side
    of the view and create a new user by clicking the **Add users** button in the
    top-right corner of the screen, as seen in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.7 – Creating users](img/Figure_10.7_B18722.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.7 – Creating users
  prefs: []
  type: TYPE_NORMAL
- en: 'We can then create a user. It does not matter what name you call the user,
    but you must ensure that they have programmatic access by checking the **Access
    key - Programmatic access** option, as seen in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.8 – First stage of creating a user](img/Figure_10.8_B18722.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.8 – First stage of creating a user
  prefs: []
  type: TYPE_NORMAL
- en: 'Once we have highlighted the programmatic access and defined the username,
    we can move on to the permissions, as seen in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.9 – Defining permissions](img/Figure_10.9_B18722.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.9 – Defining permissions
  prefs: []
  type: TYPE_NORMAL
- en: 'We can see that we have given the user `AdministratorAccess` permissions, which
    will enable us to create and destroy servers and databases. The rest of the steps
    in the user creation process are trivial, and you can get through these by just
    clicking **Next**. Once the user is created, you will be exposed to an access
    key and a secret access key. It is important to note these down in a secure location
    such as a password manager because you will never be able to see your secret access
    key again on the AWS site, and we will need them when configuring our AWS client
    on our local computer. Now that we have the user keys handy, we can configure
    our AWS client with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The AWS client will then prompt you to enter the user keys as and when they
    are required. Once this is done, your AWS client is configured, and we can use
    AWS features programmatically on our local computer. Now, we are ready to start
    creating servers using Terraform in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up our Terraform build
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When it comes to building infrastructure on AWS, we can simply point and click
    in the EC2 dashboard. However, this is not desirable. If you are anything like
    me, when I point and click a series of configuration settings, I forget what I
    have done unless I document it, and let’s be honest, documenting what you’ve clicked
    is not something you are going to look forward to. Even if you are a better person
    than me and you document it, when you change the configuration, there is a chance
    that you will not go back to update the documentation of that change. Pointing
    and clicking is also time-consuming. If we wanted to create some infrastructure
    and then destroy it a week later, and then recreate it a month after that, we
    would be reluctant to touch it if we had to point and click, and our server bills
    would be higher. This is where **infrastructure as code** (**IaC**) comes in.
    We will have to do some pointing and clicking, as we did in the previous sections.
    We cannot do any programmatic access without pointing and clicking to set up programmatic
    access.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we have programmatic access, we can build out our `build` directory,
    which should be next to our `web_app` and `front_end` directories. In the `build`
    directory, we can define our infrastructure for the build server in the `build/main.tf`
    file. It must be noted that the `.tf` extension is the standard extension for
    Terraform files. First, we define which version of Terraform is being used with
    the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that we have defined the Terraform version, we can declare that we are
    using the AWS module. The Terraform registry has modules for a range of platforms,
    including Google Cloud and Microsoft Azure. Anyone can build modules and abstract
    infrastructure to be downloaded on the Terraform registry. Our AWS module usage
    declaration takes the following form:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'You might want to pick a different region if another region suits you. A list
    of the available regions on AWS for EC2 can be found via the following link: [https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-regions-availability-zones.html](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-regions-availability-zones.html).'
  prefs: []
  type: TYPE_NORMAL
- en: 'I’m merely using `"eu-west-2"` for demonstration purposes. We can now build
    our EC2 instance with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '`resource` declares that we are defining a resource to be built, and `aws_instance`
    states that we are using the EC2 instance template in the AWS module. A list of
    the available AWS Terraform modules and their documentation can be found via the
    following link: [https://registry.terraform.io/providers/hashicorp/aws/latest/docs](https://registry.terraform.io/providers/hashicorp/aws/latest/docs).'
  prefs: []
  type: TYPE_NORMAL
- en: '`build_server` is what we are calling it. We can refer to `build_server` anywhere
    else in the Terraform script, and Terraform will work out the order in which resources
    need to be built to make sure all references are accounted for. We can see that
    we have referenced the `"remotebuild"` key that we defined in the previous section.
    We can create multiple EC2 instances that can be accessed by one key if we want.
    We also declare the name so that when we look at our EC2 instances, we know what
    the server is for. We must also note that `user_data` is the Bash script that
    will be run on the new EC2 server once it has been built. The `ami` section is
    a reference to the type of operating system and version being used. Do not directly
    copy my **Amazon Machine Image** (**AMI**) ID in the example unless you are using
    the same region, as AMI IDs can vary depending on the region. If you want to find
    out the AMI ID, go to your EC2 dashboard and click on **Launch an instance**,
    which will result in the following window:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.10 – Launching an instance](img/Figure_10.10_B18722.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.10 – Launching an instance
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, we can see that we are picking **Amazon Linux**. You must select this;
    otherwise, your build scripts will not work. If we zoom in, we can see that the
    AMI ID is visible, as seen here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.11 – Accessing AMI ID for the server](img/Figure_10.11_B18722.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.11 – Accessing AMI ID for the server
  prefs: []
  type: TYPE_NORMAL
- en: 'This will be the AMI ID for the Amazon Linux operating system in the region
    that you want to launch. You can also see nothing is stopping you from using other
    operating systems in other Terraform projects. If you have built EC2 instances
    in the past, you will know that the IP address is random unless we attach an elastic
    IP to the EC2 instance. We will have to produce an output of the IP of our EC2
    instance so that we can connect to it. Our output is defined with the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we can see that we reference our build server using `aws_instance.build_server`.
    Further reading on Terraform outputs is provided in the *Further reading* section.
    At this point, our Terraform build is nearly done. We must remember that we need
    to build the `server_build.sh` script that is going to be run on the EC2 instance
    once the EC2 instance has been built. In our `/build/server_build.sh` file, we
    can install the basic requirements needed for our server with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'With the preceding packages, we will be able to navigate around the server
    looking at file trees with `tree`; we will also be able to perform `git` operations,
    open files, and edit them using `vim`, and have multiple panels open through one
    terminal if we need to with `tmux`. The other packages enable us to compile our
    Rust code. We must also note that we have appended each install with a `-y` tag.
    This is to tell the computer to bypass input prompts and put in default answers.
    This means that we can run this script in the background without any problems.
    We now must install the PostgreSQL drivers with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'We nearly have everything that we need. In the next section, we will be using
    Docker to build and package our applications. This can be done with the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we can see that we install Docker, start the Docker service, and then
    register our user with the Docker service so that we do not have to use `sudo`
    with every Docker command. Seeing as we have installed Docker, we might as well
    install `docker-compose` for completeness. This can be done at the end of our
    script with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'The `curl` command downloads `docker-compose`. We then make the `docker-compose`
    executable with the `chmod` command. The build script is almost finished. However,
    running all the commands that we have defined in the build script will take a
    while. There is a chance that we can SSH into our server before the build script
    has finished. Therefore, we should write a `FINISHED` string to a file to inform
    other processes that the server has all the packages that have been installed.
    We can write our flag with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: We have now built out the infrastructure that is going to build our applications
    for deployment. In the next section, we are going to build scripts that orchestrate
    the building of our application using the build server that we have configured.
  prefs: []
  type: TYPE_NORMAL
- en: Writing our Python application build script
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We could technically try to fit our application-building script in the same
    scripts that we wrote in the previous section. However, it is desired to keep
    our scripts separate. For instance, if we were going to use a `build/run_build.py`
    script, we start by importing everything that we need with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'We now have the absolute path for the `build` directory, we can run Bash commands
    through the `Popen` class, and we can load JSON. Now that we have everything imported,
    we can run our Terraform commands with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: In each of the commands, we go to the directory path and then perform the Terraform
    command. We then wait for the command to finish before moving on to the next command.
    While Python is a slow, easy, and not strongly typed language, here it adds a
    lot of power. We can run multiple Bash commands at the same time and then wait
    for them later if needed. We can also pull data out of processes and manipulate
    this data and feed it into another command easily. The two Terraform commands
    that we carry out in the preceding snippet are `init` and `apply`. `init` sets
    up the Terraform state to record what is going on and downloads the modules that
    we need, which in this case is AWS. The `apply` command runs the Terraform build,
    which will build our EC2 server.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once our EC2 instance is built, we can get the output of Terraform and write
    it to a JSON file, and then load the data from that JSON file with the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that we have the server IP, we can SSH into this server and get it to do
    our builds. However, there could be some concurrency issues. There is a small-time
    window where the Terraform build finishes, but the server is not ready yet to
    accept connections. Therefore, we just need the script to wait for a small period
    before continuing with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Once this is done, we need to pass our server IP into another Bash script that
    manages the build and then destroy the server afterward with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: We have now built the orchestration of a build and the Terraform script that
    defines the infrastructure for the build. We now must build the final build script
    that will run the build commands on the server.
  prefs: []
  type: TYPE_NORMAL
- en: Writing our Bash deployment script
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Our Bash deployment script must take in the IP address of the build server,
    SSH into the server, and run a series of commands on the server. It will also
    have to copy our code onto the server to be built. We can see from the preceding
    code that we can build our build Bash script in the `/build/run_build.sh` file.
    First, we start with the standard boilerplate code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'With this boilerplate code, we have stated that this is a Bash script and that
    the rest of the Bash code will run in the `build` directory. We then upload the
    code from the Rust application with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we can see that we remove the `target` directory. As we remember, the
    `target` directory is built when we build our Rust application; we do not need
    to upload build files from the local build. We then copy our Rust code using the
    `scp` command. We access the first argument passed into the script, which is `$1`.
    Remember that we pass in the IP address, so `$1` is the IP address. We then SSH
    into our server and run commands on this server with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Here, we see that we loop sleeping for 2 seconds on each iteration until the
    `output.txt` file is present. Once the `output.txt` file is present, we know that
    the build script from the Terraform is complete and we can start our build. We
    signal this by echoing `"File found"` to the console. We then install Rust, load
    our `cargo` commands into our shell with the `source` command, move into the `web_app`
    directory, and build our Rust application.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: 'We can get rid of the Python dependency if needed by using the `jq` command
    in our `run_build.sh` script with the following code insertion:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: It must be noted that the references to the `$1` variable are replaced with
    `$IP_ADDRESS`.
  prefs: []
  type: TYPE_NORMAL
- en: 'To run our pipeline without the Python dependency, we merely need to run the
    following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: However, we will be relying on our Python script later on in the chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that our build pipeline is built, we can run it with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: WARNING
  prefs: []
  type: TYPE_NORMAL
- en: Terraform can sometimes be temperamental; if it fails, you may need to run it
    again. Sometimes, I’ve had to perform a Terraform run up to three times before
    it fully works. Every action is stored by Terraform, so do not worry—running the
    Python script again will not result in duplicate servers.
  prefs: []
  type: TYPE_NORMAL
- en: 'When running this command, you will be prompted to write `yes` at three different
    points of the process. The first time is to approve the building of the server
    with Terraform, the second time is to add the IP address of the server to the
    list of known hosts to approve the SSH connection, and the last time is to approve
    the destruction of the server. It usually makes sense to show the printouts in
    this book; however, the printout here is long and would probably take up multiple
    pages. Also, the printouts are obvious. Terraform openly states what is being
    built, the copying and building are also verbose, and the destruction of the server
    with Terraform is also printed out. It will be very clear what is going on when
    you run this build pipeline. You might also notice that there is a range of Terraform
    files that have been created. These files keep track of the state of our resources
    that have been built on the AWS platform. If you delete these state files, you
    have no way of knowing what is built, and duplicates will be spun up. It will
    also prevent Terraform from cleaning up. At the place where I work, at the time
    of writing this, we use Terraform to build massive data models for calculating
    the risk of financial loss over geographical locations. The data being processed
    can go over terabytes per chunk. We use Terraform to spin up a range of powerful
    computers, run data through it (which can take days), and then shut it down when
    it is finished. Multiple people need to monitor this process, so our Terraform
    state is housed in a `state.tf` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: It must be noted that your account needs to have access to the bucket defined.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, it is time to build our frontend application. Looking and what we have
    just done, all we need to do is add to the `/build/run_build.sh` file the steps
    to upload our frontend code to the build server and build the frontend application.
    At this point, you should be able to code this yourself. Right now, it would be
    a good use of your time to stop reading and attempt to build it. If you have attempted
    it yourself, it should look like the code shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: Here, we remove the node modules, copy the code to the server, install node,
    and then run the `install` command for our application. Now that our build pipeline
    is fully working, we can move on to wrapping our software in Docker so that we
    can package the software in Docker and deploy it.
  prefs: []
  type: TYPE_NORMAL
- en: Managing our software with Docker
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far, we have been using Docker to manage our PostgreSQL and Redis databases.
    When it comes to running our frontend and Rust server, we have merely been running
    it directly on our local computer. However, when it comes to running our applications
    on remote servers, it is simpler and easier to distribute. Before we get on to
    deploying our Docker images on servers, we need to build and run them locally,
    which starts with writing our Docker image file.
  prefs: []
  type: TYPE_NORMAL
- en: Writing Docker image files
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Before we proceed, it must be noted that the approach carried out here is the
    simplest, least optimized way to build a Rust server Docker image, because we
    are juggling a lot of new concepts. We cover an optimized way of building Rust
    server Docker images in [*Chapter 13*](B18722_13.xhtml#_idTextAnchor264), *Best
    Practices for a Clean Web App Repository*. When it comes to building a Docker
    image, we need a Dockerfile. This is where we define the steps needed to build
    our image. In our `web_app/Dockerfile` file, we basically borrow a base image
    and then run our commands on top of this image for our application to work. We
    can define the base image and the requirements to run our database interactions
    with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Here in our Docker build, we are starting with the official `rust` image. We
    then update `apt` so that we can download all the available packages. We then
    install `g++` and the `diesel` client so that our database operations will work.
    We then copy the code and config files from our Rust application and define our
    work directory with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we have everything to build our Rust application with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Now our build is done, we move the static binary from the `target` directory
    into our home directory, remove excessive code such as the `target` and `src`
    directories, and allow the static binary file to be executable with the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Now everything is done, we can expose the port at which the web server will
    be running to make the server exposed by the container and execute the command
    that gets run when the Docker image is spun up with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: Now that our Docker image file is written, we can move on to building Docker
    images.
  prefs: []
  type: TYPE_NORMAL
- en: Building Docker images
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Before we can run this, however, we need to remove our build script. There
    is only one thing left our Docker image build needs. When copying over the code
    into the Docker image, we know that the `target` directory has a lot of code and
    files that we do not need in our image. We can avoid copying over the `target`
    directory by having the following code in the `.``dockerignore` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'If we try to compile our application with the build script, Docker will just
    throw itself into an infinite file loop and then time out. This means that our
    `ALLOWED_VERSION` variable in our `main.rs` file takes the following form:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'And we then must comment out our `build` dependency in our `Cargo.toml` file
    with the following code and remove the `build.rs` file entirely:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'We are now ready to build our image; we navigate to where the Dockerfile is
    and run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'This command executes the build defined by the Dockerfile in the current directory.
    The image is tagged `rust_app`. We can list our images with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'This will give us the following printout:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'We can then test to see if our application is properly built; we just run the
    following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'This directly runs our Rust app. Our application should crash instantly with
    the following error:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: We can see that the error is not down to our build, but a connection issue with
    Redis from our counter file. This is reassuring, and it will work when we run
    our Rust application with our two databases.
  prefs: []
  type: TYPE_NORMAL
- en: There is an approach in Docker where you can do multi-layered builds. This is
    where we start off with the `rust` base image, build our application, and then
    move our build into another Docker image with no dependencies. The result is that
    our server image is usually merely 100 MB as opposed to multiple GB. However,
    our application has a lot of dependencies, and this multi-layered build approach
    will result in multiple driver errors. We explore building tiny images in [*Chapter
    13*](B18722_13.xhtml#_idTextAnchor264), *Best Practices for a Clean Web* *App
    Repository*.
  prefs: []
  type: TYPE_NORMAL
- en: Building an EC2 build server using Terraform
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We have now built our Rust Docker image locally. We can now build it on our
    build server. Before we do this, we are going to have to increase the size of
    the hard drive on our builder server; otherwise, the image will refuse to build
    due to lack of space. This can be done in our `/build/main.tf` file by adding
    a root block device, as seen in the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: '`gp2` is the version of SSD that AWS supports we are using. `150` is the number
    of GB that we are connecting to the server. This will be enough memory to build
    our Docker images, leaving us only to build the pipeline that constructs our Docker
    images.'
  prefs: []
  type: TYPE_NORMAL
- en: Orchestrating builds with Bash
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'At this point, we are also going to optimize our build Bash script in our `/build/run_build.sh`
    file. First, we do not remove the `target` directory; instead, we are selective
    with what we upload onto our server with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we can see that we make the `web_app` directory, and then upload the
    files and directories that we need to build our Rust Docker image. We then need
    to connect to the server to install Rust with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we can see that we install Rust before we block the script until the
    server is ready with everything installed. This means that we are running the
    installation of Rust at the same time the rest of the server is being built, saving
    time. We then exit the connection to our build server. Finally, we connect to
    the server again and build our Docker image with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: We have then built the pipeline that builds our Rust Docker image on our build
    server. This seems like a lot of steps, and you would be right. We can build our
    image locally with a different target operating system and chip architecture.
    Exploring it here would disjoint the flow of what we are trying to achieve, but
    further information on compiling with different targets will be provided in the
    *Further* *reading* section.
  prefs: []
  type: TYPE_NORMAL
- en: Writing a Docker image file for the React frontend
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'For now, we are going to package our frontend application in Docker. In our
    `front_end/Dockerfile` file, we inherit the node base image, copy the code, and
    define the working directory with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'We then install a `serve` package to serve the web app build files, the modules
    needed to build the application, and build the React application with the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'We then expose the port and server to our application with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'We can then build our Docker image with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'We can then run the recently built image with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'This routes the container’s external port (`80`) to the locally exposed port
    `4000`. When our image is running, we get the following printout:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'This shows that our image is running in a container. We will be able to access
    our frontend container by merely accessing our localhost, which is port `80`,
    as seen in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.12 – Accessing our frontend container using localhost](img/Figure_10.12_B18722.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.12 – Accessing our frontend container using localhost
  prefs: []
  type: TYPE_NORMAL
- en: We will not be able to do anything with it, however, because our Rust server
    is not running. We can now lift the steps that we have carried out to build our
    frontend into our `/build/run_build.sh` script to have our build pipeline construct
    our frontend image as well. This is a good opportunity for you to try to add the
    step yourself. We will have to install node and then carry out the frontend build
    steps on the build server.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you have had an attempt at incorporating our React build in our pipeline,
    it should look like the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: We can be more optimal in our implementation; however, the preceding code is
    the simplest application. First, we copy over the code we need to the build server.
    We then connect to our build server to install node. After installing node, we
    connect to the server again to move into the React application directory and build
    our Docker image.
  prefs: []
  type: TYPE_NORMAL
- en: Our build pipeline is now working. Just think of what we have achieved here—we
    have built a pipeline that constructs a build server; we then copied our code
    onto the build server, constructed Docker images, and then destroyed the server
    after the build was done. Even though this pipeline is not perfect, we have explored
    some powerful tools that will enable you to automate tasks and lift a lot of the
    code that we have covered in this subsection in other CI pipeline tools. However,
    right now, we are just building the Docker images and then destroying them with
    the server. In the next section, we will deploy our images on **Docker Hub**.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying images onto Docker Hub
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Before we can pull our images from Docker Hub, we will have to push our images
    to Docker Hub. Before we can push our images to Docker Hub, we will have to create
    a Docker Hub repo. Registering our image on Docker Hub is straightforward. After
    logging in, we click on the **Create Repository** button in the top-right corner,
    as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.13 – Creating a new repository on Docker Hub](img/Figure_10.13_B18722.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.13 – Creating a new repository on Docker Hub
  prefs: []
  type: TYPE_NORMAL
- en: 'Once we have clicked on this, we define the repository with the following configuration:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.14 – Defining a new Docker repository](img/Figure_10.14_B18722.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.14 – Defining a new Docker repository
  prefs: []
  type: TYPE_NORMAL
- en: We can see that there is an option for connecting our repository with GitHub
    by clicking on the *GitHub* button seen in the preceding screenshot. The **Connected**
    GitHub status in the preceding screenshot simply means that my GitHub is connected
    to my Docker Hub account. This means that every time a successful pull request
    gets completed, the image is rebuilt with the code, and then it is sent to the
    repository. This can be helpful if you are building a fully automated pipeline.
    However, for this book, we will not connect our GitHub repository. We will push
    it onto our build server. You will also need to create a Docker Hub repository
    for our frontend if you are deploying the React application.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we have defined our Docker Hub repositories, we need to add a Docker
    login in our build pipeline. This means that we must pass our Docker Hub password
    and username into our Python build script. Our Python script can then pass the
    Docker Hub credentials into the build Bash script. This build Bash script will
    then log in to Docker on the build server so that we can push our images to our
    Docker Hub. In our `/build/run_build.py` file, we define the arguments passed
    into the Python script with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'We can see that we have set `required` to `True`, which means that the Python
    script will not run unless both parameters are supplied. If we supply a `-h` parameter
    in the Python script, the parameters that we have defined in the preceding code
    will be printed out with help information. Now that we have ingested the Docker
    credentials, we can then pass them into our build Bash script in the `/build/run_build.py`
    file with the following adaptation to our code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we can see that the Docker username is accessed using the `args.u` attribute
    and the Docker password is accessed using the `args.p` attribute. Now that we
    are passing Docker credentials into our build Bash script, we need to use these
    credentials to push our images. In our `/build/run_build.sh` file, we should log
    in after Docker is installed on our build server with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding code, we use `–password-stdin` to pipe our password into the
    Docker login. `stdin` ensures that the password is not stored in the logs, making
    it a little bit more secure. We can then build, tag, and then push our Rust application
    with the update in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we build the Rust image as we always do. We then tag the Rust app image
    as the latest release and then push it to the Docker repository. We also must
    push our frontend application to Docker Hub. At this point, this is a good chance
    for you to write the code that pushes the frontend image. If you did attempt to
    push the frontend image, it should look like the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'We have now coded all that we need to build both of our images and push them
    to our Docker repositories. We can run our Python build script with the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'Again, the printout is lengthy, but we can check our Docker Hub repository
    to see if our image was pushed. As we can see in the following screenshot, the
    Docker Hub repository states when the image has been pushed:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.15 – View of pushed Docker repository](img/Figure_10.15_B18722.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.15 – View of pushed Docker repository
  prefs: []
  type: TYPE_NORMAL
- en: We now have our images pushed onto our Docker Hub repositories! This means that
    we can pull them onto any computer that we need, just as we did when pulling the
    PostgreSQL image in the `docker-compose` file. We should now pull our images onto
    a server so that other people can access and use our application. In the next
    section, we will deploy our application for external use.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying our application on AWS
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Even though we have packaged our Rust application in Docker, we have not run
    our Rust application in a Docker container. Before we run our Rust application
    on a server on AWS, we should run our Rust application locally. This will help
    us understand how a simple deployment works without having to build servers.
  prefs: []
  type: TYPE_NORMAL
- en: Running our application locally
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'When it comes to running our application locally, we will be using `docker-compose`
    with the following layout:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.16 – Structure for local deployment](img/Figure_10.16_B18722.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.16 – Structure for local deployment
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, we can see that the NGINX container takes in traffic from outside of
    the `docker-compose` network and directs the traffic to the appropriate container.
    Now that we understand our structure, we can define our `docker-compose` file.
    First, we need to make a directory called `deployment` next to our `build`, `front_end`,
    and `web_app` directories. Our general layout for our `docker-compose.yml` file
    in our `deployment` directory takes the following form:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'We can start with our NGINX service. Now that we know the outside port is `80`,
    it makes sense that our NGINX container listens to the outside port of `80` with
    the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: We can see that we get the latest NGINX image. We also have links to the `front_end`
    and `rust_app` containers because we will be passing HTTP requests to these containers.
    It also must be noted that we have a volume. This is where we share a volume outside
    of the container with a directory inside the container. So, this volume definition
    means that our `deploy/nginx_config.conf` file can be accessed in the NGINX container
    in the `etc/nginx/nginx.conf` directory. With this volume, we can configure NGINX
    routing rules in our `deploy/nginx_config.conf` file.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we set the number of worker processes to `auto`. We can manually define
    the number of worker processes if needed. `auto` detects the number of CPU cores
    available and sets the number to that with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: 'The `error_log` directive defines the logging to a particular file. We not
    only define the file, but we also state the minimum level needed to write to the
    log file, which is `warning`. By default, the logging level needed to write to
    the file is `error`. We can now move on to defining contexts in our `deploy/nginx_config.conf`
    file. In the `events` context, we define the maximum number of connections that
    a worker can entertain at a time. This is achieved with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: 'The number of workers that we have defined is the default number that NGINX
    sets. Now that this is done, we can move on to our `http` context. Here, we define
    the `server` context. Inside this, we instruct the server to listen to port `80`,
    which is the port that listens to outside traffic, with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we can see that if the URL has `/v1/` at the start of the endpoint, we
    then pass it through the Rust server. It must be noted that we pass `v1` forward
    to the Rust server. If we did not pass `v1` forward to the Rust server, `v1` will
    be missing from the URL when it hits the Rust server. If the URL does not contain
    `v1` in the URL, then we forward it to our `front_end` container. Our NGINX container
    is now ready to manage traffic in our `docker-compose` system. Before we move
    on to our frontend and backend services, we need to define the Redis and PostgreSQL
    databases. There is nothing new here, so at this point, you can try to define
    them yourself. If you have, then your code should look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding database definitions are the same as what we have used before
    in local development. With these databases, we can define our Rust application
    with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we can see that we are not defining an image. Instead of declaring the
    image, we point to a build. The `build` tag is where we point to a `deploy/rust_config.yml`
    file takes the following form:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we can see that we reference the name of the service defined in the `docker-compose`
    system instead of the URL. We also must change the address for our Rust application
    in our `web_app/src/main.rs` file to zeros, as seen here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: 'We then must remove our config file in our Docker build in our `web_app/Dockerfile`
    file with the following line of code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: 'If we do not do this, then our Rust application will not connect with the NGINX
    container. Now everything is defined for our Rust server, we can move on to defining
    the frontend application in our `docker-compose.yml` file with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we see that we reference our image in Docker Hub and expose the ports.
    Now that our local system is defined, we can run our system and interact with
    it by running the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: 'Everything will build and run automatically. Before we can interact with our
    system, we need to run our `diesel` migrations in our Rust application build with
    the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: 'We then need to create a user with the following `curl` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: 'We now have everything in place to interact with our application. We can see
    that localhost with no reference to ports works with the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.17 – Accessing our docker-compose system through the browser](img/Figure_10.17_B18722.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.17 – Accessing our docker-compose system through the browser
  prefs: []
  type: TYPE_NORMAL
- en: If your NGINX is working, you should be able to log in and interact with the
    to-do application as before. We are now able to deploy our system on AWS so that
    other people can access and use our to-do application in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Running our application on AWS
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We can deploy our application on AWS by carrying out the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Building a server
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Running our `docker-compose` system on that server
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Running database migrations on that server
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Creating a user
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Once we have carried out those steps, we will be able to access the application
    on the remote server. However, before we do this, we are going to have to alter
    the React application. Right now, our React application makes API calls to the
    localhost via `127.0.0.1`. When we are using a remote server, this will not work
    as we will have to make calls to the server to which we have deployed our application.
    To do this, we can extract where our API calls are made in the React application
    and update the root of the URL for the API call with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: 'What is happening here is that `window.location.href` returns the current location,
    which will be the IP of the server our application is deployed on, or localhost
    if we are developing it locally on our computer. The following files have API
    calls that need to be updated:'
  prefs: []
  type: TYPE_NORMAL
- en: '`src/components/LoginForm.js`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`src/components/CreateToDoitem.js`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`src/components/ToDoitem.js`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`src/App.js`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Once we have updated these files, we will be able to run another build in the
    `build` directory by running the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: 'Once our build has been done, both our images will be updated. We can now move
    to our `deployment` directory and flesh it out with the following files:'
  prefs: []
  type: TYPE_NORMAL
- en: '`main.tf`: This should be the same as the `main.tf` file in the `build` directory,
    except for the server having a different tag'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`run_build.py`: This should be the same as the `run_build.py` file in the `build`
    directory, except for the *destroy server* process at the end of the `run_build.py`
    script'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`server_build.sh`: This should be the same as the `server_build.sh` script
    in the `build` directory as we want our server to have the same environment as
    when our images were built'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`deployment-compose.yml`: This should be the same as the `docker-compose.yml`
    file in the `deployment` directory, except that `rust_app` service has an image
    tag instead of a build tag and the image tag should have the image of `maxwellflitton/to_do_actix:latest`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`.env`: This should be the same as the `.env` file in the `web_app` directory,
    and we will need it to perform database migrations'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We are now ready to code our `run_build.sh` file that will enable us to deploy
    our application, run migrations, and create a user. First, we start off with some
    standard boilerplate code to ensure that we are in the right directory, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: 'We then copy the files needed to spin up our `docker-compose` system and perform
    database migrations with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: 'None of this should be a surprise as we needed all the preceding files to run
    our `docker-compose` system. We then install Rust and wait for the server build
    to be done with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: 'Again, this is nothing new that we have not seen. We then install the `diesel`
    client with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs: []
  type: TYPE_PRE
- en: 'We then log in to Docker, spin up our `docker-compose` system, run our migrations,
    and then make a user with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs: []
  type: TYPE_PRE
- en: 'With this, our system is deployed! We will be able to access our application
    on our server by putting the IP of the server that is in the `output.json` file
    into the browser. We will be able to log in and use our to-do application just
    like when we were running our system on our local computer, as seen on in the
    following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.18 – Our application on our deployment server](img/Figure_10.18_B18722.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.18 – Our application on our deployment server
  prefs: []
  type: TYPE_NORMAL
- en: As we can see, the connection is not secure and our browser is giving us a warning
    because we are not implementing the HTTPS protocol. This is because our connection
    is not encrypted. We will cover how to encrypt our connection in the next chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Writing our application build script
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Right now, our application is running a database locally on the EC2 instance.
    This has a few problems. Firstly, it means that the EC2 is stateful. If we tear
    down the instance, we will lose all our data.
  prefs: []
  type: TYPE_NORMAL
- en: 'Secondly, if we wipe the containers on the instance, we could also lose all
    our data. Data vulnerability is not the only issue here. Let’s say that our traffic
    drastically increases, and we need more computing instances to manage it. This
    can be done by using NGINX as a load balancer between two instances, as shown
    in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.19 – Doubling our EC2 instances for our system](img/Figure_10.19_B18722.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.19 – Doubling our EC2 instances for our system
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, the problem here is accessing random data. If user one creates
    an item, and this request hits the instance on the left, it is stored in the database
    on the left. However, user one can then make a `GET` request, which hits the instance
    on the right side. The second request will not be able to access the item that
    was created in the first request. The user would be accessing random states depending
    on which instance the request hit.
  prefs: []
  type: TYPE_NORMAL
- en: 'This can be solved by deleting the database from our `docker-compose` file
    and creating a database outside it, as shown in this diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.20 – Our new improved system](img/Figure_10.20_B18722.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.20 – Our new improved system
  prefs: []
  type: TYPE_NORMAL
- en: Now, we have a single point of truth for our data, and our EC2 instances are
    stateless, meaning we have the freedom to create and delete instances as and when
    we need to.
  prefs: []
  type: TYPE_NORMAL
- en: 'When it comes to adding an AWS database to our deployment, we are going to
    have to build our database in Terraform, and then pass the information about the
    constructed database to our `deployment/.env` file for database migrations and
    our `deployment/rust_config.yml` file for our Rust server to access. First, we
    must add the database definition to our `deployment/main.tf` file with the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs: []
  type: TYPE_PRE
- en: 'The fields defined in the preceding code are straightforward apart from the
    `allocated_storage` field, which is the number of GB allocated to the database.
    We can also see that we use variables with the `var` variable. This means that
    we must pass a password and username into our Terraform build when running. We
    need to define our input variables in the `deployment/variables.tf` file with
    the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs: []
  type: TYPE_PRE
- en: 'These variables have defaults, so we do not need to pass in a variable. However,
    if we want to pass in a variable, we can do this with the following layout:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs: []
  type: TYPE_PRE
- en: 'We now must pass these parameters into the needed files and the Terraform build.
    This is where Python starts to shine. We will be reading and writing YAML files,
    so we will have to install the YAML Python package with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE81]'
  prefs: []
  type: TYPE_PRE
- en: 'We then import this package in our `deployment/run_build.py` file at the top
    of the script with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs: []
  type: TYPE_PRE
- en: 'We then load database parameters from a JSON file called `database.json` and
    create our `vars` command string with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE83]'
  prefs: []
  type: TYPE_PRE
- en: 'You can come up with any parameters you want for your `deployment/database.json`
    file; I have recently been playing with GitHub Copilot, which is an AI pair programmer
    that auto-fills code, and this gave me the following parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE84]'
  prefs: []
  type: TYPE_PRE
- en: 'I do not know who `Santiago` is, but the Copilot AI clearly thinks that `Santiago`
    is the right user, so I am going to use it. Going back to our `deployment/run_build.py`
    file, we must pass our parameters to the Terraform `apply` command by updating
    the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE85]'
  prefs: []
  type: TYPE_PRE
- en: 'After the processes that run the Terraform build have finished, we then store
    the output of that build in a JSON file. We then create our own database URL and
    write this URL to a text file with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE86]'
  prefs: []
  type: TYPE_PRE
- en: 'The only thing we need to do now is update our Rust application config data
    with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE87]'
  prefs: []
  type: TYPE_PRE
- en: 'There is only one change left in our pipeline, and this is in our `deployment/run_build.sh`
    file. Instead of copying our local `.env` file to our deployment server, we copy
    our `deployment/database.txt` file with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE88]'
  prefs: []
  type: TYPE_PRE
- en: Running our deployment again will deploy our server and connect it to the AWS
    database that we have created. Again, these build scripts can be brittle. Sometimes,
    a connection can be refused when copying one of the files to the deployment server,
    which can result in the breaking of the entire pipeline. Because we have coded
    all the steps ourselves and understand each step, if there is a break, it will
    not take us much to manually sort out the break or try to run the Python build
    script again.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have finally come to the end of our journey. We have created our own Docker
    image, packaging our Rust application. We then ran this on our local computer
    with the protection of an NGINX container. We then deployed it onto a Docker Hub
    account, enabling us to use it to deploy onto an AWS server that we set up.
  prefs: []
  type: TYPE_NORMAL
- en: It must be noted that we have gone through the lengthy steps of configuring
    containers and accessing our server via SSH. This has enabled us to apply this
    process to other platforms as our general approach was not AWS-centric. We merely
    used AWS to set up the server. However, if we set up a server on another provider,
    we would still be able to install Docker on the server, deploy our image onto
    it, and run it with NGINX and a connection to a database.
  prefs: []
  type: TYPE_NORMAL
- en: There are a few more things we can do as a developer’s work is never done. However,
    we have covered and achieved the core basics of building a Rust web application
    from scratch and deploying it in an automated fashion.
  prefs: []
  type: TYPE_NORMAL
- en: Considering this, there is little holding back developers from building web
    applications in Rust. Frontend frameworks can be added to improve the frontend
    functionality, and extra modules can be added to our application to increase its
    functionality and API endpoints. We now have a solid base to build a range of
    applications and read further on topics to enable us to develop our skills and
    knowledge of web development in Rust.
  prefs: []
  type: TYPE_NORMAL
- en: We are at an exciting time with Rust and web development, and hopefully, after
    getting to this point, you feel empowered to push Rust forward in the field of
    web development. In the next chapter, we will be encrypting our web traffic to
    our application using HTTPS.
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Rust compiling to different targets documentation: [https://doc.rust-lang.org/rustc/targets/index.html](https://doc.rust-lang.org/rustc/targets/index.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'GitHub Actions documentation: [https://github.com/features/actions](https://github.com/features/actions)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Travis CI documentation: [https://docs.travis-ci.com/user/for-beginners/](https://docs.travis-ci.com/user/for-beginners/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'CircleCI documentation: [https://circleci.com/docs/](https://circleci.com/docs/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Jenkins documentation: [https://www.jenkins.io/doc/](https://www.jenkins.io/doc/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Terraform output documentation: [https://developer.hashicorp.com/terraform/language/values/outputs](https://developer.hashicorp.com/terraform/language/values/outputs)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*AWS Certified Developer - Associate Guide*, *Second Edition*, *V. Tankariya*
    and *B. Parmar* (2019), *Packt Publishing*, [*Chapter 5*](B18722_05.xhtml#_idTextAnchor091),
    *Getting Started with Elastic Compute Cloud (EC2)*, page 165'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*AWS Certified Developer - Associate Guide*, *Second Edition*, *V. Tankariya*
    and *B. Parmar* (2019), *Packt Publishing*, [*Chapter 10*](B18722_10.xhtml#_idTextAnchor200),
    *AWS Relational Database Service (RDS)*, page 333'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*AWS Certified Developer - Associate Guide*, *Second Edition*, *V. Tankariya*
    and *B. Parmar* (2019), *Packt Publishing*, *Chapter 21*, *Getting Started with
    AWS CodeDeploy*, page 657'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Mastering Kubernetes*, *G. Sayfan* (2020), *Packt Publishing*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Getting Started with Terraform*, *K. Shirinkin* (2017), *Packt Publishing*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Nginx HTTP Server*, *Fourth Edition*, *M. Fjordvald* and *C. Nedelcu* (2018),
    *Packt Publishing*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
