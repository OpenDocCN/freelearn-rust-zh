<html><head></head><body>
        

                            
                    <h1 class="header-title">Packing Servers to Containers</h1>
                
            
            
                
<p class="mce-root">Microservices created with Rust are pretty simple to deploy: it's sufficient to build a binary for your server, upload that binary to your server, and start it. But that's not a flexible approach for real applications. Firstly, your microservice may need files, templates, and configuration. On the other hand, you may want to use servers with different operating systems. In that case, you would have to build a binary for every system. To reduce the amount of issues with deployment, modern microservices are packed to containers and use virtualization to launch. Virtualization helps to simplify the deployment of a set of microservices. Also, it can help to scale a microservice, because to run an extra instance of a microservice you should only start another copy of the container.</p>
<p>This chapter will immerse you in building Docker images with Rust microservices. We will look at the following:</p>
<ul>
<li>Compiling microservices with Docker.</li>
<li>Preparing a necessary Rust version in a container.</li>
<li>Reducing time spent building images with a Rust microservice. After we have prepared an image, we will create images for multiple microservices.</li>
<li>Creating a compose file for the Docker Compose utility to bootstrap a set of microservices to show how to run a complex project consisting of multiple microservices that interact with each other.</li>
<li>Configuring a set of microservices and adding a database instance to let those microservices store persistent state to a database.</li>
</ul>


            

            
        
    

        

                            
                    <h1 class="header-title">Technical requirements</h1>
                
            
            
                
<p>This chapter requires a full Docker installation with the Docker Compose utility. It doesn't require the Rust compiler, since we will build microservices with Docker containers, but it's good to have the nightly Rust compiler if you want to build and test any microservices locally or play with configuration parameters without patching the <kbd>docker-cocmpose.yml</kbd> file.</p>
<p>To install Docker, follow the instructions for your operating system here: <a href="https://docs.docker.com/compose/install/">https://docs.docker.com/compose/install/</a>.</p>
<p>To install the Docker Compose utility, look at these docs: <a href="https://docs.docker.com/compose/install/">https://docs.docker.com/compose/install/</a>.</p>
<p class="CDPAlignLeft CDPAlign">You can find the examples for this chapter in the <kbd>Chapter15</kbd> folder of the GitHub project: <a href="https://github.com/PacktPublishing/Hands-On-Microservices-with-Rust-2018/">https://github.com/PacktPublishing/Hands-On-Microservices-with-Rust-2018/</a>.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Building a Docker image with a microservice</h1>
                
            
            
                
<p>In the first part of this chapter, we will build a Docker image with the necessary version of the Rust compiler and build an image with a compiled microservice. We will use a set of microservices from other chapters to show how to join microservices created with different frameworks. We will use the <em>users</em>, <em>emails</em>, and <em>content</em> microservices from <a href="6d371e55-d1cf-45b4-83a9-4d5098a885d0.xhtml">Chapter 9</a>,  <em>Simple REST Definition and Request Routing with Frameworks</em><em> </em>and the <em>router</em> microservice from <a href="5b7dd2c1-d623-4422-83a7-e05681230ee9.xhtml">Chapter 11</a>, <em>In</em><em>volving Concurrency with Actors and Actix Crate</em>, and we'll also tune them to be configurable. Also, we will add a <kbd>dbsync</kbd> microservice, which will do all of the necessary migrations to a database, because we will use two microservices that use the database with the <kbd>diesel</kbd> crate and there will be a conflict if both microservices try to apply migrations for their own schema. That's because we'll use a single database, but if you use separate databases (not necessarily different database management applications, but only database files) for every microservice, you can use an individual migration set for every database. It's time to prepare an image with the nightly Rust compiler.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Creating an image with the Rust compiler</h1>
                
            
            
                
<p>There are many ready-to-use images on Docker Hub. You can also find an official image here: <a href="https://hub.docker.com/_/rust/">https://hub.docker.com/_/rust/</a>. But we will create our own image since official images contain a stable compiler version only. If it's enough for you, it's better to use official images, but if you use crates such as <kbd>diesel</kbd>, which need the nightly version of the Rust compiler, you will have to build your own image to build microservices.</p>
<p>Create a new <kbd>Dockerfile</kbd> and add the following content to it:</p>
<pre>FROM buildpack-deps:stretch<br/><br/>ENV RUSTUP_HOME=/usr/local/rustup \<br/>    CARGO_HOME=/usr/local/cargo \<br/>    PATH=/usr/local/cargo/bin:$PATH<br/><br/>RUN set -eux; \<br/>    url="https://static.rust-lang.org/rustup/dist/x86_64-unknown-linux-gnu/rustup-init"; \<br/>    wget "$url"; \<br/>    chmod +x rustup-init; \<br/>    ./rustup-init -y --no-modify-path --default-toolchain nightly; \<br/>    rm rustup-init; \<br/>    chmod -R a+w $RUSTUP_HOME $CARGO_HOME; \<br/>    rustup --version; \<br/>    cargo --version; \<br/>    rustc --version;</pre>
<p>I've borrowed this <kbd>Dockerfile</kbd> from the official Rust Docker image located here: <a href="https://github.com/rust-lang-nursery/docker-rust-nightly/blob/master/nightly/Dockerfile">https://github.com/rust-lang-nursery/docker-rust-nightly/blob/master/nightly/Dockerfile</a>. This file is a good starting point for good practices when creating images with the Rust compiler.</p>
<p>Our Rust image is based on the <kbd>buildpack-deps</kbd> image, which contains all of the necessary dependencies commonly used by developers. This dependency is indicated in the first line with the <kbd>FROM</kbd> command.</p>
<div><kbd>buildpack-deps</kbd> is an official Docker image based on Ubuntu (a free open-source Linux distribution based on Debian). The image includes a lot of headers for libraries such as OpenSSL and curl, and packages with all of the necessary certificates, and so on. It's very useful as a build environment for your Docker images.</div>
<p>The next line, which contains the <kbd>ENV</kbd> command, sets three environment variables in the image:</p>
<ul>
<li><kbd>RUSTUP_HOME</kbd>: Sets the root folder of the <kbd>rustup</kbd> utility, which contains a configuration and installs toolchains</li>
<li><kbd>CARGO_HOME</kbd>: Contains cached files used by the <kbd>cargo</kbd> utility</li>
<li><kbd>PATH</kbd>: The system environment variable that contains paths to executable binaries</li>
</ul>
<p>We target all utilities to the <kbd>/usr/local</kbd> folder by setting these environment variables.</p>
<p>We use the <kbd>rustup</kbd> utility here to bootstrap the Rust environment. It's an official Rust installation tool that helps you to maintain and keep multiple Rust installations up-to-date. In my opinion, using <kbd>rustup</kbd> is the best way to install Rust locally or in a container.</p>
<p>The last <kbd>Dockerfile</kbd> command, <kbd>RUN</kbd>, is complex and we will analyze this set of commands line by line. The first shell command is the following:</p>
<pre><strong>set -eux</strong></pre>
<p>Since the default shell in Ubuntu is the Bash shell, we can set three useful flags:</p>
<ul>
<li><kbd>-e</kbd>: This flag tells the shell to run the next line (command) only if the previous one finished successfully</li>
<li><kbd>-u</kbd>: With this flag, the shell will print an error to <kbd>stderr</kbd> if the command tries to expand a variable that is not set</li>
<li><kbd>-x</kbd>: With this flag, the shell will print every command to <kbd>stderr</kbd> before running it</li>
</ul>
<p>The next three lines download the <kbd>rustup-init</kbd> binary and set the executable flag to the downloaded file:</p>
<pre>url="https://static.rust-lang.org/rustup/dist/x86_64-unknown-linux-gnu/rustup-init"; \<br/>wget "$url"; \<br/>chmod +x rustup-init; \</pre>
<p>The next pair runs the<strong> </strong><kbd>rustup-init</kbd> command with parameters and removes the binary after running:</p>
<pre>./rustup-init -y --no-modify-path --default-toolchain nightly; \<br/>rm rustup-init; \</pre>
<p>The following flags were used:</p>
<ul>
<li><kbd>-y</kbd>: Suppresses any confirmation prompts</li>
<li><kbd>--no-modify-path</kbd>: Won't modify the <kbd>PATH</kbd> environment variable (we set it manually before, for the image)</li>
<li><kbd>--default-toolchain</kbd>: The type of the default toolchain (we will use <kbd>nightly</kbd>)</li>
</ul>
<p>The remaining lines set write permissions to the <kbd>RUSTUP_HOME</kbd> and <kbd>CARGO_HOME</kbd> folders and print the version for all the installed tools:</p>
<pre>chmod -R a+w $RUSTUP_HOME $CARGO_HOME; \<br/>rustup --version; \<br/>cargo --version; \<br/>rustc --version;</pre>
<p>Now you can build the <kbd>Dockerfile</kbd> to get an image that contains the preconfigured Rust compiler:</p>
<pre><strong>docker build -t rust:nightly  .</strong></pre>
<p>This command takes some time to complete, but after it has finished, you will have an image that you can use as a base for building images for microservices. If you type the <kbd>docker images</kbd> command, you will see something like this:</p>
<pre>REPOSITORY   TAG       IMAGE ID       CREATED             SIZE<br/>rust         nightly   91e52fb2cea5   About an hour ago   1.67GB</pre>
<p>Now we will use the image tagged as <kbd>rust:nightly</kbd> and create images for microservices from it. Let's start by creating an image for the users microservice.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Users microservice image</h1>
                
            
            
                
<p>The users microservice provides users with registration capabilities. This chapter contains a modified version of the users microservice from <a href="6d371e55-d1cf-45b4-83a9-4d5098a885d0.xhtml">Chapter 9</a>,  <em>Simple REST Definition and Request Routing with Frameworks</em>. Since this service requires a database and uses the <kbd>diesel</kbd> crate to interact with it, we need to use the <kbd>diesel.toml</kbd> config in the process of building the image.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">.dockerignore</h1>
                
            
            
                
<p>Since Docker copies all files from the building folder, we have to add the <kbd>.dockerignore</kbd> file that contains the patterns of paths to avoid copying these files. It's useful, for example, to skip the <kbd>target</kbd> building folder, because it may contain gigabytes of data for large projects, but in any case, we don't need all of them since we'll build a microservice using the image with the Rust compiler. Add the <kbd>.dockerignore</kbd> file:</p>
<pre>target<br/> Cargo.lock<br/> **/*.rs.bk<br/> files<br/> *.db</pre>
<p>We will ignore all Rust's build artifacts (such as the <kbd>target</kbd>, <kbd>Cargo.lock</kbd>, and <kbd>*.bk</kbd> files that are produced by the <kbd>rustfmt</kbd> tool that we will use later) in the next chapter, where we will explore continuous integration tools. We also included two patterns: <kbd>files</kbd>—this folder will be created by this microservice to store files if you try to run it locally, and <kbd>*.db</kbd>—not a necessary pattern for SQLite Database, because this version uses PostgreSQL instead of SQLite, but useful if you want to support both databases for testing reasons later.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Dockerfile</h1>
                
            
            
                
<p>Now everything is ready to build and pack the microservice to an image. To do this, add the <kbd>Dockerfile</kbd> file to the folder with the microservice and add the following lines to it:</p>
<pre>FROM rust:nightly<br/><br/>RUN USER=root cargo new --bin users-microservice<br/>WORKDIR /users-microservice<br/>COPY ./Cargo.toml ./Cargo.toml<br/>RUN cargo build<br/><br/>RUN rm src/*.rs<br/>COPY ./src ./src<br/>COPY ./diesel.toml ./diesel.toml<br/>RUN rm ./target/debug/deps/users_microservice*<br/>RUN cargo build<br/><br/>CMD ["./target/debug/users-microservice"]<br/><br/>EXPOSE 8000</pre>
<p>We created the image based on the <kbd>rust:nightly</kbd> images that we created earlier in this chapter. We set it using the <kbd>FROM</kbd> command. The next line creates a new crate:</p>
<pre>RUN USER=root cargo new --bin users-microservice</pre>
<p>You might ask why we did that and didn't use an existing crate. That's because we will reproduce the creation of the crate inside the container to build dependencies first, to avoid the lengthy process of rebuilding them, when you would add any tiny change to the source code of the microservice. This approach will save you a lot of time. Copy <kbd>Cargo.toml</kbd> to the image and build all of the dependencies without the sources of the microservice (since we have not copied them yet):</p>
<pre>WORKDIR /users-microservice<br/>COPY ./Cargo.toml ./Cargo.toml<br/>RUN cargo build</pre>
<p>The next set of commands adds sources and the <kbd>diesel.toml</kbd> file to the image, removes previous build results, and builds the crate again with the new sources:</p>
<pre>RUN rm src/*.rs<br/>COPY ./src ./src<br/>COPY ./diesel.toml ./diesel.toml<br/>RUN rm ./target/debug/deps/users_microservice*<br/>RUN cargo build</pre>
<p>At this moment, the image contains a binary of a microservice that we can use as a starting command for containers:</p>
<pre>CMD ["./target/debug/users-microservice"]</pre>
<p>By default, a container doesn't open a port and you can't connect to it with another container or forward the port of a container to a local port. Since our microservice starts at port 8000, we have to expose it using the following command:</p>
<pre><strong>EXPOSE 8000</strong></pre>
<p>The image is ready to build and run a container. Let's do it.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Building an image</h1>
                
            
            
                
<p>We have prepared the Dockerfile to build an image that first builds all the dependencies for our microservice and then builds all the source code. To start this process, you have to use the Docker <kbd>build</kbd> command:</p>
<pre><strong>docker build -t users-microservice:latest </strong></pre>
<p>When you run this command, you will see how Docker prepares files to build an image and builds all the dependencies, but only for the empty crate without the sources of a microservice:</p>
<pre>Sending build context to Docker daemon  13.82kB<br/>Step 1/12 : FROM rust:nightly<br/> ---&gt; 91e52fb2cea5<br/>Step 2/12 : RUN USER=root cargo new --bin users-microservice<br/> ---&gt; Running in 3ff6b18a9c72<br/>     Created binary (application) `users-microservice` package<br/>Removing intermediate container 3ff6b18a9c72<br/> ---&gt; 85f700c4a567<br/>Step 3/12 : WORKDIR /users-microservice<br/> ---&gt; Running in eff894de0a40<br/>Removing intermediate container eff894de0a40<br/> ---&gt; 66366486b1e2<br/>Step 4/12 : COPY ./Cargo.toml ./Cargo.toml<br/> ---&gt; 8864ae055d16<br/>Step 5/12 : RUN cargo build<br/> ---&gt; Running in 1f1150ae4661<br/>    Updating crates.io index<br/> Downloading crates ...<br/> Compiling crates ...<br/>   Compiling users-microservice v0.1.0 (/users-microservice)<br/>    Finished dev [unoptimized + debuginfo] target(s) in 2m 37s<br/>Removing intermediate container 1f1150ae4661<br/> ---&gt; 7868ea6bf9b3</pre>
<p>Our image needs 12 steps in total to build the microservice. As you can see, the building of dependencies takes two and a half minutes. It's not fast. But we don't need to repeat this step till <kbd>Cargo.toml</kbd> has changed. The next steps copy the source code of the microservices into a container and build them with prebuit dependencies:</p>
<pre>Step 6/12 : RUN rm src/*.rs<br/> ---&gt; Running in 5b7d9a1f96cf<br/>Removing intermediate container 5b7d9a1f96cf<br/> ---&gt; b03e7d0b23cc<br/>Step 7/12 : COPY ./src ./src<br/> ---&gt; 2212e3db5223<br/>Step 8/12 : COPY ./diesel.toml ./diesel.toml<br/> ---&gt; 5d4c59d31614<br/>Step 9/12 : RUN rm ./target/debug/deps/users_microservice*<br/> ---&gt; Running in 6bc9df93ebc1<br/>Removing intermediate container 6bc9df93ebc1<br/> ---&gt; c2e3d67d3bf8<br/>Step 10/12 : RUN cargo build<br/> ---&gt; Running in b985b6c793d1<br/>   Compiling users-microservice v0.1.0 (/users-microservice)<br/>    Finished dev [unoptimized + debuginfo] target(s) in 4.98s<br/>Removing intermediate container b985b6c793d1<br/> ---&gt; 553156f97943<br/>Step 11/12 : CMD ["./target/debug/users-microservice"]<br/> ---&gt; Running in c36ff8e44db3<br/>Removing intermediate container c36ff8e44db3<br/> ---&gt; 56e7eb1144aa<br/>Step 12/12 : EXPOSE 8000<br/> ---&gt; Running in 5e76a47a0ded<br/>Removing intermediate container 5e76a47a0ded<br/> ---&gt; 4b6fc8aa6f1b<br/>Successfully built 4b6fc8aa6f1b<br/>Successfully tagged users-microservice:latest</pre>
<p>As you can see in the output, building the microservice takes just 5 seconds. It's fast enough and you can rebuild it as many times as you want. Since the image has been built, we can start a container with our microservice.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Starting a container</h1>
                
            
            
                
<p>The image we built has been stored in Docker and we can see it using the <kbd>docker images</kbd> command:</p>
<pre>REPOSITORY           TAG       IMAGE ID       CREATED         SIZE<br/>users-microservice   latest    4b6fc8aa6f1b   7 minutes ago   2.3GB<br/>rust                 nightly   91e52fb2cea5   3 hours ago     1.67GB</pre>
<p>To start the microservice from an image, use the following command:</p>
<pre><strong>docker run -it --rm -p 8080:8000 users-microservice</strong></pre>
<p>The container with the microservice instance will start but it won't work since we haven't run a container with a database instance. We won't connect containers manually, since it's part of the subtleties of Docker usage, and you can read about that in Docker's documentation; however, we will learn how to connect containers with the Docker Compose tool later in this chapter, in the <em>Composing a microservice set</em> section.</p>
<p>You might also ask: Why is our microservice so big? We will try to reduce it later in this chapter. But now we should pack other microservices to images.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Content microservice image</h1>
                
            
            
                
<p>The second microservice we will use is the content microservice that we created in <a href="6d371e55-d1cf-45b4-83a9-4d5098a885d0.xhtml">Chapter 9,</a> <em>Simple REST Definition and Request Routing with Frameworks</em>. We also prepared this service for use with the PostgreSQL database. We borrowed the <kbd>dockerignore</kbd> file from the previous example and adapted the <kbd>Dockerfile</kbd> file for this microservice. Look at the following code:</p>
<pre>FROM rust:nightly<br/><br/>RUN USER=root cargo new --bin content-microservice<br/>WORKDIR /content-microservice<br/>COPY ./Cargo.toml ./Cargo.toml<br/>RUN cargo build<br/><br/>RUN rm src/*.rs<br/>COPY ./src ./src<br/>RUN rm ./target/debug/deps/content_microservice*<br/>RUN cargo build<br/><br/>CMD ["./target/debug/content-microservice"]<br/>EXPOSE 8000</pre>
<p>As you can see, this <kbd>Dockerfile</kbd> is the same as the <kbd>Dockerfile</kbd> of the previous image, but it has one difference: it doesn't copy any configuration files. We'll are using the Rocket framework, but we will set all the parameters using the environment variables in the Docker Compose file.</p>
<p>You can build this image with the following command to check how it works:</p>
<pre> d<strong>ocker build -t content-microservice:latest .</strong></pre>
<p>But it's not necessary to build this image, because we won't start containers manually—we will use Docker Compose. Let's pack an email microservice to an image too.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Email microservice image</h1>
                
            
            
                
<p>The email microservice doesn't use the <kbd>diesel</kbd> crate and we can use the official Rust image to build a microservice. Also, the email microservice has templates that are used to prepare the contents of emails. We will use the same <kbd>.dockerignore</kbd> file, but will copy <kbd>Dockerfile</kbd> from the previous example and add some changes related to the email microservice:</p>
<pre>FROM rust:1.30.1<br/><br/>RUN USER=root cargo new --bin mails-microservice<br/>WORKDIR /mails-microservice<br/>COPY ./Cargo.toml ./Cargo.toml<br/>RUN cargo build<br/><br/>RUN rm src/*.rs<br/>COPY ./src ./src<br/>COPY ./templates ./templates<br/>RUN rm ./target/debug/deps/mails_microservice*<br/>RUN cargo build<br/><br/>CMD ["./target/debug/mails-microservice"]</pre>
<p>We created this image from the <kbd>rust:1.30.1</kbd> image. The stable version of the compiler is suitable to compile this simple microservice. We also added a command to copy all the templates into the image:</p>
<pre>COPY ./templates ./templates</pre>
<p>Now we can prepare the image with the router microservice.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Router microservice image</h1>
                
            
            
                
<p>If you remember, we created the router microservice in <a href="5b7dd2c1-d623-4422-83a7-e05681230ee9.xhtml">Chapter 11,</a> <em>Involving Concurrency with Actors and the Actix Crate, </em>where we explored features of the Actix framework. We adapted the router microservice to work with other microservices—we added a <kbd>Config</kbd> and a <kbd>State</kbd> that share configuration values with handlers. Also, the improved router microservice serves assets that are in the static folder. We also have to copy this folder to an image. Look at the <kbd>Dockerfile</kbd> of the router microservice:</p>
<pre>FROM rust:1.30.1<br/><br/>RUN USER=root cargo new --bin router-microservice<br/>WORKDIR /router-microservice<br/>COPY ./Cargo.toml ./Cargo.toml<br/>RUN cargo build<br/><br/>RUN rm src/*.rs<br/>COPY ./src ./src<br/>COPY ./static ./static<br/>RUN rm ./target/debug/deps/router_microservice*<br/>RUN cargo build<br/><br/>CMD ["./target/debug/router-microservice"]<br/><br/>EXPOSE 8000</pre>
<p>We also used the official Rust image with the stable compiler. The one difference you will notice in comparison with the previous example is copying the <kbd>static</kbd> folder into an image. We use the same <kbd>.dockerignore</kbd> file as we used for the previous examples.</p>
<p>We have built images for all of the microservices, but the last element we need to add is a worker that will apply migrations to a database. We will use it with Docker Compose later to apply all migrations automatically. Let's create this Docker image.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">DBSync worker image</h1>
                
            
            
                
<p>The DBSync worker has only one function—waiting for a connection with the database and applying all migrations. We'll also pack this worker to a Docker image to use it in a compose file that we will create in the next section of this chapter.</p>
<p class="mce-root"/>


            

            
        
    

        

                            
                    <h1 class="header-title">Dependencies</h1>
                
            
            
                
<p>The worker needs the following dependencies:</p>
<pre>clap = "2.32"<br/>config = "0.9"<br/>diesel = { version = "^1.1.0", features = ["postgres", "r2d2"] }<br/>diesel_migrations = "1.3"<br/>env_logger = "0.6"<br/>failure = "0.1"<br/>log = "0.4"<br/>postgres = "0.15"<br/>r2d2 = "0.8"<br/>serde = "1.0"<br/>serde_derive = "1.0"</pre>
<p>We need the <kbd>diesel</kbd> crate with <kbd>diesel_migrations</kbd> to embed all the migrations into the code. It's not necessary, but useful. We need the <kbd>config</kbd> and <kbd>serde</kbd> crates to configure the worker. The other crates are more common and you can see how we used them in the previous chapters.</p>
<p>Add those dependencies to <kbd>Cargo.toml</kbd> and import the types that we will use in the <kbd>main</kbd> function:</p>
<pre>use diesel::prelude::*;<br/>use diesel::connection::Connection;<br/>use failure::{format_err, Error};<br/>use log::debug;<br/>use serde_derive::Deserialize;</pre>
<p>Now let's create code that will wait for a connection to the database and apply all embedded migrations.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">The main function</h1>
                
            
            
                
<p>Before we create the main function, we have to embed migrations using the <kbd>embed_migrations!</kbd> macro call:</p>
<pre>embed_migrations!();</pre>
<p>This call creates an <kbd>embedded_migrations</kbd> module, which contains the <kbd>run</kbd> function, which applies all migrations to a database. But before we use it, let's add the <kbd>Config</kbd> struct to read the database connection link from a configuration file or an environment variable using the <kbd>config</kbd> crate:</p>
<pre>#[derive(Deserialize)]<br/>struct Config {<br/>    database: Option&lt;String&gt;,<br/>}</pre>
<p>This struct contains only a single parameter—the optional <kbd>String</kbd> with a connection link to the database. We will set this parameter later with Docker Compose using the <kbd>DBSYNC_DATABASE</kbd> environment variable. We have added the <kbd>DBSYNC</kbd> prefix in the <kbd>main</kbd> function. Look at the full code of the <kbd>main</kbd> function:</p>
<pre>fn main() -&gt; Result&lt;(), Error&gt; {<br/>    env_logger::init();<br/>    let mut config = config::Config::default();<br/>    config.merge(config::Environment::with_prefix("DBSYNC"))?;<br/>    let config: Config = config.try_into()?;<br/>    let db_address = config.database.unwrap_or("postgres://localhost/".into());<br/>    debug!("Waiting for database...");<br/>    loop {<br/>        let conn: Result&lt;PgConnection, _&gt; = Connection::establish(&amp;db_address);<br/>        if let Ok(conn) = conn {<br/>            debug!("Database connected");<br/>            embedded_migrations::run(&amp;conn)?;<br/>            break;<br/>        }<br/>    }<br/>    debug!("Database migrated");<br/>    Ok(())<br/>}</pre>
<p>In the preceding code, we initialized <kbd>env_logger</kbd> to print information to strerr. After, we created a generic <kbd>Config</kbd> instance from the <kbd>config</kbd> module and merged environment variables with the <kbd>DBSYNC</kbd> prefix. If the config merged successfully, we try to convert it to a value of our own <kbd>Config</kbd> type that we declared before. We'll use a config to extract a link of a connection to the database. If the value is not provided, we will use the <kbd>postgres://localhost/</kbd> link.</p>
<p>When a connection link is ready, we use a loop to try to connect to the database. We will try to connect to it until it succeeds, because we will use this worker with Docker Compose, and despite the fact we will start a container with the database, it can be unavailable when a database instance is starting. We use a loop to wait for the connection to be ready.</p>
<p>When the connection is ready, we use it to apply embedded migrations with the <kbd>run</kbd> method of the <kbd>embedded_migrations</kbd> module. After the migrations have been applied, we break the loop and stop the worker.</p>
<p>We have all the microservices ready to launch, but their disadvantage is that their source code also remains in the image. This is not good if we want to hide the implementation details of our microservices. Let's explore a technique that hides the sources of microservices using the image building cache.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Hiding microservice source code </h1>
                
            
            
                
<p>The main drawback of building microservices inside an image is that all of the sources and build artifacts will be available for anyone who has access to a Docker image. If you want to remove sources and other building artifacts, you can use one of two approaches.</p>
<ol>
<li>The first approach is to build all sources using a Docker image with the Rust compiler, providing access to sources through a linked virtual volume. In Docker, you can map any local folder to a volume inside a container using the <kbd>-v</kbd> argument of the <kbd>docker run</kbd> command. The disadvantage of this approach is that Docker uses another ID inside the container that you have in your local session. It can create files you can't delete without changing the user ID. Also, this approach is harder to maintain. But it's useful if you need the result of compilation only. If you plan to run a microservice inside a container, it's better to build everything inside an image.</li>
<li>The second approach involves building everything with Docker, but using a building cache to get the compilation result and putting it into a newly created container. Let's explore the <kbd>Dockerfile</kbd> that implements this approach:</li>
</ol>
<pre style="padding-left: 60px">FROM rust:nightly as builder<br/><br/>RUN USER=root cargo new --bin dbsync-worker<br/>WORKDIR /dbsync-worker<br/>COPY ./Cargo.toml ./Cargo.toml<br/>RUN cargo build<br/><br/>RUN rm src/*.rs<br/>COPY ./src ./src<br/>COPY ./migrations ./migrations<br/>COPY ./diesel.toml ./diesel.toml<br/>RUN rm ./target/debug/deps/dbsync_worker*<br/>RUN cargo build<br/><br/>FROM buildpack-deps:stretch<br/><br/>COPY --from=builder /dbsync-worker/target/debug/dbsync-worker  /app/<br/>ENV RUST_LOG=debug<br/>EXPOSE 8000<br/>ENTRYPOINT ["/app/dbsync-worker"]</pre>
<p>We used the <kbd>Dockerfile</kbd> of the dbsync microservice and the first part of the file was the same as the original with one small improvement—we set that name as an image we built in the first line:</p>
<pre>FROM rust:nightly as builder</pre>
<p>Now we can use the cached data of the image using the <kbd>builder</kbd> name.</p>
<p>After this section, we start a new empty image from the <kbd>buildpack-deps</kbd> image that was originally used to build the preceding <kbd>rust:nightly</kbd> image. We copy a binary executable file from the builder image using the <kbd>COPY</kbd> command with the <kbd>--from</kbd> parameter where we set the name of the image:</p>
<pre><strong>COPY --from=builder /dbsync-worker/target/debug/dbsync-worker  /app/</strong></pre>
<p>This command copies the binary to the <kbd>/app</kbd> folder inside the image and we can use it as the entry point of the container:</p>
<pre>ENTRYPOINT ["/app/dbsync-worker"]</pre>
<p>We also set the <kbd>RUST_LOG</kbd> environment variable and expose the port. Build this image by passing the name of this <kbd>Dockerfile</kbd> with the <kbd>-f</kbd> argument of the Docker build command and you will get an image with a single binary of the microservice inside. In other words, this approach allows us to build a microservice and reuse the compiled binary for a new image. You now know enough to pack your microservices to an image and now we can explore Docker Compose's ability to start a set of microservices and connect all launched containers to each other.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Composing a microservice set</h1>
                
            
            
                
<p>Docker Compose is an awesome tool for deploying and running a set of microservices that can be connected each other. It helps you to define a multi-container application with configuration parameters in a human-readable YAML file. You are not limited to local deployment only and you can deploy it on a remote server on which the Docker daemon is also running.</p>
<p class="mce-root"/>
<p>In this section of the chapter, we will pack all our microservices with a database into a single application. You will learn how to set variables for Rust frameworks and loggers, how to connect microservices, how to define the order to start containers, how to read the logs of a running application, and how to use different configurations for testing and production.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Application definition</h1>
                
            
            
                
<p>Docker Compose is a tool that works with the YAML definition of an application. A YAML file can contain a declaration of containers, networks, and volumes. We will use version <kbd>3.6</kbd>. Create a <kbd>docker-compose.test.yml</kbd> file and add the following sections:</p>
<pre>version: "3.6"<br/>services:<br/>    # the place for containers definition</pre>
<p>In the <kbd>services</kbd> section, we will add all our microservices. Let's look at each container configuration.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Database container</h1>
                
            
            
                
<p>Our application needs a database instance. Both user and content microservices use the PostgreSQL database, and the dbsync worker applies all migrations if necessary. Look at these settings:</p>
<pre>db:<br/>  image: postgres:latest<br/>  restart: always<br/>  environment:<br/>    - POSTGRES_USER=postgres<br/>    - POSTGRES_PASSWORD=password<br/>  ports:<br/>    - 5432:5432</pre>
<p>We use the official PostgreSQL image. If the database fails, it will have to be restarted. We set the <kbd>restart</kbd> policy to <kbd>always</kbd>, which means the container will be restarted if it fails. We also set the user and password with environment variables.</p>
<p>Since we created a compose file for testing purposes, we forward a port of the container outside to connect to the database using the local client.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">A container with an email server</h1>
                
            
            
                
<p>We need the SMTP server for our mailer service. We use the <kbd>juanluisbaptiste/postfix</kbd> image with the Postfix mail server. The server also has to be restarted if it fails and we set the <kbd>restart</kbd> policy to <kbd>always</kbd>. Look at the following code:</p>
<pre>smtp:<br/>  image: juanluisbaptiste/postfix<br/>  restart: always<br/>  environment:<br/>    - SMTP_SERVER=smtp.example.com<br/>    - SMTP_USERNAME=admin@example.com<br/>    - SMTP_PASSWORD=password<br/>    - SERVER_HOSTNAME=smtp.example.com<br/>  ports:<br/>    - "2525:25"</pre>
<p>We also configure the server using the environment variables and set the server name, username, password, and a hostname. To test the mail server, we forward port <kbd>25</kbd> of the mail server to a local <kbd>2525</kbd> port.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">DBSync worker container</h1>
                
            
            
                
<p>Now we can add the dbsync worker that applies migrations to a database instance. We use a local image that will be built with <kbd>Dockerfile</kbd> from the <kbd>./microservices/dbsync</kbd> folder that we used as a value for the <kbd>build</kbd> parameter. This worker depends on a database container (called <kbd>db</kbd>) and we set this dependency with the <kbd>depends_on</kbd> parameter.</p>
<p>Dependencies don't mean the dependant container will be started when the necessary application is ready to work. It only refers to the order in which containers are started; the application that your microservice needs might not be ready. You have to control the readiness of the application, as we did for dbsync, with a loop that tries to connect to a database till it is available.</p>
<p>Also, we set the <kbd>RUST_LOG</kbd> variable with the filtering of messages with one level less than <kbd>debug</kbd> and printed messages related to the <kbd>dbsync_worker</kbd> module only:</p>
<pre>dbsync:<br/>  build: ./microservices/dbsync<br/>  depends_on:<br/>    - db<br/>  environment:<br/>    - RUST_LOG=dbsync_worker=debug<br/>    - RUST_BACKTRACE=1<br/>    - DBSYNC_DATABASE=postgresql://postgres:password@db:5432</pre>
<p>We also activated backtrace printing by setting the <kbd>RUST_BACKTRACE</kbd> variable.</p>
<p>The last variable sets a connection link to a database. As you can see, we use the <kbd>db</kbd> name of the host since Docker configures containers to resolve names and match the names of other containers, so you don't need to set or remember the IP address of the container. You can use the names of containers as host names.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Mails microservice container</h1>
                
            
            
                
<p>The microservice that sends emails to users builds on the image from the <kbd>Dockerfile</kbd> stored in the <kbd>./microservices/mails</kbd> folder. This microservice depends on the <kbd>smtp</kbd> container, but this microservice doesn't check that the mail service is ready for work. If you want to check that the mail server is ready, add a piece of code that will try to connect to the SMTP server before starting any activity. Look at the following settings:</p>
<pre>mails:<br/>  build: ./microservices/mails<br/>  depends_on:<br/>    - smtp<br/>  environment:<br/>    - RUST_LOG=mails_microservice=debug<br/>    - RUST_BACKTRACE=1<br/>    - MAILS_ADDRESS=0.0.0.0:8000<br/>    - MAILS_SMTP_ADDRESS=smtp:2525<br/>    - MAILS_SMTP_LOGIN=admin@example.com<br/>    - MAILS_SMTP_PASSWORD=password<br/>  ports:<br/>    - 8002:8000</pre>
<p>We also configure a microservice with environment variables and forward port <kbd>8002</kbd> to port <kbd>8000</kbd> of the container. You  can use port <kbd>8002</kbd> to check that the microservice started and works.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Users microservice container</h1>
                
            
            
                
<p>The users microservice is built from the <kbd>Dockerfile</kbd> we created before. This microservice depends on two other containers—dbsync and mails. First, we need to have a table of users in the database to keep user records in; secondly, we need to have the ability to send email notifications to a user. We also set the address of the socket in the <kbd>USERS_ADDRESS</kbd> variable and the link for the connection in the <kbd>USERS_DATABASE</kbd> variable:</p>
<pre>users:<br/>  build: ./microservices/users<br/>  environment:<br/>    - RUST_LOG=users_microservice=debug<br/>    - RUST_BACKTRACE=1<br/>    - USERS_ADDRESS=0.0.0.0:8000<br/>    - USERS_DATABASE=postgresql://postgres:password@db:5432<br/>  depends_on:<br/>    - dbsync<br/>    - mails<br/>  ports:<br/>    - 8001:8000</pre>
<p>Also, there is a setting to forward port <kbd>8000</kbd> of the container to the local port, <kbd>8001</kbd>, which you can use to access the microservice for testing.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Content microservice container</h1>
                
            
            
                
<p>The content microservice is built with the <kbd>Dockerfile</kbd> file in the <kbd>./microservices/content</kbd> folder. We also created this file earlier in this chapter. Since the content microservice is based on the Rocket framework, we can use the environment variables with the <kbd>ROCKET</kbd> prefix to configure the microservice:</p>
<pre>content:<br/>  build: ./microservices/content<br/>  depends_on:<br/>    - dbsync<br/>  ports:<br/>    - 8888:8000<br/>  environment:<br/>    - RUST_LOG=content_microservice=debug<br/>    - RUST_BACKTRACE=1<br/>    - ROCKET_ADDRESS=0.0.0.0<br/>    - ROCKET_PORT=8000<br/>    - ROCKET_DATABASES={postgres_database={url="postgresql://postgres:password@db:5432"}}<br/>  ports:<br/>    - 8003:8000</pre>
<p>This microservice uses the database and depends on the <kbd>dbsync</kbd> container, which in turn depends on the <kbd>db</kbd> container with a database instance. We open port <kbd>8003</kbd> to access this microservice outside Docker.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Router microservice container</h1>
                
            
            
                
<p>The last service we'll configure before we start the whole application is the router microservice. This service depends on the users and content microservices, because router proxies request these microservices:</p>
<pre>router:<br/>  build: ./microservices/router<br/>  depends_on:<br/>    - users<br/>    - content<br/>  environment:<br/>    - RUST_LOG=router_microservice=debug<br/>    - RUST_BACKTRACE=1<br/>    - ROUTER_ADDRESS=0.0.0.0:8000<br/>    - ROUTER_USERS=http://users:8000<br/>    - ROUTER_CONTENT=http://content:8000<br/>  ports:<br/>    - 8000:8000</pre>
<p>We also configured logging with the <kbd>debug</kbd> level for the <kbd>router_microservice</kbd> namespace, turned on backtrace printing, set the socket address to bind this microservice to, and set paths to the users and content microservices with environment variables supported by the configuration. We used container names as host names, since Docker Compose configures containers to reach each other by name. We also forwarded port <kbd>8000</kbd> to the same system port. Now we can start the application with all of the containers.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Running the application</h1>
                
            
            
                
<p>To run the application, we will use the Docker Compose tool, which has to be installed (you can find useful links in the Technical Requirements section of this chapter). If the utility installed successfully, you'll have the <kbd>docker-compose</kbd> command. Change the directory to a directory called <kbd>docker-compose.test.yml</kbd> and run the <kbd>up</kbd> subcommand:</p>
<pre><strong>docker-compose -f docker-compose.test.yml up</strong></pre>
<p>Thus, it will build all the images if necessary and start the application:</p>
<pre>Creating network "deploy_default" with the default driver<br/>Creating deploy_smtp_1 ... done<br/>Creating deploy_db_1    ... done<br/>Creating deploy_mails_1  ... done<br/>Creating deploy_dbsync_1 ... done<br/>Creating deploy_users_1   ... done<br/>Creating deploy_content_1 ... done<br/>Creating deploy_router_1  ... done<br/>Attaching to deploy_smtp_1, deploy_db_1, deploy_mails_1, deploy_dbsync_1, deploy_content_1, deploy_users_1, deploy_router_1</pre>
<p>When all the containers are started, you will see the logs of all the containers in the terminal, prefixed by the name of the container:</p>
<pre>smtp_1     | Setting configuration option smtp_sasl_password_maps with value: hash:\/etc\/postfix\/sasl_passwd<br/>mails_1    | [2018-12-24T19:08:20Z DEBUG mails_microservice] Waiting for SMTP server<br/>smtp_1     | Setting configuration option smtp_sasl_security_options with value: noanonymous<br/>dbsync_1   | [2018-12-24T19:08:20Z DEBUG dbsync_worker] Waiting for database...<br/>db_1       | <br/>db_1       | fixing permissions on existing directory /var/lib/postgresql/data ... ok<br/>mails_1    | [2018-12-24T19:08:20Z DEBUG mails_microservice] SMTP connected<br/>smtp_1     | Adding SASL authentication configuration<br/>mails_1    | Listening on http://0.0.0.0:8000<br/>mails_1    | Ctrl-C to shutdown server<br/>content_1  | Configured for development.<br/>router_1   | DEBUG 2018-12-24T19:08:22Z: router_microservice: Started http server: 0.0.0.0:8000<br/>content_1  | Rocket has launched from http://0.0.0.0:8000<br/>users_1    | [2018-12-24T19:08:24Z DEBUG users_microservice] Starting microservice...</pre>
<p>Now the application is started and you can connect to it with the browser using this link: <kbd>http://localhost:8000</kbd>.</p>
<p>To stop the application, use the <em>Ctrl+C</em> key combination. That will start the termination process and you will see it reflected in the Terminal:</p>
<pre>Gracefully stopping... (press Ctrl+C again to force)<br/>Stopping deploy_router_1  ... done<br/>Stopping deploy_users_1   ... done<br/>Stopping deploy_content_1 ... done<br/>Stopping deploy_mails_1   ... done<br/>Stopping deploy_db_1      ... done<br/>Stopping deploy_smtp_1    ... do</pre>
<p>If you restart the application, the database will be empty. Why? Because we stored the database on a temporary filesystem of the container. If you need persistence, you can attach a local folder to the container as a virtual volume. Let's explore this feature.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Adding persistent state to the application</h1>
                
            
            
                
<p>We created an application that consists of microservices, and that doesn't have a persistent state – the application is empty on every restart. Fixing this is simple: map the persistent volume to a folder of the container. Since no one microservice of our application keeps the data in files, but the PostgreSQL database does, we only need to attach a folder to a database container. Copy <kbd>docker-compose.test.yml</kbd> to <kbd>docker-compose.prod.yml</kbd> and add the following changes:</p>
<pre>services:<br/>  db:<br/>    image: postgres:latest<br/>    restart: always<br/>    environment:<br/>      - POSTGRES_USER=postgres<br/>      - POSTGRES_PASSWORD=password<br/>    volumes:<br/>      - database_data:/var/lib/postgresql/data<br/>  # other containers definition<br/>volumes:<br/>  database_data:<br/>    driver: local</pre>
<p>We attached a volume with the name <kbd>database_data</kbd> to the <kbd>/var/lib/postgresql/data</kbd> path of the database container. PostgreSQL uses this path by default to store database files. To declare a persistent volume, we use the <kbd>volume</kbd> section with the name of the volume. We set the <kbd>driver</kbd> parameter to <kbd>local</kbd> to keep the data on the local hard drive. Now the data is saved between restarts.</p>
<p>We also removed port forwarding for all of the microservices, excluding the router microservice, since all of the microservices are available via the inner virtual network of Docker and only the router has to be available outside the container.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Running the application in the background</h1>
                
            
            
                
<p>We started the application by attaching the terminal to the output of the containers, but that's inconvenient if you want to deploy an application to a remote server. To detach the terminal, use the <kbd>-d</kbd> parameter when you start:</p>
<pre><strong>docker-compose -f docker-compose.prod.yml up -d</strong></pre>
<p>This will start the application with a persistent state, and print something like the following:</p>
<pre>Starting deploy_db_1   ... done<br/>Starting deploy_smtp_1   ... done<br/>Starting deploy_dbsync_1 ... done<br/>Starting deploy_mails_1   ... done<br/>Starting deploy_content_1 ... done<br/>Starting deploy_users_1   ... done<br/>Starting deploy_router_1  ... done</pre>
<p>It also detaches from the Terminal. You might ask: How can I read the logs that microservices print using <kbd>env_logger</kbd> and the <kbd>log</kbd> crate? Use the following command with the name of the service at the end:</p>
<pre><strong>docker-compose -f docker-compose.prod.yml logs users</strong></pre>
<p>This command will print the logs of the <kbd>users_1</kbd> container, which represents the users service of the application. You can use the <kbd>grep</kbd> command to filter unnecessary records in logs.</p>
<p>Since the application detached from the terminal, you should use the down command to stop the application:</p>
<pre><strong>docker-compose -f docker-compose.test.yml stop</strong></pre>
<p>This will stop all containers and finish with the output: </p>
<pre>Stopping deploy_router_1  ... done<br/>Stopping deploy_users_1   ... done<br/>Stopping deploy_content_1 ... done<br/>Stopping deploy_mails_1   ... done<br/>Stopping deploy_db_1      ... done<br/>Stopping deploy_smtp_1    ... done</pre>
<p>The application has stopped and now you know how to use the Docker Compose tool to run a multi-container application. If you want to learn more about using Docker Compose on local and remote machines, read this book.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Summary</h1>
                
            
            
                
<p>This chapter introduced you to how to build images and run containers with your own microservices using Docker. We packed all of the microservices we created in <a href="6d371e55-d1cf-45b4-83a9-4d5098a885d0.xhtml">Chapter 9</a>, <em>Simple REST Definition and Request Routing with Frameworks</em><em>,</em> and <a href="5b7dd2c1-d623-4422-83a7-e05681230ee9.xhtml">Chapter 11</a>, <em>Involving Concurrency with Actors and the Actix Crate</em>, and learned how to build images manually and start a container. We also added the dbsync worker, which applied all necessary migrations and prepared a database for use with the users and content microservices.</p>
<p>Also, we considered approaches to hiding the source code of a microservice and used the cache of a container to copy a compiled binary to an empty image without building artifacts.</p>
<p>In the second half of the chapter, we learned how to run multiple microservices with necessary dependencies (such as databases and mail servers) at once. We used the Docker Compose tool to describe the configuration of a microservice set with a running order and port forwarding. We also learned how to attach volumes to services (containers), to store persistent data, and to allow you to restart an application without any risk of losing data.</p>
<p>In the next chapter, we will learn how to automate building microservices using continuous integration tools, helping you deliver the latest release of your product faster.</p>


            

            
        
    </body></html>