<html><head></head><body>
        <section>

                            <header class="header-title chapter-title">
                    Storing and Retrieving Data
                </header>
            
            <article>
                
<p>A typical need of any software application is to input/output data by reading/writing data files or data streams or by querying/manipulating a database. Regarding files and streams, unstructured data, or even binary data, is hard to manipulate, and so they are not recommended.</p>
<p>Also, proprietary data formats are not recommended because of the vendor lock-in risk, and so only standard data formats should be used. Fortunately, there are free Rust libraries that come to the rescue in these situations. There are Rust crates available to manipulate some of the most popular file formats, such as TOML, JSON, and XML.</p>
<p>In terms of databases, there are Rust crates to manipulate data using some of the most popular databases, such as SQLite, PostgreSQL, and Redis.</p>
<p>In this chapter, you will learn about the following:</p>
<ul>
<li>How to read configuration data from a TOML file</li>
<li>How to read or write a JSON data file</li>
<li>How to read an XML data file</li>
<li>How to query or manipulate data in a SQLite database</li>
<li>How to query or manipulate data in a PostgreSQL database</li>
<li>How to query or manipulate data in a Redis database</li>
</ul>
<h1 id="uuid-d4a9dd38-b406-44c5-9b4f-a19369f3d5e1" class="mce-root">Technical requirements</h1>
<p class="mce-root">It is required for you to install the SQLite runtime library when you're running the SQLite code. However, it is also useful (although not required) to install a SQLite interactive manager. You can download the precompiled binaries of SQLite tools from <a href="https://www.sqlite.org/download.html">https://www.sqlite.org/download.html</a>. However, version 3.11 or higher would be ideal.</p>
<p>Please note that if you're using Debian-derived Linux distribution, the <kbd>libsqlite3-dev</kbd> <span>package </span>should be installed.</p>
<p>It is also <span>required for you to install and run the PostgreSQL <strong>Database Management System</strong> (<strong>DBMS</strong>) when you're running the PostgreSQL code. As with SQLite, it is useful but not required to install a PostgreSQL interactive manager. You can download the precompiled binary of PostgreSQL DBMS from <a href="https://www.postgresql.org/download/">https://www.postgresql.org/download/</a>. However, version 7.4 or higher would be acceptable.</span></p>
<p>Installing and running the Redis server is necessary when you're running the Redis code. You can download it from <a href="https://redis.io/download">https://redis.io/download</a>. </p>
<p class="mce-root"><span>The complete source code for this chapter can be found in the <kbd>Chapter02</kbd></span><span> </span><span>folder </span><span>of the repository at </span><a href="https://github.com/PacktPublishing/Creative-Projects-for-Rust-Programmers">https://github.com/PacktPublishing/Creative-Projects-for-Rust-Programmers</a><span>. In this folder, there is a sub-folder for every project, plus a folder named</span> <kbd>data</kbd><span>, which contains the data that we'll use as input for the projects.</span></p>
<h1 id="uuid-aedd3cda-cca0-4601-b523-d5815c172542">Project overview</h1>
<p class="mce-root">In this chapter, we'll look at how to build a program that loads a <span>JSON</span> file and an <span>XML</span> file into three databases: a SQLite database, a PostgreSQL database, and a Redis key-value store. To avoid hardwiring the names and positions of the files and the database credentials into the program, we are going to load them from a TOML configuration file.</p>
<p class="mce-root">The final project is named <kbd>transformer</kbd>, but we'll explain this through several preliminary small projects:</p>
<ul>
<li class="mce-root"><kbd>toml_dynamic</kbd> and <kbd>toml_static</kbd>: These read a TOML file in two different ways.</li>
<li><kbd>json_dynamic</kbd> and <kbd>json_static</kbd>: These read a JSON file in two different ways.</li>
<li><kbd>xml_example</kbd>: This reads an XML file.</li>
<li><kbd>sqlite_example</kbd>: This creates two tables in a SQLite database, inserts records into them, and queries them.</li>
<li><kbd>postgresql_example</kbd>: This creates two tables in a PostgreSQL database, inserts records into them, and queries them.</li>
<li><kbd>redis_example</kbd>: This adds some data to a key-value store and queries it.</li>
</ul>
<h1 id="uuid-f8a004c4-cbff-469b-8cbd-98e5b756df5e">Reading a TOML file</h1>
<p class="mce-root">One simple and maintainable way to store information in a filesystem is to use a text file. This is also very efficient for data spanning no more than 100 KB. However, there are several competing standards for storing information in text files, such as INI, CSV, JSON, XML, YAML, and others.</p>
<p class="mce-root">The one used by Cargo is TOML. This is a really powerful format that is used by many Rust developers to store the configuration data of their apps. It is designed to be written by hand, using a text editor, but it can also be written by an application very easily.</p>
<p class="mce-root">The <kbd>toml_dynamic</kbd> and <kbd>toml_static</kbd><span> </span><span>projects</span><span> (using the</span> <kbd>toml</kbd><span> crate) load data from a TOML file. Reading a TOML file is useful when configuring a software application, and this is what we'll do. We will use the</span> <kbd>data/config.toml</kbd><span> </span><span>file, which </span><span>contains all of the parameters for the projects of this chapter.</span></p>
<p>You can also create or modify a TOML file by using code, but we are not going to do that. Being able to modify a TOML file can be useful in some scenarios, such as to save user preferences.</p>
<p>It is important to consider that when a TOML file is changed by a program, it undergoes dramatic restructuring:</p>
<ul>
<li>It acquires specific formatting, which you may dislike.</li>
<li>It loses all of its comments.</li>
<li>Its items are sorted alphabetically.</li>
</ul>
<p>So, if you want to use the TOML format both for manually edited parameters and for program-saved data, you would be better off using two distinct files:</p>
<ul>
<li>One edited only by humans</li>
<li>One edited primarily by your software, but occasionally also by humans</li>
</ul>
<p>This chapter describes two projects in which a TOML file is read using different techniques. These techniques are to be used in two different cases:</p>
<ul>
<li>In a situation where we are not sure which fields are contained in the file, and so we want to explore it. In this case, we use the <kbd>toml_dynamic</kbd> program.</li>
<li><span>In another situation where, </span>in our program, we describe exactly which fields should be <span>contained in the file and we don't accept a different format. In this case, we use the <kbd>toml_static</kbd> program.</span></li>
</ul>
<h2 id="uuid-374d417d-414f-41b0-80a7-f76be7f1e8e8">Using toml_dynamic</h2>
<p>The purpose of this section is to read the <kbd>config.toml</kbd><span> </span><span>file</span><span>, located in the</span> <kbd>data</kbd> <span>folder, when we want to explore the content of that file. The first three lines of this file are as follows:</span></p>
<pre>[input]<br/>xml_file = "../data/sales.xml"<br/>json_file = "../data/sales.json"</pre>
<p>After these lines, the file contains other sections. Among them is the <kbd>[postgresql]</kbd><span> </span><span>section</span><span>, which contains the following line:</span></p>
<pre>database = "Rust2018"</pre>
<p>To run this project, enter the<span> </span><kbd>toml_dynamic</kbd><span> folder and type in <kbd>cargo run ../data/config.toml</kbd>. A long output should be printed. It will begin with the following lines:</span></p>
<pre>Original: Table(<br/>    {<br/>        "input": Table(<br/>            {<br/>                "json_file": String(<br/>                    "../data/sales.json",<br/>                ),<br/>                "xml_file": String(<br/>                    "../data/sales.xml",<br/>                ),<br/>            },<br/>        ),</pre>
<p>Notice that this is just a verbose representation of the first three lines of the <kbd>config.toml</kbd> file. This output proceeds with emitting a similar representation for the rest of the file. After having printed the whole data structure representing the file that is read, the following line is added to the output:</p>
<pre> [Postgresql].Database: Rust2018</pre>
<p>This is the result of a specific query on the data structure loaded when the file is read.</p>
<p>Let's look at the code of<span> the </span><kbd>toml_dynamic</kbd><span> program:</span></p>
<ol>
<li>Declare a variable that will contain a description of the whole file. This variable is initialized in the next three statements:</li>
</ol>
<pre style="padding-left: 60px">let config_const_values =</pre>
<ol start="2">
<li>We add the pathname of the file from the first argument in the command line to <kbd>config_path</kbd>. Then, we load the contents of this file into the <kbd>config_text</kbd> string and we parse this string into a <span><kbd>toml::Value</kbd> structure. This is a recursive structure because it can have a <kbd>Value</kbd> property among its fields:</span></li>
</ol>
<pre style="padding-left: 60px">{<br/>    let config_path = std::env::args().nth(1).unwrap();<br/>    let config_text = <br/>     std::fs::read_to_string(&amp;config_path).unwrap();<br/>    config_text.parse::&lt;toml::Value&gt;().unwrap()<br/>};</pre>
<ol start="3">
<li>This structure is then printed using the debug structured formatting (<kbd>:#?</kbd>), and a value is retrieved from it:</li>
</ol>
<pre style="padding-left: 60px">println!("Original: {:#?}", config_const_values);<br/>println!("[Postgresql].Database: {}",<br/>    config_const_values.get("postgresql").unwrap()<br/>    .get("database").unwrap()<br/>    .as_str().unwrap());</pre>
<p>Notice that to get the value of the <kbd>"database"</kbd> item contained the <kbd>"postgresql"</kbd> section, a lot of code is required. The <kbd>get</kbd> function needs to look for a string, which may fail. That is the price of uncertainty.</p>
<h2 id="uuid-5e13234c-c3ca-463a-b831-fc1667a8af2f">Using toml_static</h2>
<p>On the other hand, if we are quite sure of the organization of our TOML file, we should use another technique shown in the project, <kbd>toml_static</kbd>.</p>
<p>To run it, open the<span> </span><kbd>toml_static</kbd><span> folder and type in <kbd>cargo run ../data/config.toml</kbd>. The program will </span><span>only</span><span> </span><span>print the following line:</span></p>
<pre>[postgresql].database: Rust2018</pre>
<p>This project uses two additional crates:</p>
<ul>
<li><kbd>serde</kbd>: This enables the use of<span> th</span><span>e basic </span><span>serialization/deserialization operations.</span></li>
<li><kbd>serde_derive</kbd>: <span>This provides a powerful additional feature known as the <strong>custom-derive</strong> feature</span><span>, which allows you to serialize/deserialize using a struct.</span></li>
</ul>
<p><kbd>serde</kbd> is the standard serialization/deserialization library. <strong>Serialization</strong> is the process of converting data structures of the program into a string (or a stream). <strong>Deserialization</strong> is the reverse process; it is <span>the process of </span><span>converting a string (or a stream) into some data structures of the program.</span></p>
<p>To read a TOML file, we need to use deserialization.</p>
<div class="packt_infobox"><span>In these two projects, we don't need to use serialization as we are not going to write a TOML file.</span></div>
<p>In the code, first, a struct is defined for any section contained in the <kbd>data/config.toml</kbd> file. That file contains the <kbd>Input</kbd>, <kbd>Redis</kbd>, <kbd>Sqlite</kbd>, and <kbd>Postgresql</kbd><span> </span><span>sections</span><span>, and so we declare as many Rust structs as the sections of the file we want to read; then, the</span> <kbd>Config</kbd> <span>struct </span><span>is defined to represent the whole file, having these sections as members.</span></p>
<p>For example, this is the structure for the <kbd>Input</kbd> section:</p>
<pre>#[allow(unused)]<br/>#[derive(Deserialize)]<br/>struct Input {<br/>    xml_file: String,<br/>    json_file: String,<br/>}</pre>
<p>Notice that the preceding declaration is preceded by two attributes.</p>
<p>The <kbd>allow(unused)</kbd> attribute is used to prevent the compiler from warning us about unused fields in the following structure. It is convenient for us to avoid these noisy warnings. The <kbd>derive(Deserialize)</kbd> attribute is used to activate the automatic deserialization initiated by <kbd>serde</kbd> for the following structure.</p>
<p>After these declarations, it is possible to write the following line of code:</p>
<pre>toml::from_str(&amp;config_text).unwrap()</pre>
<p>This invokes the <span><kbd>from_str</kbd> function, which parses the text of the file into a struct. </span>The type of that struct is not specified in this expression, but its value is assigned to the variable declared in the first line of the <kbd>main</kbd> function:</p>
<pre> let config_const_values: Config =</pre>
<p>So, its type is <kbd>Config</kbd><span>.</span></p>
<p><span>Any discrepancies between the file's contents and the struct type will be considered an error in this operation. So, if this operation is successful, any other operation on the structure cannot fail.</span></p>
<p>While the previous program (<kbd>toml_dynamic</kbd>) had a kind of dynamic typing, such as that of Python or JavaScript, this program has a kind of static typing, similar to Rust or C++.</p>
<p>The advantage of static typing appears in the last statement, where the same behavior as the long statement of the previous project is obtained by simply writing <span><kbd>config_const_values.postgresql.database</kbd>.</span></p>
<h1 id="uuid-39efed5f-0f02-47d3-8301-fb986e76d3bd">Reading and writing a JSON file</h1>
<p>For storing data that is more complex than that which is stored in a configuration file, JSON format is more appropriate. This format is quite popular, particularly among those who use the JavaScript language.</p>
<p class="mce-root">We are going to read and parse the <kbd>data/sales.json</kbd><span> </span><span>file</span><span>. This file contains a single anonymous object, which contains two arrays—</span><kbd>"products"</kbd> <span>and</span> <kbd>"sales"</kbd><span>.</span></p>
<p class="mce-root">The <kbd>"products"</kbd> array contains two objects, each one having three fields:</p>
<pre>  "products": [<br/>    {<br/>      "id": 591,<br/>      "category": "fruit",<br/>      "name": "orange"<br/>    },<br/>    {<br/>      "id": 190,<br/>      "category": "furniture",<br/>      "name": "chair"<br/>    }<br/>  ],</pre>
<p class="mce-root">The <kbd>"sales"</kbd> array contains three objects, each one containing five fields:</p>
<pre>"sales": [<br/>    {<br/>      "id": "2020-7110",<br/>      "product_id": 190,<br/>      "date": 1234527890,<br/>      "quantity": 2.0,<br/>      "unit": "u."<br/>    },<br/>    {<br/>      "id": "2020-2871",<br/>      "product_id": 591,<br/>      "date": 1234567590,<br/>      "quantity": 2.14,<br/>      "unit": "Kg"<br/>    },<br/>    {<br/>      "id": "2020-2583",<br/>      "product_id": 190,<br/>      "date": 1234563890,<br/>      "quantity": 4.0,<br/>      "unit": "u."<br/>    }<br/>  ]</pre>
<p>The information in the arrays is about some products to sell and some sale transactions associated with those products. Notice that the second field of each sale (<kbd>"product_id"</kbd>) is a reference to a product, and so it should be processed after the corresponding product object has been created.</p>
<p>We will see a pair of programs with the same behavior. They read the JSON file, increment<span> </span><span>the quantity of the second sale object</span><span> by</span> <kbd>1.5</kbd><span>, and then save the whole updated structure into another JSON file.</span></p>
<p>Similarly to the TOML format case, there can <span>also</span><span> </span><span>be a dynamic parsing technique</span><span> used </span><span>for JSON files, </span><span>where the existence and type of any data field is checked by the application code, and a static parsing technique, where it uses the deserialization library to check the existence and type of any field.</span></p>
<p>So, we have two projects: <kbd><span>json_dynamic</span></kbd><span> and <kbd>json_static</kbd>. </span>To run each of them, open its folder and type in <kbd>cargo run ../data/sales.json ../data/sales2.json</kbd>. The program will not print anything, but it will read the first file specified in the command line and create the second file that is specified.</p>
<p>The created file is similar to the read file, but with the following differences:</p>
<ul>
<li>The fields of the file created by <kbd>json_dynamic</kbd> are sorted in alphabetical order, while the fields of the file created by <kbd>json_static</kbd> are sorted in the same order as in the Rust data structure.</li>
<li>The quantity of the second sale is incremented from <kbd>2.14</kbd> to <kbd>3.64</kbd>.</li>
<li>The final empty line is removed in both created files.</li>
</ul>
<p>Now, we can see the implementations of the two techniques of serialization and deserialization.</p>
<h2 id="uuid-8366f525-4456-435f-90da-67905caa3ee3">The json_dynamic project</h2>
<p>Let's look at the source code of the project:</p>
<ol>
<li>This project gets <span>the pathnames of two files</span> from the command line—the existing JSON file <span>(<kbd>"input_path"</kbd>) </span>to read into a memory structure and a JSON file to create <span>(<kbd>"output_path"</kbd>) </span>by saving the loaded structure, after having modified it a bit.</li>
<li>Then, the input file is loaded into the string named <kbd>sales_and_products_text</kbd> and the generic <kbd>serde_json::from_str::&lt;Value&gt;</kbd> function <span>is used to parse the string into a dynamically typed structure representing the JSON file. This structure is stored in the</span> <kbd>sales_and_products</kbd> <span>local variable.</span></li>
</ol>
<p>Imagine that we want to change the quantity sold by the second sale transaction, incrementing it by <kbd>1.5</kbd> kilograms:</p>
<ol>
<li>First, we must get to this value using the following expression:</li>
</ol>
<pre style="padding-left: 60px">sales_and_products["sales"][1]["quantity"]</pre>
<ol start="2">
<li>This retrieves the <kbd>"sales"</kbd> sub-object of the general object. It is an array containing three objects.</li>
</ol>
<ol start="3">
<li>Then, this expression gets the second item (starting from zero (<kbd>[1]</kbd>)) of this array. This is an object representing a single sale transaction.</li>
<li>After this, it gets the <kbd>"quantity"</kbd> sub-object of the sale transaction object.</li>
<li>The value we have reached has a dynamic type that we think should be <kbd>serde_json::Value::Number</kbd>, and so we make a pattern matching with this type, specifying the <kbd>if let Value::Number(n)</kbd> clause.</li>
<li>If all is good, the matching succeeds and we get a variable named <kbd>n</kbd>—containing a number, or something that can be converted into a Rust floating-point number by using the <kbd>as_f64</kbd> function. Lastly, we can increment the Rust number and then create a JSON number from it using the <span><kbd>from_f64</kbd> function. We can then assign this object to the JSON structure using the same expression we used to get it:</span></li>
</ol>
<pre style="padding-left: 60px">sales_and_products["sales"][1]["quantity"]<br/>    = Value::Number(Number::from_f64(<br/>        n.as_f64().unwrap() + 1.5).unwrap());</pre>
<ol start="7">
<li>The last statement of the program saves the JSON structure to a file. Here, the <kbd>serde_json::to_string_pretty</kbd><span> function is used. As the name suggests, this function adds formatting whitespace (blanks and new lines) to make the resulting JSON file more human-readable. There is also the <kbd>serde_json::to_string</kbd> function, which creates a more compact version of the same information. It is much harder for people to read, but it is somewhat quicker to process for a computer:</span></li>
</ol>
<pre style="padding-left: 60px">std::fs::write(<br/>    output_path,<br/>    serde_json::to_string_pretty(&amp;sales_and_products).unwrap(),<br/>).unwrap();</pre>
<h2 id="uuid-b84d35cf-6247-4d5f-bda4-873961696095">The json_static project</h2>
<p>If, for our program, we are sure that we know the structure of the JSON file, a statically typed technique can and should be used instead. It is shown in the <kbd>json_static</kbd><span> </span><span>project</span><span>. The situation here is similar to that of the projects processing the TOML file.</span></p>
<p>The source code of the static version first declares three structs—one for every object type contained in the JSON file we are going to process. Each struct is preceded by the following attribute:</p>
<pre>#[derive(Deserialize, Serialize, Debug)]</pre>
<div class="packt_infobox">Let's understand the preceding snippet:
<ul>
<li><span>The <kbd>Deserialize</kbd> trait is required to parse (that is, read) JSON strings into this struct.</span></li>
<li><span>The <kbd>Serialize</kbd> trait is required to format (that is, write) this struct into a JSON string.</span></li>
<li><span>The <kbd>Debug</kbd> trait is just handy for printing </span><span>this struct on a </span><span>debug trace.</span></li>
</ul>
</div>
<p>The JSON string is parsed using the <kbd>serde_json::from_str::&lt;SalesAndProducts&gt;</kbd><span> </span><span>function</span><span>. Then, the code to increment the quantity of sold oranges becomes quite simple:</span></p>
<pre>sales_and_products.sales[1].quantity += 1.5</pre>
<p>The rest of the program is unchanged.</p>
<h1 id="uuid-1b39ab0d-08dd-4daa-9366-b7f5e8eed736"><span>Reading an XML file</span></h1>
<p>Another very popular text format is XML. Unfortunately, there is no stable serialization/deserialization library to manage XML format. However, this is not necessarily a shortcoming. In actual fact, XML format is often used to store large datasets; so large, in fact, that it would be inefficient to load them all before we start converting the data into an internal format. In these cases, it may be more efficient to scan the file or incoming stream and process it as long as it is read.</p>
<p>The <kbd>xml_example</kbd><span> </span><span>project</span><span> is a rather convoluted program that scans the XML file specified on the command line and, in a procedural fashion, loads information from the file into a Rust data structure. It is meant to read the </span><kbd>../data/sales.xml</kbd><span> </span><span>file</span><span>. This file has a structure corresponding to the JSON file we sought in the previous section. The following lines show an excerpt of that file:</span></p>
<pre>&lt;?xml version="1.0" encoding="utf-8"?&gt;<br/>&lt;sales-and-products&gt;<br/>    &lt;product&gt;<br/>        &lt;id&gt;862&lt;/id&gt;<br/>    &lt;/product&gt;<br/>    &lt;sale&gt;<br/>        &lt;id&gt;2020-3987&lt;/id&gt;<br/>    &lt;/sale&gt;<br/>&lt;/sales-and-products&gt;</pre>
<p>All XML files have a header in the first line and then one root element; in this case, the root element it is named <kbd>sales-and-products</kbd>. This element contains two kinds of elements—<kbd>product</kbd> and <kbd>sale</kbd>. Both kinds of elements have specific sub-elements, which are the fields of the corresponding data. In this example, only the <kbd>id</kbd> fields are shown.</p>
<p>To run the project, open its folder and type in <kbd>cargo run ../data/sales.xml</kbd>. Some lines will be printed on the console. The first four of them should be as follows:</p>
<pre>Got product.id: 862.<br/>Got product.category: fruit.<br/>Got product.name: cherry.<br/>  Exit product: Product { id: 862, category: "fruit", name: "cherry" }</pre>
<p>These describe the contents of the specified XML file. In particular, the program found a product with ID <kbd>862</kbd>, then it detected that it is a fruit, then that it is a cherry, and then, when the whole product had been read, the whole struct representing the product was printed. A similar output will appear for sales.</p>
<p>The parsing is performed using only the <kbd>xml-rs</kbd> crate. This crate enables a mechanism of parsing, shown in the following code excerpt:</p>
<pre>let file = std::fs::File::open(pathname).unwrap();<br/>let file = std::io::BufReader::new(file);<br/>let parser = EventReader::new(file);<br/>for event in parser {<br/>    match &amp;location_item {<br/>        LocationItem::Other =&gt; ...<br/><span>        LocationItem::InProduct =&gt; ...<br/></span><span>        LocationItem::InSale =&gt; ...<br/></span><span>    }<br/></span>}</pre>
<p>An object of the <span><kbd>EventReader</kbd></span><span> </span><span>type</span><span> scans the buffered file and it generates an event w</span><span>henever a step is performed in the parsing. The application code handles these kinds of events according to their needs.</span></p>
<p>The word <strong>event</strong> is used by this crate, but the word <strong>transition</strong> would <span>probably</span><span> </span><span>be a better description of the data extracted by the parser.</span></p>
<p>A complex language is hard to parse, but for languages as simple as our data, the situation during the parsing can be modeled by a state machine. To that purpose, three <kbd>enum</kbd> variables are declared in the source code: <span><kbd>location_item</kbd>, with the </span><kbd>LocationItem</kbd><span> </span><span>type</span><span>; <kbd>location_product</kbd>, with the </span><kbd>LocationProduct</kbd><span> </span><span>type</span><span>; and <kbd>location_sale</kbd>, with the </span><kbd>LocationSale</kbd><span> </span><span>type</span><span>.</span></p>
<p>The first one indicates the current position of the parsing in general. We can be inside a product (<kbd>InProduct</kbd>), inside a sale (<kbd>InSale</kbd>), or outside of both (<kbd>Other</kbd>). If we are inside a product, the <kbd>LocationProduct</kbd> enum indicates<span> the current position of parsing inside the current product. This can be within any of the allowed fields or outside of all of them. Similar states happen for sales.</span></p>
<p>The iteration encounters several kinds of events. The main ones are the following:</p>
<ul>
<li><kbd><span>XmlEvent</span><span>::StartElement</span></kbd><span>: Signals that an XML element is beginning. It is decorated by the name of the beginning element and the possible attributes of that element.</span></li>
<li><kbd><span>XmlEvent</span><span>::EndElement</span></kbd><span>: Signals that an XML element is ending. It is decorated by the name of the ending element.</span></li>
<li><kbd><span>XmlEvent::Characters</span></kbd><span>: Signals that the textual contents of an element is available. It is decorated by that available text.</span></li>
</ul>
<p>The program declares a mutable <kbd>product</kbd> struct, with the <kbd>Product</kbd><span> </span><span>type</span><span>, and a mutable</span> <kbd>sale</kbd> <span>struct, with the </span><kbd>Sale</kbd><span> </span><span>type</span><span>. They are initialized with default values. Whenever there are some characters available, they are stored in the corresponding field of the current struct.</span></p>
<p>For example, consider a situation where the value of <kbd>location_item</kbd> is <kbd>LocationItem::InProduct</kbd> and the value of <kbd>location_product</kbd> is <kbd>LocationProduct::InCategory</kbd>—that is, we are in a category of a product. In this situation, there can be the name of the category or the end of the category. To get the name of the category, the code contains this pattern of a <kbd>match</kbd> statement:</p>
<pre>Ok(XmlEvent::Characters(characters)) =&gt; {<br/>    product.category = characters.clone();<br/>    println!("Got product.category: {}.", characters);<br/>}</pre>
<p><span>In this statement, the <kbd>characters</kbd></span><span> </span><span>variable</span> gets the name of the category and a clone of it is assigned to the<span> </span><kbd>product.category</kbd><span> </span><span>field</span><span>. Then, the name is printed to the console.</span></p>
<h1 id="uuid-6f311ab3-c137-4bdc-862a-d184d793962c">Accessing databases</h1>
<p>Text files are good when they are small and when they don't need to be changed often. Actually, the only way that a text file can be changed is if you append something to the end of it or rewrite it completely. If you want to change the information in a large dataset quickly, the only way to do so is to use a database manager. <span>In this section, we are going to learn how to manipulate a SQLite database with a simple example.</span></p>
<p>But first, let's look at three popular, broad categories of database managers:</p>
<ul>
<li><strong>Single-user databases</strong>: These store all of the databases in a single file, which must be accessible by the application code. The database code is linked into the application (it may be a static-link library or a dynamic-link library). Only one user at a time is allowed to access it, and all users have administrative privileges. <span>To move the database anywhere, </span>you simply move the file. The most popular choices in this category are SQLite and Microsoft Access.</li>
<li><strong>DBMS</strong>: This is a process that has to be started as a service. Multiple clients can connect to it at the same time, and they can also apply changes at the same time without any data corruption. It requires more storage space, more memory, and much more start up time (for the server). There are several popular choices in this category, such as Oracle, Microsoft SQL Server, IBM DB2, MySQL, and PostgreSQL.</li>
<li><strong>Key-value stores</strong>: This is a process <span>that has to be started as a service. Multiple clients can connect to it at the same time and apply changes at the same time. It is essentially a large memory hash map that can be queried by other processes and that can optionally store its data in a file and reload it when it is restarted. This category is less popular than the other two, but it is gaining ground as the backend of high-performance websites. One of the most popular choices is Redis.</span></li>
</ul>
<p>In the following sections, we are going to show you how to access SQLite single-user databases (in the <kbd>sqlite_example</kbd><span> </span><span>project</span><span>), PostgreSQL DBMSes (in the </span><kbd>postgreSQL_example</kbd><span> </span><span>project</span><span>), and Redis key-value stores (in the </span><kbd>redis_example</kbd><span> </span><span>project</span><span>). Then, in the </span><kbd>transformer</kbd><span> </span><span>project</span><span>, all three kinds of databases will be used together.</span></p>
<h1 id="uuid-d2818c3d-7ece-4084-8b4f-3415e7f0ef6c">Accessing a SQLite database</h1>
<p><span>The source code for this section is found in the <kbd>sqlite_example</kbd></span><span> </span><span>project</span><span>. To run it, open its folder and type in </span><kbd>cargo run</kbd><span>.</span></p>
<p>This will create the <kbd>sales.db</kbd><span> </span><span>file</span><span> in the current folder. This file contains a SQLite database. Then, it will create the </span><kbd>Products</kbd> <span>and</span> <kbd>Sales</kbd><span> </span><span>tables in this database</span><span>, it will insert a row into each of these tables, and it will perform a query on the database. The query asks for all the sales, joining each of them with its associated product. For each extracted row, a line will be printed onto the console, showing the timestamp of the sale, the weight of the sale, and the name of the associated product. As there is only one sale in the database, you will see just the following line printed:</span></p>
<pre>At instant 1234567890, 7.439 Kg of pears were sold. </pre>
<p>This project <span>only</span><span> </span><span>uses</span><span> the</span><span> </span><kbd>rusqlite</kbd><span> </span><span>crate</span><span>. Its name is a contraction of</span> <strong>Rust SQLite</strong><span>. To use this crate, the</span> <kbd>Cargo.toml</kbd><span> file must contain the following line:</span></p>
<pre>rusqlite = "0.23"</pre>
<h2 id="uuid-36c80742-4be7-4e29-bddd-92d32d698e64">Implementing the project</h2>
<p><span>Let's</span><span> look at how the code for</span> <span>the</span> <kbd>sqlite_example</kbd><span> </span><span>project</span><span> </span><span>works. The</span> <kbd>main</kbd> <span>function is quite simple:</span></p>
<pre>fn main() -&gt; Result&lt;()&gt; {<br/>    let conn = create_db()?;<br/>    populate_db(&amp;conn)?;<br/>    print_db(&amp;conn)?;<br/>    Ok(())<br/>}</pre>
<p>It invokes <kbd>create_db</kbd> to open or create a database with its empty tables, and to open and return a connection to this database.</p>
<p>Then, it invokes <kbd>populate_db</kbd> to insert rows into the tables of the database referred to by that connection.</p>
<p>Then, it invokes <kbd>print_db</kbd> to execute a query on this database and prints the data extracted by that query.</p>
<p>The <kbd>create_db</kbd> function is long but easy to understand:</p>
<pre style="padding-left: 60px">fn create_db() -&gt; Result&lt;Connection&gt; {<br/>    let database_file = "sales.db";<br/>    let conn = Connection::open(database_file)?;<br/>    let _ = conn.execute("DROP TABLE Sales", params![]);<br/>    let _ = conn.execute("DROP TABLE Products", params![]);<br/>    conn.execute(<br/>        "CREATE TABLE Products (<br/>            id INTEGER PRIMARY KEY,<br/>            category TEXT NOT NULL,<br/>            name TEXT NOT NULL UNIQUE)",<br/>        params![],<br/>    )?;<br/>    conn.execute(<br/>        "CREATE TABLE Sales (<br/>            id TEXT PRIMARY KEY,<br/>            product_id INTEGER NOT NULL REFERENCES Products,<br/>            sale_date BIGINT NOT NULL,<br/>            quantity DOUBLE PRECISION NOT NULL,<br/>            unit TEXT NOT NULL)",<br/>        params![],<br/>    )?;<br/>    Ok(conn)<br/>}</pre>
<p>The<span> </span><kbd>Connection::open</kbd><span> function simply </span>uses a path to a SQLite database file<span> to open a connection</span>. If this file does not exist, it will be created. As you can see, the created <kbd>sales.db</kbd> file is very small. Typically, empty databases of DBMSes are 1,000 times larger.</p>
<p>To perform a data manipulation command, the<span> </span><kbd>execute</kbd><span> </span>method of the connection is called. Its first argument is a SQL statement, possibly containing some parameters, specified as<span> </span><kbd>$1</kbd>,<span> </span><kbd>$2</kbd>,<span> </span><kbd>$3</kbd>, and so on. The second argument of the function is a reference to a slice of values that are used to replace such parameters.</p>
<p>Of course, if there are no parameters, the parameter values list must be empty. The first parameter value, which has an index of <kbd>0</kbd>, replaces the<span> </span><kbd>$1</kbd><span> </span><span>parameter</span><span>, the second one replaces the</span><span> </span><kbd>$2</kbd><span> </span><span>parameter</span><span>, and so on.</span></p>
<p>Notice that the arguments of a parameterized SQL statement can be of different data types (numeric, alpha-numeric, BLOBs, and so on), but Rust collections can <span>only</span><span> </span><span>contain objects of the same data type. Therefore, the </span><kbd>params!</kbd><span> </span><span>macro </span><span>is used to perform a bit of magic. The data type of the second argument of the</span> <kbd>execute</kbd> <span>method must be that of a collection that can be iterated over and whose items implement the</span> <kbd>ToSql</kbd> <span>trait. The objects implementing this trait, as its name implies, can be used as parameters of a SQL statement. The <kbd>rusqlite</kbd> crate contains an implementation of this trait for many Rust basic types, such as numbers and strings.</span></p>
<p>So, for example, the <kbd>params!(34, "abc")</kbd><span> </span><span>expression</span><span> generates a collection that can be iterated over. The first item of this iteration can be converted into an object containing the number</span> <kbd>34</kbd><span>, and that number can be used to replace a SQL parameter of a numeric type. </span><span>The second item of this iteration can be converted into an object containing the <kbd>"abc"</kbd></span><span> </span><span>string</span><span>, and that string can be used to replace a SQL parameter of an alpha-numeric type.</span></p>
<p>Now, let's look at the <kbd>populate_db</kbd> function. It contains statements to insert rows into the database. Here is one of those statements:</p>
<pre style="padding-left: 60px">conn.execute(<br/>    "INSERT INTO Products (<br/>        id, category, name<br/>        ) VALUES ($1, $2, $3)",<br/>    params![1, "fruit", "pears"],<br/>)?;</pre>
<p>As explained before, this statement will have the effect of executing the following SQL statement:</p>
<pre>INSERT INTO Products (<br/>        id, category, name<br/>        ) VALUES (1, 'fruit', 'pears')</pre>
<p>At last, we see the whole <kbd>print_db</kbd> function, which is more complex than the others:</p>
<pre style="padding-left: 60px">fn print_db(conn: &amp;Connection) -&gt; Result&lt;()&gt; {<br/>    let mut command = conn.prepare(<br/>        "SELECT p.name, s.unit, s.quantity, s.sale_date<br/>        FROM Sales s<br/>        LEFT JOIN Products p<br/>        ON p.id = s.product_id<br/>        ORDER BY s.sale_date",<br/>    )?;<br/>    for sale_with_product in command.query_map(params![], |row| {<br/>        Ok(SaleWithProduct {<br/>            category: "".to_string(),<br/>            name: row.get(0)?,<br/>            quantity: row.get(2)?,<br/>            unit: row.get(1)?,<br/>            date: row.get(3)?,<br/>        })<br/>    })? {<br/>        if let Ok(item) = sale_with_product {<br/>            println!(<br/>                "At instant {}, {} {} of {} were sold.",<br/>                item.date, item.quantity, item.unit, item.name<br/>            );<br/>        }<br/>    }<br/>    Ok(())<br/>}</pre>
<p>To perform a SQL query, first, the <kbd>SELECT</kbd> SQL statement must be prepared<span> by calling the </span><kbd>prepare</kbd><span> method of the connection, </span>to convert it into an efficient internal format, with the <kbd>Statement</kbd><span> </span><span>data type</span><span>. This object is assigned to the</span> <kbd>command</kbd> <span>variable. A prepared statement must be mutable to allow the following replacement of parameters. In this case, however, we don't have any parameters.</span></p>
<p>A query can generate several rows, and we want to process one at a time, so we must create an iterator from this command. It is performed by calling the <kbd>query_map</kbd> method of the command. This method receives two arguments—a slice of parameter values and a closure—and it returns an iterator. <span>The </span><kbd>query_map</kbd><span> </span><span>function performs two jobs—first, it replaces the specified </span>parameters, and then it <span>uses the closure to map (or transform) each extracted row into a more handy structure.</span> But in our case, <span>we have no parameters to replace,</span> and so we just create a specific structure with the <kbd>SaleWithProduct</kbd> t<span>ype.</span><span> To extract the fields from a row, the</span> <kbd>get</kbd> <span>method is used. It has a zero-based index on the fields specified in the</span> <kbd>SELECT</kbd> <span>query. This structure is the object returned by the iterator for any row extracted by the query, and it is assigned to the iteration variable named </span><kbd>sale_with_product</kbd><span>.</span></p>
<p>Now that we have learned how to access a SQLite database, let's check the PostgreSQL database management system.</p>
<h1 id="uuid-12a1623d-f1d8-4c5b-a9bc-e0f913514029">Accessing a PostgreSQL database</h1>
<p>What we did in the <span>SQLite database</span> is similar to what we will be doing in the PostgreSQL database. This is because they are both based on the SQL language, but mostly because <span>SQLite is designed to be similar to PostgreSQL. </span>It may be harder to convert an application from PostgreSQL into SQLite because the former has many advanced features that are not available in the latter.</p>
<p><span>In this section, we are going to convert the example from the previous section so that it works with a PostgreSQL database instead of SQLite. So, we'll explain the differences.</span></p>
<p><span>The source code for this section can be found in the</span> <span><kbd>postgresql_example</kbd></span><span> </span><span>folder</span><span>. To run it, open its folder and type in </span><kbd>cargo run</kbd><span>. This will carry out essentially the same operations that we saw for <kbd>sqlite_example</kbd>, and so after creating and populating the database, it will print the following:</span></p>
<pre>At instant 1234567890, 7.439 Kg of pears were sold.</pre>
<h2 id="uuid-b5178598-a202-4dd2-9f30-0cc996d1b194">Implementation of the project</h2>
<p>This project <span>only</span><span> </span><span>uses the crate named </span><kbd>postgres</kbd><span>. Its name is a popular contraction of the </span><kbd>postgresql</kbd><span> </span><span>name</span><span>.</span></p>
<p>Creating a connection to a PostgreSQL database is very different from creating a connection to a SQLite database. As the latter is only a file, you do so in a similar way to opening a file, and you should write <kbd>Connection::open(&lt;pathname of the db file&gt;)</kbd>. Instead, to connect to a PostgreSQL database, you need access to a computer where a server is running, then access to the TCP port where that server is listening, and then you need to specify your credentials on this server (your username and password). Optionally, you can then specify which of the databases managed by this server you want to use.</p>
<p>So, the general form of the call is <kbd>Connection::connect(&lt;URL&gt;,<span> &lt;</span>TlsMode&gt;)</kbd>, where the URL can be, for example, <kbd>postgres://postgres:post@localhost:5432/Rust2018</kbd>. The general form of the URL is <kbd>postgres://username[:password]@host[:port][/database]</kbd>, where the password, the port, and the database parts are optional. The <kbd>TlsMode</kbd> argument specifies whether the connection must be encrypted.</p>
<p>The port is optional because it has a value of <kbd>5432</kbd> by default. Another difference is that this crate does not use the <kbd>params!</kbd> macro. Instead, it allows us to specify a reference to a slice. In this case, it is an empty slice (<kbd>&amp;[]</kbd>) because we don't need to specify parameters.</p>
<p><span>The table creation and population process is similar to the way it was done for <kbd>sqlite_example</kbd>. </span>The query is different, however. This is the body of the <kbd>print_db</kbd> function:</p>
<pre>for row in &amp;conn.query(<br/>    "SELECT p.name, s.unit, s.quantity, s.sale_date<br/>    FROM Sales s<br/>    LEFT JOIN Products p<br/>    ON p.id = s.product_id<br/>    ORDER BY s.sale_date",<br/>    &amp;[],<br/>)? {<br/>    let sale_with_product = SaleWithProduct {<br/>        category: "".to_string(),<br/>        name: row.get(0),<br/>        quantity: row.get(2),<br/>        unit: row.get(1),<br/>        date: row.get(3),<br/>    };<br/>    println!(<br/>        "At instant {}, {} {} of {} were sold.",<br/>        sale_with_product.date,<br/>        sale_with_product.quantity,<br/>        sale_with_product.unit,<br/>        sale_with_product.name<br/>    );<br/>}</pre>
<p>With PostgreSQL, the <kbd>query</kbd> method of the connection class carries out parameter substitution, similarly to the <kbd>execute</kbd> method, but it does not map the row to a structure. Instead, it returns an iterator, which can be <span>immediately </span>used in a <kbd>for</kbd> statement. Then, in the body of the loop, the <kbd>row</kbd> variable can be used (as it is in the example) to fill a struct.</p>
<p>As we now know how to access data in the SQLite and PostgreSQL databases, let's see how to store and retrieve data from a Redis store.</p>
<h1 id="uuid-49bb3120-5061-4eb4-97e2-96ab18225b62">Storing and retrieving data from a Redis store</h1>
<p>Some applications need a very fast response time for <span>certain kinds of data; faster than what a DBMS can offer. Usually, a DBMS dedicated to one user would be fast enough, but for some applications (typically large-scale web applications) there are hundreds of concurrent queries and many concurrent updates. You can use many computers, but the data must be kept coherent among them, and keeping coherence can cause a bottleneck of performance.</span></p>
<p>A solution to this problem is to use a key-value store, which is a very simple database that can be replicated across a network. This keeps the data in memory to maximize the speed, but it also supports the option to save the data in a file. This avoids losing information if the server is stopped.</p>
<p>A key-value store is similar to the <span><kbd>HashMap</kbd> collection </span>of the Rust standard library, but it is managed by a server process, which could possibly be running on a different computer. A query is a message exchanged between the client and a server. Redis is <span>one of the most used key-value stores.</span></p>
<p>The source code for this project is found in the <kbd>redis_example</kbd><span> </span><span>folder</span><span>. To run it, open the folder and type in </span><kbd>cargo run</kbd><span>. This will print the following:</span></p>
<pre>a string, 4567, 12345, Err(Response was of incompatible type: "Response type not string compatible." (response was nil)), false.</pre>
<p>This simply creates a data store in the current computer and stores in it the following three key-value pairs:</p>
<ul>
<li><kbd>"aKey"</kbd>, associated with <kbd>"a string"</kbd></li>
<li><kbd>"anotherKey"</kbd><span>, associated with </span><kbd>4567</kbd></li>
<li><kbd>45</kbd><span>, associated with </span><kbd>12345</kbd></li>
</ul>
<p>Then, it queries the store for the following keys:</p>
<ul>
<li><kbd>"aKey"</kbd>, which obtains an <kbd><span>"a string"</span></kbd> value</li>
<li><kbd>"anotherKey"</kbd><span>, which obtains a <kbd>4567</kbd></span> value</li>
<li><kbd>45</kbd><span>, which obtains a <kbd>12345</kbd></span> value</li>
<li><span><kbd>40</kbd>, which obtains </span>an error</li>
</ul>
<p>Then, it queries whether the <kbd>40</kbd><span> </span><span>key </span><span>exists in the store, which obtains</span> <kbd>false</kbd><span>.</span></p>
<h2 id="uuid-0a0728e5-b009-4780-8ef6-12cf0feb1af1"><span>Implementing the project</span></h2>
<p>Only the <kbd>redis</kbd> crate is used in this project.</p>
<p>The code is quite short and simple. Let's look at how it works:</p>
<pre>fn main() -&gt; redis::RedisResult&lt;()&gt; {<br/>    let client = redis::Client::open("redis://localhost/")?;<br/>    let mut conn = client.get_connection()?;</pre>
<p>First, a client must be obtained. The call to <kbd>redis::Client::open</kbd> receives a URL and just checks whether this URL is valid. If the URL is valid, a <kbd><span>redis::Client</span></kbd> object is returned, which has no open connections. Then, the <kbd>get_connection</kbd> method of the client tries to connect, and if it is successful, it returns an open connection.</p>
<p>Any connection <span>essentially </span>has three important methods:</p>
<ul>
<li><kbd>set</kbd>: This tries to store a key-value pair. </li>
<li><kbd>get</kbd>: This tries to retrieve the value associated with the specified key.</li>
<li><kbd>exists</kbd>: This tries to detect whether the<span> specified key is present in the store, without retrieving its associated value</span>.</li>
</ul>
<p>Then, <kbd>set</kbd> is invoked three times, with different types for the key and value:</p>
<pre style="padding-left: 60px">conn.set("aKey", "a string")?;<br/>conn.set("anotherKey", 4567)?;<br/>conn.set(45, 12345)?;</pre>
<p>At last, <kbd>get</kbd> is invoked four times and <kbd>exists</kbd> is invoked once. The first three calls get the stored value. The fourth call specifies a non-existent value, so a null value is returned, which cannot be converted into <kbd>String</kbd>, as is required, and so an error is generated:</p>
<pre style="padding-left: 60px">conn.get::&lt;_, String&gt;("aKey")?,<br/>conn.get::&lt;_, u64&gt;("anotherKey")?,<br/>conn.get::&lt;_, u16&gt;(45)?,<br/>conn.get::&lt;_, String&gt;(40),<br/>conn.exists::&lt;_, bool&gt;(40)?);</pre>
<p>You can always check the error to find out whether your key is present, but a cleaner solution is to call the <kbd>exists</kbd> method, which returns a Boolean value specifying whether the key is present.</p>
<p>With this, we now know how <span>Rust crates are used to access, store, and retrieve data using the most popular databases.</span></p>
<h1 id="uuid-eb111553-1211-4982-93fc-d09e17255d3c">Putting it all together</h1>
<p>You should now know enough to build an example that does what we described at the beginning of the chapter. We have learned the following:</p>
<ul>
<li>How to read a TOML file to parameterize the program</li>
<li>How to load <span>the data regarding products and sales</span> into memory, specified in a JSON file and in an XML file</li>
<li>How to store all of this data in three places: a SQLite DB file, a PostgreSQL database, and a Redis key-value store</li>
</ul>
<p><span>The source code of the complete example is found in the</span> <span><kbd>transformer</kbd></span><span> </span><span>project</span><span>. To run it, open its folder and type in </span><kbd>cargo run ../data/config.toml</kbd><span>. If everything is successful, it will recreate and populate the SQLite database contained in the </span><kbd>data/sales.db</kbd><span> </span><span>file</span><span>, the PostgreSQL database, which can be accessed from <kbd>localhost</kbd> on port <kbd>5432</kbd> and is named</span> <kbd>Rust2018</kbd><span>, and the Redis store, which can be accessed from <kbd>localhost</kbd>. Then, it will query the SQLite and PostgreSQL databases for the number of rows in their tables, and it will print the following:</span></p>
<pre>SQLite #Products=4. <br/>SQLite #Sales=5. <br/>PostgreSQL #Products=4. <br/>PostgreSQL #Sales=5. </pre>
<p>So, we have now seen a rather broad example of data manipulation. </p>
<h1 id="uuid-465d1889-ecdc-4503-8743-d02b1719391e">Summary</h1>
<p>In this chapter, we looked at some basic techniques to access data in popular text formats (TOML, JSON, and XML) or data managed by popular database managers (SQLite, PostgreSQL, and Redis). Of course, many other file formats and database managers <span>exist, and there is still a lot to be learned about these formats and these database managers. Nevertheless, you should now have a grasp of what they do. </span>These techniques are useful for many kinds of applications.</p>
<p>In the next chapter, we will learn how to build a web backend service using the REST architecture. To keep that chapter self-contained, we will only use a framework to receive and respond to web requests, and not use a database. Of course, that is quite unrealistic; but by combining those web techniques with the ones introduced in this chapter, you can build a real-world web service.</p>
<h1 id="uuid-b68d3e81-eb8b-4267-812f-b4efebfad53a">Questions</h1>
<ol>
<li>Why is it not a good idea to change programmatically a TOML file edited by a user?</li>
<li>When is it better to use a dynamically typed parsing of TOML or JSON files and when is it better to use statically typed parsing?</li>
<li>When is it required to derive a structure from the <kbd>Serialize</kbd> and the <kbd>Deserialize</kbd> trait?</li>
</ol>
<ol start="4">
<li>What is a pretty generation of a JSON string?</li>
<li>Why could it be better to use a stream parser, rather than a single-call parser?</li>
<li>When is SQLite a better choice and when is it better to use PostgreSQL?</li>
<li>Which is the type of the parameters passed with a SQL command to a SQLite database manager?</li>
<li>What does the <kbd>query</kbd> method do on a PostgreSQL database?</li>
<li>What are the names of the functions to read and write values in a Redis key-value store?</li>
<li>Can you try to write a program that gets an ID from the command line, queries SQLite, PostgreSQL, or the Redis database for the ID, and prints some information regarding the data found?</li>
</ol>


            </article>

            
        </section>
    </body></html>