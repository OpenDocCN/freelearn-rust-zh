- en: Reactive Microservices - Increasing Capacity and Performance
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you adhere to a microservices architecture for your application, you'll get
    the benefits of loose coupling, meaning that every microservice is standalone
    enough to be developed and maintained by separate teams. This is a kind of asynchronous
    approach to business tasks, but it's not the only benefit; there are others. You
    can increase your capacity and performance by only scaling the microservices that
    take a huge load. To achieve this, your microservice has to be reactive, and it
    has to be self-sustaining, interacting with other microservices via message passing.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, you will learn what a reactive microservice is, and how to
    use message passing to ensure the connectivity of microservices. Also, we will
    discuss whether reactive microservices can be asynchronous.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: What is a reactive microservice?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: JSON-RPC
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: gRPC
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter will cover using **remote procedure calls** (**RPCs**) in Rust.
    You'll need a working Rust compiler, because we will create two examples with
    the `jsonrpc-http-server` and `grpc` crates.
  prefs: []
  type: TYPE_NORMAL
- en: If you want to test TLS connections, you'll need OpenSSL version 0.9, because
    the `grpc` crate doesn't support version 1.0 or higher yet. Most modern operating
    systems have switched to 1.0 already, but you can build the examples to a Docker
    image that supports version 0.9, or wait till the `grpc` crate is updated to the
    latest OpenSSL version. We will build test examples without TLS.
  prefs: []
  type: TYPE_NORMAL
- en: You can find the sources of the examples from this chapter in the GitHub repository
    at, [https://github.com/PacktPublishing/Hands-On-Microservices-with-Rust/tree/master/Chapter06](https://github.com/PacktPublishing/Hands-On-Microservices-with-Rust/tree/master/Chapter06).
  prefs: []
  type: TYPE_NORMAL
- en: What is a reactive microservice?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A microservices architecture implies the presence of multiple parts in an application.
    In the past, most applications were monoliths, with all of the parts contained
    in a single code base. The microservices approach gives us the opportunity to
    split a code base between multiple teams and developers, to have an individual
    life cycle for every microservice, and for parts to interact with a common protocol.
  prefs: []
  type: TYPE_NORMAL
- en: Does this mean that your application will be free from all of the flaws of a
    monolithic application? No. You can write microservices that are so closely related
    to each other that you can't even properly update them.
  prefs: []
  type: TYPE_NORMAL
- en: How is this possible? Imagine that you have a microservice that has to wait
    for the response of another microservice to send a response to a client. The other
    microservice, in turn, also has to wait for another microservice, and so on. If
    you closely link the microservices of an application, you will find the same drawbacks
    that you have with monoliths.
  prefs: []
  type: TYPE_NORMAL
- en: You have to write microservices as independent applications that can be reused
    for multiple projects, not only yours. How can you achieve that? Develop a reactive
    microservice. Let's look at what that is.
  prefs: []
  type: TYPE_NORMAL
- en: Loose coupling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Loose coupling is a software design approach that implies every part of an application
    should know little information about the other parts. In traditional applications,
    if you write a GUI component, such as a button, it has to be possible to use it
    everywhere, for any application. As another example, if you develop a library
    to work with sound hardware, this also means you can use it with every application;
    the library is not limited to use in one kind of application. In microservices,
    however, loose coupling means that a microservice doesn't know anything about
    other microservices, or how many there are.
  prefs: []
  type: TYPE_NORMAL
- en: If you develop an application, you should write parts of it—microservices—as
    standalone applications. For example, a notification service that sends push notifications
    to mobile platforms won't know about CRM, accounting, or even the users. Is it
    possible to do this? Yes! You can write a microservice that uses a common protocol
    and interacts with other services via message passing. This is called a **message-driven
    application**.
  prefs: []
  type: TYPE_NORMAL
- en: Message-driven applications
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Traditional microservices have an API that immediately returns a result and
    every participant of a working application has to know about the other parts.
    This approach keeps the relations of microservices close. Such an application
    is hard to maintain, update, and scale.
  prefs: []
  type: TYPE_NORMAL
- en: It is much more convenient if your application interacts via messages that are
    handled by other microservices. This approach is called **message-driven**, when
    you use messages as a unit of interaction. Messages help you to reduce the coupling
    of microservices, because you can process a message for multiple services simultaneously
    or add an extra processing message for a particular message type.
  prefs: []
  type: TYPE_NORMAL
- en: To have totally uncoupled microservices, you should use a message queue or a
    message broker service. We will learn this approach in detail in [Chapter 12](98204850-538d-4a2b-9a77-23f85e716400.xhtml),
    [Scalable Microservices Architecture](https://cdp.packtpub.com/hands_on_microservices_with_rust_2018/wp-admin/post.php?post=405&action=edit), in
    which we talk about scalable architecture.
  prefs: []
  type: TYPE_NORMAL
- en: Asynchronous
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Since reactive microservices use message passing, you have to process message
    asynchronously. This doesn't mean you have to use asynchronous crates such as `tokio`
    or `futures`. But it means no one message can block the service; every message
    is processed in a short period of time and if the service has to perform a long
    task it should do it as a background task and inform the thread issued that task
    about the result by sending a message with that result. To achieve this behavior,
    you can use multiple threads without asynchronous code. But what about using asynchronous
    code for reactive microservices?
  prefs: []
  type: TYPE_NORMAL
- en: Should a reactive microservice be asynchronous?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Very often, confusion is caused by asynchronous applications being called **reactive**,
    because their event loops wait for external events and don't waste server resources
    while they're waiting. Reactive microservices don't waste resources to keep incoming
    connection to return a result, because when a client connects to a reactive microservices
    for a short time, put the task and disconnects. After a client waits for asynchronous
    response from a microservice. Reactive microservices don't need to be asynchronous,
    but they can be.
  prefs: []
  type: TYPE_NORMAL
- en: When you choose message passing for interaction, you have to take into account
    that microservices have to be asynchronous and can handle multiple messages simultaneously.
    Traditional synchronous code can't process as many messages as asynchronous code
    does, because synchronous code has to wait for I/O resources, but asynchronous
    code reacts to I/O events and utilizes as many resources as possible.
  prefs: []
  type: TYPE_NORMAL
- en: More simply, if your microservices have to process hundreds of thousands of
    messages, you should use asynchronous code. If your microservices do not have
    a heavy load, it's enough to use a modest synchronous algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: Reactive microservices with futures and streams
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you have decided to implement a reactive microservice using asynchronous
    code, you can consider using a future crate as a basis. This crate provides you
    with types to construct reactive chains to process all messages asynchronously.
    But remember, it can be hard to write all `Future` instances manually. There is
    an upcoming feature in the Rust compiler that provides `async`/`await` operators,
    which simplifies the `Future` trait implementation by writing traditional functions
    with the `Result` return type. This feature is unstable and we won't consider
    it in this book.
  prefs: []
  type: TYPE_NORMAL
- en: If you don't want to write low-level code, I recommend you use the `actix` crate.
    This is a really good framework that lets you write asynchronous code like synchronous
    code.
  prefs: []
  type: TYPE_NORMAL
- en: If you need the lowest level of control, you can use the `mio` crate that's
    used as a base by the `futures` crate. It provides you with full control of I/O
    events, and you can squeeze the maximum speed from the resources of your server.
  prefs: []
  type: TYPE_NORMAL
- en: Message brokers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Message brokers let you send all messages to a central point that routes and
    delivers messages to the necessary microservices. In some cases, this can be a
    bottleneck, because the full load will fall on a single application—the message
    broker. But in most cases, it's a great approach that helps you to decouple microservices
    and update any microservices imperceptibly.
  prefs: []
  type: TYPE_NORMAL
- en: To use message brokers, it's sufficient to support the AMQP protocol. All popular
    message brokers are compatible with that protocol. The `lapin-futures` crate provides
    types and methods to use the AMQP protocol through the API of the `futures` crate.
    If you want to use the low-level control of the `mio` crate, there is the `lapin-async`
    crate.
  prefs: []
  type: TYPE_NORMAL
- en: Remote procedure calls
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you want to connect microservices to each other directly, you can use RPCs
    to allow the functions of a service to be called remotely by another service.
    There are a lot of RPC frameworks with different formats and speed potential.
    Let's look at some popular protocols.
  prefs: []
  type: TYPE_NORMAL
- en: JSON-RPC
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The JSON-RPC protocol uses messages serialized to JSON format. It uses a special
    format for requests and responses, described here: [https://www.JSON-RPC.org/specification](https://www.jsonrpc.org/specification).
    The protocol can use different transports, such as, HTTP, Unix sockets, or even
    stdio. Later in this chapter, you will find an example of the usage of this protocol.'
  prefs: []
  type: TYPE_NORMAL
- en: gRPC
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The gRPC protocol was created by Google and uses the Protocol Buffer serialization
    format for messages. Also, the protocol lies on benefits of the `HTTP/2` transport
    and allows you to achieve excellent performance. You can find more about the protocol
    here: [https://grpc.io/docs/](https://grpc.io/docs/). There is also an example
    of using this protocol later in this chapter.'
  prefs: []
  type: TYPE_NORMAL
- en: Thrift
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Apache Thrift is a binary communication protocol developed by Facebook. Despite
    the fact the protocol is binary, there are a lot of supported languages, such
    as C++, Go, and Java. Supported transports are file, memory, and socket.
  prefs: []
  type: TYPE_NORMAL
- en: Other RPC frameworks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are other RPC protocols, such as Cap'n Proto, XML-RPC, and even vintage
    SOAP. Some have implementations for Rust, but I recommend considering choosing
    between JSON-RPC, gRPC, and Thrift, because they are the most commonly used for
    microservices.
  prefs: []
  type: TYPE_NORMAL
- en: RPC and REST
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'You may ask if it is possible to implement reactive microservices with a REST
    API or a traditional web API. Of course—yes! You can do it one of two ways:'
  prefs: []
  type: TYPE_NORMAL
- en: There are gateways that translate REST requests to JSON-RPC or other protocols.
    For example, gRPC has one ready to use: [https://github.com/grpc-ecosystem/grpc-gateway](https://github.com/grpc-ecosystem/grpc-gateway).
    You can even write your own gateway—it's not so hard for simple or specific cases.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can use a Web API to send messages from one server to another. A microservice
    doesn't have to have a single API path, but you can add a special handler for
    messages in JSON or other formats. For transport, you can use not only HTTP, but
    also the WebSocket protocol.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reactive manifesto
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'If you look at the reactive architecture as a standardized approach, you won''t
    find a guide or rules for how to turn your microservice reactive, but there is
    The Reactive Manifesto, which you can find here: [https://www.reactivemanifesto.org/](https://www.reactivemanifesto.org/).
    It contains a list of principles you can use to be inspired by ideas for the improvement
    of your application.'
  prefs: []
  type: TYPE_NORMAL
- en: Now we can create an example of a reactive microservice for the JSON-RPC procotol.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding JSON-RPC
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are some crates that provide functionality to support the JSON-RPC protocol.
    Mostly, crates support only the server or the client side, not both. Some crates
    don't support asynchronous computations either.
  prefs: []
  type: TYPE_NORMAL
- en: How JSON-RPC works
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The JSON-RPC protocol uses JSON messages in the following format for a request:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding JSON message calls the `substring` remote method of a server
    that can return a result like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: It's worth nothing that a client determines the identifier of the request and
    has to track those values. Servers are ID-agnostic and they use a connection to
    track requests.
  prefs: []
  type: TYPE_NORMAL
- en: There are two versions of the protocol—1.0 and 2.0\. They are similar, but in
    the second version there is a separation of the client and the server. Also, it
    is transport independent, because the first version uses connection events to
    determine behavior. There are improvements for errors and parameters as well.
    You should use version 2.0 for new projects.
  prefs: []
  type: TYPE_NORMAL
- en: To support JSON-RPC, your server has to respond to these kind of JSON requests.
    The protocol is really simple to implement, but we will use the `jsonrpc-http-server`
    crate, which uses HTTP transport and provides types to bootstrap a server.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a microservice
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will create an example of a microservice that supports the
    JSON-RPC protocol and has two methods. The microservice will support working as
    a part of a ring of microservices. We will send a message to one microservice,
    which will send a message to the next microservice in the ring, and that microservice
    will send the message further.
  prefs: []
  type: TYPE_NORMAL
- en: We will create a ring example, because if it is implemented incorrectly your
    microservice will be blocked, because they can't process requests in parallel
    like reactive services have to do.
  prefs: []
  type: TYPE_NORMAL
- en: Dependencies
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'First, we need to import the necessary dependencies:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Most likely, you are familiar with most crates except `jsonrpc` and `json-rpc-server`.
    The first is a JSON-RPC client that's based on the `hyper` crate. The second also
    uses the `hyper` crate and provides server functionality of JSON-RPC.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s import the necessary types and talk a little about them:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: The JSON-RPC crate has the `Client` type that we will use to call the remote
    methods of other services. We also imported `Error` from that crate as `ClientError`
    to avoid a name conflict with `Error` from the failure crate.
  prefs: []
  type: TYPE_NORMAL
- en: For the server side, we will use `ServerBuilder` from the `jsonrpc-http-server`
    crate. Also, we need `Error` to be renamed to `ServerError` from that crate. To
    implement function handlers, we need to import `IoHandler`, which can be used
    to attach functions as RPC methods. Also, we need a `Value` (actually, this type
    is reimported from the `serde_json` crate), which is used as a result type for
    RPC methods.
  prefs: []
  type: TYPE_NORMAL
- en: 'To avoid mistakes in method names, because we will use them twice for the server
    implementation and then in a client, we declare names as string constants:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The first method will start sending messages from one microservice to the next.
    The second method is used to stop this roll-calling process.
  prefs: []
  type: TYPE_NORMAL
- en: Client
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To interact with other microservice instances and to call their remote methods,
    we will create a separate struct, because it''s more convenient than using the
    JSON-RPC `Cilent` directly. But in any case, we use this type internally in our
    struct:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'We will use the `Remote` struct to make calls to remote services. To create
    the struct, we will use the following constructor:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: The `Client` struct expects the `String` URL as a parameter, but we will use `SocketAddr`
    to create a URL.
  prefs: []
  type: TYPE_NORMAL
- en: 'Also, we need a generic function that will use the `Client` instance to call
    remote methods. Add the `call_method` method to the implementation of the `Remote`
    struct:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: The calling of the JSON-RPC method using the JSON-RPC crate is simple. Use the `build_request`
    method of the `Client` instance to create a `Request` and send it using the `send_request`
    method of the same `Client`. There is a method called `do_rpc` that does this
    in a single call. We will use a more verbose approach to show that you can predefine
    requests and use them to speed up the preparation for calling. Also, it's more
    pleasant to use business-oriented struct methods instead of a raw `Client`. We
    isolate an implementation using a wrapper that hides the details of RPC calls.
    What if you decide to change to another protocol, such as gRPC?
  prefs: []
  type: TYPE_NORMAL
- en: 'Add special methods to the `Remote` struct implementation to make calls using
    the `call_method` method. First, we need the `start_roll_call` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: It won't pass any parameters with a call, but it expects the `bool` type of
    the result. We used a constant for the remote method's name.
  prefs: []
  type: TYPE_NORMAL
- en: 'Add the `mark_itself` method to the `Remote` struct:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: It doesn't send any parameters either and returns the `bool` value.
  prefs: []
  type: TYPE_NORMAL
- en: Now we can add a worker to separate outgoing method calls from incoming calls.
  prefs: []
  type: TYPE_NORMAL
- en: Worker
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Since we have two methods, we will add a struct to perform remote calls of
    these methods from a worker thread. Add the `Action` enumeration to the code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'It has two variants: `StartRollCall` to perform the remote `start_roll_call`
    method call, and the `MarkItself` variant to call the remote `mark_itself` method.'
  prefs: []
  type: TYPE_NORMAL
- en: Now we can add a function to spawn a worker in a separate thread. If we will
    perform outgoing calls immediately in incoming method handlers, we can block the
    execution, because we have a ring of microservices and blocking one microservice
    will block the whole ring's interaction.
  prefs: []
  type: TYPE_NORMAL
- en: No blocking is an important property of a reactive microservice. The microservices
    have to process all calls in parallel or asynchronously, but never block execution
    for a long time. They should work like actors in the actors model we have discussed.
  prefs: []
  type: TYPE_NORMAL
- en: 'Look at the `spawn_worker` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: This function creates a channel and spawns a new thread with a routine that
    processes all received messages from a channel. We create the `Remote` instance
    with the address extracted from the `NEXT` environment variable.
  prefs: []
  type: TYPE_NORMAL
- en: There is a flag that shows that the `start_roll_call` method has been called.
    We set it to `true` when the `StartRollCall` message is received and the `start_roll_call`
    method of the remote server is called. If the flag is already set to `true` and
    the routine received the `StartRollCall` message, the thread will call the `mark_itself`
    remote method. In other words, we will call the `start_roll_call` methods of all
    running service instances. When all services set the flag to `true`, we will call
    the `mark_itself` methods of all services.
  prefs: []
  type: TYPE_NORMAL
- en: Let's start a server and run a ring of services.
  prefs: []
  type: TYPE_NORMAL
- en: Server
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The `main` function activates a logger and spawns a worker. Then, we extract
    the `ADDRESS` environment variable to use this address value to bind a socket
    of a server. Loot at the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: To implement JSON-RPC methods, we use the `IoHandler` struct. It has the `add_method`
    method, which expects the name of the method and needs a closure with an implementation
    of this method.
  prefs: []
  type: TYPE_NORMAL
- en: 'We added two methods, `start_roll_call` and `mark_itself`, using constants
    as names for these methods. The implementation of these methods is simple: we
    only prepare the corresponding `Action` messages and send them to the worker''s
    thread.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The JSON-RPC method implementation has to return the `Result<Value, ServerError>`
    value. To convert any other errors to `ServerError` we use the following function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: The function only prints the current error message and creates an error with
    the `InternalError` code using the `internal_error` method of the `ServerError`
    type.
  prefs: []
  type: TYPE_NORMAL
- en: At the end of main function, we create a new `ServerBuilder` instance with the
    created `IoHandler` and start the HTTP server to listen for JSON-RPC requests
    with the `start_http` server.
  prefs: []
  type: TYPE_NORMAL
- en: Now we can start a ring of services to test it.
  prefs: []
  type: TYPE_NORMAL
- en: Compiling and running
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Compile this example with the `cargo build` subcommand, and let''s start three
    instances of the service using the following commands (run every command in a
    separate terminal window to see the logs):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'When the three services are started, prepare and send a JSON-RPC call request
    with `curl` from another terminal window:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'With this command, we start the interaction of all services, and they will
    call each other in a ring. You will see the logs of every service. The first prints
    something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'The second will print something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'And the third will output the following logs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: All services works as independent participants of the process, react to incoming
    messages, and send messages to other services when there is something to send.
  prefs: []
  type: TYPE_NORMAL
- en: Learning about gRPC
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will rewrite the JSON-RPC ring example to gRPC. This protocol
    differs from JSON-RPC because it requires a protocol declaration—a predefined
    interaction schema. This restriction is good for large projects, because you can't
    make a mistake in a message's layout, but with Rust, JSON-RPC is also reliable
    because you have to declare all structs exactly and you will get an error if you
    take an incorrect JSON message. With gRPC, you don't have to care about it at
    all.
  prefs: []
  type: TYPE_NORMAL
- en: How gRPC works
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The benefit of gRPC in comparison with JSON-RPC is speed. gRPC can work faster,
    because it uses a fast serialization format—Protocol Buffers. Both gRPC and Protocol
    Buffers were originally developed by Google and are proven in high-performance
    cases.
  prefs: []
  type: TYPE_NORMAL
- en: 'gRPC uses `HTTP/2` for transport. It''s a really fast and good transport protocol.
    First, it''s binary: all requests and responses are squeezed into a compact portion
    of bytes and compressed. It''s multiplexed: you can send a lot of requests simultaneously,
    but `HTTP/1` demands respect for the order of requests.'
  prefs: []
  type: TYPE_NORMAL
- en: gRPC needs a scheme and uses Protocol Buffers as the **Interface Definition
    Language** (**IDL**). Before you start writing an implementation of a service,
    you have to write the `proto` file that contains a declaration of all types and
    services. After that, you need to compile the declaration to sources (in the Rust
    programming language in our case) and use them to write the implementation.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `protobuf` crate and the common gRPC crates use that crate as a basis.
    Actually, there are not many crates; just two: the `grpcio` crate, which is a
    wrapper over the original gRPC core library, and the `grpc` crate, which is the
    pure Rust implementation of the protocol.'
  prefs: []
  type: TYPE_NORMAL
- en: Now we can rewrite the previous example from JSON-RPC protocol to gRPC. At first,
    we have to add all the necessary dependencies and write a declaration of our service.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a microservice
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The gRPC example is very complex, because we have to declare an interaction
    protocol. We also have to add the `build.rs` file to generate Rust sources from
    a protocol description.
  prefs: []
  type: TYPE_NORMAL
- en: Since it's hard to make a gRPC call from curl, we will also add a client that
    helps us to test services. You can also use other tools that are available for
    debugging gRPC applications.
  prefs: []
  type: TYPE_NORMAL
- en: Dependencies
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Create a new `binary` crate and open `Cargo.toml` in an editor. We will explore
    every section of this file, because building a gRPC example is more complex than
    services that use flexible interaction protocols such as JSON-RPC. We''ll use
    Edition 2018, as we do for most examples in this book:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'In dependencies, we need a basic set of crates—`failure`, `log`, and `env_logger`.
    Also, we add the `protobuf` crate. We won''t use it directly, but it''s used by
    generated Rust sources that we will get from a protocol description later in this
    section. The most important crate from the current example is grpc. We will use
    a version from GitHub, because the crate is in active development:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Actually, the GitHub repository of the `grpc` crate is a workspace and also
    contains the `protoc-rust-grpc` crate, which we will use to generate a protocol
    declaration in Rust using the `build.rs` file. Add this dependency to the `[build-dependencies]`
    section of `Cargo.toml`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: The `example` crate we create will produce two binary files—server and client.
    As I said, we need a client, because it's simpler than preparing calls manually,
    and use curl to call gRPC methods.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first binary is a server built from the `src/server.rs` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'The second binary uses the `src/client.rs` file to build a client:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: We also have `src/lib.rs` for common parts, but we have to describe a protocol
    and create the `build.rs` file.
  prefs: []
  type: TYPE_NORMAL
- en: Protocol
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'gRPC uses a special language for protocol declarations.There are two versions
    of the language—`proto2` and `proto3`. We will use the second as it''s more modern.
    Create a `ring.proto` file and add the following declaration:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, we specified the syntax as `proto3`. Options give you the ability
    to set the properties for the generation of source files for different languages
    if you will interact with a service from other applications or other microservices.
    We don't need to set these options for our example, but you might have this part
    in a file if you take it from another developer.
  prefs: []
  type: TYPE_NORMAL
- en: The protocol declaration contains a package name set with the `package` specifier
    and a package name that we set to `ringproto`.
  prefs: []
  type: TYPE_NORMAL
- en: Also, we added the `Empty` message with no fields. We will use this type as
    the input and output parameter for all methods, but it's better to use different
    types for real microservices. Firstly, you can't have methods without input and
    output parameters. The second reason is future service improvements. If you want
    to add extra fields to the protocol later, you can do it. Moreover, the protocol
    can easily cope with different versions of the protocol; often you can use both
    new and old microservices, because Protocol Buffers work fine with extra fields,
    and you can extend the protocol later when you need it.
  prefs: []
  type: TYPE_NORMAL
- en: The service declaration is contained in the `service` section. You can have
    multiple services' declarations in a protocol declaration file and use only the
    necessary declared services in an implementation. But we need only one service
    declaration for our ring example. Add the `Ring` service and include two RPC methods
    with the `rpc` specifier. We added the `StartRollCall` method and `MakeItself`.
    The same as we did in the previous example. Both take the `Empty` value as an
    input argument and return `Empty` as well.
  prefs: []
  type: TYPE_NORMAL
- en: The name of a service is important, because it will be used as a prefix for
    multiple types in generated Rust sources. You can create sources using the `protoc`
    tool, but it's more convenient to create a build script that will generate sources
    with protocol types during compilation.
  prefs: []
  type: TYPE_NORMAL
- en: Generating interfaces
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Rust build scripts let you implement a function that will do some additional
    preparation for project compilation. In our case, we have the `ring.proto` file
    with a protocol definition and we want to convert it to Rust sources using the `protoc-rust-grpc`
    crate.
  prefs: []
  type: TYPE_NORMAL
- en: 'Create the `build.rs` file in the project and add the following content:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: Build scripts use the `main` function as an entry point, in which you can implement
    any activities you want. We used the run function of the `protoc-rust-grpc` crate
    with `Args`—we set the output directory in the `out_dir` field, set the `ring.proto`
    file as input declaration with the `input` field, activate the `rust_protobuf` Boolean
    flag to generate sources for the `rust**-**protobuf` crate (you don't need it
    if you are already using the `protobuf` crate and generating types with it), then
    set the `includes` field to an empty array.
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, when you run `cargo build`, it will produce two modules in the `src`
    folder: `ring.rs` and `ring_grpc.rs`. I don''t put its sources here, because generated
    files are large, but we will use it to create a wrapper for a gRPC client, as
    we did in the previous example.'
  prefs: []
  type: TYPE_NORMAL
- en: Shared client
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Open the `lib.rs` source file and add two generated modules:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Import some types we need to create a wrapper for a gRPC client:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, the generated modules contain types we declared in the `ring.proto`
    file. The `ring` module contains the `Empty` struct, and the `ring_grpc` module
    contains the `Ring` trait, which represents an interface of a remote service.
    Also, `protoc_rust_grpc` in the build script generated the `RingClient` type.
    This type is a client that can be used to call remote methods. We wrap it with
    our own struct, because `RingClient` generates `Future` instances and we will
    use the `Remote` wrapper to perform them and get the result.
  prefs: []
  type: TYPE_NORMAL
- en: We also use types from the `grpc` crate. The `Error` type is imported as `GrpcError`;
  prefs: []
  type: TYPE_NORMAL
- en: '`RequestOptions`, which is necessary to prepare method call requests; `ClientConf`,
    which is used to add extra configuration parameters for the `HTTP/2` connection
    (we will use the default values); and `ClientStubExt`, which provides connection
    methods for clients.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Add the `Remote` struct holding the `RingClient` instance inside:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'We use this struct for both client and server. Add a new method to construct
    new instances of `Remote` from the provided `SocketAddr`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: Since generated clients expect separate host and port values, we extract them
    from the `SocketAddr` value. Also, we create the default `ClientConf` configuration
    and use all these values to create the `RingClient` instance to put it to the
    new `Remote` instance.
  prefs: []
  type: TYPE_NORMAL
- en: 'We create the `Remote` struct to have simple methods to call remote methods.
    Add the `start_roll_call` method to the `Remote` implementation to call the `StartRollCall`
    gRPC method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: '`RingClient` already has this method, but it expects parameters that we want
    to hide, and returns a `Future` instance that we want to perform immediately using
    the wait method call. The `Future` returns a tuple with three items, but we need
    only one value, because other values contain metadata that we don''t need.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Implement the `mark_itself` method in a similar way to call the `MarkItself`
    gRPC method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: Now we can implement a client and a server, because both need the `Remote` struct
    to perform RPC calls.
  prefs: []
  type: TYPE_NORMAL
- en: Client
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Add the `src/client.rs` file and import a few types:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: We need a generic `Error` from the `failure` crate, because it's a universal
    type for most error handling cases, and import the `Remote` struct we created
    before.
  prefs: []
  type: TYPE_NORMAL
- en: 'The client is an extremely simple tool. It calls the `StartRollCall` remote
    gRPC method of a service with the address provided in the `NEXT` environment variable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: Create the `Remote` instance with the parsed `SocketAddr` value and perform
    a call. This is it. The server is very complex. Let's implement it.
  prefs: []
  type: TYPE_NORMAL
- en: Server implementation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Add the `src/server.rs` source file and add generated modules to it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'We need these modules because we will implement the `Ring` trait for our RPC
    handler. Look at the types we will use:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: The types you are not familiar with yet are `ServerBuilder`, which is used to
    create a server instance and fill it with service implementations, and `SingleResponse`
    is the result of handler calls. The other types you already know.
  prefs: []
  type: TYPE_NORMAL
- en: Service implementation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We need our own type that will implement the `Ring` trait to implement RPC
    interface of a service. But we also have to keep a `Sender` for a worker to send
    actions to it. Add the `RingImpl` struct with a `Sender` of `Action` wrapped with
    `Mutex`, because the `Ring` trait requires the `Sync` trait implementation as
    well:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'We will construct an instance from the `Sender` instance:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'For every incoming method call, we need to send `Action` to a worker and we
    can add a method to the `RingImpl` implementation to reuse it in all handlers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: The `send_action` function takes the `Action` value and locks a `Mutex` to use
    a `Sender`. At the end, it creates an `Empty` value and returns it as a `SingleResponse`
    instance. If you have noticed, we used the `try_or_response!` macro that we defined,
    because `SingleResponse` is a `Future` instance and we have to return this type
    in any success or failure cases.
  prefs: []
  type: TYPE_NORMAL
- en: 'This macro works like the `try!` macro of the standard library. It uses match
    to extract a value or return a result if there is an error value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: The preceding macro creates the `SingleResponse` instance with the `Panic` variant
    of `GrpcError`, but uses a description of an error from the existing error value.
  prefs: []
  type: TYPE_NORMAL
- en: Handlers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now we can implement gRPC methods of the `Ring` service we declared in the `ring.proto`
    file before. We have the `Ring` trait with the same names of the methods. Every
    method expects the `Empty` value and has to return this type, because we defined
    this in the declaration. Also, every method has to return the `SingleResponse`
    type as a result. We already defined the `send_action` method that sends the `Action`
    value to a worker and returns the `SingleResponse` response with the `Empty` value.
    Let''s use the `send_action` method for both methods we have to implement:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: We have a pretty simple implementation of gRPC methods handlers, but you can
    also add more sensible implementations and produce `SingleResponse` from a Future
    asynchronously.
  prefs: []
  type: TYPE_NORMAL
- en: The main function
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Everything is ready for the implementation of the `main` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: We initialized a logger and created a channel that we will use to send actions
    from `RingImpl` to a worker. We extracted `SocketAddr` from the `ADDRESS` environment
    variable and used this value to bind a server to the provided address.
  prefs: []
  type: TYPE_NORMAL
- en: We created a `ServerBuilder` instance with the `new_plain` method. It creates
    a server without TLS, since gRPC supports secure connections and we have to provide
    a type parameter for `ServerBuilder` that implements the `TlcAcceptor` trait.
    But with `new_plain` we use the `TlasAcceptor` stub from the `tls_api_stub` crate.
    The `ServerBuilder` struct contains the `http` field of the `httpbis::ServerBuilder`
    type. We can use this file to set the address to which to bind the server's socket.
  prefs: []
  type: TYPE_NORMAL
- en: After, we create the `RingImpl` instance and use the `add_service` method of
    `ServiceBuilder` to attach a service implementation, but we have to provide the
    generic `grpc::rt::ServerServiceDefinition` definition of the service and we use
    `new_service_def` of the `RingServer` type to create it for the `RingImpl` instance.
  prefs: []
  type: TYPE_NORMAL
- en: At the end, we set the quantity of threads in the pool that will be used to
    handle incoming requests and call the `build` method of `ServiceBuilder` to start
    a server. But wait—if you leave the `build` call method, the main thread will
    be terminated and you will have to add a loop or other routine to keep the main
    thread alive.
  prefs: []
  type: TYPE_NORMAL
- en: Luckily, we need a worker and we can use the main thread to run it. If you only
    need to run the gRPC server, you can use a `loop` with the `thread::park` method
    call, which will block the thread till it is unblocked by the `unpark` method
    call. This approach is used internally by asynchronous runtimes.
  prefs: []
  type: TYPE_NORMAL
- en: We will use the `worker_loop` function call, but we have not implemented this
    function yet.
  prefs: []
  type: TYPE_NORMAL
- en: Worker
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We already implemented the worker in the JSON-RPC example. In the gRPC version,
    we use have same code, but expect a `Receiver` value and don''t spawn a new thread:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: Let's compile and run this example.
  prefs: []
  type: TYPE_NORMAL
- en: Compiling and running
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Build both the server and the client with the `cargo build` subcommand.
  prefs: []
  type: TYPE_NORMAL
- en: If you want to specify binary, use the --bin parameter with the name of a binary.
  prefs: []
  type: TYPE_NORMAL
- en: Also, you can use `cargo watch` tool for building.
  prefs: []
  type: TYPE_NORMAL
- en: If you use the `cargo watch` tool, then the `build.rs` script will generate
    files with gRPC types and `watch` will continuously restart the build. To prevent
    this, you can set the `--ignore` argument to the command with a pattern of files'
    names to ignore. For our example, we have to run the `cargo watch --ignore 'src/ring*'`
    command.
  prefs: []
  type: TYPE_NORMAL
- en: 'When both binaries are built, run three instances in separate terminals:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'When all of the services start, use a client to send a request to the first
    service:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: This command will call a remote method, `start_roll_call`, and you will see
    similar server logs to what you saw in the preceding JSON-RPC example.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This chapter covered good practices for creating reactive microservices architecture.
    We started our learning from basic concepts: what a reactive approach is, how
    to implement it, and how remote procedure calls helps to implement message-driven
    architecture. Also, we discussed existing RPC frameworks and crates that you can
    use simply with Rust.'
  prefs: []
  type: TYPE_NORMAL
- en: To demonstrate how reactive applications work, we created two examples of microservices
    that use RPC methods to interact with each other. We created an application that
    uses a ring of running microservices that send requests to each other in a loop
    till every instance is informed about an event.
  prefs: []
  type: TYPE_NORMAL
- en: We also created an example that uses the JSON-RPC protocol for instance interaction
    and used the `jsonrpc-http-server` crate for the server side and the JSON-RPC
    crate for the client side.
  prefs: []
  type: TYPE_NORMAL
- en: After that, we created an example that uses the gRPC protocol for microservice
    interaction, and we used the `grpc` crate, which covers both the client and server
    sides.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the next chater we will start to integrate microservices with database and
    explore available crates to interact with the follwoing databases: PostgreSQL,
    MySQL, Redis, MongoDB, DynamoDB.'
  prefs: []
  type: TYPE_NORMAL
