- en: '2'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '2'
- en: How Programming Languages Model Asynchronous Program Flow
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 编程语言如何模拟异步程序流程
- en: In the previous chapter, we covered asynchronous program flow, concurrency,
    and parallelism in general terms. In this chapter, we’ll narrow our scope. Specifically,
    we’ll look into different ways to model and deal with concurrency in programming
    languages and libraries.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们以一般性的方式介绍了异步程序流程、并发和并行性。在本章中，我们将缩小范围。具体来说，我们将探讨编程语言和库中模拟和处理并发性的不同方法。
- en: It’s important to keep in mind that threads, futures, fibers, goroutines, promises,
    etc. are abstractions that give us a way to model an asynchronous program flow.
    They have different strengths and weaknesses, but they share a goal of giving
    programmers an easy-to-use (and importantly, hard to misuse), efficient, and expressive
    way of creating a program that handles tasks in a non-sequential, and often unpredictable,
    order.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 需要记住的是，线程、未来、纤程、goroutines、承诺等都是抽象概念，它们为我们提供了一种模拟异步程序流程的方法。它们具有不同的优势和劣势，但它们的目标是给程序员提供一个易于使用（并且重要的是，难以误用）、高效且具有表现力的方式来创建一个处理任务的非顺序、通常不可预测的程序。
- en: The lack of precise definitions is prevalent here as well; many terms have a
    name that stems from a concrete implementation at some point in time but has later
    taken on a more general meaning that encompasses different implementations and
    varieties of the same thing.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 缺乏精确的定义在这里也很普遍；许多术语的名称源于某个时间点的具体实现，但后来它们获得了更广泛的意义，涵盖了不同实现和同一事物的不同变体。
- en: We’ll first go through a way of grouping different abstractions together based
    on their similarities before we go on to discuss the pros and cons of each of
    them. We’ll also go through important definitions that we’ll use throughout the
    book and discuss OS threads in quite some detail.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们讨论每个抽象的优缺点之前，我们首先将根据它们的相似性对不同的抽象进行分组。我们还将介绍本书中会使用的重要定义，并详细讨论操作系统线程。
- en: The topics we discuss here are quite abstract and complicated so don’t feel
    bad if you don’t understand everything immediately. As we progress through the
    book and you get used to the different terms and techniques by working through
    some examples, more and more pieces will fall into place.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这里讨论的主题相当抽象和复杂，所以如果你一开始不理解所有内容，请不要感到难过。随着我们继续阅读本书，并通过解决一些示例来熟悉不同的术语和技术，越来越多的部分将会变得清晰。
- en: 'Specifically, the following topics will be covered:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 具体来说，以下内容将会被涵盖：
- en: Definitions
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义
- en: Threads provided by the operating system
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 操作系统提供的线程
- en: Green threads/stackfull coroutines/fibers
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 绿色线程/栈满协程/纤程
- en: Callback based approaches
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于回调的方法
- en: Promises, futures, and async/await
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 承诺、未来和 async/await
- en: Definitions
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义
- en: 'We can broadly categorize abstractions over concurrent operations into two
    groups:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将并发操作的抽象大致分为两组：
- en: '`async`/`await` in Rust and JavaScript.'
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Rust 和 JavaScript 中的 `async`/`await`。
- en: '**Non-cooperative**: Tasks that don’t necessarily yield voluntarily. In such
    a system, the scheduler must be able to **pre-empt** a running task, meaning that
    the scheduler can stop the task and take control over the CPU even though the
    task would have been able to do work and progress. Examples of this are OS threads
    and Goroutines (after GO version 1.14).'
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**非协作式**：不一定自愿让出的任务。在这样的系统中，调度器必须能够**抢占**一个正在运行的任务，这意味着调度器可以停止任务并控制 CPU，即使该任务本来还能够工作并取得进展。这类任务的例子包括操作系统线程和
    Goroutines（在 GO 版本 1.14 之后）。'
- en: '![Figure 2.1 – Non-cooperative vs. cooperative multitasking](img/B20892_Figure_02.1.jpg)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.1 – 非协作式与协作式多任务处理](img/B20892_Figure_02.1.jpg)'
- en: Figure 2.1 – Non-cooperative vs. cooperative multitasking
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.1 – 非协作式与协作式多任务处理
- en: Note
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: In a system where the scheduler can pre-empt running tasks, tasks can also yield
    voluntarily as they do in a cooperative system, and it’s rare with a system that
    *only* relies on pre-emption.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个调度器可以抢占正在运行的任务的系统中，任务也可以像在协作系统中那样自愿让出，而在仅依赖于抢占的系统中的这种情况很少见。
- en: 'We can further divide these abstractions into two broad categories based on
    the characteristics of their implementation:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以根据它们实现的特点将这些抽象进一步分为两大类：
- en: '**Stackful**: Each task has its own call stack. This is often implemented as
    a stack that’s similar to the stack used by the operating system for its threads.
    Stackful tasks can suspend execution at any point in the program as the whole
    stack is preserved.'
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**有堆栈**：每个任务都有自己的调用堆栈。这通常实现为一个与操作系统用于其线程的堆栈相似的堆栈。有堆栈的任务可以在程序的任何位置挂起执行，因为整个堆栈都被保留。'
- en: '**Stackless**: There is not a separate stack for each task; they all run sharing
    the same call stack. A task can’t be suspended in the middle of a stack frame,
    limiting the runtime’s ability to pre-empt the task. However, they need to store/restore
    less information when switching between tasks so they can be more efficient.'
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**无堆栈**：每个任务没有单独的堆栈；它们都运行在共享的调用堆栈上。任务不能在堆栈帧的中间被挂起，这限制了运行时抢占任务的能力。然而，它们在任务间切换时需要存储/恢复更少的信息，因此可以更高效。'
- en: There are more nuances to these two categories that you’ll get a deep understanding
    of when we implement an example of both a stackful coroutine (fiber) and a stackless
    coroutine (Rust futures generated by `async`/`await`) later in the book. For now,
    we keep the details to a minimum to just provide an overview.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个类别还有更多细微之处，你将在本书后面通过实现一个堆栈式协程（纤程）和一个无堆栈协程（由`async`/`await`生成的Rust未来）的示例来深入理解。目前，我们只提供概述，尽量简化细节。
- en: Threads
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 线程
- en: We keep referring to threads all throughout this book, so before we get too
    far in, let’s stop and give “thread” a good definition since it’s one of those
    fundamental terms that causes a lot of confusion.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在整本书中不断提到线程，所以在我们走得太远之前，让我们停下来给“线程”一个好的定义，因为它是一个引起很多混淆的基本术语。
- en: In the most general sense, a thread refers to a **thread of execution**, meaning
    a set of instructions that need to be executed sequentially. If we tie this back
    to the first chapter of this book, where we provided several definitions under
    the Concurrency vs. Parallelism subsection, a thread of execution is similar to
    what we defined as a **task** with multiple steps that need resources to progress.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在最一般的意义上，线程指的是**执行线程**，即需要按顺序执行的一系列指令。如果我们将其与本书第一章中在并发与并行性子节下提供的几个定义联系起来，执行线程类似于我们定义的具有多个步骤且需要资源才能进展的**任务**。
- en: The generality of this definition can be a cause of some confusion. A thread
    to one person can obviously refer to an OS thread, and to another person, it can
    simply refer to any abstraction that represents a thread of execution on a system.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '这个定义的通用性可能会引起一些混淆。对某个人来说，一个线程显然可以指操作系统线程，而对另一个人来说，它可能仅仅指代任何代表系统上执行线程的抽象。 '
- en: 'Threads are often divided into two broad categories:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 线程通常分为两大类：
- en: '**OS threads**: These threads are created by the OS and managed by the OS scheduler.
    On Linux, this is known as a **kernel thread**.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**操作系统线程**：这些线程是由操作系统创建并由操作系统调度器管理的。在Linux上，这被称为**内核线程**。'
- en: '**User-level threads**: These threads are created and managed by us as programmers
    without the OS knowing about them.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**用户级线程**：这些线程是由我们程序员创建和管理的，操作系统并不知道它们的存在。'
- en: 'Now, this is where things get a bit tricky: OS threads on most modern operating
    systems have a lot of similarities. Some of these similarities are dictated by
    the design of modern CPUs. One example of this is that most CPUs assume that there
    is a stack it can perform operations on and that it has a register for the stack
    pointer and instructions for stack manipulation.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，事情变得有点棘手：大多数现代操作系统的操作系统线程有很多相似之处。其中一些相似之处是由现代CPU的设计决定的。一个例子是，大多数CPU都假设有一个它可以执行操作的堆栈，并且它有一个堆栈指针寄存器和堆栈操作指令。
- en: User-level threads can, in their broadest sense, refer to *any* implementation
    of a system (runtime) that creates and schedules tasks, and you can’t make the
    same assumptions as you do with OS threads. They can closely resemble OS threads
    by using separate stacks for each task, as we’ll see in [*Chapter 5*](B20892_05.xhtml#_idTextAnchor092)
    when we go through our fiber/green threads example, or they can be radically different
    in nature, as we’ll see when we go through how Rust models concurrent operations
    later on in Part 3 of this book.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在最广泛的意义上，用户级线程可以指代任何创建和调度任务的系统（运行时）的实现，你不能像对待操作系统线程那样做出相同的假设。它们可以通过为每个任务使用单独的堆栈而与操作系统线程相似，正如我们在[*第五章*](B20892_05.xhtml#_idTextAnchor092)中通过我们的纤程/绿色线程示例所看到的，或者它们在本质上可以非常不同，正如我们在本书第三部分的后面部分将看到的，我们将了解Rust如何模拟并发操作。
- en: No matter the definition, a set of tasks needs something that manages them and
    decides who gets what resources to progress. The most obvious resource on a computer
    system that all tasks need to progress is CPU time. We call the “something” that
    decides who gets CPU time to progress a **scheduler**.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 无论定义如何，一组任务都需要某种东西来管理它们并决定谁可以获得哪些资源以进行进展。在计算机系统中，所有任务都需要进行进展的最明显资源是CPU时间。我们将决定谁可以获得CPU时间以进行进展的“某种东西”称为**调度器**。
- en: Most likely, when someone refers to a “thread” without adding extra context,
    they refer to an OS thread/kernel thread, so that’s what we’ll do going forward.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 很可能，当某人提到“线程”而没有添加额外上下文时，他们指的是操作系统线程/内核线程，所以我们将继续这样做。
- en: I’ll also keep referring to a thread of execution as simply a **task**. I find
    the topic of asynchronous programming easier to reason about when we limit the
    use of terms that have different assumptions associated with them depending on
    the context as much as possible.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '我还会继续将执行线程简单地称为**任务**。我发现当我们尽可能限制与上下文相关的不同假设所关联的术语的使用时，异步编程的主题更容易推理。 '
- en: With that out of the way, let’s go through some defining characteristics of
    OS threads while we also highlight their limitations.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们把这个问题解决掉，同时我们也会强调操作系统中线程的一些定义特征。
- en: Important!
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 重要！
- en: Definitions will vary depending on what book or article you read. For example,
    if you read about how a specific operating system works, you might see that processes
    or threads are abstractions that represent “tasks”, which will seem to contradict
    the definitions we use here. As I mentioned earlier, the choice of reference frame
    is important, and it’s why we take so much care to define the terms we use thoroughly
    as we encounter them throughout the book.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 定义将根据你阅读的书籍或文章而有所不同。例如，如果你阅读关于特定操作系统如何工作的内容，你可能会看到进程或线程是代表“任务”的抽象，这似乎与我们在这里使用的定义相矛盾。正如我之前提到的，参考系的选择很重要，这就是为什么我们在整本书中遇到这些术语时，都要非常仔细地定义它们。
- en: The definition of a thread can also vary by operating system, even though most
    popular systems share a similar definition today. Most notably, Solaris (pre-Solaris
    9, which was released in 2002) used to have a two-level thread system that differentiated
    between application threads, lightweight processes, and kernel threads. This was
    an implementation of what we call M:N threading, which we’ll get to know more
    about later in this book. Just beware that if you read older material, the definition
    of a thread in such a system might differ significantly from the one that’s commonly
    used today.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 线程的定义也可能因操作系统而异，尽管今天大多数流行的系统共享一个类似定义。最值得注意的是，Solaris（在2002年发布的Solaris 9之前）曾经有一个两级线程系统，它区分了应用程序线程、轻量级进程和内核线程。这是我们所说的M:N线程的实现，我们将在本书后面的章节中了解更多。只是要注意，如果你阅读了旧材料，这种系统中线程的定义可能与今天普遍使用的定义有显著差异。
- en: Now that we’ve gone through the most important definitions for this chapter,
    it’s time to talk more about the most popular ways of handling concurrency when
    programming.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们已经讨论了本章最重要的定义，现在是时候更多地讨论编程时处理并发最流行的方式了。
- en: Threads provided by the operating system
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 操作系统提供的线程
- en: Note!
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 注意！
- en: We call this 1:1 threading. Each task is assigned one OS thread.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 我们称之为1:1线程。每个任务分配一个操作系统线程。
- en: Since this book will not focus specifically on OS threads as a way to handle
    concurrency going forward, we treat them more thoroughly here.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 由于本书将不会专门关注操作系统线程作为处理并发的手段，所以我们在这里更详细地讨论它们。
- en: Let’s start with the obvious. To use threads provided by the operating system,
    you need, well, an operating system. Before we discuss the use of threads as a
    means to handle concurrency, we need to be clear about what kind of operating
    systems we’re talking about since they come in different flavors.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从显而易见的事情开始。要使用操作系统提供的线程，你需要，嗯，一个操作系统。在我们讨论将线程用作处理并发的一种手段之前，我们需要清楚我们正在讨论哪种类型的操作系统，因为它们有不同的风味。
- en: Embedded systems are more widespread now than ever before. This kind of hardware
    might not have the resources for an operating system, and if they do, you might
    use a radically different kind of operating system tailored to your needs, as
    the systems tend to be less general purpose and more specialized in nature.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 嵌入式系统现在比以往任何时候都更普遍。这种硬件可能没有操作系统的资源，如果有的话，你可能会使用一种针对你的需求定制的、根本不同的操作系统，因为系统往往不那么通用，而更多是专门化的。
- en: Their support for threads, and the characteristics of how they schedule them,
    might be different from what you’re used to in operating systems such as Windows
    or Linux.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 他们对线程的支持以及它们调度线程的特性可能与你习惯的Windows或Linux等操作系统中的不同。
- en: Since covering all the different designs is a book on its own, we’ll limit the
    scope to talk about treads, as they’re used in Windows and Linux-based systems
    running on popular desktop and server CPUs.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 由于涵盖所有不同的设计本身就是一本书的内容，我们将范围限制在讨论线程上，因为它们在运行在流行桌面和服务器CPU上的基于Windows和Linux的系统中使用。
- en: OS threads are simple to implement and simple to use. We simply let the OS take
    care of everything for us. We do this by spawning a new OS thread for each task
    we want to accomplish and write code as we normally would.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 操作系统线程易于实现和使用。我们只是让操作系统为我们处理一切。我们通过为每个我们想要完成的任务创建一个新的操作系统线程，并像平常一样编写代码来实现这一点。
- en: The runtime we use to handle concurrency for us is the operating system itself.
    In addition to these advantages, you get parallelism for free. However, there
    are also some drawbacks and complexities resulting from directly managing parallelism
    and shared resources.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 我们用来处理并发的运行时是操作系统本身。除了这些优点之外，你还能免费获得并行性。然而，直接管理并行性和共享资源也会带来一些缺点和复杂性。
- en: Creating new threads takes time
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建新线程需要时间
- en: Creating a new OS thread involves some bookkeeping and initialization overhead,
    so while switching between two existing threads in the same process is pretty
    fast, creating new ones and discarding ones you don’t use anymore involves work
    that takes time. All the extra work will limit throughput if a system needs to
    create and discard a lot of them. This can be a problem if you have huge amounts
    of small tasks that need to be handled concurrently, which often is the case when
    dealing with a lot of I/O.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个新的操作系统线程涉及一些账目和初始化开销，所以虽然在同一进程内切换两个现有线程相当快，但创建新线程和丢弃不再使用的线程需要花费时间。如果系统需要创建和丢弃大量线程，所有额外的开销都会限制吞吐量。当你处理大量需要并发处理的小任务时，这可能会成为一个问题，尤其是在处理大量I/O时。
- en: Each thread has its own stack
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 每个线程都有自己的栈
- en: We’ll cover stacks in detail later in this book, but for now, it’s enough to
    know that they occupy a fixed size of memory. Each OS thread comes with its own
    stack, and even though many systems allow this size to be configured, they’re
    still fixed in size and can’t grow or shrink. They are, after all, the cause of
    stack overflows, which will be a problem if you configure them to be too small
    for the tasks you’re running.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在本书的后面详细讨论栈，但到目前为止，知道它们占据固定大小的内存就足够了。每个操作系统线程都有自己的栈，尽管许多系统允许配置这个大小，但它们仍然是固定大小的，不能增长或缩小。毕竟，它们是栈溢出的原因，如果你将它们配置得太小，以适应你正在运行的任务，这将会成为一个问题。
- en: If we have many small tasks that only require a little stack space but we reserve
    much more than we need, we will occupy large amounts of memory and possibly run
    out of it.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们有很多只需要少量栈空间的小任务，但我们预留的比实际需要的多得多，我们将占用大量内存，并可能耗尽它。
- en: Context switching
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 上下文切换
- en: As you now know, threads and schedulers are tightly connected. Context switching
    happens when the CPU stops executing one thread and proceeds with another one.
    Even though this process is highly optimized, it still involves storing and restoring
    the register state, which takes time. Every time that you yield to the OS scheduler,
    it can choose to schedule a thread from a different process on that CPU.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所知，线程和调度器紧密相连。上下文切换发生在CPU停止执行一个线程并继续执行另一个线程时。尽管这个过程高度优化，但它仍然涉及到存储和恢复寄存器状态，这需要时间。每次你向操作系统调度器让步时，它可以选择在同一个CPU上调度来自不同进程的线程。
- en: You see, threads created by these systems belong to a **process**. When you
    start a program, it starts a process, and the process creates at least one initial
    thread where it executes the program you’ve written. Each process can spawn multiple
    threads that share the same **address space**.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 你看，这些系统创建的线程属于一个**进程**。当你启动一个程序时，它会启动一个进程，进程至少创建一个初始线程来执行你编写的程序。每个进程可以创建多个线程，这些线程共享相同的**地址空间**。
- en: That means that threads within the same process can access shared memory and
    can access the same resources, such as files and file handles. One consequence
    of this is that when the OS switches contexts by stopping one thread and resuming
    another within the same process, it doesn’t have to save and restore all the state
    associated with that process, just the state that’s specific to that thread.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着同一进程内的线程可以访问共享内存，并且可以访问相同的资源，例如文件和文件句柄。这一结果之一是，当操作系统通过停止同一进程中的一个线程并恢复另一个线程来切换上下文时，它不需要保存和恢复与该进程相关的所有状态，只需保存和恢复特定于该线程的状态。
- en: On the other hand, when the OS switches from a thread associated with one process
    to a thread associated with another, the new process will use a different address
    space, and the OS needs to take measures to make sure that process “A” doesn’t
    access data or resources that belong to process “B”. If it didn’t, the system
    wouldn’t be secure.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，当操作系统从一个与一个进程关联的线程切换到与另一个进程关联的线程时，新进程将使用不同的地址空间，操作系统需要采取措施确保进程“A”不会访问属于进程“B”的数据或资源。如果不是这样，系统将不会安全。
- en: The consequence is that caches might need to be flushed and more state might
    need to be saved and restored. In a highly concurrent system under load, these
    context switches can take extra time and thereby limit the throughput in a somewhat
    unpredictable manner if they happen frequently enough.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 结果是，可能需要刷新缓存，并且可能需要保存和恢复更多的状态。在高并发系统负载下，这些上下文切换可能会花费额外的时间，如果它们频繁发生，可能会以某种不可预测的方式限制吞吐量。
- en: Scheduling
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 调度
- en: The OS can schedule tasks differently than you might expect, and *every time
    you yield to the OS*, you’re put in the same queue as all other threads and processes
    on the system.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 操作系统可以以你意想不到的方式调度任务，并且每次你向操作系统让步时，你都会被放入与系统上所有其他线程和进程相同的队列中。
- en: Moreover, since there is no guarantee that the thread will resume execution
    on the same CPU core as it left off or that two tasks won’t run in parallel and
    try to access the same data, you need to synchronize data access to prevent data
    races and other pitfalls associated with multicore programming.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，由于无法保证线程将在离开时相同的CPU核心上恢复执行，或者两个任务不会并行运行并尝试访问相同的数据，因此你需要同步数据访问以防止数据竞争和其他与多核编程相关的陷阱。
- en: Rust as a language will help you prevent many of these pitfalls, but synchronizing
    data access will require extra work and add to the complexity of such programs.
    We often say that using OS threads to handle concurrency gives us parallelism
    for free, but it isn’t free in terms of added complexity and the need for proper
    data access synchronization.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: Rust作为一种语言将帮助你防止许多这些陷阱，但同步数据访问将需要额外的工作，并增加此类程序复杂性。我们经常说，使用操作系统线程处理并发给我们带来了免费的可并行性，但从增加的复杂性和需要适当的数据访问同步的角度来看，这并不是免费的。
- en: The advantage of decoupling asynchronous operations from OS threads
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将异步操作与操作系统线程解耦的优势
- en: Decoupling asynchronous operations from the concept of threads has a lot of
    benefits.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 将异步操作与线程概念解耦有很多好处。
- en: First of all, using OS threads as a means to handle concurrency requires us
    to use what essentially is an OS abstraction to represent our tasks.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，使用操作系统线程作为处理并发的手段要求我们使用本质上是一种操作系统抽象来表示我们的任务。
- en: Having a separate layer of abstraction to represent concurrent tasks gives us
    the freedom to choose how we want to handle concurrent operations. If we create
    an abstraction over concurrent operations such as a future in Rust, a promise
    in JavaScript, or a goroutine in GO, it is up to the runtime implementor to decide
    how these concurrent tasks are handled.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 拥有一个单独的抽象层来表示并发任务，这给了我们选择如何处理并发操作的自由。如果我们创建了一个表示并发操作（如Rust中的future、JavaScript中的promise或GO中的goroutine）的抽象，那么这些并发任务的处理方式将由运行时实现者来决定。
- en: A runtime could simply map each concurrent operation to an OS thread, they could
    use fibers/green threads or state machines to represent the tasks. The programmer
    that writes the asynchronous code will not necessarily have to change anything
    in their code if the underlying implementation changes. In theory, the same asynchronous
    code could be used to handle concurrent operations on a microcontroller without
    an OS if there’s just a runtime for it.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 运行时可以将每个并发操作映射到一个操作系统线程，它们可以使用纤程/绿色线程或状态机来表示任务。编写异步代码的程序员在底层实现发生变化时，不一定需要在他们的代码中进行任何更改。理论上，如果只是有一个运行时，相同的异步代码就可以用来处理没有操作系统的情况下在微控制器上的并发操作。
- en: 'To sum it up, using threads provided by the operating system to handle concurrency
    has the following advantages:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 总结一下，使用操作系统提供的线程来处理并发有以下优点：
- en: Simple to understand
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 容易理解
- en: Easy to use
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 易于使用
- en: Switching between tasks is reasonably fast
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在任务之间切换是相对快速的
- en: You get parallelism for free
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以免费获得并行性
- en: 'However, they also have a few drawbacks:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，它们也有一些缺点：
- en: OS-level threads come with a rather large stack. If you have many tasks waiting
    simultaneously (as you would in a web server under heavy load), you’ll run out
    of memory pretty fast.
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 操作系统级别的线程带有相当大的堆栈。如果你有多个任务同时等待（就像在重负载下的Web服务器中那样），你很快就会耗尽内存。
- en: Context switching can be costly and you might get an unpredictable performance
    since you let the OS do all the scheduling.
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 上下文切换可能会造成成本增加，并且由于你让操作系统进行所有调度，你可能会得到不可预测的性能。
- en: The OS has many things it needs to handle. It might not switch back to your
    thread as fast as you’d wish.
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 操作系统有许多需要处理的事情。它可能不会像你希望的那样快速切换回你的线程。
- en: It is tightly coupled to an OS abstraction. This might not be an option on some
    systems.
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它与操作系统抽象紧密耦合。在某些系统上，这可能不是一个选项。
- en: Example
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 示例
- en: 'Since we’ll not spend more time talking about OS threads in this book, we’ll
    go through a short example so you can see how they’re used:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们不会在这本书中花费更多时间讨论操作系统线程，我们将通过一个简短的示例来展示它们是如何使用的：
- en: ch02/aa-os-threads
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: ch02/aa-os-threads
- en: '[PRE0]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: In this example, we simply spawn several OS threads and put them to sleep. Sleeping
    is essentially the same as yielding to the OS scheduler with a request to be re-scheduled
    to run after a certain time has passed. To make sure our main thread doesn’t finish
    and exit (which will exit the process) before our children thread has had time
    to run we `join` them at the end of our `main` function.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们简单地创建了几个操作系统线程并将它们放入休眠状态。休眠本质上等同于向操作系统调度器让步，请求在经过一定时间后被重新调度运行。为了确保我们的主线程在子线程有时间运行之前不会完成并退出（这将退出进程），我们在`main`函数的末尾`join`它们。
- en: 'If we run the example, we’ll see how the operations occur in a different order
    based on how long we yielded each thread to the scheduler:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们运行示例，我们会看到操作顺序的不同是基于我们让每个线程向调度器让步时间的长短：
- en: '[PRE1]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: So, while using OS threads is great for a number of tasks, we also outlined
    a number of good reasons to look at alternatives by discussing their limitations
    and downsides. The first alternatives we’ll look at are what we call fibers and
    green threads.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，虽然使用操作系统线程对于许多任务来说很棒，但我们通过讨论它们的限制和缺点，也概述了查看替代方案的好理由。我们将首先查看的是我们称之为纤维和绿色线程的替代方案。
- en: Fibers and green threads
  id: totrans-90
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 纤维和绿色线程
- en: Note!
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 注意！
- en: This is an example of **M:N threading**. Many tasks can run concurrently on
    one OS thread. Fibers and green threads are often referred to as stackful coroutines.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个**M:N线程**的例子。许多任务可以在一个操作系统线程上并发运行。纤维和绿色线程通常被称为堆栈协程。
- en: The name “green threads” originally stems from an early implementation of an
    M:N threading model used in Java and has since been associated with different
    implementations of M:N threading. You will encounter different variations of this
    term, such as “green processes” (used in Erlang), which are different from the
    ones we discuss here. You’ll also see some that define green threads more broadly
    than we do here.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: “绿色线程”这个名字最初来源于Java中早期使用的M:N线程模型的一个实现，并且自那时起就与M:N线程的不同实现相关联。你将遇到这个术语的不同变体，例如“绿色进程”（在Erlang中使用），这与我们在这里讨论的不同。你也会看到一些定义绿色线程比我们在这里更广泛的例子。
- en: The way we define green threads in this book makes them synonymous with fibers,
    so both terms refer to the same thing going forward.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在这本书中，我们定义的绿色线程与纤维同义，因此这两个术语在以后都指同一件事。
- en: The implementation of fibers and green threads implies that there is a runtime
    with a scheduler that’s responsible for scheduling what task (M) gets time to
    run on the OS thread (N). There are many more tasks than there are OS threads,
    and such a system can run perfectly fine using only one OS thread. The latter
    case is often referred to as **M:1 threading**.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 纤维和绿色线程的实现意味着存在一个运行时和一个调度器，该调度器负责调度哪个任务（M）在操作系统线程（N）上运行。任务的数量远多于操作系统线程的数量，这样的系统仅使用一个操作系统线程就可以运行得很好。后者通常被称为**M:1线程**。
- en: Goroutines is an example of a specific implementation of stackfull coroutines,
    but it comes with slight nuances. The term “coroutine” usually implies that they’re
    cooperative in nature, but Goroutines can be pre-empted by the scheduler (at least
    since version 1.14), thereby landing them in somewhat of a grey area using the
    categories we present here.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: Goroutines 是堆栈满协程的特定实现的一个例子，但它有一些细微差别。术语“协程”通常意味着它们本质上是合作的，但 Goroutines 可以被调度器抢占（至少从版本
    1.14 开始），因此它们在我们提出的类别中处于某种灰色区域。
- en: Green threads and fibers use the same mechanisms as an OS, setting up a stack
    for each task, saving the CPU’s state, and jumping from one task(thread) to another
    by doing a context switch.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 绿色线程和纤维使用与操作系统相同的机制，为每个任务设置一个堆栈，保存 CPU 的状态，并通过上下文切换从一个任务（线程）跳转到另一个任务。
- en: We yield control to the scheduler (which is a central part of the runtime in
    such a system), which then continues running a different task.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将控制权交给调度器（在这样一个系统的运行时中，调度器是一个核心部分），然后它继续运行不同的任务。
- en: The state of execution is stored in each stack, so in such a solution, there
    would be no need for `async`, `await`, `Future`, or `Pin`. In many ways, green
    threads mimic how an operating system facilitates concurrency, and implementing
    them is a great learning experience.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 执行状态存储在每个堆栈中，因此在这种解决方案中，不需要 `async`、`await`、`Future` 或 `Pin`。在许多方面，绿色线程模仿了操作系统如何促进并发，实现它们是一个很好的学习经历。
- en: A runtime using fibers/green threads for concurrent tasks can have a high degree
    of flexibility. Tasks can, for example, be pre-empted and context switched at
    any time and at any point in their execution, so a long-running task that hogs
    the CPU could in theory be pre-empted by the runtime, acting as a safeguard from
    having tasks that end up blocking the whole system due to an edge-case or a programmer
    error.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 使用纤维/绿色线程进行并发任务运行的运行时可以具有高度的灵活性。例如，任务可以在任何时间、任何执行点被抢占和上下文切换，因此理论上，一个长时间运行的、占用
    CPU 的任务可以被运行时抢占，作为防止任务由于边缘情况或程序员错误而阻塞整个系统的安全措施。
- en: This gives the runtime scheduler almost the same capabilities as the OS scheduler,
    which is one of the biggest advantages of systems using fibers/green threads.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 这使得运行时调度器几乎具有与操作系统调度器相同的性能，这是使用纤维/绿色线程的系统最大的优点之一。
- en: 'The typical flow goes as follows:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 典型的流程如下：
- en: You run some non-blocking code
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你运行一些非阻塞代码
- en: You make a blocking call to some external resource
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你向某个外部资源发起一个阻塞调用
- en: The CPU jumps to the main thread, which schedules a different thread to run
    and jumps to that stack
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CPU 跳转到主线程，调度另一个线程运行，并跳转到那个堆栈
- en: You run some non-blocking code on the new thread until a new blocking call or
    the task is finished
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你在新线程上运行一些非阻塞代码，直到新的阻塞调用或任务完成
- en: The CPU jumps back to the main thread, schedules a new thread that is ready
    to make progress, and jumps to that thread
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CPU 跳回到主线程，调度一个准备好进行进度的新线程，并跳转到那个线程
- en: '![Figure 2.2 – Program flow using fibers/green threads](img/B20892_Figure_02.2.jpg)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.2 – 使用纤维/绿色线程的程序流程](img/B20892_Figure_02.2.jpg)'
- en: Figure 2.2 – Program flow using fibers/green threads
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.2 – 使用纤维/绿色线程的程序流程
- en: Each stack has a fixed space
  id: totrans-110
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 每个堆栈都有固定空间
- en: As fibers and green threads are similar to OS threads, they do have some of
    the same drawbacks as well. Each task is set up with a stack of a fixed size,
    so you still have to reserve more space than you actually use. However, these
    stacks can be growable, meaning that once the stack is full, the runtime can grow
    the stack. While this sounds easy, it’s a rather complicated problem to solve.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 由于纤维和绿色线程类似于操作系统线程，它们确实有一些相同的缺点。每个任务都设置了一个固定大小的堆栈，所以你仍然需要预留比你实际使用的更多空间。然而，这些堆栈可以是可增长的，这意味着一旦堆栈满了，运行时可以增长堆栈。虽然这听起来很简单，但解决这个问题相当复杂。
- en: 'We can’t simply grow a stack as we grow a tree. What actually needs to happen
    is one of two things:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不能像生长一棵树那样简单地生长一个堆栈。实际上需要发生的是以下两种情况之一：
- en: You allocate a new piece of continuous memory and handle the fact that your
    stack is spread over two disjointed memory segments
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你分配一块新的连续内存，并处理你的堆栈分布在两个不连续内存段的事实
- en: You allocate a new larger stack (for example, twice the size of the previous
    stack), move all your data over to the new stack, and continue from there
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你分配一个新的更大的堆栈（例如，是之前堆栈的两倍大小），将所有数据移动到新的堆栈上，并从这里继续
- en: The first solution sounds pretty simple, as you can leave the original stack
    as it is, and you can basically context switch over to the new stack when needed
    and continue from there. However, modern CPUs can work extremely fast if they
    can work on a contiguous piece of memory due to caching and their ability to predict
    what data your next instructions are going to work on. Spreading the stack over
    two disjointed pieces of memory will hinder performance. This is especially noticeable
    when you have a loop that happens to be just at the stack boundary, so you end
    up making up to two context switches for each iteration of the loop.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个解决方案听起来相当简单，因为你可以将原始栈保持原样，并在需要时基本切换到新栈，并从那里继续。然而，由于缓存和它们预测你接下来要处理的数据的能力，现代CPU可以在连续的内存块上工作得非常快。将栈分散到两块不连续的内存中将会阻碍性能。这在你有一个恰好位于栈边界处的循环时尤为明显，因此你可能会为循环的每次迭代进行多达两次的上下文切换。
- en: The second solution solves the problems with the first solution by having the
    stack as a contiguous piece of memory, but it comes with some problems as well.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个解决方案通过将栈作为连续的内存块来解决第一个解决方案的问题，但它也带来了一些问题。
- en: 'First, you need to allocate a new stack and move all the data over to the new
    stack. But what happens with all pointers and references that point to something
    located on the stack when everything moves to a new location? You guessed it:
    every pointer and reference to anything located on the stack needs to be updated
    so they point to the new location. This is complex and time-consuming, but if
    your runtime already includes a garbage collector, you already have the overhead
    of keeping track of all your pointers and references anyway, so it might be less
    of a problem than it would for a non-garbage collected program. However, it does
    require a great deal of integration between the garbage collector and the runtime
    to do this every time the stack grows, so implementing this kind of runtime can
    get very complicated.'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，你需要分配一个新的栈并将所有数据移动到新栈上。但是，当一切移动到新位置时，所有指向栈上位置的指针和引用怎么办？你已经猜到了：指向栈上任何内容的指针和引用都需要更新，以便它们指向新位置。这是复杂且耗时的，但如果你的运行时已经包括垃圾回收器，你已经在跟踪所有指针和引用方面有了开销，所以这可能比非垃圾回收程序的问题要小。然而，它确实需要在垃圾回收器和运行时之间进行大量的集成，以便每次栈增长时都执行此操作，因此实现这种运行时可能会变得非常复杂。
- en: Secondly, you have to consider what happens if you have a lot of long-running
    tasks that only require a lot of stack space for a brief period of time (for example,
    if it involves a lot of recursion at the start of the task) but are mostly I/O
    bound the rest of the time. You end up growing your stack many times over only
    for one specific part of that task, and you have to make a decision whether you
    will accept that the task occupies more space than it needs or at some point move
    it back to a smaller stack. The impact this will have on your program will of
    course vary greatly based on the type of work you do, but it’s still something
    to be aware of.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，你必须考虑如果你有很多长时间运行的任务，这些任务在短时间内只需要大量的栈空间（例如，如果任务开始时涉及大量的递归）但大部分时间都是I/O密集型的情况。你最终会只为任务的一个特定部分增长栈多次，你必须决定你是否会接受任务占用比它需要的更多空间，或者在某些时候将其移回较小的栈。这种影响当然会根据你所做的工作类型而有很大差异，但这仍然是一件需要注意的事情。
- en: Context switching
  id: totrans-119
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 上下文切换
- en: Even though these fibers/green threads are lightweight compared to OS threads,
    you still have to save and restore registers at every context switch. This likely
    won’t be a problem most of the time, but when compared to alternatives that don’t
    require context switching, it can be less efficient.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 即使这些纤程/绿色线程与操作系统线程相比很轻量级，你仍然需要在每次上下文切换时保存和恢复寄存器。这很可能不会成为问题，但与不需要上下文切换的替代方案相比，它可能效率较低。
- en: Context switching can also be pretty complex to get right, especially if you
    intend to support many different platforms.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 上下文切换也可能非常复杂，特别是如果你打算支持许多不同的平台。
- en: Scheduling
  id: totrans-122
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 调度
- en: When a fiber/green thread yields to the runtime scheduler, the scheduler can
    simply resume execution on a new task that’s ready to run. This means that you
    avoid the problem of being put in the same run queue as every other task in the
    system every time you yield to the scheduler. From the OS perspective, your threads
    are busy doing work all the time, so it will try to avoid pre-empting them if
    it can.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 当一个纤维/绿色线程向运行时调度器让步时，调度器可以简单地在新任务上恢复执行。这意味着每次你向调度器让步时，你都不会被放入与系统中每个其他任务相同的运行队列。从操作系统的角度来看，你的线程一直在忙于工作，所以如果可能，它会尽量避免抢占它们。
- en: One unexpected downside of this is that most OS schedulers make sure all threads
    get some time to run by giving each OS thread a time slice where it can run before
    the OS pre-empts the thread and schedules a new thread on that CPU. A program
    using many OS threads might be allotted more time slices than a program with fewer
    OS threads. A program using M:N threading will most likely only use a few OS threads
    (one thread per CPU core seems to be the starting point on most systems). So,
    depending on whatever else is running on the system, your program might be allotted
    fewer time slices in total than it would be using many OS threads. However, with
    the number of cores available on most modern CPUs and the typical workload on
    concurrent systems, the impact from this should be minimal.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 这个方法的一个意想不到的缺点是，大多数操作系统调度器确保所有线程都能得到一些运行时间，通过为每个操作系统线程分配一个时间片，在该时间片内它可以运行，然后操作系统抢占线程并在此CPU上调度新的线程。使用许多操作系统线程的程序可能会被分配比使用较少操作系统线程的程序更多的时片。使用M:N线程的程序很可能只会使用少数操作系统线程（在大多数系统上，每个CPU核心似乎是一个起点）。因此，根据系统上运行的其他内容，你的程序可能总共被分配的时片比使用许多操作系统线程时更少。然而，考虑到大多数现代CPU上可用的核心数量和并发系统的典型工作负载，这种影响应该是微不足道的。
- en: FFI
  id: totrans-125
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: FFI
- en: Since you create your own stacks that are supposed to grow/shrink under certain
    conditions and might have a scheduler that assumes it can pre-empt running tasks
    at any point, you will have to take extra measures when you use FFI. Most FFI
    functions will assume a normal OS-provided C-stack, so it will most likely be
    problematic to call an FFI function from a fiber/green thread. You need to notify
    the runtime scheduler, context switch to a different OS thread, and have some
    way of notifying the scheduler that you’re done and the fiber/green thread can
    continue. This naturally creates overhead and added complexity both for the runtime
    implementor and the user making the FFI call.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 由于你创建了自己的栈，这些栈在特定条件下会增长/缩小，并且可能有一个假设可以在任何时间抢占运行中的任务的调度器，因此在使用FFI时，你必须采取额外措施。大多数FFI函数将假设一个正常的操作系统提供的C栈，因此从纤维/绿色线程调用FFI函数可能会出现问题。你需要通知运行时调度器，切换到不同的操作系统线程，并有一种方式通知调度器你已经完成，纤维/绿色线程可以继续。这自然为运行时实现者和进行FFI调用的用户都增加了开销和复杂性。
- en: Advantages
  id: totrans-127
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 优点
- en: It is simple to use for the user. The code will look like it does when using
    OS threads.
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于用户来说，使用起来很简单。代码看起来就像使用操作系统线程时一样。
- en: Context switching is reasonably fast.
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 上下文切换相对较快。
- en: Abundant memory usage is less of a problem when compared to OS threads.
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与操作系统线程相比，内存使用量过多的问题较小。
- en: You are in full control over how tasks are scheduled and if you want you can
    prioritize them as you see fit.
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以完全控制任务的调度方式，如果你愿意，可以根据自己的需求优先级排序。
- en: It’s easy to incorporate pre-emption, which can be a powerful feature.
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 很容易整合抢占，这可以是一个强大的特性。
- en: Drawbacks
  id: totrans-133
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 缺点
- en: Stacks need a way to grow when they run out of space creating additional work
    and complexity
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 栈需要在空间不足时有一种增长的方式，这会创建额外的工作和复杂性。
- en: You still need to save the CPU state on every context switch
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你仍然需要在每次上下文切换时保存CPU状态。
- en: It’s complicated to implement correctly if you intend to support many platforms
    and/or CPU architectures
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你打算支持许多平台和/或CPU架构，正确实现会比较复杂。
- en: FFI can have a lot of overhead and add unexpected complexity
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: FFI可能会有很多开销并增加意外的复杂性。
- en: Callback based approaches
  id: totrans-138
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于回调的方法
- en: Note!
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 注意！
- en: This is another example of M:N threading. Many tasks can run concurrently on
    one OS thread. Each task consists of a chain of callbacks.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 这是M:N线程的另一个例子。许多任务可以在一个操作系统线程上并发运行。每个任务由一系列回调组成。
- en: You probably already know what we’re going to talk about in the next paragraphs
    from JavaScript, which I assume most know.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能已经知道接下来几段将要讨论的内容，这来自于JavaScript，我假设大多数人知道。
- en: The whole idea behind a callback-based approach is to save a pointer to a set
    of instructions we want to run later together with whatever state is needed. In
    Rust, this would be a closure.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 基于回调的方法背后的整个想法是保存一组我们想要稍后一起运行的指令的指针，以及所需的任何状态。在Rust中，这将是一个闭包。
- en: Implementing callbacks is relatively easy in most languages. They don’t require
    any context switching or pre-allocated memory for each task.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 在大多数语言中实现回调相对容易。它们不需要为每个任务进行上下文切换或预分配内存。
- en: However, representing concurrent operations using callbacks requires you to
    write the program in a radically different way from the start. Re-writing a program
    that uses a normal sequential program flow to one using callbacks represents a
    substantial rewrite, and the same goes the other way.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，使用回调表示并发操作需要你从开始就以一种截然不同的方式编写程序。将使用正常顺序程序流的程序重写为使用回调的程序，这代表了一次重大的重写，反之亦然。
- en: Callback-based concurrency can be hard to reason about and can become very complicated
    to understand. It’s no coincidence that the term “callback hell” is something
    most JavaScript developers are familiar with.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 基于回调的并发可能很难理解，也可能变得非常复杂。因此，“回调地狱”这个术语是大多数JavaScript开发者都熟悉的一点，这并非巧合。
- en: Since each sub-task must save all the state it needs for later, the memory usage
    will grow linearly with the number of callbacks in a task.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 由于每个子任务必须保存它稍后需要的所有状态，内存使用量将与任务中回调的数量线性增长。
- en: Advantages
  id: totrans-147
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 优点
- en: Easy to implement in most languages
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在大多数语言中易于实现
- en: No context switching
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 没有上下文切换
- en: Relatively low memory overhead (in most cases)
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 相对较低的内存开销（在大多数情况下）
- en: Drawbacks
  id: totrans-151
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 缺点
- en: Memory usage grows linearly with the number of callbacks.
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内存使用量与回调的数量线性增长。
- en: Programs and code can be hard to reason about.
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 程序和代码可能很难理解。
- en: It’s a very different way of writing programs and it will affect almost all
    aspects of the program since all yielding operations require one callback.
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这是一种完全不同的编写程序的方式，它将影响程序的几乎所有方面，因为所有让步操作都需要一个回调。
- en: Ownership can be hard to reason about. The consequence is that writing callback-based
    programs without a garbage collector can become very difficult.
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所有权可能很难理解。结果是，在没有垃圾收集器的情况下编写基于回调的程序可能变得非常困难。
- en: Sharing state between tasks is difficult due to the complexity of ownership
    rules.
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于所有权规则的复杂性，任务之间的状态共享很困难。
- en: Debugging callbacks can be difficult.
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调试回调可能很困难。
- en: 'Coroutines: promises and futures'
  id: totrans-158
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 协程：承诺和未来
- en: Note!
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 注意！
- en: This is another example of M:N threading. Many tasks can run concurrently on
    one OS thread. Each task is represented as a state machine.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 这又是M:N线程的一个例子。许多任务可以在一个操作系统线程上并发运行。每个任务都表示为一个状态机。
- en: '**Promises** in JavaScript and **futures** in Rust are two different implementations
    that are based on the same idea.'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '**JavaScript中的承诺**和**Rust中的未来**是基于相同理念的不同实现。'
- en: There are differences between different implementations, but we’ll not focus
    on those here. It’s worth explaining promises a bit since they’re widely known
    due to their use in JavaScript. Promises also have a lot in common with Rust’s
    futures.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 不同的实现之间有一些差异，但在这里我们不会关注这些。由于它们在JavaScript中的使用而广为人知，解释承诺是值得的。承诺也与Rust的future有很多共同之处。
- en: First of all, many languages have a concept of promises, but I’ll use the one
    from JavaScript in the following examples.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，许多语言都有一个承诺的概念，但以下示例中我将使用JavaScript中的承诺。
- en: Promises are one way to deal with the complexity that comes with a callback-based
    approach.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 承诺是处理基于回调方法带来的复杂性的一个方法。
- en: 'Instead of:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 而不是：
- en: '[PRE2]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'We can do:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以这样做：
- en: '[PRE3]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The latter approach is also referred to as **the continuation-passing style**.
    Each subtask calls a new one once it’s finished.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 后者方法也被称为**延续传递风格**。每个子任务一旦完成就调用一个新的子任务。
- en: 'The difference between callbacks and promises is even more substantial under
    the hood. You see, promises return a state machine that can be in one of three
    states: `pending`, `fulfilled`, or `rejected`.'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 回调和承诺之间的区别在底层更为显著。你看，承诺返回一个可以处于三种状态之一的状态机：`pending`、`fulfilled`或`rejected`。
- en: When we call `timer(200)` in the previous example, we get back a promise in
    the `pending` state.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们在前面的例子中调用`timer(200)`时，我们得到一个处于`pending`状态的承诺。
- en: Now, the continuation-passing style does fix some of the issues related to callbacks,
    but it still retains a lot of them when it comes to complexity and the different
    ways of writing programs. However, they enable us to leverage the compiler to
    solve a lot of these problems, which we’ll discuss in the next paragraph.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，传递风格的确解决了与回调相关的一些问题，但在复杂性和编写程序的不同方式方面，它仍然保留了很多。然而，它们使我们能够利用编译器来解决这些问题，我们将在下一段中讨论。
- en: Coroutines and async/await
  id: totrans-173
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 协程和async/await
- en: 'Coroutines come in two flavors: **asymmetric** and **symmetric**. Asymmetric
    coroutines yields to a scheduler, and they’re the ones we’ll focus on. Symmetric
    coroutines yield a specific destination; for example, a different coroutine.'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 协程有两种类型：**非对称**和**对称**。非对称协程将控制权交给调度器，我们将关注这些。对称协程将控制权交给特定的目的地；例如，另一个协程。
- en: While coroutines are a pretty broad concept in general, the introduction of
    coroutines as `objects` in programming languages is what really makes this way
    of handling concurrency rival the ease of use that OS threads and fibers/green
    threads are known for.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然协程在一般情况下是一个相当广泛的概念，但将协程作为编程语言中的`对象`引入，才是真正使这种处理并发的方式与操作系统线程和纤程/绿色线程所知的易于使用性相媲美的原因。
- en: You see when you write `async` in Rust or JavaScript, the compiler re-writes
    what looks like a normal function call into a future (in the case of Rust) or
    a promise (in the case of JavaScript). **Await**, on the other hand, yields control
    to the runtime scheduler, and the task is suspended until the future/promise you’re
    awaiting has finished.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 当你在Rust或JavaScript中写入`async`时，编译器会将看起来像正常函数调用的代码重写为未来（在Rust的情况下）或承诺（在JavaScript的情况下）。另一方面，**await**将控制权交给运行时调度器，任务将在你等待的未来/承诺完成之前挂起。
- en: This way, we can write programs that handle concurrent operations in almost
    the same way we write our normal sequential programs.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 这样，我们可以编写几乎以与编写正常顺序程序相同的方式处理并发操作的程序。
- en: 'Our JavaScript program can now be written as follows:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以将JavaScript程序编写如下：
- en: '[PRE4]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: You can consider the `run` function as a pausable task consisting of several
    sub-tasks. On each “await” point, it yields control to the scheduler (in this
    case, it’s the well-known JavaScript event loop).
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以将`run`函数视为一个由多个子任务组成的可暂停任务。在每个“await”点上，它将控制权交给调度器（在这种情况下，它是众所周知的JavaScript事件循环）。
- en: Once one of the sub-tasks changes state to either `fulfilled` or `rejected`,
    the task is scheduled to continue to the next step.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦子任务的状态变为`fulfilled`或`rejected`之一，任务将被安排继续到下一步。
- en: 'When using Rust, you can see the same transformation happening with the function
    signature when you write something such as this:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用Rust时，当你写下类似以下内容时，你可以看到函数签名发生了相同的转换：
- en: '[PRE5]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The function wraps the return object, and instead of returning the type `()`,
    it returns a `Future` with an output type of `()`:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 该函数包装了返回对象，而不是返回类型`()`，而是返回一个输出类型为`()`的`Future`：
- en: '[PRE6]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Syntactically, Rust’s futures 0.1 was a lot like the promise example we just
    showed, and the Rust futures we use today have a lot in common with how `async`/`await`
    works in JavaScript..
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 语法上，Rust的futures 0.1与我们所展示的承诺示例非常相似，我们今天使用的Rust futures与JavaScript中的`async`/`await`的工作方式有很多共同之处。
- en: This way of rewriting what look like normal functions and code into something
    else has a lot of benefits, but it’s not without its drawbacks.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 这种将看起来像正常函数和代码重写为其他方式的方法有很多好处，但并非没有缺点。
- en: As with any stackless coroutine implementation, full pre-emption can be hard,
    or impossible, to implement. These functions have to yield at specific points,
    and there is no way to suspend execution in the middle of a stack frame in contrast
    to fibers/green threads. Some level of pre-emption is possible by having the runtime
    or compiler insert pre-emption points at every function call, for example, but
    it’s not the same as being able to pre-empt a task at any point during its execution.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 就像任何无栈协程实现一样，完全预占可能很难实现，或者根本不可能实现。这些函数必须在特定点让出，与纤程/绿色线程不同，在栈帧的中间无法挂起执行。通过在每次函数调用处插入预占点，例如，运行时或编译器可以实现一定程度的预占，但这并不等同于能够在执行过程中任何时刻预占任务。
- en: Pre-emption points
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 预占点
- en: Pre-emption points can be thought of as inserting code that calls into the scheduler
    and asks it if it wishes to pre-empt the task. These points can be inserted by
    the compiler or the library you use before every new function call for example.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 预先中断点可以被视为插入调用调度器的代码，并询问它是否希望中断任务。这些点可以通过编译器或你使用的库在每次新的函数调用之前插入，例如。
- en: Furthermore, you need compiler support to make the most out of it. Languages
    that have metaprogramming abilities (such as macros) can emulate much of the same,
    but this will still not be as seamless as it will when the compiler is aware of
    these special async tasks.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，你需要编译器的支持来充分利用它。具有元编程能力（如宏）的语言可以模拟很多相同的功能，但这仍然不会像编译器知道这些特殊异步任务时那样无缝。
- en: Debugging is another area where care must be taken when implementing futures/promises.
    Since the code is re-written as state machines (or generators), you won’t have
    the same stack traces as you do with normal functions. Usually, you can assume
    that the caller of a function is what precedes it both in the stack and in the
    program flow. For futures and promises, it might be the runtime that calls the
    function that progresses the state machine, so there might not be a good backtrace
    you can use to see what happened before calling the function that failed. There
    are ways to work around this, but most of them will incur some overhead.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 调试是另一个在实现未来/承诺时必须小心处理的问题领域。由于代码被重写为状态机（或生成器），你将不会像在正常函数中那样拥有相同的堆栈跟踪。通常，你可以假设函数的调用者既在堆栈中也在程序流程中先于它。对于未来和承诺，可能是运行时调用函数来推进状态机，因此可能没有好的回溯可以用来查看在调用失败的函数之前发生了什么。有方法可以绕过这个问题，但大多数方法都会带来一些开销。
- en: Advantages
  id: totrans-193
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 优点
- en: You can write code and model programs the same way you normally would
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以像平时一样编写代码和模拟程序
- en: No context switching
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 没有上下文切换
- en: It can be implemented in a very memory-efficient way
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它可以以非常内存高效的方式实现
- en: It’s easy to implement for various platforms
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它很容易在各种平台上实现
- en: Drawbacks
  id: totrans-198
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 缺点
- en: Pre-emption can be hard, or impossible, to fully implement, as the tasks can’t
    be stopped in the middle of a stack frame
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预先中断可能很难或不可能完全实现，因为任务不能在堆栈帧的中间停止
- en: It needs compiler support to leverage its full advantages
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它需要编译器的支持来发挥其全部优势
- en: Debugging can be difficult both due to the non-sequential program flow and the
    limitations on the information you get from the backtraces.
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调试可能很困难，这既是因为程序的流程非顺序性，也是因为从回溯中获取的信息有限。
- en: Summary
  id: totrans-202
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: You’re still here? That’s excellent! Good job on getting through all that background
    information. I know going through text that describes abstractions and code can
    be pretty daunting, but I hope you see why it’s so valuable for us to go through
    these higher-level topics now at the start of the book. We’ll get to the examples
    soon. I promise!
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 你还在这里吗？这太棒了！你做得很好，已经通过了所有这些背景信息。我知道阅读描述抽象和代码的文本可能相当令人畏惧，但我希望你能看到为什么我们现在在书的开始部分研究这些高级主题是如此有价值。我们很快就会看到例子。我保证！
- en: In this chapter, we went through a lot of information on how we can model and
    handle asynchronous operations in programming languages by using both OS-provided
    threads and abstractions provided by a programming language or a library. While
    it’s not an extensive list, we covered some of the most popular and widely used
    technologies while discussing their advantages and drawbacks.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们讨论了如何通过使用操作系统提供的线程和编程语言或库提供的抽象来模拟和处理编程语言中的异步操作。虽然这不是一个详尽的列表，但我们讨论了一些最流行和广泛使用的技术，同时讨论了它们的优缺点。
- en: We spent quite some time going in-depth on threads, coroutines, fibers, green
    threads, and callbacks, so you should have a pretty good idea of what they are
    and how they’re different from each other.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 我们花了很多时间深入探讨了线程、协程、纤程、绿色线程和回调，所以你应该对它们是什么以及它们之间有何不同有一个相当好的了解。
- en: The next chapter will go into detail about how we do system calls and create
    cross-platform abstractions and what OS-backed event queues such as Epoll, Kqueue,
    and IOCP really are and why they’re fundamental to most async runtimes you’ll
    encounter out in the wild.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 下一章将详细介绍我们如何进行系统调用和创建跨平台抽象，以及像Epoll、Kqueue和IOCP这样的操作系统支持的事件队列究竟是什么，以及为什么它们对于你将在野外遇到的几乎所有异步运行时都是基本的。
