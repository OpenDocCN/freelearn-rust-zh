- en: Exploring Maps and Sets
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Up until this chapter, data structures have only become faster for searching,
    and this chapter is no different. What makes it different is why and how data
    can be found in two higher-level data structures: maps and sets. While the former
    is also known as dictionary, associative array, object, or hash table, the latter
    commonly crosses people''s minds as a mathematical concept. Both can rely on hashing,
    a technique that allows for constant (or close to constant) time retrieval of
    items, checking whether they are contained in a set, or routing requests in distributed
    hash tables.'
  prefs: []
  type: TYPE_NORMAL
- en: 'These data structures are also one level higher than the previous ones, since
    all of them build on existing structures, such as dynamic arrays or trees, and
    to top things off, the chapter starts with an algorithm. Understanding this chapter
    will be great preparation heading into the second part of the book, where algorithms
    are the main focus. Topics learned in this chapter include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Hashing functions and what they are good for
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to implement a set based on different data structures
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What makes maps special
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hashing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The birthday paradox is a well-known phenomenon; two people share this special
    day that year, seemingly often, and we still get excited when it happens. Statistically
    speaking, the probability of meeting someone like this is really high, since in
    a room of just 23 people, the probability is already at 50%. While this may be
    an interesting fact, why is this introducing a section about hashing?
  prefs: []
  type: TYPE_NORMAL
- en: 'Birthdays can be considered a hash function—although a bad one. Hash functions
    are functions that map one value onto another value of a fixed size, like combining
    the day and month of a birthday into `u64`, shown as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'This function will prove very ineffective indeed, shown as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: It is very hard to find out someone's birthday deterministically without asking
    them
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The space is limited to 366 unique values, which also makes collisions very
    likely
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: They are not evenly distributed across the year
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'What makes a good hash function? It depends on the use case. There are many
    properties that can be associated with a hash function, such as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: One way or two way (that is, given a hash, can one get the original value back?)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deterministic
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Uniform
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fixed or variable range
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Designing good hash functions is a *very* hard task in any field; there are
    countless algorithms that have been shown to be too weak for their designed purpose
    after several years of use, with SHA-1 being the latest prominent victim.
  prefs: []
  type: TYPE_NORMAL
- en: There is a wide variety of hashing algorithms for all kinds of use cases available,
    ranging from cryptographically secure to something akin to a parity bit to mitigate
    tampering. This section will focus on a few areas that we deemed interesting;
    for a wider picture, Wikipedia ([https://en.wikipedia.org/wiki/List_of_hash_functions](https://en.wikipedia.org/wiki/List_of_hash_functions))
    provides a list that shows a number of available hashing algorithms and their
    articles.
  prefs: []
  type: TYPE_NORMAL
- en: '**Signatures** are one of the most important fields for hashing algorithms
    and they can be as simple as the last digit on a credit card number (to validate
    the number) to 512-bit strong cryptographic digest functions, where a single collision
    is the end of that particular algorithm.'
  prefs: []
  type: TYPE_NORMAL
- en: Outside of cryptography, hashing is used in completely different areas as well,
    such as peer-to-peer routing or encoding information in a tree-like structure.
    **GeoHashes** are a great example; instead of comparing longitude and latitude,
    these GeoHashes allow to quickly check if an area is located close to (or within)
    another area by comparing the first few characters of the hash. The algorithm
    was put into the public domain and can be found under [http://geohash.org/](http://geohash.org/).
    Collisions in this space can be ruled out since the entire space of possible input
    variations (coordinates on planet Earth) is known beforehand.
  prefs: []
  type: TYPE_NORMAL
- en: What are **collisions**? A collision occurs when two different input parameters
    lead to the same output, making the hash ambiguous. In cryptography, this fact
    will lead to a large scale crisis, just like it would if you found another key
    that matches your door lock. The main difference being that in the physical world,
    trying every door in your neighborhood is highly impractical, but with fully connected
    computers, this can be done in a matter of seconds. This means that the potential
    inputs are just as important as the quality of the hashing function itself—be
    it time and practicality (like physical items), or the applicable range (Earth
    coordinates, maximum number of nodes in a cluster)—transferring a function to
    a domain with a larger range leads to unexpected outcomes.
  prefs: []
  type: TYPE_NORMAL
- en: To summarize, collisions appear when the potential space of a key is either
    not large enough to withstand a full enumeration (brute force), or the outputs
    of the hash function are unevenly distributed.
  prefs: []
  type: TYPE_NORMAL
- en: Create your own
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For the purpose of representing an object as a number (for use in a hash map
    or for comparison), most languages' built-in types come with a solid hash function
    for exactly that purpose, so building your own is almost never a good idea, unless
    a lot of time and effort goes into it. The better choice is to use what's built-in,
    or use a library that provides tested and proven methods.
  prefs: []
  type: TYPE_NORMAL
- en: 'It is important though to know how those functions are built, so let''s create
    a trivial implementation to analyze the basic principles. The following example
    is one that uses the XOR operation on the previous and current byte to save their
    binary differences, then shifts it to the left up to four times (to fill up the
    `u32` type):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'When this function is applied to a range of repeated letter strings, how are
    the values distributed? A histogram and a scatter plot tell the story, shown as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9a669b5e-197c-458e-a30f-6af514eaca50.png)'
  prefs: []
  type: TYPE_IMG
- en: The output chart of the XOR Hasher
  prefs: []
  type: TYPE_NORMAL
- en: This histogram shows the distribution of the hash output, when the function
    is applied to all combinations of ten `AA`-`ZZ`, but each letter repeated ten
    times, so the first string is `AAAAAAAAAAAAAAAAAAAA` (20 letters), the last string
    is `ZZZZZZZZZZZZZZZZZZZZ`, yielding 675 combinations of 20 letter "words." This
    leads to a less optimal distribution, where the highest frequency is five times
    as high as the lowest. While speed can be a factor in using that function, it
    will clearly produce suboptimal results for cryptography.
  prefs: []
  type: TYPE_NORMAL
- en: 'In a scatter plot, this looks like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2d6b5bb2-22e5-4a17-bfbd-70218b754f4c.png)'
  prefs: []
  type: TYPE_IMG
- en: The output graph of the scatter plot
  prefs: []
  type: TYPE_NORMAL
- en: The scatter plot shows a different story. On the *x* axis, the index of each
    combination is shown, the *y* axis shows the hash output. Therefore, horizontal
    lines mean collisions, and they are all over the place! It can be interesting
    to explore further properties of a function like this, but the first results look
    quite dire, and searching for a better algorithm is the best use of anyone's time.
    Let's move on to checksums and digests.
  prefs: []
  type: TYPE_NORMAL
- en: Message digestion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Message digests are created as a way to guarantee authenticity; if a message
    was sent, a digest or signature of this message provides an ability to check whether
    the message has been tampered with. Typically, the signature will therefore be
    transmitted differently than the original message.
  prefs: []
  type: TYPE_NORMAL
- en: 'Obviously, this requires the hashing function to adhere to some basic rules
    to be considered good, listed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: A signature has to be quick and easy to obtain regardless of message size
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The signature can only have a fixed length
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The function has to minimize collisions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The hash functions contained in this group are the most popular ones and are
    the objective of many security researchers: MD5, SHA-1/2/3, or Adler 32\. Adler
    32 is prominently used in the `zlib` library to ensure the file''s integrity,
    but should not be used to authenticate messages, thanks to the limited output
    space of 32-bit. However, it is easy to implement and understand, which makes
    it great for the purposes of this book:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The algorithm sums up the bytes of any byte stream, and avoids an overflow by
    applying the modulo operation, using a large prime number (`65521`), which makes
    it harder for a byte to change without changing the final result. The algorithm
    has considerable weaknesses since there are many ways to change the operands of
    a sum without affecting the outcome!
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, rolling over (after the modulo is applied) gives some weight to
    the order of bytes, so if the sum of bytes is not large enough, the algorithm
    is expected to produce even more collisions. Generally, this algorithm primarily
    protects against random transmission errors that cause bits to change, and is
    not useful in authenticating messages.
  prefs: []
  type: TYPE_NORMAL
- en: Wrap up
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Hashing is a very useful tool that developers use every day—knowingly or unknowingly.
    Integer comparisons are fast, so checking the equality of two strings can be improved
    by comparing their hashes. Diverse keys can be made comparable by hashing—a method
    that is used in distributed databases to assign a partition to a row.
  prefs: []
  type: TYPE_NORMAL
- en: '**Modulo hashing** is a technique that lets a distributed database assign a
    row to a partition deterministically. Hash the row''s key, then use the modulo
    operator with the maximum number of partitions to receive a destination to store
    the row.'
  prefs: []
  type: TYPE_NORMAL
- en: Earlier, we explored some hash functions (XOR-based and Adler 32), but we never
    compared them. Additionally, Rust's standard library offers a hash function (built
    for `HashSet<K,V>`/`HashMap<K,V>`, and implemented for all standard types), which
    is a good baseline.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, histograms—to show how many occurrences each hash has. As mentioned
    before, the XOR-based approach yields a very strange distribution, where some
    hashes clearly appear more often than others, shown as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7cc10d71-afea-442e-abe4-05f40b742a5e.png)'
  prefs: []
  type: TYPE_IMG
- en: The output chart of the XOR Hasher
  prefs: []
  type: TYPE_NORMAL
- en: 'The Adler checksum creates a normal distribution in this case, which is probably
    due to the repetitive content, and the commutative nature of summing up numbers
    (*2 + 1 = 1 + 2*). Considering that transmission errors in compressed files are
    probably creating repetition, it looks like a solid choice for that use case.
    It would not do well in most other scenarios though:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ffeb7cb5-8ac8-4035-ba7f-0fab812a6107.png)'
  prefs: []
  type: TYPE_IMG
- en: The output chart of Adler 32
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is Rust''s default choice, the `SipHash` based `DefaultHasher`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6c686356-d22a-4834-ade0-4582e766951f.png)'
  prefs: []
  type: TYPE_IMG
- en: The output chart of the Rust DefaultHasher
  prefs: []
  type: TYPE_NORMAL
- en: Seeing the three distributions, their use in a hash table, where the frequency
    directly translates to the length of the lists at each bucket, becomes obvious.
    While it's best to have a length of one, lists of the same length at least yield
    the best performance if there is *any* collision. The Rust standard library clearly
    made a great choice with the `SipHash` based ([https://link.springer.com/chapter/10.1007/978-3-642-34931-7_28](https://link.springer.com/chapter/10.1007/978-3-642-34931-7_28))
    implementation.
  prefs: []
  type: TYPE_NORMAL
- en: 'A comparative scatter plot also sheds some light on the behavior of hash functions.
    Be aware that it is log-scaled to fit the results into a manageable plot, shown
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/26552fa7-52f4-4792-99dd-273042acc591.png)'
  prefs: []
  type: TYPE_IMG
- en: The comparison plot for XOR, Adler 32, and DefaultHasher
  prefs: []
  type: TYPE_NORMAL
- en: While the scale does not allow for a detailed judgment, what appears to be a
    line is always a collision-heavy behavior. As expected from the histograms, the
    Adler 32 and XOR-based approach both do not show a cloud. Since the *y* axis shows
    the actual hash (log-scaled), the more vertically spread it is, the better the
    distribution. Ideally, there would be a unique hash for each *x* value, but roughly
    the same number of dots for each *y* value predict a uniform hash function. Again,
    Rust's `DefaultHasher` looks very good in this plot, while both contenders show
    less optimal behaviors when used in similar cases.
  prefs: []
  type: TYPE_NORMAL
- en: 'A word of caution in the end. This is a software developer''s perspective on
    hashing: security researchers and professionals know *a lot* more about hashing.
    It should be left to them to come up with new ways to create message signatures,
    so we can focus on building great software and use the best possible components
    to do that. In short: *do not build your own hash function for any production
    system.*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, for some practical application of hashing in a data structure: the map.'
  prefs: []
  type: TYPE_NORMAL
- en: Maps
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Index operations in arrays are fast, simple, and easy to understand, with one
    drawback: they only work with integers. Since an **array** is a continuous portion
    in memory that can be accessed by dividing it evenly, which makes the jumps between
    the elements easy, can this work with arbitrary keys as well? Yes! Enter maps.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Maps** (also called dictionaries or associative arrays), are data structures
    that store and manage unique key-value pairs in an efficient way. These structures
    aim to quickly provide access to the values associated with the keys that are
    typically stored in one of the following two ways:'
  prefs: []
  type: TYPE_NORMAL
- en: A hashtable
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A tree
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'When key-value pairs are stored in a tree, the result is very similar to what
    was discussed in the previous chapter: self-balancing trees will provide consistent
    performance, avoiding the worst-case cost of a hash map.'
  prefs: []
  type: TYPE_NORMAL
- en: Since trees have been discussed extensively in the previous chapter, the hash
    map is the main focus in this section. It uses a hashing function to translate
    the provided key into a number of some sort, which is in turn "mapped" on array
    buckets. This is where the entire pair is typically stored as a list (or tree)
    to deal with collisions effectively. Whenever a key is looked up, the map can
    search the associated bucket for the exact key. A key-value pair is inserted by
    hashing the key, using the modulo operation to find a spot in the array, and appending
    the pair to the list at the bucket.
  prefs: []
  type: TYPE_NORMAL
- en: 'If two or more elements are in that list, one or more collisions have occurred:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/aff5dc8b-2f6c-4d11-943a-94de51c78130.png)'
  prefs: []
  type: TYPE_IMG
- en: 'While this usually results in great access times, whenever similar hashes have
    to be stored (due to a bad hash function), the worst case scenario will be a search
    through an unordered list—with linear performance. This results in a boxed slice
    that holds all the data in the form of an `Entry` type, a vector of tuples. In
    this case, the implementation is even using generics:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Additionally, the hash function can be freely chosen and is stored as a boxed
    function, which makes it handy to store within the object, and call whenever required.
    This also lets users customize the type of hashing for a particular use case.
  prefs: []
  type: TYPE_NORMAL
- en: By associating an index with a certain hash, a map lacks the ability to traverse
    its content in any kind of order. Therefore, keys and values cannot be iterated
    over in any kind of order, requiring sorting before any operation happens.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once again, the product team is innovating and another feature would really
    add a lot of value to customers: associating postcodes with their factual data
    about the location. This way, a web service can cache commonly used data and reduce
    the load on the database, while serving customers a lot quicker! Since these locations
    are updated manually, an expiration is not required and the map can be filled
    on startup.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Customers provided a list of concise requirements as well to assist, shown
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Insert location information under their unique name
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Quickly retrieve information using their name
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fetch all location names and associated information
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Update locations using their name
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A hash table would do a great job here, would it not?
  prefs: []
  type: TYPE_NORMAL
- en: A location cache
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Caching values is a typical use case for maps because even a large number of
    items won't affect the performance much, since the keys are always distinct. These
    keys can even carry information themselves!
  prefs: []
  type: TYPE_NORMAL
- en: For the use case defined in the last section, each customer uses postcodes within
    a country to identify locations; they typically cover an area that only holds
    a single office. Postal codes are stored as strings to cover the real world's
    wide variety of systems, and they are unique per country.
  prefs: []
  type: TYPE_NORMAL
- en: 'Thanks to a previous generic implementation, the entire `LocationCache` type
    can be an alias to a specialized `HashMap`, only requiring the hash function to
    be supplied on creation, shown as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The `HashMap` itself is a custom implementation that contains a key of type
    `K`, which has to also implement `PartialEq` (for comparing key instances directly),
    and `Clone` (for practical reasons).
  prefs: []
  type: TYPE_NORMAL
- en: The hash function
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In addition to providing a generic data structure, the implementation lets the
    user supply a custom hash function that only maps a reference to the key type
    to a `usize` return type. The choice for the return type is arbitrary, and was
    chosen to avoid overflows.
  prefs: []
  type: TYPE_NORMAL
- en: 'Since the previously implemented hash function performed better than the Adler
    32 checksum algorithm, the location cache will use this. To recall, the algorithm
    applies XOR between a byte and its predecessor and then bit shifts to the left,
    based on the byte''s index. Alternatively, Rust''s `DefaultHasher` is available
    as well:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Choosing a hashing algorithm is an important decision, as we will see in the
    *Wrap up* section. But first, locations need to be added!
  prefs: []
  type: TYPE_NORMAL
- en: Adding locations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In order to add a location, there are two important steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Compute the hash
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Choose a bucket
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Further operations, such as doing a sorted insert, will improve performance
    too, but they can be omitted by using a tree instead of a list within each bucket.
  prefs: []
  type: TYPE_NORMAL
- en: The location cache implementation uses a simple modulo operation between the
    hash and the length of the array to choose a bucket, which means that on top of
    regular hash collisions, choosing the size of the internal storage has a major
    influence on the performance as well. Choose a size too small and the buckets
    will overlap, regardless of the hash function!
  prefs: []
  type: TYPE_NORMAL
- en: 'In Rust code, the first part is done in the first line using the provided boxed
    `hashcode` function to create a hash. What follows is finding a bucket by applying
    something akin to the modulo operation (a binary AND operation between the hash
    and the highest index of the storage array) and a linear search of the attached
    list. If the key is found, the attached pair is updated and if not, it is added
    to the vector:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Once a location and the matching hash is stored, it can be retrieved again.
  prefs: []
  type: TYPE_NORMAL
- en: Fetching locations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Just like inserting, the retrieval process has the same steps. Whether the
    `get()` function to return a value or the `remove()` function, both go through
    the same steps: hash, match a bucket, do a linear search, and lastly, match with
    the expected return type. The `get()` function can utilize Rust''s powerful iterators
    by using `find` to match the predicate within a bucket''s vector and, since an
    `Option<Item>` is returned, its `map` function to extract the value instead of
    returning the entire pair:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: The `remove` function is literally the inversion of an `insert` function; instead
    of updating the key-value pair if found, it is removed from the bucket and returned
    to the caller.
  prefs: []
  type: TYPE_NORMAL
- en: Wrap up
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Hash maps are a great data structure, and often their value cannot be overstated,
    especially in caching or to simplify code that would otherwise have to match labels
    (or keys) to values using array indices. Their key breaking points are the hash
    function itself, and the bucket selection and organization, all of which warrant
    entire PhD theses and papers in computer science.
  prefs: []
  type: TYPE_NORMAL
- en: 'While a hash map is quick and easy to implement, the real question is: how
    does it perform? This is a valid question! Software engineers are prone to prefer
    their own implementation over learning what others already created, and while
    this is the premise for this entire book, benchmarks keep us honest and help us
    to appreciate the work that others have done.'
  prefs: []
  type: TYPE_NORMAL
- en: 'How did this `HashMap` do, especially compared to `std::collections::HashMap<K,V>`?
    We have seen the hash function is far from ideal in some histograms, but what
    are the performance implications? Here is a scatter plot to answer all of these
    questions; it shows the `HashMap` implemented here with different hashing functions
    (Adler 32, `DefaultHasher`, XOR-based) compared to the `HashMap<K,V>` from the
    standard library (which uses `DefaultHasher` exclusively). The following benchmarks
    were performed on the same 1,000 to 10,000 randomly permuted strings between *A*
    and *Z* of lengths of 10 to 26 characters. The *y* axis shows the time required
    for a `get()` operation in nanoseconds, the *x* axis shows the number of items
    in the map. The sizes represent the deviation of the result:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5aab1392-5007-4192-a2ca-0a8de69dc326.png)'
  prefs: []
  type: TYPE_IMG
- en: The scatter plot of the deviation of the result in Adler 32, DefaultHasher,
    XOR-based, collections-HashMap
  prefs: []
  type: TYPE_NORMAL
- en: This plot shows the real value and use of the particular hash functions, as
    they were all applied to this `HashMap`, and the work of the amazing Rust community
    with `std::collections::HashMap<K,V>`, which uses the `DefaultHasher`. Adler 32,
    as a checksum algorithm, did rather badly, which was expected, with even an increasing
    variance as the number of inserted items increased. Surprisingly, the XOR-based
    algorithm was not as bad as expected, but still had a high variance compared to
    the `DefaultHasher`, which performed consistently well.
  prefs: []
  type: TYPE_NORMAL
- en: All of them are a far cry off the `HashMap<K,V>` that comes with the standard
    library. This is great news, because the performance of this hash map implementation
    is also worse than the trees and skip lists presented in [Chapter 5](84f203ac-a9f6-498b-90ff-e069c41aaca0.xhtml),
    *Robust Trees* and [Chapter 4](1a6971bb-ec24-47d5-b44c-cfb4da7d5b24.xhtml), *Lists,
    Lists, More Lists*.
  prefs: []
  type: TYPE_NORMAL
- en: This is proof that while the theory sounds great (constant time retrieval, best
    case)—implementation details can make or break a particular data structure, which
    is why we suspect that `collections::HashMap` sorts and inserts and use of traits
    instead of a boxed (hash) function to significantly improve performance.
  prefs: []
  type: TYPE_NORMAL
- en: Upsides
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The hash map provides a great way to do key-value associations, which are highlighted
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Low overhead storage
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hashed complex keys by default thanks to hashing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Easy to understand
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Constant time retrieval
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yet, there are a few things that may be troublesome when compared to trees,
    or other efficient retrieval structures.
  prefs: []
  type: TYPE_NORMAL
- en: Downsides
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Even though constant time retrieval sounds nice, the benchmarks show that it''s
    not that simple. The downsides are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Performance highly depends on the hash function and application
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Easy to implement naively, hard to get right
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Unordered storage
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Some of these downsides could be mitigated by using a tree-based map, but that
    would be a tree as described in the previous chapter, and there is one data structure
    left to discuss here: the set.'
  prefs: []
  type: TYPE_NORMAL
- en: Sets
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Structured Query Language** (**SQL**), is a declarative language invented
    to perform database operations. Its primary qualities are the ability to express
    *what* you want, rather than *how* you want it ("I want a set of items that conform
    to a predicate X" versus "Filter every item using predicate X"); this also allows
    non-programmers to work with databases, which is an aspect that today''s NoSQL
    databases often lack.'
  prefs: []
  type: TYPE_NORMAL
- en: 'You may think: how is that relevant? SQL allows us to think of the data as
    sets linked together with relations, which is what makes it so pleasant to work
    with. Understanding sets as a distinct collection of objects is sufficient to
    understand the language and how to manipulate the results. While this definition
    is also called the naive set theory, it is a useful definition for most purposes.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In general, a set has elements as members that can be described using a sentence
    or rule, like all positive integers, but it would contain every element only once
    and allow several basic operations: unions, intersections, differences, and the
    Cartesian product, which is the combination of two sets so that elements are combined
    in every possible way:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4557c684-c99f-4c75-bb82-29d9df532471.png)'
  prefs: []
  type: TYPE_IMG
- en: Since set elements are unique, any implementation of a set, therefore, has to
    make sure that each element is unique within the data structure, which is what
    makes the actual data structure special; it optimizes for uniqueness and retrieval.
  prefs: []
  type: TYPE_NORMAL
- en: What about using linear search on a vector to guarantee uniqueness? It works,
    but inserting in a populated set is going to take a lot longer than a new one.
    Additionally, the previous chapters talked about how trees are much better at
    finding things than lists, which is also why no good set implementation should
    use them.
  prefs: []
  type: TYPE_NORMAL
- en: 'The Rust collections in the standard library know two types of sets: `BTreeSet<K,V>`
    and `HashSet<K,V>`, both names that hint at their implementations. As mentioned
    in [Chapter 5](84f203ac-a9f6-498b-90ff-e069c41aaca0.xhtml), *Robust Trees*, the
    B-Tree is a generic, self-balancing tree implementation that allows an arbitrary
    number of children per node, and makes search within its keys very efficient.'
  prefs: []
  type: TYPE_NORMAL
- en: '`HashSet<K,V>` is different. By storing a hash representation of the key, lookup
    can be done in constant time if the hashes are distributed uniformly. Since hash
    sets and hash maps have the same inner workings, this section will focus on a
    tree-based implementation and another section goes further into the depths of
    a hash map.'
  prefs: []
  type: TYPE_NORMAL
- en: Other than inserting and checking whether a set contains a certain element,
    the main operations that a set should provide are union, intersect, and difference,
    as well as an iterator. Having these operations available will provide an efficient
    way to combine multiple sets in various ways, which is part of why they are useful.
  prefs: []
  type: TYPE_NORMAL
- en: 'In Rust code, a trie-based set could look like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: This the trie implementation of [Chapter 5](84f203ac-a9f6-498b-90ff-e069c41aaca0.xhtml),
    *Robust Trees*, with generics added and using a `BTreeMap<K,V>` root node to avoid
    creating too many trait dependencies. This allows arbitrary chains of simple data
    types to be stored as a trie, a highly efficient data structure where overlaps
    are kept together only to branch off once they diverge (read more on tries in
    [Chapter 5](84f203ac-a9f6-498b-90ff-e069c41aaca0.xhtml), *Robust Trees*).
  prefs: []
  type: TYPE_NORMAL
- en: Can this store numbers? Yes, although they have to be converted to a byte array,
    but then anything can be stored in this set.
  prefs: []
  type: TYPE_NORMAL
- en: '*The product team has had an idea: they want to store network addresses for
    a network analysis software. They want to store these addresses in order to run
    some basic analysis on top of them: which network devices are in both networks,
    gathering all the addresses that are in either all or not in some specified networks.
    Since IP addresses are unique and consist of individual bytes that have to have
    common prefixes, wouldn''t this be a great opportunity to use that trie set?*'
  prefs: []
  type: TYPE_NORMAL
- en: Storing network addresses
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Storing network addresses is not a hard problem and there are many solutions
    out there. Their binary structure provides an opportunity to create something
    really specific—if time is not an issue.
  prefs: []
  type: TYPE_NORMAL
- en: 'In many cases, however, an off-the-shelf implementation of a data structure
    is enough to cover most basic use cases when that isn''t your main concern. Hence,
    the network address storage can simple be a type alias that specifies the key
    type for the trie set, shown as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Slight modifications to the `insert` (former `add`) function of the trie allows
    users to simply pass a slice of the key type into the function, shown in the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: This implementation differs only in a few details from what was done in the
    previous chapter. Firstly, it's important to avoid incrementing the length twice,
    which is avoided by checking if a key ends at the last node of the new key. This
    flag is also a new addition since the other implementation was specifically implemented
    to store instances of the `IoTDevice` type, and each node would have an optional
    device attached to it to signal the completion of a key.
  prefs: []
  type: TYPE_NORMAL
- en: A similar reasoning was applied to the `walk` and `contains` functions.
  prefs: []
  type: TYPE_NORMAL
- en: Networked operations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One key requirement of the product team was the ability to run simple analytics
    on top of this set. As a first step, these analytics can be comprised of set operations
    and comparing their lengths in order to create simple indicators.
  prefs: []
  type: TYPE_NORMAL
- en: 'One thing that is important, however, is to also get the addresses back out.
    For that, the implementation this time provides an iterator implementation that
    consumes the trie and stores it as a `Vec<T>`, shown as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Once the vector is created, an index will do for keeping track of moving the
    iterator around. The set operations are actually not much more complex than that.
    However, all of them use the `walk()` function, which requires us to provide mutability
    in a lambda expression (or closure), and consequently a `RefCell` to take care
    of mutability management dynamically.
  prefs: []
  type: TYPE_NORMAL
- en: Union
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The definition of a set union is that every element that occurs in either set
    is required to occur in the result. Therefore, the challenge is to insert elements
    from both sets into the resulting set, without creating duplicates.
  prefs: []
  type: TYPE_NORMAL
- en: 'Since this is handled by the `insert` process, a naive implementation could
    look like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: This consumes both sets, returning only the result. The next operation, the
    intersection, looks very similar.
  prefs: []
  type: TYPE_NORMAL
- en: Intersection
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To find the common elements of two sets, the intersection is a way of doing
    that. The definition also describes exactly that, which is why the naive implementation
    in Rust also follows that pattern, shown as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: As a last function, the difference is important, since it excludes common elements
    from the result set.
  prefs: []
  type: TYPE_NORMAL
- en: Difference
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Instead of common elements, sometimes the opposite is required—removing elements
    that occur in both sets. This operation is also referred to as the complement
    of two sets, which only inserts elements into the result if they don''t occur
    in the other set:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: With that, the set is finished, and all the desired functionality can be provided.
  prefs: []
  type: TYPE_NORMAL
- en: Wrap up
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Sets are not complicated, but are useful. While database indices might be B-Trees,
    the result sets are the sets of primary keys that get moved around and operated
    on until the very last step, when the associated row information is fetched from
    disk. These are the moments when set data structures come in handy and provide
    a simple solution.
  prefs: []
  type: TYPE_NORMAL
- en: Similarly to everyday tasks, creating a list of unique elements can be very
    inefficient when a list is used; storing them in a set, however, requires no extra
    effort. In fact, most elements can then just be thrown into the set, which won't
    insert duplicates anyway.
  prefs: []
  type: TYPE_NORMAL
- en: Upsides
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The set is a higher-level data structure that does the following:'
  prefs: []
  type: TYPE_NORMAL
- en: provides a simple interface for unique lists
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implements a mathematical concept
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Has a very efficient way of storing and retrieving its elements
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Downsides
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The set has some downsides as well, primarily the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Element order determinism depends on the implementation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Does not always add a lot of value compared to maps
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Limited use cases
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Since maps will be used a lot more often, let's dive into those.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Hashing** is the art (and science) of creating a single representation (typically
    a number) from an arbitrary object, be it strings, `type` instances, or collections;
    there is a way to break them down into a number that should reflect a particular
    use case. The real question is what you want to achieve and what characteristics
    are expected from the outcome. Cryptographic hashing deals with minimizing collisions
    and creating signatures that create a very different hash from minor modifications,
    whereas GeoHashes are a way to hierarchically structure Earth''s coordinates into
    a string. Whenever two (or more) inputs to a hash function lead to the same output,
    this is called a collision—a bad sign for any cryptographic hashing, but fine
    if it''s mostly about storing something in a hash map, as long as the collisions
    are evenly distributed. Most importantly, however, software engineers should *never*
    come up with their own hash functions, especially if security is a concern.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Maps** store and manage key-value pairs in an underlying data structure,
    which is typically either a tree or an array that maps hashes to key-value pairs
    called hash maps. By using a hash function to describe the key and sort the pair
    into buckets (array elements), hash maps are a great use case for hashing. These
    buckets are basically indices on an array that stores a list (or tree) for whenever
    different inputs lead to the same bucket. Consequently, the best case performance
    of a hash map is constant time (*O(1)*) to retrieve any value, whereas the worst
    case is linear time (*O(n)*) if the hash function returns a constant number. In
    reality, there are other uses that might be beneficial, such as caching, where
    the use case limits the potential inputs, and best case performance is always
    achieved.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Contrary to maps, **sets** are great data structures to store a unique collection
    of elements to perform set operations on. They can be implemented just like a
    hash map, using a hash function or a tree. In this chapter, we implemented a set
    based on a modified trie data structure from the previous chapter (*Robust Trees*),
    as well as the basic three operations: union, intersection, and difference.'
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will continue to explore Rust's `std::collections` library
    and its contents. This will include some benchmarking and looking into more implementation
    details, since these are the best implementations of all the concepts discussed
    in the book so far.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What makes a good hash function?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How can you estimate the suitability of a hash function for a particular task?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Is a checksum hash useful in other ways?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What are two ways to implement a map?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What are buckets?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Can a set replace a list?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What makes a set useful?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Refer to the following links for more information:'
  prefs: []
  type: TYPE_NORMAL
- en: '[http://geohash.org/](http://geohash.org/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Fletcher''s checksum* ([https://en.wikipedia.org/wiki/Fletcher%27s_checksum](https://en.wikipedia.org/wiki/Fletcher%27s_checksum))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rust's `HashMap` implementation reasoning ([https://www.reddit.com/r/rust/comments/52grcl/rusts_stdcollections_is_absolutely_horrible/d7kcei2](https://www.reddit.com/r/rust/comments/52grcl/rusts_stdcollections_is_absolutely_horrible/d7kcei2))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://doc.rust-lang.org/std/hash/](https://doc.rust-lang.org/std/hash/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wikipedia's list of hash functions ([https://en.wikipedia.org/wiki/List_of_hash_functions](https://en.wikipedia.org/wiki/List_of_hash_functions))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
