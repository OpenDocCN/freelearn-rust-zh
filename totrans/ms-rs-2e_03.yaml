- en: Tests, Documentation, and Benchmarks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we will continue with Cargo and learn how to write tests, how
    to document our code, and how to measure the performance of our code with benchmark
    tests. We'll then put those skills to use and build a simple crate that simulates
    logic gates, giving you an end- to-end experience of writing unit and integration
    tests, as well as documentation tests.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we''ll cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Motivation on testing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Organizing tests and testing primitives
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Unit tests and integration tests
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Documentation tests
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Benchmark tests
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Continuous integration with Travis CI
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Motivation for testing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*"Things that are impossible just take longer." **                         
                                                                                 
                                                                                 
              - **Ian Hickson*'
  prefs: []
  type: TYPE_NORMAL
- en: Software systems are like machines with small cogs and gears. If any of the
    individual gears malfunctions, the machine as a whole is most likely to behave
    in an unreliable manner. In software, the individual gears are functions, modules,
    or any libraries that you use. Functional testing of the individual components
    of a software system is an effective and practical way of maintaining high quality
    code. It doesn't prove that bugs don't exist, but it helps in building confidence
    when deploying the code to production and maintaining the sanity of the code base
    when the project is to be maintained for a long time. Furthermore, large-scale
    refactoring in software is hard to do without unit tests. The benefits of the
    smart and balanced use of unit testing in software are profound. During the implementation
    phase, a well-written unit test becomes an informal specification for components
    of the software. In the maintenance phase, the existing unit tests serve as a
    harness against regressions in the code base, encouraging an immediate fix. In
    compiled languages like Rust, this gets even better as the refactors involved
    (if any) for regressions from unit tests are more guided due to helpful error
    diagnostics from the compiler.
  prefs: []
  type: TYPE_NORMAL
- en: Another good side effect of unit tests is that they encourage the programmer
    to write modular code that is mostly dependent on the input parameters, that is,
    stateless functions. It moves the programmer away from writing code that depends
    on a global mutable state. Writing tests that depend on a global mutable state
    are hard to write. Moreover, the act of simply thinking about writing tests for
    a piece of code helps the programmer figure out silly mistakes in their implementation.
    They also act as very good documentation for any newcomer trying to understand
    how different parts of the code base interact with each other.
  prefs: []
  type: TYPE_NORMAL
- en: The takeaway is that tests are indispensable for any software project. Now,
    let's look at how we can write tests in Rust, starting by learning about organizing
    tests!
  prefs: []
  type: TYPE_NORMAL
- en: Organizing tests
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'At a minimum, there are two kinds of tests that we usually write when developing
    software: unit tests and integration tests. They both serve different purposes
    and interact differently with the code base under test. Unit tests are always
    meant to be lightweight, testing individual components so that the developer can
    run them often, thus providing a shorter feedback loop, while integration tests
    are heavy and are meant to simulate real-world scenarios, making assertions based
    on their environment and specification. Rust''s built-in testing framework provides
    us with sane defaults for writing and organizing these tests:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Unit tests**: Unit tests are usually written within the same module that
    contains the code to be tested. When these tests increase in number, they are
    organized into one entity as a nested module. One usually creates a child module
    within the current module, names it `tests` (by convention) with an annotation
    of the  `#[cfg(test)]` attribute over it, and puts all the test-related functions
    inside of it. This attribute simply tells the compiler to include code within
    the tests module, but only when `cargo test` is run. More on attributes in a moment.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Integration tests**: Integration tests are written separately in a `tests/`
    directory at the crate root. They are written as if the tests are the consumer
    of the crate being tested. Any `.rs` file within the `tests/` directory can add
    a `use` declaration to bring in any public API that needs to be tested.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To write any of the aforementioned tests, there are some testing primitives
    we need to be familiar with.
  prefs: []
  type: TYPE_NORMAL
- en: Testing primitives
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Rust's built-in testing framework is based on a bunch of primitives that are
    mainly composed of attributes and macros. Before we write any actual tests, it's
    important that we get familiar with how to use them effectively.
  prefs: []
  type: TYPE_NORMAL
- en: Attributes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'An attribute is an annotation on an item in Rust code. Items are top-level
    language constructs in a crate such as functions, modules, structs, enums, and
    constant declarations, and other things that are meant to be defined only at the
    crate root. Attributes are usually compiler built-ins, but can also be created
    by users through compiler plugins. They instruct the compiler to inject extra
    code or meaning for the item that appears below them, or for the module if they
    apply to a module. We''ll cover more on these in [Chapter 7](63263043-9b5e-4711-b2e2-e44240a0e843.xhtml),
    *Advanced Concepts*. For the sake of keeping things in scope, we will talk about
    two forms of attributes here:'
  prefs: []
  type: TYPE_NORMAL
- en: '`#[<name>]`: This applies per item and usually appears above them in their
    definition. For example, test functions in Rust are annotated with the `#[test]`
    attribute. It signifies that the function is to be treated as part of the test
    harness.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`#![<name>]`: This applies to the whole crate. Notice that it has an extra
    `!` there. It usually goes at the very top of your crate root.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If we are creating a library crate, the crate root is basically `lib.rs`, whereas
    when creating a binary crate, the crate root would be the `main.rs` file.
  prefs: []
  type: TYPE_NORMAL
- en: There are also other forms of attributes such as `#[cfg(test)]` that are used
    when writing tests within a module. This attribute is added on top of test modules
    to hint to the compiler to conditionally compile the module, but only when code
    is compiled in test mode. Attributes are not just limited to being used in testing
    code; they are widely used in Rust. We'll get to see more of them in upcoming
    chapters.
  prefs: []
  type: TYPE_NORMAL
- en: Assertion macros
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In testing, when given a test case, we try to assert the expected behavior
    of our software component on a given range of inputs. Languages usually provide
    functions called assertion functions to perform these assertions. Rust provides
    us with assertion functions, implemented as macros, that help us achieve the same
    thing. Let''s take a look at some of the commonly used ones:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '`assert!`: This is the simplest assertion macro that takes a Boolean value
    to assert against. If the value is `false`, the test panics, showing the line
    where the failure happened. This can additionally take in a format string, followed
    by a corresponding number of variables, for providing custom error messages:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '`assert_eq!`: This takes in two values and fails if they are not equal. This
    can also take in a format string for custom error messages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`assert_ne!`: This is similar to `assert_eq!` since it takes two values, but
    only asserts when the values are not equal to each other.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`debug_assert!`: This is similar to `assert!`. Debug assertion macros can be
    also be used in code other than test code. This is mostly used in code to assert
    for any contract or invariant that should be held by the code during runtime.
    These assertions are only effective on debug builds and help catch assertion violations
    when run in debug mode. When the code is compiled in optimized mode, these macro
    invocations are completely ignored and optimized away to a no-op. There are similar
    variants to this such as `debug_assert_eq!` and `debug_assert_ne!`, which work
    just like the `assert!` class of macros.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To compare the values within these assertion macros, Rust relies on traits.
    For example, the `==` inside `assert!(a == b)` actually turns into a method call, `a.eq(&b)`,
    which returns a `bool` value. The `eq` method comes from the `PartialEq` trait.
    Most built-in types in Rust implement the `PartialEq` and `Eq` traits so that
    they can be compared. The details of these traits and the difference between `PartialEq`
    and `Eq` are discussed in [Chapter 4](93373ddb-63dc-4b4c-a42f-7a099818705c.xhtml), *Types,
    Generics, and Traits.*
  prefs: []
  type: TYPE_NORMAL
- en: For user-defined types, however, we need to implement these traits. Fortunately,
    Rust provides us with a convenient macro called **derive**, which takes one or
    more trait names to implement. It can be used by putting the `#[derive(Eq, PartialEq)]`
    annotation over any user-defined type. Notice the trait names within parentheses.
    Derive is a procedural macro that simply generates code for `impl` blocks for
    the type on which it appears and implements the trait's methods or any associated
    functions. We'll discuss these macros when we get to [Chapter 9](7143ebcd-54cc-4e31-a2ad-07ce90268584.xhtml),
    *Metaprogramming with Macros*.
  prefs: []
  type: TYPE_NORMAL
- en: With that aside, let's start writing some tests!
  prefs: []
  type: TYPE_NORMAL
- en: Unit tests
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In general, a unit test is a function that instantiates a small portion of an
    application and verifies its behavior independently from other parts of the code
    base**.** In Rust, unit tests are usually written within a module. Ideally, they
    should only aim to cover the module's functionality and its interfaces.
  prefs: []
  type: TYPE_NORMAL
- en: First unit test
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following is our very first unit test:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: A unit test is written as a function and is marked with a `#[test]` attribute.
    There's nothing complex in the preceding `basic_test` function. We have a basic
    `assert!` call passing in `true`. For better organization, you may also create
    a child module called **tests** (by convention) and put all related test code
    inside it.
  prefs: []
  type: TYPE_NORMAL
- en: Running tests
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The way we run this test is by compiling our code in test mode. The compiler
    ignores the compilation of test annotated functions unless it''s told to build
    in test mode. This can be achieved by passing the `--test` flag to `rustc` when
    compiling the test code. Following that, tests can be run by simply executing
    the compiled binary. For the preceding test, we''ll compile it in test mode by
    running this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: With the `--test` flag, `rustc` puts a `main` function with some test harness
    code and invokes all your defined test functions as threads in parallel. All tests
    are run in parallel by default unless told to do so with the environment variable `RUST_TEST_THREADS=1`.
    This means that if we want to run the preceding test in single thread mode, we
    can execute with `RUST_TEST_THREADS=1 ./first_unit_test`.
  prefs: []
  type: TYPE_NORMAL
- en: Now, Cargo already has support for running tests, and all of this is usually
    done internally by invoking `cargo test`. This command compiles and runs the test
    annotated functions for us. In the examples that follow, we will mostly use Cargo
    to run our tests.
  prefs: []
  type: TYPE_NORMAL
- en: Isolating test code
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When our tests grow in complexity, there may be additional helper methods that
    we might create that only gets used within the context of our test code. In such
    situations, it is beneficial to isolate the test-related code from the actual
    code. We can do this by encapsulating all of our test-related code inside a module
    and putting a `#[cfg(test)]` annotation over it.
  prefs: []
  type: TYPE_NORMAL
- en: The `cfg` in the `#[cfg(...)]` attribute is generally used for conditional compilation
    and not just limited to test code. It can include or exclude code for different
    architectures or configuration flags. Here, the configuration flag is `test`.
    You might remember that the tests in the previous chapter were already using this
    form. This has the advantage that your test code is only compiled and included
    in the compiled binary when you run `cargo test`, and otherwise ignored.
  prefs: []
  type: TYPE_NORMAL
- en: 'Say you want to programmatically generate test data for your tests, but there''s
    no reason to have that code in the release build. Let''s create a project by running
    `cargo new unit_test --lib` to demonstrate this. In `lib.rs`, we have defined
    some tests and functions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: We can run these tests by running `cargo test`. Let's go through the preceding
    code. We generate known input and output pairs in the `sum_inputs_outputs` function,
    which is used by the `test_sums` function. The `#[test]` attribute keeps the `test_sums`
    function out of our release compilation. However, `sum_inputs_outputs` is not
    marked with `#[test]`, and will get included in compilation if it's declared outside
    the `tests` module. By using `#[cfg(test)]` with a `mod tests {}` child module
    and encapsulating all the test code and its related functions inside this module,
    we get the benefit of keeping both the code and the resulting binary clean of
    the test code.
  prefs: []
  type: TYPE_NORMAL
- en: We also had our `sum` function defined as private without the `pub` visibility
    modifier, which means that unit tests within modules also allow you to test private
    functions and methods. Quite convenient!
  prefs: []
  type: TYPE_NORMAL
- en: Failing tests
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are also test cases where you will want your API methods to fail based
    on some input, and you want the test framework to assert this failure. Rust provides
    an attribute called `#[should_panic]` for this. Here''s a test that panics and
    uses this attribute:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: The `#[should_panic]` attribute can be paired with a `#[test]` attribute to
    signify that running the `this_panics` function should cause a non-recoverable
    failure, which is called a **panic** in Rust.
  prefs: []
  type: TYPE_NORMAL
- en: Ignoring tests
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Another useful attribute for writing tests is `#[ignore]`. If your test code
    is exceedingly heavy, the `#[ignore]` annotation enables the test harness to ignore
    such test functions when running `cargo test`. You can then choose to individually
    run those tests by supplying an `--ignored` parameter to either your test runner
    or the `cargo test` command. Here''s the code containing a silly loop that, when
    run using `cargo test`, is ignored by default:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Note the `#[ignore]` attribute over the `test_silly_loop` test function. Here''s
    the output from the ignored test:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/fe9815c7-ab4a-44d5-a9c2-34f6393962db.png)**Note**: A single test can
    also be run by supplying the test function name to Cargo, for example, `cargo
    test some_test_func`.'
  prefs: []
  type: TYPE_NORMAL
- en: Integration tests
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: While unit tests can test the private interface of your crate and individual
    modules, integration tests are kind of like black box tests that aim to test the
    end-to-end use of the public interface of your crate from a consumer's perspective.
    In terms of writing code, there is not a lot of difference between writing integration
    tests and unit tests. The only difference lies in the directory structure and
    that the items need to be made public, which is already exposed by the developer
    as per the design of the crate.
  prefs: []
  type: TYPE_NORMAL
- en: First integration test
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As we stated previously, Rust expects all integration tests to live in the
    `tests/` directory. Files within the `tests/` directory are compiled as if they
    are separate binary crates while using our library under test. For the following
    example, we''ll create a new crate by running  `cargo new integration_test --lib`,
    with the same function, `sum` ,as in the previous unit test, but now we have added
    a `tests/` directory, which has an integration test function defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'We first bring the function `sum` in scope. Second, we have a function, `sum_test` ,
    that calls `sum` and asserts on the return value. When we try to run `cargo test`,
    we are presented with the following error:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c864b7f9-9d25-452a-8e09-a6faa593ff57.png)'
  prefs: []
  type: TYPE_IMG
- en: 'This error seems reasonable. We want the users of our crate to use the `sum`
    function, but in our crate we have it defined as a private function by default.
    So, after adding the `pub` modifier before the `sum` function and running `cargo
    test`, our test is green again:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c2ad6160-52bc-4d26-9cb7-fd8ca6ed0243.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Here''s a view of the directory tree of our `integration_test` example crate:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: As an example of an integration test, this was very trivial, but the gist of
    it is that when we write integration tests, we use the crate that's being tested,
    like any other user of a library would use it.
  prefs: []
  type: TYPE_NORMAL
- en: Sharing common code
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As is often the case with integration tests, there is some setup and teardown-related
    code that we might need to put in place before we can actually run our tests.
    You usually want them to be shared by all of the files in the `tests/` directory.
    For sharing code, we can use modules by either creating them as a directory that
    shares common code, or use a module `foo.rs` and declare in our `integration`
    test files that we depend on it by putting a `mod` declaration. So, in our preceding `tests/`
    directory, we added a `common.rs` module that has two functions called `setup`
    and `teardown`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: In both of our functions, we can have any kind of fixture-related code. Consider
    that you have an integration test that relies on the existence of a text file.
    In our function `setup`, we can create the text file, while in our functi0n `teardown`,
    we can clean up our resources by deleting the file.
  prefs: []
  type: TYPE_NORMAL
- en: 'To use these functions in our integration test code in `tests/sum.rs`, we put
    in the `mod` declarations like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'We have added another function,  `test_with_fixture` , that includes calls
    to `setup` and `teardown`. We can run this test with `cargo test test_with_fixture`.
    As you may have noticed from the output, we don''t get to see our `println!` calls
    anywhere from within the `setup` or `teardown` functions. This is because, by
    default, the test harness hides or captures print statements within test functions
    to make the test results tidier, and only shows the test harness''s outputs. If
    we want to view print statements within our tests, we can run the test with `cargo
    test test_with_fixture -- --nocapture`, which gives us the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/560e2a59-d90d-4504-b4f1-24f86660a15e.png)'
  prefs: []
  type: TYPE_IMG
- en: We can see our print statements now. We needed the `--` in `cargo test test_with_fixture
    -- --nocapture` because we actually want to pass the `--nocapture` flag to our
    test runner. `--` marks the end of arguments for `cargo` itself, and any argument
    following that is passed to the binary being invoked by cargo, which is our compiled
    binary with test harness.
  prefs: []
  type: TYPE_NORMAL
- en: That's about it for integration tests. At the end of this chapter, we'll create
    a project where we get to see both unit tests and integration tests work in tandem.
    Next, we'll learn about documenting Rust code, an overlooked but quite important
    part of software development.
  prefs: []
  type: TYPE_NORMAL
- en: Documentation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Documentation is a very crucial aspect of any open source software aiming for
    wide adoption by the programmer community. While your code, which should be readable,
    tells you how it works, the documentation should tell you about the why and how
    of the design decisions and example usage of the public APIs of your software.
    Well documented code with a comprehensive `README.md` page boosts the discoverability
    of your project many times over.
  prefs: []
  type: TYPE_NORMAL
- en: The Rust community takes documentation very seriously and has tools at various
    levels to make it easy to write documentation for code. It also makes it presentable
    and consumable for its users. For writing documentation, it supports the markdown
    dialect. Markdown is a very popular markup language and is the standard these
    days for writing docs. Rust has a dedicated tool called **rustdoc** that parses
    markdown doc comments, converts them to HTML, and generates beautiful and searchable
    documentation pages.
  prefs: []
  type: TYPE_NORMAL
- en: Writing documentation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To write documentation, we have special symbols for marking the start of documentation
    comments (doc comments hereafter). Docs are written in a similar fashion, the
    way we write comments, but they are treated differently compared to ordinary comments
    and are parsed by rustdoc. The doc comments are divided into two levels and use
    separate symbols to mark the start of the doc comment:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Item level**: These comments are meant for items within the module such as
    structs, enum declarations, functions, trait constants, and so on. They should
    appear above the item. For single-line comments, they start with `///`, while
    multi-line comments begin with `/**` and end with `*/`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Module level**: These are comments that appear at the root level, i.e., `main.rs`, `lib.rs`,
    or any other module, and use `//!` to mark the start of a line comment – or `/*!`
    for multi-line comments – before ending them with `*/`. They are suitable for
    giving a general overview of your crate and example usage.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Within the doc comment, you can write docs using the usual markdown syntax.
    It also supports writing valid Rust code within backticks ([PRE11]`), which becomes
    part of documentation tests.
  prefs: []
  type: TYPE_NORMAL
- en: The preceding notation for writing comments is actually a syntatic sugar for
    the `#[doc="your doc comment"]` attribute. These are called **doc attributes**.
    When rustdoc parses the `///` or `/**` lines, it converts them into these doc
    attributes. Alternatively, you can also write docs using these doc attributes.
  prefs: []
  type: TYPE_NORMAL
- en: Generating and viewing documentation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To generate documentation, we can use the `cargo doc` command in our project
    directory. It generates docs in the `target/doc/` directory with a bunch of HTML
    files and predefined stylesheets. By default, it generates docs for a crate's
    dependencies too. We can tell Cargo to ignore generating docs for dependencies
    by running `cargo doc --no-deps`.
  prefs: []
  type: TYPE_NORMAL
- en: To view the documentation, one can spawn a HTTP server by navigating inside
    the `target/doc` directory. Python's simple HTTP server can come in handy here.
    However, there's a better way to do this! Passing the `--open` option to `cargo
    doc` will open the documentation page directly in your default browser.
  prefs: []
  type: TYPE_NORMAL
- en: '`cargo doc` can be combined with `cargo watch` to get a seamless experience
    in writing documentation and getting live feedback on the generated page for any
    documentation changes you do on your project.'
  prefs: []
  type: TYPE_NORMAL
- en: Hosting documentation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'After your documentation has been generated, you will need to host it somewhere
    for the public to view and use. There are three possibilities here:'
  prefs: []
  type: TYPE_NORMAL
- en: '**docs.rs**: Crates that are hosted on `crates.io` get their documentation
    page automatically generated and hosted on [https://docs.rs](https://docs.rs).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**GitHub pages**: You can host your documentation on the `gh-pages` branch
    if your crate is on GitHub.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**External website:** You can manage your own web server for hosting documentation.
    Rust''s standard library documentation is a fine example of this: [https://doc.rust-lang.org/std/](https://doc.rust-lang.org/std/).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As an added note, if your project's documentation spans more than two to three
    pages and requires a detailed introduction, then there's a better option to generate
    book-like documentation. This is done by using the `mdbook` project. For more
    information on that, check out their GitHub page at [https://github.com/rust-lang-nursery/mdBook](https://github.com/rust-lang-nursery/mdBook).
  prefs: []
  type: TYPE_NORMAL
- en: Doc attributes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We mentioned that the doc comments that we write get converted into doc attributes
    form. Apart from those, there are other doc attributes for documentation that
    can tweak the generated documentation page, and these are applied either at the
    crate level or at the item level. They are written like `#[doc(key = value)]`.
    Some of the most useful doc attributes are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Crate-level attributes**:'
  prefs: []
  type: TYPE_NORMAL
- en: '`#![doc(html_logo_url = "image url")`: Allows you to add a logo to the top-left
    of your documentation page.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`#![doc(html_root_url = "https://docs.rs/slotmap/0.2.1")]`: Allows you to set
    the URL for the documentation page.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`#![doc(html_playground_url = "https://play.rust-lang.org/")]`: Allows you
    to put a run button near the code example in your documentation so that you can
    run it directly in the online Rust playground.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Item-level attributes**:'
  prefs: []
  type: TYPE_NORMAL
- en: '`#[doc(hidden)]`: Say you have written the documentation for a public function, `foo`,
    as a note to yourself. However, you don''t want your consumers to view the documentation.
    You can use this attribute to tell rustdoc to ignore generating docs for `foo`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`#[doc(include)]`: This can be used to include documentation from other files.
    This helps you separate your documentation from code if it''s really long.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For more attributes like these ones, head over to [https://doc.rust-lang.org/beta/rustdoc/the-doc-attribute.html](https://doc.rust-lang.org/beta/rustdoc/the-doc-attribute.html).
  prefs: []
  type: TYPE_NORMAL
- en: Documentation tests
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It's often a good practice to include code examples with any documentation for
    your crate's public APIs. There's a caveat in maintaining such examples, though.
    Your code might change and you might forget to update your examples. Documentation
    tests (doctests) are there to remind you to update your example code as well.
    Rust allows you to embed code in backticks within doc comments. Cargo can then
    run this example code that's been embedded within your documentation, and treats
    it as part of the unit test suite. This means that documentation examples run
    every time you run your unit tests, forcing you to update them. Quite amazing!
  prefs: []
  type: TYPE_NORMAL
- en: 'Documentation tests are also executed via Cargo. We have created a project
    called `doctest_demo` to illustrate documentation tests. In `lib.rs`, we have
    the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: //! use doctest_demo::sum;
  prefs: []
  type: TYPE_NORMAL
- en: //!
  prefs: []
  type: TYPE_NORMAL
- en: //! let work_a = 4;
  prefs: []
  type: TYPE_NORMAL
- en: //! let work_b = 34;
  prefs: []
  type: TYPE_NORMAL
- en: //! let total_work = sum(work_a, work_b);
  prefs: []
  type: TYPE_NORMAL
- en: //! [PRE13]
  prefs: []
  type: TYPE_NORMAL
- en: /// assert_eq!(doctest_demo::sum(1, 1), 2);
  prefs: []
  type: TYPE_NORMAL
- en: /// [PRE14]
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, the difference between module-level and function-level doctests
    is not much. They are used in pretty much the same way. It is just that the module-level
    doctests show the overall usage of the crate, covering more than one API surface,
    while function-level doctests cover just the particular function over which they
    appear.
  prefs: []
  type: TYPE_NORMAL
- en: 'Documentation tests run with all the other tests when you run `cargo test`.
    Here''s the output when we run `cargo test` in our `doctest_demo` crate:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0edfb5b3-92f4-4e90-8ca8-8d4038260bea.png)'
  prefs: []
  type: TYPE_IMG
- en: Benchmarks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When business needs change and your program gets a requirement to perform more
    efficiently, the first step to take is to find out the areas that are slow in
    the program. How can you tell where the bottlenecks are? You can tell by measuring
    individual parts of your program on various expected ranges or on a magnitude
    of inputs. This is known as benchmarking your code. Benchmarking is usually done
    at the very last stage of development (but does not have to be) to provide insights
    on areas where there are performance pitfalls in code.
  prefs: []
  type: TYPE_NORMAL
- en: There are various ways to perform benchmark tests for a program. The trivial
    way is to use the Unix tool time to measure the execution time of your program
    after your changes. But that doesn't provide precise micro-level insights. Rust
    provides us with a built-in micro benchmarking framework. By micro benchmarking,
    we mean that it can be used to benchmark individual parts of the code in isolation
    and remains unbiased from external factors. However, it also means that we should
    not rely solely on micro benchmarks since the real world results can be skewed.
    Thus, a micro benchmark is often followed by profiling and macro benchmarking
    of the code. Nonetheless, micro benchmarking is often a starting point for improving
    the performance of your code as the individual parts contribute a lot to the overall
    running time of your program.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we will discuss the tool that Rust provides as a built in for
    performing micro benchmarks. Rust lowers the bar for writing benchmarking code
    right from the initial stages of development, rather than doing it as a last resort.
    The way you run benchmarks is similar to how tests are run, but uses the `cargo
    bench` command instead.
  prefs: []
  type: TYPE_NORMAL
- en: Built-in micro-benchmark harness
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Rust''s built-in benchmarking framework measures the performance of code by
    running it through several iterations and reports the average time taken for the
    operation in question. This is facilitated by two things:'
  prefs: []
  type: TYPE_NORMAL
- en: The `#[bench]` annotation on a function. This marks the function as a benchmark
    test.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The internal compiler crate `libtest` with a `Bencher` type, which the benchmark
    function uses for running the same benchmark code in several iterations. This
    type resides under the `test` crate, which is internal to the compiler.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Now, we''ll write and run a simple benchmark test. Let''s create a new Cargo
    project by running `cargo new --lib bench_example`. No changes to `Cargo.toml`
    are needed for this. The contents of `src/lib.rs` is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Note that we had to specify the internal crate `test` with the `external crate`
    declaration, along with the `#[feature(test)]` attribute. The `extern` declaration
    is needed for crates internal to the compiler. In future versions of the compiler,
    this might not be needed and you will be able to `use` them like normal crates.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we run our benchmarks by running `cargo bench`, we will see the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1489bed5-f538-4cc3-9414-1529bbe4783a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Unfortunately, benchmark tests are an unstable feature, so we''ll have to use
    the nightly compiler for these. Fortunately, with `rustup`, moving between different
    release channels of the Rust compiler is easy. First, we''ll make sure that the
    nightly compiler is installed by running `rustup update nightly`. Then, within
    our `bench_example` directory, we will override the default toolchain for this
    directory by running `rustup override set nightly`. Now, running `cargo bench`
    will give the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2c9be90a-ff60-4a95-bd8a-f27155da64eb.png)'
  prefs: []
  type: TYPE_IMG
- en: Those are nanoseconds per iteration, with the figure inside the parentheses
    showing the variation between each run. Our slower implementation was quite slow
    and variable in running time (as shown by the large `+/-` variation).
  prefs: []
  type: TYPE_NORMAL
- en: Inside our functions marked with `#[bench]`, the parameter to `iter` is a closure
    with no parameters. If the closure had parameters, they would be inside `||`.
    This essentially means that `iter` is passed a function that the benchmark test
    can run repeatedly. We print a single dot in the function so that Rust won't optimize
    the empty loop away. If the `println!()` was not there, then the compiler would
    have optimized away the loop to a no-op, and we would get false results. There
    are ways to get around this, and this is done by using the `black_box` function
    from the `test` module. However, even using that does not guarantee that the optimizer
    won't optimize your code. Now, we also have other third-party solutions for running
    benchmarks on stable Rust.
  prefs: []
  type: TYPE_NORMAL
- en: Benchmarking on stable Rust
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The built-in benchmarking framework provided by Rust is unstable, but fortunately
    there are community developed benchmarking crates that work on stable Rust. One
    such popular crate that we'll explore here is `criterion-rs`. This crate is designed
    to be easy to use while at the same time providing detailed information on the
    benchmarked code. It also maintains the state of the last run, reporting performance
    regressions (if any) on every run. Criterion.rs generates more statistical reports
    than the built-in benchmark framework, and also generates helpful charts and graphs
    using *gnuplot* to make it understandable to the user.
  prefs: []
  type: TYPE_NORMAL
- en: 'To demonstrate using this crate, we''ll create a new crate called `cargo new
    criterion_demo --lib`. We will add the criterion crate to `Cargo.toml` as a dependency
    under the `dev-dependencies` section:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: We have also added a new section known as `[[bench]]`, which indicates to cargo
    that we have a new benchmark test named `fibonacci` and that it does not use the
    built-in benchmark harness (`harness = false`), since we are using the criterion
    crate's test harness.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, in `src/lib.rs`, we have a fast and a slow version of a function that
    computes the nth `fibonacci` number (with initial values of `n[0] = 0` and `n[1]
    = 1`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: '`fast_fibonacci` is the bottom-up iterative solution to get the nth fibonacci
    number, whereas the `slow_fibonacci` version is the slow recursive version. Now,
    criterion-rs requires us to place our benchmarks inside a `benches/` directory,
    which we created at the crate root. Within the `benches/` directory, we have also
    created a file named `fibonacci.rs`, which matches our name under the `[[bench]]`
    in `Cargo.toml`. It has the following content:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: There's quite a lot going on here! In the preceding code, we first declare our
    required crates and import our the `fibonacci` functions that we need to benchmark
    (`fast_fibonacci` and `slow_fibonacci`). Also, there is a `#[macro_use]` attribute
    above `extern crate criterion`, which means to use any macros from a crate, we
    need to opt for it using this attribute as they are not exposed by default. It's
    similar to a `use` statement, which is used to expose module items.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, criterion has this notion of benchmark groups that can hold related benchmark
    code. Accordingly, we created a function named `fibonacci_benchmark`, which we
    then pass on to the `criterion_group!` macro. This assigns a name of `fib_bench`
    to this benchmark group. The `fibonacci_benchmark` function takes in a mutable
    reference to a `criterion` object, which holds the state of our benchmark runs.
    This exposes a method called `bench_function`, which we use to pass in our benchmark
    code to run in a closure with a given name (above `fibonacci 8`). Then, we need
    to create the main benchmark harness, which generates code with a `main` function
    to run all of it by using `criterion_main!`, before passing in our benchmark group,  `fib_bench`.
    Now, it''s time to run `cargo bench` with the first `slow_fibonacci` function
    inside the closure. We get the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/52a10831-cbb4-457a-816a-6fac29cac734.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We can see that the recursive version of our `fibonacci` function takes about
    106.95 ns to run on average. Now, within the same benchmark closure, if we replace
    our `slow_fibonacci` with our `fast_fibonacci` and run `cargo bench` again, we''ll
    get the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b0014a93-911b-4f03-ad70-5f1633c66d0a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Great! The `fast_fibonacci` version takes just 7.8460 ns to run on average.
    That''s obvious, but the great thing about this is the detailed benchmark report,
    which also shows a human-friendly message: Performace has improved. The reason
    criterion is able to show this regression report is that it maintains the previous
    state of benchmark runs and uses their history to report changes in performance.'
  prefs: []
  type: TYPE_NORMAL
- en: Writing and testing a crate – logic gate simulator
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Armed with all of this knowledge, let's start things off with our logic gate
    simulation crate. We'll create a new project by running `cargo new logic_gates
    --lib`. Starting with primitive gates implemented as functions such as `and`,
    `xor`, and so on, we will write unit tests for these gates. Following that, we'll
    write integration tests by implementing a half adder that uses our primitive gates.
    During this process, we'll also get to write documentation for our crate.
  prefs: []
  type: TYPE_NORMAL
- en: 'First off, we''ll start with some unit tests. Here''s the initial crate code
    in its entirety:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'We have started with two logic gates, `and` and `xor`, which have been implemented
    as functions. We also have tests cases against those that fail when run because
    they haven''t been implemented yet. Note that to represent bit `0` and `1`, we
    are using a `u8` as Rust does not have a native type to represent bits. Now, let''s
    fill in their implementation, along with some documentation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding code, we just expressed the truth tables of the `and` and
    `xor` gates using match expressions. We can see how concise match expressions
    can be in expressing our logic. Now, we can run the tests by running `cargo test`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6930937c-7ed3-444d-9d53-f972ffae96f7.png)'
  prefs: []
  type: TYPE_IMG
- en: 'All green! We are now ready to write integration tests by implementing a half
    adder using these gates. A half adder fits in perfectly as an integration test
    example as it tests the individual components of our crate while they''re being
    used together. Under the `tests/` directory, we''ll create a file called `half_adder.rs`
    that includes the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding code, we import our primitive gate functions `xor` and `and`.
    Following that, we have something like `pub type Sum = u8`, which is known as
    a **type alias**. They are helpful in situations where you either have a type
    that is cumbersome to write every time or when you have types with complex signatures.
    It gives another name to our original type and is purely for readability and disambiguation;
    it has no implications in the way Rust analyzes those types. We then use the  `Sum`
    and `Carry` in our `half_adder_input_output` function, which implements the truth
    table for the half adder. This is a convenient helper function to test our `half_adder`
    function that follows it. This function takes in two one-bit inputs and calculates
    the `Sum` and `Carry` from them before returning them as a tuple of `(Sum, Carry)`.
    Further ahead, we have our `one_bit_adder` integration test function, in which
    we iterate over our half adder input output pairs and assert against the output
    of the  `half_adder`. By running `cargo test`, we get the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0d2972a5-d5a3-4bda-8fbe-eb2d072ae584.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Great ! Let''s also generate documentation for our crate by running `cargo
    doc --open`. The `--open` flag opens the page for us to view in a browser. To
    customize our documentation, we''ll also add an icon to our crate docs page. To
    do this, we need to add the following attribute at the top of `lib.rs`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'After generation, the documentation page looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/fb250dfc-08a7-4a13-b628-21c9b54654bd.png)'
  prefs: []
  type: TYPE_IMG
- en: This is great! We have come a long way in our testing journey. Next, let's look
    at the aspect  automating out test suites.
  prefs: []
  type: TYPE_NORMAL
- en: Continuous integration with Travis CI
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It is often the case in large software systems that for every change to our
    code, we want both our unit and integration tests to run automatically. Moreover,
    in a collaborative project, the manual way is just not practical. Fortunately,
    Continuous Integration is a practice that aims to automate those aspects of software
    development. Travis CI is a public continuous integration service that allows
    you to run your project's tests automatically in the cloud, based on event hooks.
    One example of an event hook is when new commits are pushed.
  prefs: []
  type: TYPE_NORMAL
- en: 'Travis is generally used to automate running builds and tests and to report
    failed builds, but can also be used for creating releases and even deploying them
    in staging or production environments. We''ll focus on one aspect of Travis in
    this section, performing automated runs of our tests for our project. GitHub already
    has integration with Travis that can run tests for new commits in our project.
    To make this happen, we need the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Our project on GitHub
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An account in Travis, which is made by logging in with GitHub
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Your project enabled for builds in Travis
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A `.travis.yml` file at the root of your repository that tells Travis what to
    run on
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The first step is to go to [https://travis-ci.org/](https://travis-ci.org/)
    and log in with your GitHub credentials. From there, we can add our GitHub repository
    in Travis. Travis has good native support for Rust projects and keeps its Rust
    compiler continuously up to date. It provides a basic version of the `.travis.yml`
    file for Rust projects, which is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: The Rust project recommends testing against beta and nightly channels too, but
    you may choose to target just a single version by removing the corresponding lines.
    This recommended setup runs the tests on all three versions, but allows the fast-moving
    nightly compiler to fail.
  prefs: []
  type: TYPE_NORMAL
- en: With this `.travis.yml` file in your repository, GitHub will inform Travis CI
    every time you push your code and run your tests automatically. We can also attach
    build status badges to our repository's `README.md` file, which shows a green
    badge when tests pass and a red badge in when tests fail.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s integrate Travis with our `logic_gates` crate. For this, we have to
    add a `.travis.yml` file at our crate root. The following is the contents of the `.travis.yml` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'After pushing this to GitHub, we then need to enable Travis for our project
    on their page, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6cf809eb-a568-430d-acdd-dd7942b2ada8.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The preceding screenshot is from my TravisCI account. Now, we''ll make a commit
    to our `logic_gates` repository by adding a simple `README.md` file to trigger
    the Travis build runner. While we do this, let''s also add a build badge to our
    `README.md` file that will show the status of our repository to consumers. To
    do this, we''ll click the build passing badge on the right:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/df44efff-27ec-48b2-aabf-f62f4aa402be.png)'
  prefs: []
  type: TYPE_IMG
- en: 'This opens up a popup menu with the badge link:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/28fb3d03-5593-4f32-abfb-a7e09dd74dc1.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We will copy this link and add it to the top in our `README.md` file as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: You need to replace `$USERNAME` and `$REPO_NAME` with your details.
  prefs: []
  type: TYPE_NORMAL
- en: 'After this change and committing the `README.md` file, we will start to see
    the Travis build starting and succeeding:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1daa5147-2ee3-4b1a-be63-0e5d20c713c5.png)'
  prefs: []
  type: TYPE_IMG
- en: Awesome! If you are feeling more ambitious, you can also try hosting the `logic_gates`
    crate's documentation on your repository's `gh-pages` branch on GitHub. You can
    do this by using the `cargo-travis` project, which is available at [https://github.com/roblabla/cargo-travis\](https://github.com/roblabla/cargo-travis).
  prefs: []
  type: TYPE_NORMAL
- en: For an even more versatile CI setup that covers major platforms, you can use
    the template provided by the trust project, which is available at [https://github.com/japaric/trust](https://github.com/japaric/trust).
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, to publish your crate on *crates.io*, you can follow the directions
    given in Cargo''s reference documentation: [https://doc.rust-lang.org/cargo/reference/publishing.html](https://doc.rust-lang.org/cargo/reference/publishing.html).'
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we got acquainted with writing unit tests, integration tests,
    documentation tests, and benchmarks using both `rustc` and the `cargo` tool. We
    then implemented a logic gate simulator crate and got to experience the whole
    crate development workflow. Later, we learned how to integrate Travis CI for our
    GitHub project.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we'll explore Rust's type system and how to use it to express
    proper semantics in our program at compile time.
  prefs: []
  type: TYPE_NORMAL
