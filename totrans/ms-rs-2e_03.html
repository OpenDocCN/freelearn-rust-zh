<html><head></head><body>
        

                            
                    <h1 class="header-title">Tests, Documentation, and Benchmarks</h1>
                
            
            
                
<p>In this chapter, we will continue with Cargo and learn how to write tests, how to document our code, and how to measure the performance of our code with benchmark tests. We'll then put those skills to use and build a simple crate that simulates logic gates, giving you an end- to-end experience of writing unit and integration tests, as well as documentation tests.</p>
<p>In this chapter, we'll cover the following topics:</p>
<ul>
<li>Motivation on testing</li>
<li>Organizing tests and testing primitives</li>
<li>Unit tests and integration tests</li>
<li>Documentation tests</li>
<li>Benchmark tests</li>
<li>Continuous integration with Travis CI</li>
</ul>


            

            
        
    

        

                            
                    <h1 class="header-title">Motivation for testing</h1>
                
            
            
                
<div><em>"Things that are impossible just take longer." </em><em>                                                                                                                                                                                                - </em><em>Ian Hickson</em></div>
<p>Software systems are like machines with small cogs and gears. If any of the individual gears malfunctions, the machine as a whole is most likely to behave in an unreliable manner. In software, the individual gears are functions, modules, or any libraries that you use. Functional testing of the individual components of a software system is an effective and practical way of maintaining high quality code. It doesn't prove that bugs don't exist, but it helps in building confidence when deploying the code to production and maintaining the sanity of the code base when the project is to be maintained for a long time. Furthermore, large-scale refactoring in software is hard to do without unit tests. The benefits of the smart and balanced use of unit testing in software are profound. During the implementation phase, a well-written unit test becomes an informal specification for components of the software. In the maintenance phase, the existing unit tests serve as a harness against regressions in the code base, encouraging an immediate fix. In compiled languages like Rust, this gets even better as the refactors involved (if any) for regressions from unit tests are more guided due to helpful error diagnostics from the compiler.</p>
<p>Another good side effect of unit tests is that they encourage the programmer to write modular code that is mostly dependent on the input parameters, that is, stateless functions. It moves the programmer away from writing code that depends on a global mutable state. Writing tests that depend on a global mutable state are hard to write. Moreover, the act of simply thinking about writing tests for a piece of code helps the programmer figure out silly mistakes in their implementation. They also act as very good documentation for any newcomer trying to understand how different parts of the code base interact with each other.</p>
<p>The takeaway is that tests are indispensable for any software project. Now, let's look at how we can write tests in Rust, starting by learning about organizing tests!</p>
<p class="mce-root"/>
<p class="mce-root"/>


            

            
        
    

        

                            
                    <h1 class="header-title">Organizing tests</h1>
                
            
            
                
<p>At a minimum, there are two kinds of tests that we usually write when developing software: unit tests and integration tests. They both serve different purposes and interact differently with the code base under test. Unit tests are always meant to be lightweight, testing individual components so that the developer can run them often, thus providing a shorter feedback loop, while integration tests are heavy and are meant to simulate real-world scenarios, making assertions based on their environment and specification. Rust's built-in testing framework provides us with sane defaults for writing and organizing these tests:</p>
<ul>
<li><strong>Unit tests</strong>: Unit tests are usually written within the same module that contains the code to be tested. When these tests increase in number, they are organized into one entity as a nested module. One usually creates a child module within the current module, names it <kbd>tests</kbd> (by convention) with an annotation of the  <kbd>#[cfg(test)]</kbd> attribute over it, and puts all the test-related functions inside of it. This attribute simply tells the compiler to include code within the tests module, but only when <kbd>cargo test</kbd> is run. More on attributes in a moment.<br/></li>
<li><strong>Integration tests</strong>: Integration tests are written separately in a <kbd>tests/</kbd> directory at the crate root. They are written as if the tests are the consumer of the crate being tested. Any <kbd>.rs</kbd> file within the <kbd>tests/</kbd> directory can add a <kbd>use</kbd> declaration to bring in any public API that needs to be tested.</li>
</ul>
<p>To write any of the aforementioned tests, there are some testing primitives we need to be familiar with.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Testing primitives</h1>
                
            
            
                
<p>Rust's built-in testing framework is based on a bunch of primitives that are mainly composed of attributes and macros. Before we write any actual tests, it's important that we get familiar with how to use them effectively.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Attributes</h1>
                
            
            
                
<p>An attribute is an annotation on an item in Rust code. Items are top-level language constructs in a crate such as functions, modules, structs, enums, and constant declarations, and other things that are meant to be defined only at the crate root. Attributes are usually compiler built-ins, but can also be created by users through compiler plugins. They instruct the compiler to inject extra code or meaning for the item that appears below them, or for the module if they apply to a module. We'll cover more on these in <a href="63263043-9b5e-4711-b2e2-e44240a0e843.xhtml">Chapter 7</a>, <em>Advanced Concepts</em>. For the sake of keeping things in scope, we will talk about two forms of attributes here:</p>
<ul>
<li><kbd>#[&lt;name&gt;]</kbd>: This applies per item and usually appears above them in their definition. For example, test functions in Rust are annotated with the <kbd>#[test]</kbd> attribute. It signifies that the function is to be treated as part of the test harness.</li>
<li><kbd>#![&lt;name&gt;]</kbd>: This applies to the whole crate. Notice that it has an extra <kbd>!</kbd> there. It usually goes at the very top of your crate root.</li>
</ul>
<p>If we are creating a library crate, the crate root is basically <kbd>lib.rs</kbd>, whereas when creating a binary crate, the crate root would be the <kbd>main.rs</kbd> file.</p>
<p>There are also other forms of attributes such as <kbd>#[cfg(test)]</kbd> that are used when writing tests within a module. This attribute is added on top of test modules to hint to the compiler to conditionally compile the module, but only when code is compiled in test mode. Attributes are not just limited to being used in testing code; they are widely used in Rust. We'll get to see more of them in upcoming chapters.</p>
<p class="mce-root"/>
<p class="mce-root"/>


            

            
        
    

        

                            
                    <h1 class="header-title">Assertion macros</h1>
                
            
            
                
<p>In testing, when given a test case, we try to assert the expected behavior of our software component on a given range of inputs. Languages usually provide functions called assertion functions to perform these assertions. Rust provides us with assertion functions, implemented as macros, that help us achieve the same thing. Let's take a look at some of the commonly used ones:</p>
<pre>      assert!(true);<br/>      assert!(a == b, "{} was not equal to {}", a, b);</pre>
<ul>
<li><kbd>assert!</kbd>: This is the simplest assertion macro that takes a Boolean value to assert against. If the value is <kbd>false</kbd>, the test panics, showing the line where the failure happened. This can additionally take in a format string, followed by a corresponding number of variables, for providing custom error messages:</li>
</ul>
<pre>      let a = 23;<br/>      let b = 87;<br/>      assert_eq!(a, b, "{} and {} are not equal", a, b);</pre>
<ul>
<li><kbd>assert_eq!</kbd>: This takes in two values and fails if they are not equal. This can also take in a format string for custom error messages.</li>
<li><kbd>assert_ne!</kbd>: This is similar to <kbd>assert_eq!</kbd> since it takes two values, but only asserts when the values are not equal to each other.</li>
<li><kbd>debug_assert!</kbd>: This is similar to <kbd>assert!</kbd>. Debug assertion macros can be also be used in code other than test code. This is mostly used in code to assert for any contract or invariant that should be held by the code during runtime. These assertions are only effective on debug builds and help catch assertion violations when run in debug mode. When the code is compiled in optimized mode, these macro invocations are completely ignored and optimized away to a no-op. There are similar variants to this such as <kbd>debug_assert_eq!</kbd> and <kbd>debug_assert_ne!</kbd>, which work just like the <kbd>assert!</kbd> class of macros.</li>
</ul>
<p>To compare the values within these assertion macros, Rust relies on traits. For example, the <kbd>==</kbd> inside <kbd>assert!(a == b)</kbd> actually turns into a method call, <kbd>a.eq(&amp;b)</kbd>, which returns a <kbd>bool</kbd> value. The <kbd>eq</kbd> method comes from the <kbd>PartialEq</kbd> trait. Most built-in types in Rust implement the <kbd>PartialEq</kbd> and <kbd>Eq</kbd> traits so that they can be compared. The details of these traits and the difference between <kbd>PartialEq</kbd> and <kbd>Eq</kbd> are discussed in <a href="93373ddb-63dc-4b4c-a42f-7a099818705c.xhtml">Chapter 4</a>, <em>Types, Generics, and Traits.</em></p>
<p class="mce-root"/>
<p>For user-defined types, however, we need to implement these traits. Fortunately, Rust provides us with a convenient macro called <strong>derive</strong>, which takes one or more trait names to implement. It can be used by putting the <kbd>#[derive(Eq, PartialEq)]</kbd> annotation over any user-defined type. Notice the trait names within parentheses. Derive is a procedural macro that simply generates code for <kbd>impl</kbd> blocks for the type on which it appears and implements the trait's methods or any associated functions. We'll discuss these macros when we get to <a href="7143ebcd-54cc-4e31-a2ad-07ce90268584.xhtml">Chapter 9</a>, <em>Metaprogramming with Macros</em>.</p>
<p>With that aside, let's start writing some tests!</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Unit tests</h1>
                
            
            
                
<p>In general, a unit test is a function that instantiates a small portion of an application and verifies its behavior independently from other parts of the code base<strong>.</strong> In Rust, unit tests are usually written within a module. Ideally, they should only aim to cover the module's functionality and its interfaces. </p>


            

            
        
    

        

                            
                    <h1 class="header-title">First unit test</h1>
                
            
            
                
<p>The following is our very first unit test:</p>
<pre>// first_unit_test.rs<br/><br/>#[test] <br/>fn basic_test() { <br/>    assert!(true);<br/>}</pre>
<p>A unit test is written as a function and is marked with a <kbd>#[test]</kbd> attribute. There's nothing complex in the preceding <kbd>basic_test</kbd> function. We have a basic <kbd>assert!</kbd> call passing in <kbd>true</kbd>. For better organization, you may also create a child module called <strong>tests</strong> (by convention) and put all related test code inside it.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Running tests</h1>
                
            
            
                
<p>The way we run this test is by compiling our code in test mode. The compiler ignores the compilation of test annotated functions unless it's told to build in test mode. This can be achieved by passing the <kbd>--test</kbd> flag to <kbd>rustc</kbd> when compiling the test code. Following that, tests can be run by simply executing the compiled binary. For the preceding test, we'll compile it in test mode by running this:</p>
<pre><strong>rustc --test first_unit_test.rs</strong></pre>
<p>With the <kbd>--test</kbd> flag, <kbd>rustc</kbd> puts a <kbd>main</kbd> function with some test harness code and invokes all your defined test functions as threads in parallel. All tests are run in parallel by default unless told to do so with the environment variable <kbd>RUST_TEST_THREADS=1</kbd>. This means that if we want to run the preceding test in single thread mode, we can execute with <kbd>RUST_TEST_THREADS=1 ./first_unit_test</kbd>.</p>
<p>Now, Cargo already has support for running tests, and all of this is usually done internally by invoking <kbd>cargo test</kbd>. This command compiles and runs the test annotated functions for us. In the examples that follow, we will mostly use Cargo to run our tests.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Isolating test code</h1>
                
            
            
                
<p>When our tests grow in complexity, there may be additional helper methods that we might create that only gets used within the context of our test code. In such situations, it is beneficial to isolate the test-related code from the actual code. We can do this by encapsulating all of our test-related code inside a module and putting a <kbd>#[cfg(test)]</kbd> annotation over it.</p>
<p>The <kbd>cfg</kbd> in the <kbd>#[cfg(...)]</kbd> attribute is generally used for conditional compilation and not just limited to test code. It can include or exclude code for different architectures or configuration flags. Here, the configuration flag is <kbd>test</kbd>. You might remember that the tests in the previous chapter were already using this form. This has the advantage that your test code is only compiled and included in the compiled binary when you run <kbd>cargo test</kbd>, and otherwise ignored.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>Say you want to programmatically generate test data for your tests, but there's no reason to have that code in the release build. Let's create a project by running <kbd>cargo new unit_test --lib</kbd> to demonstrate this. In <kbd>lib.rs</kbd>, we have defined some tests and functions:</p>
<pre>// unit_test/src/lib.rs<br/><br/>// function we want to test<br/>fn sum(a: i8, b: i8) -&gt; i8 {<br/>    a + b<br/>}<br/><br/>#[cfg(test)]<br/>mod tests {<br/>    fn sum_inputs_outputs() -&gt; Vec&lt;((i8, i8), i8)&gt; {<br/>        vec![((1, 1), 2), ((0, 0), 0), ((2, -2), 0)]<br/>    }<br/><br/>    #[test]<br/>    fn test_sums() {<br/>        for (input, output) in sum_inputs_outputs() {<br/>            assert_eq!(crate::sum(input.0, input.1), output);<br/>        }<br/>    }<br/>}</pre>
<p>We can run these tests by running <kbd>cargo test</kbd>. Let's go through the preceding code. We generate known input and output pairs in the <kbd>sum_inputs_outputs</kbd> function, which is used by the <kbd>test_sums</kbd> function. The <kbd>#[test]</kbd> attribute keeps the <kbd>test_sums</kbd> function out of our release compilation. However, <kbd>sum_inputs_outputs</kbd> is not marked with <kbd>#[test]</kbd>, and will get included in compilation if it's declared outside the <kbd>tests</kbd> module. By using <kbd>#[cfg(test)]</kbd> with a <kbd>mod tests {}</kbd> child module and encapsulating all the test code and its related functions inside this module, we get the benefit of keeping both the code and the resulting binary clean of the test code.</p>
<p>We also had our <kbd>sum</kbd> function defined as private without the <kbd>pub</kbd> visibility modifier, which means that unit tests within modules also allow you to test private functions and methods. Quite convenient!</p>
<p class="mce-root"/>


            

            
        
    

        

                            
                    <h1 class="header-title">Failing tests</h1>
                
            
            
                
<p>There are also test cases where you will want your API methods to fail based on some input, and you want the test framework to assert this failure. Rust provides an attribute called <kbd>#[should_panic]</kbd> for this. Here's a test that panics and uses this attribute:</p>
<pre>// panic_test.rs<br/><br/>#[test]<br/>#[should_panic]<br/>fn this_panics() {<br/>    assert_eq!(1, 2);<br/>}</pre>
<p>The <kbd>#[should_panic]</kbd> attribute can be paired with a <kbd>#[test]</kbd> attribute to signify that running the <kbd>this_panics</kbd> function should cause a non-recoverable failure, which is called a <strong>panic</strong> in Rust.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Ignoring tests</h1>
                
            
            
                
<p>Another useful attribute for writing tests is <kbd>#[ignore]</kbd>. If your test code is exceedingly heavy, the <kbd>#[ignore]</kbd> annotation enables the test harness to ignore such test functions when running <kbd>cargo test</kbd>. You can then choose to individually run those tests by supplying an <kbd>--ignored</kbd> parameter to either your test runner or the <kbd>cargo test</kbd> command. Here's the code containing a silly loop that, when run using <kbd>cargo test</kbd>, is ignored by default:</p>
<pre>// silly_loop.rs<br/><br/>pub fn silly_loop() {<br/>    for _ in 1..1_000_000_000 {};<br/>}<br/><br/>#[cfg(test)]<br/>mod tests {<br/>    #[test]<br/>    #[ignore]<br/>    pub fn test_silly_loop() {<br/>        ::silly_loop();<br/>    }<br/>}</pre>
<p>Note the <kbd>#[ignore]</kbd> attribute over the <kbd>test_silly_loop</kbd> test function. Here's the output from the ignored test:</p>
<div><img src="img/fe9815c7-ab4a-44d5-a9c2-34f6393962db.png" style="width:37.92em;height:17.50em;"/></div>
<div><strong>Note</strong>: A single test can also be run by supplying the test function name to Cargo, for example, <kbd>cargo test some_test_func</kbd>.</div>


            

            
        
    

        

                            
                    <h1 class="header-title">Integration tests</h1>
                
            
            
                
<p>While unit tests can test the private interface of your crate and individual modules, integration tests are kind of like black box tests that aim to test the end-to-end use of the public interface of your crate from a consumer's perspective. In terms of writing code, there is not a lot of difference between writing integration tests and unit tests. The only difference lies in the directory structure and that the items need to be made public, which is already exposed by the developer as per the design of the crate.</p>
<p class="mce-root"/>


            

            
        
    

        

                            
                    <h1 class="header-title">First integration test</h1>
                
            
            
                
<p>As we stated previously, Rust expects all integration tests to live in the <kbd>tests/</kbd> directory. Files within the <kbd>tests/</kbd> directory are compiled as if they are separate binary crates while using our library under test. For the following example, we'll create a new crate by running  <kbd>cargo new integration_test --lib</kbd>, with the same function, <kbd>sum</kbd> ,as in the previous unit test, but now we have added a <kbd>tests/</kbd> directory, which has an integration test function defined as follows:</p>
<pre>// integration_test/tests/sum.rs<br/><br/>use integration_test::sum;<br/><br/>#[test]<br/>fn sum_test() { <br/>    assert_eq!(sum(6, 8), 14); <br/>} </pre>
<p>We first bring the function <kbd>sum</kbd> in scope. Second, we have a function, <kbd>sum_test</kbd> , that calls <kbd>sum</kbd> and asserts on the return value. When we try to run <kbd>cargo test</kbd>, we are presented with the following error:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/c864b7f9-9d25-452a-8e09-a6faa593ff57.png" style="width:36.83em;height:12.42em;"/></p>
<p>This error seems reasonable. We want the users of our crate to use the <kbd>sum</kbd> function, but in our crate we have it defined as a private function by default. So, after adding the <kbd>pub</kbd> modifier before the <kbd>sum</kbd> function and running <kbd>cargo test</kbd>, our test is green again:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/c2ad6160-52bc-4d26-9cb7-fd8ca6ed0243.png" style="width:38.83em;height:6.33em;"/></p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>Here's a view of the directory tree of our <kbd>integration_test</kbd> example crate:</p>
<pre>. <br/>├── Cargo.lock <br/>├── Cargo.toml <br/>├── src <br/>│   └── lib.rs <br/>└── tests <br/>    └── sum.rs </pre>
<p>As an example of an integration test, this was very trivial, but the gist of it is that when we write integration tests, we use the crate that's being tested, like any other user of a library would use it.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Sharing common code</h1>
                
            
            
                
<p>As is often the case with integration tests, there is some setup and teardown-related code that we might need to put in place before we can actually run our tests. You usually want them to be shared by all of the files in the <kbd>tests/</kbd> directory. For sharing code, we can use modules by either creating them as a directory that shares common code, or use a module <kbd>foo.rs</kbd> and declare in our <kbd>integration</kbd> test files that we depend on it by putting a <kbd>mod</kbd> declaration. So, in our preceding <kbd>tests/</kbd> directory, we added a <kbd>common.rs</kbd> module that has two functions called <kbd>setup</kbd> and <kbd>teardown</kbd>:</p>
<pre>// integration_test/tests/common.rs<br/><br/>pub fn setup() {<br/>    println!("Setting up fixtures");<br/>}<br/><br/>pub fn teardown() {<br/>    println!("Tearing down");<br/>}</pre>
<p>In both of our functions, we can have any kind of fixture-related code. Consider that you have an integration test that relies on the existence of a text file. In our function <kbd>setup</kbd>, we can create the text file, while in our functi0n <kbd>teardown</kbd>, we can clean up our resources by deleting the file.</p>
<p>To use these functions in our integration test code in <kbd>tests/sum.rs</kbd>, we put in the <kbd>mod</kbd> declarations like so:</p>
<pre>// integration_test/tests/sum.rs<br/><br/>use integration_test::sum;<br/><br/>mod common;<br/><br/>use common::{setup, teardown};<br/><br/>#[test]<br/>fn sum_test() { <br/>    assert_eq!(sum(6, 8), 14); <br/>}<br/><br/>#[test]<br/>fn test_with_fixture() {<br/>    setup();<br/>    assert_eq!(sum(7, 14), 21);<br/>    teardown();<br/>}</pre>
<p>We have added another function,  <kbd>test_with_fixture</kbd> , that includes calls to <kbd>setup</kbd> and <kbd>teardown</kbd>. We can run this test with <kbd>cargo test test_with_fixture</kbd>. As you may have noticed from the output, we don't get to see our <kbd>println!</kbd> calls anywhere from within the <kbd>setup</kbd> or <kbd>teardown</kbd> functions. This is because, by default, the test harness hides or captures print statements within test functions to make the test results tidier, and only shows the test harness's outputs. If we want to view print statements within our tests, we can run the test with <kbd>cargo test test_with_fixture -- --nocapture</kbd>, which gives us the following output:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/560e2a59-d90d-4504-b4f1-24f86660a15e.png" style="width:35.50em;height:7.83em;"/></p>
<p>We can see our print statements now. We needed the <kbd>--</kbd> in <kbd>cargo test test_with_fixture -- --nocapture</kbd> because we actually want to pass the <kbd>--nocapture</kbd> flag to our test runner. <kbd>--</kbd> marks the end of arguments for <kbd>cargo</kbd> itself, and any argument following that is passed to the binary being invoked by cargo, which is our compiled binary with test harness.</p>
<p class="mce-root"/>
<p>That's about it for integration tests. At the end of this chapter, we'll create a project where we get to see both unit tests and integration tests work in tandem. Next, we'll learn about documenting Rust code, an overlooked but quite important part of software development.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Documentation</h1>
                
            
            
                
<p>Documentation is a very crucial aspect of any open source software aiming for wide adoption by the programmer community. While your code, which should be readable, tells you how it works, the documentation should tell you about the why and how of the design decisions and example usage of the public APIs of your software. Well documented code with a comprehensive <kbd>README.md</kbd> page boosts the discoverability of your project many times over.</p>
<p>The Rust community takes documentation very seriously and has tools at various levels to make it easy to write documentation for code. It also makes it presentable and consumable for its users. For writing documentation, it supports the markdown dialect. Markdown is a very popular markup language and is the standard these days for writing docs. Rust has a dedicated tool called <strong>rustdoc</strong> that parses markdown doc comments, converts them to HTML, and generates beautiful and searchable documentation pages.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Writing documentation</h1>
                
            
            
                
<p>To write documentation, we have special symbols for marking the start of documentation comments (doc comments hereafter). Docs are written in a similar fashion, the way we write comments, but they are treated differently compared to ordinary comments and are parsed by rustdoc. The doc comments are divided into two levels and use separate symbols to mark the start of the doc comment:</p>
<ul>
<li><strong>Item level</strong>: These comments are meant for items within the module such as structs, enum declarations, functions, trait constants, and so on. They should appear above the item. For single-line comments, they start with <kbd>///</kbd>, while multi-line comments begin with <kbd>/**</kbd> and end with <kbd>*/</kbd>.</li>
<li><strong>Module level</strong>: These are comments that appear at the root level, i.e., <kbd>main.rs</kbd>, <kbd>lib.rs</kbd>, or any other module, and use <kbd>//!</kbd> to mark the start of a line comment – or <kbd>/*!</kbd> for multi-line comments – before ending them with <kbd>*/</kbd>. They are suitable for giving a general overview of your crate and example usage.</li>
</ul>
<p>Within the doc comment, you can write docs using the usual markdown syntax. It also supports writing valid Rust code within backticks (```<kbd>let a = 23;</kbd>```), which becomes part of documentation tests.</p>
<p>The preceding notation for writing comments is actually a syntatic sugar for the <kbd>#[doc="your doc comment"]</kbd> attribute. These are called <strong>doc attributes</strong>. When rustdoc parses the <kbd>///</kbd> or <kbd>/**</kbd> lines, it converts them into these doc attributes. Alternatively, you can also write docs using these doc attributes.<br/></p>


            

            
        
    

        

                            
                    <h1 class="header-title">Generating and viewing documentation</h1>
                
            
            
                
<p>To generate documentation, we can use the <kbd>cargo doc</kbd> command in our project directory. It generates docs in the <kbd>target/doc/</kbd> directory with a bunch of HTML files and predefined stylesheets. By default, it generates docs for a crate's dependencies too. We can tell Cargo to ignore generating docs for dependencies by running <kbd>cargo doc --no-deps</kbd>.</p>
<p>To view the documentation, one can spawn a HTTP server by navigating inside the <kbd>target/doc</kbd> directory. Python's simple HTTP server can come in handy here. However, there's a better way to do this! Passing the <kbd>--open</kbd> option to <kbd>cargo doc</kbd> will open the documentation page directly in your default browser.</p>
<div><kbd>cargo doc</kbd> can be combined with <kbd>cargo watch</kbd> to get a seamless experience in writing documentation and getting live feedback on the generated page for any documentation changes you do on your project.</div>


            

            
        
    

        

                            
                    <h1 class="header-title">Hosting documentation</h1>
                
            
            
                
<p>After your documentation has been generated, you will need to host it somewhere for the public to view and use. There are three possibilities here:</p>
<ul>
<li><strong>docs.rs</strong>: Crates that are hosted on <kbd>crates.io</kbd> get their documentation page automatically generated and hosted on <a href="https://docs.rs">https://docs.rs</a>.</li>
<li><strong>GitHub pages</strong>: You can host your documentation on the <kbd>gh-pages</kbd> branch if your crate is on GitHub.</li>
<li><strong>External website:</strong> You can manage your own web server for hosting documentation. Rust's standard library documentation is a fine example of this: <a href="https://doc.rust-lang.org/std/">https://doc.rust-lang.org/std/</a>.</li>
</ul>
<p>As an added note, if your project's documentation spans more than two to three pages and requires a detailed introduction, then there's a better option to generate book-like documentation. This is done by using the <kbd>mdbook</kbd> project. For more information on that, check out their GitHub page at <a href="https://github.com/rust-lang-nursery/mdBook">https://github.com/rust-lang-nursery/mdBook</a>.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Doc attributes</h1>
                
            
            
                
<p>We mentioned that the doc comments that we write get converted into doc attributes form. Apart from those, there are other doc attributes for documentation that can tweak the generated documentation page, and these are applied either at the crate level or at the item level. They are written like <kbd>#[doc(key = value)]</kbd>. Some of the most useful doc attributes are as follows:</p>
<p><strong>Crate-level attributes</strong>:</p>
<ul>
<li><kbd>#![doc(html_logo_url = "image url")</kbd>: Allows you to add a logo to the top-left of your documentation page.</li>
<li>
<p class="mce-root"><kbd>#![doc(html_root_url = "https://docs.rs/slotmap/0.2.1")]</kbd>: Allows you to set the URL for the documentation page.</p>
</li>
<li><kbd>#![doc(html_playground_url = "https://play.rust-lang.org/")]</kbd>: Allows you to put a run button near the code example in your documentation so that you can run it directly in the online Rust playground.</li>
</ul>
<p><strong>Item-level attributes</strong>:</p>
<ul>
<li><kbd>#[doc(hidden)]</kbd>: Say you have written the documentation for a public function, <kbd>foo</kbd>, as a note to yourself. However, you don't want your consumers to view the documentation. You can use this attribute to tell rustdoc to ignore generating docs for <kbd>foo</kbd>.</li>
<li><kbd>#[doc(include)]</kbd>: This can be used to include documentation from other files. This helps you separate your documentation from code if it's really long.</li>
</ul>
<p>For more attributes like these ones, head over to <a href="https://doc.rust-lang.org/beta/rustdoc/the-doc-attribute.html">https://doc.rust-lang.org/beta/rustdoc/the-doc-attribute.html</a>.</p>
<p class="mce-root"/>


            

            
        
    

        

                            
                    <h1 class="header-title">Documentation tests</h1>
                
            
            
                
<p>It's often a good practice to include code examples with any documentation for your crate's public APIs. There's a caveat in maintaining such examples, though. Your code might change and you might forget to update your examples. Documentation tests (doctests) are there to remind you to update your example code as well. Rust allows you to embed code in backticks within doc comments. Cargo can then run this example code that's been embedded within your documentation, and treats it as part of the unit test suite. This means that documentation examples run every time you run your unit tests, forcing you to update them. Quite amazing!</p>
<p>Documentation tests are also executed via Cargo. We have created a project called <kbd>doctest_demo</kbd> to illustrate documentation tests. In <kbd>lib.rs</kbd>, we have the following code:</p>
<pre>// doctest_demo/src/lib.rs<br/><br/>//! This crate provides functionality for adding things<br/>//!<br/>//! # Examples<br/>//! ```<br/>//! use doctest_demo::sum;<br/>//!<br/>//! let work_a = 4;<br/>//! let work_b = 34;<br/>//! let total_work = sum(work_a, work_b);<br/>//! ```<br/><br/>/// Sum two arguments<br/>///<br/>/// # Examples<br/>///<br/>/// ```<br/>/// assert_eq!(doctest_demo::sum(1, 1), 2);<br/>/// ```<br/>pub fn sum(a: i8, b: i8) -&gt; i8 {<br/>    a + b<br/>}</pre>
<p>As you can see, the difference between module-level and function-level doctests is not much. They are used in pretty much the same way. It is just that the module-level doctests show the overall usage of the crate, covering more than one API surface, while function-level doctests cover just the particular function over which they appear.</p>
<p>Documentation tests run with all the other tests when you run <kbd>cargo test</kbd>. Here's the output when we run <kbd>cargo test</kbd> in our <kbd>doctest_demo</kbd> crate:</p>
<div><img src="img/0edfb5b3-92f4-4e90-8ca8-8d4038260bea.png" style="width:41.08em;height:17.67em;"/></div>


            

            
        
    

        

                            
                    <h1 class="header-title">Benchmarks</h1>
                
            
            
                
<p>When business needs change and your program gets a requirement to perform more efficiently, the first step to take is to find out the areas that are slow in the program. How can you tell where the bottlenecks are? You can tell by measuring individual parts of your program on various expected ranges or on a magnitude of inputs. This is known as benchmarking your code. Benchmarking is usually done at the very last stage of development (but does not have to be) to provide insights on areas where there are performance pitfalls in code.</p>
<p>There are various ways to perform benchmark tests for a program. The trivial way is to use the Unix tool time to measure the execution time of your program after your changes. But that doesn't provide precise micro-level insights. Rust provides us with a built-in micro benchmarking framework. By micro benchmarking, we mean that it can be used to benchmark individual parts of the code in isolation and remains unbiased from external factors. However, it also means that we should not rely solely on micro benchmarks since the real world results can be skewed. Thus, a micro benchmark is often followed by profiling and macro benchmarking of the code. Nonetheless, micro benchmarking is often a starting point for improving the performance of your code as the individual parts contribute a lot to the overall running time of your program.</p>
<p>In this section, we will discuss the tool that Rust provides as a built in for performing micro benchmarks. Rust lowers the bar for writing benchmarking code right from the initial stages of development, rather than doing it as a last resort. The way you run benchmarks is similar to how tests are run, but uses the <kbd>cargo bench</kbd> command instead.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Built-in micro-benchmark harness</h1>
                
            
            
                
<p>Rust's built-in benchmarking framework measures the performance of code by running it through several iterations and reports the average time taken for the operation in question. This is facilitated by two things:</p>
<ul>
<li>The <kbd>#[bench]</kbd> annotation on a function. This marks the function as a benchmark test.</li>
<li>The internal compiler crate <kbd>libtest</kbd> with a <kbd>Bencher</kbd> type, which the benchmark function uses for running the same benchmark code in several iterations. This type resides under the <kbd>test</kbd> crate, which is internal to the compiler.</li>
</ul>
<p>Now, we'll write and run a simple benchmark test. Let's create a new Cargo project by running <kbd>cargo new --lib bench_example</kbd>. No changes to <kbd>Cargo.toml</kbd> are needed for this. The contents of <kbd>src/lib.rs</kbd> is as follows:</p>
<p> </p>
<pre>// bench_example/src/lib.rs<br/><br/>#![feature(test)]<br/>extern crate test;<br/><br/>use test::Bencher;<br/><br/>pub fn do_nothing_slowly() {<br/>    print!(".");<br/>    for _ in 1..10_000_000 {};<br/>}<br/><br/>pub fn do_nothing_fast() {<br/>}<br/><br/>#[bench]<br/>fn bench_nothing_slowly(b: &amp;mut Bencher) {<br/>    b.iter(|| do_nothing_slowly());<br/>}<br/><br/>#[bench]<br/>fn bench_nothing_fast(b: &amp;mut Bencher) {<br/>    b.iter(|| do_nothing_fast());<br/>}</pre>
<p>Note that we had to specify the internal crate <kbd>test</kbd> with the <kbd>external crate</kbd> declaration, along with the <kbd>#[feature(test)]</kbd> attribute. The <kbd>extern</kbd> declaration is needed for crates internal to the compiler. In future versions of the compiler, this might not be needed and you will be able to <kbd>use</kbd> them like normal crates.</p>
<p>If we run our benchmarks by running <kbd>cargo bench</kbd>, we will see the following:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/1489bed5-f538-4cc3-9414-1529bbe4783a.png" style="width:36.17em;height:15.33em;"/></p>
<p>Unfortunately, benchmark tests are an unstable feature, so we'll have to use the nightly compiler for these. Fortunately, with <kbd>rustup</kbd>, moving between different release channels of the Rust compiler is easy. First, we'll make sure that the nightly compiler is installed by running <kbd>rustup update nightly</kbd>. Then, within our <kbd>bench_example</kbd> directory, we will override the default toolchain for this directory by running <kbd>rustup override set nightly</kbd>. Now, running <kbd>cargo bench</kbd> will give the following output:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/2c9be90a-ff60-4a95-bd8a-f27155da64eb.png" style="width:47.50em;height:16.67em;"/></p>
<p class="mce-root"/>
<p>Those are nanoseconds per iteration, with the figure inside the parentheses showing the variation between each run. Our slower implementation was quite slow and variable in running time (as shown by the large <kbd>+/-</kbd> variation).</p>
<p>Inside our functions marked with <kbd>#[bench]</kbd>, the parameter to <kbd>iter</kbd> is a closure with no parameters. If the closure had parameters, they would be inside <kbd>||</kbd>. This essentially means that <kbd>iter</kbd> is passed a function that the benchmark test can run repeatedly. We print a single dot in the function so that Rust won't optimize the empty loop away. If the <kbd>println!()</kbd> was not there, then the compiler would have optimized away the loop to a no-op, and we would get false results. There are ways to get around this, and this is done by using the <kbd>black_box</kbd> function from the <kbd>test</kbd> module. However, even using that does not guarantee that the optimizer won't optimize your code. Now, we also have other third-party solutions for running benchmarks on stable Rust.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Benchmarking on stable Rust</h1>
                
            
            
                
<p>The built-in benchmarking framework provided by Rust is unstable, but fortunately there are community developed benchmarking crates that work on stable Rust. One such popular crate that we'll explore here is <kbd>criterion-rs</kbd>. This crate is designed to be easy to use while at the same time providing detailed information on the benchmarked code. It also maintains the state of the last run, reporting performance regressions (if any) on every run. Criterion.rs generates more statistical reports than the built-in benchmark framework, and also generates helpful charts and graphs using <em>gnuplot</em> to make it understandable to the user.</p>
<p>To demonstrate using this crate, we'll create a new crate called <kbd>cargo new criterion_demo --lib</kbd>. We will add the criterion crate to <kbd>Cargo.toml</kbd> as a dependency under the <kbd>dev-dependencies</kbd> section:</p>
<pre>[dev-dependencies]<br/>criterion = "0.1"<br/><br/>[[bench]]<br/>name = "fibonacci"<br/>harness = false</pre>
<p>We have also added a new section known as <kbd>[[bench]]</kbd>, which indicates to cargo that we have a new benchmark test named <kbd>fibonacci</kbd> and that it does not use the built-in benchmark harness (<kbd>harness = false</kbd>), since we are using the criterion crate's test harness.</p>
<p class="mce-root"/>
<p>Now, in <kbd>src/lib.rs</kbd>, we have a fast and a slow version of a function that computes the nth <kbd>fibonacci</kbd> number (with initial values of <kbd>n<sub>0</sub> = 0</kbd> and <kbd>n<sub>1</sub> = 1</kbd>):</p>
<pre>// criterion_demo/src/lib.rs<br/><br/>pub fn slow_fibonacci(nth: usize) -&gt; u64 {<br/>    if nth &lt;= 1 {<br/>        return nth as u64;   <br/>    } else {<br/>        return slow_fibonacci(nth - 1) + slow_fibonacci(nth - 2);<br/>    }<br/>}<br/><br/>pub fn fast_fibonacci(nth: usize) -&gt; u64 {<br/>    let mut a = 0;<br/>    let mut b = 1;<br/>    let mut c = 0;<br/>    for _ in 1..nth {<br/>        c = a + b;<br/>        a = b;<br/>        b = c;<br/>    }<br/>    c<br/>}</pre>
<p><kbd>fast_fibonacci</kbd> is the bottom-up iterative solution to get the nth fibonacci number, whereas the <kbd>slow_fibonacci</kbd> version is the slow recursive version. Now, criterion-rs requires us to place our benchmarks inside a <kbd>benches/</kbd> directory, which we created at the crate root. Within the <kbd>benches/</kbd> directory, we have also created a file named <kbd>fibonacci.rs</kbd>, which matches our name under the <kbd>[[bench]]</kbd> in <kbd>Cargo.toml</kbd>. It has the following content:</p>
<pre>// criterion_demo/benches/fibonacci.rs<br/><br/>#[macro_use]<br/>extern crate criterion;<br/>extern crate criterion_demo;<br/><br/>use criterion_demo::{fast_fibonacci, slow_fibonacci};<br/>use criterion::Criterion;<br/><br/>fn fibonacci_benchmark(c: &amp;mut Criterion) {<br/>    c.bench_function("fibonacci 8", |b| b.iter(|| slow_fibonacci(8)));<br/>}<br/><br/>criterion_group!(fib_bench, fibonacci_benchmark);<br/>criterion_main!(fib_bench);</pre>
<p>There's quite a lot going on here! In the preceding code, we first declare our required crates and import our the <kbd>fibonacci</kbd> functions that we need to benchmark (<kbd>fast_fibonacci</kbd> and <kbd>slow_fibonacci</kbd>). Also, there is a <kbd>#[macro_use]</kbd> attribute above <kbd>extern crate criterion</kbd>, which means to use any macros from a crate, we need to opt for it using this attribute as they are not exposed by default. It's similar to a <kbd>use</kbd> statement, which is used to expose module items.</p>
<p>Now, criterion has this notion of benchmark groups that can hold related benchmark code. Accordingly, we created a function named <kbd>fibonacci_benchmark</kbd>, which we then pass on to the <kbd>criterion_group!</kbd> macro. This assigns a name of <kbd>fib_bench</kbd> to this benchmark group. The <kbd>fibonacci_benchmark</kbd> function takes in a mutable reference to a <kbd>criterion</kbd> object, which holds the state of our benchmark runs. This exposes a method called <kbd>bench_function</kbd>, which we use to pass in our benchmark code to run in a closure with a given name (above <kbd>fibonacci 8</kbd>). Then, we need to create the main benchmark harness, which generates code with a <kbd>main</kbd> function to run all of it by using <kbd>criterion_main!</kbd>, before passing in our benchmark group,  <kbd>fib_bench</kbd>. Now, it's time to run <kbd>cargo bench</kbd> with the first <kbd>slow_fibonacci</kbd> function inside the closure. We get the following output:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/52a10831-cbb4-457a-816a-6fac29cac734.png" style="width:44.00em;height:17.17em;"/></p>
<p>We can see that the recursive version of our <kbd>fibonacci</kbd> function takes about 106.95 ns to run on average. Now, within the same benchmark closure, if we replace our <kbd>slow_fibonacci</kbd> with our <kbd>fast_fibonacci</kbd> and run <kbd>cargo bench</kbd> again, we'll get the following output:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/b0014a93-911b-4f03-ad70-5f1633c66d0a.png" style="width:42.58em;height:18.42em;"/></p>
<p>Great! The <kbd>fast_fibonacci</kbd> version takes just 7.8460 ns to run on average. That's obvious, but the great thing about this is the detailed benchmark report, which also shows a human-friendly message: Performace has improved. The reason criterion is able to show this regression report is that it maintains the previous state of benchmark runs and uses their history to report changes in performance.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Writing and testing a crate – logic gate simulator</h1>
                
            
            
                
<p>Armed with all of this knowledge, let's start things off with our logic gate simulation crate. We'll create a new project by running <kbd>cargo new logic_gates --lib</kbd>. Starting with primitive gates implemented as functions such as <kbd>and</kbd>, <kbd>xor</kbd>, and so on, we will write unit tests for these gates. Following that, we'll write integration tests by implementing a half adder that uses our primitive gates. During this process, we'll also get to write documentation for our crate.</p>
<p class="mce-root"/>
<p>First off, we'll start with some unit tests. Here's the initial crate code in its entirety:</p>
<pre>//! This is a logic gates simulation crate built to demonstrate writing unit tests and integration tests<br/><br/>// logic_gates/src/lib.rs<br/><br/>pub fn and(a: u8, b: u8) -&gt; u8 {<br/>    unimplemented!()<br/>}<br/><br/>pub fn xor(a: u8, b: u8) -&gt; u8 {<br/>    unimplemented!()<br/>}<br/><br/>#[cfg(test)]<br/>mod tests {<br/>    use crate::{xor, and};<br/>    #[test]<br/>    fn test_and() {<br/>        assert_eq!(1, and(1, 1));<br/>        assert_eq!(0, and(0, 1));<br/>        assert_eq!(0, and(1, 0));<br/>        assert_eq!(0, and(0, 0));<br/>    }<br/><br/>    #[test]<br/>    fn test_xor() {<br/>        assert_eq!(1, xor(1, 0));<br/>        assert_eq!(0, xor(0, 0));<br/>        assert_eq!(0, xor(1, 1));<br/>        assert_eq!(1, xor(0, 1));<br/>    }<br/>}</pre>
<p>We have started with two logic gates, <kbd>and</kbd> and <kbd>xor</kbd>, which have been implemented as functions. We also have tests cases against those that fail when run because they haven't been implemented yet. Note that to represent bit <kbd>0</kbd> and <kbd>1</kbd>, we are using a <kbd>u8</kbd> as Rust does not have a native type to represent bits. Now, let's fill in their implementation, along with some documentation:</p>
<pre>/// Implements a boolean `and` gate taking as input two bits and returns a bit as output<br/>pub fn and(a: u8, b: u8) -&gt; u8 {<br/>    match (a, b) {<br/>        (1, 1) =&gt; 1,<br/>        _ =&gt; 0<br/>    }<br/>}<br/><br/>/// Implements a boolean `xor` gate taking as input two bits and returning a bit as output<br/>pub fn xor(a: u8, b: u8) -&gt; u8 {<br/>    match (a, b) {<br/>        (1, 0) | (0, 1) =&gt; 1,<br/>        _ =&gt; 0<br/>    }<br/>}</pre>
<p>In the preceding code, we just expressed the truth tables of the <kbd>and</kbd> and <kbd>xor</kbd> gates using match expressions. We can see how concise match expressions can be in expressing our logic. Now, we can run the tests by running <kbd>cargo test</kbd>:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/6930937c-7ed3-444d-9d53-f972ffae96f7.png" style="width:31.75em;height:6.25em;"/></p>
<p>All green! We are now ready to write integration tests by implementing a half adder using these gates. A half adder fits in perfectly as an integration test example as it tests the individual components of our crate while they're being used together. Under the <kbd>tests/</kbd> directory, we'll create a file called <kbd>half_adder.rs</kbd> that includes the following code:</p>
<pre>// logic_gates/tests/half_adder.rs<br/><br/>use logic_gates::{and, xor};<br/><br/>pub type Sum = u8;<br/>pub type Carry = u8;<br/><br/>pub fn half_adder_input_output() -&gt; Vec&lt;((u8, u8), (Sum, Carry))&gt; { <br/>    vec![<br/>        ((0, 0), (0, 0)), <br/>        ((0, 1), (1, 0)), <br/>        ((1, 0), (1, 0)), <br/>        ((1, 1), (0, 1)), <br/>    ] <br/>}<br/><br/>/// This function implements a half adder using primitive gates<br/>fn half_adder(a: u8, b: u8) -&gt; (Sum, Carry) {<br/>    (xor(a, b), and(a, b))<br/>}<br/><br/>#[test]<br/>fn one_bit_adder() {<br/>    for (inn, out) in half_adder_input_output() {<br/>        let (a, b) = inn;<br/>        println("Testing: {}, {} -&gt; {}", a, b, out);<br/>        assert_eq!(half_adder(a, b), out);<br/>    }<br/>}<br/></pre>
<p class="mce-root">In the preceding code, we import our primitive gate functions <kbd>xor</kbd> and <kbd>and</kbd>. Following that, we have something like <kbd>pub type Sum = u8</kbd>, which is known as a <strong>type alias</strong>. They are helpful in situations where you either have a type that is cumbersome to write every time or when you have types with complex signatures. It gives another name to our original type and is purely for readability and disambiguation; it has no implications in the way Rust analyzes those types. We then use the  <kbd>Sum</kbd> and <kbd>Carry</kbd> in our <kbd>half_adder_input_output</kbd> function, which implements the truth table for the half adder. This is a convenient helper function to test our <kbd>half_adder</kbd> function that follows it. This function takes in two one-bit inputs and calculates the <kbd>Sum</kbd> and <kbd>Carry</kbd> from them before returning them as a tuple of <kbd>(Sum, Carry)</kbd>. Further ahead, we have our <kbd>one_bit_adder</kbd> integration test function, in which we iterate over our half adder input output pairs and assert against the output of the  <kbd>half_adder</kbd>. By running <kbd>cargo test</kbd>, we get the following output:</p>
<div><img src="img/0d2972a5-d5a3-4bda-8fbe-eb2d072ae584.png" style="width:40.17em;height:23.50em;"/></div>
<p>Great ! Let's also generate documentation for our crate by running <kbd>cargo doc --open</kbd>. The <kbd>--open</kbd> flag opens the page for us to view in a browser. To customize our documentation, we'll also add an icon to our crate docs page. To do this, we need to add the following attribute at the top of <kbd>lib.rs</kbd>:</p>
<pre>#![doc(html_logo_url = "https://d30y9cdsu7xlg0.cloudfront.net/png/411962-200.png")]</pre>
<p>After generation, the documentation page looks like this:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/fb250dfc-08a7-4a13-b628-21c9b54654bd.png"/></p>
<p>This is great! We have come a long way in our testing journey. Next, let's look at the aspect  automating out test suites.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Continuous integration with Travis CI</h1>
                
            
            
                
<p>It is often the case in large software systems that for every change to our code, we want both our unit and integration tests to run automatically. Moreover, in a collaborative project, the manual way is just not practical. Fortunately, Continuous Integration is a practice that aims to automate those aspects of software development. Travis CI is a public continuous integration service that allows you to run your project's tests automatically in the cloud, based on event hooks. One example of an event hook is when new commits are pushed.</p>
<p>Travis is generally used to automate running builds and tests and to report failed builds, but can also be used for creating releases and even deploying them in staging or production environments. We'll focus on one aspect of Travis in this section, performing automated runs of our tests for our project. GitHub already has integration with Travis that can run tests for new commits in our project. To make this happen, we need the following:</p>
<ul>
<li>Our project on GitHub</li>
<li>An account in Travis, which is made by logging in with GitHub</li>
<li>Your project enabled for builds in Travis</li>
<li>A <kbd>.travis.yml</kbd> file at the root of your repository that tells Travis what to run on</li>
</ul>
<p>The first step is to go to <a href="https://travis-ci.org/">https://travis-ci.org/</a> and log in with your GitHub credentials. From there, we can add our GitHub repository in Travis. Travis has good native support for Rust projects and keeps its Rust compiler continuously up to date. It provides a basic version of the <kbd>.travis.yml</kbd> file for Rust projects, which is as follows:</p>
<pre>language: rust <br/>rust: <br/>  - stable <br/>  - beta <br/>  - nightly <br/>matrix: <br/>  allow_failures: <br/>  - rust: nightly </pre>
<p>The Rust project recommends testing against beta and nightly channels too, but you may choose to target just a single version by removing the corresponding lines. This recommended setup runs the tests on all three versions, but allows the fast-moving nightly compiler to fail.</p>
<p>With this <kbd>.travis.yml</kbd> file in your repository, GitHub will inform Travis CI every time you push your code and run your tests automatically. We can also attach build status badges to our repository's <kbd>README.md</kbd> file, which shows a green badge when tests pass and a red badge in when tests fail.</p>
<p>Let's integrate Travis with our <kbd>logic_gates</kbd> crate. For this, we have to add a <kbd>.travis.yml</kbd> file at our crate root. The following is the contents of the <kbd>.travis.yml</kbd> file:</p>
<pre>language: rust<br/>rust:<br/>  - stable<br/>  - beta<br/>  - nightly<br/>matrix:<br/>  allow_failures:<br/>    - rust: nightly<br/>  fast_finish: true<br/>cache: cargo<br/><br/>script:<br/>  - cargo build --verbose<br/>  - cargo test --verbose</pre>
<p>After pushing this to GitHub, we then need to enable Travis for our project on their page, as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/6cf809eb-a568-430d-acdd-dd7942b2ada8.png"/></p>
<p>The preceding screenshot is from my TravisCI account. Now, we'll make a commit to our <kbd>logic_gates</kbd> repository by adding a simple <kbd>README.md</kbd> file to trigger the Travis build runner. While we do this, let's also add a build badge to our <kbd>README.md</kbd> file that will show the status of our repository to consumers. To do this, we'll click the build passing badge on the right:</p>
<p class="mce-root CDPAlignCenter CDPAlign"><img src="img/df44efff-27ec-48b2-aabf-f62f4aa402be.png" style="width:20.92em;height:2.08em;"/></p>
<p>This opens up a popup menu with the badge link:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/28fb3d03-5593-4f32-abfb-a7e09dd74dc1.png"/></p>
<p>We will copy this link and add it to the top in our <kbd>README.md</kbd> file as follows:</p>
<pre>[![Build Status](https://travis-ci.org/$USERNAME/$REPO_NAME.svg?branch=master)](https://travis-ci.org/creativcoder/logic_gates)</pre>
<p>You need to replace <kbd>$USERNAME</kbd> and <kbd>$REPO_NAME</kbd> with your details.</p>
<p>After this change and committing the <kbd>README.md</kbd> file, we will start to see the Travis build starting and succeeding:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/1daa5147-2ee3-4b1a-be63-0e5d20c713c5.png"/></p>
<p>Awesome! If you are feeling more ambitious, you can also try hosting the <kbd>logic_gates</kbd> crate's documentation on your repository's <kbd>gh-pages</kbd> branch on GitHub. You can do this by using the <kbd>cargo-travis</kbd> project, which is available at <a href="https://github.com/roblabla/cargo-travis">https://github.com/roblabla/cargo-travis\</a>.</p>
<p>For an even more versatile CI setup that covers major platforms, you can use the template provided by the trust project, which is available at <a href="https://github.com/japaric/trust">https://github.com/japaric/trust</a>.</p>
<p>Finally, to publish your crate on <em>crates.io</em>, you can follow the directions given in Cargo's reference documentation: <a href="https://doc.rust-lang.org/cargo/reference/publishing.html">https://doc.rust-lang.org/cargo/reference/publishing.html</a>.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Summary</h1>
                
            
            
                
<p>In this chapter, we got acquainted with writing unit tests, integration tests, documentation tests, and benchmarks using both <kbd>rustc</kbd> and the <kbd>cargo</kbd> tool. We then implemented a logic gate simulator crate and got to experience the whole crate development workflow. Later, we learned how to integrate Travis CI for our GitHub project.</p>
<p>In the next chapter, we'll explore Rust's type system and how to use it to express proper semantics in our program at compile time.</p>


            

            
        
    </body></html>