- en: '14'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Exploring the Tokio Framework
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far in this book, we have been building web apps using frameworks and packaging
    them in Docker to be deployed on a server. Building standard servers is useful
    and will enable us to solve a range of problems. However, there will come a point
    in your web development career where a standard REST API server will not be the
    best solution. It is useful to reach for another tool to implement more custom
    solutions.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will explore the **Tokio** framework to enable async programming.
    We will then use the Tokio runtime to build safe custom async systems, by sending
    messages to async code blocks using channels. These messages can even be sent
    over different threads. We will then facilitate async solutions to complex problems
    by implementing the actor model.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Exploring the Tokio framework for async programming
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Working with workers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exploring the actor model for async programming
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Working with channels
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Working with actors in Tokio
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By the end of this chapter, you will be able to create async programs that solve
    complex problems using the actor model. Your async program will not need any external
    infrastructure such as a database, and the implementation of our async program
    will be safe and isolated because you will be able to pass data around your system
    and threads using channels. You will be able to understand and implement the building
    blocks of highly concurrent async programs and network applications.
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, no previous code is needed.
  prefs: []
  type: TYPE_NORMAL
- en: The code for this chapter can be found at [https://github.com/PacktPublishing/Rust-Web-Programming-2nd-Edition/tree/main/chapter14](https://github.com/PacktPublishing/Rust-Web-Programming-2nd-Edition/tree/main/chapter14).
  prefs: []
  type: TYPE_NORMAL
- en: Exploring the Tokio framework for async programming
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Before we explore what Tokio is and how it works, we should try to execute
    some async code in normal Rust. Throughout this chapter, we will be building a
    basic simulation using Tokio. Therefore, the Tokio code that we will be writing
    is in the `simulation` directory as its own Cargo project. Seeing as we are running
    `async` functions in our Rust server code to process views, we can see if we can
    execute a basic `async` function in our `main` function in the `main.rs` file
    with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'This looks simple enough; however, if we try to run our `main` function, we
    get the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we are reminded that our `async` function is a `Hello, world!` message
    because we did not wait for the `hello` function to execute. However, if we implement
    `await` on our `hello` function, we will get the following error:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The `main` function is not `async`. If we try to turn our `main` function into
    an `async` function, we get a very clear error message that the `main` function
    is not allowed to be `async`.
  prefs: []
  type: TYPE_NORMAL
- en: 'We could implement our own structs that implement a `Future` trait and then
    create our own poll method. However, creating our own futures from scratch would
    be excessive for the context of this book, as this book is not dedicated to async
    Rust. Luckily, the Tokio framework comes to the rescue by turning our `main` runtime
    function into an `async` runtime function. To run our `hello` function, we first
    need to add Tokio to our `Cargo.toml` file with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'We then import the following Tokio macro and `Error` struct in our `main.rs`
    file to enable an async runtime:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'We can then apply our Tokio macro to make our `main` function async and execute
    our `hello` function with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we can see that we are either returning a `Result` with an empty tuple,
    which is the same as `None` or `Void` in other languages, or an error. If we return
    an error, we return a struct that implements the `Error` trait that is on heap
    memory due to the `Box` notation. When we run our program now, we will get the
    `hello world` message. From this, we can deduce that our program is blocked until
    the `hello` function has executed. However, the preceding code requires us to
    return something, and there is a bit of boilerplate code in the definition. If
    we drop all imports, we can have the following simpler `main` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we can see that we are not having to bother with `return` definitions,
    and we can do whatever we want in the last statement of the `main` function. We
    still block the thread on `await`, as we can see with the following printout:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that we have got basic `async` functions running in Tokio, we can do an
    experiment. We can run multiple `async` functions and wait for them with the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Running this code will give the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Here, we can see that the operations are executed in the order `main` is executed.
    This means that when we use `await` to wait on a future to complete, the runtime
    is blocked until the future has completed. Even though the `two` future was defined
    before the `three` future, the `three` future executes before the `two` future
    because the `three` future was awaited before the `two` future.
  prefs: []
  type: TYPE_NORMAL
- en: 'So what? What’s the big deal? If our `async` functions are blocking the runtime,
    then why don’t we just define normal functions? We can do one last experiment
    to get to know Tokio: the standard sleep test. First, we need to import the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'We then redefine our `hello` function to sleep for 5 seconds before printing
    out to the terminal with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'We then spawn Tokio tasks when waiting for our futures to execute in our hello
    function. We spawn a Tokio task using `tokio::spawn`. A Tokio task is a light
    weight, non-blocking unit of execution. While Tokio tasks are like OS threads,
    they are not managed by the OS scheduler but by the Tokio runtime instead. The
    Tokio task spawned is run on a thread pool. The spawned task could correspond
    to a thread, but it could also not. It is up to the Tokio runtime. We spawn our
    tasks with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'If our futures block the entire runtime, then the time elapsed will be 15 seconds.
    However, running our program will give us the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Here, we can see that there is some asynchronous order in which the futures
    can be executed. However, the total time is 5 seconds because they are running
    concurrently. Again, at face value, this does not seem too impressive. However,
    this is where it gets exciting. The super smart people building Tokio keep track
    of threading using polling. This is where the Tokio runtime keeps checking to
    see if a future has executed by polling a bit of memory. Because of polling, checking
    up on threads does not take a lot of resources. Because checking up on threads
    does not take a lot of resources, Tokio can literally keep millions of tasks open.
    If there is an `await` instance in the thread and it is blocking the runtime of
    that thread, Tokio will merely switch over to another thread and start executing
    the new thread. A future running in the background would occasionally poll the
    task executor end query if there is a result or not. As a result, Tokio is powerful,
    and therefore we used Tokio as a runtime for our Actix Web server when exploring
    Actix in [*Chapter 3*](B18722_03.xhtml#_idTextAnchor059), *Handling HTTP Requests*.
    Getting to know Tokio will enable us to build our own networking applications
    at a lower level.
  prefs: []
  type: TYPE_NORMAL
- en: While spinning off multiple threads using Tokio is exciting, we must explore
    the trade-offs of working with multiple workers.
  prefs: []
  type: TYPE_NORMAL
- en: Working with workers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'When it comes to defining workers, we can augment the Tokio runtime macro with
    the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we can see that we state that the runtime is multithreaded, and we have
    four worker threads. Workers are essentially processes that run in constant loops.
    Each worker consumes tasks through a channel, putting them in a queue. The worker
    then works through the tasks, executing them in the order received. If a worker
    has finished all the tasks, it will search other queues belonging to other workers,
    stealing tasks if they are available, as seen here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 14.1 – Worker event loops (Work stealing runtime. By Carl Lerche –
    License MIT: https://tokio.rs/blog/2019-10-scheduler#the-next-generation-tokio-scheduler)](img/Figure_14.1_B18722.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 14.1 – Worker event loops (Work stealing runtime. By Carl Lerche – License
    MIT: https://tokio.rs/blog/2019-10-scheduler#the-next-generation-tokio-scheduler)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we know we can alter the number of workers, we can test how the number
    of worker threads affects how our runtime. First, we must change our `hello` function
    to sleep for only 1 second at a time. We then loop through a range of numbers
    where we spawn a task for each iteration of that range, pushing the handle of
    the spawned task to a vector. We then await all the futures in the vector with
    the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'We could keep running the program with a different number of worker threads
    to see how the number of threads affects the time taken. To save you time, this
    has been done, providing the graph shown in *Figure 14**.2*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 14.2 – Time versus the number of workers](img/Figure_14.2_B18722.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14.2 – Time versus the number of workers
  prefs: []
  type: TYPE_NORMAL
- en: We can see that the first four workers have a big effect on the overall time
    of the program. However, the returns sharply diminish as we increase the number
    of workers to more than four. This might be different for you. I got this graph
    because my computer that is running our program has four cores. It is advised
    that we have one worker thread per core.
  prefs: []
  type: TYPE_NORMAL
- en: We have now managed to speed up our program using Tokio worker threads. We have
    also gotten a deeper appreciation for the trade-off of worker threads and how
    they process tasks. However, what advantage is there to understanding this? We
    could just use a higher-level framework like Actix Web or Rocket to concurrently
    handle API endpoints. Yes, higher-level frameworks are useful and do solve a problem,
    but these are just one solution to the problems. In the next section, we will
    cover the actor model as this is an asynchronous solution that can run in a program
    or a web server depending on your needs.
  prefs: []
  type: TYPE_NORMAL
- en: Exploring the actor model for async programming
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you have coded complex solutions to complex problems before in an object-oriented
    fashion, you will be familiar with objects, attributes, and class inheritance.
    If you are not familiar, do not worry—we are not going to implement them in this
    chapter. However, it is advised that you read up on the concepts of object-oriented
    programming to gain a full appreciation for the actor model.
  prefs: []
  type: TYPE_NORMAL
- en: 'For objects, we have a range of processes and an encapsulated state around
    those processes, which can be attributes of the object. Objects are useful for
    compartmentalizing logic and state around a concept or process. Some people merely
    see objects as a tool to reduce repeated code; however, objects can be used as
    interfaces between modules or can be used to orchestrate processes. Objects are
    the cornerstone of many complex systems. However, when it comes to asynchronous
    programming, objects can get messy—for instance, when we have two objects referencing
    data from another object or in general when we have shared common resources between
    objects, modifying them simultaneously, as seen in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 14.3 – Objects and async](img/Figure_14.3_B18722.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14.3 – Objects and async
  prefs: []
  type: TYPE_NORMAL
- en: In this diagram, we can imagine a system where *Object C* is keeping track of
    investments. We have a rule coded into *Object C* that we do not spend over £50\.
    However, *Object A* and *Object B* are both performing processes that invest in
    different stocks. For a range of reasons, from network latency to maybe different
    price calculation strategies, the processes for deciding to invest in a stock
    can vary. Even though both *Object A* and *Object B* get approved by getting the
    total amount already invested from *Object C*, *Object B* places the order first
    due to *Object B*’s process finishing first. So, when *Object A* finishes its
    process and places an order, it could tip our total investment over £50\. This
    is a data race problem. We can potentially spend over our investment budget because
    two competing investment executions are operating too close to each other. When
    we consider that we could be keeping track of potentially hundreds of positions,
    it will become certain that data races will end up breaking the rules of our strategy.
  prefs: []
  type: TYPE_NORMAL
- en: 'To solve the data race problem, we could implement a database, or try to keep
    an eye on all the threads running to implement locks in the form of Mutexes, RwLocks,
    and so on. However, the database solution requires more memory, infrastructure,
    and code to handle the data. The data is also persisted when the program has been
    shut down, which adds to the complexity of the management. The locking system
    and keeping track of common shared resources also introduce potential bugs and
    excessive complexity for the simple problem that we have defined. This is where
    actors come in. Actors are essentially units of computation with their own state.
    However, it must be noted that actors are not free; they require heavier RAM usage.
    Also, actors can die, which will also kill their state, so database backups can
    be helpful to persist the state if and when actors die. Actors only communicate
    through channels using messages. These messages are queued and then processed
    in the order the messages were sent. This gives us the following system dynamic:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 14.4 – Actors and async](img/Figure_14.4_B18722.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14.4 – Actors and async
  prefs: []
  type: TYPE_NORMAL
- en: Here, we can see that *Actor C* accepts messages and places an order if we have
    not exceeded our investment budget. We can have hundreds of actors sending buy-and-sell
    messages to *Actor C* and still be confident that the budget would not be exceeded.
    Our system does not get increasingly complicated as we add more actors. There
    is nothing stopping us from getting our *Actor C* to send messages to other actors
    to stop or increase the number of buy-or-sell positions, depending on the current
    state of our investment budget.
  prefs: []
  type: TYPE_NORMAL
- en: 'To build more complex systems, you must be familiar with the following terms:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Actor**: A unit of work that can contain state and modifies that state by
    processing messages it receives. You never have reference to an actor state or
    actor directly.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Actor reference**: A handle to an actor. This allows you to send the actor
    messages without knowing its implementation type or location on the network. All
    I need to know is that if we send a message to an actor, we get *X* back. We do
    not need to know if the actor is local somewhere else.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Actor system**: A collection of actors that exist inside a single process
    and communicate via in-memory message passing.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cluster**: A collection of networked actor systems whose actors communicate
    via TCP message passing.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What makes this exciting is that we can achieve asynchronism without having
    to rely on a database or on keeping track of threads. We can run it all in our
    Tokio runtime in one static binary! This is very powerful. However, there is nothing
    stopping us from using the actor model on a microservices-cluster scale in the
    form of nanoservices. At the time of writing this book, nano services are lightly
    written about and used by some companies such as Netflix. However, with what we
    have explored with Rust and distroless containers, we can deploy Rust servers
    into a cluster at 50 MB a server. With what we have covered so far in this book,
    there is nothing stopping you from pushing the boundaries and building nano services,
    and implementing the actor model using nano services.
  prefs: []
  type: TYPE_NORMAL
- en: 'The actor model is being used in a lot of IoT devices and real-time event systems.
    Some applications that make use of the actor model are listed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Event-driven applications (chat, workflow, CRM)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finance (pricing, fraud detection, algorithmic trading)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gaming (multi-player)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Analytics and monitoring
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Marketing automation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Systems integration
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: IoT (healthcare, transportation, security)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'OK—we may never truly understand Hollywood actors, but at least we are familiar
    with computational actors. With the high-level concepts out of the way, we can
    move on to constructing the building blocks of an actor system: actors. Before
    we work with actors, we need to get actors to communicate with each other. This
    is achieved using channels in Tokio.'
  prefs: []
  type: TYPE_NORMAL
- en: Working with channels
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We can experiment with channels by rewriting our `main.rs` file. First, we
    need to import channels and implement the `main` trait for the `main` function
    with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we can see that we import the `mpsc` module. `mpsc`. We can now create
    our channel and spawn a thread that sends multiple messages to a receiver down
    the channel we created in our `main` function with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we can see that the creation of a channel returns a tuple, which we unpack
    to transmit (`tx`) and receive (`rx`). We then loop through a range of integers
    from 0 to 10, sending them down the channel we created. If there is an error,
    we print it out and return an empty tuple, breaking the loop. In the following
    loop, we print out what we sent down the channel. We can then receive the messages
    with the code shown next:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'It must be noted that split halves of channels implement the `Iterator` trait,
    enabling us to read messages from these channels in a `while` loop. If we run
    our code now, we get the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: The printout continues to `9`, but we get the idea of what is going on. We are
    not sending all our messages and then processing them. Both code blocks are executing
    side by side, sending and receiving messages. If we make one of the code blocks
    sleep between iterations, we will still get the same printout.
  prefs: []
  type: TYPE_NORMAL
- en: 'While getting the basis of async message sending and receiving is a nice step
    in the right direction, it is not useful. Right now, we are just sending a number.
    If we want to be able to implement actors that communicate with each other, we
    need to be able to send more comprehensive messages over the channel. To work
    out how to do this, we can inspect the `channel` source code, which reveals the
    following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'We can see that the `channel` function is implementing generics. The sender
    and receiver can send anything if it is consistent, as denoted in the `(Sender<T>,
    Receiver<T>)` return type. Now that we know the `channel` function can load any
    type, we can create a message struct outside of the `channel` function with the
    following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we have a struct that has an order, which can either be `BUY` or `SELL`.
    Our `Message` struct also has a ticker to denote the name of the stock being processed
    and the amount of stock being processed. Inside our `main` function, we then pass
    our `Message` struct into the `channel` function and define the stocks that we
    are going to buy with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that our orders are defined, we loop through the orders, sending and receiving
    them with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Running our program now gives us the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'We can see here that we are sending and receiving messages across the channel.
    However, it must be noted before we move on that if we increase the size of the
    buffer passed into the `channel` function from 1 to 300, we get the following
    printout:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: This is because the buffer is so large that multiple messages can be sent without
    having to wait for the channel to be read (drained) until there is a new buffer
    that is more available.
  prefs: []
  type: TYPE_NORMAL
- en: Working with actors in Tokio
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This will be the last time we rewrite our `main.rs` file. However, once we
    have finished this section, we will have built a basic actor model system. In
    our system, we will create an actor that keeps track of the orders so that we
    do not exceed our budget threshold. We then need to build an actor that sends
    the order, resulting in the following process:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 14.5 – Our stock order interaction for actors](img/Figure_14.5_B18722.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14.5 – Our stock order interaction for actors
  prefs: []
  type: TYPE_NORMAL
- en: 'We can see that this time round, we need to send the address of the actor that
    is making the order with the order message. This is a design choice because, in
    our system, *order* actors spin up and die quickly after the order has been made.
    We cannot keep track of the addresses for all the *order* actors in our program
    in our *order book* actor. Instead, the *order book* actor can get the address
    from the message to send the response to the *order* actor. First, we must import
    the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: Here, we import the `mpsc` channel to send the message to the *order book*.
    We then import the `oneshot` channel to facilitate the outcome being sent back
    to the *order*. A `oneshot` channel is a channel that stays open until a message
    is sent. This is because a `oneshot` channel has a capacity/buffer size of one,
    so it is bounded to only one message being sent before the channel is closed.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we have imported all that we need, we can move on to defining the
    message with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we can see that we have attached the `Sender` struct, which enables the
    receiver to send values to the sender through a channel. With this message, we
    can build out our *order book* actor with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'The state of the *order book* actor will live on throughout the lifetime of
    the program. The `receiver` field will be used to accept incoming messages from
    all *order* actors, and a decision on how to process the order will be made on
    the total invested and the investment cap that we define when we are creating
    the actor. We now must implement functions that create the *order book* actor,
    handle incoming messages, and run the actor with the following outline:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'We can start with the constructor (the `new` function), which takes the following
    form:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'The implementation of the constructor is not surprising. We merely pass in
    a receiver and the investment cap, and automatically set the total invested to
    `0`. Now that the *order* actor can be constructed, we can handle the messages
    the *order* actor received with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: Here, we have kept the implementation basic. If the new order brings our invested
    capital over our threshold, we print out that we have rejected the order and return
    a `0`. If our new order does not breach the threshold, we then print out that
    we are processing the order and send a `1`. For our example, the *order* actor
    is not going to act on the response from the *order book* actor; however, if you
    were to build in a system where another order is placed (such as a sell order),
    it is advised that you create another *order* actor based on the outcome.
  prefs: []
  type: TYPE_NORMAL
- en: 'The only function left for our *order book* actor is the `run` function, which
    is defined with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: Here, we merely wait for messages until all the senders in our channel have
    been killed. If a message is sent to our actor, we process it with our `handle_message`
    function.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our *order book* actor can now be constructed, run, and receive messages returning
    a response through a channel with three separate functions. We need to build an
    *order* actor struct so that we can send messages to our *order book* actor. First,
    we define our order fields with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we need to define the ticker symbol that we are buying, the amount that
    we are buying, and the type of order. We then have the `Sender` struct so that
    we can send messages to the *order book*. For the *order* actor, we only need
    two functions: the `constructor` function and the `send` function. This is because
    our *order* actor is the one sending the initial message, so the *order* actor
    does not need a separate function to wait for messages. Our two functions for
    our *order* actor have the following outline:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'At this point in time, you should be able to code the constructor for the *order*
    actor yourself. If you stop to have an attempt at this, your code should look
    like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: Here, we merely pass the parameters into the creation of the struct, with the
    `order` field being automatically set to `BUY`.
  prefs: []
  type: TYPE_NORMAL
- en: 'With the constructor built, the only function left to define is the `send`
    function, which takes the following form:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: Here, we set up a one-shot channel that will close once the response from the
    *order book* actor has been received. We then package our message with the fields
    of our *order* actor struct and include the address of the *order* actor in the
    `respond_to` field of the message. The *order* actor then sends the message and
    awaits a response, which we merely print out as it is an example.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our system components are now built. We can now orchestrate our actors to work
    with each other in our `main` function with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: Here, we define the channel and clone the sender to the channel once so that
    we have two senders for the same channel. This is because we have two Tokio threads
    sending order messages. We then create our *order book* actor and run it. If we
    cloned another sender but did not use it, our program would hang forever until
    we shut it down because the *order book* actor would be waiting for all senders
    for the channel to be killed before stopping.
  prefs: []
  type: TYPE_NORMAL
- en: 'Inside our threads, we will simply be sending a lot of stocks using loops with
    the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'It must be noted that we drop the `tx_one` and `tx` transmitters after we have
    sent all of our messages to signal early the task has completed, instead of having
    to wait for the end of the runtime to close the channel. We have two threads running
    because we want to properly check if our *order book* is safe to handle concurrent
    messages. If we run our program, we get the following printout:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: Here, we can see messages are being sent and processed to our *order book* actor
    in an async manner. However, no matter how many times you run the program, you
    will never exceed your threshold of investment.
  prefs: []
  type: TYPE_NORMAL
- en: And here we have it. Tokio enables us to run async code in the `main` function,
    and the actor model enables us to build safe async code that is easy to understand
    without having to rely on locks, handling of threads, passing state over threads,
    or external infrastructure such as a database. This does not mean that we should
    run around applying the actor model to everything. However, if you want to write
    safe async code that has a simple, testable implementation without external infrastructure
    and fast access to local memory, then the actor model combined with Tokio is very
    powerful.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we managed to revisit async programming. Initially, we explored
    the Tokio framework by looking into what the Tokio framework enabled us to do
    and then implementing basic async code, which was then implemented by the Tokio
    framework. We then increased the number of worker threads to demonstrate the point
    that we get diminishing returns when we simply increase the number of worker threads.
    We then worked with channels to facilitate sending messages through these channels.
    This enabled us to send data between different areas of the code even if the code
    is running in a different thread.
  prefs: []
  type: TYPE_NORMAL
- en: However, while async programming with the Tokio framework is interesting and
    fun, the basic combination of Tokio and async programming with channels does not
    directly lead to practical applications by itself. To gain some practical skills
    with Tokio and async programming, we explored the actor framework. This is where
    we define structs with their own state, and then communicate between the structs
    that we now call actors using channels. We then used actors to build a basic system
    that places orders where the amount of money invested does not exceed a defined
    threshold, even though we are placing these orders in an async manner. Implementing
    the actor model in Tokio has enabled us to build safe async systems without having
    any external infrastructure such as a database. In the next chapter, we take the
    ability to build custom async systems to the next level by building TCP listeners
    for our Tokio async application, meaning that we can listen for commands sent
    to our application from other applications and clients across a network.
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Tokio documentation: [https://tokio.rs/tokio/tutorial](https://tokio.rs/tokio/tutorial'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: )
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: How does an actor model prevent data race issues?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How can we engineer a two-way communication where an actor can send a message
    to another actor and get a response back?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What happens to our program if we have two actors sending one message each to
    a third actor but we have cloned three instances of the sender for the MPSC channel
    facilitating the communication between the actors?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What are the advantages of using channels and messages to communicate data between
    code blocks?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Answers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The actor model is where actors send messages to each other. Each actor has
    a queue for processing the incoming messages for the actor. Because of this, the
    incoming messages are processed in the order they are received.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The actor receiving the initial message has the receiver of the MPSC channel.
    The actor sending the initial message has the sender for the MPSC channel and
    creates a one-shot channel. The actor sending the initial message then sends the
    sender from the one-shot channel in the initial message. The actor sending the
    initial message then waits for the actor receiving the initial message to process
    the data and then uses the sender in the initial sender to send back a response.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Our program will run as we expect; however, only two of the senders for the
    MSPC channel will be killed as we only have two actors that are sending messages.
    This means that one sender will be left over. As one sender is not used up, the
    channel is not closed, so the receiving actor will continue to keep the program
    running indefinitely.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Channels and messages give us a lot of flexibility. We can send messages across
    threads. We also do not have to pass data across multiple different areas of code.
    If a block has a connection to a channel, the code block can receive/send data.
    We also must note that we can implement different patterns. For instance, we can
    have a message emitted into a channel and received by multiple subscribers. We
    can also enforce the direction of traffic or rules such as one-shot. This means
    we have a lot of control over the flow of the data.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
