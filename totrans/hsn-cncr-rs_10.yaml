- en: Futurism – Near-Term Rust
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 未来主义——近期的 Rust
- en: We've covered a lot of material in this book.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本书我们已经涵盖了大量的内容。
- en: If you already knew parallel programming well from another systems programming
    language, I hope that now you've got a confident handle on the way Rust operates.
    Its ownership model is strict, and can feel foreign at first. Unsafe Rust, if
    my own experiences are any kind of general guide, feels like more familiar ground.
    I hope that you too have come to appreciate the general safety of Rust, as well
    as its ability to do fiddly things in memory when needed. I find being able to
    implement unsafe code that is then wrapped up in a safe interface nothing short
    of incredible.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你已经从另一种系统编程语言中很好地了解了并行编程，我希望你现在对 Rust 的操作方式有了自信的掌握。它的所有权模型是严格的，一开始可能会感觉陌生。如果我的个人经验可以作为一个普遍的指南，那么不安全的
    Rust 感觉更熟悉。我希望你也开始欣赏 Rust 的一般安全性，以及它在需要时在内存中执行繁琐操作的能力。我发现能够实现不安全代码，然后将其封装在安全接口中，这对我来说是不可思议的。
- en: If you knew parallel programming fairly well from a high-level, garbage-collected
    programming language, then I hope that this book has served as an introduction
    to parallel programming at a systems level. As you know, memory safety does not
    guarantee correct operation, hence this book's continual focus on testing—generative
    and fuzz, in addition to performance inspection—and careful reasoning about models.
    Rust, I have argued, is one of the easier systems languages to do parallel programming
    well in because of the language's focus on ownership management with lifetimes
    and the strong, static type system. Rust is not immune to bugs—in fact, it's vulnerable
    to a wide variety—but these are common to all languages on modern hardware, and
    Rust does manage to solve a swath of memory-related issues.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你已经从高级、垃圾回收的编程语言中相当熟悉并行编程，那么我希望这本书已经作为系统级并行编程的入门为你提供了帮助。正如你所知，内存安全并不能保证正确运行，因此这本书持续关注测试——生成性和模糊测试，以及性能检查——并对模型进行仔细推理。我主张，Rust
    由于语言对所有权管理和生命周期的关注以及强大的静态类型系统，是易于进行良好并行编程的系统语言之一。Rust 并非对错误免疫——事实上，它容易受到广泛的错误影响——但这些在现代硬件上的所有语言都是共通的，而且
    Rust 确实设法解决了一系列与内存相关的问题。
- en: If you already knew Rust, but didn't know much about parallel programming, I
    very much hope that this book has managed to convince you of one thing—concurrency
    is not magic. Parallel programming is a wide, wide field of endeavor, one that
    takes a great deal of study, but it can be understood and mastered. Moreover,
    it need not be mastered all at once. The shape of this book argues for one path
    among several. May this book be the first of many on your journey.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你已经了解 Rust，但不太了解并行编程，我非常希望这本书已经设法让你相信了一件事——并发不是魔法。并行编程是一个广泛的领域，需要大量的研究，但它可以理解和掌握。此外，它不必一次性掌握。这本书的形状为多条路径中的一条提供了论据。希望这本书能成为你旅程中的第一本书。
- en: Whatever your background, thank you for reading through to the end. I know that,
    at times, the material covered was not easy and it must have taken some real willpower
    to get through it all. I appreciate it. I wrote this book to be what I would have
    wanted for myself ten years ago. It was a real pleasure getting the opportunity
    to write it out for you.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 无论你的背景如何，感谢你阅读到最后一页。我知道，有时覆盖的材料并不容易，完成这一切肯定需要真正的意志力。我非常感激。我写这本书是为了满足我十年前的愿望。有机会把它写出来给你看，这是一件真正令人愉快的事情。
- en: 'By the end of this chapter, we will have:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，我们将：
- en: Discussed the future of SIMD in Rust
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 讨论了 Rust 中 SIMD 的未来
- en: Discussed the future of async IO in Rust
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 讨论了 Rust 中异步 I/O 的未来
- en: Discussed the possibility of specialization being stablized and in what fashion
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 讨论了专业化的稳定性和其可能的形式
- en: Discussed more extensive testing methods for Rust
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 讨论了 Rust 的更广泛的测试方法
- en: Introduced various avenues to get involved with the Rust community
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介绍了参与 Rust 社区的各种途径
- en: Technical requirements
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: This chapter has no software requirements.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 本章没有软件要求。
- en: You can find the source code for this book's projects at [https://github.com/PacktPublishing/Hands-On-Concurrency-with-Rust](https://github.com/PacktPublishing/Hands-On-Concurrency-with-Rust).
    Chapter 10 has its source code under `Chapter10/`.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在 [https://github.com/PacktPublishing/Hands-On-Concurrency-with-Rust](https://github.com/PacktPublishing/Hands-On-Concurrency-with-Rust)
    找到这本书项目的源代码。第 10 章的源代码位于 `Chapter10/`。
- en: Near-term improvements
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 近期改进
- en: The focus of 2018's Rust development has been stabilization. Since the 1.0 days
    in 2015, many important crates were nightly-only, whether because of modifications
    to the compiler or because of the fear of standardizing too quickly on awkward
    APIs. This fear was reasonable. At the time, Rust was a new language and it changed
    *very* drastically in the lead-up to 1.0\. A new language takes time to resolve
    into its natural style. By the end of 2017, the community had come to a general
    feeling that a stabilization cycle was in order, that some natural expression
    of the language had more or less been established, and that in areas where this
    was not true, it could be established, with some work.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 2018年Rust开发的重点是稳定化。自2015年的1.0版本以来，许多重要的crate仅限于夜间使用，无论是由于编译器的修改还是因为担心过于快速地标准化令人尴尬的API。这种担忧是合理的。当时，Rust是一种新的语言，它在1.0版本前的变化非常剧烈。一种新的语言需要时间来形成其自然风格。到2017年底，社区普遍认为需要一个稳定周期，即语言的某些自然表达已经或多或少地确立，而在这些方面没有确立的地方，通过一些工作可以确立。
- en: Let's discuss this stabilization work with regards to the topics we've followed
    throughout the book.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们讨论一下与书中所讨论的主题相关的这个稳定化工作。
- en: SIMD
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: SIMD
- en: In this book, we discussed thread-based concurrency. In [Chapter 8](d4802512-564b-4037-9407-b6035bd38f31.xhtml),
    *High-Level Parallelism – Threadpools, Parallel Iterators, and Processes*, we
    took to a higher level of abstraction with Rayon's parallel iterators. Underneath,
    as we saw, rayon uses a sophisticated work-stealing threadpool. Threads are merely
    one approach to concurrency on modern CPUs. In a sense, serial programs are parallel
    on CPUs with deep lookahead pipelines and sophisticated branch predictors, as
    we saw in [Chapter 2](8c61da2f-08c8-40be-89d4-d8afa8510850.xhtml), *Sequential
    Rust Performance and Testing*. Exploiting this parallelism is a matter of carefully
    structuring your data and managing access to it, among the other details we discussed.
    What we have not gone into in this book is how to exploit a modern CPUs' ability
    to perform the same operation on contiguous memory in parallel *without* resorting
    to threads—vectorization. We haven't looked at this because, as I write this,
    the language is only now getting minimal support in the standard library for vectorization
    instructions.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在这本书中，我们讨论了基于线程的并发。在第8章[高级并行性 – Threadpools, Parallel Iterators, and Processes](d4802512-564b-4037-9407-b6035bd38f31.xhtml)中，我们通过Rayon的并行迭代器达到了更高的抽象层次。正如我们所看到的，rayon使用了一个复杂的工作窃取线程池。线程只是现代CPU上实现并发的一种方法。从某种意义上说，具有深度预取流水线和复杂的分支预测器的CPU上的串行程序是并行的，正如我们在第2章[顺序Rust性能和测试](8c61da2f-08c8-40be-89d4-d8afa8510850.xhtml)中看到的。利用这种并行性是一个精心设计数据结构并管理对其访问的问题，以及其他我们讨论的细节。在这本书中，我们没有探讨如何利用现代CPU并行执行连续内存中相同操作的能力，而不需要求助于线程——向量化。我们没有探讨这一点，因为在我写这篇文章的时候，该语言的标准库中只为向量化指令提供了最小限度的支持。
- en: 'Vectorization comes in two variants—MIMD and SIMD. MIMD stands for multiple
    instructions, multiple data. SIMD stands for single instructions, single data.
    The basic idea is this: A modern CPU can apply an instruction to a contiguous,
    specifically sized block of data in parallel. That''s it. Now, consider how many
    loops we''ve written in this book where we''ve done the exact same operation to
    every element of the loop. More than a few! Had we investigated string algorithms
    or looked into doing numeric calculations—encryption, physics simulations, or
    the like—we would have had more such loops in this book.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 向量化有两种变体——MIMD和SIMD。MIMD代表多个指令，多个数据。SIMD代表单指令，单数据。基本思路是这样的：现代CPU可以并行地将一条指令应用于连续的、特定大小的数据块。仅此而已。现在，考虑一下在这本书中我们编写了多少个循环，其中我们对循环的每个元素都执行了完全相同的操作。不止几个！如果我们调查了字符串算法或者考虑进行数值计算——加密、物理模拟等——那么在这本书中就会有更多这样的循环。
- en: As I write this, the merger of SIMD vectorization into the standard library
    is held up behind RFC 2366 ([https://github.com/rust-lang/rfcs/pull/2366](https://github.com/rust-lang/rfcs/pull/2366)),
    with ambitions to having x86 SIMD in a stable channel by year's end, with other
    architectures to follow. The reader may remember from [Chapter 1](5f3aec9d-fd53-48ff-9ba8-43ce13e91cff.xhtml),* Preliminaries
    – Machine Architecture and Getting Started with Rust,* that the memory systems
    of x86 and ARM are quite different. Well, this difference extends to their SIMD
    systems. It *is* possible to exploit SIMD instructions using stable Rust via the
    stdsimd ([https://crates.io/crates/stdsimd](https://crates.io/crates/stdsimd))
    and simd ([https://crates.io/crates/simd](https://crates.io/crates/simd)) crates.
    The stdsimd crate is the best for programmers to target as it will eventually
    be the standard library implementation.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 当我写下这些文字时，SIMD向量化合并到标准库的进程被RFC 2366（[https://github.com/rust-lang/rfcs/pull/2366](https://github.com/rust-lang/rfcs/pull/2366)）所阻碍，目标是到年底前将x86
    SIMD纳入稳定渠道，其他架构随后跟进。读者可能还记得[第一章](5f3aec9d-fd53-48ff-9ba8-43ce13e91cff.xhtml)，“预备知识——机器架构和Rust入门”，其中提到x86和ARM的内存系统相当不同。嗯，这种差异也扩展到了它们的SIMD系统。确实可以通过稳定的Rust通过stdsimd（[https://crates.io/crates/stdsimd](https://crates.io/crates/stdsimd)）和simd（[https://crates.io/crates/simd](https://crates.io/crates/simd)）crate来利用SIMD指令。对于程序员来说，stdsimd
    crate是最好的目标，因为它最终将成为标准库的实现。
- en: A discussion of SIMD is beyond the scope of this book, given the remaining space.
    Suffice it to say that getting the details right with SIMD is roughly on a par
    with the difficulty of getting the details right in atomic programming. I expect
    that, post stabilization, the community will build higher-level libraries to exploit
    SIMD approaches without requiring a great deal of pre-study, though potentially
    with less chance for finely tuned optimizations. The faster ([https://crates.io/crates/faster](https://crates.io/crates/faster))
    crate, for example, exposes SIMD-parallel iterators in the spirit of rayon. The
    programming model there, from an end-user perspective, is extremely convenient.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 由于剩余空间有限，关于SIMD的讨论超出了本书的范围。简单来说，正确处理SIMD的细节与正确处理原子编程的细节难度相当。我预计，在稳定化之后，社区将构建高级库来利用SIMD方法，而无需进行大量的预先学习，尽管可能优化空间较小。例如，faster（[https://crates.io/crates/faster](https://crates.io/crates/faster)）crate以rayon的精神暴露了SIMD并行迭代器。从最终用户的角度来看，那里的编程模型极其方便。
- en: Hex encoding
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 十六进制编码
- en: 'Let''s look at an example from the stdsimd crate. We won''t dig in too deeply
    here; we''re only out to get a sense of the structure of this kind of programming.
    We''ve pulled stdsimd at `2f86c75a2479cf051b92fc98273daaf7f151e7a1`. The file
    we''ll examine is `examples/hex.rs`. The program''s purpose is to `hex` encode
    stdin. For example:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看stdsimd crate的一个例子。我们在这里不会深入挖掘；我们只是想对这种编程的结构有一个大致的了解。我们已经拉取了stdsimd在`2f86c75a2479cf051b92fc98273daaf7f151e7a1`。我们将要检查的文件是`examples/hex.rs`。程序的目的是对stdin进行`hex`编码。例如：
- en: '[PRE0]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Note that this requires a nightly channel, and not a stable one, we've used
    so far in this book. I tested this on nightly, 2018-05-10\. The details of the
    implementation are shifting so rapidly and rely on such unstable compiler features
    that you should make sure that you use the specific nightly channel that is listed,
    otherwise the example code may not compile.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，这需要nightly渠道，而不是我们在这本书中迄今为止所使用的稳定渠道。我在nightly，2018-05-10上进行了测试。实现细节变化非常快，依赖于如此不稳定的编译器特性，因此您应该确保使用列出的特定nightly渠道，否则示例代码可能无法编译。
- en: 'The preamble to `examples/hex.rs` contains a good deal of information we''ve
    not seen in the book so far. Let''s take it in two chunks and tease out the unknowns:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '`examples/hex.rs`的序言部分包含了许多我们在这本书中尚未见过的信息。让我们分两块来看，并揭示未知的内容：'
- en: '[PRE1]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Because we've stuck to stable Rust, we've not seen anything like `#![feature(stdsimd)]`
    before. What is this? Rust allows the adventurous user to enable in-progress features
    that are present in rustc, but that are not yet exposed in the nightly variant
    of the language. I say adventurous because an in-progress feature may maintain
    a stable API through its development, or it may change every few days, requiring
    updates on the consumer side. Now, what is `cfg_attr`? This is a conditional compilation
    attribute, turning on features selectively. You can read all about it in *The
    Rust Reference*, linked in the *Further reading* section. There are many details,
    but the idea is simple—turn bits of code on or off depending on user directives—such
    as testing—or the running environment.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 因为我们坚持使用稳定的 Rust，所以我们之前没有见过 `#![feature(stdsimd)]` 这样的东西。这是什么？Rust 允许有冒险精神的用户启用
    rustc 中存在但尚未在语言的夜间版本中公开的功能。我说冒险是因为一个正在进行中的功能可能在其开发过程中保持稳定的 API，或者它可能每隔几天就改变一次，需要消费者端的更新。那么，`cfg_attr`
    是什么？这是一个条件编译属性，可以选择性启用功能。你可以在 *The Rust Reference* 中了解所有关于它的信息，该信息链接在 *进一步阅读*
    部分。有很多细节，但想法很简单——根据用户指令（如测试或运行环境）打开或关闭代码片段。
- en: 'This later is what `#[cfg(any(target_arch = "x86", target_arch = "x86_64"))]`
    means. On either x86 or x86_64, stdsimd will be externed with macros enabled and
    without them enabled when on any other platform. Now, hopefully, the rest of the
    preamble is self-explanatory:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 这后面的内容是 `#[cfg(any(target_arch = "x86", target_arch = "x86_64"))]` 的意思。在 x86
    或 x86_64 上，stdsimd 将通过宏启用并外置，在其他平台上则不启用。现在，希望下面的前言部分是自解释的：
- en: '[PRE2]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The `main` function of this program is quite brief:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 这个程序的 `main` 函数相当简短：
- en: '[PRE3]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The whole of stdin is read into the input and a brief vector to hold the hash,
    called `dst`. `hex_encode`, is also used. The first portion performs input validation:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 整个 stdin 被读入输入，并创建了一个简短的向量来存储哈希值，称为 `dst`。还使用了 `hex_encode`。第一部分执行输入验证：
- en: '[PRE4]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Note the return—a `&str` on success and a `usize`—the faulty length—on failure.
    The rest of the function is a touch more complicated:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 注意返回值——成功时返回 `&str`，失败时返回 `usize`——错误的长度。函数的其余部分稍微复杂一些：
- en: '[PRE5]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'This introduces conditional compilation, which we saw previously, and contains
    a new thing too—`is_x86_feature_detected!`. This macro is new to the SIMD feature,
    and tests at runtime whether the given CPU feature is available at runtime via
    libcpuid. If it is, the feature is used. On an ARM processor, for instance, `hex_encode_fallback`
    will be executed. On an x86 processor, one or the other avx2 or sse4.1, implementations
    will be followed, depending on the chip''s exact capabilities. Which implementation
    is called is determined at runtime. Let''s look into the implementation of `hex_encode_fallback`
    first:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 这引入了条件编译，我们之前已经见过，还包含了一个新内容——`is_x86_feature_detected!`。这个宏是 SIMD 功能的新特性，它在运行时通过
    libcpuid 测试给定的 CPU 功能是否可用。如果是，则使用该功能。例如，在 ARM 处理器上，将执行 `hex_encode_fallback`。在
    x86 处理器上，将根据芯片的确切能力执行 avx2 或 sse4.1 之一的实现。哪个实现被调用是在运行时确定的。让我们首先看看 `hex_encode_fallback`
    的实现：
- en: '[PRE6]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The interior function `hex` acts as a static lookup table, and the for loop
    zips together the bytes from the `src` and a two-chunk pull from `dst`, updating
    `dst` as the loop proceeds. Finally, `dst` is converted into a `&str` and returned.
    It's safe to use `from_utf8_unchecked` here as we can verify that no non-utf8
    characters are possible in `dst`, saving us a check.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 内部函数 `hex` 作为一个静态查找表，for 循环将 `src` 中的字节和从 `dst` 中拉取的两个块组合在一起，在循环过程中更新 `dst`。最后，`dst`
    被转换为 `&str` 并返回。在这里使用 `from_utf8_unchecked` 是安全的，因为我们能验证 `dst` 中不可能存在非 utf8 字符，从而节省了检查。
- en: 'Okay, now that''s the fallback. How do the SIMD variants read? We''ll look
    at `hex_encode_avx2`, leaving the sse4.1 variant to the ambitious reader. First,
    we see the reappearance of conditional compilation and the familiar function types:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 好吧，现在这是后备方案。SIMD 变体是如何读取的？我们将查看 `hex_encode_avx2`，将 sse4.1 变体留给有抱负的读者。首先，我们看到条件编译和熟悉的功能类型再次出现：
- en: '[PRE7]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'So far, so good. Now, look at the following:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，一切顺利。现在，看看以下内容：
- en: '[PRE8]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Well, the function `_mm256_set1_epi8` is certainly new! The documentation ([https://rust-lang-nursery.github.io/stdsimd/x86_64/stdsimd/arch/x86_64/fn._mm256_set1_epi8.html](https://rust-lang-nursery.github.io/stdsimd/x86_64/stdsimd/arch/x86_64/fn._mm256_set1_epi8.html)) states
    the following:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 好吧，函数 `_mm256_set1_epi8` 确实是新的！文档（[https://rust-lang-nursery.github.io/stdsimd/x86_64/stdsimd/arch/x86_64/fn._mm256_set1_epi8.html](https://rust-lang-nursery.github.io/stdsimd/x86_64/stdsimd/arch/x86_64/fn._mm256_set1_epi8.html)）中说明了以下内容：
- en: '"Broadcast 8-bit integer a to all elements of returned vector."'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '"将 8 位整数 a 广播到返回向量的所有元素。"'
- en: Okay. What vector? Many SIMD instructions are carried out in terms of vectors
    with implicit sizes, the size being defined by the CPU architecture. For instance,
    the function that we have been looking at returns an `stdsimd::arch::x86_64::__m256i`,
    a 256-bit-wide vector. So, `ascii_zero` is 256-bits-worth of zeros, `ascii_a` 256-bits-worth
    of `a`, and so forth. Each of these functions and types, incidentally, follows
    Intel's naming scheme. It's my understanding that the LLVM uses their own naming
    scheme, but Rust—in an effort to reduce developer confusion—maintains a mapping
    from the architecture names to LLVM's names. By keeping the architecture names,
    Rust makes it real easy to look up details about each intrinsic. You can see this
    in the *Intel Intrinsics Guide* at `mm256_set1_epi8` ([https://software.intel.com/sites/landingpage/IntrinsicsGuide/#text=_mm256_set1_epi8&expand=4676](https://software.intel.com/sites/landingpage/IntrinsicsGuide/#text=_mm256_set1_epi8&expand=4676)).
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 好的。哪个向量？许多 SIMD 指令都是以隐式大小的向量的形式执行的，大小由 CPU 架构定义。例如，我们一直在查看的函数返回一个 `stdsimd::arch::x86_64::__m256i`，一个
    256 位宽的向量。所以，`ascii_zero` 是 256 位的零，`ascii_a` 是 256 位的 `a`，以此类推。顺便说一句，这些函数和类型都遵循英特尔命名方案。我理解
    LLVM 使用自己的命名方案，但 Rust 为了减少开发者混淆，维护了一个从架构名称到 LLVM 名称的映射。通过保留架构名称，Rust 使得查找每个内嵌函数的详细信息变得非常容易。您可以在
    `mm256_set1_epi8` 的 *英特尔内嵌函数指南* 中看到这一点（[https://software.intel.com/sites/landingpage/IntrinsicsGuide/#text=_mm256_set1_epi8&expand=4676](https://software.intel.com/sites/landingpage/IntrinsicsGuide/#text=_mm256_set1_epi8&expand=4676))。
- en: 'The implementation then enters a loop, processing `src` in 256-bit-wide chunks
    until there are only 32 or fewer bits left:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 实现然后进入一个循环，以 256 位宽的块处理 `src`，直到只剩下 32 位或更少：
- en: '[PRE9]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The variable `invec` is now 256 bits of `src`, with `_mm256_loadu_si256` being
    responsible for performing a load. SIMD instructions have to operate on their
    native types, you see. In the actual reality of the machine, there is no type,
    but specialized registers. What comes next is complex, but we can reason through
    it:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 变量 `invec` 现在是 `src` 的 256 位，`_mm256_loadu_si256` 负责执行加载。SIMD 指令必须在其原生类型上操作，您明白的。在机器的实际现实中，没有类型，但有专用寄存器。接下来要讨论的内容很复杂，但我们可以通过推理来理解：
- en: '[PRE10]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Okay, `_mm256_and_si256` performs a bitwise boolean-and of two `__m256i`, returning
    the result. `masked1` is the bitwise boolean-and of `invec` and `and4bits`. The
    same is true for `masked2`, except we need to determine what `_mm256_srli_epi64`
    does. The Intel document state the following:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，`_mm256_and_si256` 执行两个 `__m256i` 的按位布尔与操作，返回结果。`masked1` 是 `invec` 和 `and4bits`
    的按位布尔与操作。对于 `masked2` 也是如此，但我们需要确定 `_mm256_srli_epi64` 做了什么。英特尔文档中说明了以下内容：
- en: '"Shift packed 64-bit integers in a right by imm8 while shifting in zeros, and
    store the results in dst."'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '"将打包的 64 位整数在 dst 中右移 imm8 位，同时移入零，并将结果存储在 dst 中。"'
- en: '`invec` is subdivided into four 64-bit integers, and these are shifted right
    by four bits. That is then boolean-and''ed with `and4bits`, and `masked2` pops
    out. If you refer back to `hex_encode_fallback` and squint a little, you can start
    to see the relationship to `(*byte >> 4) & 0xf`. Next up, two comparison masks
    are put together:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '`invec` 被细分为四个 64 位整数，然后这些整数右移四位。然后与 `and4bits` 进行布尔与操作，`masked2` 就出现了。如果您回顾
    `hex_encode_fallback` 并稍微眯一下眼睛，您就可以开始看到它与 `(*byte >> 4) & 0xf` 的关系。接下来，两个比较掩码被组合在一起：'
- en: '[PRE11]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '`_mm256_cmpgt_epi8` greater-than compares 8-bit chunks of the 256-bit vector,
    returning the larger byte. The comparison masks are then used to control the blending
    of `ascii_zero` and `ascii_a`, and the result of that is added to `masked1`:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '`_mm256_cmpgt_epi8` 对 256 位向量中的 8 位块进行大于比较，返回较大的字节。然后使用比较掩码来控制 `ascii_zero`
    和 `ascii_a` 的混合，并将该结果添加到 `masked1`：'
- en: '[PRE12]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Blending is done bytewise, with the high bit in each byte determining whether
    to move a byte from the first vector in the `arg` list or the second. The computed
    masks are then interleaved, choosing high and low halves:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 混合是按字节进行的，每个字节的最高位决定是否将字节从 `arg` 列表中的第一个向量或第二个向量移动过来。然后计算出的掩码交错选择高半部和低半部：
- en: '[PRE13]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'In the high half of the interleaved masks, the destination''s first 128 bits
    are filled with the top 128 bits from the source, the remainder being filled in
    with zeros. In the lower half of the interleaved masks, the destination''s first
    128 bits are filled from the bottom 128 bits from the source, the remainder being
    zeros. Then, at long last, a pointer is computed into `dst` at 64-bit strides
    and further subdivided into 16-bit chunks, and the `res1` and `res2` are stored
    there:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在交错掩码的高半部分，目标地址的前128位被填充自源地址的最高128位，其余位用零填充。在交错掩码的低半部分，目标地址的前128位被填充自源地址的最低128位，其余位用零填充。最后，计算出一个指向`dst`的指针，以64位步长进行计算，并进一步细分为16位块，然后在这里存储`res1`和`res2`：
- en: '[PRE14]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'When the `src` is less than 32 bytes, `hex_encode_sse4` is called on it, but
    we''ll leave the details of that to the adventurous reader:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 当`src`小于32字节时，会对其调用`hex_encode_sse4`，但我们将细节留给有冒险精神的读者：
- en: '[PRE15]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: That was tough! If our aim here was to do more than get a flavor of the SIMD
    style of programming, then we'd probably need to work out by hand how these instructions
    work on a bit level. Is it worth it? This example comes from RFC 2325 ([https://github.com/rust-lang/rfcs/blob/master/text/2325-stable-simd.md](https://github.com/rust-lang/rfcs/blob/master/text/2325-stable-simd.md)),
    *Stable SIMD*. Their benchmarking demonstrates that the fallback implementation
    we looked at first hashes at around 600 megabytes per second. The avx2 implementation
    hashes at 15,000 MB/s, a 60% performance bump. Not too shabby. And keep in mind
    that each CPU core comes equipped with SIMD capability. You could split such computations
    up among threads, too.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 这很困难！如果我们在这里的目标不仅仅是了解SIMD编程风格，那么我们可能需要手动分析这些指令在位级别上的工作方式。这值得吗？这个例子来自RFC 2325
    ([https://github.com/rust-lang/rfcs/blob/master/text/2325-stable-simd.md](https://github.com/rust-lang/rfcs/blob/master/text/2325-stable-simd.md))，*稳定的SIMD*。他们的基准测试表明，我们最初查看的回退实现每秒大约可以散列600兆字节。avx2实现每秒散列15,000
    MB，性能提升了60%。这并不算差。而且要记住，每个CPU核心都配备了SIMD能力。你还可以将这些计算分配给线程。
- en: Like atomic programming, SIMD is not a panacea or even especially easy. If you
    need the speed, though, it's worth the work.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 就像原子编程一样，SIMD既不是万能的，也不是特别容易。不过，如果你需要速度，那么这些努力是值得的。
- en: Futures and async/await
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Futures和async/await
- en: Asynchronous I/O is a hot topic in the Rust ecosystem right now. The C10K challenge
    we discussed briefly in [Chapter 8](d4802512-564b-4037-9407-b6035bd38f31.xhtml),
    *High-Level Parallelism – Threadpools, Parallel Iterators, and Processes*, was
    resolved when operating systems introduced scalable I/O notification syscalls
    such as kqueue in the BSDs and epoll in Linux. Prior to epoll, kqueue, and friends,
    I/O notification suffered linear growth in processing time as the number of file
    descriptors increased—a real problem. The aggressively naive approach to networking
    we've taken in this book also suffers from linear blowup. Every TCP socket we
    opened for listening would need to be polled in a loop, underserving very high-volume
    connections and overserving all others.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 异步I/O现在是Rust生态系统中的热门话题。我们在[第8章](d4802512-564b-4037-9407-b6035bd38f31.xhtml)“高级并行性
    – 线程池、并行迭代器和进程”中简要讨论的C10K挑战，在操作系统引入可伸缩的I/O通知系统调用（如BSD中的kqueue和Linux中的epoll）时得到了解决。在epoll、kqueue及其朋友出现之前，I/O通知的处理时间随着文件描述符数量的增加而呈线性增长——这是一个真正的问题。本书中我们采取的积极而天真的网络方法也遭受了线性增长。我们为监听而打开的每个TCP套接字都需要在循环中进行轮询，这导致高流量连接得不到充分服务，而其他连接则得到了过多的服务。
- en: 'Rust''s abstraction for scalable network I/O is mio ([https://crates.io/crates/mio](https://crates.io/crates/mio)).
    If you go poking around inside of mio, you''ll find that it is a clean adapter
    for the I/O notification subsystems of a few common platforms: Windows, Unixen,
    and that''s about it. The user of mio doesn''t get much in the way of additional
    support. Where do you store your mio sockets? That''s up to the programmer. Can
    you include multithreading? Up to you. Now, that''s great for very specific use
    cases—cernan, for example, uses mio to drive its ingress I/O because we wanted
    very fine control over all of these details—but unless you have very specific
    needs, this is probably going to be a very tedious situation for you. The community
    has been investing very heavily in tokio ([https://crates.io/crates/tokio](https://crates.io/crates/tokio)),
    a framework for doing scalable I/O with essential things such as back-pressure,
    transaction cancellation, and higher-level abstractions to simplify request/response
    protocols. Tokio''s been a fast-moving project, but will almost surely be one
    of the *key* projects in the coming years. Tokio is, fundamentally, a reactor-based
    ([https://en.wikipedia.org/wiki/Reactor_pattern](https://en.wikipedia.org/wiki/Reactor_pattern))
    architecture; an I/O event becomes available and handlers you''ve registered are
    then called.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: Rust的可扩展网络I/O抽象是mio ([https://crates.io/crates/mio](https://crates.io/crates/mio))。如果你在mio内部探索，你会发现它是一些常见平台（Windows、Unixen）的I/O通知子系统的干净适配器：这就是全部了。mio的用户不会得到很多额外的支持。你的mio套接字存储在哪里？这取决于程序员。你能包含多线程吗？由你决定。现在，这对非常具体的用例来说很棒——例如，cernan使用mio来驱动其入口I/O，因为我们希望对这些细节有非常精细的控制——但除非你有非常具体的需求，否则这可能会对你来说是一个非常繁琐的情况。社区已经在tokio
    ([https://crates.io/crates/tokio](https://crates.io/crates/tokio))上投入了大量的精力，这是一个用于执行可扩展I/O的框架，它具有如背压、事务取消和高级抽象等基本功能，以简化请求/响应协议。Tokio是一个快速发展的项目，但几乎肯定将成为未来几年中的*关键*项目之一。Tokio在本质上是一个基于反应器（[https://en.wikipedia.org/wiki/Reactor_pattern](https://en.wikipedia.org/wiki/Reactor_pattern)）的架构；一个I/O事件变得可用，然后调用你已注册的处理程序。
- en: 'Reactor-based systems are simple enough to program if you have only one event
    to respond to. But, more often than you''d imagine, there exist dependency relationships
    between I/O events in a real system—an ingressing UDP packet results in a TCP
    round-trip to a network memory cache, which results in an egress UDP packet to
    the original ingress system, and another as well. Coordinating that is hard. Tokio—and
    the Rust ecosystem somewhat generally—has gone all-in on a promise library called
    futures ([https://crates.io/crates/futures](https://crates.io/crates/futures)).
    Promises are a fairly tidy solution to asynchronous I/O: the underlying reactor
    calls a well-established interface, you implement a closure inside (or a trait
    to then slot inside) that interface, and everyone''s code stays loosely coupled.
    Rust''s futures are pollable, meaning you can hit the poll function on a future
    and it might resolve into a value or a notification that the value isn''t ready
    yet.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你只需要响应一个事件，基于反应器的系统编程足够简单。但是，比你想象的更常见的是，在真实系统中，I/O事件之间存在依赖关系——一个进入的UDP数据包会导致对网络内存缓存的TCP往返，这又导致对原始进入系统的出口UDP数据包，以及另一个。协调这一点是困难的。Tokio——以及Rust生态系统在某种程度上——完全投入了一个名为futures
    ([https://crates.io/crates/futures](https://crates.io/crates/futures))的承诺库。承诺是对异步I/O的一个相当整洁的解决方案：底层的反应器调用一个已建立的接口，你在其中实现一个闭包（或一个特质，然后将其放入该接口），这样每个人的代码都保持松散耦合。Rust的futures是可轮询的，这意味着你可以在一个future上调用poll函数，它可能解析为一个值或一个通知，表明该值尚未准备好。
- en: This is similar to promise systems in other languages. But, as anyone who remembers
    the early introduction of NodeJS into the JavaScript ecosystem can attest to,
    promises without language support get weird and deeply nested fast. Rust's borrow
    checker made the situation harder, requiring boxing or full-on arcs where, in
    straight-line code, this would not have been necessary.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 这与其他语言的承诺系统类似。但是，正如任何记得NodeJS早期引入JavaScript生态系统的人都可以证明的那样，没有语言支持的承诺会变得很奇怪，并且很快就会变得非常嵌套。Rust的借用检查器使得情况变得更糟，需要装箱或完全的弧，而在直线代码中，这本来是不必要的。
- en: Languages with promises as a first-class concern generally evolve async/await
    syntaxes. An async function is a function in Rust that will return a future and
    little else. A Rust future is simple trait, extracted from the futures project. The
    actual implementation will live outside the language's standard library and allow
    for alternative implementations. The interior of an async function is not executed
    immediately, but only when the future is polled. The interior of the function
    executes through the polling until an await point is hit, resulting in a notification
    that the value is not yet ready and that whatever is polling the future should
    move on.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 将承诺作为一等关注点的语言通常会演变async/await语法。异步函数是Rust中返回未来而几乎没有其他内容的函数。Rust的未来是一个简单的特质，它从futures项目中提取出来。实际的实现将存在于语言的标准库之外，并允许有替代实现。异步函数的内部不会立即执行，而只有在未来被轮询时才会执行。函数的内部通过轮询执行，直到遇到await点，导致一个通知，表明值尚未准备好，并且正在轮询未来的任何内容都应该继续进行。
- en: As in other languages, Rust's proposed async / await syntax really is a sugar
    over the top of an explicit callback chaining structure. But, because the async/await
    syntax and futures trait is moving into the compiler, rules can be added to the
    borrow-checking system to remove the current boxing concerns. I expect you'll
    see more futures in stable Rust once they become more convenient to interact with.
    Indeed, as we saw in [Chapter 8](d4802512-564b-4037-9407-b6035bd38f31.xhtml),
    *High-Level Parallelism – Pools, Iterators, and Processes*, rayon is investing
    time in a futures-based interface.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 正如其他语言一样，Rust提出的async/await语法实际上是在显式回调链结构之上的糖衣。但是，由于async/await语法和futures特质正在进入编译器，可以向借用检查系统添加规则以消除当前的装箱关注点。我预计，一旦它们变得更容易交互，你将看到更多稳定版Rust中的futures。确实，正如我们在[第八章](d4802512-564b-4037-9407-b6035bd38f31.xhtml)《高级并行性——池、迭代器和进程》中看到的那样，rayon正在投资时间开发基于futures的接口。
- en: Specialization
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 特定化
- en: 'In [Chapter 2](8c61da2f-08c8-40be-89d4-d8afa8510850.xhtml), *Sequential Rust
    Performance and Testing*, we noted that the technique of *specialization* would
    be cut off from data structure implementors if they intended to target stable
    Rust. Specialization is a means by which a generic structure—say, a `HashMap`—can
    be implemented specifically for one type. Usually, this is done to improve performance—say,
    by turning a `HashMap` with `u8` keys into an array—or provide a simpler implementation
    when possible. Specialization has been in Rust for a good while, but limited to
    nightly projects, such as the compiler, because of soundness issues when interacting
    with lifetimes. The canonical example has always been the following:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第二章](8c61da2f-08c8-40be-89d4-d8afa8510850.xhtml)《顺序Rust性能和测试》中，我们提到，如果数据结构实现者打算针对稳定版Rust进行目标开发，*特定化*技术将被切断。特定化是一种方法，通过这种方法，一个泛型结构——比如一个`HashMap`——可以针对一个特定类型进行具体实现。通常，这样做是为了提高性能——比如将具有`u8`键的`HashMap`转换为数组——或者在可能的情况下提供一个更简单的实现。特定化在Rust中已经存在了一段时间，但由于与生命周期交互时的稳定性问题，它仅限于夜间项目，如编译器。经典的例子一直是以下内容：
- en: '[PRE16]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Lifetimes are erased at a certain point in the compilation process. String literals
    are static, but by the time dispatch to specialized type would occur there's not
    enough information in the compiler to decide. Lifetime equality in specialization
    also poses difficulties.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 生命周期在编译过程中的某个点被消除。字符串字面量是静态的，但在调用特定类型之前，编译器中信息不足，无法做出决定。在特定化中的生命周期等价性也带来了困难。
- en: It seemed for a good while that specialization would miss the boat for inclusion
    into the language in 2018\. Now, *maybe*, a more limited form of specialization
    will be included. A specialization will only apply if the implementation is generic
    with regard to lifetimes, does not introduce duplication into trait lifetimes,
    does not repeat generic type parameters, and all trait bounds are themselves applicable
    for specialization. The exact details are in flux as I write this, but do keep
    an eye out.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 有很长一段时间，人们认为特定化将错过2018年语言中包含的机会。现在，*也许*将包含一种更有限的特定化形式。只有当实现是关于生命周期的泛型时，特定化才会适用，它不会在特质生命周期中引入重复，不会重复泛型类型参数，并且所有特质界限本身都适用于特定化。具体的细节在我写这篇文章时还在变化，但请务必留意。
- en: Interesting projects
  id: totrans-78
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 有趣的项目
- en: There are many interesting projects in the Rust community right now. In this
    section, I'd like to look at two that I didn't get a chance to discuss at length
    in the book.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 目前Rust社区中有很多有趣的项目。在本节中，我想探讨两个我在书中没有详细讨论的项目。
- en: Fuzzing
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模糊测试
- en: In previous chapters we've used AFL to validate that our programs did not exhibit
    crashing behavior. While AFL is very commonly used, it's not the only fuzzer available
    for Rust. LLVM has a native library—libfuzzer ([https://llvm.org/docs/LibFuzzer.html](https://llvm.org/docs/LibFuzzer.html))—covering
    the same space, and the cargo-fuzz ([https://crates.io/crates/cargo-fuzz](https://crates.io/crates/cargo-fuzz))
    project acts as an executor. You might also be interested in honggfuzz-rs ([https://crates.io/crates/honggfuzz](https://crates.io/crates/honggfuzz)),
    a fuzzer developed at Google for searching out security related violations. It
    is natively multithreaded—there is no need to spin up multiple processes manually—and
    can do network fuzzing. My preference, traditionally, has been to fuzz with AFL.
    The honggfuzz project has real momentum, and readers should give it a try in their
    own projects.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
- en: Seer, a symbolic execution engine for Rust
  id: totrans-82
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Fuzzing, as we discussed previously, explores the state space of a program using
    random inputs and binary instrumentation. This can be, as we've seen, slow. The
    ambition of symbolic execution ([https://en.wikipedia.org/wiki/Symbolic_execution](https://en.wikipedia.org/wiki/Symbolic_execution))
    is to allow the same exploration of state space, but without random probing. Searching
    for program crashes is one area of application, but it can also be used with proof
    tools. Symbolic execution, in a carefully written program, can let you demonstrate
    that your program can never reach error states. Rust has a partially implemented
    symbolic execution tool, seer ([https://github.com/dwrensha/seer](https://github.com/dwrensha/seer)).
    The project uses z3, a constraint solver, to generate branching inputs at program
    branches. Seer's README, as of SHA `91f12b2291fa52431f4ac73f28d3b18a0a56ff32`,
    amusingly decodes a hash. This is done by defining the decoding of the hashed
    data to be a crashable condition. Seer churns for a bit and then decodes the hash,
    crashing the program. It reports the decoded value among the error report.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: It's still early days for seer, but the potential is there.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
- en: The community
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Rust community is large and multi-faceted. It's so large, in fact, that
    it can be hard to know where to go with questions or ideas. More, books at the
    intermediate to advanced level will often assume that readers know as much about
    the language community as the author does. Having been mostly on the other side
    of the author, reader relationship I've always found this assumption frustrating.
    As an author, though, I now understand the hesitancy—none of the community information
    will stay up to date.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
- en: Oh well. Some of this information may be out of date by the time you get to
    it. Reader beware.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: Throughout this book, we've referred to the crates ecosystem; crates.io ([https://crates.io/](https://crates.io/))
    is *the* location for Rust source projects. The docs.rs ([https://docs.rs/](https://docs.rs/))
    is a vital resource for understanding crates, and is run by the Rust team. You
    can also `cargo docs` and get a copy of your project's dependency documentation
    locally. I'm often without Wi-Fi, and I find this very useful.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
- en: As with almost all things in Rust, the community itself is documented on this
    web page ([https://www.rust-lang.org/en-US/community.html](https://www.rust-lang.org/en-US/community.html)).
    IRC is fairly common for real-time, loose conversations, but there's a real focus
    on the web-facing side of Rust's communication. The Users Forum ([https://users.rust-lang.org/](https://users.rust-lang.org/))
    is a web forum intended for folks who use the language and have questions or announcements.
    The compiler people—as well as the standard library implementors, and so on—hang
    out on the Internals Forum([https://internals.rust-lang.org/](https://internals.rust-lang.org/)).
    There is a good deal of overlap in the two communities, as you might expect.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
- en: Throughout this book, we've referenced various RFCs. Rust evolves through a
    request-for-comments system, all of which are centralized ([https://github.com/rust-lang/rfcs](https://github.com/rust-lang/rfcs)).
    That's just for the Rust compiler and standard library. Many community projects
    follow a similar system—for example, crossbeam RFCs ([https://github.com/crossbeam-rs/rfcs](https://github.com/crossbeam-rs/rfcs)).
    These are well worth reading, by the way.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
- en: Should I use unsafe?
  id: totrans-91
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It's not uncommon to hear some variant of the following position—*I won't use
    any library that has an* `unsafe` *block in it*. The reasoning behind this position
    is that `unsafe`, well, advertises that the crate is potentially unsafe and might
    crash your otherwise carefully crafted program. That's true—kind of. As we've
    seen in this book, it's entirely possible to put together a project using `unsafe`
    that is totally safe at runtime. We've also seen that it's entirely possible to
    put together a project without `unsafe` blocks that flame out at runtime. The
    existence or absence of `unsafe` blocks shouldn't reduce the original programmer's
    responsibilities for due diligence—writing tests, probing the implementation with
    fuzzing tools, and so on. Moreover, the existence or absence of `unsafe` blocks
    does not relieve the user of a crate from that same responsibility. Any software,
    at some level, should be considered suspect unless otherwise demonstrated to be
    safe.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: Go ahead and use the `unsafe` keyword. Do so when it's necessary. Keep in mind
    that the compiler won't be able to help you as much as it normally would—that's
    all.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-94
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this last chapter of the book, we discussed near and midterm improvements
    coming to the Rust language—features being stabilized after a while out in the
    wilderness, the foundations of larger projects being integrated, research that
    may or may not pan out, and other topics. Some of these topics will surely have
    chapters of their own in the second edition of this book, should it get a new
    edition (Tell your friends to pick up a copy!). We also touched on the community,
    which is the place to find ongoing discussions, ask questions, and get involved.
    Then, we affirmed that, yes indeed, you should write in unsafe Rust when you have
    reason to do so.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: Okay, that's it. That's the end of the book.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  id: totrans-97
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Shipping specialization: a story of soundness*, available at [https://aturon.github.io/blog/2017/07/08/lifetime-dispatch/](https://aturon.github.io/blog/2017/07/08/lifetime-dispatch/).
    There''s long been an ambition to see specialization available in stable Rust,
    and it''s not for want of trying that it hasn''t happened yet. In this blog post,
    Aaron Turon discusses the difficulties of specialization in 2017, introducing
    the Chalk logic interpreter in the discussion. Chalk is interesting in its own
    right, especially if you are interested in compiler internals or logic programming.'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Maximally minimal specialization: always applicable impls*, available at [http://smallcultfollowing.com/babysteps/blog/2018/02/09/maximally-minimal-specialization-always-applicable-impls/](http://smallcultfollowing.com/babysteps/blog/2018/02/09/maximally-minimal-specialization-always-applicable-impls/).
    This blog post by Niko Matsakis extends the topics covered in Turon''s *Shipping
    specialization* article, discussing a *min-max* solution to the specialization
    soundness issue. The approach seemed to be the most likely candidate for eventual
    implementation, but flaws were discovered. Happily, not unresolvable flaws. This
    post is an excellent example of the preRFC conversation in the Rust community.'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Sound and ergonomic specialization for Rust*, available at [http://aturon.github.io/2018/04/05/sound-specialization/](http://aturon.github.io/2018/04/05/sound-specialization/). This
    blog post addresses the issues in the min-max article and proposes the implementation
    discussed in this chapter. It is, as of writing this book, the most likely to
    be implemented, unless some bright spark finds a flaw in it.'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Chalk*, available at [https://github.com/rust-lang-nursery/chalk](https://github.com/rust-lang-nursery/chalk).
    Chalk is really a very interesting Rust project. It is, according to the project
    description, a *PROLOG-ish interpreter written in Rust*. To date, Chalk is being
    used to reason about specialization in the Rust language, but there are plans
    to merge Chalk into `rustc` itself someday. The project README, as of `SHA 94a1941a021842a5fcb35cd043145c8faae59f08`,
    has a list of excellent articles on the applications of chalk.'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*The Unstable Book*, available at [https://doc.rust-lang.org/nightly/unstable-book/](https://doc.rust-lang.org/nightly/unstable-book/).
    `rustc` has a large number of in-flight features. *The Unstable Book* is intended
    to be a best-effort collection of these features, the justifications behind them,
    and any relevant tracking issues. It is well worth a read, especially if you''re
    looking to contribute to the compiler project.'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*《不稳定的书籍》*，可在[https://doc.rust-lang.org/nightly/unstable-book/](https://doc.rust-lang.org/nightly/unstable-book/)找到。`rustc`拥有大量正在开发中的特性。*《不稳定的书籍》*旨在收集这些特性、它们背后的理由以及任何相关的跟踪问题，值得一读，尤其是如果你打算为编译器项目做出贡献的话。'
- en: '*Zero-cost futures in Rust*, available at [http://aturon.github.io/blog/2016/08/11/futures/](http://aturon.github.io/blog/2016/08/11/futures/).
    This post introduced the Rust community to the futures project and explains the
    motivation behind the introduction well. The actual implementation details of
    futures have changed with time, but this article is still well worth a read.'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Rust中的零成本future*，可在[http://aturon.github.io/blog/2016/08/11/futures/](http://aturon.github.io/blog/2016/08/11/futures/)找到。这篇文章向Rust社区介绍了future项目，并很好地解释了引入它的动机。随着时间的推移，future的实际实现细节已经发生了变化，但这篇文章仍然值得一读。'
- en: '*Async / Await*, available at  [https://github.com/rust-lang/rfcs/blob/master/text/2394-async_await.md](https://github.com/rust-lang/rfcs/blob/master/text/2394-async_await.md). RFC 
    2394 introduces the motivation for simplifying the ergonomics of futures in Rust,
    as well as laying out the implementation approach for it. The RFC is, itself,
    a fine example of how Rust evolves—community desire turns into experimentation
    which then turns into support from the compiler.'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*异步/等待*，可在[https://github.com/rust-lang/rfcs/blob/master/text/2394-async_await.md](https://github.com/rust-lang/rfcs/blob/master/text/2394-async_await.md)找到。RFC
    2394介绍了简化Rust中future的易用性的动机，并概述了其实施方法。该RFC本身是Rust如何演化的一个很好的例子——社区的需求转化为实验，然后转化为编译器的支持。'
