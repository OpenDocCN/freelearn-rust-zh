["```rs\nrayon = \"1.0.0\"\n```", "```rs\n1  extern crate rayon;\n2  use rayon::prelude::*;\n3 \n4  fn main() {\n5    let legend = \"Did you ever hear the tragedy of Darth Plagueis \n     The Wise?\";\n6    let words: Vec<_> = legend.split_whitespace().collect();\n7 \n8   // The following will execute in parallel,\n9   // so the exact order of execution is not foreseeable\n10  words.par_iter().for_each(|val| println!(\"{}\", val));\n11 \n12   // par_iter can do everything that a normal iterator does, but\n13   // in parallel. This way you can easily parallelize any \n       algorithm\n14   let words_with_a: Vec<_> = words\n15       .par_iter()\n16       .filter(|val| val.find('a').is_some())\n17       .collect();\n18 \n19    println!(\n20       \"The following words contain the letter 'a': {:?}\",\n21        words_with_a\n22    );\n23  }\n```", "```rs\nwords.par_iter().for_each(|val| println!(\"{}\", val));\n```", "```rs\nrayon = \"1.0.0\"\n```", "```rs\n1 extern crate rayon;\n2 \n3  #[derive(Debug)]\n4  struct Rectangle {\n5    height: u32,\n6    width: u32,\n7  }\n8 \n9  impl Rectangle {\n10    fn area(&self) -> u32 {\n11       self.height * self.width\n12    }\n13    fn perimeter(&self) -> u32 {\n14       2 * (self.height + self.width)\n15    }\n16  }\n17 \n18  fn main() {\n19    let rect = Rectangle {\n20       height: 30,\n21       width: 20,\n22    };\n23    // rayon::join makes closures run potentially in parallel and\n24    // returns their returned values in a tuple\n25    let (area, perimeter) = rayon::join(|| rect.area(), || \n      rect.perimeter());\n26    println!(\"{:?}\", rect);\n27    println!(\"area: {}\", area);\n28    println!(\"perimeter: {}\", perimeter);\n29 \n30    let fib = fibonacci(6);\n31    println!(\"The sixth number in the fibonacci sequence is {}\", \n      fib);\n32  }\n33 \n34  fn fibonacci(n: u32) -> u32 {\n35    if n == 0 || n == 1 {\n36     n\n37    } else {\n38      // rayon::join can really shine in recursive functions\n39      let (a, b) = rayon::join(|| fibonacci(n - 1), || fibonacci(n \n          - 2));\n40       a + b\n41    }\n42  }\n```", "```rs\nrayon::join(a, b);\n```", "```rs\nfn join<A,B>(oper_a: A, oper_b: B)\n    where A: FnOnce() + Send,\n          B: FnOnce() + Send,\n{\n    // Advertise `oper_b` to other threads as something\n    // they might steal:\n    let job = push_onto_local_queue(oper_b);\n\n    // Execute `oper_a` ourselves:\n    oper_a();\n\n    // Check whether anybody stole `oper_b`:\n    if pop_from_local_queue(oper_b) {\n        // Not stolen, do it ourselves.\n        oper_b();\n    } else {\n        // Stolen, wait for them to finish. In the\n        // meantime, try to steal from others:\n        while not_yet_complete(job) {\n            steal_from_others();\n        }\n        result_b = job.result();\n    }\n}\n```", "```rs\n1  use std::thread;\n2  use std::sync::Arc;\n3  \n4  fn main() {\n5    // An Arc (\"Atomically Reference Counted\") is used the exact\n6    // same way as an Rc, but also works in a parallel context\n7    let some_resource = Arc::new(\"Hello World\".to_string());\n8 \n9    // We use it to give a new thread ownership of a clone of the \n        Arc\n10   let thread_a = {\n11     // It is very common to give the clone the same name as the \n          original\n12     let some_resource = some_resource.clone();\n13     // The clone is then moved into the closure:\n14     thread::spawn(move || {\n15       println!(\"Thread A says: {}\", some_resource);\n16      })\n17   };\n18   let thread_b = {\n19       let some_resource = some_resource.clone();\n20       thread::spawn(move || {\n21         println!(\"Thread B says: {}\", some_resource);\n22        })\n23   };\n24 \n25  // .join() blocks the main thread until the other thread is done\n26  thread_a.join().expect(\"Thread A panicked\");\n27  thread_b.join().expect(\"Thread B panicked\");\n28  }\n```", "```rs\nlet some_resource = Arc::new(\"Hello World\".to_string());\n```", "```rs\n    let thread_a = {\n        let some_resource = some_resource.clone();\n        thread::spawn(move || {\n            println!(\"Thread A says: {}\", some_resource);\n        })\n    };\n```", "```rs\nlet thread_a = thread::spawn(|| {\n    println!(\"Thread A says: {}\", some_resource);\n});\n```", "```rs\n    let thread_a = thread::spawn(move || {\n        println!(\"Thread A says: {}\", some_resource);\n    });\n```", "```rs\n    let some_resource_clone = some_resource.clone();\n    let thread_a = thread::spawn(move || {\n        println!(\"Thread A says: {}\", some_resource_clone);\n    });\n```", "```rs\nlet thread_a = {\n    let some_resource = some_resource.clone();\n    thread::spawn(move || {\n        println!(\"Thread A says: {}\", some_resource);\n    })\n};\n```", "```rs\nrand = \"0.4.2\"\n```", "```rs\n1  extern crate rand;\n2 \n3  use rand::Rng;\n4  use std::thread;\n5  // mpsc stands for \"Multi-producer, single-consumer\"\n6  use std::sync::mpsc::channel;\n7 \n8  fn main() {\n9     // channel() creates a connected pair of a sender and a \n        receiver.\n10    // They are usually called tx and rx, which stand for\n11    // \"transmission\" and \"reception\"\n12    let (tx, rx) = channel();\n13    for i in 0..10 {\n14        // Because an mpsc channel is \"Multi-producer\",\n15        // the sender can be cloned infinitely\n16        let tx = tx.clone();\n17        thread::spawn(move || {\n18           println!(\"sending: {}\", i);\n19           // send() pushes arbitrary data to the connected \n              receiver\n20           tx.send(i).expect(\"Disconnected from receiver\");\n21        });\n22    }\n23    for _ in 0..10 {\n24       // recv() blocks the current thread\n25       // until a message was received\n26       let msg = rx.recv().expect(\"Disconnected from sender\");\n27       println!(\"received: {}\", msg);\n28    }\n29 \n30    let (tx, rx) = channel();\n31    const DISCONNECT: &str = \"Goodbye!\";\n32    // The following thread will send random messages\n33    // until a goodbye message was sent\n34    thread::spawn(move || {\n35        let mut rng = rand::thread_rng();\n36        loop {\n37          let msg = match rng.gen_range(0, 5) {\n38              0 => \"Hi\",\n39              1 => DISCONNECT,\n40              2 => \"Howdy there, cowboy\",\n41              3 => \"How are you?\",\n42              4 => \"I'm good, thanks\",\n43              _ => unreachable!(),\n44          };\n45          println!(\"sending: {}\", msg);\n46          tx.send(msg).expect(\"Disconnected from receiver\");\n47          if msg == DISCONNECT {\n48            break;\n49          }\n50       }\n51   });\n52 \n53   // An iterator over messages in a receiver is infinite.\n54   // It will block the current thread until a message is    \n     available\n55   for msg in rx {\n56        println!(\"received: {}\", msg);\n57    }\n58  }\n```", "```rs\nfor i in 0..10 {\n    let tx = tx.clone();\n    thread::spawn(move || {\n        println!(\"sending: {}\", i);\n        tx.send(i).expect(\"Disconnected from receiver\");\n    });\n}\n```", "```rs\nfor _ in 0..10 {\n    let msg = rx.recv().expect(\"Disconnected from sender\");\n    println!(\"received: {}\", msg);\n}\n```", "```rs\n    for msg in rx {\n        println!(\"received: {}\", msg);\n    }\n```", "```rs\n1 use std::sync::{Arc, RwLock};\n2 use std::thread;\n3 \n4 fn main() {\n5 // An RwLock works like the RefCell, but blocks the current\n6 // thread if the resource is unavailable\n7 let resource = Arc::new(RwLock::new(\"Hello \n      World!\".to_string()));\n8 \n9 // The reader_a thread will print the current content of\n10 // our resource fourty times\n11 let reader_a = {\n12 let resource = resource.clone();\n13 thread::spawn(move || {\n14 for _ in 0..40 {\n15 // Lock resource for reading access\n16 let resource = resource\n17 .read()\n18 .expect(\"Failed to lock resource for reading\");\n19 println!(\"Reader A says: {}\", resource);\n20 }\n21 })\n22 };\n23 \n24 // The reader_b thread will print the current content of\n25 // our resource fourty times as well. Because RwLock allows\n26 // multiple readers, it will execute at the same time as \n        reader_a\n27 let reader_b = {\n28 let resource = resource.clone();\n29 thread::spawn(move || {\n30 for _ in 0..40 {\n31 // Lock resource for reading access\n32 let resource = resource\n33 .read()\n34 .expect(\"Failed to lock resource for reading\");\n35 println!(\"Reader B says: {}\", resource);\n36 }\n37 })\n38 };\n39 \n40 // The writer thread will modify the resource ten times.\n41 // Because RwLock enforces Rust's access rules\n42 // (multiple readers xor one writer), this thread will wait \n          until\n43 // thread_a and thread_b are not using the resource and then \n         block\n44 // them both until its done.\n45 let writer = {\n46 let resource = resource.clone();\n47 thread::spawn(move || {\n48 for _ in 0..10 {\n49 // Lock resource for writing access\n50 let mut resource = resource\n51 .write()\n52 .expect(\"Failed to lock resource for writing\");\n53 \n54 resource.push('!');\n55 }\n56 })\n57 };\n58 \n59 reader_a.join().expect(\"Reader A panicked\");\n60 reader_b.join().expect(\"Reader B panicked\");\n61 writer.join().expect(\"Writer panicked\");\n62 }\n```", "```rs\n1 use std::sync::Arc;\n2 use std::sync::atomic::{AtomicBool, AtomicUsize, Ordering, ATOMIC_BOOL_INIT, ATOMIC_USIZE_INIT};\n3 use std::thread;\n4 use std::ops::{Deref, DerefMut};\n5 use std::cell::UnsafeCell;\n6 \n7 fn main() {\n8 // Atomics are primitive types suited for\n9 // well defined concurrent behaviour\n10 let some_number = AtomicUsize::new(0);\n11 // They are usually initialized by copying them from\n12 // their global constants, so the following line does the same:\n13 let some_number = ATOMIC_USIZE_INIT;\n14 \n15 // load() gets the current value of the atomic\n16 // Ordering tells the compiler how exactly to handle the \n         interactions\n17 // with other threads. SeqCst (\"Sequentially Consistent\") can \n         always be used\n18 // as it results in the same thing as if no parallelism was \n         involved\n19 let curr_val = some_number.load(Ordering::SeqCst);\n20 println!(\"The current value of some_number is {}\", curr_val);\n21 \n22 // store() sets the variable\n23 some_number.store(123, Ordering::SeqCst);\n24 let curr_val = some_number.load(Ordering::SeqCst);\n25 println!(\"The current value of some_number is {}\", curr_val);\n26 \n27 // swap() sets the variable and returns the old value\n28 let old_val = some_number.swap(12_345, Ordering::SeqCst);\n29 let curr_val = some_number.load(Ordering::SeqCst);\n30 println!(\"The old value of some_number was {}\", old_val);\n31 println!(\"The current value of some_number is {}\", curr_val);\n32 \n33 // compare_and_swap only swaps the variable if it\n34 // is currently equal to the first argument.\n35 // It will always return the old variable\n36 let comparison = 12_345;\n37 let new_val = 6_789;\n38 let old_val = some_number.compare_and_swap(comparison, new_val, \n      Ordering::SeqCst);\n39 if old_val == comparison {\n40 println!(\"The value has been updated\");\n41 }\n42 \n43 // The previous atomic code is equivalent to\n44 // the following sequential code\n45 let mut some_normal_number = 12_345;\n46 let old_val = some_normal_number;\n47 if old_val == comparison {\n48 some_normal_number = new_val;\n49 println!(\"The value has been updated sequentially\");\n50 }\n51 \n52 // fetch_add() and fetch_sub() add/subtract a number from the \n         value,\n53 // returning the old value\n54 let old_val_one = some_number.fetch_add(12, Ordering::SeqCst);\n55 let old_val_two = some_number.fetch_sub(24, Ordering::SeqCst);\n56 let curr_val = some_number.load(Ordering::SeqCst);\n57 println!(\n58 \"some_number was first {}, then {} and is now {}\",\n59 old_val_one, old_val_two, curr_val\n60 );\n61 \n62 // fetch_or() performs an \"or\" (\"||\") operation on the variable \n         and\n63 // an argument and sets the variable to the result. It then \n         returns the old value.\n64 // For the other logical operations, fetch_and(), fetch_nand() \n         and fetch_xor also exist\n65 let some_bool = ATOMIC_BOOL_INIT;\n66 let old_val = some_bool.fetch_or(true, Ordering::SeqCst);\n67 let curr_val = some_bool.load(Ordering::SeqCst);\n68 println!(\"({} || true) is {}\", old_val, curr_val);\n69 \n70 // The following is a demonstration of our own Mutex \n         implementation,\n71 // based on an AtomicBool that checks if it's locked or not\n72 let naive_mutex = Arc::new(NaiveMutex::new(1));\n73 \n74 // The updater thread will set the value in the mutex to 2\n75 let updater = {\n76 let naive_mutex = naive_mutex.clone();\n77 thread::spawn(move || {\n78 let mut val = naive_mutex.lock();\n79 *val = 2;\n80 })\n81 };\n82 \n83 // The updater thread will print the value in the mutex\n84 let printer = {\n85 let naive_mutex = naive_mutex.clone();\n86 thread::spawn(move || {\n87 let val = naive_mutex.lock();\n88 println!(\"The value in the naive mutex is: {}\", *val);\n89 })\n90 };\n91 \n92 // The exact order of execution is unpredictable,\n93 // but our mutex guarantees that the two threads will\n94 // never access the data at the same time\n95 updater.join().expect(\"The updater thread panicked\");\n96 printer.join().expect(\"The printer thread panicked\");\n97 }\n```", "```rs\n99 // NaiveMutex is an easy, albeit very suboptimal,\n100 // implementation of a Mutex, similar to std::sync::Mutex\n101 // A mutex is a lock that only allows one thread to access a    \n    ressource at all times\n102 pub struct NaiveMutex<T> {\n103 locked: AtomicBool,\n104 // UnsafeCell is the underlying struct of every\n105 // internally mutable container such as ours\n106 data: UnsafeCell<T>,\n107 }\n108 \n109 // This is a RAII guard, identical to the one from the last                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n    chapter\n110 pub struct NaiveMutexGuard<'a, T: 'a> {\n111 naive_mutex: &'a NaiveMutex<T>,\n112 }\n113 \n114 impl<T> NaiveMutex<T> {\n115 pub fn new(data: T) -> Self {\n116 NaiveMutex {\n117 locked: ATOMIC_BOOL_INIT,\n118 data: UnsafeCell::new(data),\n119 }\n120 }\n121 \n122 pub fn lock(&self) -> NaiveMutexGuard<T> {\n123 // The following algorithm is called a \"spinlock\", because it \n             keeps\n124 // the current thread blocked by doing nothing (it keeps it \n             \"spinning\")\n125 while self.locked.compare_and_swap(false, true, \n          Ordering::SeqCst) {}\n126 NaiveMutexGuard { naive_mutex: self }\n127 }\n128 }\n129 \n130 // Every type that is safe to send between threads is automatically\n131 // safe to share between threads if wrapped in our mutex, as it\n132 // guarantees that no threads will access it ressource at the  \nsame time\n133 unsafe impl<T: Send> Sync for NaiveMutex<T> {}\n134 \n135 // Automatically unlock the mutex on drop\n136 impl<'a, T> Drop for NaiveMutexGuard<'a, T> {\n137 fn drop(&mut self) {\n138 self.naive_mutex.locked.store(false, Ordering::SeqCst);\n139 }\n140 }\n141 \n142 // Automatically dereference to the underlying data\n143 impl<'a, T> Deref for NaiveMutexGuard<'a, T> {\n144 type Target = T;\n145 fn deref(&self) -> &T {\n146 unsafe { &*self.naive_mutex.data.get() }\n147 }\n148 }\n149 \n150 impl<'a, T> DerefMut for NaiveMutexGuard<'a, T> {\n151 fn deref_mut(&mut self) -> &mut T {\n152 unsafe { &mut *self.naive_mutex.data.get() }\n153 }\n154 }\n```", "```rs\npub struct NaiveMutex<T> {\n    locked: AtomicBool,\n    data: UnsafeCell<T>,\n}\n```", "```rs\npub struct NaiveMutexGuard<'a, T: 'a> {\n    naive_mutex: &'a NaiveMutex<T>,\n}\n```", "```rs\npub fn lock(&self) -> NaiveMutexGuard<T> {\n  while self.locked.compare_and_swap(false, true, Ordering::SeqCst) {}\n    NaiveMutexGuard { naive_mutex: self }\n}\n```", "```rs\nfn drop(&mut self) {\n    self.naive_mutex.locked.store(false, Ordering::SeqCst);\n}\n```", "```rs\nunsafe { &*self.naive_mutex.data.get() }\n```", "```rs\nunsafe impl<T: Send> Sync for NaiveMutex<T> {}\n```", "```rs\n1 use std::sync::{Arc, RwLock};\n2 use std::net::Ipv6Addr;\n3 use std::collections::HashMap;\n4 use std::{thread, time};\n5 use std::sync::atomic::{AtomicUsize, Ordering, ATOMIC_USIZE_INIT};\n6 \n7 // Client holds whatever state your client might have\n8 struct Client {\n9 ip: Ipv6Addr,\n10 }\n11 \n12 // ConnectionHandler manages a list of connections\n13 // in a parallelly safe way\n14 struct ConnectionHandler {\n15 // The clients are identified by a unique key\n16 clients: RwLock<HashMap<usize, Client>>,\n17 next_id: AtomicUsize,\n18 }\n19 \n20 impl Client {\n21 fn new(ip: Ipv6Addr) -> Self {\n22 Client { ip }\n23 }\n24 }\n25 \n26 impl ConnectionHandler {\n27 fn new() -> Self {\n28 ConnectionHandler {\n29 clients: RwLock::new(HashMap::new()),\n30 next_id: ATOMIC_USIZE_INIT,\n31 }\n32 }\n33 \n34 fn client_count(&self) -> usize {\n35 self.clients\n36 .read()\n37 .expect(\"Failed to lock clients for reading\")\n38 .len()\n39 }\n40 \n41 fn add_connection(&self, ip: Ipv6Addr) -> usize {\n42 let last = self.next_id.fetch_add(1, Ordering::SeqCst);\n43 self.clients\n44 .write()\n45 .expect(\"Failed to lock clients for writing\")\n46 .insert(last, Client::new(ip));\n47 last\n48 }\n49 \n50 fn remove_connection(&self, id: usize) -> Option<()> {\n51 self.clients\n52 .write()\n53 .expect(\"Failed to lock clients for writing\")\n54 .remove(&id)\n55 .and(Some(()))\n56 }\n57 }\n```", "```rs\n59 fn main() {\n60 let connections = Arc::new(ConnectionHandler::new());\n61 \n62 // the connector thread will add a new connection every now and \n        then\n63 let connector = {\n64 let connections = connections.clone();\n65 let dummy_ip = Ipv6Addr::new(0, 0, 0, 0, 0, 0xffff, 0xc00a, \n          0x2ff);\n66 let ten_millis = time::Duration::from_millis(10);\n67 thread::spawn(move || {\n68 for _ in 0..20 {\n69 connections.add_connection(dummy_ip);\n70 thread::sleep(ten_millis);\n71 }\n72 })\n73 };\n74 \n75 // the disconnector thread will remove the third connection at \n         some point\n76 let disconnector = {\n77 let connections = connections.clone();\n78 let fifty_millis = time::Duration::from_millis(50);\n79 thread::spawn(move || {\n80 thread::sleep(fifty_millis);\n81 connections.remove_connection(2);\n82 })\n83 };\n84 \n85 // The main thread will print the active connections in a short \n         interval\n86 let five_millis = time::Duration::from_millis(5);\n87 for _ in 0..40 {\n88 let count = connections.client_count();\n89 println!(\"Active connections: {}\", count);\n90 thread::sleep(five_millis);\n91 }\n92 \n93 connector.join().expect(\"The connector thread panicked\");\n94 disconnector\n95 .join()\n96 .expect(\"The disconnector thread panicked\");\n97 }\n```", "```rs\nlet last = self.next_id.fetch_add(1, Ordering::SeqCst);\n```"]