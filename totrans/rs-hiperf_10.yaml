- en: Multithreading
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多线程
- en: 'So far, we have seen how to make our code faster and faster by optimizing various
    aspects of how we code, but there is still one point left to optimize: making
    our code work in parallel. In this chapter, you will learn how **fearless concurrency** works
    in Rust by using threads to process your data.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经看到了如何通过优化我们编码的各个方面来使我们的代码越来越快，但还有一个优化点：让我们的代码并行工作。在本章中，您将通过使用线程来处理您的数据，了解Rust中如何实现**无畏并发**。
- en: 'During this chapter, you will learn the following:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您将学习以下内容：
- en: '`Send` and `Sync` traits—how does Rust achieve memory safety?'
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Send`和`Sync`特质——Rust是如何实现内存安全的？'
- en: Basic threading in Rust—creating and managing threads
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rust中的基本线程——创建和管理线程
- en: Moving data between threads
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在线程之间移动数据
- en: Crates to make multithreading easier and faster
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使多线程更容易更快的工具包
- en: Concurrency in Rust
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Rust中的并发
- en: For a long time, it has not made sense to perform all tasks sequentially in
    a computer. Of course, sometimes you need to perform some tasks before others,
    but in most real-world applications, you will want to run some tasks in parallel.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 很长时间以来，在计算机中按顺序执行所有任务都没有意义。当然，有时您需要在其他任务之前执行某些任务，但在大多数实际应用中，您将希望并行运行一些任务。
- en: You might, for example, want to respond to HTTP requests. If you do one after
    the other, the overall server will be slow. Especially when you get many requests
    per second and some of them take time to complete. You probably want to start
    responding to others before you finish with the current one.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，您可能想响应HTTP请求。如果您一个接一个地处理，整体服务器将会很慢。特别是当您每秒收到很多请求，其中一些需要时间来完成时。您可能想在完成当前请求之前开始响应其他请求。
- en: Furthermore, we now have multiple processors in almost any computer or server,
    even in most mobile phones. This means that not only can we process other tasks
    in parallel while our main task is idle, we can really use one processor for each
    task by using threads. This is a feature that we must use to our advantage when
    developing high-performance applications.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，现在几乎在每台计算机或服务器上，甚至在大多数手机上，我们都有多个处理器。这意味着我们不仅可以在主任务空闲时并行处理其他任务，而且我们可以通过使用线程为每个任务真正使用一个处理器。这是我们在开发高性能应用程序时必须利用的优势功能。
- en: The main issue with concurrency is that it's hard. We are not used to thinking
    in parallel, and as programmers we make mistakes. We only have to check some of
    the security vulnerabilities or bugs in our most-used systems, developed by the
    greatest programmers, to see that it's difficult to make it right.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 并发的主要问题是它很难。我们不习惯于并行思考，作为程序员，我们会犯错误。我们只需要检查一下我们最常用的系统中的某些安全漏洞或错误，这些系统是由最伟大的程序员开发的，就可以看到要正确地做到这一点是多么困难。
- en: Sometimes, we try to change a variable without remembering that another task
    might be reading it, or even changing it at the same time. Imagine a request counter
    in the HTTP example. If we separate the load between two processors, and each
    processor receives a request, the shared counter should go up by two, right?
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，我们试图更改一个变量，却忘记了另一个任务可能正在读取它，甚至同时更改它。想象一下HTTP示例中的请求计数器。如果我们把负载分开给两个处理器，并且每个处理器都收到一个请求，共享的计数器应该增加两个，对吧？
- en: Each thread wants to add 1 to the counter. For that, they load the current counter
    in the CPU, they add one to it and then save it again in the RAM. This takes some
    time, especially loading it from RAM, which means that if they both load the counter
    at the same time, they will both have the current counter in the CPU.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 每个线程都想给计数器加1。为此，它们在CPU中加载当前的计数器，给它加一，然后再将其保存到RAM中。这需要一些时间，尤其是从RAM中加载，这意味着如果它们同时加载计数器，它们都会在CPU中有当前的计数器。
- en: If both add one to the counter and save it back, the value in the RAM will only
    add one request, instead of two, because both processors will save the new `+1`
    value in the RAM. This is what we call a data race. There are some tools that
    avoid this behavior, such as atomic variables, semaphores, and mutexes, but we
    sometimes forget to use them.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 如果两个处理器都给计数器加一并保存它，RAM中的值只会增加一个请求，而不是两个，因为两个处理器都会将新的`+1`值保存到RAM中。这就是我们所说的数据竞争。有一些工具可以避免这种行为，例如原子变量、信号量和互斥锁，但我们有时会忘记使用它们。
- en: One of the best-known features in Rust is the fearless concurrency. This means
    that as long as we use safe Rust, we shouldn't be able to create a data race.
    This solves our issue but, how do they do it?
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: Rust中最知名的功能之一是无畏并发。这意味着只要我们使用安全的Rust，我们就应该无法创建数据竞争。这解决了我们的问题，但他们是如何做到的呢？
- en: Understanding the Send and Sync traits
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解 `Send` 和 `Sync` 特性
- en: The secret ingredients for this to work are the `Send` and `Sync` traits. They
    are traits known to the compiler, so it will check whether they are the types
    we use want to use to implement them and act accordingly. You cannot implement
    `Send` or `Sync` for your types directly. The compiler will know whether your
    types are `Send` or `Sync` by checking whether the contained fields are `Sync`
    or `Send`, in the case of structures or enumerations with fields.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 使这一切工作起来的秘密成分是 `Send` 和 `Sync` 特性。它们是编译器所知的特性，因此编译器会检查我们是否想要使用它们来实现类型，并相应地行动。你不能直接为你自己的类型实现
    `Send` 或 `Sync`。在结构体或枚举体具有字段的情况下，编译器将通过检查包含的字段是否为 `Sync` 或 `Send` 来知道你的类型是否是 `Send`
    或 `Sync`。
- en: Let's now understand how they work. First of all, you should note that neither
    `Send` nor `Sync` traits add methods to a given type. This means that, once compiled,
    they will not occupy any memory or add any extra overhead to your binary. They
    will only be checked at compile time to make sure that multithreading is safe.
    You cannot directly implement `Send` or `Sync` for your types unless you are using
    an unsafe block, so the compiler will do it for you where appropriate.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们了解它们是如何工作的。首先，你应该注意，`Send` 和 `Sync` 特性都不会向给定的类型添加方法。这意味着一旦编译，它们不会占用任何内存或给你的二进制文件添加任何额外的开销。它们只会在编译时进行检查，以确保多线程是安全的。除非你使用一个不安全的块，否则你不能直接为你自己的类型实现
    `Send` 或 `Sync`，因此编译器会在适当的地方为你完成这项工作。
- en: The Send trait
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '`Send` 特性'
- en: A structure implementing the `Send` trait is safe to be moved between threads.
    This means that you can safely transfer ownership of a `Send` type between threads.
    The standard library implements `Send` for the types that can actually be moved
    across thread boundaries, and the compiler will automatically implement it for
    your types if they can also be moved between threads. If a type is only composed
    of `Send` types, it will be a `Send` type.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 实现了 `Send` 特性的结构体可以在线程之间安全地移动。这意味着你可以在线程之间安全地转移 `Send` 类型的所有权。标准库为那些实际上可以跨越线程边界的类型实现了
    `Send`，如果您的类型也可以在线程之间移动，编译器会自动为您实现它。如果一个类型仅由 `Send` 类型组成，它也将是一个 `Send` 类型。
- en: Most types in the standard library implement the `Send` trait. You can safely
    move ownership of a `u32` to another thread, for example. This means that the
    previous thread will not be able to use it again and that the new thread will
    be in charge of dropping it once it gets out of scope.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 标准库中的大多数类型都实现了 `Send` 特性。例如，你可以安全地将 `u32` 的所有权移动到另一个线程。这意味着之前的线程将无法再次使用它，而新的线程将负责在它超出作用域时将其丢弃。
- en: There are some exceptions, though. Raw pointers cannot be safely moved to another
    thread, since they have no safety guards. You can copy a raw pointer multiple
    times, and it could happen that one gets to one thread and the other stays in
    the current one. If both try to manipulate the same memory at the same time, it
    will create undefined behavior.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，也有一些例外。原始指针不能安全地移动到另一个线程，因为它们没有安全保护。你可以多次复制一个原始指针，可能会发生一个到达一个线程而另一个留在当前线程的情况。如果两个线程同时尝试操作同一内存，将会产生未定义的行为。
- en: The other exception is the reference-counted pointer or `Rc` type. This type
    can easily and efficiently create shared pointers to a given memory location.
    It will be safe since the type itself has some memory guarantees to make sure
    that if a mutable borrow exists, no other borrows can be made, and that if one
    or more non-mutable borrows exists, no mutable borrow can be made. The information
    pointed by the pointer will be dropped at the same time the last reference gets
    out of scope.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个例外是引用计数指针或 `Rc` 类型。这种类型可以轻松高效地创建指向给定内存位置的共享指针。由于该类型本身有一些内存保证，确保如果存在可变借用，则不能进行其他借用，并且如果存在一个或多个不可变借用，则不能进行可变借用，因此它是安全的。指针所指向的信息将在最后一个引用超出作用域时同时被丢弃。
- en: 'This works by having a counter that adds `1` each time a reference gets created
    by calling the `clone()` method and that subtracts `1` once a reference gets dropped.
    You might have already realized the issue that will arise when sharing it between
    threads: if two threads drop a reference at the same time, the reference count
    might only subtract `1`. This means that when the last reference gets dropped,
    the counter won''t be zero, and it will not drop the `Rc`, creating a memory leak.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 这是通过有一个计数器来实现的，每次通过调用 `clone()` 方法创建引用时，计数器增加 `1`，一旦引用被丢弃，计数器减去 `1`。你可能已经意识到了在线程之间共享时可能出现的问题：如果两个线程同时丢弃引用，引用计数可能只会减去
    `1`。这意味着当最后一个引用被丢弃时，计数器不会为零，它不会丢弃 `Rc`，从而造成内存泄漏。
- en: Since Rust cannot allow memory leaks, the `Rc` type is not `Send`. There is
    an equivalent shared pointer that can be shared between threads, the atomically
    reference-counted pointer or `Arc`. This type makes sure that each addition or
    subtraction to the reference count gets performed atomically, so that if a new
    thread wants to add or subtract one reference, it will need to wait for the other
    threads to finish updating that counter. This makes it thread-safe, but it will
    be slower than an `Rc` due to the checks that need to be performed. So, you should
    use `Rc` if you don't need to send a reference to another thread.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 Rust 不允许内存泄漏，`Rc` 类型不是 `Send`。有一个等效的共享指针可以在线程之间共享，即原子引用计数的指针或 `Arc`。这种类型确保对引用计数的每次增加或减少都是在原子操作中完成的，因此如果新线程想要增加或减少一个引用，它将需要等待其他线程完成更新那个计数器。这使得它是线程安全的，但由于需要执行的检查，它将比
    `Rc` 慢。所以，如果你不需要将引用发送到另一个线程，你应该使用 `Rc`。
- en: The Sync trait
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '`Sync` 特征'
- en: The `Sync` trait, on the other hand, represents a type that can be shared between
    threads. This refers to actually sharing the variable without transferring its
    ownership to the new thread.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 与之相反，`Sync` 特征代表一种可以在线程之间共享的类型。这指的是实际上共享变量而不将其所有权转移到新线程。
- en: As with the `Send` trait, raw pointers and `Rc` are not `Sync`, but there is
    another family of types that implement not `Send` but not `Sync`. A `Cell` can
    be safely sent between threads, but it cannot be shared. Let's review how a `Cell`
    works.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 与 `Send` 特征一样，原始指针和 `Rc` 不是 `Sync`，但还有一个类型家族实现了既不是 `Send` 也不是 `Sync`。`Cell`
    可以安全地在线程之间传递，但不能共享。让我们回顾一下 `Cell` 的工作原理。
- en: A cell that can be found in the `std::cell` module is a container that will
    have some inner data. This data will be another type. Cells are used for interior
    mutability, but what is that? Interior mutability is the option to change the
    contents of a variable without it being mutable. This might sound counter-intuitive,
    especially in Rust, but it's possible.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 可以在 `std::cell` 模块中找到的单元格是一个将包含一些内部数据的容器。这些数据将是另一种类型。单元格用于内部可变性，但那是什么意思呢？内部可变性是更改变量内容而不使其可变的选择。这听起来可能有些反直觉，尤其是在
    Rust 中，但这是可能的。
- en: 'The two safe types of cells are `Cell` and `RefCell`. The first ones implement
    interior mutability by moving values in and out of the `Cell`. This means that
    you will be able to insert a new value in the cell or get the current cell value
    if it''s a `Copy` type, but you won''t be able to use its mutable methods if you
    are using a complex type, such as a vector or a `HashMap`. It''s useful for small
    types such as integers, for example. An `Rc` will use a `Cell` to store a count
    of the references so that you can call the `clone()` method on a non-mutable `Rc`
    and still update the count of references. Let''s see an example:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 两种安全的单元格类型是 `Cell` 和 `RefCell`。前者通过在 `Cell` 中移动值来实现内部可变性。这意味着你将能够在单元格中插入新值，或者如果它是
    `Copy` 类型，则获取当前单元格的值，但如果你使用的是复杂类型，如向量或 `HashMap`，则无法使用其可变方法。这对于像整数这样的小型类型很有用。`Rc`
    将使用 `Cell` 来存储引用计数，这样你就可以在非可变的 `Rc` 上调用 `clone()` 方法，同时更新引用计数。让我们看一个例子：
- en: '[PRE0]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Note that the `my_cell` variable is not mutable, but the program still compiles
    and the output is the following:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，`my_cell` 变量是不可变的，但程序仍然可以编译，输出如下：
- en: '![](img/ff7ab900-af0b-48de-acb8-efae1884c3b8.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/ff7ab900-af0b-48de-acb8-efae1884c3b8.png)'
- en: A `RefCell` does a similar thing, but it can be used with any kind of type,
    and you can get mutable references to the value inside if there are no other references
    to it. This internally uses unsafe code, of course, since Rust does not allow
    this. For this to work, it has a flag that lets the `RefCell` know whether it's
    currently borrowed or not. If it's borrowed for read, more read-only borrows can
    be generated with the `borrow()` method, but no mutable borrow can be done. If
    it's mutably borrowed with the `borrow_mut()` method, you will not be able to
    borrow it mutably or non-mutably.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '`RefCell` 做类似的事情，但它可以与任何类型的类型一起使用，如果没有其他引用指向它，你可以获取其内部值的可变引用。当然，它内部使用不安全代码，因为
    Rust 不允许这样做。为了使其工作，它有一个标志让 `RefCell` 知道它是否当前被借用。如果它被用于读取而借用，可以使用 `borrow()` 方法生成更多只读借用，但不能进行可变借用。如果使用
    `borrow_mut()` 方法进行可变借用，你将无法以可变或不可变的方式借用它。'
- en: 'These two methods will check the current borrow status at runtime, not at compile
    time, which is standard for Rust rules, and panic if the current state is not
    correct. They have non-panicking alternatives named `try_borrow()` and `try_borrow_mut()`.
    Since all the checks are done at runtime, they will be slower than the usual Rust
    rules, but they allow for this interior mutability. Let''s see an example:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这两种方法将在运行时检查当前的借用状态，而不是在编译时，这是 Rust 规则的标准做法，如果当前状态不正确，它们将引发恐慌。它们有非恐慌的替代方法，名为
    `try_borrow()` 和 `try_borrow_mut()`。由于所有检查都是在运行时完成的，它们将比常规的 Rust 规则慢，但允许这种内部可变性。让我们看一个例子：
- en: '[PRE1]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Once again, note that the `my_cell` variable is not mutable, and yet this code
    compiles and we get a mutable borrow to it, which allows us to insert a new key/value
    pair into the hash map. The output, as expected, is the following:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 再次提醒，`my_cell` 变量是不可变的，但这段代码仍然可以编译，并且我们可以获得对其的可变借用，这允许我们在哈希表中插入一个新的键/值对。预期的输出如下：
- en: '![](img/55222331-d28c-418d-8773-5a1a5e240546.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](img/55222331-d28c-418d-8773-5a1a5e240546.png)'
- en: On the other hand, since the borrow flag is not thread safe, the whole `RefCell`
    structure will not be `Sync`. You can safely send the complete ownership of the
    cell to a new thread, but you cannot have shared references to it. If you want
    to better understand how `Rc`, Cells, and RefCells work, we talked about them
    in [Chapter 3](71d38dd3-1f0b-408e-b454-3d342b413f7c.xhtml), *Memory Management
    in Rust*.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，由于借用标志不是线程安全的，整个 `RefCell` 结构将不会是 `Sync`。你可以安全地将单元格的完整所有权发送到新线程，但不能有对其的共享引用。如果你想更好地理解
    `Rc`、Cells 和 RefCells 的工作原理，我们已经在 [第 3 章](71d38dd3-1f0b-408e-b454-3d342b413f7c.xhtml)
    中讨论了它们，*Rust 的内存管理*。
- en: There are thread-safe alternatives that allow interior mutability, called Mutexes.
    A `Mutex` stores the guard in an actual system `Mutex`, which synchronizes the
    threads before accessing the data. This makes it `Sync` but also slower. We will
    see how they work in this chapter.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 存在着线程安全的替代方案，允许内部可变性，称为 Mutexes。`Mutex` 将守卫存储在一个实际的系统 `Mutex` 中，在访问数据之前同步线程。这使得它成为
    `Sync`，但同时也更慢。我们将在本章中看到它们是如何工作的。
- en: Other types of concurrency in Rust
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Rust 中的其他并发类型
- en: There are other ways of achieving parallel computing in Rust and in many other
    languages. In this chapter, we will talk about multithreading, where each thread
    has access to shared memory and creates its own stacks so that it can work independently.
    Ideally, you should have about the same number of threads working at the same
    time as the number of virtual CPUs in your PC/server.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Rust 以及许多其他语言中，还有其他实现并行计算的方法。在本章中，我们将讨论多线程，其中每个线程都可以访问共享内存，并创建自己的堆栈，以便它可以独立工作。理想情况下，你应该有大约与你的
    PC/服务器中虚拟 CPU 数量相同的线程同时工作。
- en: This is usually twice the number of CPU cores, thanks to hyperthreading, where
    one core can run two threads at the same time by using its own hardware scheduler
    to decide which parts of each thread run at a given point in time.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 这通常是 CPU 核心数量的两倍，多亏了超线程技术，其中一个核心可以通过使用自己的硬件调度器来同时运行两个线程，以决定在给定时间点运行每个线程的哪些部分。
- en: The main issue with threads is that if you don't put a limit and run too many
    of them, maybe because some of them are idle and your CPU should be able to run
    the others, you will consume a lot of RAM. This is because of all the stacks that
    need to be created per thread. It is not uncommon for some web servers to create
    one thread per request. This will make things much slower when the load is high,
    since it will require a lot of RAM.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 线程的主要问题在于，如果你不设置限制而运行太多线程，可能是因为其中一些线程是空闲的，而你的CPU应该能够运行其他线程，你将消耗大量的RAM。这是因为每个线程都需要创建所有这些栈。一些Web服务器为每个请求创建一个线程并不罕见。当负载高时，这会使事情变得非常慢，因为它需要大量的RAM。
- en: Another approach to concurrency is asynchronous programming. Rust has great
    tools for this kind of use and we will see them in the next chapter. The best
    improvement that asynchronous programming brings is the possibility for one thread
    to run multiple I/O requests while not blocking the actual thread.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 并发性的另一种方法是异步编程。Rust在这方面有很好的工具，我们将在下一章中看到它们。异步编程带来的最佳改进是允许一个线程在不会阻塞实际线程的情况下运行多个I/O请求。
- en: Not only that, if the thread goes idle, it will not need to sleep for some time
    and then it will poll for new requests. The underlying operating system will wake
    the thread up when there is new information for it. This approach will, therefore,
    use the minimum possible resources for I/O operations.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 不仅如此，如果线程空闲，它不需要等待一段时间然后再去轮询新的请求。当有新信息时，底层操作系统会唤醒线程。因此，这种方法将使用尽可能少的资源进行I/O操作。
- en: But what about programs that do not need I/O? In those cases, things can be
    executed in parallel further than using threads. Most processors nowadays allow
    vectorization. Vectorization uses some special CPU instructions and registers
    where you can enter more than one variable and perform the same operation in all
    of them at the same time. This is extremely useful for high-performance computing,
    where you need to apply a certain algorithm multiple times to different datasets.
    With this approach, you can perform multiple additions, subtractions, multiplications,
    and divisions at the same time.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 但对于那些不需要I/O的程序呢？在这种情况下，事情可以比使用线程更并行地执行。如今的大多数处理器都允许向量化。向量化使用一些特殊的CPU指令和寄存器，你可以输入多个变量，同时在这些变量上执行相同的操作。这对于高性能计算非常有用，在那里你需要多次将某种算法应用于不同的数据集。采用这种方法，你可以同时执行多个加法、减法、乘法和除法。
- en: The special instructions used for vectorization are called the **SIMD** family,
    from **Single Instruction Multiple Data**. You can use them by running the assembly
    directly with the `asm!{}` macro in nightly Rust, and the compiler will try to
    automatically vectorize your code, even though this is not usually as good as
    professionals can achieve manually. There are multiple proposals to stabilize
    SIMD intrinsics in 2018\. This way, you will be able to use this instruction with
    some abstraction from assembly. There is some effort going on in the `faster`
    crate ([https://crates.io/crates/faster](https://crates.io/crates/faster)).
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 用于向量化的特殊指令被称为**SIMD**系列，源自**单指令多数据**。你可以在夜间的Rust中直接通过`asm!{}`宏运行汇编，编译器将尝试自动向量化你的代码，尽管这通常不如专业人士手动操作的效果好。2018年有多项提议稳定SIMD内建函数。这样，你将能够使用这些指令，同时从汇编中抽象出来。在`faster`crate（[https://crates.io/crates/faster](https://crates.io/crates/faster)）中正在进行一些努力。
- en: Understanding multithreading
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解多线程
- en: 'Now that we understand the different approaches for concurrency in Rust, we
    can start with the most basic one: creating threads. If you have previously used
    languages such as Java or C++, you will probably be familiar with the `new Thread()`
    syntax in the former or the `std::thread` in the latter. In both cases, you will
    need to specify some code that the new thread will run, and some extra information
    the thread will have. In both cases, you can start threads and wait for them to
    finish.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了Rust中不同的并发方法，我们可以从最基本的方法开始：创建线程。如果你之前使用过Java或C++等语言，你可能会熟悉前者的`new Thread()`语法或后者的`std::thread`。在两种情况下，你都需要指定新线程将运行的代码以及线程将拥有的额外信息。在两种情况下，你都可以启动线程并等待它们完成。
- en: Creating threads
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建线程
- en: 'In Rust, things are similar to the C++ approach, where we have the `std::thread`
    module with the `spawn()` function. This function will receive a closure or a
    pointer to a function and execute it. It will return a handle to the thread, and
    we will be able to manage it from outside. Let''s see how this works:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Rust 中，与 C++ 方法类似，我们有一个带有 `spawn()` 函数的 `std::thread` 模块。这个函数将接收一个闭包或指向函数的指针并执行它。它将返回一个线程句柄，我们将能够从外部管理它。让我们看看它是如何工作的：
- en: '[PRE2]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'This will output something similar to this:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 这将输出类似以下内容：
- en: '![](img/6dbb166c-a42f-42e3-ac6d-0ba22f5e440e.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6dbb166c-a42f-42e3-ac6d-0ba22f5e440e.png)'
- en: The **Inside the thread!** and **After thread spawn!** messages could be ordered
    in any way, in theory, even though in this simple example it is easy to see that
    spawning the thread will take more time than printing in the screen buffer.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '**线程内！** 和 **线程启动后！** 消息可以在理论上以任何顺序排列，尽管在这个简单的例子中很容易看出启动线程将比在屏幕缓冲区中打印花费更多时间。'
- en: 'Nevertheless, this example shows some valuable information on how to work with
    threads. First, when the **Before the thread!** message gets printed, there is
    only one thread in execution: the main thread, running the `main()` function.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这个例子展示了如何与线程一起工作的宝贵信息。首先，当打印出 **线程之前！** 消息时，只有一个线程正在执行：主线程，运行 `main()` 函数。
- en: Then, we spawn a new thread with the `std::thread::spawn()` function, and we
    pass a simple closure to it. This closure will just print the **Inside the thread!** message
    in the console. This happens at the same time as the printing of the **After thread
    spawn!** message. In fact, in some programming languages, you might see that the
    characters of both messages get mixed and the final message is just a lot of incomprehensible
    characters.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们使用 `std::thread::spawn()` 函数启动一个新的线程，并向它传递一个简单的闭包。这个闭包将只会在控制台打印 **线程内！**
    消息。这发生在 **线程启动后！** 消息打印的同时。实际上，在某些编程语言中，你可能会看到两个消息的字符混合在一起，最终的消息只是一堆难以理解的字符。
- en: Rust avoids this by only accessing the standard output file descriptor with
    a `Mutex`. The `println!()` macro will lock `stdout` while it writes the message,
    and if a new message wants to be written, it will have to wait until the first
    write finishes.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: Rust 通过仅使用 `Mutex` 访问标准输出文件描述符来避免这种情况。`println!()` 宏会在写入消息时锁定 `stdout`，如果新的消息想要被写入，它将必须等待第一次写入完成。
- en: This has both advantages and disadvantages. As a clear advantage, the printed
    messages are clearly readable, since one of the threads (the main thread or the
    second thread) will always arrive before the other. On the other hand, it means
    that while the second thread is waiting for the first one to finish printing on
    the screen, it will be blocked and won't be able to do any computation.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 这既有优点也有缺点。作为一个明显的优点，打印的消息清晰可读，因为线程之一（主线程或第二个线程）总是会先于另一个到达。另一方面，这意味着当第二个线程等待第一个线程在屏幕上完成打印时，它将被阻塞，无法进行任何计算。
- en: You will need to make sure that you take that into account, and don't print
    frequently from many threads while performing computations. In fact, since Rust
    is a thread-safe language, it will happen with any shared resource, so you will
    need to be careful to avoid overhead.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要确保考虑到这一点，在执行计算时不要从许多线程中频繁打印。实际上，由于 Rust 是一个线程安全的语言，这将在任何共享资源上发生，因此你需要小心避免开销。
- en: You might think that this is a bad approach for performance, since it will make
    things slower, but actually, it's the only possible approach if the integrity
    of the data needs to be preserved. In other languages, you will need to implement
    the solution yourself, or use existing solutions explicitly to avoid memory corruption.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会认为这是一个对性能不好的方法，因为它会使事情变慢，但实际上，如果需要保留数据的完整性，这是唯一可能的方法。在其他语言中，你可能需要自己实现解决方案，或者显式地使用现有解决方案来避免内存损坏。
- en: Before the end of the example code, we can see that we call the `join()` method
    in the thread handle. This will make the current thread wait for the other one
    to finish. You might note that I added a call to the `expect()` method after it.
    This is because the `join()` method returns a `Result` because it might have panicked
    before finishing.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在示例代码的末尾之前，我们可以看到我们调用了线程句柄中的 `join()` 方法。这将使当前线程等待另一个线程完成。你可能注意到我在它之后添加了对 `expect()`
    方法的调用。这是因为 `join()` 方法返回一个 `Result`，因为它可能在完成之前崩溃。
- en: Panicking in Rust
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Rust 中的恐慌
- en: 'Let''s first understand what a thread panic is. You might already know that
    you can cause a panic by calling the `unwrap()` or `expect()` methods in an `Option`
    or `Result`, or even by calling directly to `panic!()`. There are multiple ways
    of panicking: the `unimplemented!()` macro panics, letting the user know that
    the feature is not implemented, the `assert!()` macro family will panic if the
    conditions are not satisfied, and indexing a slice out of bounds will also panic,
    but, what is a panic?'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们首先了解什么是线程恐慌。你可能已经知道，你可以通过在`Option`或`Result`中调用`unwrap()`或`expect()`方法，甚至直接调用`panic!()`来引发恐慌。有几种引发恐慌的方式：`unimplemented!()`宏会引发恐慌，让用户知道该功能尚未实现，`assert!()`宏家族如果条件不满足也会引发恐慌，并且超出范围的切片索引也会引发恐慌，但，什么是恐慌？
- en: When talking about a single-threaded application, you might think that a panic
    is like exiting the program with an error, similar to the `exit()` function in
    C/C++. What might sound new to you is that a panic is something that happens at
    the thread level. If the main thread panics, the whole program exits, but if a
    non-main thread panics, you can recover from it.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 当谈论单线程应用程序时，你可能会认为恐慌就像带错误退出程序一样，类似于C/C++中的`exit()`函数。可能对你来说听起来很新颖的是，恐慌是发生在线程级别上的事情。如果主线程发生恐慌，整个程序会退出，但如果非主线程发生恐慌，你可以从中恢复。
- en: But, is a panic really a simple program end? Actually, it's much more than that.
    In C/C++, when you exit a program, the memory just gets handed back to the kernel
    and then it just ends. Rust, on the other hand, due to its memory safety guarantees,
    makes sure that it calls all the destructors in the current stack. This means
    that all the variables will be dropped gracefully.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，恐慌真的只是简单的程序结束吗？实际上，它远不止于此。在C/C++中，当你退出程序时，内存只是归还给内核，然后程序就结束了。然而，Rust由于它的内存安全保证，确保它调用当前栈中的所有析构函数。这意味着所有变量都将优雅地释放。
- en: This is what is called **stack unwinding**, but it's not the only option. As
    we saw in the first chapter, where we explained how to configure the behavior
    in the `Cargo.toml` file, you can also opt to abort panics, which will mimic the
    standard C/C++ behavior.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是所谓的**栈回溯**，但这不是唯一的选择。正如我们在第一章中解释的，如何在`Cargo.toml`文件中配置行为，你也可以选择中止恐慌，这将模仿标准C/C++的行为。
- en: The main advantage of the unwinding panic is, of course, that you can perform
    cleaning operations if things go bad. You can, for example, close files, write
    last minute logs, and update some databases just by implementing the `Drop` trait
    in your structures.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 栈回溯恐慌的主要优点当然是，如果你事情搞砸了，你可以执行清理操作。例如，你可以通过在结构体中实现`Drop`特质来关闭文件、记录最后时刻的日志和更新一些数据库。
- en: The main disadvantage, though, as we already mentioned in [Chapter 1](ad672e4d-0f5e-4c59-b823-249da183abc8.xhtml),
    *Common Performance Pitfalls*, is that each time we call the `unwrap()` or `expect()`
    methods, for example, a new branch appears. Either things go wrong and the thread
    panics or things go as they should. If they panic, the compiler needs to add the
    whole code for the stack unwinding, which makes executables noticeably bigger.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，正如我们在[第一章](ad672e4d-0f5e-4c59-b823-249da183abc8.xhtml)“常见性能陷阱”中已经提到的，主要缺点是每次我们调用`unwrap()`或`expect()`方法时，例如，就会出现一个新的分支。要么事情出错，线程发生恐慌，要么事情按预期进行。如果它们发生恐慌，编译器需要添加整个代码进行栈回溯，这使得可执行文件明显变大。
- en: 'Now that you know how panics work, let''s look at how we can recover from them:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经了解了恐慌的工作原理，让我们看看我们如何从中恢复：
- en: '[PRE3]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: As you can see, I added some more boilerplate code. I added a name to the thread,
    for example, which is a good practice so that we know what each thread is called
    if something goes wrong.  I changed the console print inside the second thread
    for an explicit panic, and then I checked if things were wrong when joining the
    thread. What is important here is that you should never just call `expect()` or
    `unwrap()` when joining a thread, since it could make your whole program fail.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所见，我添加了一些更多的样板代码。例如，我为线程添加了一个名称，这是一个好的实践，这样我们就可以知道如果出现问题，每个线程叫什么。我将第二个线程内的控制台打印更改为显式的恐慌，然后检查在连接线程时是否有问题。这里重要的是，你绝不应该在连接线程时仅仅调用`expect()`或`unwrap()`，因为这可能会使你的整个程序失败。
- en: 'For this example, the output should be similar to the following:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个例子，输出应该类似于以下内容：
- en: '![](img/cb9f8ba2-7f2c-4aa5-8ed1-6abb46ec9bad.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![](img/cb9f8ba2-7f2c-4aa5-8ed1-6abb46ec9bad.png)'
- en: There is an extra tip when working with panicking threads. If you have a structure
    that implements the `Drop` trait, the `drop()` method will be called when panicking
    or when going out of scope.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 当与引发错误的线程一起工作时，有一个额外的技巧。如果你有一个实现了`Drop`特质的结构体，当引发错误或超出作用域时，将会调用`drop()`方法。
- en: 'You can find out whether the current thread is panicking by calling the `std::thread::panicking()`
    function. Let''s see how it works:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过调用`std::thread::panicking()`函数来找出当前线程是否正在引发错误。让我们看看它是如何工作的：
- en: '[PRE4]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Let's first see what this code does. It adds a new `MyStruct` structure, which
    has a name in it and that implements the Drop trait. Then, it creates one instance
    of the structure with the `whole program` name. This structure will be dropped
    at the end of the `main()` function.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们看看这段代码的作用。它添加了一个新的`MyStruct`结构体，其中包含一个名称并实现了`Drop`特质。然后，它使用`whole program`名称创建了这个结构体的一个实例。这个结构体将在`main()`函数的末尾被丢弃。
- en: Then, in an artificial scope, it adds a scoped instance of the structure that
    will be dropped just at the end of that inner scope. Finally, inside the thread,
    it creates a new structure that should be dropped at the end of the thread, which
    will be unwound.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，在一个人工的作用域中，它添加了一个结构体的作用域实例，这个实例将在那个内部作用域的末尾被丢弃。最后，在线程内部，它创建了一个新的结构体，这个结构体应该在线程结束时被丢弃，并且将会被展开。
- en: 'The Drop implementation of the `MyStruct` structure uses the `std::thread::panicking()`
    function to check whether it''s being dropped while panicking or simply because
    it went out of scope. Here we have the output of this example:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '`MyStruct`结构的`Drop`实现使用了`std::thread::panicking()`函数来检查它是否在引发错误时被丢弃，或者仅仅是因为它超出了作用域。这里是我们这个示例的输出：'
- en: '![](img/c37d2d98-8759-4105-8682-95c54944722a.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c37d2d98-8759-4105-8682-95c54944722a.png)'
- en: As we can see, the first message is the drop of the inner scope binding. Then,
    the new thread spawns, it panics, and the binding inside the thread is dropped
    while unwinding the stack. Finally, after the last message in the `main()` function,
    the first binding we created gets dropped.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，第一条信息是内部作用域绑定的丢弃。然后，新的线程被创建，它引发了错误，线程内部的绑定在展开栈时被丢弃。最后，在`main()`函数的最后一条信息之后，我们最初创建的第一个绑定被丢弃。
- en: Moving data between threads
  id: totrans-84
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在线程间移动数据
- en: 'We saw with the `Send` and `Sync` traits that the first one allows for a variable
    to be sent between threads, but how does that work? Can we just use a variable
    created in the main thread inside our secondary thread? Let''s try it:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过`Send`和`Sync`特质看到了第一个特质允许变量在线程间传递，但它是如何工作的？我们能否在次要线程中使用在主线程中创建的变量？让我们试一试：
- en: '[PRE5]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'What we did was create a vector outside the thread and then use it from inside.
    But it seems it does not work. Let''s see what the compiler tells us:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 我们所做的是在线程外部创建一个向量，然后从内部使用它。但看起来它不起作用。让我们看看编译器告诉我们什么：
- en: '![](img/b2e48acd-7fe8-4108-9167-a6d87885dba4.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b2e48acd-7fe8-4108-9167-a6d87885dba4.png)'
- en: That's interesting. The compiler noticed that the `my_vec` binding would be
    dropped at the end of the `main()` function, and that the inner thread could live
    longer. This is not the case in our example, since we `join()` both threads before
    the end of the `main()` function, but it could happen in a scenario where a thread
    is creating more threads and then ending itself. This would make the reference
    inside the thread invalid, and Rust does not allow that.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 这很有趣。编译器注意到`my_vec`绑定将在`main()`函数的末尾被丢弃，而内部线程可以存活得更久。在我们的例子中并不是这样，因为我们`join()`了两个线程，在`main()`函数结束之前，但在一个场景中，一个线程创建更多的线程然后结束自己，这种情况可能会发生。这将使线程内部的引用无效，而Rust不允许这种情况发生。
- en: The move keyword
  id: totrans-90
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 移动关键字
- en: 'Nevertheless, it gives a great explanation of something we can do. We have
    two options: share the binding between the threads or send it to the second one.
    Since we won''t use it in the main thread, we can add the `move` keyword before
    the closure and send the vector to the new thread, since it''s `Send`. Let''s
    see how we can make it work:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，它为我们能做的事情提供了一个很好的解释。我们有两种选择：在线程间共享绑定或将它发送到第二个线程。由于我们不会在主线程中使用它，我们可以在闭包之前添加`move`关键字并将向量发送到新的线程，因为它实现了`Send`特质。让我们看看我们如何让它工作：
- en: '[PRE6]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: This now compiles and shows the list of numbers in the console, perfect! But,
    what if we want to be able to see it in the main thread, too? Trying to print
    the vector after the spawning of the second thread won't work, since the variable
    has been moved to the new thread, and we already saw that if we don't move the
    vector we cannot use it inside the thread. What can we do?
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 现在代码可以编译，并在控制台显示了数字列表，太棒了！但是，如果我们想在主线程中也能看到它怎么办？在第二个线程启动后尝试打印向量是不行的，因为变量已经被移动到了新的线程，而且我们已经看到如果我们不移动向量，我们无法在线程中使用它。我们该怎么办？
- en: Sharing data between threads
  id: totrans-94
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 线程间共享数据
- en: 'There is one special reference-counted pointer that can be shared between threads
    that we already mentioned: `std::sync::Arc`. The main difference from the `Rc`
    is that the `Arc` counts the references with an atomic counter. This means that
    the kernel will make sure that all updates to the reference count will happen
    one by one, making it thread-safe. Let''s see it with an example:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经提到过一个可以在线程间共享的特殊引用计数指针：`std::sync::Arc`。与 `Rc` 的主要区别在于，`Arc` 使用原子计数器来计数引用。这意味着内核将确保所有对引用计数的更新都会逐个发生，使其线程安全。让我们用一个例子来看看：
- en: '[PRE7]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: As you can see, the vector is used both inside the second thread and in the
    main thread. You might be wondering what `clone()` means in the pointer. Are we
    cloning the vector? Well, that would be the easy solution, right? The real deal
    is that we are just getting a new reference to the vector. That's because the
    `Clone` trait is not a normal clone in the `Arc`. It will return a new `Arc`,
    yes, but it will also increase the reference count. And since both instances of
    `Arc` will have the same pointers to the reference counter and the vector, we
    will be effectively sharing the vector.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，向量在第二个线程和主线程中都被使用。你可能想知道指针中的 `clone()` 是什么意思。我们是克隆向量吗？嗯，那将是一个简单的解决方案，对吧？实际情况是，我们只是得到了向量的新引用。这是因为
    `Clone` 特性在 `Arc` 中并不是一个普通的克隆。它将返回一个新的 `Arc`，是的，但它也会增加引用计数。由于两个 `Arc` 实例都将有相同的指针指向引用计数器和向量，我们将有效地共享这个向量。
- en: 'How is it possible to simply debug the vector pointer inside the `Arc`? This
    is an interesting trick. `Arc<T>` implements `Deref<T>`, which means that it will
    automatically dereference to the vector it''s pointing to when calling the debug.
    Interestingly enough, there are two traits that allow that automatic dereference:
    `Deref` and `DerefMut`. As you might guess, the former gives you an immutable
    borrow of the contained value, while the latter gives you a mutable borrow.'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 如何简单地调试 `Arc` 内部的向量指针？这是一个有趣的技巧。`Arc<T>` 实现了 `Deref<T>`，这意味着在调用调试时，它将自动解引用到它所指向的向量。有趣的是，有两个特性允许这种自动解引用：`Deref`
    和 `DerefMut`。正如你可能猜到的，前者给你一个包含值的不可变借用，而后者给你一个可变借用。
- en: '`Arc` only implements `Deref`, not `DerefMut`, so we are not able to mutate
    what we have inside of it. But wait, we have cells that can mutate while being
    immutable, right? Well, there is an issue with them. The behavior we have seen
    from the `Arc`, of being able to be shared among threads, is only thanks to implementing
    the `Sync` trait, and it will only implement it if the inner value implements
    `Sync` and `Send`. Cells can be sent between threads, they implement `Send`, but
    they do not implement `Sync`. `Vec`, on the other hand, implements whatever the
    inside values implement, so in this case, it was both `Send` and `Sync`.'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '`Arc` 只实现了 `Deref`，而没有实现 `DerefMut`，所以我们无法修改其内部的内容。但是等等，我们不是有可以保持不可变状态的同时进行修改的
    cells 吗？嗯，它们确实存在一个问题。我们从 `Arc` 看到的能够在线程间共享的行为，仅仅是因为实现了 `Sync` 特性，而且它只有在内部值实现了
    `Sync` 和 `Send` 时才会实现它。Cells 可以在线程间传递，它们实现了 `Send`，但它们没有实现 `Sync`。另一方面，`Vec` 实现了内部值的任何实现，所以在这种情况下，它既是
    `Send` 也是 `Sync`。'
- en: 'So, is that it? Can''t we mutate anything inside an `Arc`? As you might have
    guessed, that''s not the case. If what we want to share between threads is an
    integer or a Boolean, we can use any of the `std::sync::atomic` integers and Booleans,
    even though some are not stable yet. They implement `Sync` and they have interior
    mutability with their `load()` and `store()` methods. You will only need to specify
    the memory ordering of the operation. Let''s see how that works:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，就这样了吗？我们能在 `Arc` 内部修改任何东西吗？正如你可能猜到的，情况并非如此。如果我们想在线程间共享的是整数或布尔值，我们可以使用任何 `std::sync::atomic`
    整数和布尔值，即使其中一些还不稳定。它们实现了 `Sync`，并且它们通过 `load()` 和 `store()` 方法具有内部可变性。你只需要指定操作的内存排序即可。让我们看看它是如何工作的：
- en: '[PRE8]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'If you run this program multiple times, you will see that the final number
    will be different each time, and none of them will be 500,000 (it could happen,
    but it''s almost impossible). What we have is similar to a data race:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你多次运行这个程序，你会看到最终数字每次都会不同，而且它们都不会是500,000（可能会发生，但几乎不可能）。我们有的类似于数据竞争：
- en: '![](img/84daab71-a9b4-4fd9-b233-bd78e7090d5f.png)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![](img/84daab71-a9b4-4fd9-b233-bd78e7090d5f.png)'
- en: But wait, can't Rust prevent all data races? Well, this is not exactly a data
    race. When we save the integer, we don't check whether it has changed, so we are
    overriding whatever was written there. We are not using the advantages Rust gives
    us. It will make sure that the state of the variable is consistent, but it won't
    prevent logic errors.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 但等等，Rust不能防止所有数据竞争吗？嗯，这并不完全是一个数据竞争。当我们保存整数时，我们没有检查它是否已更改，所以我们覆盖了那里写下的任何内容。我们没有使用Rust给予我们的优势。它将确保变量的状态是一致的，但它不会防止逻辑错误。
- en: 'The issue is that when we store it back, that value has already changed. To
    avoid it, atomics have the great `fetch_add()` function and its friends `fetch_sub()`,
    `fetch_and()`, `fetch_or()`, and `fetch_xor()`. They will perform the complete
    operation atomically. They also have the great `compare_and_swap()` and `compare_exchange()`
    functions, which can be used to create locks. Let''s see how that would work:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 问题在于当我们存储它回去时，那个值已经改变了。为了避免这种情况，原子操作有伟大的`fetch_add()`函数及其朋友`fetch_sub()`、`fetch_and()`、`fetch_or()`和`fetch_xor()`。它们将完整操作原子化。它们还有伟大的`compare_and_swap()`和`compare_exchange()`函数，可以用来创建锁。让我们看看这将如何工作：
- en: '[PRE9]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'As you can see now, the result is 500,000 every time you run it. If you want
    to perform more complex operations, you will need a lock. You can do that with
    an `AtomicBool`, for example, where you can wait for it to be `false`, then swap
    it with `true` and then perform operations. You would need to make sure that all
    your threads only change values when the lock is set to `true` by them, by using
    some memory ordering. Let''s see an example:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你现在所看到的，每次运行的结果都是500,000。如果你想执行更复杂的操作，你需要一个锁。你可以用`AtomicBool`来做，例如，你可以等待它变为`false`，然后将其交换为`true`并执行操作。你需要确保所有线程只在锁被它们设置为`true`时更改值，通过使用某种内存排序。让我们看看一个例子：
- en: '[PRE10]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: If you run it, you will see that it works perfectly. But this only works because
    in both threads we only change the value between the lock acquisition and the
    lock release. In fact, this is so safe that we could avoid using an atomic integer
    altogether, even though Rust won't allow us to do so in safe code.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你运行它，你会看到它工作得非常完美。但这只因为在这两个线程中，我们只在锁定和释放锁之间改变值。事实上，这是如此安全，以至于我们可以完全避免使用原子整数，尽管Rust在安全代码中不允许我们这样做。
- en: 'Now that we have seen how to mutate integers shared between threads, you might
    be wondering if something similar can be done with other types of bindings. As
    you can probably guess, it can. You will need to use `std::sync::Mutex`, and it
    will be much more expensive in performance terms than using atomic operations,
    so use them with caution. Let''s see how they work:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经看到了如何在线程间共享的整数进行变异的方法，你可能想知道是否可以对其他类型的绑定做类似的事情。正如你可能猜到的，是可以的。你需要使用`std::sync::Mutex`，在性能方面这会比使用原子操作要昂贵得多，所以请谨慎使用。让我们看看它们是如何工作的：
- en: '[PRE11]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'It will output something similar to this:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 它将输出类似的内容：
- en: '![](img/b66f3067-2acb-443f-a7b2-0f95faaf398a.png)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b66f3067-2acb-443f-a7b2-0f95faaf398a.png)'
- en: If you analyze the output closely, you will see that it will first add all numbers
    from 0 to 49 and then do the same again. If both threads were running in parallel,
    shouldn't all numbers be randomly distributed? Maybe two 1s first, then two 2s,
    and so on?
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你仔细分析输出，你会看到它首先将0到49的所有数字相加，然后再次执行相同的操作。如果两个线程都在并行运行，所有数字不应该是随机分布的吗？也许先有两个1，然后是两个2，以此类推？
- en: The main issue with sharing information between threads is that when the `Mutex`
    locks, it requires synchronization from both threads. This is perfectly fine and
    safe, but it takes a lot of time to switch from one thread to another to write
    in the vector. This is why the kernel scheduler allows for one of the threads
    to work for some time before locking the `Mutex`. If it was locking and unlocking
    the `Mutex` for each iteration, it would take ages to finish.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 在线程间共享信息的主要问题是，当`Mutex`锁定时，它需要来自两个线程的同步。这是完全正常和安全的，但它需要花费很多时间从一个线程切换到另一个线程来写入向量。这就是为什么内核调度器允许在锁定`Mutex`之前让其中一个线程工作一段时间。如果它每次迭代都锁定和解锁`Mutex`，那么完成它将需要很长时间。
- en: This means that if your loops were more than 50 iterations, maybe something
    like 1 million per loop, you would see that after some time, one of the threads
    would stop to give priority to the second one. In small numbers of iterations,
    though, you will see that one runs after the other.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着如果你的循环超过50次迭代，也许每个循环1百万次，你会在一段时间后看到，其中一个线程会停止，以便优先考虑第二个线程。然而，在迭代次数较少的情况下，你会看到它们一个接一个地运行。
- en: A `Mutex` gets locked when you call `lock()` and gets unlocked when it goes
    out of scope. In this case, since there is no binding to it, it will go out of
    scope after calling `push(i)`, so we could add more computation after it and it
    would be done without requiring synchronization between threads. Sometimes, it
    might even be useful to create artificial scopes to unlock the `Mutex` as soon
    as possible if our work involves more than one line and we need a binding.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 当你调用`lock()`时，互斥锁被锁定，当它超出作用域时解锁。在这种情况下，由于没有与之绑定，它将在调用`push(i)`后超出作用域，因此我们可以在它之后添加更多计算，而无需在线程之间进行同步。有时，如果我们的工作涉及多行并且我们需要绑定，创建人工作用域以尽快解锁互斥锁可能甚至是有用的。
- en: 'There is an extra issue we have to take into account when working with Mutexes:
    thread panicking. If your thread panics while the `Mutex` is locked, the `lock()`
    function in another thread will return a `Result::Err(_)`, so if we call `unwrap()`
    every time we `lock()` our `Mutex`, we can get into big trouble, since all threads
    would panic. This is called `Mutex` poisoning and there is a way to avoid it.'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们使用互斥锁时，必须考虑的一个额外问题是线程崩溃。如果你的线程在互斥锁锁定时崩溃，另一个线程中的`lock()`函数将返回`Result::Err(_)`，所以如果我们每次`lock()`互斥锁时都调用`unwrap()`，我们可能会遇到大麻烦，因为所有线程都会崩溃。这被称为`Mutex`中毒，并且有方法可以避免它。
- en: 'When a `Mutex` is poisoned because a thread panicked while having it locked,
    the error result of calling the `lock()` method will return the poisoning error.
    We can recover from it by calling the `into_inner()` method. Let''s see an example
    of how this would work:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 当互斥锁因为一个线程在锁定时崩溃而中毒时，调用`lock()`方法的错误结果将返回中毒错误。我们可以通过调用`into_inner()`方法从中恢复。让我们看看一个例子，看看这是如何工作的：
- en: '[PRE12]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'As you can see in the code, the second thread will panic after inserting the
    first number in the vector. I added a small 1-second sleep in the main thread
    to make sure that the secondary thread would execute before the main one. If you
    run it, you will get something similar to this:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 如你在代码中所见，第二个线程在向向量插入第一个数字后会崩溃。我在主线程中添加了一个短暂的1秒休眠，以确保在主线程之前执行副线程。如果你运行它，你会得到类似以下的结果：
- en: '![](img/174110c7-bce9-4437-b31e-2aa46881b193.png)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/174110c7-bce9-4437-b31e-2aa46881b193.png)'
- en: As you can see, once a `Mutex` has been poisoned, it will stay poisoned for
    all of its life. You should therefore try to avoid any behavior that could lead
    to a panic once you get the lock in a `Mutex`. In any case, you can still use
    it and as you can see, the final vector will contain values from both threads;
    only the `0` from the secondary thread, until the panic, and then the rest from
    the main thread. Make sure not to `unwrap()` a `Mutex` in a critical application,
    as it will make all your threads panic if you do it in all your threads after
    the first panic.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，一旦`Mutex`被中毒，它将一直保持中毒状态。因此，你应该尽量避免任何可能导致在`Mutex`中获取锁后崩溃的行为。无论如何，你仍然可以使用它，并且如你所见，最终的向量将包含来自两个线程的值；只有来自副线程的`0`，直到崩溃，然后是主线程的其余部分。确保不要在关键应用程序中`unwrap()`互斥锁，因为这将在第一次崩溃后使所有线程崩溃。
- en: Channels between threads
  id: totrans-124
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 线程间的通道
- en: There is an extra way of sending information between two or more threads. They
    are called channels, or more specifically, multi-producer, single-consumer FIFO
    communication primitives.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在两个或多个线程之间发送信息有另一种方式。它们被称为通道，或者更具体地说，是多生产者、单消费者FIFO通信原语。
- en: Let's first analyze what that means. Since they are multi-producer channels,
    you can send the data to the receiver from multiple threads at the same time.
    In the same way, since they are single-consumers, only one receiver will receive
    data from all the associated senders in the channel. Finally, FIFO comes from
    **first input, first output**, which means that the messages in the channel will
    be ordered by their creation timestamp, and you will only be able to read the
    second `message` after reading the first one in the receiver.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们来分析一下这意味着什么。由于它们是多生产者通道，你可以同时从多个线程向接收者发送数据。同样，由于它们是单消费者，只有一个接收者会从通道中所有相关的发送者那里接收数据。最后，FIFO来源于**先入先出**，这意味着通道中的消息将按照它们的创建时间戳进行排序，你只能在读取接收器中的第一个消息之后才能读取第二个`消息`。
- en: These channels are located in the `std::sync::mpsc` module, and they are really
    useful for logging or telemetry, for example. One thread can manage the I/O interface
    with the communication or logging mechanism, while the others can send this thread
    the information they want to log or communicate. An approach using these channels
    is being studied for OpenStratos, for a stratospheric balloon-control software
    being written in Rust.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 这些通道位于`std::sync::mpsc`模块中，它们对于日志记录或遥测等用途非常有用。一个线程可以管理与通信或日志机制的I/O接口，而其他线程可以向这个线程发送它们想要记录或通信的信息。对于用Rust编写的对流层气球控制软件，正在研究使用这些通道的方法。
- en: 'A channel consists of a `Sender` and a `Receiver`. `Sender` implements `Clone`,
    so that cloning the sender, multiple threads can send information to the associated
    receiver. There are two types of senders: `Sender` and `SyncSender`. The former
    will just send the message to the receiver without checking anything extra, while
    the latter will send the message only when the receiver''s buffer has enough space.
    It will block the current thread until the message is sent.'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 通道由一个`Sender`和一个`Receiver`组成。`Sender`实现了`Clone`，这样就可以克隆发送者，多个线程可以向相关的接收者发送信息。有两种类型的发送者：`Sender`和`SyncSender`。前者会将消息直接发送到接收者而不会检查任何额外的内容，而后者只有在接收者的缓冲区有足够空间时才会发送消息。它将阻塞当前线程，直到消息发送完成。
- en: Channels are created using the `channel()` and `sync_channel()` functions in
    the `std::sync::mpsc` module. They will return a tuple with a `Sender` or `SyncSender`,
    respectively, as the first element and a `Receiver` as the second one. Since `Sender`
    and `Receiver` implement `Send`, they can safely be sent to another thread with
    the `move` keyword. In the case of a synchronous channel, the `sync_channel()`
    will require a `usize` to set the buffer size. The `Sender` will block if the
    buffer is full. On the other hand, asynchronous channels work as if they had an
    infinite buffer, they will always accept sending new data.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 通道是通过`std::sync::mpsc`模块中的`channel()`和`sync_channel()`函数创建的。它们将分别返回一个包含`Sender`或`SyncSender`（分别作为第一个元素）和一个`Receiver`（作为第二个元素）的元组。由于`Sender`和`Receiver`实现了`Send`，它们可以安全地使用`move`关键字发送到另一个线程。在同步通道的情况下，`sync_channel()`将需要一个`usize`来设置缓冲区大小。如果缓冲区已满，`Sender`将阻塞。另一方面，异步通道就像它们有一个无限缓冲区一样工作，它们总是会接受发送新数据。
- en: 'Each channel can only send or receive one particular type of data, so if a
    channel is configured to send `u32`, only one `u32` per message can be sent. You
    can configure it to send your own types, though, such as a custom `Frame` type
    with all the information you might want to send. Let''s see how a channel works:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 每个通道只能发送或接收一种特定的数据类型，所以如果一个通道被配置为发送`u32`，则每条消息只能发送一个`u32`。不过，你也可以配置它发送你自己的类型，例如一个包含你可能想要发送的所有信息的自定义`Frame`类型。让我们看看通道是如何工作的：
- en: '[PRE13]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: As you can see in the code, five threads get created with an iterator, and their
    handles are collected in a vector. These threads will have a name containing the
    thread number, and will send the `Hello from sender {}!` message to the receiver.
    For each thread, the sender gets cloned so that the clone can be moved to the
    thread closure.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 如代码所示，使用迭代器创建了五个线程，并将它们的句柄收集到一个向量中。这些线程将有一个包含线程编号的名称，并将`Hello from sender {}!`消息发送给接收者。对于每个线程，发送者都会被克隆，以便克隆可以被移动到线程闭包中。
- en: Then, a `while` loop will check with a 1-second timeout for the messages. It
    should be enough, since messages will be sent as soon as the threads start. In
    the case that no message gets received for one second (or all the senders get
    out of scope), the `while` loop will stop printing the messages and the threads
    will be joined. Finally, a completion message will be printed.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，一个 `while` 循环将检查消息，超时时间为1秒。这应该足够了，因为消息会在线程启动后立即发送。如果一秒钟内没有收到消息（或者所有发送者都超出作用域），`while`
    循环将停止打印消息，并将线程连接起来。最后，将打印一条完成消息。
- en: 'If you run this example, you will see an output similar to this one:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你运行这个示例，你将看到类似以下输出的内容：
- en: '![](img/b6376638-1397-4e17-9632-110b3f7d6fd5.png)'
  id: totrans-135
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/b6376638-1397-4e17-9632-110b3f7d6fd5.png)'
- en: As you can see, the threads are not executed in any particular order. They will
    send the message to the receiver, and the receiver will read them in the received
    order. Since this example is asynchronous, we don't need to wait for the receiver
    to empty the buffer to send new messages, so it's really lightweight. In fact,
    we could join the threads before reading any messages from the receiver.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，线程的执行顺序并不特定。它们会将消息发送给接收者，接收者将按接收顺序读取它们。由于这个示例是异步的，我们不需要等待接收者清空缓冲区以发送新消息，所以它非常轻量级。实际上，我们可以在读取接收者的任何消息之前就连接线程。
- en: Multithreading crates
  id: totrans-137
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多线程crate
- en: Until now, we have only been using the standard library to manipulate threads,
    but thanks to the great *crates.io* ecosystem, we can make use of more approaches
    that will improve our development speed as well as the performance of our code.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们只使用标准库来操作线程，但多亏了伟大的 *crates.io* 生态系统，我们可以利用更多的方法来提高我们的开发速度以及代码的性能。
- en: Non-blocking data structures
  id: totrans-139
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 非阻塞数据结构
- en: One of the issues we saw earlier was that if we wanted to share something more
    complex than an integer or a Boolean between threads and if we wanted to mutate
    it, we needed to use a `Mutex`. This is not entirely true, since one crate, Crossbeam,
    allows us to use great data structures that do not require locking a `Mutex`.
    They are therefore much faster and more efficient.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前看到的一个问题是，如果我们想在线程之间共享比整数或布尔值更复杂的东西，并且我们想修改它，我们需要使用 `Mutex`。这并不完全正确，因为有一个crate，Crossbeam，允许我们使用不需要锁定
    `Mutex` 的大数据结构。因此，它们要快得多，效率也更高。
- en: Often, when we want to share information between threads, it's usually a list
    of tasks that we want to work on cooperatively. Other times, we want to create
    information in multiple threads and add it to a list of information. It's therefore
    not so usual for multiple threads to be working with exactly the same variables,
    since as we have seen, that requires synchronization and it will be slow.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，当我们想在线程之间共享信息时，我们通常想要合作处理的任务列表。有时，我们想在多个线程中创建信息并将其添加到信息列表中。因此，多个线程通常不会使用完全相同的变量，因为我们已经看到，这需要同步，并且会变慢。
- en: 'This is where Crossbeam shows all its potential. Crossbeam gives us some multithreaded
    queues and stacks, where we can insert data and consume data from different threads.
    We can, in fact, have some threads doing an initial processing of the data and
    others performing a second phase of the processing. Let''s see how we can use
    these features. First, add `crossbeam` to the dependencies of the crate in the
    `Cargo.toml` file. Then, we start with a simple example:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是Crossbeam展示其全部潜力的地方。Crossbeam为我们提供了一些多线程队列和栈，我们可以从不同的线程中插入和消费数据。实际上，我们可以让一些线程进行数据的初步处理，而其他线程则执行处理的第二阶段。让我们看看我们如何使用这些功能。首先，将
    `crossbeam` 添加到 `Cargo.toml` 文件中crate的依赖项。然后，我们从简单的示例开始：
- en: '[PRE14]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Let's first understand what this example does. It will iterate 1,000,000 times
    in 5 different threads, and each time it will push a 10 to a queue. Queues are
    FIFO lists, first input, first output. This means that the first number entered
    will be the first one to `pop()` and the last one will be the last to do so. In
    this case, all of them are a 10, so it doesn't matter.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先了解这个示例做了什么。它将在5个不同的线程中迭代1,000,000次，每次都会将一个10推入队列。队列是FIFO列表，先入先出。这意味着第一个输入的数字将是第一个
    `pop()` 的，最后一个输入的将是最后一个 `pop()` 的。在这种情况下，所有数字都是10，所以这并不重要。
- en: Once the threads finish populating the queue, we iterate over it and we add
    all the numbers. A simple computation should make you able to guess that if everything
    goes perfectly, the final number should be 50,000,000\. If you run it, that will
    be the result, and that's not all. If you run it by executing `cargo run --release`,
    it will run blazingly fast. On my computer, it took about one second to complete.
    If you want, try to implement this code with the standard library `Mutex` and
    vector, and you will see that the performance difference is amazing.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦线程完成队列的填充，我们就遍历它并将所有数字添加进去。一个简单的计算应该让你能够猜出，如果一切顺利，最终的数字应该是50,000,000。如果你运行它，那将是结果，而且不仅如此。如果你通过执行`cargo
    run --release`来运行它，它将运行得非常快。在我的电脑上，它大约需要一秒钟来完成。如果你想，尝试使用标准库`Mutex`和向量实现这段代码，你将看到性能差异惊人。
- en: As you can see, we still needed to use an `Arc` to control the multiple references
    to the queue. This is needed because the queue itself cannot be duplicated and
    shared, it has no reference count.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，我们仍然需要使用`Arc`来控制对队列的多个引用。这是因为队列本身不能被复制和共享，它没有引用计数。
- en: 'Crossbeam not only gives us FIFO queues. We also have LIFO stacks. LIFO comes
    from last input, first output, and it means that the last element you inserted
    in the stack will be the first one to `pop()`. Let''s see the difference with
    a couple of threads:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: Crossbeam不仅为我们提供了FIFO队列。我们还有LIFO栈。LIFO来源于后进先出，这意味着你最后插入栈中的元素将是第一个被`pop()`的。让我们通过几个线程来看看它们的区别：
- en: '[PRE15]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'As you can see in the code, we have two shared variables: a queue and a stack.
    The secondary thread will push new values to each of them, in the same order,
    from 0 to 4\. Then, the main thread will try to get them back. It will loop indefinitely
    and use the `try_pop()` method. The `pop()` method can be used, but it will block
    the thread if the queue or the stack is empty. This will happen in any case once
    all values get popped, since no new values are being added, so the `try_pop()`
    method will help not to block the main thread and end gracefully.'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 如代码所示，我们有两个共享变量：一个队列和一个栈。次要线程将按相同的顺序将新值推送到它们中，从0到4。然后，主线程将尝试取回它们。它将无限循环并使用`try_pop()`方法。可以使用`pop()`方法，但如果队列或栈为空，它将阻塞线程。一旦所有值都被弹出，这将在任何情况下发生，因为没有新的值被添加，所以`try_pop()`方法将帮助不会阻塞主线程并优雅地结束。
- en: The way it checks whether all the values were popped is by counting how many
    times it failed to pop a new value. Every time it fails, it will wait for 100
    milliseconds, while the push thread only waits for 50 milliseconds between pushes.
    This means that if it tries to pop new values two times and there are no new values,
    the pusher thread has already finished.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 它通过计算尝试弹出新值失败的次数来检查是否所有值都被弹出。每次失败，它将等待100毫秒，而推送线程只在推送之间等待50毫秒。这意味着如果它尝试弹出新值两次而没有新值，推送线程已经完成。
- en: 'It will add values as they are popped to two vectors and then print the result.
    In the meantime, it will print messages about pushing and popping new values.
    You will understand this better by seeing the output:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 它将弹出的值添加到两个向量中，然后打印结果。同时，它将打印有关推送和弹出新值的消息。通过查看输出，你会更好地理解这一点：
- en: '![](img/a9446abb-afee-4432-a2f2-7f8d33925c1f.png)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a9446abb-afee-4432-a2f2-7f8d33925c1f.png)'
- en: Note that the output can be different in your case, since threads don't need
    to be executed in any particular order.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，由于线程不需要按任何特定顺序执行，所以你的输出可能会有所不同。
- en: In this example output, as you can see, it first tries to get something from
    the queue and the stack but there is nothing there, so it sleeps. The second thread
    then starts pushing things, two numbers actually. After this, the queue and the
    stack will be `[0, 1]`. Then, it pops the first item from each of them. From the
    queue, it will pop the `0` and from the stack it will pop the `1` (the last one),
    leaving the queue as `[1]` and the stack as `[0]`.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例输出中，如你所见，它首先尝试从队列和栈中获取一些东西，但那里没有，所以它休眠。然后，第二个线程开始推送东西，实际上是两个数字。之后，队列和栈将变为`[0,
    1]`。然后，它从每个中弹出第一个项目。从队列中，它将弹出`0`，从栈中弹出`1`（最后一个），使队列变为`[1]`，栈变为`[0]`。
- en: It will go back to sleep and the secondary thread will insert a `2` in each
    variable, leaving the queue as `[1, 2]` and the stack as `[0, 2]`. Then, the main
    thread will pop two elements from each of them. From the queue, it will pop the
    `1` and the `2`, while from the stack it will pop the `2` and then the `0`, leaving
    both empty.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，它将再次进入休眠状态，次要线程将每个变量的值增加2，使队列变为 `[1, 2]`，堆栈变为 `[0, 2]`。然后，主线程将从每个队列和堆栈中弹出两个元素。从队列中，它将弹出
    `1` 和 `2`，而从堆栈中，它将弹出 `2` 然后是 `0`，使它们都为空。
- en: The main thread then goes to sleep, and for the next two tries, the secondary
    thread will push one element and the main thread will pop it, twice.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 主线程随后进入休眠状态，在接下来的两次尝试中，次要线程将推送一个元素，而主线程将弹出它，两次。
- en: It might seem a little bit complex, but the idea is that these queues and stacks
    can be used efficiently between threads without requiring a `Mutex`, and they
    accept any `Send` type. This means that they are great for complex computations,
    and even for multi-staged complex computations.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这可能看起来有点复杂，但想法是这些队列和堆栈可以在线程之间高效地使用，而无需使用 `Mutex`，并且它们接受任何 `Send` 类型。这意味着它们非常适合复杂计算，甚至适合多阶段复杂计算。
- en: 'The Crossbeam crate also has some helpers to deal with epochs and even some
    variants of the mentioned types. For multithreading, Crossbeam also adds a great
    utility: scoped threads.'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: Crossbeam crate 还提供了一些辅助工具来处理时代和提到的类型的某些变体。对于多线程，Crossbeam 还增加了一个非常有用的功能：作用域线程。
- en: Scoped threads
  id: totrans-159
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 作用域线程
- en: In all our examples, we have used standard library threads. As we have discussed,
    these threads have their own stack, so if we want to use variables that we created
    in the main thread we will need to *send* them to the thread. This means that
    we will need to use things such as `Arc` to share non-mutable data. Not only that,
    having their own stack means that they will also consume more memory and eventually
    make the system slower if they use too much.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们所有的例子中，我们都使用了标准库线程。正如我们讨论的那样，这些线程有自己的堆栈，所以如果我们想在主线程中使用的变量，我们需要将它们 *发送* 到线程。这意味着我们需要使用像
    `Arc` 这样的东西来共享不可变数据。不仅如此，由于它们有自己的堆栈，它们也会消耗更多的内存，如果使用过多，最终会使系统变慢。
- en: Crossbeam gives us some special threads that allow sharing stacks between them.
    They are called scoped threads. Using them is pretty simple and the crate documentation
    explains them perfectly; you will just need to create a `Scope` by calling `crossbeam::scope()`.
    You will need to pass a closure that receives the Scope. You can then call `spawn()`
    in that scope the same way you would do it in `std::thread`, but with one difference,
    you can share immutable variables among threads if they were created inside the
    scope or moved to it.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: Crossbeam 给我们一些特殊的线程，允许它们之间共享堆栈。它们被称为作用域线程。使用它们相当简单，crate 文档解释得非常完美；你只需要通过调用
    `crossbeam::scope()` 创建一个 `Scope`。你需要传递一个接收作用域的闭包。你可以在该范围内调用 `spawn()`，就像在 `std::thread`
    中做的那样，但有一个区别，如果你在作用域内创建或将其移动到作用域中，你可以在线程之间共享不可变变量。
- en: 'This means that for the queues or stacks we just talked about, or for atomic
    data, you can simply call their methods without requiring an `Arc`! This will
    improve the performance even further. Let''s see how it works with a simple example:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着对于我们刚才提到的队列或堆栈，或者对于原子数据，你可以简单地调用它们的方法，而无需使用 `Arc`！这将进一步提高性能。让我们看看它如何通过一个简单的例子来工作：
- en: '[PRE16]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Let's see what this code does. It will first just create a vector with all the
    numbers from 0 to 1000\. Then, for each of them, in a `crossbeam` scope, it will
    run one scoped thread per number and perform a supposedly complex computation.
    This is just an example, since it will just return a result of a simple second-order
    function.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看这段代码做了什么。它首先将创建一个包含从0到1000的所有数字的向量。然后，对于每一个数字，在一个 `crossbeam` 范围内，它将为每个数字运行一个作用域线程并执行一个假设的复杂计算。这只是一个例子，因为它将只返回一个简单二阶函数的结果。
- en: Interestingly enough, though, the `scope.spawn()` method allows returning a
    result of any type, which is great in our case. The code will add each result
    to a vector. This won't directly add the resulting number, since it will be executed
    in parallel. It will add a result guard, which we will be able to check outside
    the scope.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，有趣的是，`scope.spawn()` 方法允许返回任何类型的结果，这在我们的情况下是非常好的。代码将把每个结果添加到一个向量中。由于它将在并行执行，所以它不会直接添加结果数字，而是添加一个结果保护器，我们可以在范围外检查它。
- en: Then, after all the threads run and return the results, the scope will end.
    We can now check all the results, which are guaranteed to be ready for us. For
    each of them, we just need to call `join()` and we will get the result. Then,
    we sum it up to check that they are actual results from the computation.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，在所有线程运行并返回结果后，作用域将结束。我们现在可以检查所有结果，它们保证对我们来说是准备好的。对于每一个，我们只需要调用 `join()`，我们就会得到结果。然后，我们将它们加起来以检查它们是否是实际的计算结果。
- en: This `join()` method can also be called inside the scope and get the results,
    but it will mean that if you do it inside the `for` loop, for example, you will
    block the loop until the result is generated, which is not efficient. The best
    thing is to at least run all the computations first and then start checking the
    results. If you want to perform more computations after them, you might find it
    useful to run the new computation in another loop or iterator inside the `crossbeam`
    scope.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 这个 `join()` 方法也可以在作用域内调用并获取结果，但这意味着如果您在 `for` 循环内这样做，例如，您将阻塞循环直到生成结果，这并不高效。最好的做法是至少先运行所有计算，然后再开始检查结果。如果您想在它们之后进行更多计算，您可能会发现将新的计算在
    `crossbeam` 作用域内的另一个循环或迭代器中运行很有用。
- en: But, how does `crossbeam` allow you to use the variables outside the scope freely?
    Won't there be data races? Here is where the magic happens. The scope will join
    all the inner threads before exiting, which means that no further code will be
    executed in the main thread until all the scoped threads finish. This means that
    we can use the variables of the main thread, also called **parent stack**, due
    to the main thread being the parent of the scope in this case without any issue.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，`crossbeam` 是如何让您在作用域外自由使用变量的呢？不会出现数据竞争吗？这就是魔法发生的地方。作用域将在退出之前将所有内部线程连接起来，这意味着在所有作用域线程完成之前，主线程将不会执行任何进一步的代码。这意味着我们可以使用主线程的变量，也称为
    **父栈**，因为在这种情况下，主线程是作用域的父线程，而没有任何问题。
- en: 'We can actually check what is happening by using the `println!()` macro. If
    we remember from previous examples, printing to the console after spawning some
    threads would usually run even before the spawned threads, due to the time it
    takes to set them up. In this case, since we have `crossbeam` preventing it, we
    won''t see it. Let''s check the example:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 我们实际上可以使用 `println!()` 宏来检查正在发生的事情。如果我们从之前的例子中记得，在生成一些线程后打印到控制台通常会先于生成的线程运行，这是因为设置它们所需的时间。在这种情况下，由于
    `crossbeam` 阻止了它，我们不会看到它。让我们检查以下示例：
- en: '[PRE17]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'If you run this code, you will see something similar to the following output:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您运行此代码，您将看到以下类似输出：
- en: '![](img/23ccb780-ea03-42ca-a70c-c597251ed1dd.png)'
  id: totrans-172
  prefs: []
  type: TYPE_IMG
  zh: '![](img/23ccb780-ea03-42ca-a70c-c597251ed1dd.png)'
- en: As you can see, scoped threads will run without any particular order. In this
    case, it will first run the `1`, then the `0`, then the `2`, and so on. Your output
    will probably be different. The interesting thing, though, is that the main thread
    won't continue executing until all the threads have finished. Therefore, reading
    and modifying variables in the main thread is perfectly safe.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，作用域线程将以没有任何特定顺序的方式运行。在这种情况下，它将首先运行 `1`，然后是 `0`，然后是 `2`，依此类推。您的输出可能不同。但有趣的是，主线程不会继续执行，直到所有线程都完成。因此，在主线程中读取和修改变量是绝对安全的。
- en: There are two main performance advantages with this approach; `Arc` will require
    a call to `malloc()` to allocate memory in the heap, which will take time if it's
    a big structure and the memory is a bit full. Interestingly enough, that data
    is already in our stack, so if possible, we should try to avoid duplicating it
    in the heap. Moreover, the `Arc` will have a reference counter, as we saw. And
    it will even be an atomic reference counter, which means that every time we clone
    the reference, we will need to atomically increment the count. This takes time,
    even more than incrementing simple integers.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 采用这种方法有两个主要性能优势；`Arc` 将需要调用 `malloc()` 来在堆中分配内存，如果这是一个大结构且内存有点满，这将花费时间。有趣的是，这些数据已经在我们的栈中了，所以如果可能的话，我们应该尽量避免在堆中重复它。此外，`Arc`
    将有一个引用计数器，正如我们所看到的。它甚至将是一个原子引用计数器，这意味着每次我们克隆引用时，我们都需要原子地增加计数。这需要时间，甚至比增加简单的整数还要多。
- en: Most of the time, we might be waiting for some expensive computations to run,
    and it would be great if they just gave all the results when finished. We can
    still add some more chained computations, using scoped threads, that will only
    be executed after the first ones finish, so we should use scoped threads more
    often than normal threads, if possible.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数时候，我们可能正在等待一些昂贵的计算运行，如果它们完成时能直接给出所有结果那就太好了。我们仍然可以添加一些链式计算，使用作用域线程，这些计算将在第一个计算完成后执行，所以如果可能的话，我们应该比正常线程更频繁地使用作用域线程。
- en: Thread pooling
  id: totrans-176
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 线程池
- en: So far, we have seen multiple ways of creating new threads and sharing information
    between them. Nevertheless, as we saw at the beginning of the chapter, the ideal
    number of threads we should spawn to do all the work should be around the number
    of virtual processors in the system. This means we should not spawn one thread
    for each chunk of work. Nevertheless, controlling what work each thread does can
    be complex, since you have to make sure that all threads have work to do at any
    given point in time.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经看到了创建新线程和它们之间共享信息的好几种方法。然而，正如我们在本章开头看到的，我们应该生成的理想线程数应该接近系统虚拟处理器的数量。这意味着我们不应该为每一块工作生成一个线程。尽管如此，控制每个线程执行的工作可能很复杂，因为你必须确保在任何给定时间点所有线程都有工作可做。
- en: Here is where thread pooling comes in handy. The `Threadpool` crate will enable
    you to iterate over all your work and for each of your small chunks, you can call
    something similar to a `thread::spawn()`. The interesting thing is that each task
    will be assigned to an idle thread, and no new thread will be created for each
    task. The number of threads is configurable and you can get the number of CPUs
    with other crates. Not only that, if one of the threads panics, it will automatically
    add a new one to the pool.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 正是在这里，线程池派上了用场。`Threadpool` crate 将允许你遍历所有的工作，并且对于你的每一个小块工作，你可以调用类似于 `thread::spawn()`
    的操作。有趣的是，每个任务将被分配给一个空闲线程，并且不会为每个任务创建新的线程。线程的数量是可以配置的，你可以使用其他 crate 来获取 CPU 的数量。不仅如此，如果其中一个线程发生恐慌，它将自动向池中添加一个新的线程。
- en: 'To see an example, first, let''s add `threadpool` and `num_cpus` as dependencies
    in our `Cargo.toml` file.  Then, let''s see an example code:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 为了看到示例，首先，让我们在我们的 `Cargo.toml` 文件中将 `threadpool` 和 `num_cpus` 添加为依赖项。然后，让我们看看一个示例代码：
- en: '[PRE18]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'This code will create a thread pool of threads with the number of logical CPUs
    in your computer. Then, it will add a number from 0 to 1,000,000 to an atomic
    `usize`, just to test parallel processing. Each addition will be performed by
    one thread. Doing this with one thread per operation (1,000,000 threads) would
    be really inefficient. In this case, though, it will use the appropriate number
    of threads, and the execution will be really fast. There is another crate that
    gives thread pools an even more interesting parallel processing feature: Rayon.'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码将创建一个具有计算机逻辑 CPU 数量的线程池。然后，它将一个从 0 到 1,000,000 的数字添加到一个原子的 `usize`，只是为了测试并行处理。每个加法操作将由一个线程执行。如果每个操作使用一个线程（1,000,000
    个线程）将会非常低效。然而，在这种情况下，它将使用适当的线程数量，执行将会非常快。还有一个 crate 提供了线程池一个更有趣的并行处理功能：Rayon。
- en: Parallel iterators
  id: totrans-182
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 并行迭代器
- en: If you can see the big picture in these code examples, you'll have realized
    that most of the parallel work has a long loop, giving work to different threads.
    It happened with simple threads and it happens even more with scoped threads and
    thread pools. It's usually the case in real life, too. You might have a bunch
    of data to process, and you can probably separate that processing into chunks,
    iterate over them, and hand them over to various threads to do the work for you.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你能在这些代码示例中看到整体情况，你就会意识到大多数并行工作都有一个长循环，将工作分配给不同的线程。这发生在简单的线程上，在作用域线程和线程池中发生得更多。在现实生活中通常也是这样。你可能有一堆数据要处理，你可能会将这个处理分成几块，遍历它们，并将它们交给不同的线程去完成工作。
- en: The main issue with that approach is that if you need to use multiple stages
    to process a given piece of data, you might end up with lots of boilerplate code
    that can make it difficult to maintain. Not only that, you might find yourself
    not using parallel processing sometimes due to the hassle of having to write all
    that code.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法的主要问题是，如果你需要使用多个阶段来处理给定数据，你可能会得到很多样板代码，这可能会使维护变得困难。不仅如此，你可能会发现自己有时不使用并行处理，因为必须编写所有这些代码的麻烦。
- en: Luckily, Rayon has multiple data parallelism primitives around iterators that
    you can use to parallelize any iterative computation. You can almost forget about
    the `Iterator` trait and use Rayon's `ParallelIterator` alternative, which is
    as easy to use as the standard library trait!
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，Rayon围绕迭代器提供了多个数据并行原语，你可以使用这些原语并行化任何迭代计算。你几乎可以忘记`Iterator`特性，并使用Rayon的`ParallelIterator`替代品，它和标准库特性一样容易使用！
- en: Rayon uses a parallel iteration technique called **work stealing**. For each
    iteration of the parallel iterator, the new value or values get added to a queue
    of pending work. Then, when a thread finishes its work, it checks whether there
    is any pending work to do and if there is, it starts processing it. This, in most
    languages, is a clear source of data races, but thanks to Rust, this is no longer
    an issue, and your algorithms can run extremely fast and in parallel.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: Rayon使用一种称为**工作窃取**的并行迭代技术。对于并行迭代器的每次迭代，新的值或值被添加到待处理工作的队列中。然后，当一个线程完成其工作后，它会检查是否有待处理的工作要做，如果有，它就开始处理。在大多数语言中，这是一个明显的数据竞争来源，但多亏了Rust，这不再是问题，你的算法可以运行得非常快，并且并行运行。
- en: 'Let''s look at how to use it for an example similar to those we have seen in
    this chapter. First, add `rayon` to your `Cargo.toml` file and then let''s start
    with the code:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何使用它来处理本章中我们看到的类似示例。首先，将`rayon`添加到你的`Cargo.toml`文件中，然后让我们从代码开始：
- en: '[PRE19]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: As you can see, this works just as you would write it in a sequential iterator,
    yet, it's running in parallel. Of course, running this example sequentially will
    be faster than running it in parallel thanks to compiler optimizations, but when
    you need to process data from files, for example, or perform very complex mathematical
    computations, parallelizing the input can give great performance gains.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所见，这就像你在顺序迭代器中编写的那样工作，然而，它是在并行运行的。当然，由于编译器的优化，顺序运行此示例会比并行运行快，但当你需要从文件中处理数据，例如，或执行非常复杂的数学计算时，并行化输入可以带来巨大的性能提升。
- en: Rayon implements these parallel iteration traits to all standard library iterators
    and ranges. Not only that, it can also work with standard library collections,
    such as `HashMap` and `Vec`. In most cases, if you are using the `iter()` or `into_iter()`
    methods from the standard library in your code, you can simply use `par_iter()`
    or `into_par_iter()` in those calls and your code should now be parallel and work
    perfectly.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: Rayon将这些并行迭代特性实现到了所有标准库迭代器和范围中。不仅如此，它还可以与标准库集合一起工作，例如`HashMap`和`Vec`。在大多数情况下，如果你在代码中使用标准库的`iter()`或`into_iter()`方法，你可以在这些调用中简单地使用`par_iter()`或`into_par_iter()`，并且你的代码现在应该是并行并且运行得很好的。
- en: But, beware, sometimes parallelizing something doesn't automatically improve
    its performance. Take into account that if you need to update some shared information
    between the threads, they will need to synchronize somehow, and you will lose
    performance. Therefore, multithreading is only great if workloads are completely
    independent and you can execute one without any dependency on the rest.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，要注意，有时并行化某物并不会自动提高其性能。考虑到如果你需要在线程之间更新一些共享信息，它们将需要以某种方式进行同步，这将导致性能损失。因此，只有在工作负载完全独立并且你可以独立执行而无需依赖其他任何内容时，多线程才是伟大的。
- en: Summary
  id: totrans-192
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we saw how our sequential algorithms can easily gain performance
    by running in parallel. This parallelism can be obtained in multiple ways, and
    in this chapter, we learned about multithreading. We saw how multithreading is
    really safe in Rust, and how we can take advantage of the crate ecosystem to improve
    our performance even more.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们看到了我们的顺序算法如何通过并行运行来轻松提高性能。这种并行性可以通过多种方式获得，在本章中，我们学习了多线程。我们看到了在Rust中多线程是如何真正安全的，以及我们如何利用crate生态系统进一步提高我们的性能。
- en: We learned about some performance enhancements we can develop for our multithreaded
    code, and how to use all the available tools to our advantage. You can now develop
    a high-performance concurrent application in Rust using multiple threads.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 我们了解了一些我们可以为我们的多线程代码开发的性能增强，以及如何使用所有可用的工具来发挥我们的优势。你现在可以使用多个线程在Rust中开发高性能并发应用程序。
- en: In the next chapter, we will look at asynchronous programming. The primitives
    we will look at enable us to write concurrent programs that won't lock our threads
    if we are waiting for some computation, without even requiring us to spawn new
    threads!
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将探讨异步编程。我们将探讨的原始程序使我们能够编写并发程序，即使我们在等待某些计算时，也不会锁定我们的线程，甚至不需要我们生成新的线程！
