<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Reactive Microservices - Increasing Capacity and Performance</h1>
                </header>
            
            <article>
                
<p><span>If you adhere to a microservices architecture for your application, you'll get the benefits of loose coupling, meaning that every microservice is standalone enough to be developed and maintained by separate teams. This is a kind of asynchronous approach to business tasks, but it's not the only benefit; there are others. You can increase your capacity and performance by only scaling the microservices that take a huge load. To achieve this, your microservice has to be reactive, and it has to be self-sustaining, interacting with other microservices via message passing.</span></p>
<p>In this chapter, you will learn what a reactive microservice is, and how to use message passing to ensure the connectivity of microservices. Also, we will discuss whether reactive microservices can be asynchronous.</p>
<p>In this chapter, we will cover the following topics: </p>
<ul>
<li>What is a reactive microservice?</li>
<li>JSON-RPC</li>
<li>gRPC</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Technical requirements</h1>
                </header>
            
            <article>
                
<p>This chapter will cover using <strong>remote procedure calls</strong> (<strong>RPCs</strong>) in Rust. You'll need a working Rust compiler, because we will create two examples with the <kbd>jsonrpc-http-server</kbd> and <kbd>grpc</kbd> crates.</p>
<p>If you want to test TLS connections, you'll need OpenSSL version 0.9, because the <kbd>grpc</kbd> crate doesn't support version 1.0 or higher yet. Most modern operating systems have switched to 1.0 already, but you can build the examples to a Docker image that supports <span>version </span>0.9, or wait till the <kbd>grpc</kbd> crate is updated to the latest OpenSSL version. We will build test examples without TLS.</p>
<p>You can find the sources of the examples from this chapter in the GitHub repository at, <a href="https://github.com/PacktPublishing/Hands-On-Microservices-with-Rust/tree/master/Chapter06">https://github.com/PacktPublishing/Hands-On-Microservices-with-Rust/tree/master/Chapter06</a>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">What is a reactive microservice?</h1>
                </header>
            
            <article>
                
<p>A microservices architecture implies the presence of multiple parts in an application. In the past, most applications were monoliths, with all of the parts contained in a single code base. The microservices approach gives us the opportunity to split a code base between multiple teams and developers, to have an individual life cycle for every microservice, and for parts to interact with a common protocol.</p>
<p>Does this mean that your application will be free from all of the flaws of a monolithic application? No. You can write microservices that are so closely related to each other that you can't even properly update them.</p>
<p>How is this possible? Imagine that you have a microservice that has to wait for the response of another microservice to send a response to a client. The other microservice, in turn, also has to wait for another microservice, and so on. If you closely link the microservices of an application, you will find the same drawbacks that you have with monoliths.</p>
<p>You have to write microservices as independent applications that can be reused for multiple projects, not only yours. How can you achieve that? Develop a reactive microservice. Let's look at what that is.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Loose coupling</h1>
                </header>
            
            <article>
                
<p>Loose coupling is a software design approach that <span><span>implies </span></span>every part of an application should know little information about the other parts. In traditional applications, if you write a GUI component, such as a button, it has to be possible to use it everywhere, for any application. As another example, if you develop a library to work with sound hardware, this also means you can use it with every application; the library is not limited to use in one kind of application. In microservices, however, loose coupling means that a microservice doesn't know anything about other microservices, or how many there are.</p>
<p>If you develop an application, you should write parts of it—microservices—as standalone applications. For example, a notification service that sends push notifications to mobile platforms won't know about CRM, accounting, or even the users. Is it possible to do this? Yes! You can write a microservice that uses a common protocol and interacts with other services via message passing. This is called a <strong>message-driven application</strong>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Message-driven applications</h1>
                </header>
            
            <article>
                
<p>Traditional microservices have an API that immediately returns a result and every participant of a working application has to know about the other parts. This approach keeps the relations of microservices close. Such an application is hard to maintain, update, and scale.</p>
<p>It is much more convenient if your application interacts via messages that are handled by other microservices. This approach is called <strong>message-driven</strong>, when you use messages as a unit of interaction. Messages help you to reduce the coupling of microservices, because you can process a message for multiple services simultaneously or add an extra processing message for a particular message type.</p>
<p>To have totally uncoupled microservices, you should use a message queue or a message broker service. We will learn this approach in detail in <a href="98204850-538d-4a2b-9a77-23f85e716400.xhtml">Chapter 12</a>, <a href="https://cdp.packtpub.com/hands_on_microservices_with_rust_2018/wp-admin/post.php?post=405&amp;action=edit">Scalable Microservices Architecture</a>, <span>in which we talk about scalable architecture.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Asynchronous</h1>
                </header>
            
            <article>
                
<p>Since reactive microservices use message passing, you have to process message asynchronously. This doesn't mean you have to use asynchronous crates such as <kbd>tokio</kbd> or <kbd>futures</kbd>. But it means no one message can block the service; every message is processed in a short period of time and if the service has to perform a long task it should do it as a background task and inform the thread issued that task about the result by sending a message with that result. To achieve this behavior, you can use multiple threads without asynchronous code. But what about using asynchronous code for reactive microservices?</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Should a reactive microservice be asynchronous?</h1>
                </header>
            
            <article>
                
<p>Very often, confusion is caused by asynchronous applications being called <strong>reactive</strong>, because their event loops wait for external events and don't waste server resources while they're waiting. Reactive microservices don't waste resources to keep incoming connection to return a result, because when a client connects to a reactive microservices for a short time, put the task and disconnects. After a client waits for asynchronous response from a microservice. Reactive microservices don't need to be asynchronous, but they can be.</p>
<p>When you choose message passing for interaction, you have to take into account that microservices have to be asynchronous and can handle multiple messages simultaneously. Traditional synchronous code can't process as many messages as asynchronous code does, because synchronous code has to wait for I/O resources, but asynchronous code reacts to I/O events and utilizes as many resources as possible.</p>
<p>More simply, if your microservices have to process hundreds of thousands of messages, you should use asynchronous code. If your microservices do not have a heavy load, it's enough to use a modest synchronous algorithm.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Reactive microservices with futures and streams</h1>
                </header>
            
            <article>
                
<p>If you have decided to implement a reactive microservice using asynchronous code, you can consider using a future crate as a basis. This crate provides you with types to construct reactive chains to process all messages asynchronously. But remember, it can be hard to write all <kbd>Future</kbd> instances manually. There is an upcoming feature in the Rust compiler that provides <kbd>async</kbd>/<kbd>await</kbd> operators, which simplifies the <kbd>Future</kbd> trait implementation by writing traditional functions with the <kbd>Result</kbd> return type. This feature is unstable and we won't consider it in this book.</p>
<p>If you don't want to write low-level code, I recommend you use the <kbd>actix</kbd> crate. This is a really good framework that lets you write asynchronous code like synchronous code.</p>
<p>If you need the lowest level of control, you can use the <kbd>mio</kbd> crate that's used as a base by the <kbd>futures</kbd> crate. It provides you with full control of I/O events, and you can squeeze the maximum speed from the resources of your server.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Message brokers</h1>
                </header>
            
            <article>
                
<p>Message brokers let you send all messages to a central point that routes and delivers messages to the necessary microservices. In some cases, this can be a bottleneck, because the full load will fall on a single application—the message broker. But in most cases, it's a great approach that helps you to decouple microservices and update any microservices imperceptibly.</p>
<p>To use message brokers, it's sufficient to support the AMQP protocol. All popular message brokers are compatible with that protocol. The <kbd>lapin-futures</kbd> crate provides types and methods to use the AMQP protocol through the API of the <kbd>futures</kbd> crate. If you want to use the low-level control of the <kbd>mio</kbd> crate, there is the <kbd>lapin-async</kbd> crate.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Remote procedure calls</h1>
                </header>
            
            <article>
                
<p>If you want to connect microservices to each other directly, you can use RPCs to allow the functions of a service to be called remotely by another service. There are a lot of RPC frameworks with different formats and speed potential. Let's look at some popular protocols.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">JSON-RPC</h1>
                </header>
            
            <article>
                
<p>The JSON-RPC protocol uses messages serialized to JSON format. It uses a special format for requests and responses, described here: <a href="https://www.jsonrpc.org/specification">https://www.JSON-RPC.org/specification</a>. The protocol can use different transports, such as, HTTP, Unix sockets, or even stdio. Later in this chapter, you will find an example of the usage of this protocol.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">gRPC</h1>
                </header>
            
            <article>
                
<p>The gRPC protocol was created by Google and uses the Protocol Buffer serialization format for messages. Also, the protocol lies on benefits of the <kbd>HTTP/2</kbd> transport and allows you to achieve excellent performance. You can find more about the protocol here: <a href="https://grpc.io/docs/">https://grpc.io/docs/</a>. There is also an example of using this protocol later in this chapter.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Thrift</h1>
                </header>
            
            <article>
                
<p>Apache Thrift is a binary communication protocol developed by Facebook. Despite the fact the protocol is binary, there are a lot of supported languages, such as C++, Go, and Java. Supported transports are file, memory, and socket.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Other RPC frameworks</h1>
                </header>
            
            <article>
                
<p>There are other RPC protocols, such as Cap'n Proto, XML-RPC, and even vintage SOAP. Some have implementations for Rust, but I recommend considering choosing between JSON-RPC, gRPC, and Thrift, because they are the most commonly used for microservices.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">RPC and REST</h1>
                </header>
            
            <article>
                
<p>You may ask if it is possible to implement reactive microservices with a REST API or a traditional web API. Of course—yes! You can do it one of two ways:</p>
<ul>
<li>There are gateways that translate REST requests to JSON-RPC or other protocols. For example, gRPC has one ready to use: <a href="https://github.com/grpc-ecosystem/grpc-gateway">https://github.com/grpc-ecosystem/grpc-gateway</a>. You can even write your own gateway—it's not so hard for simple or specific cases.</li>
<li>You can use a Web API to send messages from one server to another. A microservice doesn't have to have a single API path, but you can add a special handler for messages in JSON or other formats. For transport, you can use not only HTTP, but also the WebSocket protocol.</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Reactive manifesto</h1>
                </header>
            
            <article>
                
<p>If you look at the reactive architecture as a standardized approach, you won't find a guide or rules for how to turn your microservice reactive, but there is The Reactive Manifesto, which you can find here: <a href="https://www.reactivemanifesto.org/">https://www.reactivemanifesto.org/</a>. It contains a list of principles you can use to be inspired by ideas for the improvement of your application.</p>
<p>Now we can create an example of a reactive microservice for the JSON-RPC procotol.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Understanding JSON-RPC</h1>
                </header>
            
            <article>
                
<p>There are some crates that provide functionality to support the JSON-RPC protocol. Mostly, crates support only the server or the client side, not both. Some crates don't support asynchronous computations either.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How JSON-RPC works</h1>
                </header>
            
            <article>
                
<p>The JSON-RPC protocol uses JSON messages in the following format for a request:</p>
<pre>{"jsonrpc": "2.0", "method": "substring", "params": [2, 6, \"string\"], "id": 1}</pre>
<p>The preceding JSON message calls the <kbd>substring</kbd> remote method of a server that can return a result like this:</p>
<pre>{"jsonrpc": "2.0", "result": "ring", "id": 1}</pre>
<p>It's worth nothing that a client determines the identifier of the request and has to track those values. Servers are ID-agnostic and they use a connection to track requests.</p>
<p>There are two versions of the protocol—1.0 and 2.0. They are similar, but in the second version there is a separation of the client and the server. Also, it is transport independent, because the first version uses connection events to determine behavior. There are improvements for errors and parameters as well. You should use version 2.0 for new projects.</p>
<p>To support JSON-RPC, your server has to respond to these kind of JSON requests. The protocol is really simple to implement, but we will use the <kbd>jsonrpc-http-server</kbd> crate, which uses HTTP transport and provides types to bootstrap a server.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Creating a microservice</h1>
                </header>
            
            <article>
                
<p>In this section, we will create an example of a microservice that supports the JSON-RPC protocol and has two methods. The microservice will support working as a part of a ring of microservices. We will send a message to one microservice, which will send a message to the next microservice in the ring, and that microservice will send the message further.</p>
<p>We will create a ring example, because if it is implemented incorrectly your microservice will be blocked, because they can't process requests in parallel like reactive services have to do.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Dependencies</h1>
                </header>
            
            <article>
                
<p>First, we need to import the necessary dependencies:</p>
<pre>failure = "0.1"<br/>JSON-RPC = { git = "https://github.com/apoelstra/rust-JSON-RPC" }<br/>jsonrpc-http-server = { git = "https://github.com/paritytech/JSON-RPC" }<br/>log = "0.4"<br/>env_logger = "0.6"<br/>serde = "1.0"<br/>serde_derive = "1.0"</pre>
<p>Most likely, you are familiar with most crates except <kbd>jsonrpc</kbd> and <kbd>json-rpc-server</kbd>. The first is a JSON-RPC client that's based on the <kbd>hyper</kbd> crate. The second also uses the <kbd>hyper</kbd> crate and provides server functionality of JSON-RPC.</p>
<p>Let's import the necessary types and talk a little about them:</p>
<pre>use failure::Error;<br/>use JSON-RPC::client::Client;<br/>use JSON-RPC::error::Error as ClientError;<br/>use JSON-RPC_http_server::ServerBuilder;<br/>use JSON-RPC_http_server::JSON-RPC_core::{IoHandler, Error as ServerError, Value};<br/>use log::{debug, error, trace};<br/>use serde::Deserialize;<br/>use std::env;<br/>use std::fmt;<br/>use std::net::SocketAddr;<br/>use std::sync::Mutex;<br/>use std::sync::mpsc::{channel, Sender};<br/>use std::thread;</pre>
<p>The JSON-RPC crate has the <kbd>Client</kbd> type that we will use to call the remote methods of other services. We also imported <kbd>Error</kbd> from that crate as <kbd>ClientError</kbd> to avoid a name conflict with <kbd>Error</kbd> from the failure crate.</p>
<p>For the server side, we will use <kbd>ServerBuilder</kbd> from the <kbd>jsonrpc-http-server</kbd> crate. Also, we need <kbd>Error</kbd> to be renamed to <kbd>ServerError</kbd> from that crate. To implement function handlers, we need to import <kbd>IoHandler</kbd>, which can be used to attach functions as RPC methods. Also, we need a <kbd>Value</kbd> (actually, this type is reimported from the <kbd>serde_json</kbd> crate), which is used as a result type for RPC methods.</p>
<p>To avoid mistakes in method names, because we will use them twice for the server implementation and then in a client, we declare names as string constants:</p>
<pre>const START_ROLL_CALL: &amp;str = "start_roll_call";<br/>const MARK_ITSELF: &amp;str = "mark_itself";</pre>
<p class="mce-root">The first method will start sending messages from one microservice to the next. The second method is used to stop this roll-calling process.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Client</h1>
                </header>
            
            <article>
                
<p>To interact with other microservice instances and to call their remote methods, we will create a separate struct, because it's more convenient than using the JSON-RPC <kbd>Cilent</kbd> directly. But in any case, we use this type internally in our struct:</p>
<pre>struct Remote {<br/>    client: Client,<br/>}</pre>
<p>We will use the <kbd>Remote</kbd> struct to make calls to remote services. To create the struct, we will use the following constructor:</p>
<pre>impl Remote {<br/>    fn new(addr: SocketAddr) -&gt; Self {<br/>        let url = format!("http://{}", addr);<br/>        let client = Client::new(url, None, None);<br/>        Self {<br/>            client<br/>        }<br/>    }<br/>}</pre>
<p>The <kbd>Client</kbd> struct expects the <kbd>String</kbd> URL as a parameter, but we will use <kbd>SocketAddr</kbd> to create a URL.</p>
<p>Also, we need a generic function that will use the <kbd>Client</kbd> instance to call remote methods. Add the <kbd>call_method</kbd> method to the implementation of the <kbd>Remote</kbd> struct:</p>
<pre>fn call_method&lt;T&gt;(&amp;self, meth: &amp;str, args: &amp;[Value]) -&gt; Result&lt;T, ClientError&gt;<br/>where<br/>    T: for &lt;'de&gt; Deserialize&lt;'de&gt;,<br/>{<br/>    let request = self.client.build_request(meth, args);<br/>    self.client.send_request(&amp;request).and_then(|res| res.into_result::&lt;T&gt;())<br/>}</pre>
<p>The calling of the JSON-RPC method using the JSON-RPC crate is simple. Use the <kbd>build_request</kbd> method of the <kbd>Client</kbd> instance to create a <kbd>Request</kbd> and send it using the <kbd>send_request</kbd> method of the same <kbd>Client</kbd>. There is a method called <kbd>do_rpc</kbd> that does this in a single call. We will use a more verbose approach to show that you can predefine requests and use them to speed up the preparation for calling. Also, it's more pleasant to use business-oriented struct methods instead of a raw <kbd>Client</kbd>. We isolate an implementation using a wrapper that hides the details of RPC calls. What if you decide to change to another protocol, such as gRPC?</p>
<p>Add special methods to the <kbd>Remote</kbd> struct implementation to make calls using the <kbd>call_method</kbd> method. First, we need the <kbd>start_roll_call</kbd> function:</p>
<pre>fn start_roll_call(&amp;self) -&gt; Result&lt;bool, ClientError&gt; {<br/>    self.call_method(START_ROLL_CALL, &amp;[])<br/>}</pre>
<p>It won't pass any parameters with a call, but it expects the <kbd>bool</kbd> type of the result. We used a constant for the remote method's name.</p>
<p>Add the <kbd>mark_itself</kbd> method to the <kbd>Remote</kbd> struct:</p>
<pre>fn mark_itself(&amp;self) -&gt; Result&lt;bool, ClientError&gt; {<br/>    self.call_method("mark_itself", &amp;[])<br/>}</pre>
<p>It doesn't send any parameters either and returns the <kbd>bool</kbd> value.</p>
<p>Now we can add a worker to separate outgoing method calls from incoming calls.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Worker</h1>
                </header>
            
            <article>
                
<p>Since we have two methods, we will add a struct to perform remote calls of these methods from a worker thread. Add the <kbd>Action</kbd> enumeration to the code:</p>
<pre>enum Action {<br/>    StartRollCall,<br/>    MarkItself,<br/>}</pre>
<p>It has two variants: <kbd>StartRollCall</kbd> to perform the remote <kbd>start_roll_call</kbd> method call, and the <kbd>MarkItself</kbd> variant to call the remote <kbd>mark_itself</kbd> method.</p>
<p>Now we can add a function to spawn a worker in a separate thread. If we will perform outgoing calls immediately in incoming method handlers, we can block the execution, because we have a ring of microservices and blocking one microservice will block the whole ring's interaction.</p>
<div class="packt_infobox">No blocking is an important property of a reactive microservice. The microservices have to process all calls in parallel or asynchronously, but never block execution for a long time. They should work like actors in the actors model we have discussed.</div>
<p>Look at the <kbd>spawn_worker</kbd> function:</p>
<pre>fn spawn_worker() -&gt; Result&lt;Sender&lt;Action&gt;, Error&gt; {<br/>    let (tx, rx) = channel();<br/>    let next: SocketAddr = env::var("NEXT")?.parse()?;<br/>    thread::spawn(move || {<br/>        let remote = Remote::new(next);<br/>        let mut in_roll_call = false;<br/>        for action in rx.iter() {<br/>            match action {<br/>                Action::StartRollCall =&gt; {<br/>                    if !in_roll_call {<br/>                        if remote.start_roll_call().is_ok() {<br/>                            debug!("ON");<br/>                            in_roll_call = true;<br/>                        }<br/>                    } else {<br/>                        if remote.mark_itself().is_ok() {<br/>                            debug!("OFF");<br/>                            in_roll_call = false;<br/>                        }<br/>                    }<br/>                }<br/>                Action::MarkItself =&gt; {<br/>                    if in_roll_call {<br/>                        if remote.mark_itself().is_ok() {<br/>                            debug!("OFF");<br/>                            in_roll_call = false;<br/>                        }<br/>                    } else {<br/>                        debug!("SKIP");<br/>                    }<br/>                }<br/>            }<br/>        }<br/>    });<br/>    Ok(tx)<br/>}</pre>
<p>This function creates a channel and spawns a new thread with a routine that processes all received messages from a channel. We create the <kbd>Remote</kbd> instance with the address extracted from the <kbd>NEXT</kbd> environment variable.</p>
<p>There is a flag that shows that the <kbd>start_roll_call</kbd> method has been called. We set it to <kbd>true</kbd> when the <kbd>StartRollCall</kbd> message is received and the <kbd>start_roll_call</kbd> method of the remote server is called. If the flag is already set to <kbd>true</kbd> and the routine received the <kbd>StartRollCall</kbd> message, the thread will call the <kbd>mark_itself</kbd> remote method. In other words, we will call the <kbd>start_roll_call</kbd> methods of all running service instances. When all services set the flag to <kbd>true</kbd>, we will call the <kbd>mark_itself</kbd> methods of all services.</p>
<p>Let's start a server and run a ring of services.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Server</h1>
                </header>
            
            <article>
                
<p>The <kbd>main</kbd> function activates a logger and spawns a worker. Then, we extract the <kbd>ADDRESS</kbd> environment variable to use this address value to bind a socket of a server. Loot at the following code:</p>
<pre>fn main() -&gt; Result&lt;(), Error&gt; {<br/>    env_logger::init();<br/>    let tx = spawn_worker()?;<br/>    let addr: SocketAddr = env::var("ADDRESS")?.parse()?;<br/>    let mut io = IoHandler::default();<br/>    let sender = Mutex::new(tx.clone());<br/>    io.add_method(START_ROLL_CALL, move |_| {<br/>        trace!("START_ROLL_CALL");<br/>        let tx = sender<br/>            .lock()<br/>            .map_err(to_internal)?;<br/>        tx.send(Action::StartRollCall)<br/>            .map_err(to_internal)<br/>            .map(|_| Value::Bool(true))<br/>    });<br/>    let sender = Mutex::new(tx.clone());<br/>    io.add_method(MARK_ITSELF, move |_| {<br/>        trace!("MARK_ITSELF");<br/>        let tx = sender<br/>            .lock()<br/>            .map_err(to_internal)?;<br/>        tx.send(Action::MarkItself)<br/>            .map_err(to_internal)<br/>            .map(|_| Value::Bool(true))<br/>    });<br/>    let server = ServerBuilder::new(io).start_http(&amp;addr)?;<br/>    Ok(server.wait())<br/>}</pre>
<p>To implement JSON-RPC methods, we use the <kbd>IoHandler</kbd> struct. It has the <kbd>add_method</kbd> method, which expects the name of the method and needs a closure with an implementation of this method.</p>
<p>We added two methods, <kbd>start_roll_call</kbd> and <kbd>mark_itself</kbd>, using constants as names for these methods. The implementation of these methods is simple: we only prepare the corresponding <kbd>Action</kbd> messages and send them to the worker's thread.</p>
<p>The JSON-RPC method implementation has to return the <kbd>Result&lt;Value, ServerError&gt;</kbd> value. To convert any other errors to <kbd>ServerError</kbd> we use the following function:</p>
<pre>fn to_internal&lt;E: fmt::Display&gt;(err: E) -&gt; ServerError {<br/>    error!("Error: {}", err);<br/>    ServerError::internal_error()<br/>}</pre>
<p>The function only prints the current error message and creates an error with the <kbd>InternalError</kbd> code using the <kbd>internal_error</kbd> method of the <kbd>ServerError</kbd> type.</p>
<p>At the end of main function, we create a new <kbd>ServerBuilder</kbd> instance with the created <kbd>IoHandler</kbd> and start the HTTP server to listen for JSON-RPC requests with the <kbd>start_http</kbd> server.</p>
<p>Now we can start a ring of services to test it.</p>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Compiling and running</h1>
                </header>
            
            <article>
                
<p>Compile this example with the <kbd>cargo build</kbd> subcommand, and let's start three instances of the service using the following commands (run every command in a separate terminal window to see the logs):</p>
<pre><strong>RUST_LOG=JSON-RPC_ring=trace ADDRESS=127.0.0.1:4444 NEXT=127.0.0.1:5555 target/debug/JSON-RPC-ring</strong><br/><strong>RUST_LOG=JSON-RPC_ring=trace ADDRESS=127.0.0.1:5555 NEXT=127.0.0.1:6666 target/debug/JSON-RPC-ring</strong><br/><strong>RUST_LOG=JSON-RPC_ring=trace ADDRESS=127.0.0.1:6666 NEXT=127.0.0.1:4444 target/debug/JSON-RPC-ring</strong></pre>
<p>When the three services are started, prepare and send a JSON-RPC call request with <kbd>curl</kbd> from another terminal window:</p>
<pre><strong>curl -H "Content-Type: application/json" --data-binary '{"JSON-RPC":"2.0","id":"curl","method":"start_roll_call","params":[]}' http://127.0.0.1:4444</strong></pre>
<p>With this command, we start the interaction of all services, and they will call each other in a ring. You will see the logs of every service. The first prints something like this:</p>
<pre>[2019-01-14T10:45:29Z TRACE JSON-RPC_ring] START_ROLL_CALL<br/>[2019-01-14T10:45:29Z DEBUG JSON-RPC_ring] ON<br/>[2019-01-14T10:45:29Z TRACE JSON-RPC_ring] START_ROLL_CALL<br/>[2019-01-14T10:45:29Z DEBUG JSON-RPC_ring] OFF<br/>[2019-01-14T10:45:29Z TRACE JSON-RPC_ring] MARK_ITSELF<br/>[2019-01-14T10:45:29Z DEBUG JSON-RPC_ring] SKIP</pre>
<p>The second will print something like this:</p>
<pre>[2019-01-14T10:45:29Z TRACE JSON-RPC_ring] START_ROLL_CALL<br/>[2019-01-14T10:45:29Z DEBUG JSON-RPC_ring] ON<br/>[2019-01-14T10:45:29Z TRACE JSON-RPC_ring] MARK_ITSELF<br/>[2019-01-14T10:45:29Z DEBUG JSON-RPC_ring] OFF</pre>
<p>And the third will output the following logs:</p>
<pre>[2019-01-14T10:45:29Z TRACE JSON-RPC_ring] START_ROLL_CALL<br/>[2019-01-14T10:45:29Z DEBUG JSON-RPC_ring] ON<br/>[2019-01-14T10:45:29Z TRACE JSON-RPC_ring] MARK_ITSELF<br/>[2019-01-14T10:45:29Z DEBUG JSON-RPC_ring] OFF</pre>
<p>All services works as independent participants of the process, react to incoming messages, and send messages to other services when there is something to send.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Learning about gRPC</h1>
                </header>
            
            <article>
                
<p>In this section, we will rewrite the JSON-RPC ring example to gRPC. This protocol differs from JSON-RPC because it requires a protocol declaration—a predefined interaction schema. This restriction is good for large projects, because you can't make a mistake in a message's layout, but with Rust, JSON-RPC is also reliable because you have to declare all structs exactly and you will get an error if you take an incorrect JSON message. With gRPC, you don't have to care about it at all.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How gRPC works</h1>
                </header>
            
            <article>
                
<p>The benefit of gRPC in comparison with JSON-RPC is speed. gRPC can work faster, because it uses a fast serialization format—Protocol Buffers. Both gRPC and Protocol Buffers were originally developed by Google and are proven in high-performance cases.</p>
<p>gRPC uses <kbd>HTTP/2</kbd> for transport. It's a really fast and good transport protocol. First, it's binary: all requests and responses are squeezed into a compact portion of bytes and compressed. It's multiplexed: you can send a lot of requests simultaneously, but <kbd>HTTP/1</kbd> demands respect for the order of requests.</p>
<p>gRPC needs a scheme and uses Protocol Buffers as the <strong>Interface Definition Language</strong> (<strong>IDL</strong>). Before you start writing an implementation of a service, you have to write the <kbd>proto</kbd> file that contains a declaration of all types and services. After that, you need to compile the declaration to sources (in the Rust programming language in our case) and use them to write the implementation.</p>
<p>The <kbd>protobuf</kbd> crate and the common gRPC crates use that crate as a basis. Actually, there are not many crates; just two: the <kbd><span class="pl-s">grpcio</span></kbd> crate, which is a wrapper over the original gRPC core library, and the <kbd>grpc</kbd> crate, which is the pure Rust implementation of the protocol.</p>
<p>Now we can rewrite the previous example from JSON-RPC protocol to gRPC. At first, we have to add all the necessary dependencies and write a declaration of our service.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Creating a microservice</h1>
                </header>
            
            <article>
                
<p>The gRPC example is very complex, because we have to declare an interaction protocol. We also have to add the <kbd>build.rs</kbd> file to generate Rust sources from a protocol description.</p>
<p>Since it's hard to make a gRPC call from curl, we will also add a client that helps us to test services. You can also use other tools that are available for debugging gRPC applications.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Dependencies</h1>
                </header>
            
            <article>
                
<p>Create a new <kbd>binary</kbd> crate and open <kbd>Cargo.toml</kbd> in an editor. We will explore every section of this file, because building a gRPC example is more complex than services that use flexible interaction protocols such as JSON-RPC. We'll use Edition 2018, as we do for most examples in this book:</p>
<pre>[package]<br/>name = "grpc-ring"<br/>version = "0.1.0"<br/>authors = ["your email"]<br/>edition = "2018"</pre>
<p>In dependencies, we need a basic set of crates—<kbd>failure</kbd>, <kbd>log</kbd>, and <kbd>env_logger</kbd>. Also, we add the <kbd>protobuf</kbd> crate. We won't use it directly, but it's used by generated Rust sources that we will get from a protocol description later in this section. The most important crate from the current example is grpc. We will use a version from GitHub, because the crate is in active development:</p>
<pre>[dependencies]<br/>env_logger = "0.6"<br/>failure = "0.1"<br/>grpc = { git = "https://github.com/stepancheg/grpc-rust" }<br/>log = "0.4"<br/>protobuf = "2.2"</pre>
<p>Actually, the GitHub repository of the <kbd>grpc</kbd> crate is a workspace and also contains the <kbd>protoc-rust-grpc</kbd> crate, which we will use to generate a protocol declaration in Rust using the <kbd>build.rs</kbd> file. Add this dependency to the <kbd>[build-dependencies]</kbd> section of <kbd>Cargo.toml</kbd>:</p>
<pre>[build-dependencies]<br/>protoc-rust-grpc = { git = "https://github.com/stepancheg/grpc-rust" }</pre>
<p>The <kbd>example</kbd> crate we create will produce two binary files—server and client. As I said, we need a client, because it's simpler than preparing calls manually, and use curl to call gRPC methods.</p>
<p>The first binary is a server built from the <kbd>src/server.rs</kbd> file:</p>
<pre>[[bin]]<br/>name = "grpc-ring"<br/>path = "src/server.rs"<br/>test = false</pre>
<p>The second binary uses the <kbd>src/client.rs</kbd> file to build a client:</p>
<pre>[[bin]]<br/>name = "grpc-ring-client"<br/>path = "src/client.rs"<br/>test = false</pre>
<p>We also have <kbd>src/lib.rs</kbd> for common parts, but we have to describe a protocol and create the <kbd>build.rs</kbd> file.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Protocol</h1>
                </header>
            
            <article>
                
<p>gRPC uses a special language for protocol declarations.There are two versions of the language—<kbd>proto2</kbd> and <kbd>proto3</kbd>. We will use the second as it's more modern. Create a <kbd>ring.proto</kbd> file and add the following declaration:</p>
<pre>syntax = "proto3";<br/><br/>option java_multiple_files = true;<br/>option java_package = "rust.microservices.ring";<br/>option java_outer_classname = "RingProto";<br/>option objc_class_prefix = "RING";<br/><br/>package ringproto;<br/><br/>message Empty { }<br/><br/>service Ring {<br/>  rpc StartRollCall (Empty) returns (Empty);<br/>  rpc MarkItself (Empty) returns (Empty);<br/>}</pre>
<p>As you can see, we specified the syntax as <kbd>proto3</kbd>. Options give you the ability to set the properties for the generation of source files for different languages if you will interact with a service from other applications or other microservices. We don't need to set these options for our example, but you might have this part in a file if you take it from another developer.</p>
<p>The protocol declaration contains a package name set with the <kbd>package</kbd> specifier and a package name that we set to <kbd>ringproto</kbd>.</p>
<p>Also, we added the <kbd>Empty</kbd> message with no fields. We will use this type as the input and output parameter for all methods, but it's better to use different types for real microservices. Firstly, you can't have methods without input and output parameters. The second reason is future service improvements. If you want to add extra fields to the protocol later, you can do it. Moreover, the protocol can easily cope with different versions of the protocol; often you can use both new and old microservices, because Protocol Buffers work fine with extra fields, and you can extend the protocol later when you need it.</p>
<p>The service declaration is contained in the <kbd>service</kbd> section. You can have multiple services' declarations in a protocol declaration file and use only the necessary declared services in an implementation. But we need only one service declaration for our ring example. Add the <kbd>Ring</kbd> service and include two RPC methods with the <kbd>rpc</kbd> specifier. We added the <kbd>StartRollCall</kbd> method and <kbd>MakeItself</kbd>. The same as we did in the previous example. Both take the <kbd>Empty</kbd> value as an input argument and return <kbd>Empty</kbd> as well.</p>
<p>The name of a service is important, because it will be used as a prefix for multiple types in generated Rust sources. You can create sources using the <kbd>protoc</kbd> tool, but it's more convenient to create a build script that will generate sources with protocol types during compilation.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Generating interfaces</h1>
                </header>
            
            <article>
                
<p>Rust build scripts let you implement a function that will do some additional preparation for project compilation. In our case, we have the <kbd>ring.proto</kbd> file with a protocol definition and we want to convert it to Rust sources using the <kbd>protoc-rust-grpc</kbd> crate.</p>
<p>Create the <kbd>build.rs</kbd> file in the project and add the following content:</p>
<pre>extern crate protoc_rust_grpc;<br/><br/>fn main() {<br/>    protoc_rust_grpc::run(protoc_rust_grpc::Args {<br/>        out_dir: "src",<br/>        includes: &amp;[],<br/>        input: &amp;["ring.proto"],<br/>        rust_protobuf: true,<br/>        ..Default::default()<br/>    }).expect("protoc-rust-grpc");<br/>}</pre>
<p>Build scripts use the <kbd>main</kbd> function as an entry point, in which you can implement any activities you want. We used the run function of the <kbd>protoc-rust-grpc</kbd> crate with <kbd>Args</kbd>—we set the output directory in the <kbd>out_dir</kbd> field, set the <kbd>ring.proto</kbd> file as input declaration with the <kbd>input</kbd> field, activate the <kbd>rust_protobuf</kbd> Boolean flag to generate sources for the <kbd>rust<strong>-</strong>protobuf</kbd> crate (you don't need it if you are already using the <kbd>protobuf</kbd> crate and generating types with it), then set the <kbd>includes</kbd> field to an empty array.</p>
<p>Then, when you run <kbd>cargo build</kbd>, it will produce two modules in the <kbd>src</kbd> folder: <kbd>ring.rs</kbd> and <kbd>ring_grpc.rs</kbd>. I don't put its sources here, because generated files are large, but we will use it to create a wrapper for a gRPC client, as we did in the previous example.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Shared client</h1>
                </header>
            
            <article>
                
<p>Open the <kbd>lib.rs</kbd> source file and add two generated modules:</p>
<pre>mod ring;<br/>mod ring_grpc;</pre>
<p>Import some types we need to create a wrapper for a gRPC client:</p>
<pre>use crate::ring::Empty;<br/>use crate::ring_grpc::{Ring, RingClient};<br/>use grpc::{ClientConf, ClientStubExt, Error as GrpcError, RequestOptions};<br/>use std::net::SocketAddr;</pre>
<p>As you can see, the generated modules contain types we declared in the <kbd>ring.proto</kbd> file. The <kbd>ring</kbd> module contains the <kbd>Empty</kbd> struct, and the <kbd>ring_grpc</kbd> module contains the <kbd>Ring</kbd> trait, which represents an interface of a remote service. Also, <kbd>protoc_rust_grpc</kbd> in the build script generated the <kbd>RingClient</kbd> type. This type is a client that can be used to call remote methods. We wrap it with our own struct, because <kbd>RingClient</kbd> generates <kbd>Future</kbd> instances and we will use the <kbd>Remote</kbd> wrapper to perform them and get the result.</p>
<p>We also use types from the <kbd>grpc</kbd> crate. The <kbd>Error</kbd> type is imported as <kbd>GrpcError</kbd>; <br/>
<kbd>RequestOptions</kbd>, which is necessary to prepare method call requests; <kbd>ClientConf</kbd>, which is used to add extra configuration parameters for the <kbd>HTTP/2</kbd> connection (we will use the default values); and <kbd>ClientStubExt</kbd>, which provides connection methods for clients.</p>
<p>Add the <kbd>Remote</kbd> struct holding the <kbd>RingClient</kbd> instance inside:</p>
<pre>pub struct Remote {<br/>    client: RingClient,<br/>}</pre>
<p>We use this struct for both client and server. Add a new method to construct new instances of <kbd>Remote</kbd> from the provided <kbd>SocketAddr</kbd>:</p>
<pre>impl Remote {<br/>    pub fn new(addr: SocketAddr) -&gt; Result&lt;Self, GrpcError&gt; {<br/>        let host = addr.ip().to_string();<br/>        let port = addr.port();<br/>        let conf = ClientConf::default();<br/>        let client = RingClient::new_plain(&amp;host, port, conf)?;<br/>        Ok(Self {<br/>            client<br/>        })<br/>    }<br/>}</pre>
<p>Since generated clients expect separate host and port values, we extract them from the <kbd>SocketAddr</kbd> value. Also, we create the default <kbd>ClientConf</kbd> configuration and use all these values to create the <kbd>RingClient</kbd> instance to put it to the new <kbd>Remote</kbd> instance.</p>
<p>We create the <kbd>Remote</kbd> struct to have simple methods to call remote methods. Add the <kbd>start_roll_call</kbd> method to the <kbd>Remote</kbd> implementation to call the <kbd>StartRollCall</kbd> gRPC method:</p>
<pre>pub fn start_roll_call(&amp;self) -&gt; Result&lt;Empty, GrpcError&gt; {<br/>    self.client.start_roll_call(RequestOptions::new(), Empty::new())<br/>        .wait()<br/>        .map(|(_, value, _)| value)<br/>}</pre>
<p><kbd>RingClient</kbd> already has this method, but it expects parameters that we want to hide, and returns a <kbd>Future</kbd> instance that we want to perform immediately using the wait method call. The <kbd>Future</kbd> returns a tuple with three items, but we need only one value, because other values contain metadata that we don't need.</p>
<p>Implement the <kbd>mark_itself</kbd> method in a similar way to call the <kbd>MarkItself</kbd> gRPC method:</p>
<pre>pub fn mark_itself(&amp;self) -&gt; Result&lt;Empty, GrpcError&gt; {<br/>    self.client.mark_itself(RequestOptions::new(), Empty::new())<br/>        .wait()<br/>        .map(|(_, value, _)| value)<br/>}</pre>
<p>Now we can implement a client and a server, because both need the <kbd>Remote</kbd> struct to perform RPC calls.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Client</h1>
                </header>
            
            <article>
                
<p>Add the <kbd>src/client.rs</kbd> file and import a few types:</p>
<pre>use failure::Error;<br/>use grpc_ring::Remote;<br/>use std::env;</pre>
<p>We need a generic <kbd>Error</kbd> from the <kbd>failure</kbd> crate, because it's a universal type for most error handling cases, and import the <kbd>Remote</kbd> struct we created before.</p>
<p>The client is an extremely simple tool. It calls the <kbd>StartRollCall</kbd> remote gRPC method of a service with the address provided in the <kbd>NEXT</kbd> environment variable:</p>
<pre>fn main() -&gt; Result&lt;(), Error&gt; {<br/>    let next = env::var("NEXT")?.parse()?;<br/>    let remote = Remote::new(next)?;<br/>    remote.start_roll_call()?;<br/>    Ok(())<br/>}</pre>
<p>Create the <kbd>Remote</kbd> instance with the parsed <kbd>SocketAddr</kbd> value and perform a call. This is it. The server is very complex. Let's implement it.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Server implementation</h1>
                </header>
            
            <article>
                
<p>Add the <kbd>src/server.rs</kbd> source file and add generated modules to it:</p>
<pre>mod ring;<br/>mod ring_grpc;</pre>
<p>We need these modules because we will implement the <kbd>Ring</kbd> trait for our RPC handler. Look at the types we will use:</p>
<pre>use crate::ring::Empty;<br/>use crate::ring_grpc::{Ring, RingServer};<br/>use failure::Error;<br/>use grpc::{Error as GrpcError, ServerBuilder, SingleResponse, RequestOptions};<br/>use grpc_ring::Remote;<br/>use log::{debug, trace};<br/>use std::env;<br/>use std::net::SocketAddr;<br/>use std::sync::Mutex;<br/>use std::sync::mpsc::{channel, Receiver, Sender};</pre>
<p>The types you are not familiar with yet are <kbd>ServerBuilder</kbd>, which is used to create a server instance and fill it with service implementations, and <kbd>SingleResponse</kbd> is the result of handler calls. The other types you already know.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Service implementation</h1>
                </header>
            
            <article>
                
<p>We need our own type that will implement the <kbd>Ring</kbd> trait to implement RPC interface of a service. But we also have to keep a <kbd>Sender</kbd> for a worker to send actions to it. Add the <kbd>RingImpl</kbd> struct with a <kbd>Sender</kbd> of <kbd>Action</kbd> wrapped with <kbd>Mutex</kbd>, because the <kbd>Ring</kbd> trait requires the <kbd>Sync</kbd> trait implementation as well:</p>
<pre>struct RingImpl {<br/>    sender: Mutex&lt;Sender&lt;Action&gt;&gt;,<br/>}</pre>
<p>We will construct an instance from the <kbd>Sender</kbd> instance:</p>
<pre>impl RingImpl {<br/>    fn new(sender: Sender&lt;Action&gt;) -&gt; Self {<br/>        Self {<br/>            sender: Mutex::new(sender),<br/>        }<br/>    }<br/>}</pre>
<p>For every incoming method call, we need to send <kbd>Action</kbd> to a worker and we can add a method to the <kbd>RingImpl</kbd> implementation to reuse it in all handlers:</p>
<pre>fn send_action(&amp;self, action: Action) -&gt; SingleResponse&lt;Empty&gt; {<br/>    let tx = try_or_response!(self.sender.lock());<br/>    try_or_response!(tx.send(action));<br/>    let result = Empty::new();<br/>    SingleResponse::completed(result)<br/>}</pre>
<p>The <kbd>send_action</kbd> function takes the <kbd>Action</kbd> value and locks a <kbd>Mutex</kbd> to use a <kbd>Sender</kbd>. At the end, it creates an <kbd>Empty</kbd> value and returns it as a <kbd>SingleResponse</kbd> instance. If you have noticed, we used the <kbd>try_or_response!</kbd> macro that we defined, because <kbd>SingleResponse</kbd> is a <kbd>Future</kbd> instance and we have to return this type in any success or failure cases.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>This macro works like the <kbd>try!</kbd> macro of the standard library. It uses match to extract a value or return a result if there is an error value:</p>
<pre>macro_rules! try_or_response {<br/>    ($x:expr) =&gt; {{<br/>        match $x {<br/>            Ok(value) =&gt; {<br/>                value<br/>            }<br/>            Err(err) =&gt; {<br/>                let error = GrpcError::Panic(err.to_string());<br/>                return SingleResponse::err(error);<br/>            }<br/>        }<br/>    }};<br/>}</pre>
<p>The preceding macro creates the <kbd>SingleResponse</kbd> instance with the <kbd>Panic</kbd> variant of <kbd>GrpcError</kbd>, but uses a description of an error from the existing error value.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Handlers</h1>
                </header>
            
            <article>
                
<p>Now we can implement gRPC methods of the <kbd>Ring</kbd> service we declared in the <kbd>ring.proto</kbd> file before. We have the <kbd>Ring</kbd> trait with the same names of the methods. Every method expects the <kbd>Empty</kbd> value and has to return this type, because we defined this in the declaration. Also, every method has to return the <kbd>SingleResponse</kbd> type as a result. We already defined the <kbd>send_action</kbd> method that sends the <kbd>Action</kbd> value to a worker and returns the <kbd>SingleResponse</kbd> response with the <kbd>Empty</kbd> value. Let's use the <kbd>send_action</kbd> method for both methods we have to implement:</p>
<pre>impl Ring for RingImpl {<br/>    fn start_roll_call(&amp;self, _: RequestOptions, _: Empty) -&gt; SingleResponse&lt;Empty&gt; {<br/>        trace!("START_ROLL_CALL");<br/>        self.send_action(Action::StartRollCall)<br/>    }<br/><br/>    fn mark_itself(&amp;self, _: RequestOptions, _: Empty) -&gt; SingleResponse&lt;Empty&gt; {<br/>        trace!("MARK_ITSELF");<br/>        self.send_action(Action::MarkItself)<br/>    }<br/>}</pre>
<p>We have a pretty simple implementation of gRPC methods handlers, but you can also add more sensible implementations and produce <kbd>SingleResponse</kbd> from a Future asynchronously.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The main function</h1>
                </header>
            
            <article>
                
<p>Everything is ready for the implementation of the <kbd>main</kbd> function:</p>
<pre>fn main() -&gt; Result&lt;(), Error&gt; {<br/>    env_logger::init();<br/>    let (tx, rx) = channel();<br/>    let addr: SocketAddr = env::var("ADDRESS")?.parse()?;<br/>    let mut server = ServerBuilder::new_plain();<br/>    server.http.set_addr(addr)?;<br/>    let ring = RingImpl::new(tx);<br/>    server.add_service(RingServer::new_service_def(ring));<br/>    server.http.set_cpu_pool_threads(4);<br/>    let _server = server.build()?;<br/><br/>    worker_loop(rx)<br/>}</pre>
<p>We initialized a logger and created a channel that we will use to send actions from <kbd>RingImpl</kbd> to a worker. We extracted <kbd>SocketAddr</kbd> from the <kbd>ADDRESS</kbd> environment variable and used this value to bind a server to the provided address.</p>
<p>We created a <kbd>ServerBuilder</kbd> instance with the <kbd>new_plain</kbd> method. It creates a server without TLS, since gRPC supports secure connections and we have to provide a type parameter for <kbd>ServerBuilder</kbd> that implements the <kbd>TlcAcceptor</kbd> trait. But with <kbd>new_plain</kbd> we use the <kbd>TlasAcceptor</kbd> stub from the <kbd>tls_api_stub</kbd> crate. The <kbd>ServerBuilder</kbd> struct contains the <kbd>http</kbd> field of the <kbd>httpbis::ServerBuilder</kbd> type. We can use this file to set the address to which to bind the server's socket.</p>
<p>After, we create the <kbd>RingImpl</kbd> instance and use the <kbd>add_service</kbd> method of <kbd>ServiceBuilder</kbd> to attach a service implementation, but we have to provide the generic <kbd>grpc::rt::ServerServiceDefinition</kbd> definition of the service and we use <kbd>new_service_def</kbd> of the <kbd>RingServer</kbd> type to create it for the <kbd>RingImpl</kbd> instance.</p>
<p>At the end, we set the quantity of threads in the pool that will be used to handle incoming requests and call the <kbd>build</kbd> method of <kbd>ServiceBuilder</kbd> to start a server. But wait—if you leave the <kbd>build</kbd> call method, the main thread will be terminated and you will have to add a loop or other routine to keep the main thread alive.</p>
<p>Luckily, we need a worker and we can use the main thread to run it. If you only need to run the gRPC server, you can use a <kbd>loop</kbd> with the <kbd>thread::park</kbd> method call, which will block the thread till it is unblocked by the <kbd>unpark</kbd> method call. This approach is used internally by asynchronous runtimes.</p>
<p>We will use the <kbd>worker_loop</kbd> function call, but we have not implemented this function yet.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Worker</h1>
                </header>
            
            <article>
                
<p>We already implemented the worker in the JSON-RPC example. In the gRPC version, we use have same code, but expect a <kbd>Receiver</kbd> value and don't spawn a new thread:</p>
<pre>fn worker_loop(receiver: Receiver&lt;Action&gt;) -&gt; Result&lt;(), Error&gt; {<br/>    let next = env::var("NEXT")?.parse()?;<br/>    let remote = Remote::new(next)?;<br/>    let mut in_roll_call = false;<br/>    for action in receiver.iter() {<br/>        match action { /* Action variants here */ }<br/>    }<br/>    Ok(())<br/>}</pre>
<p>Let's compile and run this example.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Compiling and running</h1>
                </header>
            
            <article>
                
<p>Build both the server and the client with the <kbd>cargo build</kbd> subcommand.</p>
<div class="packt_tip">If you want to specify binary, use the --bin parameter with the name of a binary.</div>
<div>Also, you can use <kbd>cargo watch</kbd> tool for building.</div>
<div class="packt_tip">If you use the <kbd>cargo watch</kbd> tool, then the <kbd>build.rs</kbd> script will generate files with gRPC types and <kbd>watch</kbd> will continuously restart the build. To prevent this, you can set the <kbd>--ignore</kbd> argument to the command with a pattern of files' names to ignore. For our example, we have to run the <kbd>cargo watch --ignore 'src/ring*'</kbd> command.</div>
<p>When both binaries are built, run three instances in separate terminals:</p>
<pre><strong>RUST_LOG=grpc_ring=trace ADDRESS=127.0.0.1:4444 NEXT=127.0.0.1:5555 target/debug/grpc-ring</strong><br/><strong>RUST_LOG=grpc_ring=trace ADDRESS=127.0.0.1:5555 NEXT=127.0.0.1:6666 target/debug/grpc-ring</strong><br/><strong>RUST_LOG=grpc_ring=trace ADDRESS=127.0.0.1:6666 NEXT=127.0.0.1:4444 target/debug/grpc-ring</strong></pre>
<p>When all of the services start, use a client to send a request to the first service:</p>
<pre><strong>NEXT=127.0.0.1:4444 target/debug/grpc-ring-client</strong></pre>
<p>This command will call a remote method, <kbd>start_roll_call</kbd>, and you will see similar server logs to what you saw in the preceding JSON-RPC example.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>This chapter covered good practices for creating reactive microservices architecture. We started our learning from basic concepts: what a reactive approach is, how to implement it, and how remote procedure calls helps to implement message-driven architecture. Also, we discussed existing RPC frameworks and crates that you can use simply with Rust.</p>
<p>To demonstrate how reactive applications work, we created two examples of microservices that use RPC methods to interact with each other. We created an application that uses a ring of running microservices that send requests to each other in a loop till every instance is informed about an event.</p>
<p>We also created an example that uses the JSON-RPC protocol for instance interaction and used the <kbd>jsonrpc-http-server</kbd> crate for the server side and the JSON-RPC crate for the client side.</p>
<p>After that, we created an example that uses the gRPC protocol for microservice interaction, and we used the <kbd>grpc</kbd> crate, which covers both the client and server sides.</p>
<p><span>In the next chater we will start to integrate microservices with database and explore available crates to interact with the follwoing databases: PostgreSQL, MySQL, Redis, MongoDB, DynamoDB.</span></p>


            </article>

            
        </section>
    </body></html>