- en: Getting Practical with Rust
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Even after nine chapters of Rust, we are still missing the parts that make applications
    pleasant to use. Many crates within Rust's ecosystem provide important functions
    across different domains and, depending on the application type, you might need
    several additional crates. In this chapter, we will look at various parts within
    Rust's standard library and public crate repository to make our application development
    faster, easier, and—in general—more productive. Although this chapter has a strong
    focus on command-line applications, we think that many of the recipes are just
    as applicable for other types, such as web servers or shared utility libraries.
    You can look forward to learning how to create usable Rust programs that integrate
    well with the OS and behave in ways that users know and expect. On top of that,
    we added a recipe for machine learning enthusiasts who are looking to use Rust
    for their work.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is the full list of what we will cover:'
  prefs: []
  type: TYPE_NORMAL
- en: Random number generation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: File I/O
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dynamic JSON
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Regular expressions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Filesystem access
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Command-line arguments
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Piping input and output
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Web requests
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using state-of-the-art machine learning libraries
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Logging
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Starting subprocesses
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generating random numbers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Random number generation is a fundamental technology that we use daily—encryption,
    simulation, approximation, testing, data selection, and more. Each of these applications
    has its own requirements for the random number generator ([https://xkcd.com/221/](https://xkcd.com/221/)).
    While encryption needs a generator that is as close to true randomness ([https://www.random.org/](https://www.random.org/))
    as possible, simulation, testing, and data selection may need to have reproducible
    samples drawn from a certain distribution.
  prefs: []
  type: TYPE_NORMAL
- en: Due to printing constraints we had to replace the original emoji with characters
    and numbers. Check out the GitHub repository for this book for the full version.
  prefs: []
  type: TYPE_NORMAL
- en: Since there is no random generator in Rust's standard library, the `rand` crate
    is the way to go for many projects. Let's see how we can use it.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We can obtain randomness in just a few steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Open a Terminal to create a new project using `cargo new random-numbers --lib`.
    Use VS Code to open the project directory.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'First, we need to add the `rand` crate as a dependency in `Cargo.toml`. Open
    it to add the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Since we are exploring how to use the `rand` library, we are going to add to
    the test module and implement three tests. Let''s start by replacing the default
    content in `src/lib.rs` with some required imports:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Right underneath the imports (inside the `mod tests` scope), we are going to
    add the first test to check how **Random Number Generators** (**RNGs**) and **Pseudo-Random
    Number Generators** (**PRNGs**) work. To have predictable random numbers, we make
    every generator based on the first, which uses an array literal for initialization:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Having seen regular (P)RNGs, we can move on to something more sophisticated.
    How about using these RNGs to operate on sequences? Let''s add this test that
    uses PRNGs to do a shuffle and pick results:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'As we stated in this recipe''s introduction, RNGs can follow a distribution.
    Now, let''s add another test to the tests module to draw random numbers that follow
    a distribution using the `rand` crate:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Lastly, we can run the tests to see whether the test outputs positive results:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Let's see how it's done behind the scenes.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `rand` crate has lived through several major version revisions since 2018
    and several things have changed. In particular, the crate is now organized differently ([https://rust-random.github.io/book/guide-gen.html](https://rust-random.github.io/book/guide-gen.html)),
    with several companion crates that contain implementations for lesser-used parts.
  prefs: []
  type: TYPE_NORMAL
- en: This is why, in *step 2*, we don't only import a single crate, even though they
    all share a single GitHub repository ([https://github.com/rust-random/rand](https://github.com/rust-random/rand)).
    The reason for this split was presumably to be compatible with the different requirements
    across the field.
  prefs: []
  type: TYPE_NORMAL
- en: RNGs represent—in short—a numeric sequence that is determined on the fly based
    on its predecessor. What is the first number though? It's called the **seed** and
    can be some literal (for reproducibility in tests) or as close to true randomness
    as possible (when not testing).
  prefs: []
  type: TYPE_NORMAL
- en: Popular seeds include seconds since 1 Jan 1970, entropy by the OS, user input,
    and more. The less predictable it is, the better.
  prefs: []
  type: TYPE_NORMAL
- en: In *step 3*, we set up the remaining code with some imports that we are using
    right away in *step 4*. There, we get into using different types of RNGs ([https://rust-random.github.io/book/guide-rngs.html](https://rust-random.github.io/book/guide-rngs.html)).
    The first is `rand` crate's `StdRng`, which is an abstraction over (as of this
    writing) the ChaCha PRNG ([https://docs.rs/rand/0.7.0/rand/rngs/struct.StdRng.html](https://docs.rs/rand/0.7.0/rand/rngs/struct.StdRng.html)),
    chosen for efficiency and cryptographic security. The second algorithm is SmallRng
    ([https://docs.rs/rand/0.7.0/rand/rngs/struct.SmallRng.html](https://docs.rs/rand/0.7.0/rand/rngs/struct.SmallRng.html)),
    a PRNG chosen by the `rand` team that has great throughput and resource efficiency.
    However, since it is fairly easy to predict, the use cases have to be chosen carefully.
    The last algorithm (`Pcg32`) is a pick from the list of available PRNGs ([https://rust-random.github.io/book/guide-rngs.html](https://rust-random.github.io/book/guide-rngs.html)),
    which comes as part of a different crate.
  prefs: []
  type: TYPE_NORMAL
- en: In *step* 5, we work with sequences and choose from or shuffle through them.
    Functions include partial shuffling (that is, picking a random subset) and full,
    in-place shuffles, as well as a random choice of one or more elements in a list.
    Note that the traits for these operations are implemented in a way that they are
    agnostic of the actual random number generator used. This provides a very flexible
    and easy-to-use API.
  prefs: []
  type: TYPE_NORMAL
- en: Only in *step 6* do we get to random numbers that follow distributions. These
    can be very important to do more scientific work such as initializing vectors,
    simulation, or games.
  prefs: []
  type: TYPE_NORMAL
- en: 'The default of most RNGs is the uniform distribution where each number is equally
    likely. Actually drawing samples from the distribution requires an initialized
    RNG, which is provided in the form of a seeded StdRng. The assert statement (empirically)
    shows that it truly is a uniform distribution: after 10,000 draws, the numbers
    average almost exactly in the range''s middle (+/-2).'
  prefs: []
  type: TYPE_NORMAL
- en: The following distribution is the Bernoulli distribution ([http://mathworld.wolfram.com/BernoulliDistribution.html](http://mathworld.wolfram.com/BernoulliDistribution.html)).
    It can be initialized with a chance of success (0.8, in this case)—but, in general,
    it's easy to imagine as a series of coin flips. In fact, this distribution is
    used for generating Boolean values (which is why we can filter by the generated
    value).
  prefs: []
  type: TYPE_NORMAL
- en: Lastly, in this test, we are creating a generator for a normal distribution
    ([http://mathworld.wolfram.com/NormalDistribution.html](http://mathworld.wolfram.com/NormalDistribution.html)).
    This is a well-known form of distributing a random variable around a center point
    (mean) with a defined spread (standard deviation). The closer the values are to
    the center, the more likely their occurrence. In this case, we are initializing
    with a mean of 2.0 and a standard deviation of 0.5, which means that, after a
    significant number of draws, we should end up with exactly that mean and standard
    deviation we provided. `assert_eq!` confirms that for the mean.
  prefs: []
  type: TYPE_NORMAL
- en: '*Step 7* then shows the test output—and it works (at the time of this writing).'
  prefs: []
  type: TYPE_NORMAL
- en: The code in the accompanying repository may fail for this recipe if some implementation
    details of the `rand` crate change (for example, a minor version update).
  prefs: []
  type: TYPE_NORMAL
- en: To read more about the `rand` crate, read more in this book ([https://rust-random.github.io/book/](https://rust-random.github.io/book/)).
    However, if you are interested in how to implement a PRNG and find out more about
    them, check out *Hands-On Data Structures and Algorithms with Rust*, published
    by Packt ([https://www.packtpub.com/application-development/hands-data-structures-and-algorithms-rust](https://www.packtpub.com/application-development/hands-data-structures-and-algorithms-rust)),
    where we go deeper. However, as we have successfully learned to use the `rand`
    crate, we can move on to the next recipe.
  prefs: []
  type: TYPE_NORMAL
- en: Writing to and reading from files
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Processing files is a daily task and sometimes—depending on the programming
    language—unreasonably hard. The Rust project teams have taken care of that problem
    and provide an easy-to-use API to access files. Let's dive right in.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: First, create a new project using `cargo new file-stuff`. Now, to work with
    files, we need a text file to read and process. Lorem Ipsum ([https://www.lipsum.com/](https://www.lipsum.com/)) is
    a popular dummy text that can be generated on a large scale, so to proceed with
    the recipe, generate a few (200) paragraphs with this generator and save the text
    in a file called `lorem.txt` in the root directory.
  prefs: []
  type: TYPE_NORMAL
- en: Finish your preparations by opening the project directory in VS Code.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We can read files from disk in just a few steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Since the Rust standard library comes with all of the basics we need, let''s
    dive directly into `src/main.rs` to add the imports there:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'First, let''s take care of reading from files. For that, we create a function
    called `read()` that reads and extracts the contents from the prepared file, `lorem.txt`, underneath
    the imports:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Writing is going to be the next part we are taking care of. In this case, we
    are creating a dummy file and writing to it in a variety of ways. You can add
    the following to `src/main.rs`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'In the last step, we should tie the functions together in the `main` function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'With `cargo run`, we can now read from and write to disk to perform various
    tasks. Here, we can observe some general statistics about the `lorem.txt` file
    and the file metadata for where we write to:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Let's get behind how we were working with files here.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'After setting up the project, we dive right in with *step 1* and provide the
    imports required to work with the file APIs. Note that working with and reading/writing
    files are in two different modules: `std::fs` for access and `std::io` for read
    and write. In addition to that, the `std::path` module provides powerful and easy
    ways to work with paths in a platform-agnostic way.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Step 2* provides a function that shows several ways to read data from the
    test file we created in preparation. First, we open the file and pass the reference
    to `BufReader` ([https://doc.rust-lang.org/std/io/struct.BufReader.html](https://doc.rust-lang.org/std/io/struct.BufReader.html)),
    a buffered reader. While the initial reference allows reading data as well, `BufReader`
    reads the file contents in bulk and serves them from memory. This reduces disk
    access while improving performance considerably (compared to byte-to-byte reading).
    Additionally, this allows iterating over lines using the `lines()` function.'
  prefs: []
  type: TYPE_NORMAL
- en: With that, we can iterate over each line, splitting it on whitespace and counting
    the resulting iterator (`.split_ascii_whitespace().count()`). Summing these numbers
    up and dividing them by the number of lines found, we can determine the average
    number of words per line. This shows how everything boils down to iterators in
    Rust and allows powerful things to be created within just a couple of lines of
    code.
  prefs: []
  type: TYPE_NORMAL
- en: Instead of reading in an iterator, the Rust standard library supports reading
    into one large string directly as well. For this common task, `fs::read_to_string()`
    provides a convenient shortcut. However, if you want to retain the file pointer
    for later use, the `File` struct provides a `read_to_string()` function as well.
  prefs: []
  type: TYPE_NORMAL
- en: Since the file pointer is set to where it stopped reading in the file (which
    is the end, in this case), we have to reset the file pointer using the `seek()`
    function before further use. For example, if we want to read bytes instead of
    characters, the API provides an iterator for that as well (but there are better
    ways to get the file size in bytes).
  prefs: []
  type: TYPE_NORMAL
- en: '*Step 3* goes deeper into writing files. We start off by creating a `Path`
    instance (which cannot be changed), so we translate it to a mutable `PathBuf` instance
    and add a filename. By calling `File::create()`, we create (overwrite) and obtain
    a file pointer quickly. The `metadata()` function provides some meta-information
    about the file (formatted for readability):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Writing to a file is the same as writing to the console (for example, using
    the `write!()` macro) and can include any data, as long as it can be serialized
    to bytes. The `b"Hello"` byte literal works just as well as an `&str` slice. Akin
    to buffered reading, buffered writing also offers improved performance by only
    writing large blocks at once.
  prefs: []
  type: TYPE_NORMAL
- en: '*Steps 4* and *5* tie everything together in the `main` function and by running
    to see the result.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Nothing is surprising when working with files: the API is expectedly straightforward
    and profits from its integration in common iterators and by using standardized
    traits. We can happily move on to the next recipe.'
  prefs: []
  type: TYPE_NORMAL
- en: Parsing unstructured formats like JSON
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before we start, let's define what we are talking about when we say structured
    and unstructured data. The former, structured data, follows a schema of some sorts—like
    a table schema in an SQL database. Unstructured data, on the other hand, is unpredictable
    in what it will contain. In the most extreme example, a body of prose text is
    the least structured thing we could probably come up with—each sentence may follow
    different rules depending on its content.
  prefs: []
  type: TYPE_NORMAL
- en: JSON is a bit more readable, but unstructured, nevertheless. An object can have
    properties of various data types and no two objects have to be the same. In this
    chapter, we are going to explore some of the ways JSON (and other formats) can
    be handled when it doesn't follow a schema that we can declare in a struct.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This project requires Python to run a small script. For the Python part of the
    project, install Python (3.6 or 3.7 from [https://www.python.org/](https://www.python.org/)),
    following the instructions on the website. The `python3` command should be available
    in a Terminal/PowerShell.
  prefs: []
  type: TYPE_NORMAL
- en: Once available, create a new project using `cargo new dynamic-data --lib`. Use
    VS Code to open the project directory.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Parsing is a multi-step process (but it''s easy to do):'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let''s add `serde` and its sub-crates to `Cargo.toml`. Open the file
    and add the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let''s use the crates and see what they can do. We do this by creating
    tests that parse the same data from various formats, starting with JSON. In `src/lib.rs`,
    we replace the default tests module with the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'TOML is a text-based format rivaling JSON and YAML for configuration files.
    Let''s create the same test as preceding, but with TOML instead of JSON, and add
    the following code to the `tests` module:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Since the last two were text-based formats, let''s look at a binary format
    as well. Python''s pickle format is often used to serialize data as well as machine
    learning models. However, before we can use Rust to read it, let''s create the
    file in a small Python script called `create_pickle.py` in the project''s root
    directory:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Run `python3 create_pickle.py` to create a `user.pkl` file in the project's
    root directory (the script should exit silently).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Add the last test to the `tests` module in `src/lib.rs,` which parses and compares
    the contents of the pickle file with what''s expected:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Lastly, we want to see the tests run (successfully). Let''s execute `cargo
    test` to see the test results and how we were able to read binary and text data
    of various origins:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Let's see how that works.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Statically typed languages like Rust make programming a lot more comfortable
    once types are established. However, in a world with ever-changing web service
    APIs, a simple additional property can lead to a parser error, making it impossible
    to continue. Therefore, `serde` does not only support fully automated parsing
    but also dynamically extracting data from its `Value` type, complete with type
    parsing.
  prefs: []
  type: TYPE_NORMAL
- en: In *step 1*, we add the various dependencies, all of which comply with the `serde`
    interfaces (which are located in the `serde` crate)—although they come from different
    sources. Using them is demonstrated in *step 2* and later.
  prefs: []
  type: TYPE_NORMAL
- en: We begin with creating a raw string that contains a JSON string for `serde_json`
    to parse. Once the `Value` variable is created, we can use the `json!` macro to
    create an equivalent object to compare. After that, we call the `Value` API to
    retrieve individual properties and check for their type and content. `Value` is
    an enum ([https://docs.serde.rs/serde_json/value/enum.Value.html](https://docs.serde.rs/serde_json/value/enum.Value.html))
    that implements a range of automated conversions and retrieval functions, which
    enable these seamless `assert_eq!` statements. In case a property or list index
    doesn't exist, the `Null` variant of `Value` is returned.
  prefs: []
  type: TYPE_NORMAL
- en: '*Step 3* parses the TOML ([https://github.com/toml-lang/toml](https://github.com/toml-lang/toml))
    format and compares it to the JSON output—thanks to the unified `Value` enum,
    it''s very similar to *step 2*. The main difference is that the user property
    is a list in TOML to demonstrate the other list syntax (`[[this-way-to-declare-a-list-item]]`).'
  prefs: []
  type: TYPE_NORMAL
- en: In *steps 4* and *5,* we prepare a Python pickle file containing a dictionary
    object—parsed from the same JSON object as in *step 2*. Pickle is a binary format,
    which means we tell Python's file API to write raw bytes instead of encoded text.
    In contrast, when we read the file, Rust reads bytes by default and requires the
    programmer to provide the interpretation (codec) if they care to. The `File` API
    ([https://doc.rust-lang.org/std/fs/struct.File.html](https://doc.rust-lang.org/std/fs/struct.File.html))
    automatically returns an (unbuffered) `Read` object to fetch the contents, which
    we can directly pass into the appropriate pickle function. The remaining portion
    of the code verifies whether the contents read from the pickle file are the same
    as for the other objects.
  prefs: []
  type: TYPE_NORMAL
- en: We showed reading three types here, but `serde` supports many more. Check out
    their documentation to learn more, but now let's move on to the next recipe.
  prefs: []
  type: TYPE_NORMAL
- en: Extract text using regular expressions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Regular expressions have been a part of programming for a long time and, in
    the context of Rust, found popularity in the form of `ripgrep` ([https://github.com/BurntSushi/ripgrep](https://github.com/BurntSushi/ripgrep)).
    `ripgrep` is a grep variation that searches files for a particular regular expression—and
    it has been adopted as a major part of VS Code, where it powers the search engine.
    The reason for this is simple: speed ([https://github.com/BurntSushi/ripgrep#quick-examples-comparing-tools](https://github.com/BurntSushi/ripgrep#quick-examples-comparing-tools)).'
  prefs: []
  type: TYPE_NORMAL
- en: Rust's regular expression library has been re-implemented, which may be why
    it outperforms earlier implementations (and because Rust is fast). Let's see how
    we can leverage regular expressions in our Rust projects.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s follow a few steps to explore regular expressions in Rust:'
  prefs: []
  type: TYPE_NORMAL
- en: Open a Terminal to create a new project using `cargo new regex --lib `. Use
    VS Code to open the project directory.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: First, we are going to add the regex crate to our dependencies in `Cargo.toml:`
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, let''s open `src/lib.rs` to create some tests that we can run. To start,
    we create a tests module, replacing any existing code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Regular expressions are typically used to parse data or validate that the data
    conforms to the expression''s rules. Let''s add a test inside the tests module
    for some simple parsing:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'However, regular expressions can do much more with their pattern matching.
    Another task could be to replace data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'As a last test, we can have some more fun analyzing data using regular expressions,
    for example, counting the prefixes on telephone numbers:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let''s run the tests using `cargo test` and we can see that the regular
    expressions perform well:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: Now that we know how to use regular expressions, let's find out how they work.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: After the initial setup in *steps 1* and *2*, we start by creating a tests module
    in *step 3* along with the required dependencies. *Step 4* then contains the first
    test that shows how the regex crate ([https://docs.rs/regex/1.2.1/regex/](https://docs.rs/regex/1.2.1/regex/))
    handles simple parsing of data.
  prefs: []
  type: TYPE_NORMAL
- en: By using the raw string literal syntax, `r"I am a raw string"`, we compile a
    new `Regex` instance that we match to date strings. The included character classes
    are what is commonly used across OSes and languages, which includes support for
    whitespaces as well as (alpha) numerical characters and raw bytes. Additionally,
    flags can be placed directly in the expression using a `(?flag)` notation.
  prefs: []
  type: TYPE_NORMAL
- en: The regular expression in* step 4* is composed of three parts: `(?P<y>\d{4})-(?P<m>\d{2})-(?P<d>\d{2})`.
  prefs: []
  type: TYPE_NORMAL
- en: The first part is named `y` (`?P<name>` declares a name) and looks for exactly
    four (`{4}`) digits `\d` that it can match. Parts two and three look for two digits
    each and are named `m` and `d` respectively. This naming is going to be important
    later on when we want to retrieve the matches. In between those patterns, we see
    a `-`, which means that the final pattern has to look like `yyyy-mm-dd` (or `1234-12-12` to
    be precise) to match.
  prefs: []
  type: TYPE_NORMAL
- en: Going down the test, this is what we do. By preparing a few positive examples,
    we can validate a date (`1999-12-01`), as well as extract the individual parts
    by name (`2019-02-27`). If a string has multiple matches, we can also iterate
    over these captures to remain efficient. In the case of the test, we also check
    whether the extracted content matches the expected values while iterating.
  prefs: []
  type: TYPE_NORMAL
- en: Compiling a regular expression takes a fair amount of time, especially when
    the expression is very large. Consequently, pre-compile and reuse as much as possible
    and avoid compiling in loops!
  prefs: []
  type: TYPE_NORMAL
- en: '*Step 5* creates a similar regular expression and replicates the `fun_dates`
    variable from the *step 4* test. However, instead of just extracting the content,
    we want to replace the pattern, which—in this case—transforms the ISO `-` notation
    into a European-style `.` notation. Since we named the groups in the regex, we
    can now also refer to those names in the replacement string.'
  prefs: []
  type: TYPE_NORMAL
- en: In *step 6*, we return to matching, but instead of simply validating, we extract
    and work with the extracted data to create information. Assuming that a task is
    to count country codes in phone numbers, we can apply the regular expression and
    use `HashMap` for keeping track of each number's occurrence. The regular expression
    matches anything starting with `+`, followed by one to four digits: `(\+[\d]{1,4})`.
  prefs: []
  type: TYPE_NORMAL
- en: Using Rust's iterator powers, we extract the match and filter out any non-matches
    before folding the results into common `HashMap`. `RefCell` helps with managing
    mutability and, since the fold function has to return the accumulated result,
    we have to scope off the mutable borrowing to ensure memory safety (the compiler
    will tell you). Once we extract the inner value of the cell, we can see what the
    numbers were.
  prefs: []
  type: TYPE_NORMAL
- en: This only touches on a few common subjects inside the realm of possible tasks
    with regular expressions. We highly recommend reading the documentation to find
    out more!
  prefs: []
  type: TYPE_NORMAL
- en: However, now that we have had a taste of some regular expressions, we can move
    on to the next recipe.
  prefs: []
  type: TYPE_NORMAL
- en: Recursively searching the filesystem
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ripgrep—as we mentioned in the previous recipe (*Extracting text using regular
    expressions*)—is a popular grep engine that walks through files to find anything
    that matches the provided regular expression rules. For that, it's not only necessary
    to compile and match a regular expression to massive amounts of text, but also
    to find these texts. To get to and open these files, we need to walk the directory
    trees of the filesystem. Let's find out how to do that in Rust.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We can understand recursive search by following a few steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Open a Terminal to create a new project using `cargo new filesystem`. Use VS
    Code to open the project directory.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Edit `Cargo.toml` to add a dependency to a crate called `glob` for walking
    the filesystem:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'In `src/main.rs`, we can then start implementing functions to walk the filesystem
    tree, but first, let''s set up the imports and a type alias for boxed errors:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we are going to add a recursive `walk` function that is only using the
    Rust standard library. Add the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: '`glob` is also the name of a style of wildcards for filesystems (for example, `*.txt`
    or `Cargo*`), working on both Windows and Linux/Unix. In some implementations,
    globs can be recursive as well, which is why we can use the crate of the same
    name to implement another `walk` function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'What''s missing now is the `main` function to tie it all together and call
    the functions accordingly. Add the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'As usual, we want to see it running—use `cargo run` to recursively list files
    from your filesystem using the filters we defined in *step 6*. We also encourage
    you to change the paths to something that fits your system:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: Let's get into the inner workings of walking through the filesystem with a filter.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Walking a filesystem tree is not a particularly complicated task. However, just
    like any other tree walks, it is much easier to be done recursively, even though
    there is always a risk of running into stack overflow problems if the directory
    nesting is too deep. While an iterative approach is possible, it is much longer
    and more complicated to implement.
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we start off with setting everything up in *step 1*, adding
    the `glob` crate ([https://docs.rs/glob/0.3.0/glob/](https://docs.rs/glob/0.3.0/glob/))
    as a dependency in *step 2*, and finally importing the required modules in *step
    3*. In *step 4**,* we write the first `walk` function, a recursive in-order walk.
    This means that we recursively descend as far as possible into the first (by some
    order) directory before we start executing the provided callback on that path—we
    are therefore processing the nodes in the order they came up.
  prefs: []
  type: TYPE_NORMAL
- en: Rust's `DirEntry` struct is powerful in that it allows access to its contents
    via a property (instead of calling a different function). The `io::Result<()>`
    return type also allows for using the `?` operator and would end early in cases
    of errors.
  prefs: []
  type: TYPE_NORMAL
- en: '*Step 5* offers a similar function using the `glob` iterator. Since the input
    is a pattern (both recursive and non-recursive), this pattern is parsed and—if
    it''s valid—returns an iterator over matching file and folder paths. We can then
    call the callback with these entries.'
  prefs: []
  type: TYPE_NORMAL
- en: In *step 6*, we call the functions using a range of paths. The first descends
    into the `src` directory, listing all of the files there using the recursive approach.
    The second pattern first goes up into the project directory's parent and then
    recursively matches all of the `*.rs` files it finds there (and below). In the
    case of this book's chapter, you should see all of the code files we have written
    (and will write).
  prefs: []
  type: TYPE_NORMAL
- en: Lastly, the filter can also be something simple and match the two `Cargo.*`
    files, as shown in the last call of `walk_glob()`.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we know how to go through the filesystem, let's move on to another
    recipe.
  prefs: []
  type: TYPE_NORMAL
- en: Custom command-line arguments
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Working with command-line arguments is a great way to configure a program to
    run specific tasks, use a particular set of input data, or simply to output more
    information. However, looking at the help text output of a Linux program these
    days, it offers an impressive amount of information on all of the flags and arguments
    it can work with. In addition to that, the text is printed in a somewhat standardized
    format, which is why this is usually done with strong library support.
  prefs: []
  type: TYPE_NORMAL
- en: Rust's most popular crate for working with command-line arguments is called
    `clap` ([https://clap.rs/](https://clap.rs/)), and, in this recipe, we are looking
    at how we can leverage its strengths to create a useful command-line interface.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A simple program that uses command-line arguments to print directories/files only
    requires a few steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Open a Terminal to create a new project using `cargo new command-line-args `.
    Use VS Code to open the project directory.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'First, let''s adapt `Cargo.toml` to download `clap` and to have a better binary
    output name:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'In `src/main.rs`, we are going to start with imports:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we define a `walk` function that recursively walks through the filesystem
    to execute a callback on each entry. The function supports excluding certain paths,
    which we implement using its own type:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'With that available, we can define the `walk` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, a few helper functions make our life easier for printing:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'In the `main` function, we are using the `clap` API for the first time. Here,
    we are creating the argument/subcommand structure of the application:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'After the arguments, we add subcommands in the same way—following the builder
    pattern:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'Once we retrieve the matches, we have to get the actual values that have been
    passed into the program:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'However, with subcommands, we can match on their specific flags and other arguments
    too, which is best extracted with Rust''s pattern matching:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s see what that did. Run `cargo run` to see the initial output:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'Nothing! Indeed, we did not specify any required commands or parameters. Let''s
    run `cargo run -- help` (since we named the program list, calling the compiled
    executable directly would be `list help`) to see the help text showing us which
    options we could try:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'We should look at the `dirs` subcommand first, so let''s run `cargo run --
    dirs` to see whether it recognizes the required `PATH` argument:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s also try a fully parameterized run where we list all subfolders of the
    project directory excluding anything called `src` (and their subdirectories):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'Try it yourself: several combinations show the power of `clap`. Let''s see
    how it works.'
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '`clap` ([https://clap.rs/](https://clap.rs/)) prides itself on being a simple-to-use
    crate for working with command-line arguments in Rust—and they are right. In the
    initial two steps, we set up the application config and dependencies. We also
    renamed the binary since `list` is a more to-the-point name than `command-line-args`.'
  prefs: []
  type: TYPE_NORMAL
- en: In *step 3*, we start by importing the necessary structs ([https://docs.rs/clap/2.33.0/clap/struct.App.html](https://docs.rs/clap/2.33.0/clap/struct.App.html))—`App`[,](https://docs.rs/clap/2.33.0/clap/struct.App.html)
    `Arg`[,](https://docs.rs/clap/2.33.0/clap/struct.App.html) `SubCommand` for `clap`,
    and, in *step 4,* we are creating the function that we are going to parameterize
    using command line arguments. The function itself is a simple directory tree walk
    with the ability to execute a callback on each entry and a way to exclude certain
    paths as an exclusion.
  prefs: []
  type: TYPE_NORMAL
- en: This is similar to what we did in the *Recursively searching the filesystem*
    recipe earlier in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Some additional helper callbacks for printing directories and files only are
    defined in *step 5*. Closures could have worked as well but wouldn't achieve the
    same readability.
  prefs: []
  type: TYPE_NORMAL
- en: '*Step 6* is where we work with the `clap` API. This particular case is using
    the Rust API only; however, `clap` supports using external files for configuring
    the parameters as well. Read more at [https://docs.rs/clap/2.33.0/clap/index.html](https://docs.rs/clap/2.33.0/clap/index.html).
    Regardless of how you are going to define the parameters, the structure is very
    similar: the `App` struct has several meta-parameters for informing the user about
    the author, version, and others as well as the arguments it can have.'
  prefs: []
  type: TYPE_NORMAL
- en: An argument can be a flag (that is, setting something to `true`/`false`) or
    a value (such as an input path), which is why we use the `Arg` struct to configure
    each individually. Typical command-line flags have a shorthand for a longer name
    (`ls -a` versus `ls --all` on Linux/Unix), as well as a short help text explaining
    the usage. The last setting concerns whether the flag has a more complex type
    than a Boolean, which we set to `true` for `exclude` and leave at `false` for
    the `recursive` flag. These names will later be used to retrieve these values.
  prefs: []
  type: TYPE_NORMAL
- en: Many command-line applications nowadays have a subcommand structure that allows
    for better structuring and readability. A subcommand can be nested and have its
    own arguments—just like the `App` struct. The arguments we define here are positional,
    so they are not referred to by their name but rather have to be present at that
    particular position. Since the argument is required, the argument parser takes
    in whatever value comes in.
  prefs: []
  type: TYPE_NORMAL
- en: With a call to `get_matches()`, we execute the parsing (which also triggers
    help texts and early exits if necessary) and retrieve an `ArgMatches` instance.
    This type manages the key-value pairs (argument name and the value it got), using
    the `Option` and `Result` types, which allow us to use Rust code for defaults.
  prefs: []
  type: TYPE_NORMAL
- en: Subcommands behave like sub-applications in a way. They come with their own
    `ArgMatches` instance, for accessing their flags and more directly.
  prefs: []
  type: TYPE_NORMAL
- en: '*Step 6* shows a few possible calls to run the program. We use two dashes, `--`,
    to pass any arguments through to the application (rather than `cargo` interpreting
    them), and by running the default help subcommand, we can see a nice and standardized
    help output with all of the texts and names we supplied.'
  prefs: []
  type: TYPE_NORMAL
- en: These help texts are also provided in case parsing does not work out (for example,
    when a flag is misspelled) and for each subcommand. However, the last part of
    *step 6* shows what happens when it works out, listing all of the build directories
    in `target/` (since we excluded `src`). Since we don't want to bore you with various
    parameter combinations, we encourage you to try out the other arguments we configured
    and see different results!
  prefs: []
  type: TYPE_NORMAL
- en: Now that we know how to work with command-line arguments, let's move on to the
    next recipe.
  prefs: []
  type: TYPE_NORMAL
- en: Working with piped input data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Reading data from files is a very common task that we described in another
    recipe in this chapter (*Writing to and reading from files*). However, that''s
    not always the best option. In fact, many Linux/Unix programs can be chained together
    using a pipe (`|`) to process an incoming stream. This allows for several things
    to be done:'
  prefs: []
  type: TYPE_NORMAL
- en: Flexibility on the input source, static text, files, and networking streams—no
    need to change the programs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Run several processes, writing only the end result back to disk
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lazy evaluation of the stream
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Flexible processing up-/downstream (for example, gzipping the output before
    writing to disk)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you are not familiar with how this works, the pipe syntax may look cryptic.
    However, it actually stems from a functional programming paradigm ([https://www.geeksforgeeks.org/functional-programming-paradigm/](https://www.geeksforgeeks.org/functional-programming-paradigm/)),
    where pipes and stream processing are quite common—not unlike Rust's iterators.
    Let's build a CSV to a line-based JSON (each line is an object) converter to see
    how we can work with pipes!
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Open a Terminal to create a new project using `cargo new pipes.` Use VS Code
    to open the project directory and create a simple CSV file called `cars.csv` with
    the following content:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: We are now going to parse this file and create a series of JSON objects from
    it.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Follow the steps to implement `csv` to the JSON converter:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Open `Cargo.toml` to add a few dependencies we need for parsing CSV and creating
    JSON:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let''s add some code. As usual, we are going to import a few things in
    `src/main.rs,` so we can use them in the code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'The next thing to do is add a function that converts the input data into JSON.
    We can do this elegantly using the `Iterator` trait that each `csv::StringRecord` instance
    implements:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'How do we get these `csv::StringRecords` instances? By reading from the console!
    As a last piece of code, we replace the default `main` function with the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'Lastly, use PowerShell (on Windows) or your favorite Terminal (Linux/macOS)
    to run the binary with piped input data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: Let's dive into how we streamed data through multiple programs.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Linux OS is largely file-based; many important interfaces to the kernel
    can be found in virtual filesystems pretending to be a file or folder structure.
    The best example is the `/proc/` filesystem, which allows user-access to hardware
    and other current information of the kernel/system. In the same spirit, the console
    inputs and outputs are treated; they are actually reserved file handles with the
    numbers 0 (standard input), 1 (standard output), and 2 (standard error). In fact,
    these link back to the `/proc/` filesystem, where `/proc/<process id>/fd/1` is
    the standard output of that particular process ID.
  prefs: []
  type: TYPE_NORMAL
- en: Keeping this concept in mind, these file descriptors can be read just like any
    other file—which is what we are doing in this recipe. After setting up the basic
    dependencies in *step 1* and importing the modules in *step 2*, we create a processing
    function in *step 3*. The function takes in two of the `csv` crate's ([https://docs.rs/csv/1.1.1/](https://docs.rs/csv/1.1.1/))
    generic `StringRecord`—which holds a row's worth of data each—for the header row
    and the current row. The `zip()` ([https://doc.rust-lang.org/std/iter/trait.Iterator.html#method.zip](https://doc.rust-lang.org/std/iter/trait.Iterator.html#method.zip))
    function on the iterator allows us to align the indices efficiently, the result
    of which we can then transform into a tuple of `String` and `serde_json::Value::String`.
    This allows us to collect these tuples into a `serde_json::Map` type, which gets
    converted into `serde_json::Value::Object` (representing a JSON object).
  prefs: []
  type: TYPE_NORMAL
- en: The iterator's `collect()` function relies on implementing the `FromIterator` trait
    for the particular types. `serde_json::Map` implements this for `(String, serde_json::Value)`.
  prefs: []
  type: TYPE_NORMAL
- en: '*Step 4* then calls this `to_json()` function—but only after it builds a custom
    `Reader` object! By default `csv::Reader` expects the incoming rows to conform
    to a `Deserialize` struct—something that is impossible in a generic tool. Therefore,
    we resort to creating an instance using `ReaderBuilder` by specifying the options
    we need:'
  prefs: []
  type: TYPE_NORMAL
- en: '`trim(csv::Trim::All)`: This makes sanitation easier.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`has_headers(false)`: This allows us to read the headers first; otherwise,
    they would be ignored.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`delimiter(b'','')`: This hardcodes the delimiter to be a comma.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`from_reader(io::stdin())`: This attaches to the `Read` interface of standard
    input.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Upon creation, we read the first row and assume it is the CSV's header. Hence,
    we save it separately to borrow it to the `to_json()` function as needed. Following
    that, the `for` loop takes care of evaluating the (unlimited) iterator over the
    `Read` interface of standard input (typically until the `EOF` signal is received,
    with *Ctrl* + *D* on Linux/UNIX OSes). Each iteration prints the result to standard
    output again for other programs to read via a pipe.
  prefs: []
  type: TYPE_NORMAL
- en: That's it! We highly recommend checking out the repository of the `csv` crate
    to learn more about the functions it offers (as well as `serde_json` ([https://docs.serde.rs/serde_json/](https://docs.serde.rs/serde_json/)))[),
    before moving on to the next recipe.](https://docs.serde.rs/serde_json/))
  prefs: []
  type: TYPE_NORMAL
- en: Sending web requests
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Over recent years, web requests have become an important part of many applications.
    Almost anything integrates with some kind of web service, even if it's only diagnostics
    and usage statistics. HTTP's versatility has proven to be a great asset in a more
    centralized computing world.
  prefs: []
  type: TYPE_NORMAL
- en: One of the libraries in this recipe (`surf`) is cutting edge and depends on
    an unstable (at the time of writing this) `async`/`await` feature of Rust. Depending
    on when you read this, the library or `async`/`await` in Rust may have changed—in
    that case, please open an issue on the accompanying GitHub repository so we can
    provide a working example for other readers.
  prefs: []
  type: TYPE_NORMAL
- en: Making these web requests has not always been straightforward in any language,
    especially with regard to sending and receiving data types, variables, and more.
    Since Rust does not come with web request modules available out of the box, there
    are a few libraries we can use to connect to remote HTTP services. Let's see how.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We can make web requests in just a few steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Open a Terminal to create a new project using `cargo new web-requests.` Use
    VS Code to open the project directory.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'First, let''s edit `Cargo.toml` to add the dependencies we are going to use
    later:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s start importing these external dependencies and setting up some data
    structs in `src/main.rs`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: '`surf` ([https://github.com/rustasync/surf](https://github.com/rustasync/surf)) is
    a recent crate developed fully `async`. Let''s create a test function to see it
    in action. First, we create the client and issue a simple `GET` request:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we upgrade to something more complex, form data, which we also confirm
    was received well:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, the same procedure is repeated for JSON payloads:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'And finally, we query parameters in `GET` requests:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'Since `surf` is very new, let''s also test a more mature (and not `async`)
    crate, `reqwest` ([https://github.com/seanmonstar/reqwest/](https://github.com/seanmonstar/reqwest/)).
    Just like the previous function, it will go through several ways to do different
    types of web tasks, starting with a simple `GET` request:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'The next request features an HTML form request body:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'This is followed by a JSON `PUT` request:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'The final request features query parameters, automatically serialized by `serde`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: 'One major function is still required: `main()`. Here, we are going to call
    the preceding tests:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: 'The most important command is `cargo +nightly run`, so we can see that making
    requests works for both crates:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: Let's check behind the scenes to see what's up.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Rust community's web frameworks are great examples of how the lessons learned
    from other languages influence the design of a more recent technology. Both crates
    discussed in this chapter follow a similar pattern that can be observed in a range
    of libraries and frameworks across various languages (for example, Python's requests),
    which evolved to this stage themselves.
  prefs: []
  type: TYPE_NORMAL
- en: The way these frameworks operate is often called the builder pattern together
    with the decorator pattern (both described in *Design Patterns,* Gamma et al,
    1994). For C# programmers, the pattern is explained at [https://airbrake.io/blog/design-patterns/structural-design-patterns-decorator](https://airbrake.io/blog/design-patterns/structural-design-patterns-decorator).
  prefs: []
  type: TYPE_NORMAL
- en: 'In this recipe, we look at two frameworks: `reqwest` and `surf`. After setting
    up the dependencies in `Cargo.toml` (*step 2*), we import some structs to create
    a serializable data type (to pass into `serde_urlencoded` ([https://github.com/nox/serde_urlencoded](https://github.com/nox/serde_urlencoded)))
    for `GET` parameters in *step 3*.'
  prefs: []
  type: TYPE_NORMAL
- en: In *step 4*, we create a function that covers `surf`. `surf` is fully `async`,
    which means that—to use `await`—we need to declare the function to be `async`
    as well. Then, we can create reusable `surf::Client`, which issues a `GET` request
    (to [https://blog.x5ff.xyz/other/cookbook2018](https://blog.x5ff.xyz/other/cookbook2018))
    right away. As with all of the other calls in this function, we use `await` to
    wait for the request to complete and the `?` operator to fail in case an error
    occurs.
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we are using the incredibly useful [https://httpbin.org/](https://httpbin.org/).
    This website reflects many properties of the request back to the sender, allowing
    us to see what the server received in a JSON-formatted output (among other things).
  prefs: []
  type: TYPE_NORMAL
- en: The next request is a `POST` request with form data, which can be represented
    as a vector of tuples (key-value pairs). Using the same client as before (unlike
    other frameworks, it's not bound to a specific domain), we can simply pass the
    vector as the form-body of the `POST` request. Since we already know what the
    endpoint will return (JSON), we can ask the framework to parse the results into `serde_json::Value`
    (see also the *Parsing unstructured formats such as JSON* recipe in this chapter)
    right away. Again, any parsing errors, timeouts, and more are handled by the `?`
    operator, which would return an error at this point.
  prefs: []
  type: TYPE_NORMAL
- en: The returned JSON contains the form values in the request, confirming that the
    request contained the data in the expected encoding and format. Similarly, if
    we send JSON data in a `PUT` request, the returned JSON is expected to be equal
    to what we sent.
  prefs: []
  type: TYPE_NORMAL
- en: In the last request, we send HTTP `GET` with automatically constructed query
    parameters from the previously defined `struct`. After sending off the request,
    the reflected JSON contains the data found in the query parameters, which is what
    we sent off—if we (and the library) did everything correctly.
  prefs: []
  type: TYPE_NORMAL
- en: '*Step 5* repeats the same ideas for `reqwest`, with only a few API differences
    (features aside):'
  prefs: []
  type: TYPE_NORMAL
- en: Instead of `futures` and `await`, `reqwest` uses `send()` to execute the request.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Declaring the format for receiving data (JSON, plaintext, and so on) is done
    on the response instance (that is, on the `send()` return type).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Step 6* shows that each of the test functions works and no panics or errors
    are reported.'
  prefs: []
  type: TYPE_NORMAL
- en: Both libraries provide excellent ways to connect to remote web services, with
    `surf` having more features on the portability side (for example, various backends
    and WASM support), while `reqwest` is great for stable applications without `async`
    support and in need of cookies and proxies. For more information, read their respective
    documentations to match it to your project and use case. For now, let's move on
    to the next recipe.
  prefs: []
  type: TYPE_NORMAL
- en: Running machine learning models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Machine learning and especially deep learning has been a rising topic ever
    since AlexNet''s triumph in 2012 ([https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)),
    with the language of choice being mostly Python for its easy-to-use syntax and
    flexibility. However, the underlying frameworks (TensorFlow, PyTorch, and more)
    are commonly built using C++, not only for performance reasons but also because
    accessing hardware (such as a GPU) is a lot easier. Rust has—so far—not been the
    language of choice to implement lower-level frameworks. Even outside the area
    of deep learning, Rust lacks library support in several areas including data preparation,
    classical machine learning, and optimization (progress is tracked here: [http://www.arewelearningyet.com/](http://www.arewelearningyet.com/))—so,
    why bother using Rust in any machine learning task?'
  prefs: []
  type: TYPE_NORMAL
- en: The Rust community provides bindings to popular deep learning frameworks to
    a Rust API, allowing users to do some (limited) experimentation as well as using
    weights of known architectures for inference. While all of this is highly experimental,
    it represents a push in the right direction and it's fascinating to work with.
  prefs: []
  type: TYPE_NORMAL
- en: In the long run, we see Rust—as a low-level language—utilizing its low overhead
    and high performance to benefit the *deploying *of machine learning models (that
    is, model inference), targeting IoT-type devices with limited resources (for example, [https://github.com/snipsco/tract](https://github.com/snipsco/tract)).
    Until then, we can have some fun getting Rust's torch bindings to work. One example
    of using Rust in an efficient way for non-neural networks can be found at [https://blog.x5ff.xyz/blog/azure-functions-wasm-rust-ai/](https://blog.x5ff.xyz/blog/azure-functions-wasm-rust-ai/).
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This recipe cannot cover the details of how and why neural networks work, so
    we assume that you already have an idea what training and test datasets are, what
    a convolutional network does, and how loss functions together with an optimizer
    achieve model convergence. If that sentence didn't make sense to you, we recommend
    taking one of the many online courses such as the [https://www.fast.ai/](https://www.fast.ai/)
    MOOC ([http://course.fast.ai/](http://course.fast.ai/)), the Coursera machine
    learning course ([https://www.coursera.org/learn/machine-learning](https://www.coursera.org/learn/machine-learning)),
    or Microsoft AI school ([https://aischool.microsoft.com/en-us/machine-learning/learning-paths](https://aischool.microsoft.com/en-us/machine-learning/learning-paths)) before
    implementing this recipe. If you are ready to start, use a command-line Terminal
    to create a new Rust project by running `cargo new rusty-ml` and change into the
    `rusty-ml` directory to create a new directory, `models`.
  prefs: []
  type: TYPE_NORMAL
- en: To obtain the data, change into the `rusty-ml` directory and clone (or download
    and extract) Zalando Research's fashion MNIST ([https://research.zalando.com/welcome/mission/research-projects/fashion-mnist/](https://research.zalando.com/welcome/mission/research-projects/fashion-mnist/))
    repository from [https://github.com/zalandoresearch/fashion-mnist](https://github.com/zalandoresearch/fashion-mnist).
    Ultimately, you should end up with three directories, namely, `models`, `fashion-mnist`,
    and `src` within the `rusty-ml` project directory.
  prefs: []
  type: TYPE_NORMAL
- en: In the GitHub repository accompanying this book, the `fashion-mnist` repository
    is liked as a Git submodule ([https://git-scm.com/book/en/v2/Git-Tools-Submodules](https://git-scm.com/book/en/v2/Git-Tools-Submodules)).
    If you run `git submodule update --init` from within your local copy of the repository,
    it will download the `fashion-mnist` repository.
  prefs: []
  type: TYPE_NORMAL
- en: Before we can continue, we need to unzip the data files, which are located in
    `fashion-mnist/data/fashion`. On Linux/macOS, you can use `gunzip *.gz` from within
    this directory to extract all; on Windows, use your preferred tool to do the same.
  prefs: []
  type: TYPE_NORMAL
- en: 'The end result should look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: The original MNIST ([http://yann.lecun.com/exdb/mnist/](http://yann.lecun.com/exdb/mnist/))
    is a dataset comprised of small images (28 x 28 pixels, grayscale) that show handwritten
    digits, and the goal was to classify them into classes from 0 to 9—that is, recognize
    the number. After 20 years, modern algorithms solve this task with exceedingly
    high accuracy, so it needed an upgrade—which is what Zalando, a fashion company
    located in Berlin, Germany, took on. The `fashion-mnist` dataset is a drop-in
    replacement for the original showing small clothing items instead of digits. The
    classification of these items is much harder, thanks to their intricate details
    that make up each item in the ten classes. The task is to correctly classify which
    class (out of ten) a clothing item belongs to. The classes include boots, sneakers,
    pants, t-shirts, and others.
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we are going to train a very accurate (~90%) model to identify
    these items using Rust's PyTorch bindings, `tch-rs`.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Only a few steps are needed to train and use a neural network in Rust:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Open `Cargo.toml` to add the dependency for `tch-rs`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s add some code for the imports to `src/main.rs` before diving deep:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: 'PyTorch (and thereby, `tch-rs`) architectures typically store their layers
    individually, so we can store them in individual properties in `struct`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: 'For these layers to work together as a neural network, it requires a forward
    pass. The `nn` module of `tch` provides two traits (`Module` and `ModuleT`) that
    we can implement to do that. We decided on implementing `ModuleT`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we are going to implement the training loop. Other deep learning frameworks
    hide these bits from the user, but PyTorch allows us to understand the individual
    steps better by writing them from scratch. Add the following function to `src/main.rs`,
    starting with some data loading:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we instantiate two important things: `VarStore` where everything gets
    saved in `tch`, and `ConvNet`, which we declared earlier:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: 'Once we have that, we can use a loop to iterate over the training data in (random)
    batches, feeding them into the network, computing the loss, and running the back
    propagation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: 'After going through the entire training set, we then test the model on the
    entire test set. Since this should not influence the model performance, we skip
    the backpropagation this time:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we print some statistics so we know whether we are on the right track,
    but only after we save the current best model weights (that is, where the loss
    is the lowest):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: 'After having a trained model, you typically also want to run inference on other
    images (that is, predict stuff). The next function takes the best model''s weights
    and applies it to the `ConvNet` architecture:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: 'With this model in place, we can then take a random subset of the training
    data and run inference:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: 'The `main` function ties it all together and trains a model before calling
    the inference function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: 'That''s exciting! Let''s train a model for a few epochs to see decreasing loss
    and increasing test accuracy scores:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: This was a very interesting detour into the world of machine learning. Let's
    find out more about it.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Deep learning in Rust works—however, it comes with many strings attached. `tch-rs`
    ([https://github.com/LaurentMazare/tch-rs](https://github.com/LaurentMazare/tch-rs))
    is a great framework if you already know some PyTorch and it lets you get into
    it right away. However, anyone who is new to the idea of machine learning should
    look at Python (and PyTorch) to get comfortable with the type of thinking that
    is required. `tch-rs` uses the C++ foundation of the Python version and provides
    a thin wrapper around the bindings it created. This means two things:'
  prefs: []
  type: TYPE_NORMAL
- en: Most ideas of the Python version should apply to `tch-rs`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The extensive C++ usage is likely *very* unsafe.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By using bindings, wrapped code is much more likely to leave some kind of memory
    unfreed thanks to the added layer of abstraction and the changed programming paradigms
    in the host language. For applications such as machine learning, where tens (or
    even hundreds) of gigabytes of memory usage is not uncommon, a memory leak has
    a much larger impact. However, it's great to see it working so well already and
    we expect that this project will go much further.
  prefs: []
  type: TYPE_NORMAL
- en: We made a few simplifications to the model training process for brevity. It's
    recommended to do some research into how to properly evaluate a model and rule
    out overfitting before going any further with it.
  prefs: []
  type: TYPE_NORMAL
- en: In *step 1*, we set up the `tch` dependency to resolve the imports we use in
    *step 2*. *Step 3* is where things get interesting (model architecture). Deep
    learning is a set of matrix multiplications, where—technically speaking—the input
    and output dimensions have to match for it to work. Since PyTorch ([https://pytorch.org/](https://pytorch.org/))
    is famously low-level, we have to set the individual layers up and match their
    dimensions by hand. In this case, we use two layers of 2-dimensional convolutions
    with two dense layers at the end to make sense of what the convolutions found.
    When we initialize the network in the `new()` function, we assign the input size,
    number of neurons/filters, and output/layers to the instantiation (`nn::conv2d`
    and `nn::linear`) functions. As you can see, the numbers match between the layers
    for it to be able to concatenate them, while the last layer outputs exactly the
    number of classes we are looking for (10).
  prefs: []
  type: TYPE_NORMAL
- en: 'Tensors are a generalized version of vectors in mathematics. They can be anything
    from a single number (scalar) to a multi-dimensional vector of vectors. Read more
    at [http://mathworld.wolfram.com/Tensor.html](http://mathworld.wolfram.com/Tensor.html)
    (warning: lots of math).'
  prefs: []
  type: TYPE_NORMAL
- en: 'In *step 4*, we implement the forward process provided by the `nn::ModuleT`
    trait. The difference to `nn::Module` is the `train` parameter, which indicates
    whether this run is intended for training in the `forward_t()` function. The other
    parameter in that function is the actual data represented as an `nn::Tensor` reference.
    Before we can use it, we have to assign a structure to it, and, since we are dealing
    with (grayscale) images, the choice is straightforward: it''s a 4-dimensional
    tensor. The dimensions are assigned as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: The first dimension is the batch, so there are zero to `batchsize` number of
    images in there.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The second dimension represents the number of channels in the image, which is
    one for grayscale but three for RGB.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the last two dimensions, we are storing the actual image, so they are the
    image's width and height.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'So, as we call the `.view()` function on the tensor instance, we are changing
    the interpretation to these dimensions, with -1 meaning whatever fits (typical
    for batch size). From there on, we are dealing with a bunch of 28 x 28 x 1 images
    that we feed into the first convolutional layer and apply the **Rectified Linear
    Unit** (**ReLU**) ([https://machinelearningmastery.com/rectified-linear-activation-function-for-deep-learning-neural-networks/](https://machinelearningmastery.com/rectified-linear-activation-function-for-deep-learning-neural-networks/))
    function on the outcome. That follows a 2-dimensional max pooling layer, after
    which the pattern is repeated for the second convolutional layer. This is common
    to control the output sizes of a convolutional layer. After the second max pooling,
    we flatten the output vector (1,024 is a calculated value: [https://medium.com/@iamvarman/how-to-calculate-the-number-of-parameters-in-the-cnn-5bd55364d7ca](https://medium.com/@iamvarman/how-to-calculate-the-number-of-parameters-in-the-cnn-5bd55364d7ca))
    and apply the fully connected layers one after the other with a ReLU function
    in between. The raw output of the last layer is then returned as a tensor.'
  prefs: []
  type: TYPE_NORMAL
- en: In the training loop in *step 5*, we start off by reading the data from disk,
    using a predefined dataset function. We are taking advantage of this since the
    MNIST data is very common in machine learning examples. Ultimately, this is an
    iterator over the data (in this case, images) that comes with a few handy functions
    attached. In fact, there are multiple iterators since the data is already split
    into training and test sets.
  prefs: []
  type: TYPE_NORMAL
- en: Once loaded, we create an `nn::VarStore`, which is a `tch-rs` concept to store
    the model weights. This `VarStore` instance is passed into our model architecture
    struct, `ConvNet`, and the optimizer, so that it can do the backpropagation (Adam
    ([https://arxiv.org/abs/1412.6980](https://arxiv.org/abs/1412.6980)) is a stochastic
    optimizer and, as of early 2019, considered state of the art). Since PyTorch allows
    moving data between devices (that is CPU versus GPU), we always have to assign
    a device to weights and data so the framework knows which memory to write to.
  prefs: []
  type: TYPE_NORMAL
- en: The `learning_rate` parameter represents a step size of how far the optimizer
    jumps toward the best solution. This parameter is almost always very small (for
    example, `1e-2`) because choosing a larger value might overshoot its goal and
    worsen the solution, and a too-small value could mean it never gets there. Read
    more at [https://www.jeremyjordan.me/nn-learning-rate/](https://www.jeremyjordan.me/nn-learning-rate/).
  prefs: []
  type: TYPE_NORMAL
- en: 'Next in the training loop, we have to implement the actual loop. This loop
    runs for several epochs and, generally, a higher number means more convergence
    (for example, overfitting: [https://machinelearningmastery.com/overfitting-and-underfitting-with-machine-learning-algorithms/](https://machinelearningmastery.com/overfitting-and-underfitting-with-machine-learning-algorithms/)),
    but the number we chose (5) in this recipe is definitely too low and chosen for
    the training to finish quickly with tangible results. Try a higher number and
    see how (whether) the model improves! Within each epoch, we can then run through
    the shuffled batches (a convenience function provided by the dataset implementation),
    run the forward pass and compute the loss for each batch. The loss function—cross
    entropy ([https://pytorch.org/docs/stable/nn.html#crossentropyloss](https://pytorch.org/docs/stable/nn.html#crossentropyloss))—comes
    back with a number that lets us know how far off we were with the prediction,
    which is important for running the backpropagation. In this example, we chose
    a large batch size of 1,024 images in one go, meaning that it has to run the loop
    59 times for each epoch. This speeds up the process without too much of an impact
    on the training quality—if you can fit everything into memory.'
  prefs: []
  type: TYPE_NORMAL
- en: Think of a loss function as a function to determine how wrong the model was.
    Typically, we choose a predefined loss function based on the type of problem (regression,
    binary classification, or multi-class classification). Cross entropy is the default
    for multi-class classification.
  prefs: []
  type: TYPE_NORMAL
- en: 'As we are walking through the batches, we also want to know how we are doing,
    which is why we created a simple vector to store the average loss per batch. Plotting
    the losses per epoch, we get a typical shape where the loss levels off toward
    zero:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e0ba6358-59b7-4961-b7c5-888816be9fa1.png)'
  prefs: []
  type: TYPE_IMG
- en: Since the algorithm has seen the training data, we need some test data to see
    whether it actually improved or whether it just learned to recognize the training
    data really well. This is why the test set is done without backpropagation and
    calculates the accuracy directly.
  prefs: []
  type: TYPE_NORMAL
- en: It is generally recommended to have a three-way split of your data ([https://machinelearningmastery.com/difference-test-validation-datasets/](https://machinelearningmastery.com/difference-test-validation-datasets/)).
    A training set that the model learns on should make up the majority, a test set
    that should show progress and overfitting after every epoch, and, finally, another
    set of data that the network has never seen before. The last one is to make sure
    that it performs as expected on real-world data and it must not be used to change
    any parameter in training. Confusingly, the naming of these three is sometimes
    training, validation, test (respectively) as well as training, test, validation.
  prefs: []
  type: TYPE_NORMAL
- en: In a strategy known as checkpointing, we then save the best model to disk as
    soon as the loss it produces is lower than what we had before. When training 200
    epochs, the loss function likely shows several spikes as the model learns wrong
    features and we don't want to lose the best model so far. Once done with the training
    for one epoch, we want to print out something to see if the model converges as
    expected.
  prefs: []
  type: TYPE_NORMAL
- en: In *step 6*, we repeat some of the setup processes for loading the data, but,
    instead of training the architecture, we simply load the weights of the network
    from disk. The weights are the parts that we trained in the previous step and,
    in an inference-only scenario, we would train somewhere else and simply transfer
    the weights to where we classify real-world data (or load the entire model with
    something like ONNX: [https://onnx.ai/](https://onnx.ai/)).
  prefs: []
  type: TYPE_NORMAL
- en: To illustrate the prediction process, we are using the test set (again)—something
    that should be avoided in practice, since the model has to work on unseen data
    just as well as the data used in training. We take 10 random images (in 10 batches
    of size 1), run the forward pass, and then use a function called softmax to derive
    probabilities from the raw network output. After an application of `.view()` to
    align the data to the labels, we print the probabilities to the command line for
    us to see. Since these are probabilities, taking the index with the highest probability
    is the network's prediction. Since we used a dataset implementation, we can trust
    that these indices align with the input labels.
  prefs: []
  type: TYPE_NORMAL
- en: '*Step 7* calls the functions in order and we get to see some training and predictions
    in the *step 8* output. As described in the *step 5* explanation, we print the
    loss (for this machine, each line took about 30 seconds to appear) and training
    accuracy. After the training is done, we know where the best model weights are
    located and use those to run the inference and print out the probability matrix.'
  prefs: []
  type: TYPE_NORMAL
- en: Each line in that matrix represents the possible outcomes with probabilities
    assigned to each class—and, while it is 100% certain in the first line, the second
    line is a closer call (57% for class 0 and 40% for class 6). The sixth example
    has been wrongly predicted, and unfortunately, the model was fairly confident
    as well (71% for class 3 and 11% for class 2), which leads us to believe that
    more training is required.
  prefs: []
  type: TYPE_NORMAL
- en: We encourage you to play around a little bit with the parameters to see how
    the outcomes can change quickly (for better or worse), or if you are more experienced,
    to build a better architecture. Regardless of what you are doing, `tch-rs` is
    an interesting way of using deep learning in Rust and we hope that it develops
    further so we can use it for a range of tasks in machine learning.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we know more about machine learning in Rust, let's move on to more
    tangible things in the next recipe.
  prefs: []
  type: TYPE_NORMAL
- en: Configuring and using logging
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'While sending debug and other information out to the console is popular and
    easy, chances are that it becomes confusing and chaotic beyond a certain complexity.
    This includes the lack of a standardized date/time or origin class or inconsistent
    formatting, making it hard to trace an execution path through the system. Moreover,
    recent systems focus on logs as an additional source for information: how many
    users did we serve each hour of the day? Where did they come from? What was the
    95^(th) percentile response time?'
  prefs: []
  type: TYPE_NORMAL
- en: Due to printing constraints we had to replace the original emoji with their
    names. Check out the GitHub repository for this book for the full version.
  prefs: []
  type: TYPE_NORMAL
- en: These questions can be answered with diligent logging using a framework that
    provides consistent and configurable output that can be easily parsed and shipped
    to a log analytics service. Let's create a simple Rust application that logs data
    in a variety of ways.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Follow the steps to create and use a custom logger:'
  prefs: []
  type: TYPE_NORMAL
- en: Open a Terminal to create a new project using `cargo new logging`. Use VS Code
    to open the project directory.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'As a first step, we adapt `Cargo.toml` to include our new dependencies:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, in `src/main.rs`, we can import the required macros:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs: []
  type: TYPE_PRE
- en: 'Before getting into more complex things, let''s add a function that shows us
    how to use the macros we just imported:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs: []
  type: TYPE_PRE
- en: 'These macros work because they are pre-configured by the logging framework.
    Consequently, if we are configuring the logging, it has to be done globally—for
    example, in the `main` function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs: []
  type: TYPE_PRE
- en: 'By using `log4rs::init_file()`, we use a YAML configuration that can be changed
    without recompiling the program. Before continuing in `src/main.rs`, we should
    create `log4rs.yml` like this (the YAML format is picky about indentations):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs: []
  type: TYPE_PRE
- en: 'Back to `src/main.rs`: we saw an ability to create and use a fully custom logger.
    For that, we create a nested module in `src/main.rs` and implement our logger
    there:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs: []
  type: TYPE_PRE
- en: 'Once we have defined the imports and basic `struct`, we can implement the `log::Log`
    trait for our new `EmojiLogger` type:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE81]'
  prefs: []
  type: TYPE_PRE
- en: 'To avoid any lifetime conflicts, we want the logger to have a static lifetime
    ([https://doc.rust-lang.org/reference/items/static-items.html](https://doc.rust-lang.org/reference/items/static-items.html)),
    so let''s instantiate and declare the variable using Rust''s `static` keyword:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s execute `cargo run`, first with the `USE_CUSTOM` constant (created in
    *step 5*) set to `false`, which tells the program to read and use the `log4rs.yaml`
    configuration, instead of the custom module:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE83]'
  prefs: []
  type: TYPE_PRE
- en: 'In addition to that, we configured it so that, if something gets logged to
    `special-target`, we append it to a file called `outfile.log.` Let''s see what''s
    in there as well:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE84]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that we have used the `log4rs` default logger, let''s see what our own
    logging class does. Set `USE_CUSTOM` (from *step 5*) to `true` and use `cargo
    run` to create the following output:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE85]'
  prefs: []
  type: TYPE_PRE
- en: Now that we have seen it at work, let's dive into why this is the case.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this more complex example, we are using Rust''s logging infrastructure,
    which consists of two main parts:'
  prefs: []
  type: TYPE_NORMAL
- en: The `log` crate ([https://github.com/rust-lang-nursery/log](https://github.com/rust-lang-nursery/log)),
    which provides the facade (interface) to the logging macros
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A logging implementor such as `log4rs` ([https://github.com/sfackler/log4rs](https://github.com/sfackler/log4rs)),
    `env_logger` ([https://github.com/sebasmagri/env_logger/](https://github.com/sebasmagri/env_logger/)),
    or similar ([https://docs.rs/log/0.4.8/log/#available-logging-implementations](https://docs.rs/log/0.4.8/log/#available-logging-implementations)[)](https://github.com/sfackler/log4rs)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'After the initial setup in *steps 1* and *2*, we simply have to import the
    macros provided by the `log` crate in *step 3*—nothing more. As we create a function
    to write to all available log levels (think of the levels as tags to filter by)
    and an additional target in this line in *step 4* (as shown in the following), we
    cover most of the use cases for logging:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE86]'
  prefs: []
  type: TYPE_PRE
- en: '*Step 5* sets up the logging framework, `log4rs`, a crate that is modeled after
    the de-facto standard in the Java world: `log4j` ([https://logging.apache.org/log4j/2.x/](https://logging.apache.org/log4j/2.x/)).
    The crate provides excellent flexibility when it comes to where to write which
    log levels and using what format, and it can be changed at runtime. Check the *step
    6* configuration file to see an example. There we define `refresh_rate` (when
    to rescan the file for changes) of 30 seconds, which enables us to change the
    file without having to restart the application. Next, we define two appenders,
    which means output targets. The first one, `stdout`, is a simple console output,
    whereas `outfile` produces `outfile.log`, which we show in *step 10*. Its encoder
    property also hints toward how we can change the formatting.'
  prefs: []
  type: TYPE_NORMAL
- en: Next, we defined a `root` logger, which represents the default. Having `trace`
    as the default level leads to excessive logging in many cases; having `warn` is
    often enough, especially in production settings. Additional loggers are created
    in the loggers property, where each child (`special-target`) represents a target
    we can use in the log macro (as seen in the preceding). These targets come with
    a configurable log level (`info`, in this case) and can use a range of appenders
    to write to. There are many more options that you can use here—just check out
    the documentation on how to set up more complex scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: 'In *step 7*, we return to Rust code and create our own logger. This logger
    implements the log crate''s `Log` trait directly and translates any incoming `log::Record`
    into an emoji-backed console output for our visual entertainment. By implementing
    `enabled()`, we can filter whether any calls to `log()` are made and therefore
    base our decisions on more than just simple log levels as well. We instantiate
    the `EmojiLogger` struct in *step 8* as a static variable ([https://doc.rust-lang.org/reference/items/static-items.html](https://doc.rust-lang.org/reference/items/static-items.html)),
    which is passed into the `log::set_logger()` function whenever we set the `USE_CUSTOM` constant
    (*step 5*) to `true`. *Step 9* and *step 10* show these two outcomes:'
  prefs: []
  type: TYPE_NORMAL
- en: The `log4rs` default format includes the module, log level, timestamp, and message,
    and it creates the `outfile.log` file we configured it to.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Our custom logger creates unusual formatting along with an emoji showing the
    log levels—just as we wanted.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `log` crate is particularly useful in Rust since it allows you to attach
    your own loggers to third-party crates as well. The crates for issuing web requests
    in this chapter (in the *Sending web requests* recipe) provide infrastructure
    ([https://docs.rs/surf/1.0.2/surf/middleware/logger/index.html](https://docs.rs/surf/1.0.2/surf/middleware/logger/index.html))
    to do that, just like many other crates do (for example, `actix-web` in an earlier
    chapter). This means that, just by adding a dependency and a few lines of code,
    you can already create an application completely with logging.
  prefs: []
  type: TYPE_NORMAL
- en: This concludes our detour into logging, so let's move on to another recipe.
  prefs: []
  type: TYPE_NORMAL
- en: Starting subprocesses
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Pipelines, container orchestration, and command-line tools all share a common
    task: they all have to start and monitor other programs. These system calls are
    done in a variety of ways in other technologies, so let''s call a few standard
    programs with Rust''s `Command` interface.'
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Follow these quick steps to call on external programs:'
  prefs: []
  type: TYPE_NORMAL
- en: Open a Terminal to create a new project using `cargo new sub-processes.` Use
    VS Code to open the project directory.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Open `src/main.rs`. Rust''s standard library comes with an external command
    interface built-in, but first, let''s import it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE87]'
  prefs: []
  type: TYPE_PRE
- en: 'Once imported, we can do the rest in the `main` function. We''ll start off
    by calling `ls` with some arguments in two different directories:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE88]'
  prefs: []
  type: TYPE_PRE
- en: 'In the next step, we are setting environment variables in the subprocess and,
    by grabbing the standard output of the `env` program, we can check whether it
    worked:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE89]'
  prefs: []
  type: TYPE_PRE
- en: '`rev` is a program that reverses anything that comes in via standard input
    and it''s available on Windows and Linux/Unix. Let''s call it with some text and
    capture the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE90]'
  prefs: []
  type: TYPE_PRE
- en: 'Use `cargo run` to see the program print the `ls` output (your output will
    look a little different):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE91]'
  prefs: []
  type: TYPE_PRE
- en: Windows users have to run this program in PowerShell, where `ls` is available.
  prefs: []
  type: TYPE_NORMAL
- en: Let's see how it works behind the scenes.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This recipe quickly covers some abilities of the Rust `std::process::Command`
    struct. After setting everything up in *steps 1* and *2*, we create the `main`
    function in *step 3*. Using `Result<(), Box<dyn Error + ...>>` with a boxed `dyn`
    trait ([https://doc.rust-lang.org/edition-guide/rust-2018/trait-system/dyn-trait-for-trait-objects.html](https://doc.rust-lang.org/edition-guide/rust-2018/trait-system/dyn-trait-for-trait-objects.html))
    as the return type for the main function allows us to use the `?` operator instead
    of `unwrap()`, `expect()`, or other constructs—regardless of the actual error
    type.
  prefs: []
  type: TYPE_NORMAL
- en: 'We start off by using the `ls` command, which lists the directory contents.
    Except for Windows, the program takes arguments to expand the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '`-l` adds additional information such as permissions, date, and size (also
    called a long listing).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`-a` includes hidden files as well (a stands for all).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`-h` uses human-friendly sizes (for example, KiB after 1,000 bytes).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For `ls`, we can pass these flags as one large flag, `-alh`, (the order doesn't
    matter) and the `args()` function allows us to do that as a string slice. The
    actual execution of the process child is only done when we check the `status()`
    function of the instance and, here, we are also printing the results. The status
    code (on Linux) represents the success or failure of a particular program when
    it's `zero` or `non-zero` respectively.
  prefs: []
  type: TYPE_NORMAL
- en: The next part catches the standard output of the program and sets an environment
    variable for it. Environment variables can be a great way to transfer data or
    settings to the subprogram as well (for example, compiler flags for builds and
    keys for command-line APIs). `env` ([https://linux.die.net/man/1/env](https://linux.die.net/man/1/env))
    is a program on Linux (with a PowerShell equivalent) that prints available environment
    variables, so when we capture standard output, we can try to find the variable
    and its value.
  prefs: []
  type: TYPE_NORMAL
- en: 'The next part passes data to the `rev` program through the standard input while
    catching standard output. `rev` simply reverses the input data, so we expect the
    output to be the reverse of the input. There are two interesting things to note:'
  prefs: []
  type: TYPE_NORMAL
- en: Getting a handle for standard input is scoped to avoid violating borrowing rules.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Writing and reading from the pipes is done in bytes, which requires parsing
    to convert from/into a string. The `String::from_utf8_lossy()` function does that
    while ignoring invalid data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: After that, the `main` function returns with a positive empty result (`Ok(())`).
  prefs: []
  type: TYPE_NORMAL
- en: In the last step, as usual, we run the code to see whether it works and, although
    we only have two `println!()` statements with only the exit code of the `ls` command
    in our source file, there is a lot of output. This is due to the default setting
    of passing a subprocess's standard output through the console. What we see here
    is, therefore, the output of the `ls -alh` command on Linux, which will be a little
    different on your machine.
  prefs: []
  type: TYPE_NORMAL
- en: Having successfully created and run several commands using Rust, we can now
    go out and create our own applications. We hope that this book helped you with
    that.
  prefs: []
  type: TYPE_NORMAL
