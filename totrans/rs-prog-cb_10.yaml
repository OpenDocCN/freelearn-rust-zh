- en: Getting Practical with Rust
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Rust的实际应用
- en: Even after nine chapters of Rust, we are still missing the parts that make applications
    pleasant to use. Many crates within Rust's ecosystem provide important functions
    across different domains and, depending on the application type, you might need
    several additional crates. In this chapter, we will look at various parts within
    Rust's standard library and public crate repository to make our application development
    faster, easier, and—in general—more productive. Although this chapter has a strong
    focus on command-line applications, we think that many of the recipes are just
    as applicable for other types, such as web servers or shared utility libraries.
    You can look forward to learning how to create usable Rust programs that integrate
    well with the OS and behave in ways that users know and expect. On top of that,
    we added a recipe for machine learning enthusiasts who are looking to use Rust
    for their work.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 即使已经学习了Rust的九个章节，我们仍然缺少使应用程序易于使用的部分。Rust生态系统中的许多crate在不同的领域提供了重要的功能，并且根据应用程序类型，您可能需要几个额外的crate。在本章中，我们将查看Rust标准库和公共crate仓库中的各种部分，以使我们的应用程序开发更快、更简单，并且在一般情况下更高效。尽管本章重点在于命令行应用程序，但我们认为其中许多配方同样适用于其他类型，如Web服务器或共享实用库。您可以期待学习如何创建与操作系统良好集成的可使用Rust程序，并以用户熟悉和期望的方式运行。此外，我们还为希望使用Rust进行工作的机器学习爱好者添加了一个配方。
- en: 'Here is the full list of what we will cover:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们将涵盖的完整列表：
- en: Random number generation
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随机数生成
- en: File I/O
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文件I/O
- en: Dynamic JSON
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 动态JSON
- en: Regular expressions
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 正则表达式
- en: Filesystem access
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文件系统访问
- en: Command-line arguments
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 命令行参数
- en: Piping input and output
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 管道输入和输出
- en: Web requests
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 网络请求
- en: Using state-of-the-art machine learning libraries
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用最先进的机器学习库
- en: Logging
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 记录日志
- en: Starting subprocesses
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 启动子进程
- en: Generating random numbers
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成随机数
- en: Random number generation is a fundamental technology that we use daily—encryption,
    simulation, approximation, testing, data selection, and more. Each of these applications
    has its own requirements for the random number generator ([https://xkcd.com/221/](https://xkcd.com/221/)).
    While encryption needs a generator that is as close to true randomness ([https://www.random.org/](https://www.random.org/))
    as possible, simulation, testing, and data selection may need to have reproducible
    samples drawn from a certain distribution.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 随机数生成是一种基本技术，我们每天都在使用——加密、模拟、近似、测试、数据选择等。每个应用都有其随机数生成器的特定要求（[https://xkcd.com/221/](https://xkcd.com/221/)）。虽然加密需要一个尽可能接近真实随机的生成器（[https://www.random.org/](https://www.random.org/)），但模拟、测试和数据选择可能需要从某个分布中抽取可重复的样本。
- en: Due to printing constraints we had to replace the original emoji with characters
    and numbers. Check out the GitHub repository for this book for the full version.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 由于打印限制，我们不得不将原始表情符号替换为字符和数字。查看此书的GitHub仓库以获取完整版本。
- en: Since there is no random generator in Rust's standard library, the `rand` crate
    is the way to go for many projects. Let's see how we can use it.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 由于Rust标准库中没有随机生成器，对于许多项目来说，`rand`包是最佳选择。让我们看看如何使用它。
- en: How to do it...
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'We can obtain randomness in just a few steps:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在几个步骤中获取随机性：
- en: Open a Terminal to create a new project using `cargo new random-numbers --lib`.
    Use VS Code to open the project directory.
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开终端，使用`cargo new random-numbers --lib`创建一个新的项目。使用VS Code打开项目目录。
- en: 'First, we need to add the `rand` crate as a dependency in `Cargo.toml`. Open
    it to add the following:'
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们需要在`Cargo.toml`中将`rand`包添加为依赖项。打开它并添加以下内容：
- en: '[PRE0]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Since we are exploring how to use the `rand` library, we are going to add to
    the test module and implement three tests. Let''s start by replacing the default
    content in `src/lib.rs` with some required imports:'
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于我们正在探索如何使用`rand`库，我们将向测试模块添加并实现三个测试。让我们首先将`src/lib.rs`中的默认内容替换为一些必需的导入：
- en: '[PRE1]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Right underneath the imports (inside the `mod tests` scope), we are going to
    add the first test to check how **Random Number Generators** (**RNGs**) and **Pseudo-Random
    Number Generators** (**PRNGs**) work. To have predictable random numbers, we make
    every generator based on the first, which uses an array literal for initialization:'
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在导入下面（在`mod tests`作用域内），我们将添加第一个测试来检查**随机数生成器**（**RNGs**）和**伪随机数生成器**（**PRNGs**）的工作原理。为了获得可预测的随机数，我们使每个生成器基于第一个，它使用数组字面量进行初始化：
- en: '[PRE2]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Having seen regular (P)RNGs, we can move on to something more sophisticated.
    How about using these RNGs to operate on sequences? Let''s add this test that
    uses PRNGs to do a shuffle and pick results:'
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在了解了常规（P）RNGs之后，我们可以继续到更复杂的内容。我们是否可以使用这些RNGs来操作序列？让我们添加这个测试，它使用伪随机数生成器（PRNGs）来进行洗牌并选择结果：
- en: '[PRE3]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'As we stated in this recipe''s introduction, RNGs can follow a distribution.
    Now, let''s add another test to the tests module to draw random numbers that follow
    a distribution using the `rand` crate:'
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如我们在本食谱的介绍中所述，随机数生成器（RNGs）可以遵循一个分布。现在，让我们向测试模块添加另一个测试，使用`rand` crate来绘制遵循分布的随机数：
- en: '[PRE4]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Lastly, we can run the tests to see whether the test outputs positive results:'
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们可以运行测试以查看测试输出是否为正结果：
- en: '[PRE5]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Let's see how it's done behind the scenes.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看幕后是如何操作的。
- en: How it works...
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的……
- en: The `rand` crate has lived through several major version revisions since 2018
    and several things have changed. In particular, the crate is now organized differently ([https://rust-random.github.io/book/guide-gen.html](https://rust-random.github.io/book/guide-gen.html)),
    with several companion crates that contain implementations for lesser-used parts.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 自2018年以来，`rand` crate经历了几个主要版本的修订，并且有几件事情发生了变化。特别是，crate现在组织方式不同（[https://rust-random.github.io/book/guide-gen.html](https://rust-random.github.io/book/guide-gen.html)），包含几个伴随crate，这些crate包含对较少使用部分的实现。
- en: This is why, in *step 2*, we don't only import a single crate, even though they
    all share a single GitHub repository ([https://github.com/rust-random/rand](https://github.com/rust-random/rand)).
    The reason for this split was presumably to be compatible with the different requirements
    across the field.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是为什么在*步骤2*中，我们不仅仅导入一个crate，尽管它们都共享一个GitHub仓库（[https://github.com/rust-random/rand](https://github.com/rust-random/rand)）。这种分割的原因可能是为了与该领域的不同要求兼容。
- en: RNGs represent—in short—a numeric sequence that is determined on the fly based
    on its predecessor. What is the first number though? It's called the **seed** and
    can be some literal (for reproducibility in tests) or as close to true randomness
    as possible (when not testing).
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，RNGs代表的是一个基于其前驱动态确定的数字序列。那么第一个数字是什么呢？它被称为**种子**，可以是某个字面量（用于测试的可重复性）或者尽可能接近真正的随机性（当不进行测试时）。
- en: Popular seeds include seconds since 1 Jan 1970, entropy by the OS, user input,
    and more. The less predictable it is, the better.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 流行的种子包括自1970年1月1日以来的秒数、操作系统的熵、用户输入等等。它越不可预测，就越好。
- en: In *step 3*, we set up the remaining code with some imports that we are using
    right away in *step 4*. There, we get into using different types of RNGs ([https://rust-random.github.io/book/guide-rngs.html](https://rust-random.github.io/book/guide-rngs.html)).
    The first is `rand` crate's `StdRng`, which is an abstraction over (as of this
    writing) the ChaCha PRNG ([https://docs.rs/rand/0.7.0/rand/rngs/struct.StdRng.html](https://docs.rs/rand/0.7.0/rand/rngs/struct.StdRng.html)),
    chosen for efficiency and cryptographic security. The second algorithm is SmallRng
    ([https://docs.rs/rand/0.7.0/rand/rngs/struct.SmallRng.html](https://docs.rs/rand/0.7.0/rand/rngs/struct.SmallRng.html)),
    a PRNG chosen by the `rand` team that has great throughput and resource efficiency.
    However, since it is fairly easy to predict, the use cases have to be chosen carefully.
    The last algorithm (`Pcg32`) is a pick from the list of available PRNGs ([https://rust-random.github.io/book/guide-rngs.html](https://rust-random.github.io/book/guide-rngs.html)),
    which comes as part of a different crate.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在*步骤3*中，我们使用一些立即在*步骤4*中使用的导入设置剩余的代码。在那里，我们开始使用不同类型的RNGs（[https://rust-random.github.io/book/guide-rngs.html](https://rust-random.github.io/book/guide-rngs.html)）。第一个是`rand`
    crate的`StdRng`，它是对（截至本文写作时）ChaCha PRNG的抽象，出于效率和加密安全性的考虑而选择。第二个算法是SmallRng（[https://docs.rs/rand/0.7.0/rand/rngs/struct.SmallRng.html](https://docs.rs/rand/0.7.0/rand/rngs/struct.SmallRng.html)），这是`rand`团队选择的一个PRNG，具有很高的吞吐量和资源效率。然而，由于它很容易预测，必须仔细选择使用场景。最后一个算法（`Pcg32`）是从可用的PRNG列表中挑选的（[https://rust-random.github.io/book/guide-rngs.html](https://rust-random.github.io/book/guide-rngs.html)），它是作为不同crate的一部分提供的。
- en: In *step* 5, we work with sequences and choose from or shuffle through them.
    Functions include partial shuffling (that is, picking a random subset) and full,
    in-place shuffles, as well as a random choice of one or more elements in a list.
    Note that the traits for these operations are implemented in a way that they are
    agnostic of the actual random number generator used. This provides a very flexible
    and easy-to-use API.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在**步骤**5中，我们处理序列并从中选择或打乱顺序。函数包括部分打乱（即，随机选择一个子集）和原地全打乱，以及从列表中选择一个或多个元素的随机选择。请注意，这些操作的特性是以一种不依赖于实际使用的随机数生成器的方式实现的。这提供了一个非常灵活且易于使用的API。
- en: Only in *step 6* do we get to random numbers that follow distributions. These
    can be very important to do more scientific work such as initializing vectors,
    simulation, or games.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 只有在**步骤6**中，我们才能得到遵循分布的随机数。这些对于进行更多科学工作（如初始化向量、模拟或游戏）可能非常重要。
- en: 'The default of most RNGs is the uniform distribution where each number is equally
    likely. Actually drawing samples from the distribution requires an initialized
    RNG, which is provided in the form of a seeded StdRng. The assert statement (empirically)
    shows that it truly is a uniform distribution: after 10,000 draws, the numbers
    average almost exactly in the range''s middle (+/-2).'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数随机数生成器的默认值是均匀分布，其中每个数字出现的可能性相同。实际上从分布中抽取样本需要一个初始化的随机数生成器，它以种子的形式提供StdRng。断言语句（经验上）显示它确实是一个均匀分布：在进行了10,000次抽取后，数字的平均值几乎正好在范围的中间（+/-2）。
- en: The following distribution is the Bernoulli distribution ([http://mathworld.wolfram.com/BernoulliDistribution.html](http://mathworld.wolfram.com/BernoulliDistribution.html)).
    It can be initialized with a chance of success (0.8, in this case)—but, in general,
    it's easy to imagine as a series of coin flips. In fact, this distribution is
    used for generating Boolean values (which is why we can filter by the generated
    value).
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 以下分布是伯努利分布（[http://mathworld.wolfram.com/BernoulliDistribution.html](http://mathworld.wolfram.com/BernoulliDistribution.html)）。它可以初始化为成功的概率（例如，0.8）——但通常可以想象为一系列的抛硬币。实际上，这个分布用于生成布尔值（这就是为什么我们可以根据生成的值进行过滤）。
- en: Lastly, in this test, we are creating a generator for a normal distribution
    ([http://mathworld.wolfram.com/NormalDistribution.html](http://mathworld.wolfram.com/NormalDistribution.html)).
    This is a well-known form of distributing a random variable around a center point
    (mean) with a defined spread (standard deviation). The closer the values are to
    the center, the more likely their occurrence. In this case, we are initializing
    with a mean of 2.0 and a standard deviation of 0.5, which means that, after a
    significant number of draws, we should end up with exactly that mean and standard
    deviation we provided. `assert_eq!` confirms that for the mean.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在这个测试中，我们正在创建一个正态分布的生成器（[http://mathworld.wolfram.com/NormalDistribution.html](http://mathworld.wolfram.com/NormalDistribution.html)）。这是一种在中心点（均值）周围以定义的扩散（标准差）分布随机变量的已知形式。值越接近中心，其发生的可能性就越大。在这种情况下，我们使用均值为2.0和标准差为0.5进行初始化，这意味着在进行了大量抽取之后，我们应该得到我们提供的确切均值和标准差。`assert_eq!`确认了均值。
- en: '*Step 7* then shows the test output—and it works (at the time of this writing).'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '**步骤7**展示了测试输出——并且它工作（在撰写本文时）。'
- en: The code in the accompanying repository may fail for this recipe if some implementation
    details of the `rand` crate change (for example, a minor version update).
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 如果`rand`包的一些实现细节发生变化（例如，小版本更新），则伴随的存储库中的代码可能会失败。
- en: To read more about the `rand` crate, read more in this book ([https://rust-random.github.io/book/](https://rust-random.github.io/book/)).
    However, if you are interested in how to implement a PRNG and find out more about
    them, check out *Hands-On Data Structures and Algorithms with Rust*, published
    by Packt ([https://www.packtpub.com/application-development/hands-data-structures-and-algorithms-rust](https://www.packtpub.com/application-development/hands-data-structures-and-algorithms-rust)),
    where we go deeper. However, as we have successfully learned to use the `rand`
    crate, we can move on to the next recipe.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多关于`rand`包的信息，请阅读这本书中的更多内容（[https://rust-random.github.io/book/](https://rust-random.github.io/book/)）。然而，如果你对如何实现伪随机数生成器并了解更多相关信息感兴趣，请查看Packt出版的《使用Rust的数据结构和算法实践》（[https://www.packtpub.com/application-development/hands-data-structures-and-algorithms-rust](https://www.packtpub.com/application-development/hands-data-structures-and-algorithms-rust)），在那里我们将深入了解。然而，由于我们已经成功地学会了使用`rand`包，我们可以继续到下一个菜谱。
- en: Writing to and reading from files
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 写入和读取文件
- en: Processing files is a daily task and sometimes—depending on the programming
    language—unreasonably hard. The Rust project teams have taken care of that problem
    and provide an easy-to-use API to access files. Let's dive right in.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 处理文件是日常任务，有时——根据编程语言的不同——可能不合理地困难。Rust 项目团队已经解决了这个问题，并提供了易于使用的 API 来访问文件。让我们直接深入探讨。
- en: Getting ready
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: First, create a new project using `cargo new file-stuff`. Now, to work with
    files, we need a text file to read and process. Lorem Ipsum ([https://www.lipsum.com/](https://www.lipsum.com/)) is
    a popular dummy text that can be generated on a large scale, so to proceed with
    the recipe, generate a few (200) paragraphs with this generator and save the text
    in a file called `lorem.txt` in the root directory.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，使用 `cargo new file-stuff` 创建一个新的项目。现在，为了处理文件，我们需要一个用于读取和处理的文本文件。Lorem Ipsum（[https://www.lipsum.com/](https://www.lipsum.com/））是一种流行的虚拟文本，可以大规模生成，因此为了继续这个配方，使用这个生成器生成几个（200）段落，并将文本保存为根目录下的
    `lorem.txt` 文件。
- en: Finish your preparations by opening the project directory in VS Code.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 通过在 VS Code 中打开项目目录来完成你的准备工作。
- en: How to do it...
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'We can read files from disk in just a few steps:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 我们只需几个步骤就可以从磁盘读取文件：
- en: 'Since the Rust standard library comes with all of the basics we need, let''s
    dive directly into `src/main.rs` to add the imports there:'
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于 Rust 标准库包含了我们需要的所有基础知识，让我们直接进入 `src/main.rs` 并在那里添加导入：
- en: '[PRE6]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'First, let''s take care of reading from files. For that, we create a function
    called `read()` that reads and extracts the contents from the prepared file, `lorem.txt`, underneath
    the imports:'
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，让我们处理从文件中读取。为此，我们创建一个名为 `read()` 的函数，该函数读取并从导入下的准备文件 `lorem.txt` 中提取内容：
- en: '[PRE7]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Writing is going to be the next part we are taking care of. In this case, we
    are creating a dummy file and writing to it in a variety of ways. You can add
    the following to `src/main.rs`:'
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将处理写入。在这种情况下，我们创建一个虚拟文件并以各种方式向其写入。你可以在 `src/main.rs` 中添加以下内容：
- en: '[PRE8]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'In the last step, we should tie the functions together in the `main` function:'
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在最后一步，我们应该在 `main` 函数中将函数组合起来：
- en: '[PRE9]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'With `cargo run`, we can now read from and write to disk to perform various
    tasks. Here, we can observe some general statistics about the `lorem.txt` file
    and the file metadata for where we write to:'
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `cargo run`，我们现在可以从磁盘读取和写入以执行各种任务。在这里，我们可以观察一些关于 `lorem.txt` 文件以及我们写入的文件元数据的一般统计信息：
- en: '[PRE10]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Let's get behind how we were working with files here.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看我们在这里是如何处理文件的。
- en: How it works...
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'After setting up the project, we dive right in with *step 1* and provide the
    imports required to work with the file APIs. Note that working with and reading/writing
    files are in two different modules: `std::fs` for access and `std::io` for read
    and write. In addition to that, the `std::path` module provides powerful and easy
    ways to work with paths in a platform-agnostic way.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在设置好项目后，我们直接进入 *步骤 1* 并提供与文件 API 一起工作的所需导入。请注意，与文件一起工作以及读取/写入文件位于两个不同的模块中：`std::fs`
    用于访问，`std::io` 用于读取和写入。此外，`std::path` 模块提供了以平台无关的方式处理路径的强大且简单的方法。
- en: '*Step 2* provides a function that shows several ways to read data from the
    test file we created in preparation. First, we open the file and pass the reference
    to `BufReader` ([https://doc.rust-lang.org/std/io/struct.BufReader.html](https://doc.rust-lang.org/std/io/struct.BufReader.html)),
    a buffered reader. While the initial reference allows reading data as well, `BufReader`
    reads the file contents in bulk and serves them from memory. This reduces disk
    access while improving performance considerably (compared to byte-to-byte reading).
    Additionally, this allows iterating over lines using the `lines()` function.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '*步骤 2* 提供了一个函数，展示了从我们在准备中创建的测试文件中读取数据的好几种方式。首先，我们打开文件并将 `BufReader`（[https://doc.rust-lang.org/std/io/struct.BufReader.html](https://doc.rust-lang.org/std/io/struct.BufReader.html)）的引用传递给它，这是一个缓冲读取器。虽然初始引用也允许读取数据，但
    `BufReader` 以批量方式读取文件内容并从内存中提供它们。这减少了磁盘访问次数，同时显著提高了性能（与逐字节读取相比）。此外，这还允许使用 `lines()`
    函数迭代行。'
- en: With that, we can iterate over each line, splitting it on whitespace and counting
    the resulting iterator (`.split_ascii_whitespace().count()`). Summing these numbers
    up and dividing them by the number of lines found, we can determine the average
    number of words per line. This shows how everything boils down to iterators in
    Rust and allows powerful things to be created within just a couple of lines of
    code.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这种方式，我们可以遍历每一行，在空白处分割它，并计算结果迭代器（`.split_ascii_whitespace().count()`）。将这些数字相加，然后除以找到的行数，我们可以确定每行的平均单词数。这展示了在Rust中一切都可以归结为迭代器，并且只需几行代码就能创建出强大的功能。
- en: Instead of reading in an iterator, the Rust standard library supports reading
    into one large string directly as well. For this common task, `fs::read_to_string()`
    provides a convenient shortcut. However, if you want to retain the file pointer
    for later use, the `File` struct provides a `read_to_string()` function as well.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 除了读取迭代器，Rust标准库还支持直接读取到一个大字符串中。对于这个常见任务，`fs::read_to_string()`提供了一个方便的快捷方式。然而，如果你想保留文件指针以供以后使用，`File`结构体也提供了一个`read_to_string()`函数。
- en: Since the file pointer is set to where it stopped reading in the file (which
    is the end, in this case), we have to reset the file pointer using the `seek()`
    function before further use. For example, if we want to read bytes instead of
    characters, the API provides an iterator for that as well (but there are better
    ways to get the file size in bytes).
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 由于文件指针被设置为停止读取文件的位置（在这种情况下是末尾），在进一步使用之前，我们必须使用`seek()`函数重置文件指针。例如，如果我们想读取字节而不是字符，API也提供了一个迭代器来处理这种情况（但还有更好的方法来获取文件大小）。
- en: '*Step 3* goes deeper into writing files. We start off by creating a `Path`
    instance (which cannot be changed), so we translate it to a mutable `PathBuf` instance
    and add a filename. By calling `File::create()`, we create (overwrite) and obtain
    a file pointer quickly. The `metadata()` function provides some meta-information
    about the file (formatted for readability):'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '*步骤3*深入探讨了写入文件。我们首先创建一个`Path`实例（它不能被更改），因此我们将其转换为可变的`PathBuf`实例并添加一个文件名。通过调用`File::create()`，我们快速创建（覆盖）并获取文件指针。`metadata()`函数提供了关于文件的一些元信息（格式化以提高可读性）：'
- en: '[PRE11]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Writing to a file is the same as writing to the console (for example, using
    the `write!()` macro) and can include any data, as long as it can be serialized
    to bytes. The `b"Hello"` byte literal works just as well as an `&str` slice. Akin
    to buffered reading, buffered writing also offers improved performance by only
    writing large blocks at once.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 向文件写入与向控制台写入相同（例如，使用`write!()`宏），可以包含任何数据，只要它可以序列化为字节。`b"Hello"`字节字面量与`&str`切片一样有效。类似于缓冲读取，缓冲写入也通过一次只写入大块数据来提高性能。
- en: '*Steps 4* and *5* tie everything together in the `main` function and by running
    to see the result.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '*步骤4*和*步骤5*在`main`函数中将一切联系在一起，并通过运行来查看结果。'
- en: 'Nothing is surprising when working with files: the API is expectedly straightforward
    and profits from its integration in common iterators and by using standardized
    traits. We can happily move on to the next recipe.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理文件时，没有什么令人惊讶的：API预期是直观的，并得益于其在常见迭代器和标准化特质中的集成。我们可以愉快地继续到下一个菜谱。
- en: Parsing unstructured formats like JSON
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 解析无结构格式如JSON
- en: Before we start, let's define what we are talking about when we say structured
    and unstructured data. The former, structured data, follows a schema of some sorts—like
    a table schema in an SQL database. Unstructured data, on the other hand, is unpredictable
    in what it will contain. In the most extreme example, a body of prose text is
    the least structured thing we could probably come up with—each sentence may follow
    different rules depending on its content.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始之前，让我们定义当我们说结构化和无结构数据时我们指的是什么。前者，结构化数据，遵循某种模式——比如SQL数据库中的表模式。另一方面，无结构数据在它将包含的内容方面是不可预测的。在最极端的例子中，一篇文章的文本体可能是我们可能想到的最无结构的东西——每个句子可能根据其内容遵循不同的规则。
- en: JSON is a bit more readable, but unstructured, nevertheless. An object can have
    properties of various data types and no two objects have to be the same. In this
    chapter, we are going to explore some of the ways JSON (and other formats) can
    be handled when it doesn't follow a schema that we can declare in a struct.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: JSON的可读性略好，但仍然是无结构的。一个对象可以具有各种数据类型的属性，并且两个对象不必相同。在本章中，我们将探讨一些处理JSON（以及其他格式）的方法，当它不遵循我们可以在结构体中声明的模式时。
- en: Getting ready
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: This project requires Python to run a small script. For the Python part of the
    project, install Python (3.6 or 3.7 from [https://www.python.org/](https://www.python.org/)),
    following the instructions on the website. The `python3` command should be available
    in a Terminal/PowerShell.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 此项目需要Python来运行一个小脚本。对于项目的Python部分，按照网站上的说明安装 Python（3.6 或 3.7，见[https://www.python.org/](https://www.python.org/)）。`python3`
    命令应在终端/PowerShell 中可用。
- en: Once available, create a new project using `cargo new dynamic-data --lib`. Use
    VS Code to open the project directory.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦可用，使用 `cargo new dynamic-data --lib` 创建一个新的项目。使用 VS Code 打开项目目录。
- en: How to do it...
  id: totrans-83
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到这一点...
- en: 'Parsing is a multi-step process (but it''s easy to do):'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 解析是一个多步骤的过程（但很容易做）：
- en: 'First, let''s add `serde` and its sub-crates to `Cargo.toml`. Open the file
    and add the following:'
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，让我们将 `serde` 及其子crate添加到 `Cargo.toml` 文件中。打开文件并添加以下内容：
- en: '[PRE12]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Now, let''s use the crates and see what they can do. We do this by creating
    tests that parse the same data from various formats, starting with JSON. In `src/lib.rs`,
    we replace the default tests module with the following:'
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们使用这些crate并看看它们能做什么。我们通过创建测试来做到这一点，这些测试从各种格式解析相同的数据，从 JSON 开始。在 `src/lib.rs`
    中，我们用以下内容替换默认的测试模块：
- en: '[PRE13]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'TOML is a text-based format rivaling JSON and YAML for configuration files.
    Let''s create the same test as preceding, but with TOML instead of JSON, and add
    the following code to the `tests` module:'
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: TOML 是一种基于文本的格式，与 JSON 和 YAML 竞争配置文件。让我们创建与之前相同的测试，但使用 TOML 而不是 JSON，并将以下代码添加到
    `tests` 模块中：
- en: '[PRE14]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Since the last two were text-based formats, let''s look at a binary format
    as well. Python''s pickle format is often used to serialize data as well as machine
    learning models. However, before we can use Rust to read it, let''s create the
    file in a small Python script called `create_pickle.py` in the project''s root
    directory:'
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于最后两个是基于文本的格式，让我们看看一个二进制格式。Python 的 pickle 格式常用于序列化数据以及机器学习模型。然而，在我们能够使用 Rust
    读取它之前，让我们在项目根目录中创建一个名为 `create_pickle.py` 的小 Python 脚本来创建文件：
- en: '[PRE15]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Run `python3 create_pickle.py` to create a `user.pkl` file in the project's
    root directory (the script should exit silently).
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行 `python3 create_pickle.py` 在项目的根目录中创建一个 `user.pkl` 文件（脚本应该静默退出）。
- en: 'Add the last test to the `tests` module in `src/lib.rs,` which parses and compares
    the contents of the pickle file with what''s expected:'
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将最后一个测试添加到 `src/lib.rs` 中的 `tests` 模块，该测试解析并比较pickle文件的内容与预期内容：
- en: '[PRE16]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Lastly, we want to see the tests run (successfully). Let''s execute `cargo
    test` to see the test results and how we were able to read binary and text data
    of various origins:'
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们想看到测试运行的结果（成功）。让我们执行 `cargo test` 来查看测试结果以及我们如何能够读取来自各种来源的二进制和文本数据：
- en: '[PRE17]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Let's see how that works.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看它是如何工作的。
- en: How it works...
  id: totrans-99
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: Statically typed languages like Rust make programming a lot more comfortable
    once types are established. However, in a world with ever-changing web service
    APIs, a simple additional property can lead to a parser error, making it impossible
    to continue. Therefore, `serde` does not only support fully automated parsing
    but also dynamically extracting data from its `Value` type, complete with type
    parsing.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 静态类型语言如Rust，一旦确定了类型，编程就会变得非常舒适。然而，在一个不断变化的网络服务API的世界里，一个简单的附加属性可能导致解析错误，使得无法继续。因此，`serde`不仅支持完全自动化的解析，还能从其`Value`类型动态提取数据，包括类型解析。
- en: In *step 1*, we add the various dependencies, all of which comply with the `serde`
    interfaces (which are located in the `serde` crate)—although they come from different
    sources. Using them is demonstrated in *step 2* and later.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在 *步骤 1* 中，我们添加了各种依赖项，所有这些依赖项都符合 `serde` 接口（位于 `serde` crate 中）——尽管它们来自不同的来源。它们的使用在
    *步骤 2* 和之后进行了演示。
- en: We begin with creating a raw string that contains a JSON string for `serde_json`
    to parse. Once the `Value` variable is created, we can use the `json!` macro to
    create an equivalent object to compare. After that, we call the `Value` API to
    retrieve individual properties and check for their type and content. `Value` is
    an enum ([https://docs.serde.rs/serde_json/value/enum.Value.html](https://docs.serde.rs/serde_json/value/enum.Value.html))
    that implements a range of automated conversions and retrieval functions, which
    enable these seamless `assert_eq!` statements. In case a property or list index
    doesn't exist, the `Null` variant of `Value` is returned.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从创建一个包含`serde_json`要解析的JSON字符串的原始字符串开始。一旦创建了`Value`变量，我们就可以使用`json!`宏创建一个等效对象以进行比较。之后，我们调用`Value`
    API来检索单个属性并检查它们的类型和内容。`Value`是一个枚举（[https://docs.serde.rs/serde_json/value/enum.Value.html](https://docs.serde.rs/serde_json/value/enum.Value.html)），它实现了一系列自动转换和检索函数，这些函数使得这些无缝的`assert_eq!`语句成为可能。如果属性或列表索引不存在，则返回`Value`的`Null`变体。
- en: '*Step 3* parses the TOML ([https://github.com/toml-lang/toml](https://github.com/toml-lang/toml))
    format and compares it to the JSON output—thanks to the unified `Value` enum,
    it''s very similar to *step 2*. The main difference is that the user property
    is a list in TOML to demonstrate the other list syntax (`[[this-way-to-declare-a-list-item]]`).'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '*第3步* 解析TOML格式（[https://github.com/toml-lang/toml](https://github.com/toml-lang/toml)）并将其与JSON输出进行比较——多亏了统一的`Value`枚举，它与*第2步*非常相似。主要区别在于，TOML中的用户属性是一个列表，以展示其他列表语法（`[[this-way-to-declare-a-list-item]]`）。'
- en: In *steps 4* and *5,* we prepare a Python pickle file containing a dictionary
    object—parsed from the same JSON object as in *step 2*. Pickle is a binary format,
    which means we tell Python's file API to write raw bytes instead of encoded text.
    In contrast, when we read the file, Rust reads bytes by default and requires the
    programmer to provide the interpretation (codec) if they care to. The `File` API
    ([https://doc.rust-lang.org/std/fs/struct.File.html](https://doc.rust-lang.org/std/fs/struct.File.html))
    automatically returns an (unbuffered) `Read` object to fetch the contents, which
    we can directly pass into the appropriate pickle function. The remaining portion
    of the code verifies whether the contents read from the pickle file are the same
    as for the other objects.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在*步骤4*和*步骤5*中，我们准备了一个包含字典对象的Python pickle文件——从与*步骤2*相同的JSON对象解析而来。Pickle是一种二进制格式，这意味着我们告诉Python的文件API写入原始字节而不是编码文本。相比之下，当我们读取文件时，Rust默认读取字节，并要求程序员提供解释（codec）如果他们关心的话。`File`
    API（[https://doc.rust-lang.org/std/fs/struct.File.html](https://doc.rust-lang.org/std/fs/struct.File.html)）自动返回一个（未缓冲的）`Read`对象以获取内容，我们可以直接将其传递到适当的pickle函数。代码的其余部分验证从pickle文件中读取的内容是否与其他对象相同。
- en: We showed reading three types here, but `serde` supports many more. Check out
    their documentation to learn more, but now let's move on to the next recipe.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这里展示了读取三种类型，但`serde`支持更多。查看他们的文档以了解更多信息，但现在让我们继续下一个食谱。
- en: Extract text using regular expressions
  id: totrans-106
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用正则表达式提取文本
- en: 'Regular expressions have been a part of programming for a long time and, in
    the context of Rust, found popularity in the form of `ripgrep` ([https://github.com/BurntSushi/ripgrep](https://github.com/BurntSushi/ripgrep)).
    `ripgrep` is a grep variation that searches files for a particular regular expression—and
    it has been adopted as a major part of VS Code, where it powers the search engine.
    The reason for this is simple: speed ([https://github.com/BurntSushi/ripgrep#quick-examples-comparing-tools](https://github.com/BurntSushi/ripgrep#quick-examples-comparing-tools)).'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 正则表达式长期以来一直是编程的一部分，在Rust的上下文中，它以`ripgrep`（[https://github.com/BurntSushi/ripgrep](https://github.com/BurntSushi/ripgrep)）的形式获得了流行。`ripgrep`是grep的一个变体，用于搜索特定正则表达式的文件——它已被作为VS
    Code的主要部分采用，其中它为搜索引擎提供动力。原因很简单：速度（[https://github.com/BurntSushi/ripgrep#quick-examples-comparing-tools](https://github.com/BurntSushi/ripgrep#quick-examples-comparing-tools)）。
- en: Rust's regular expression library has been re-implemented, which may be why
    it outperforms earlier implementations (and because Rust is fast). Let's see how
    we can leverage regular expressions in our Rust projects.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: Rust的正则表达式库已被重新实现，这可能是它优于早期实现的原因（以及因为Rust运行速度快）。让我们看看我们如何在Rust项目中利用正则表达式。
- en: How to do it...
  id: totrans-109
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到这一点...
- en: 'Let''s follow a few steps to explore regular expressions in Rust:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们遵循几个步骤来探索Rust中的正则表达式：
- en: Open a Terminal to create a new project using `cargo new regex --lib `. Use
    VS Code to open the project directory.
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开终端，使用`cargo new regex --lib`创建一个新的项目。使用VS Code打开项目目录。
- en: First, we are going to add the regex crate to our dependencies in `Cargo.toml:`
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们将向`Cargo.toml`中的依赖项添加regex crate：
- en: '[PRE18]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Next, let''s open `src/lib.rs` to create some tests that we can run. To start,
    we create a tests module, replacing any existing code:'
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，让我们打开`src/lib.rs`来创建一些我们可以运行的测试。首先，我们创建一个测试模块，替换任何现有的代码：
- en: '[PRE19]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Regular expressions are typically used to parse data or validate that the data
    conforms to the expression''s rules. Let''s add a test inside the tests module
    for some simple parsing:'
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 正则表达式通常用于解析数据或验证数据是否符合表达式的规则。让我们在测试模块中添加一个测试来执行一些简单的解析：
- en: '[PRE20]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'However, regular expressions can do much more with their pattern matching.
    Another task could be to replace data:'
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然而，正则表达式可以通过它们的模式匹配做更多的事情。另一个任务可能是替换数据：
- en: '[PRE21]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'As a last test, we can have some more fun analyzing data using regular expressions,
    for example, counting the prefixes on telephone numbers:'
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 作为最后的测试，我们可以通过使用正则表达式分析数据来玩得更有趣，例如，统计电话号码的前缀：
- en: '[PRE22]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Now, let''s run the tests using `cargo test` and we can see that the regular
    expressions perform well:'
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们使用`cargo test`运行测试，我们可以看到正则表达式表现良好：
- en: '[PRE23]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Now that we know how to use regular expressions, let's find out how they work.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经知道了如何使用正则表达式，让我们来看看它们是如何工作的。
- en: How it works...
  id: totrans-125
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: After the initial setup in *steps 1* and *2*, we start by creating a tests module
    in *step 3* along with the required dependencies. *Step 4* then contains the first
    test that shows how the regex crate ([https://docs.rs/regex/1.2.1/regex/](https://docs.rs/regex/1.2.1/regex/))
    handles simple parsing of data.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 在步骤1和步骤2的初始设置之后，我们首先在步骤3中创建一个测试模块，以及所需的依赖项。然后，步骤4包含第一个测试，展示了regex crate ([https://docs.rs/regex/1.2.1/regex/](https://docs.rs/regex/1.2.1/regex/))如何处理数据的简单解析。
- en: By using the raw string literal syntax, `r"I am a raw string"`, we compile a
    new `Regex` instance that we match to date strings. The included character classes
    are what is commonly used across OSes and languages, which includes support for
    whitespaces as well as (alpha) numerical characters and raw bytes. Additionally,
    flags can be placed directly in the expression using a `(?flag)` notation.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用原始字符串字面量语法，`r"I am a raw string"`，我们编译一个新的`Regex`实例，并将其与日期字符串进行匹配。包含的字符类是跨操作系统和语言普遍使用的，包括对空白字符以及（字母）数字字符和原始字节的支撑。此外，可以使用`(?flag)`标记直接在表达式中放置标志。
- en: The regular expression in* step 4* is composed of three parts: `(?P<y>\d{4})-(?P<m>\d{2})-(?P<d>\d{2})`.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 第4步中的正则表达式由三个部分组成：`(?P<y>\d{4})-(?P<m>\d{2})-(?P<d>\d{2})`。
- en: The first part is named `y` (`?P<name>` declares a name) and looks for exactly
    four (`{4}`) digits `\d` that it can match. Parts two and three look for two digits
    each and are named `m` and `d` respectively. This naming is going to be important
    later on when we want to retrieve the matches. In between those patterns, we see
    a `-`, which means that the final pattern has to look like `yyyy-mm-dd` (or `1234-12-12` to
    be precise) to match.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 第一部分命名为`y`（`?P<name>`声明了一个名称）并寻找恰好四个（`{4}`）数字`\d`，它可以匹配。第二部分和第三部分各寻找两个数字，分别命名为`m`和`d`。这种命名在稍后当我们想要检索匹配时将变得很重要。在这些模式之间，我们看到一个`-`，这意味着最终的模式必须看起来像`yyyy-mm-dd`（或者更精确地说，像`1234-12-12`）才能匹配。
- en: Going down the test, this is what we do. By preparing a few positive examples,
    we can validate a date (`1999-12-01`), as well as extract the individual parts
    by name (`2019-02-27`). If a string has multiple matches, we can also iterate
    over these captures to remain efficient. In the case of the test, we also check
    whether the extracted content matches the expected values while iterating.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 在测试中向下进行，这是我们要做的事情。通过准备一些正面的例子，我们可以验证一个日期（`1999-12-01`），以及通过名称提取各个部分（`2019-02-27`）。如果字符串有多个匹配，我们也可以遍历这些捕获以保持效率。在测试的情况下，我们还检查在遍历时提取的内容是否与预期值匹配。
- en: Compiling a regular expression takes a fair amount of time, especially when
    the expression is very large. Consequently, pre-compile and reuse as much as possible
    and avoid compiling in loops!
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 编译正则表达式需要相当多的时间，尤其是当表达式非常大时。因此，尽可能预先编译并重用，避免在循环中编译！
- en: '*Step 5* creates a similar regular expression and replicates the `fun_dates`
    variable from the *step 4* test. However, instead of just extracting the content,
    we want to replace the pattern, which—in this case—transforms the ISO `-` notation
    into a European-style `.` notation. Since we named the groups in the regex, we
    can now also refer to those names in the replacement string.'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '*步骤5*创建了一个类似的正则表达式，并复制了*步骤4*测试中的`fun_dates`变量。然而，我们不仅想要提取内容，还想要替换模式，在这种情况下，将ISO
    `-`表示法转换为欧洲风格的`.`表示法。由于我们在正则表达式中命名了组，我们现在也可以在替换字符串中引用这些名称。'
- en: In *step 6*, we return to matching, but instead of simply validating, we extract
    and work with the extracted data to create information. Assuming that a task is
    to count country codes in phone numbers, we can apply the regular expression and
    use `HashMap` for keeping track of each number's occurrence. The regular expression
    matches anything starting with `+`, followed by one to four digits: `(\+[\d]{1,4})`.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 在*步骤6*中，我们返回到匹配，但不是简单地验证，而是提取并处理提取的数据以创建信息。假设任务是要统计电话号码中的国家代码，我们可以应用正则表达式并使用`HashMap`来跟踪每个数字的出现次数。正则表达式匹配以`+`开头，后跟一到四个数字：`(\+[\d]{1,4})`。
- en: Using Rust's iterator powers, we extract the match and filter out any non-matches
    before folding the results into common `HashMap`. `RefCell` helps with managing
    mutability and, since the fold function has to return the accumulated result,
    we have to scope off the mutable borrowing to ensure memory safety (the compiler
    will tell you). Once we extract the inner value of the cell, we can see what the
    numbers were.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Rust的迭代器功能，我们提取匹配项并过滤掉任何非匹配项，然后将结果折叠到常见的`HashMap`中。`RefCell`帮助我们管理可变性，由于折叠函数必须返回累积的结果，我们必须将可变借用范围缩小以确保内存安全（编译器会告诉你）。一旦我们提取了单元格的内部值，我们就可以看到数字是什么。
- en: This only touches on a few common subjects inside the realm of possible tasks
    with regular expressions. We highly recommend reading the documentation to find
    out more!
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 这只是触及了正则表达式领域中可能任务的一些常见主题。我们强烈建议阅读文档以了解更多信息！
- en: However, now that we have had a taste of some regular expressions, we can move
    on to the next recipe.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，现在我们已经尝试了一些正则表达式，我们可以继续到下一道菜谱。
- en: Recursively searching the filesystem
  id: totrans-137
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 递归搜索文件系统
- en: ripgrep—as we mentioned in the previous recipe (*Extracting text using regular
    expressions*)—is a popular grep engine that walks through files to find anything
    that matches the provided regular expression rules. For that, it's not only necessary
    to compile and match a regular expression to massive amounts of text, but also
    to find these texts. To get to and open these files, we need to walk the directory
    trees of the filesystem. Let's find out how to do that in Rust.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: ripgrep——正如我们在上一道菜谱（*使用正则表达式提取文本*）中提到的——是一个流行的grep引擎，它遍历文件以查找与提供的正则表达式规则匹配的任何内容。为此，不仅需要编译和匹配大量文本中的正则表达式，还需要找到这些文本。为了到达并打开这些文件，我们需要遍历文件系统的目录树。让我们来看看如何在Rust中实现这一点。
- en: How to do it...
  id: totrans-139
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到这一点...
- en: 'We can understand recursive search by following a few steps:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过以下步骤来理解递归搜索：
- en: Open a Terminal to create a new project using `cargo new filesystem`. Use VS
    Code to open the project directory.
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开一个终端，使用`cargo new filesystem`创建一个新的项目。使用VS Code打开项目目录。
- en: 'Edit `Cargo.toml` to add a dependency to a crate called `glob` for walking
    the filesystem:'
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编辑`Cargo.toml`以添加一个名为`glob`的crate依赖项，用于遍历文件系统：
- en: '[PRE24]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'In `src/main.rs`, we can then start implementing functions to walk the filesystem
    tree, but first, let''s set up the imports and a type alias for boxed errors:'
  id: totrans-144
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`src/main.rs`中，我们可以开始实现遍历文件系统树的函数，但首先，让我们设置导入和一个类型别名以处理boxed错误：
- en: '[PRE25]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Next, we are going to add a recursive `walk` function that is only using the
    Rust standard library. Add the following:'
  id: totrans-146
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将添加一个仅使用Rust标准库的递归`walk`函数。添加以下内容：
- en: '[PRE26]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '`glob` is also the name of a style of wildcards for filesystems (for example, `*.txt`
    or `Cargo*`), working on both Windows and Linux/Unix. In some implementations,
    globs can be recursive as well, which is why we can use the crate of the same
    name to implement another `walk` function:'
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`glob`也是文件系统通配符样式的一种（例如，`*.txt`或`Cargo*`），在Windows和Linux/Unix上都能使用。在某些实现中，glob也可以是递归的，这就是为什么我们可以使用同名crate来实现另一个`walk`函数：'
- en: '[PRE27]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'What''s missing now is the `main` function to tie it all together and call
    the functions accordingly. Add the following:'
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在缺少的是`main`函数，用于将所有这些内容串联起来并相应地调用函数。添加以下内容：
- en: '[PRE28]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'As usual, we want to see it running—use `cargo run` to recursively list files
    from your filesystem using the filters we defined in *step 6*. We also encourage
    you to change the paths to something that fits your system:'
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如同往常，我们希望看到它运行——使用`cargo run`递归地列出文件系统中的文件，使用我们在*第6步*中定义的过滤器。我们还鼓励你将路径更改为适合你系统的路径：
- en: '[PRE29]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Let's get into the inner workings of walking through the filesystem with a filter.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们深入了解使用过滤器遍历文件系统的内部机制。
- en: How it works...
  id: totrans-155
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: Walking a filesystem tree is not a particularly complicated task. However, just
    like any other tree walks, it is much easier to be done recursively, even though
    there is always a risk of running into stack overflow problems if the directory
    nesting is too deep. While an iterative approach is possible, it is much longer
    and more complicated to implement.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 遍历文件系统树并不是一个特别复杂的工作。然而，就像任何其他树遍历一样，递归地执行它要容易得多，尽管如果目录嵌套太深，总会有遇到栈溢出问题的风险。虽然迭代方法也是可能的，但实现起来要长得多，也更复杂。
- en: In this recipe, we start off with setting everything up in *step 1*, adding
    the `glob` crate ([https://docs.rs/glob/0.3.0/glob/](https://docs.rs/glob/0.3.0/glob/))
    as a dependency in *step 2*, and finally importing the required modules in *step
    3*. In *step 4**,* we write the first `walk` function, a recursive in-order walk.
    This means that we recursively descend as far as possible into the first (by some
    order) directory before we start executing the provided callback on that path—we
    are therefore processing the nodes in the order they came up.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们从*第1步*开始设置一切，在*第2步*中添加`glob` crate ([https://docs.rs/glob/0.3.0/glob/](https://docs.rs/glob/0.3.0/glob/))作为依赖项，并在*第3步*中最终导入所需的模块。在*第4步*中，我们编写了第一个`walk`函数，一个递归顺序遍历。这意味着我们在开始在该路径上执行提供的回调之前，尽可能递归地深入到第一个（按某种顺序）目录——因此我们是以节点出现的顺序处理节点的。
- en: Rust's `DirEntry` struct is powerful in that it allows access to its contents
    via a property (instead of calling a different function). The `io::Result<()>`
    return type also allows for using the `?` operator and would end early in cases
    of errors.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: Rust的`DirEntry`结构体非常强大，因为它允许通过属性访问其内容（而不是调用不同的函数）。`io::Result<()>`返回类型还允许使用`?`操作符，并在出现错误时提前结束。
- en: '*Step 5* offers a similar function using the `glob` iterator. Since the input
    is a pattern (both recursive and non-recursive), this pattern is parsed and—if
    it''s valid—returns an iterator over matching file and folder paths. We can then
    call the callback with these entries.'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: '*第5步*提供了一个类似的函数，使用`glob`迭代器。由于输入是一个模式（递归和非递归），这个模式会被解析，如果有效，则返回一个匹配的文件和文件夹路径的迭代器。然后我们可以使用这些条目调用回调函数。'
- en: In *step 6*, we call the functions using a range of paths. The first descends
    into the `src` directory, listing all of the files there using the recursive approach.
    The second pattern first goes up into the project directory's parent and then
    recursively matches all of the `*.rs` files it finds there (and below). In the
    case of this book's chapter, you should see all of the code files we have written
    (and will write).
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 在*第6步*中，我们使用一系列路径调用函数。第一个路径深入到`src`目录，使用递归方法列出该目录下的所有文件。第二个模式首先进入项目目录的父目录，然后递归地匹配它找到的所有`*.rs`文件（及其子目录）。在本章的例子中，你应该能看到我们编写（以及将要编写）的所有代码文件。
- en: Lastly, the filter can also be something simple and match the two `Cargo.*`
    files, as shown in the last call of `walk_glob()`.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，过滤器也可以是简单的东西，匹配最后的`walk_glob()`调用中的两个`Cargo.*`文件。
- en: Now that we know how to go through the filesystem, let's move on to another
    recipe.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们知道了如何遍历文件系统，让我们继续到另一个菜谱。
- en: Custom command-line arguments
  id: totrans-163
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自定义命令行参数
- en: Working with command-line arguments is a great way to configure a program to
    run specific tasks, use a particular set of input data, or simply to output more
    information. However, looking at the help text output of a Linux program these
    days, it offers an impressive amount of information on all of the flags and arguments
    it can work with. In addition to that, the text is printed in a somewhat standardized
    format, which is why this is usually done with strong library support.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 使用命令行参数是配置程序以运行特定任务、使用特定输入数据集或简单地输出更多信息的好方法。然而，现在查看Linux程序的帮助文本输出，它提供了关于它可以处理的全部标志和参数的令人印象深刻的信息。除此之外，文本以某种标准化的格式打印出来，这也是为什么这通常需要强大的库支持。
- en: Rust's most popular crate for working with command-line arguments is called
    `clap` ([https://clap.rs/](https://clap.rs/)), and, in this recipe, we are looking
    at how we can leverage its strengths to create a useful command-line interface.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: Rust中用于处理命令行参数最受欢迎的crate叫做`clap`([https://clap.rs/](https://clap.rs/))，在这个菜谱中，我们正在查看如何利用其优势来创建一个有用的命令行界面。
- en: How to do it...
  id: totrans-166
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到这一点...
- en: 'A simple program that uses command-line arguments to print directories/files only
    requires a few steps:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 一个使用命令行参数打印目录/文件的简单程序只需要几个步骤：
- en: Open a Terminal to create a new project using `cargo new command-line-args `.
    Use VS Code to open the project directory.
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开一个终端，使用`cargo new command-line-args`创建一个新的项目。使用VS Code打开项目目录。
- en: 'First, let''s adapt `Cargo.toml` to download `clap` and to have a better binary
    output name:'
  id: totrans-169
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，让我们将`Cargo.toml`适配以下载`clap`并有一个更好的二进制输出名称：
- en: '[PRE30]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'In `src/main.rs`, we are going to start with imports:'
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`src/main.rs`中，我们将从导入开始：
- en: '[PRE31]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Then, we define a `walk` function that recursively walks through the filesystem
    to execute a callback on each entry. The function supports excluding certain paths,
    which we implement using its own type:'
  id: totrans-173
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们定义一个`walk`函数，该函数递归地遍历文件系统，并在每个条目上执行回调。该函数支持排除某些路径，我们使用其自身类型来实现：
- en: '[PRE32]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'With that available, we can define the `walk` function:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这个，我们可以定义`walk`函数：
- en: '[PRE33]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Next, a few helper functions make our life easier for printing:'
  id: totrans-177
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，几个辅助函数使我们的打印工作变得更简单：
- en: '[PRE34]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'In the `main` function, we are using the `clap` API for the first time. Here,
    we are creating the argument/subcommand structure of the application:'
  id: totrans-179
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`main`函数中，我们第一次使用`clap` API。在这里，我们正在创建应用程序的参数/子命令结构：
- en: '[PRE35]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'After the arguments, we add subcommands in the same way—following the builder
    pattern:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 在参数之后，我们以相同的方式添加子命令——遵循构建器模式：
- en: '[PRE36]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Once we retrieve the matches, we have to get the actual values that have been
    passed into the program:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们检索到匹配项，我们必须获取传递给程序的实际值：
- en: '[PRE37]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'However, with subcommands, we can match on their specific flags and other arguments
    too, which is best extracted with Rust''s pattern matching:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，使用子命令，我们还可以匹配它们的特定标志和其他参数，这最好使用Rust的模式匹配来提取：
- en: '[PRE38]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Let''s see what that did. Run `cargo run` to see the initial output:'
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们看看这做了什么。运行`cargo run`来查看初始输出：
- en: '[PRE39]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Nothing! Indeed, we did not specify any required commands or parameters. Let''s
    run `cargo run -- help` (since we named the program list, calling the compiled
    executable directly would be `list help`) to see the help text showing us which
    options we could try:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 没有东西！确实，我们没有指定任何必需的命令或参数。让我们运行`cargo run -- help`（因为我们命名了程序为list，直接调用编译后的可执行文件将是`list
    help`）来查看显示我们可以尝试的选项的帮助文本：
- en: '[PRE40]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'We should look at the `dirs` subcommand first, so let''s run `cargo run --
    dirs` to see whether it recognizes the required `PATH` argument:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该首先查看`dirs`子命令，所以让我们运行`cargo run -- dirs`来查看它是否识别所需的`PATH`参数：
- en: '[PRE41]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Let''s also try a fully parameterized run where we list all subfolders of the
    project directory excluding anything called `src` (and their subdirectories):'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们也尝试一个完全参数化的运行，其中我们列出项目目录下的所有子文件夹，排除所有名为`src`的文件夹（及其子文件夹）：
- en: '[PRE42]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Try it yourself: several combinations show the power of `clap`. Let''s see
    how it works.'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 试试看：几个组合展示了`clap`的强大功能。让我们看看它是如何工作的。
- en: How it works...
  id: totrans-196
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: '`clap` ([https://clap.rs/](https://clap.rs/)) prides itself on being a simple-to-use
    crate for working with command-line arguments in Rust—and they are right. In the
    initial two steps, we set up the application config and dependencies. We also
    renamed the binary since `list` is a more to-the-point name than `command-line-args`.'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: '`clap`([https://clap.rs/](https://clap.rs/))自豪于是一个简单易用的crate，用于在Rust中处理命令行参数——他们是对的。在最初的两个步骤中，我们设置了应用程序配置和依赖项。我们还重命名了二进制文件，因为`list`比`command-line-args`更直接。'
- en: In *step 3*, we start by importing the necessary structs ([https://docs.rs/clap/2.33.0/clap/struct.App.html](https://docs.rs/clap/2.33.0/clap/struct.App.html))—`App`[,](https://docs.rs/clap/2.33.0/clap/struct.App.html)
    `Arg`[,](https://docs.rs/clap/2.33.0/clap/struct.App.html) `SubCommand` for `clap`,
    and, in *step 4,* we are creating the function that we are going to parameterize
    using command line arguments. The function itself is a simple directory tree walk
    with the ability to execute a callback on each entry and a way to exclude certain
    paths as an exclusion.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 在*步骤 3*中，我们首先导入必要的结构体（[https://docs.rs/clap/2.33.0/clap/struct.App.html](https://docs.rs/clap/2.33.0/clap/struct.App.html)——`App`[，](https://docs.rs/clap/2.33.0/clap/struct.App.html)
    `Arg`[，](https://docs.rs/clap/2.33.0/clap/struct.App.html) `SubCommand`对于`clap`），然后在*步骤
    4*中，我们正在创建一个函数，我们将使用命令行参数来参数化这个函数。该函数本身是一个简单的目录树遍历，能够在每个条目上执行回调，并有一种排除某些路径的方法。
- en: This is similar to what we did in the *Recursively searching the filesystem*
    recipe earlier in this chapter.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 这与我们在本章前面“递归搜索文件系统”菜谱中所做的是类似的。
- en: Some additional helper callbacks for printing directories and files only are
    defined in *step 5*. Closures could have worked as well but wouldn't achieve the
    same readability.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 在*步骤 5*中定义了一些额外的辅助回调，用于仅打印目录和文件。闭包也可以工作，但不会达到相同的可读性。
- en: '*Step 6* is where we work with the `clap` API. This particular case is using
    the Rust API only; however, `clap` supports using external files for configuring
    the parameters as well. Read more at [https://docs.rs/clap/2.33.0/clap/index.html](https://docs.rs/clap/2.33.0/clap/index.html).
    Regardless of how you are going to define the parameters, the structure is very
    similar: the `App` struct has several meta-parameters for informing the user about
    the author, version, and others as well as the arguments it can have.'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: '*步骤 6*是我们与`clap` API一起工作的地方。这个特定案例仅使用Rust API；然而，`clap`也支持使用外部文件来配置参数。更多信息请参阅[https://docs.rs/clap/2.33.0/clap/index.html](https://docs.rs/clap/2.33.0/clap/index.html)。无论你如何定义参数，结构都非常相似：`App`结构体有几个元参数，用于告知用户作者、版本以及其他信息，以及它可以拥有的参数。'
- en: An argument can be a flag (that is, setting something to `true`/`false`) or
    a value (such as an input path), which is why we use the `Arg` struct to configure
    each individually. Typical command-line flags have a shorthand for a longer name
    (`ls -a` versus `ls --all` on Linux/Unix), as well as a short help text explaining
    the usage. The last setting concerns whether the flag has a more complex type
    than a Boolean, which we set to `true` for `exclude` and leave at `false` for
    the `recursive` flag. These names will later be used to retrieve these values.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 参数可以是标志（即设置某个值为`true`/`false`）或值（例如输入路径），这就是为什么我们使用`Arg`结构体来分别配置每个参数。典型的命令行标志有一个简写名称，用于较长的名称（例如Linux/Unix上的`ls
    -a`与`ls --all`），以及一个简短的帮助文本来解释用法。最后一个设置是关于标志是否具有比布尔值更复杂的类型，我们将`exclude`标志设置为`true`，而将`recursive`标志保留为`false`。这些名称将稍后用于检索这些值。
- en: Many command-line applications nowadays have a subcommand structure that allows
    for better structuring and readability. A subcommand can be nested and have its
    own arguments—just like the `App` struct. The arguments we define here are positional,
    so they are not referred to by their name but rather have to be present at that
    particular position. Since the argument is required, the argument parser takes
    in whatever value comes in.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 现在许多命令行应用程序都具有子命令结构，这有助于更好地组织和提高可读性。子命令可以嵌套，并拥有自己的参数——就像`App`结构体一样。我们在这里定义的参数是位置参数，因此它们不是通过名称来引用，而必须出现在特定的位置。由于参数是必需的，参数解析器会接受任何传入的值。
- en: With a call to `get_matches()`, we execute the parsing (which also triggers
    help texts and early exits if necessary) and retrieve an `ArgMatches` instance.
    This type manages the key-value pairs (argument name and the value it got), using
    the `Option` and `Result` types, which allow us to use Rust code for defaults.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 通过调用`get_matches()`，我们执行解析（这也会在必要时触发帮助文本和早期退出）并检索一个`ArgMatches`实例。该类型管理键值对（参数名称及其获取的值），使用`Option`和`Result`类型，这允许我们使用Rust代码来设置默认值。
- en: Subcommands behave like sub-applications in a way. They come with their own
    `ArgMatches` instance, for accessing their flags and more directly.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 子命令在某种程度上就像子应用程序。它们带有自己的`ArgMatches`实例，用于访问它们的标志和更直接地操作。
- en: '*Step 6* shows a few possible calls to run the program. We use two dashes, `--`,
    to pass any arguments through to the application (rather than `cargo` interpreting
    them), and by running the default help subcommand, we can see a nice and standardized
    help output with all of the texts and names we supplied.'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: '*步骤 6* 展示了运行程序的一些可能调用。我们使用两个短横线，`--`，将任何参数传递给应用程序（而不是 `cargo` 解释它们），通过运行默认的帮助子命令，我们可以看到包含我们提供的所有文本和名称的整洁且标准化的帮助输出。'
- en: These help texts are also provided in case parsing does not work out (for example,
    when a flag is misspelled) and for each subcommand. However, the last part of
    *step 6* shows what happens when it works out, listing all of the build directories
    in `target/` (since we excluded `src`). Since we don't want to bore you with various
    parameter combinations, we encourage you to try out the other arguments we configured
    and see different results!
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 这些帮助文本也提供了一种情况，即解析失败（例如，当标志拼写错误时）以及每个子命令。然而，*步骤 6* 的最后一部分展示了当它成功时会发生什么，列出了 `target/`
    中的所有构建目录（因为我们排除了 `src`）。由于我们不希望您被各种参数组合所困扰，我们鼓励您尝试我们配置的其他参数，并查看不同的结果！
- en: Now that we know how to work with command-line arguments, let's move on to the
    next recipe.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经知道了如何处理命令行参数，让我们继续到下一个菜谱。
- en: Working with piped input data
  id: totrans-209
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 处理管道输入数据
- en: 'Reading data from files is a very common task that we described in another
    recipe in this chapter (*Writing to and reading from files*). However, that''s
    not always the best option. In fact, many Linux/Unix programs can be chained together
    using a pipe (`|`) to process an incoming stream. This allows for several things
    to be done:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 从文件中读取数据是本章另一个菜谱中描述的非常常见的任务（*写入和读取文件*）。然而，这并不总是最佳选择。实际上，许多 Linux/Unix 程序可以使用管道（`|`）链接在一起来处理传入的流。这允许执行多项操作：
- en: Flexibility on the input source, static text, files, and networking streams—no
    need to change the programs
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 输入源、静态文本、文件和网络流量的灵活性——无需更改程序
- en: Run several processes, writing only the end result back to disk
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 运行多个进程，只将最终结果写回磁盘
- en: Lazy evaluation of the stream
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 流的惰性评估
- en: Flexible processing up-/downstream (for example, gzipping the output before
    writing to disk)
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 上游/下游的灵活处理（例如，在写入磁盘之前对输出进行 gzip 压缩）
- en: If you are not familiar with how this works, the pipe syntax may look cryptic.
    However, it actually stems from a functional programming paradigm ([https://www.geeksforgeeks.org/functional-programming-paradigm/](https://www.geeksforgeeks.org/functional-programming-paradigm/)),
    where pipes and stream processing are quite common—not unlike Rust's iterators.
    Let's build a CSV to a line-based JSON (each line is an object) converter to see
    how we can work with pipes!
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您不熟悉这是如何工作的，管道语法可能看起来很神秘。然而，它实际上源于函数式编程范式（[https://www.geeksforgeeks.org/functional-programming-paradigm/](https://www.geeksforgeeks.org/functional-programming-paradigm/)），其中管道和流处理相当常见——与
    Rust 的迭代器非常相似。让我们构建一个 CSV 到基于行的 JSON（每行是一个对象）转换器，看看我们如何与管道一起工作！
- en: Getting ready
  id: totrans-216
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'Open a Terminal to create a new project using `cargo new pipes.` Use VS Code
    to open the project directory and create a simple CSV file called `cars.csv` with
    the following content:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 打开终端，使用 `cargo new pipes.` 创建一个新的项目。使用 VS Code 打开项目目录，创建一个名为 `cars.csv` 的简单
    CSV 文件，内容如下：
- en: '[PRE43]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: We are now going to parse this file and create a series of JSON objects from
    it.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将解析此文件并从中创建一系列 JSON 对象。
- en: How to do it...
  id: totrans-220
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Follow the steps to implement `csv` to the JSON converter:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 按照以下步骤实现 `csv` 到 JSON 转换器：
- en: 'Open `Cargo.toml` to add a few dependencies we need for parsing CSV and creating
    JSON:'
  id: totrans-222
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开 `Cargo.toml` 以添加我们需要的几个依赖项，用于解析 CSV 和创建 JSON：
- en: '[PRE44]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Now, let''s add some code. As usual, we are going to import a few things in
    `src/main.rs,` so we can use them in the code:'
  id: totrans-224
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们添加一些代码。像往常一样，我们将导入 `src/main.rs` 中的几个东西，这样我们就可以在代码中使用它们：
- en: '[PRE45]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'The next thing to do is add a function that converts the input data into JSON.
    We can do this elegantly using the `Iterator` trait that each `csv::StringRecord` instance
    implements:'
  id: totrans-226
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一步是添加一个将输入数据转换为 JSON 的函数。我们可以优雅地使用每个 `csv::StringRecord` 实例实现的 `Iterator` 特性来完成此操作：
- en: '[PRE46]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'How do we get these `csv::StringRecords` instances? By reading from the console!
    As a last piece of code, we replace the default `main` function with the following:'
  id: totrans-228
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们如何获取这些 `csv::StringRecords` 实例？通过从控制台读取！作为最后一部分代码，我们用以下代码替换默认的 `main` 函数：
- en: '[PRE47]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Lastly, use PowerShell (on Windows) or your favorite Terminal (Linux/macOS)
    to run the binary with piped input data:'
  id: totrans-230
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，使用 PowerShell（在 Windows 上）或您喜欢的终端（Linux/macOS）通过管道输入数据来运行二进制文件：
- en: '[PRE48]'
  id: totrans-231
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: Let's dive into how we streamed data through multiple programs.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们深入了解我们如何通过多个程序流式传输数据。
- en: How it works...
  id: totrans-233
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: The Linux OS is largely file-based; many important interfaces to the kernel
    can be found in virtual filesystems pretending to be a file or folder structure.
    The best example is the `/proc/` filesystem, which allows user-access to hardware
    and other current information of the kernel/system. In the same spirit, the console
    inputs and outputs are treated; they are actually reserved file handles with the
    numbers 0 (standard input), 1 (standard output), and 2 (standard error). In fact,
    these link back to the `/proc/` filesystem, where `/proc/<process id>/fd/1` is
    the standard output of that particular process ID.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: Linux操作系统主要是基于文件的；许多重要的内核接口可以在模拟文件或文件夹结构的虚拟文件系统中找到。最好的例子是 `/proc/` 文件系统，它允许用户访问硬件和其他内核/系统的当前信息。同样地，控制台输入和输出也被处理；实际上，它们是保留的文件句柄，编号为0（标准输入）、1（标准输出）和2（标准错误）。实际上，这些链接回
    `/proc/` 文件系统，其中 `/proc/<process id>/fd/1` 是该特定进程ID的标准输出。
- en: Keeping this concept in mind, these file descriptors can be read just like any
    other file—which is what we are doing in this recipe. After setting up the basic
    dependencies in *step 1* and importing the modules in *step 2*, we create a processing
    function in *step 3*. The function takes in two of the `csv` crate's ([https://docs.rs/csv/1.1.1/](https://docs.rs/csv/1.1.1/))
    generic `StringRecord`—which holds a row's worth of data each—for the header row
    and the current row. The `zip()` ([https://doc.rust-lang.org/std/iter/trait.Iterator.html#method.zip](https://doc.rust-lang.org/std/iter/trait.Iterator.html#method.zip))
    function on the iterator allows us to align the indices efficiently, the result
    of which we can then transform into a tuple of `String` and `serde_json::Value::String`.
    This allows us to collect these tuples into a `serde_json::Map` type, which gets
    converted into `serde_json::Value::Object` (representing a JSON object).
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这个概念，这些文件描述符可以像任何其他文件一样读取——这正是我们在本食谱中所做的。在 *步骤1* 中设置基本依赖项并在 *步骤2* 中导入模块之后，我们在
    *步骤3* 中创建一个处理函数。该函数接收 `csv` crate 的两个泛型 `StringRecord`（每个都包含一行数据）——一个用于标题行，另一个用于当前行。迭代器上的
    `zip()` 函数允许我们有效地对齐索引，然后我们可以将结果转换为一个 `String` 和 `serde_json::Value::String` 的元组。这允许我们将这些元组收集到
    `serde_json::Map` 类型中，该类型随后被转换为 `serde_json::Value::Object`（表示一个JSON对象）。
- en: The iterator's `collect()` function relies on implementing the `FromIterator` trait
    for the particular types. `serde_json::Map` implements this for `(String, serde_json::Value)`.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 迭代器的 `collect()` 函数依赖于特定类型的 `FromIterator` 特性的实现。`serde_json::Map` 为 `(String,
    serde_json::Value)` 实现了这一特性。
- en: '*Step 4* then calls this `to_json()` function—but only after it builds a custom
    `Reader` object! By default `csv::Reader` expects the incoming rows to conform
    to a `Deserialize` struct—something that is impossible in a generic tool. Therefore,
    we resort to creating an instance using `ReaderBuilder` by specifying the options
    we need:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: '*第4步* 然后调用这个 `to_json()` 函数——但在此之前，它必须构建一个自定义的 `Reader` 对象！默认情况下，`csv::Reader`
    期望传入的行符合 `Deserialize` 结构——这在通用工具中是不可能的。因此，我们通过 `ReaderBuilder` 创建一个实例，并指定所需的选项：'
- en: '`trim(csv::Trim::All)`: This makes sanitation easier.'
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trim(csv::Trim::All)`: 这使得清理变得更容易。'
- en: '`has_headers(false)`: This allows us to read the headers first; otherwise,
    they would be ignored.'
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`has_headers(false)`: 这允许我们首先读取标题；否则，它们将被忽略。'
- en: '`delimiter(b'','')`: This hardcodes the delimiter to be a comma.'
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`delimiter(b'','')`: 这会将分隔符硬编码为逗号。'
- en: '`from_reader(io::stdin())`: This attaches to the `Read` interface of standard
    input.'
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`from_reader(io::stdin())`: 这将连接到标准输入的 `Read` 接口。'
- en: Upon creation, we read the first row and assume it is the CSV's header. Hence,
    we save it separately to borrow it to the `to_json()` function as needed. Following
    that, the `for` loop takes care of evaluating the (unlimited) iterator over the
    `Read` interface of standard input (typically until the `EOF` signal is received,
    with *Ctrl* + *D* on Linux/UNIX OSes). Each iteration prints the result to standard
    output again for other programs to read via a pipe.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 在创建时，我们读取第一行并假设它是CSV的标题。因此，我们将其单独保存，以便在需要时借用给 `to_json()` 函数。随后，`for` 循环负责处理标准输入的
    `Read` 接口的（无限）迭代器（通常直到接收到 `EOF` 信号，在Linux/UNIX操作系统上为 *Ctrl* + *D*）。每次迭代都会将结果再次打印到标准输出，以便其他程序可以通过管道读取。
- en: That's it! We highly recommend checking out the repository of the `csv` crate
    to learn more about the functions it offers (as well as `serde_json` ([https://docs.serde.rs/serde_json/](https://docs.serde.rs/serde_json/)))[),
    before moving on to the next recipe.](https://docs.serde.rs/serde_json/))
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样！我们强烈建议在继续下一个菜谱之前，查看 `csv` crate 的存储库，以了解更多它提供的功能（以及 `serde_json` ([https://docs.serde.rs/serde_json/](https://docs.serde.rs/serde_json/)))）。
- en: Sending web requests
  id: totrans-244
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 发送网络请求
- en: Over recent years, web requests have become an important part of many applications.
    Almost anything integrates with some kind of web service, even if it's only diagnostics
    and usage statistics. HTTP's versatility has proven to be a great asset in a more
    centralized computing world.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，网络请求已成为许多应用程序的重要组成部分。几乎所有东西都集成了某种类型的网络服务，即使只是诊断和用法统计。HTTP 的多功能性在更集中的计算世界中已被证明是一大资产。
- en: One of the libraries in this recipe (`surf`) is cutting edge and depends on
    an unstable (at the time of writing this) `async`/`await` feature of Rust. Depending
    on when you read this, the library or `async`/`await` in Rust may have changed—in
    that case, please open an issue on the accompanying GitHub repository so we can
    provide a working example for other readers.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 本菜谱中的库之一（`surf`）是前沿的，依赖于 Rust 在编写此内容时的不稳定（`async`/`await`）功能。根据你阅读此内容的时间，库或
    Rust 中的 `async`/`await` 可能已经改变——在这种情况下，请在相应的 GitHub 存储库中打开一个问题，这样我们就可以为其他读者提供一个可工作的示例。
- en: Making these web requests has not always been straightforward in any language,
    especially with regard to sending and receiving data types, variables, and more.
    Since Rust does not come with web request modules available out of the box, there
    are a few libraries we can use to connect to remote HTTP services. Let's see how.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 在任何语言中，制作这些网络请求并不总是直截了当的，尤其是在发送和接收数据类型、变量等方面。由于 Rust 并不自带网络请求模块，因此我们可以使用几个库来连接到远程
    HTTP 服务。让我们看看如何操作。
- en: How to do it...
  id: totrans-248
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到这一点...
- en: 'We can make web requests in just a few steps:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以仅用几个步骤就进行网络请求：
- en: Open a Terminal to create a new project using `cargo new web-requests.` Use
    VS Code to open the project directory.
  id: totrans-250
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开终端，使用 `cargo new web-requests.` 创建一个新的项目。使用 VS Code 打开项目目录。
- en: 'First, let''s edit `Cargo.toml` to add the dependencies we are going to use
    later:'
  id: totrans-251
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，让我们编辑 `Cargo.toml` 以添加我们稍后将要使用的依赖项：
- en: '[PRE49]'
  id: totrans-252
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'Let''s start importing these external dependencies and setting up some data
    structs in `src/main.rs`:'
  id: totrans-253
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们从导入这些外部依赖项并在 `src/main.rs` 中设置一些数据结构开始：
- en: '[PRE50]'
  id: totrans-254
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: '`surf` ([https://github.com/rustasync/surf](https://github.com/rustasync/surf)) is
    a recent crate developed fully `async`. Let''s create a test function to see it
    in action. First, we create the client and issue a simple `GET` request:'
  id: totrans-255
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`surf` ([https://github.com/rustasync/surf](https://github.com/rustasync/surf))
    是一个完全 `async` 开发的最新 crate。让我们创建一个测试函数来看看它的作用。首先，我们创建客户端并发出一个简单的 `GET` 请求：'
- en: '[PRE51]'
  id: totrans-256
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'Then, we upgrade to something more complex, form data, which we also confirm
    was received well:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将升级到更复杂的内容，表单数据，我们也会确认它已经被很好地接收：
- en: '[PRE52]'
  id: totrans-258
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'Next, the same procedure is repeated for JSON payloads:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，对 JSON 有效负载重复相同的步骤：
- en: '[PRE53]'
  id: totrans-260
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'And finally, we query parameters in `GET` requests:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们在 `GET` 请求中查询参数：
- en: '[PRE54]'
  id: totrans-262
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'Since `surf` is very new, let''s also test a more mature (and not `async`)
    crate, `reqwest` ([https://github.com/seanmonstar/reqwest/](https://github.com/seanmonstar/reqwest/)).
    Just like the previous function, it will go through several ways to do different
    types of web tasks, starting with a simple `GET` request:'
  id: totrans-263
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于 `surf` 非常新，让我们也测试一个更成熟的（并且不是 `async`）crate，`reqwest` ([https://github.com/seanmonstar/reqwest/](https://github.com/seanmonstar/reqwest/))）。就像之前的函数一样，它将通过几种不同的方式来完成不同类型的网络任务，从简单的
    `GET` 请求开始：
- en: '[PRE55]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'The next request features an HTML form request body:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个请求具有 HTML 表单请求体：
- en: '[PRE56]'
  id: totrans-266
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'This is followed by a JSON `PUT` request:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 这之后是一个 JSON `PUT` 请求：
- en: '[PRE57]'
  id: totrans-268
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'The final request features query parameters, automatically serialized by `serde`:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 最终请求包含查询参数，由 `serde` 自动序列化：
- en: '[PRE58]'
  id: totrans-270
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'One major function is still required: `main()`. Here, we are going to call
    the preceding tests:'
  id: totrans-271
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 还需要一个主要功能：`main()`。在这里，我们将调用前面的测试：
- en: '[PRE59]'
  id: totrans-272
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'The most important command is `cargo +nightly run`, so we can see that making
    requests works for both crates:'
  id: totrans-273
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最重要的命令是 `cargo +nightly run`，这样我们就可以看到对两个 crate 都可以发出请求：
- en: '[PRE60]'
  id: totrans-274
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: Let's check behind the scenes to see what's up.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们幕后看看发生了什么。
- en: How it works...
  id: totrans-276
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: The Rust community's web frameworks are great examples of how the lessons learned
    from other languages influence the design of a more recent technology. Both crates
    discussed in this chapter follow a similar pattern that can be observed in a range
    of libraries and frameworks across various languages (for example, Python's requests),
    which evolved to this stage themselves.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: Rust 社区的 Web 框架是其他语言中学习到的经验如何影响更近期技术设计的绝佳例子。本章中讨论的两个 crate 都遵循一个类似的模式，这个模式可以在各种语言（例如
    Python 的 requests）的众多库和框架中观察到，它们自身也发展到这一阶段。
- en: The way these frameworks operate is often called the builder pattern together
    with the decorator pattern (both described in *Design Patterns,* Gamma et al,
    1994). For C# programmers, the pattern is explained at [https://airbrake.io/blog/design-patterns/structural-design-patterns-decorator](https://airbrake.io/blog/design-patterns/structural-design-patterns-decorator).
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 这些框架的操作方式通常被称为构建器模式与装饰器模式（两者均在 *设计模式*，Gamma 等人，1994 年中描述）。对于 C# 程序员来说，该模式在 [https://airbrake.io/blog/design-patterns/structural-design-patterns-decorator](https://airbrake.io/blog/design-patterns/structural-design-patterns-decorator)
    中有解释。
- en: 'In this recipe, we look at two frameworks: `reqwest` and `surf`. After setting
    up the dependencies in `Cargo.toml` (*step 2*), we import some structs to create
    a serializable data type (to pass into `serde_urlencoded` ([https://github.com/nox/serde_urlencoded](https://github.com/nox/serde_urlencoded)))
    for `GET` parameters in *step 3*.'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们探讨了两个框架：`reqwest` 和 `surf`。在 `Cargo.toml` 中设置依赖项（*步骤 2*）之后，我们导入一些结构体来创建可序列化的数据类型（在
    *步骤 3* 中传递给 `serde_urlencoded` ([https://github.com/nox/serde_urlencoded](https://github.com/nox/serde_urlencoded)))
    以用于 `GET` 参数。
- en: In *step 4*, we create a function that covers `surf`. `surf` is fully `async`,
    which means that—to use `await`—we need to declare the function to be `async`
    as well. Then, we can create reusable `surf::Client`, which issues a `GET` request
    (to [https://blog.x5ff.xyz/other/cookbook2018](https://blog.x5ff.xyz/other/cookbook2018))
    right away. As with all of the other calls in this function, we use `await` to
    wait for the request to complete and the `?` operator to fail in case an error
    occurs.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 在 *步骤 4* 中，我们创建了一个涵盖 `surf` 的函数。`surf` 是完全 `async` 的，这意味着为了使用 `await`，我们需要将函数声明为
    `async`。然后，我们可以立即创建可重用的 `surf::Client`，它发出一个 `GET` 请求（到 [https://blog.x5ff.xyz/other/cookbook2018](https://blog.x5ff.xyz/other/cookbook2018)）。与这个函数中的所有其他调用一样，我们使用
    `await` 等待请求完成，并使用 `?` 操作符在发生错误时失败。
- en: In this recipe, we are using the incredibly useful [https://httpbin.org/](https://httpbin.org/).
    This website reflects many properties of the request back to the sender, allowing
    us to see what the server received in a JSON-formatted output (among other things).
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们使用了极其有用的 [https://httpbin.org/](https://httpbin.org/)。这个网站将许多请求属性反射回发送者，使我们能够看到服务器接收到的
    JSON 格式输出（以及其他内容）。
- en: The next request is a `POST` request with form data, which can be represented
    as a vector of tuples (key-value pairs). Using the same client as before (unlike
    other frameworks, it's not bound to a specific domain), we can simply pass the
    vector as the form-body of the `POST` request. Since we already know what the
    endpoint will return (JSON), we can ask the framework to parse the results into `serde_json::Value`
    (see also the *Parsing unstructured formats such as JSON* recipe in this chapter)
    right away. Again, any parsing errors, timeouts, and more are handled by the `?`
    operator, which would return an error at this point.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个请求是一个带有表单数据的 `POST` 请求，它可以表示为一个元组（键值对）的向量。使用之前的相同客户端（与其它框架不同，它不受特定域的限制），我们可以简单地将向量作为
    `POST` 请求的表单体传递。由于我们已经知道端点将返回什么（JSON），我们可以要求框架立即将结果解析为 `serde_json::Value`（参见本章的
    *解析非结构化格式，如 JSON* 菜谱）。同样，任何解析错误、超时等问题都由 `?` 操作符处理，此时将返回错误。
- en: The returned JSON contains the form values in the request, confirming that the
    request contained the data in the expected encoding and format. Similarly, if
    we send JSON data in a `PUT` request, the returned JSON is expected to be equal
    to what we sent.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 返回的 JSON 包含请求中的表单值，确认请求中包含的数据符合预期的编码和格式。同样地，如果我们通过 `PUT` 请求发送 JSON 数据，期望返回的
    JSON 应该与我们发送的相同。
- en: In the last request, we send HTTP `GET` with automatically constructed query
    parameters from the previously defined `struct`. After sending off the request,
    the reflected JSON contains the data found in the query parameters, which is what
    we sent off—if we (and the library) did everything correctly.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 在最后一个请求中，我们发送了带有从先前定义的 `struct` 自动构建的查询参数的 HTTP `GET`。在发送请求后，反射的 JSON 包含查询参数中的数据，这是我们发送的数据——如果我们（和库）一切都做得正确的话。
- en: '*Step 5* repeats the same ideas for `reqwest`, with only a few API differences
    (features aside):'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: '*步骤 5* 对 `reqwest` 重复了相同的概念，只有少数 API 差异（除了功能之外）：'
- en: Instead of `futures` and `await`, `reqwest` uses `send()` to execute the request.
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与 `futures` 和 `await` 不同，`reqwest` 使用 `send()` 来执行请求。
- en: Declaring the format for receiving data (JSON, plaintext, and so on) is done
    on the response instance (that is, on the `send()` return type).
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 声明接收数据格式（JSON、纯文本等）是在响应实例上完成的（即 `send()` 返回类型上）。
- en: '*Step 6* shows that each of the test functions works and no panics or errors
    are reported.'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: '*步骤 6* 显示了每个测试函数都正常工作，没有报告任何恐慌或错误。'
- en: Both libraries provide excellent ways to connect to remote web services, with
    `surf` having more features on the portability side (for example, various backends
    and WASM support), while `reqwest` is great for stable applications without `async`
    support and in need of cookies and proxies. For more information, read their respective
    documentations to match it to your project and use case. For now, let's move on
    to the next recipe.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个库都提供了连接远程网络服务的优秀方法，其中 `surf` 在可移植性方面具有更多功能（例如，各种后端和 WASM 支持），而 `reqwest`
    对于不需要 `async` 支持且需要 cookies 和代理的稳定应用来说非常出色。有关更多信息，请阅读它们各自的文档，以匹配您的项目和用例。现在，让我们继续下一个菜谱。
- en: Running machine learning models
  id: totrans-290
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 运行机器学习模型
- en: 'Machine learning and especially deep learning has been a rising topic ever
    since AlexNet''s triumph in 2012 ([https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)),
    with the language of choice being mostly Python for its easy-to-use syntax and
    flexibility. However, the underlying frameworks (TensorFlow, PyTorch, and more)
    are commonly built using C++, not only for performance reasons but also because
    accessing hardware (such as a GPU) is a lot easier. Rust has—so far—not been the
    language of choice to implement lower-level frameworks. Even outside the area
    of deep learning, Rust lacks library support in several areas including data preparation,
    classical machine learning, and optimization (progress is tracked here: [http://www.arewelearningyet.com/](http://www.arewelearningyet.com/))—so,
    why bother using Rust in any machine learning task?'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习和特别是深度学习自从 2012 年 AlexNet 胜利以来一直是一个热门话题 ([https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf))，首选的语言通常是
    Python，因为它的语法简单易用且灵活。然而，底层框架（TensorFlow、PyTorch 等）通常是用 C++ 构建的，这不仅是因为性能原因，也因为访问硬件（如
    GPU）要容易得多。到目前为止，Rust 并不是实现底层框架的首选语言。即使在深度学习领域之外，Rust 在数据准备、传统机器学习和优化（进展跟踪在此：[http://www.arewelearningyet.com/](http://www.arewelearningyet.com/))
    等多个领域缺乏库支持——那么，为什么要在任何机器学习任务中使用 Rust 呢？
- en: The Rust community provides bindings to popular deep learning frameworks to
    a Rust API, allowing users to do some (limited) experimentation as well as using
    weights of known architectures for inference. While all of this is highly experimental,
    it represents a push in the right direction and it's fascinating to work with.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: Rust 社区为流行的深度学习框架提供了到 Rust API 的绑定，使用户可以进行一些（有限的）实验，以及使用已知架构的权重进行推理。虽然所有这些都高度实验性，但它代表了正确的方向，并且与它们一起工作非常有趣。
- en: In the long run, we see Rust—as a low-level language—utilizing its low overhead
    and high performance to benefit the *deploying *of machine learning models (that
    is, model inference), targeting IoT-type devices with limited resources (for example, [https://github.com/snipsco/tract](https://github.com/snipsco/tract)).
    Until then, we can have some fun getting Rust's torch bindings to work. One example
    of using Rust in an efficient way for non-neural networks can be found at [https://blog.x5ff.xyz/blog/azure-functions-wasm-rust-ai/](https://blog.x5ff.xyz/blog/azure-functions-wasm-rust-ai/).
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 从长远来看，我们看到 Rust——作为一种底层语言——利用其低开销和高性能来促进机器学习模型的**部署**（即模型推理），针对资源有限的物联网设备（例如，[https://github.com/snipsco/tract](https://github.com/snipsco/tract)）。在此之前，我们可以享受让
    Rust 的 torch 绑定工作起来的乐趣。一个使用 Rust 以高效方式处理非神经网络示例可以在 [https://blog.x5ff.xyz/blog/azure-functions-wasm-rust-ai/](https://blog.x5ff.xyz/blog/azure-functions-wasm-rust-ai/)
    找到。
- en: Getting ready
  id: totrans-294
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: This recipe cannot cover the details of how and why neural networks work, so
    we assume that you already have an idea what training and test datasets are, what
    a convolutional network does, and how loss functions together with an optimizer
    achieve model convergence. If that sentence didn't make sense to you, we recommend
    taking one of the many online courses such as the [https://www.fast.ai/](https://www.fast.ai/)
    MOOC ([http://course.fast.ai/](http://course.fast.ai/)), the Coursera machine
    learning course ([https://www.coursera.org/learn/machine-learning](https://www.coursera.org/learn/machine-learning)),
    or Microsoft AI school ([https://aischool.microsoft.com/en-us/machine-learning/learning-paths](https://aischool.microsoft.com/en-us/machine-learning/learning-paths)) before
    implementing this recipe. If you are ready to start, use a command-line Terminal
    to create a new Rust project by running `cargo new rusty-ml` and change into the
    `rusty-ml` directory to create a new directory, `models`.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 这个配方不能涵盖神经网络是如何以及为什么工作的细节，所以我们假设你已经对训练和测试数据集、卷积网络的作用以及损失函数与优化器如何一起实现模型收敛有了一定的了解。如果这句话对你来说没有意义，我们建议在实施此配方之前，参加许多在线课程之一，例如
    [https://www.fast.ai/](https://www.fast.ai/) 的 MOOC ([http://course.fast.ai/](http://course.fast.ai/))、Coursera
    的机器学习课程 ([https://www.coursera.org/learn/machine-learning](https://www.coursera.org/learn/machine-learning))
    或 Microsoft AI 学院 ([https://aischool.microsoft.com/en-us/machine-learning/learning-paths](https://aischool.microsoft.com/en-us/machine-learning/learning-paths)）。
- en: To obtain the data, change into the `rusty-ml` directory and clone (or download
    and extract) Zalando Research's fashion MNIST ([https://research.zalando.com/welcome/mission/research-projects/fashion-mnist/](https://research.zalando.com/welcome/mission/research-projects/fashion-mnist/))
    repository from [https://github.com/zalandoresearch/fashion-mnist](https://github.com/zalandoresearch/fashion-mnist).
    Ultimately, you should end up with three directories, namely, `models`, `fashion-mnist`,
    and `src` within the `rusty-ml` project directory.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 要获取数据，切换到 `rusty-ml` 目录，并从 [https://github.com/zalandoresearch/fashion-mnist](https://github.com/zalandoresearch/fashion-mnist)
    克隆（或下载并解压）Zalando Research 的时尚 MNIST ([https://research.zalando.com/welcome/mission/research-projects/fashion-mnist/](https://research.zalando.com/welcome/mission/research-projects/fashion-mnist/))
    仓库。最终，你应该在 `rusty-ml` 项目目录中拥有三个目录，即 `models`、`fashion-mnist` 和 `src`。
- en: In the GitHub repository accompanying this book, the `fashion-mnist` repository
    is liked as a Git submodule ([https://git-scm.com/book/en/v2/Git-Tools-Submodules](https://git-scm.com/book/en/v2/Git-Tools-Submodules)).
    If you run `git submodule update --init` from within your local copy of the repository,
    it will download the `fashion-mnist` repository.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 在伴随本书的 GitHub 仓库中，`fashion-mnist` 仓库被作为一个 Git 子模块（[https://git-scm.com/book/en/v2/Git-Tools-Submodules](https://git-scm.com/book/en/v2/Git-Tools-Submodules)）。如果你在你的本地仓库副本中运行
    `git submodule update --init`，它将下载 `fashion-mnist` 仓库。
- en: Before we can continue, we need to unzip the data files, which are located in
    `fashion-mnist/data/fashion`. On Linux/macOS, you can use `gunzip *.gz` from within
    this directory to extract all; on Windows, use your preferred tool to do the same.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们继续之前，我们需要解压位于 `fashion-mnist/data/fashion` 的数据文件。在 Linux/macOS 上，你可以在该目录中运行
    `gunzip *.gz` 以提取所有文件；在 Windows 上，使用你喜欢的工具进行相同的操作。
- en: 'The end result should look like this:'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 最终结果应该看起来像这样：
- en: '[PRE61]'
  id: totrans-300
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: The original MNIST ([http://yann.lecun.com/exdb/mnist/](http://yann.lecun.com/exdb/mnist/))
    is a dataset comprised of small images (28 x 28 pixels, grayscale) that show handwritten
    digits, and the goal was to classify them into classes from 0 to 9—that is, recognize
    the number. After 20 years, modern algorithms solve this task with exceedingly
    high accuracy, so it needed an upgrade—which is what Zalando, a fashion company
    located in Berlin, Germany, took on. The `fashion-mnist` dataset is a drop-in
    replacement for the original showing small clothing items instead of digits. The
    classification of these items is much harder, thanks to their intricate details
    that make up each item in the ten classes. The task is to correctly classify which
    class (out of ten) a clothing item belongs to. The classes include boots, sneakers,
    pants, t-shirts, and others.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 原始的MNIST（[http://yann.lecun.com/exdb/mnist/](http://yann.lecun.com/exdb/mnist/））是一个由小图像（28
    x 28像素，灰度）组成的数据库，展示了手写的数字，目标是将它们分类到0到9的类别中——即识别数字。20年后，现代算法以极高的准确率解决了这个任务，因此需要升级——这是德国柏林的时尚公司Zalando所承担的任务。`fashion-mnist`数据集是原始数据集的替代品，显示的是小件服装而不是数字。由于这些物品的复杂细节构成了十个类别中的每一个物品，对这些物品的分类要困难得多。任务是正确分类服装物品属于哪个类别（十个类别中的哪一个）。这些类别包括靴子、运动鞋、裤子、T恤和其他。
- en: In this recipe, we are going to train a very accurate (~90%) model to identify
    these items using Rust's PyTorch bindings, `tch-rs`.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们将使用Rust的PyTorch绑定`tch-rs`训练一个非常准确（约90%）的模型来识别这些物品。
- en: How to do it...
  id: totrans-303
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到这一点...
- en: 'Only a few steps are needed to train and use a neural network in Rust:'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 训练和使用Rust中的神经网络只需要几个步骤：
- en: 'Open `Cargo.toml` to add the dependency for `tch-rs`:'
  id: totrans-305
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开`Cargo.toml`以添加`tch-rs`的依赖项：
- en: '[PRE62]'
  id: totrans-306
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'Let''s add some code for the imports to `src/main.rs` before diving deep:'
  id: totrans-307
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在深入研究之前，让我们先在`src/main.rs`中添加一些导入代码：
- en: '[PRE63]'
  id: totrans-308
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'PyTorch (and thereby, `tch-rs`) architectures typically store their layers
    individually, so we can store them in individual properties in `struct`:'
  id: totrans-309
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: PyTorch（以及因此，`tch-rs`）架构通常单独存储它们的层，因此我们可以在`struct`中单独的属性中存储它们：
- en: '[PRE64]'
  id: totrans-310
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'For these layers to work together as a neural network, it requires a forward
    pass. The `nn` module of `tch` provides two traits (`Module` and `ModuleT`) that
    we can implement to do that. We decided on implementing `ModuleT`:'
  id: totrans-311
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了使这些层作为一个神经网络协同工作，需要一个前向传递。`tch`的`nn`模块提供了两个特性（`Module`和`ModuleT`），我们可以实现它们来完成这个任务。我们决定实现`ModuleT`：
- en: '[PRE65]'
  id: totrans-312
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'Next, we are going to implement the training loop. Other deep learning frameworks
    hide these bits from the user, but PyTorch allows us to understand the individual
    steps better by writing them from scratch. Add the following function to `src/main.rs`,
    starting with some data loading:'
  id: totrans-313
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将实现训练循环。其他深度学习框架通常将这些部分隐藏起来，但PyTorch允许我们通过从头编写来更好地理解这些步骤。将以下函数添加到`src/main.rs`中，从一些数据加载开始：
- en: '[PRE66]'
  id: totrans-314
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'Then, we instantiate two important things: `VarStore` where everything gets
    saved in `tch`, and `ConvNet`, which we declared earlier:'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们实例化两个重要的事情：`VarStore`，在`tch`中保存一切，以及`ConvNet`，这是我们之前声明的：
- en: '[PRE67]'
  id: totrans-316
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 'Once we have that, we can use a loop to iterate over the training data in (random)
    batches, feeding them into the network, computing the loss, and running the back
    propagation:'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们有了这个，我们就可以使用循环来遍历训练数据（随机）批次，将它们输入到网络中，计算损失，并运行反向传播：
- en: '[PRE68]'
  id: totrans-318
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: 'After going through the entire training set, we then test the model on the
    entire test set. Since this should not influence the model performance, we skip
    the backpropagation this time:'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 在遍历整个训练集之后，我们然后在整个测试集上测试模型。由于这不应该影响模型性能，我们这次跳过了反向传播：
- en: '[PRE69]'
  id: totrans-320
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: 'Finally, we print some statistics so we know whether we are on the right track,
    but only after we save the current best model weights (that is, where the loss
    is the lowest):'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们打印一些统计数据，以便我们知道我们是否在正确的轨道上，但只有在保存当前最佳模型权重（即损失最低的地方）之后：
- en: '[PRE70]'
  id: totrans-322
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: 'After having a trained model, you typically also want to run inference on other
    images (that is, predict stuff). The next function takes the best model''s weights
    and applies it to the `ConvNet` architecture:'
  id: totrans-323
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在训练好模型之后，你通常还想要在其他图像上运行推理（即预测内容）。下一个函数接受最佳模型的权重并将其应用于`ConvNet`架构：
- en: '[PRE71]'
  id: totrans-324
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'With this model in place, we can then take a random subset of the training
    data and run inference:'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这个模型，我们可以然后取训练数据的一个随机子集并运行推理：
- en: '[PRE72]'
  id: totrans-326
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: 'The `main` function ties it all together and trains a model before calling
    the inference function:'
  id: totrans-327
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`main`函数将所有这些整合在一起，在调用推理函数之前训练一个模型：'
- en: '[PRE73]'
  id: totrans-328
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: 'That''s exciting! Let''s train a model for a few epochs to see decreasing loss
    and increasing test accuracy scores:'
  id: totrans-329
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这很令人兴奋！让我们训练一个模型几个周期，看看损失逐渐减少，测试准确率分数逐渐提高：
- en: '[PRE74]'
  id: totrans-330
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: This was a very interesting detour into the world of machine learning. Let's
    find out more about it.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一次非常有趣的机器学习世界之旅。让我们了解更多关于它。
- en: How it works...
  id: totrans-332
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'Deep learning in Rust works—however, it comes with many strings attached. `tch-rs`
    ([https://github.com/LaurentMazare/tch-rs](https://github.com/LaurentMazare/tch-rs))
    is a great framework if you already know some PyTorch and it lets you get into
    it right away. However, anyone who is new to the idea of machine learning should
    look at Python (and PyTorch) to get comfortable with the type of thinking that
    is required. `tch-rs` uses the C++ foundation of the Python version and provides
    a thin wrapper around the bindings it created. This means two things:'
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Rust 中进行深度学习是可行的——然而，它附带了许多条件。如果你已经了解一些 PyTorch，`tch-rs` ([https://github.com/LaurentMazare/tch-rs](https://github.com/LaurentMazare/tch-rs))
    是一个很好的框架，它让你可以立即开始使用。然而，对于任何刚开始接触机器学习的人来说，应该看看 Python（和 PyTorch），以熟悉所需的思维方式。`tch-rs`
    使用 Python 版本的 C++ 基础，并对其创建的绑定提供了一个薄薄的包装。这意味着两件事：
- en: Most ideas of the Python version should apply to `tch-rs`.
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Python 版本的多数想法应该适用于 `tch-rs`。
- en: The extensive C++ usage is likely *very* unsafe.
  id: totrans-335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大量的 C++ 使用可能 *非常* 不安全。
- en: By using bindings, wrapped code is much more likely to leave some kind of memory
    unfreed thanks to the added layer of abstraction and the changed programming paradigms
    in the host language. For applications such as machine learning, where tens (or
    even hundreds) of gigabytes of memory usage is not uncommon, a memory leak has
    a much larger impact. However, it's great to see it working so well already and
    we expect that this project will go much further.
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用绑定，由于抽象层和宿主语言中编程范式的改变，封装的代码更有可能因为添加的抽象层而留下一些类型的内存未释放。对于机器学习等应用，其中数十（甚至数百）GB
    的内存使用并不罕见，内存泄漏的影响要大得多。然而，看到它已经如此出色地工作是非常令人兴奋的，我们预计这个项目将走得更远。
- en: We made a few simplifications to the model training process for brevity. It's
    recommended to do some research into how to properly evaluate a model and rule
    out overfitting before going any further with it.
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简洁，我们对模型训练过程做了一些简化。建议在进一步操作之前，研究如何正确评估模型并排除过拟合。
- en: In *step 1*, we set up the `tch` dependency to resolve the imports we use in
    *step 2*. *Step 3* is where things get interesting (model architecture). Deep
    learning is a set of matrix multiplications, where—technically speaking—the input
    and output dimensions have to match for it to work. Since PyTorch ([https://pytorch.org/](https://pytorch.org/))
    is famously low-level, we have to set the individual layers up and match their
    dimensions by hand. In this case, we use two layers of 2-dimensional convolutions
    with two dense layers at the end to make sense of what the convolutions found.
    When we initialize the network in the `new()` function, we assign the input size,
    number of neurons/filters, and output/layers to the instantiation (`nn::conv2d`
    and `nn::linear`) functions. As you can see, the numbers match between the layers
    for it to be able to concatenate them, while the last layer outputs exactly the
    number of classes we are looking for (10).
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 在 *步骤 1* 中，我们设置了 `tch` 依赖项以解决 *步骤 2* 中使用的导入。*步骤 3* 是事情变得有趣的地方（模型架构）。深度学习是一系列矩阵乘法，从技术上讲，输入和输出维度必须匹配才能工作。由于
    PyTorch ([https://pytorch.org/](https://pytorch.org/)) 以其低级而闻名，我们必须手动设置各个层并匹配它们的维度。在这种情况下，我们使用两层二维卷积和两个密集层在最后来理解卷积发现的内容。当我们使用
    `new()` 函数初始化网络时，我们将输入大小、神经元/滤波器数量和输出/层分配给实例化函数（`nn::conv2d` 和 `nn::linear`）。如您所见，层之间的数字匹配，以便能够将它们连接起来，而最后一层正好输出我们寻找的类数量（10）。
- en: 'Tensors are a generalized version of vectors in mathematics. They can be anything
    from a single number (scalar) to a multi-dimensional vector of vectors. Read more
    at [http://mathworld.wolfram.com/Tensor.html](http://mathworld.wolfram.com/Tensor.html)
    (warning: lots of math).'
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 张量是数学中向量的泛化版本。它们可以是单个数字（标量）到多维向量向量的多维度向量。更多信息请参阅 [http://mathworld.wolfram.com/Tensor.html](http://mathworld.wolfram.com/Tensor.html)（警告：有很多数学内容）。
- en: 'In *step 4*, we implement the forward process provided by the `nn::ModuleT`
    trait. The difference to `nn::Module` is the `train` parameter, which indicates
    whether this run is intended for training in the `forward_t()` function. The other
    parameter in that function is the actual data represented as an `nn::Tensor` reference.
    Before we can use it, we have to assign a structure to it, and, since we are dealing
    with (grayscale) images, the choice is straightforward: it''s a 4-dimensional
    tensor. The dimensions are assigned as follows:'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 在第4步中，我们实现了由`nn::ModuleT`特性提供的正向过程。与`nn::Module`的区别在于`train`参数，它表示`forward_t()`函数中的这次运行是否旨在进行训练。该函数中的另一个参数是实际数据，表示为`nn::Tensor`引用。在我们能够使用它之前，我们必须为其分配一个结构，并且由于我们处理的是（灰度）图像，所以选择很简单：它是一个4维张量。维度分配如下：
- en: The first dimension is the batch, so there are zero to `batchsize` number of
    images in there.
  id: totrans-341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一维度是批次，因此其中包含从0到`batchsize`数量的图像。
- en: The second dimension represents the number of channels in the image, which is
    one for grayscale but three for RGB.
  id: totrans-342
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第二维度表示图像中的通道数，对于灰度图像是1，对于RGB图像是3。
- en: In the last two dimensions, we are storing the actual image, so they are the
    image's width and height.
  id: totrans-343
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在最后两个维度中，我们存储的是实际图像，因此它们是图像的宽度和高度。
- en: 'So, as we call the `.view()` function on the tensor instance, we are changing
    the interpretation to these dimensions, with -1 meaning whatever fits (typical
    for batch size). From there on, we are dealing with a bunch of 28 x 28 x 1 images
    that we feed into the first convolutional layer and apply the **Rectified Linear
    Unit** (**ReLU**) ([https://machinelearningmastery.com/rectified-linear-activation-function-for-deep-learning-neural-networks/](https://machinelearningmastery.com/rectified-linear-activation-function-for-deep-learning-neural-networks/))
    function on the outcome. That follows a 2-dimensional max pooling layer, after
    which the pattern is repeated for the second convolutional layer. This is common
    to control the output sizes of a convolutional layer. After the second max pooling,
    we flatten the output vector (1,024 is a calculated value: [https://medium.com/@iamvarman/how-to-calculate-the-number-of-parameters-in-the-cnn-5bd55364d7ca](https://medium.com/@iamvarman/how-to-calculate-the-number-of-parameters-in-the-cnn-5bd55364d7ca))
    and apply the fully connected layers one after the other with a ReLU function
    in between. The raw output of the last layer is then returned as a tensor.'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，当我们对张量实例调用`.view()`函数时，我们正在将这些维度作为解释，其中-1表示适合的任何值（对于批次大小来说是典型的）。从那时起，我们处理的是28
    x 28 x 1的图像，我们将这些图像输入到第一个卷积层，并在结果上应用**ReLU**（[https://machinelearningmastery.com/rectified-linear-activation-function-for-deep-learning-neural-networks/](https://machinelearningmastery.com/rectified-linear-activation-function-for-deep-learning-neural-networks/))函数。这后面跟着一个2维的最大池化层，之后对第二个卷积层重复此模式。这是常见的，用于控制卷积层的输出大小。在第二次最大池化之后，我们将输出向量展平（1,024是一个计算值：[https://medium.com/@iamvarman/how-to-calculate-the-number-of-parameters-in-the-cnn-5bd55364d7ca](https://medium.com/@iamvarman/how-to-calculate-the-number-of-parameters-in-the-cnn-5bd55364d7ca))，然后依次应用带有ReLU函数的全连接层。最后层的原始输出随后作为张量返回。
- en: In the training loop in *step 5*, we start off by reading the data from disk,
    using a predefined dataset function. We are taking advantage of this since the
    MNIST data is very common in machine learning examples. Ultimately, this is an
    iterator over the data (in this case, images) that comes with a few handy functions
    attached. In fact, there are multiple iterators since the data is already split
    into training and test sets.
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 在第5步的训练循环中，我们首先从磁盘读取数据，使用预定义的数据集函数。我们利用这一点，因为MNIST数据在机器学习示例中非常常见。最终，这是一个数据（在这种情况下，图像）的迭代器，附带一些实用的函数。实际上，由于数据已经分为训练集和测试集，所以有多个迭代器。
- en: Once loaded, we create an `nn::VarStore`, which is a `tch-rs` concept to store
    the model weights. This `VarStore` instance is passed into our model architecture
    struct, `ConvNet`, and the optimizer, so that it can do the backpropagation (Adam
    ([https://arxiv.org/abs/1412.6980](https://arxiv.org/abs/1412.6980)) is a stochastic
    optimizer and, as of early 2019, considered state of the art). Since PyTorch allows
    moving data between devices (that is CPU versus GPU), we always have to assign
    a device to weights and data so the framework knows which memory to write to.
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦加载，我们创建一个`nn::VarStore`，这是`tch-rs`概念，用于存储模型权重。这个`VarStore`实例被传递到我们的模型架构结构体`ConvNet`和优化器中，以便它可以进行反向传播（Adam
    [https://arxiv.org/abs/1412.6980](https://arxiv.org/abs/1412.6980) 是一个随机优化器，截至2019年初，被认为是最佳实践）。由于PyTorch允许在设备之间移动数据（即CPU与GPU之间），我们总是必须为权重和数据分配一个设备，以便框架知道写入哪个内存。
- en: The `learning_rate` parameter represents a step size of how far the optimizer
    jumps toward the best solution. This parameter is almost always very small (for
    example, `1e-2`) because choosing a larger value might overshoot its goal and
    worsen the solution, and a too-small value could mean it never gets there. Read
    more at [https://www.jeremyjordan.me/nn-learning-rate/](https://www.jeremyjordan.me/nn-learning-rate/).
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: '`学习率`参数表示优化器跳向最佳解决方案的步长。这个参数几乎总是非常小（例如，`1e-2`），因为选择更大的值可能会超过目标并恶化解决方案，而太小的值可能意味着它永远不会到达那里。更多信息请参阅[https://www.jeremyjordan.me/nn-learning-rate/](https://www.jeremyjordan.me/nn-learning-rate/)。'
- en: 'Next in the training loop, we have to implement the actual loop. This loop
    runs for several epochs and, generally, a higher number means more convergence
    (for example, overfitting: [https://machinelearningmastery.com/overfitting-and-underfitting-with-machine-learning-algorithms/](https://machinelearningmastery.com/overfitting-and-underfitting-with-machine-learning-algorithms/)),
    but the number we chose (5) in this recipe is definitely too low and chosen for
    the training to finish quickly with tangible results. Try a higher number and
    see how (whether) the model improves! Within each epoch, we can then run through
    the shuffled batches (a convenience function provided by the dataset implementation),
    run the forward pass and compute the loss for each batch. The loss function—cross
    entropy ([https://pytorch.org/docs/stable/nn.html#crossentropyloss](https://pytorch.org/docs/stable/nn.html#crossentropyloss))—comes
    back with a number that lets us know how far off we were with the prediction,
    which is important for running the backpropagation. In this example, we chose
    a large batch size of 1,024 images in one go, meaning that it has to run the loop
    59 times for each epoch. This speeds up the process without too much of an impact
    on the training quality—if you can fit everything into memory.'
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来在训练循环中，我们必须实现实际的循环。这个循环运行几个时期，一般来说，数字越大意味着收敛性越好（例如，过度拟合：[https://machinelearningmastery.com/overfitting-and-underfitting-with-machine-learning-algorithms/](https://machinelearningmastery.com/overfitting-and-underfitting-with-machine-learning-algorithms/)），但在这个配方中我们选择的数字（5）显然太低，是为了让训练快速完成并得到有形的结果。尝试一个更高的数字，看看模型是否有所改进！在每个时期内，我们可以运行通过打乱批次的操作（由数据集实现提供的便利函数），运行正向传递并计算每个批次的损失。损失函数——交叉熵（[https://pytorch.org/docs/stable/nn.html#crossentropyloss](https://pytorch.org/docs/stable/nn.html#crossentropyloss)）——会返回一个数字，告诉我们预测偏离了多少，这对于运行反向传播很重要。在这个例子中，我们选择了一次性处理1,024张图像的大批量，这意味着每个时期必须运行循环59次。这加快了过程，而对训练质量的影响不大——如果你能将所有内容都放入内存中。
- en: Think of a loss function as a function to determine how wrong the model was.
    Typically, we choose a predefined loss function based on the type of problem (regression,
    binary classification, or multi-class classification). Cross entropy is the default
    for multi-class classification.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 将损失函数视为一个确定模型错误程度的函数。通常，我们会根据问题的类型（回归、二分类或多分类）选择一个预定义的损失函数。对于多分类，交叉熵是默认选项。
- en: 'As we are walking through the batches, we also want to know how we are doing,
    which is why we created a simple vector to store the average loss per batch. Plotting
    the losses per epoch, we get a typical shape where the loss levels off toward
    zero:'
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们遍历批次时，我们也想知道我们的表现如何，这就是为什么我们创建了一个简单的向量来存储每个批次的平均损失。绘制每个时期的损失，我们得到一个典型的形状，损失逐渐趋于零：
- en: '![](img/e0ba6358-59b7-4961-b7c5-888816be9fa1.png)'
  id: totrans-351
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e0ba6358-59b7-4961-b7c5-888816be9fa1.png)'
- en: Since the algorithm has seen the training data, we need some test data to see
    whether it actually improved or whether it just learned to recognize the training
    data really well. This is why the test set is done without backpropagation and
    calculates the accuracy directly.
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 由于算法已经看到了训练数据，我们需要一些测试数据来查看它是否真正改进了，或者它只是学会了很好地识别训练数据。这就是为什么测试集不进行反向传播，直接计算准确率的原因。
- en: It is generally recommended to have a three-way split of your data ([https://machinelearningmastery.com/difference-test-validation-datasets/](https://machinelearningmastery.com/difference-test-validation-datasets/)).
    A training set that the model learns on should make up the majority, a test set
    that should show progress and overfitting after every epoch, and, finally, another
    set of data that the network has never seen before. The last one is to make sure
    that it performs as expected on real-world data and it must not be used to change
    any parameter in training. Confusingly, the naming of these three is sometimes
    training, validation, test (respectively) as well as training, test, validation.
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 通常建议将数据分为三个部分（[https://machinelearningmastery.com/difference-test-validation-datasets/](https://machinelearningmastery.com/difference-test-validation-datasets/)）。模型学习的训练集应占大多数，测试集应在每个epoch后显示进度和过拟合，最后，还有另一组网络之前从未见过的数据。最后一个目的是确保它在真实世界数据上的表现符合预期，并且不能用于训练中更改任何参数。令人困惑的是，这三个部分的命名有时是训练、验证、测试（分别）以及训练、测试、验证。
- en: In a strategy known as checkpointing, we then save the best model to disk as
    soon as the loss it produces is lower than what we had before. When training 200
    epochs, the loss function likely shows several spikes as the model learns wrong
    features and we don't want to lose the best model so far. Once done with the training
    for one epoch, we want to print out something to see if the model converges as
    expected.
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 在一种称为检查点（checkpointing）的策略中，我们一旦发现模型产生的损失低于之前，就立即将最佳模型保存到磁盘。在训练200个epoch时，损失函数可能会出现几个峰值，因为模型学习到了错误特征，我们不希望丢失迄今为止的最佳模型。一旦完成一个epoch的训练，我们想要打印出一些信息来查看模型是否如预期那样收敛。
- en: In *step 6*, we repeat some of the setup processes for loading the data, but,
    instead of training the architecture, we simply load the weights of the network
    from disk. The weights are the parts that we trained in the previous step and,
    in an inference-only scenario, we would train somewhere else and simply transfer
    the weights to where we classify real-world data (or load the entire model with
    something like ONNX: [https://onnx.ai/](https://onnx.ai/)).
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 在*步骤6*中，我们重复了一些加载数据的设置过程，但不是训练架构，而是简单地从磁盘加载网络的权重。权重是我们上一步训练的部分，在仅推理的场景中，我们会在其他地方训练并将权重转移到我们分类真实世界数据的地方（或者使用类似ONNX的东西加载整个模型：[https://onnx.ai/](https://onnx.ai/)）。
- en: To illustrate the prediction process, we are using the test set (again)—something
    that should be avoided in practice, since the model has to work on unseen data
    just as well as the data used in training. We take 10 random images (in 10 batches
    of size 1), run the forward pass, and then use a function called softmax to derive
    probabilities from the raw network output. After an application of `.view()` to
    align the data to the labels, we print the probabilities to the command line for
    us to see. Since these are probabilities, taking the index with the highest probability
    is the network's prediction. Since we used a dataset implementation, we can trust
    that these indices align with the input labels.
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明预测过程，我们再次使用测试集（在实际情况中应避免这样做，因为模型必须像训练数据一样处理未见过的数据）。我们取10张随机图像（在10个大小为1的批次中），运行前向传播，然后使用一个名为softmax的函数从原始网络输出中推导出概率。在应用`.view()`以对齐数据到标签后，我们将概率打印到命令行供我们查看。由于这些是概率，取概率最高的索引就是网络的预测。由于我们使用了数据集实现，我们可以相信这些索引与输入标签相匹配。
- en: '*Step 7* calls the functions in order and we get to see some training and predictions
    in the *step 8* output. As described in the *step 5* explanation, we print the
    loss (for this machine, each line took about 30 seconds to appear) and training
    accuracy. After the training is done, we know where the best model weights are
    located and use those to run the inference and print out the probability matrix.'
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: '*步骤7*按顺序调用函数，我们在*步骤8*的输出中看到一些训练和预测。正如*步骤5*的解释所述，我们打印损失（对于这台机器，每行大约需要30秒出现）和训练准确率。训练完成后，我们知道最佳模型权重在哪里，并使用这些权重进行推理并打印出概率矩阵。'
- en: Each line in that matrix represents the possible outcomes with probabilities
    assigned to each class—and, while it is 100% certain in the first line, the second
    line is a closer call (57% for class 0 and 40% for class 6). The sixth example
    has been wrongly predicted, and unfortunately, the model was fairly confident
    as well (71% for class 3 and 11% for class 2), which leads us to believe that
    more training is required.
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 该矩阵中的每一行都代表每个类别的可能结果，并分配了相应的概率——虽然第一行是100%确定的，但第二行则更接近（类别0为57%，类别6为40%）。第六个例子被错误地预测了，不幸的是，模型也相当自信（类别3为71%，类别2为11%），这让我们相信需要更多的训练。
- en: We encourage you to play around a little bit with the parameters to see how
    the outcomes can change quickly (for better or worse), or if you are more experienced,
    to build a better architecture. Regardless of what you are doing, `tch-rs` is
    an interesting way of using deep learning in Rust and we hope that it develops
    further so we can use it for a range of tasks in machine learning.
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 我们鼓励您稍微调整一下参数，看看结果如何快速变化（无论是好是坏），或者如果您更有经验，可以构建更好的架构。无论您做什么，`tch-rs`都是使用Rust进行深度学习的一种有趣方式，我们希望它能进一步发展，以便我们可以在机器学习的各种任务中使用它。
- en: Now that we know more about machine learning in Rust, let's move on to more
    tangible things in the next recipe.
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们对Rust中的机器学习有了更多的了解，让我们继续到下一个菜谱中更具体的内容。
- en: Configuring and using logging
  id: totrans-361
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 配置和使用日志记录
- en: 'While sending debug and other information out to the console is popular and
    easy, chances are that it becomes confusing and chaotic beyond a certain complexity.
    This includes the lack of a standardized date/time or origin class or inconsistent
    formatting, making it hard to trace an execution path through the system. Moreover,
    recent systems focus on logs as an additional source for information: how many
    users did we serve each hour of the day? Where did they come from? What was the
    95^(th) percentile response time?'
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然将调试和其他信息发送到控制台很流行且简单，但很可能会在一定的复杂性之后变得混乱。这包括缺乏标准化的日期/时间或来源类别或格式不一致，这使得难以通过系统追踪执行路径。此外，最近系统将日志视为信息的一个附加来源：我们每小时服务了多少用户？他们来自哪里？95^(th)百分位响应时间是多少？
- en: Due to printing constraints we had to replace the original emoji with their
    names. Check out the GitHub repository for this book for the full version.
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 由于打印限制，我们不得不将原始表情符号替换为它们的名称。查看这本书的GitHub仓库以获取完整版本。
- en: These questions can be answered with diligent logging using a framework that
    provides consistent and configurable output that can be easily parsed and shipped
    to a log analytics service. Let's create a simple Rust application that logs data
    in a variety of ways.
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 这些问题可以通过使用提供一致和可配置输出的框架进行勤奋的日志记录来回答，这些输出可以轻松解析并发送到日志分析服务。让我们创建一个简单的Rust应用程序，以多种方式记录数据。
- en: How to do it...
  id: totrans-365
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到这一点...
- en: 'Follow the steps to create and use a custom logger:'
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 按照以下步骤创建和使用自定义日志记录器：
- en: Open a Terminal to create a new project using `cargo new logging`. Use VS Code
    to open the project directory.
  id: totrans-367
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开终端，使用`cargo new logging`创建一个新的项目。使用VS Code打开项目目录。
- en: 'As a first step, we adapt `Cargo.toml` to include our new dependencies:'
  id: totrans-368
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 作为第一步，我们将`Cargo.toml`适配以包含我们的新依赖项：
- en: '[PRE75]'
  id: totrans-369
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: 'Then, in `src/main.rs`, we can import the required macros:'
  id: totrans-370
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，在`src/main.rs`中，我们可以导入所需的宏：
- en: '[PRE76]'
  id: totrans-371
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: 'Before getting into more complex things, let''s add a function that shows us
    how to use the macros we just imported:'
  id: totrans-372
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在深入研究更复杂的内容之前，让我们添加一个函数，展示我们如何使用刚刚导入的宏：
- en: '[PRE77]'
  id: totrans-373
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: 'These macros work because they are pre-configured by the logging framework.
    Consequently, if we are configuring the logging, it has to be done globally—for
    example, in the `main` function:'
  id: totrans-374
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这些宏之所以有效，是因为它们是由日志框架预先配置的。因此，如果我们正在配置日志，它必须全局进行——例如，在`main`函数中：
- en: '[PRE78]'
  id: totrans-375
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: 'By using `log4rs::init_file()`, we use a YAML configuration that can be changed
    without recompiling the program. Before continuing in `src/main.rs`, we should
    create `log4rs.yml` like this (the YAML format is picky about indentations):'
  id: totrans-376
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过使用`log4rs::init_file()`，我们使用一个可以不重新编译程序即可更改的YAML配置。在继续`src/main.rs`之前，我们应该创建一个类似于下面的`log4rs.yml`（YAML格式对缩进很挑剔）：
- en: '[PRE79]'
  id: totrans-377
  prefs: []
  type: TYPE_PRE
  zh: '[PRE79]'
- en: 'Back to `src/main.rs`: we saw an ability to create and use a fully custom logger.
    For that, we create a nested module in `src/main.rs` and implement our logger
    there:'
  id: totrans-378
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 回到`src/main.rs`：我们看到了创建和使用完全自定义日志记录器的功能。为此，我们在`src/main.rs`中创建一个嵌套模块并在这里实现我们的日志记录器：
- en: '[PRE80]'
  id: totrans-379
  prefs: []
  type: TYPE_PRE
  zh: '[PRE80]'
- en: 'Once we have defined the imports and basic `struct`, we can implement the `log::Log`
    trait for our new `EmojiLogger` type:'
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们定义了导入和基本 `struct`，我们就可以为我们的新 `EmojiLogger` 类型实现 `log::Log` 特性：
- en: '[PRE81]'
  id: totrans-381
  prefs: []
  type: TYPE_PRE
  zh: '[PRE81]'
- en: 'To avoid any lifetime conflicts, we want the logger to have a static lifetime
    ([https://doc.rust-lang.org/reference/items/static-items.html](https://doc.rust-lang.org/reference/items/static-items.html)),
    so let''s instantiate and declare the variable using Rust''s `static` keyword:'
  id: totrans-382
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了避免任何生命周期冲突，我们希望日志器具有静态生命周期 ([https://doc.rust-lang.org/reference/items/static-items.html](https://doc.rust-lang.org/reference/items/static-items.html))，因此让我们使用
    Rust 的 `static` 关键字实例化和声明变量：
- en: '[PRE82]'
  id: totrans-383
  prefs: []
  type: TYPE_PRE
  zh: '[PRE82]'
- en: 'Let''s execute `cargo run`, first with the `USE_CUSTOM` constant (created in
    *step 5*) set to `false`, which tells the program to read and use the `log4rs.yaml`
    configuration, instead of the custom module:'
  id: totrans-384
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们执行 `cargo run` 命令，首先将 `USE_CUSTOM` 常量（在 *步骤 5* 中创建）设置为 `false`，这告诉程序读取并使用
    `log4rs.yaml` 配置文件，而不是自定义模块：
- en: '[PRE83]'
  id: totrans-385
  prefs: []
  type: TYPE_PRE
  zh: '[PRE83]'
- en: 'In addition to that, we configured it so that, if something gets logged to
    `special-target`, we append it to a file called `outfile.log.` Let''s see what''s
    in there as well:'
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们还配置了它，如果将某些内容记录到 `special-target`，则将其追加到名为 `outfile.log` 的文件中。让我们也看看里面有什么：
- en: '[PRE84]'
  id: totrans-387
  prefs: []
  type: TYPE_PRE
  zh: '[PRE84]'
- en: 'Now that we have used the `log4rs` default logger, let''s see what our own
    logging class does. Set `USE_CUSTOM` (from *step 5*) to `true` and use `cargo
    run` to create the following output:'
  id: totrans-388
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 既然我们已经使用了 `log4rs` 默认的日志记录器，让我们看看我们自己的日志类做了什么。将 `USE_CUSTOM`（来自 *步骤 5*）设置为 `true`
    并使用 `cargo run` 生成以下输出：
- en: '[PRE85]'
  id: totrans-389
  prefs: []
  type: TYPE_PRE
  zh: '[PRE85]'
- en: Now that we have seen it at work, let's dive into why this is the case.
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们已经看到了它的工作情况，让我们深入探讨为什么会出现这种情况。
- en: How it works...
  id: totrans-391
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'In this more complex example, we are using Rust''s logging infrastructure,
    which consists of two main parts:'
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个更复杂的例子中，我们使用 Rust 的日志基础设施，它由两个主要部分组成：
- en: The `log` crate ([https://github.com/rust-lang-nursery/log](https://github.com/rust-lang-nursery/log)),
    which provides the facade (interface) to the logging macros
  id: totrans-393
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提供（接口）到日志宏的 `log` crate ([https://github.com/rust-lang-nursery/log](https://github.com/rust-lang-nursery/log))
- en: A logging implementor such as `log4rs` ([https://github.com/sfackler/log4rs](https://github.com/sfackler/log4rs)),
    `env_logger` ([https://github.com/sebasmagri/env_logger/](https://github.com/sebasmagri/env_logger/)),
    or similar ([https://docs.rs/log/0.4.8/log/#available-logging-implementations](https://docs.rs/log/0.4.8/log/#available-logging-implementations)[)](https://github.com/sfackler/log4rs)
  id: totrans-394
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个日志实现者，如 `log4rs` ([https://github.com/sfackler/log4rs](https://github.com/sfackler/log4rs))，`env_logger`
    ([https://github.com/sebasmagri/env_logger/](https://github.com/sebasmagri/env_logger/))
    或类似 ([https://docs.rs/log/0.4.8/log/#available-logging-implementations](https://docs.rs/log/0.4.8/log/#available-logging-implementations)[)](https://github.com/sfackler/log4rs)
- en: 'After the initial setup in *steps 1* and *2*, we simply have to import the
    macros provided by the `log` crate in *step 3*—nothing more. As we create a function
    to write to all available log levels (think of the levels as tags to filter by)
    and an additional target in this line in *step 4* (as shown in the following), we
    cover most of the use cases for logging:'
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: 在 *步骤 1* 和 *步骤 2* 的初始设置之后，我们只需导入在 *步骤 3* 中由 `log` crate 提供的宏——就这么多。当我们创建一个函数来写入所有可用的日志级别（将级别视为过滤的标签）以及在此行
    *步骤 4* 中的附加目标时（如下所示），我们就涵盖了大多数日志记录的使用案例：
- en: '[PRE86]'
  id: totrans-396
  prefs: []
  type: TYPE_PRE
  zh: '[PRE86]'
- en: '*Step 5* sets up the logging framework, `log4rs`, a crate that is modeled after
    the de-facto standard in the Java world: `log4j` ([https://logging.apache.org/log4j/2.x/](https://logging.apache.org/log4j/2.x/)).
    The crate provides excellent flexibility when it comes to where to write which
    log levels and using what format, and it can be changed at runtime. Check the *step
    6* configuration file to see an example. There we define `refresh_rate` (when
    to rescan the file for changes) of 30 seconds, which enables us to change the
    file without having to restart the application. Next, we define two appenders,
    which means output targets. The first one, `stdout`, is a simple console output,
    whereas `outfile` produces `outfile.log`, which we show in *step 10*. Its encoder
    property also hints toward how we can change the formatting.'
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: '*步骤 5* 设置了日志框架，`log4rs`，这是一个模仿 Java 世界事实标准的 crate：`log4j` ([https://logging.apache.org/log4j/2.x/](https://logging.apache.org/log4j/2.x/))。该
    crate 在确定日志级别和格式的地方提供了出色的灵活性，并且可以在运行时进行更改。查看 *步骤 6* 配置文件以查看示例。在那里我们定义了 `refresh_rate`（何时重新扫描文件以查找更改）为
    30 秒，这使得我们可以在不重新启动应用程序的情况下更改文件。接下来，我们定义了两个追加器，这意味着输出目标。第一个，`stdout`，是一个简单的控制台输出，而
    `outfile` 生成 `outfile.log`，我们在 *步骤 10* 中展示了它。其编码属性也暗示了我们可以如何更改格式。'
- en: Next, we defined a `root` logger, which represents the default. Having `trace`
    as the default level leads to excessive logging in many cases; having `warn` is
    often enough, especially in production settings. Additional loggers are created
    in the loggers property, where each child (`special-target`) represents a target
    we can use in the log macro (as seen in the preceding). These targets come with
    a configurable log level (`info`, in this case) and can use a range of appenders
    to write to. There are many more options that you can use here—just check out
    the documentation on how to set up more complex scenarios.
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们定义了一个`root`日志记录器，它代表默认设置。默认级别为`trace`会导致许多情况下日志记录过多；在`warn`通常就足够了，尤其是在生产环境中。在日志记录器属性中创建了额外的日志记录器，其中每个子（`special-target`）代表我们可以在日志宏中使用的目标（如前所述）。这些目标带有可配置的日志级别（在这种情况下为`info`）并可以使用一系列追加器来写入。这里还有许多其他选项可以使用——只需查看如何设置更复杂场景的文档即可。
- en: 'In *step 7*, we return to Rust code and create our own logger. This logger
    implements the log crate''s `Log` trait directly and translates any incoming `log::Record`
    into an emoji-backed console output for our visual entertainment. By implementing
    `enabled()`, we can filter whether any calls to `log()` are made and therefore
    base our decisions on more than just simple log levels as well. We instantiate
    the `EmojiLogger` struct in *step 8* as a static variable ([https://doc.rust-lang.org/reference/items/static-items.html](https://doc.rust-lang.org/reference/items/static-items.html)),
    which is passed into the `log::set_logger()` function whenever we set the `USE_CUSTOM` constant
    (*step 5*) to `true`. *Step 9* and *step 10* show these two outcomes:'
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: 在*步骤7*中，我们回到Rust代码并创建我们自己的日志记录器。这个日志记录器直接实现了log crate的`Log`特质，并将任何传入的`log::Record`转换为带有表情符号的终端输出，以供我们视觉娱乐。通过实现`enabled()`，我们可以过滤是否调用`log()`，因此我们的决策不仅仅基于简单的日志级别。我们在*步骤8*中将`EmojiLogger`结构体实例化为一个静态变量（[https://doc.rust-lang.org/reference/items/static-items.html](https://doc.rust-lang.org/reference/items/static-items.html)），每次我们将`USE_CUSTOM`常量（*步骤5*）设置为`true`时，都会将其传递给`log::set_logger()`函数。*步骤9*和*步骤10*展示了这两个结果：
- en: The `log4rs` default format includes the module, log level, timestamp, and message,
    and it creates the `outfile.log` file we configured it to.
  id: totrans-400
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`log4rs`默认格式包括模块、日志级别、时间戳和消息，并创建了配置的`outfile.log`文件。'
- en: Our custom logger creates unusual formatting along with an emoji showing the
    log levels—just as we wanted.
  id: totrans-401
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们的定制日志记录器创建了不寻常的格式，并附带一个显示日志级别的表情符号——正如我们想要的。
- en: The `log` crate is particularly useful in Rust since it allows you to attach
    your own loggers to third-party crates as well. The crates for issuing web requests
    in this chapter (in the *Sending web requests* recipe) provide infrastructure
    ([https://docs.rs/surf/1.0.2/surf/middleware/logger/index.html](https://docs.rs/surf/1.0.2/surf/middleware/logger/index.html))
    to do that, just like many other crates do (for example, `actix-web` in an earlier
    chapter). This means that, just by adding a dependency and a few lines of code,
    you can already create an application completely with logging.
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: 在Rust中，`log` crate特别有用，因为它允许你将你自己的日志记录器附加到第三方crate上。本章中用于发出网络请求的crate（在*发送网络请求*菜谱中）提供了基础设施（[https://docs.rs/surf/1.0.2/surf/middleware/logger/index.html](https://docs.rs/surf/1.0.2/surf/middleware/logger/index.html)）来做这件事，就像许多其他crate一样（例如，在早期章节中的`actix-web`）。这意味着，只需添加一个依赖项和几行代码，你就可以创建一个完全带有日志记录的应用程序。
- en: This concludes our detour into logging, so let's move on to another recipe.
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: 这就结束了我们对日志记录的偏离，让我们继续到另一个菜谱。
- en: Starting subprocesses
  id: totrans-404
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 启动子进程
- en: 'Pipelines, container orchestration, and command-line tools all share a common
    task: they all have to start and monitor other programs. These system calls are
    done in a variety of ways in other technologies, so let''s call a few standard
    programs with Rust''s `Command` interface.'
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: 管道、容器编排和命令行工具都共享一个共同的任务：它们都必须启动和监控其他程序。这些系统调用在其他技术中以各种方式完成，所以让我们用Rust的`Command`接口调用几个标准程序。
- en: How to do it...
  id: totrans-406
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'Follow these quick steps to call on external programs:'
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: 按照以下快速步骤调用外部程序：
- en: Open a Terminal to create a new project using `cargo new sub-processes.` Use
    VS Code to open the project directory.
  id: totrans-408
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开终端，使用`cargo new sub-processes.`创建一个新的项目。使用VS Code打开项目目录。
- en: 'Open `src/main.rs`. Rust''s standard library comes with an external command
    interface built-in, but first, let''s import it:'
  id: totrans-409
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开`src/main.rs`。Rust的标准库内置了一个外部命令接口，但首先，让我们导入它：
- en: '[PRE87]'
  id: totrans-410
  prefs: []
  type: TYPE_PRE
  zh: '[PRE87]'
- en: 'Once imported, we can do the rest in the `main` function. We''ll start off
    by calling `ls` with some arguments in two different directories:'
  id: totrans-411
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦导入，我们就可以在`main`函数中做其余的事情。我们首先会在两个不同的目录中使用一些参数调用`ls`：
- en: '[PRE88]'
  id: totrans-412
  prefs: []
  type: TYPE_PRE
  zh: '[PRE88]'
- en: 'In the next step, we are setting environment variables in the subprocess and,
    by grabbing the standard output of the `env` program, we can check whether it
    worked:'
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一步中，我们在子进程中设置环境变量，并通过抓取`env`程序的标准输出，我们可以检查它是否工作：
- en: '[PRE89]'
  id: totrans-414
  prefs: []
  type: TYPE_PRE
  zh: '[PRE89]'
- en: '`rev` is a program that reverses anything that comes in via standard input
    and it''s available on Windows and Linux/Unix. Let''s call it with some text and
    capture the output:'
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: '`rev`是一个程序，它反转通过标准输入传入的任何内容，它在Windows和Linux/Unix上可用。让我们用一些文本调用它并捕获输出：'
- en: '[PRE90]'
  id: totrans-416
  prefs: []
  type: TYPE_PRE
  zh: '[PRE90]'
- en: 'Use `cargo run` to see the program print the `ls` output (your output will
    look a little different):'
  id: totrans-417
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`cargo run`来查看程序打印`ls`输出（你的输出可能会有点不同）：
- en: '[PRE91]'
  id: totrans-418
  prefs: []
  type: TYPE_PRE
  zh: '[PRE91]'
- en: Windows users have to run this program in PowerShell, where `ls` is available.
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: Windows用户必须在PowerShell中运行此程序，其中`ls`可用。
- en: Let's see how it works behind the scenes.
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看它背后的工作原理。
- en: How it works...
  id: totrans-421
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: This recipe quickly covers some abilities of the Rust `std::process::Command`
    struct. After setting everything up in *steps 1* and *2*, we create the `main`
    function in *step 3*. Using `Result<(), Box<dyn Error + ...>>` with a boxed `dyn`
    trait ([https://doc.rust-lang.org/edition-guide/rust-2018/trait-system/dyn-trait-for-trait-objects.html](https://doc.rust-lang.org/edition-guide/rust-2018/trait-system/dyn-trait-for-trait-objects.html))
    as the return type for the main function allows us to use the `?` operator instead
    of `unwrap()`, `expect()`, or other constructs—regardless of the actual error
    type.
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: 这个配方快速介绍了Rust `std::process::Command`结构的一些功能。在*步骤1*和*步骤2*中设置好一切后，我们在*步骤3*中创建`main`函数。使用`Result<(),
    Box<dyn Error + ...>>`作为主函数的返回类型，允许我们使用`?`运算符而不是`unwrap()`、`expect()`或其他构造——无论实际的错误类型如何。
- en: 'We start off by using the `ls` command, which lists the directory contents.
    Except for Windows, the program takes arguments to expand the output:'
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先使用`ls`命令，该命令列出目录内容。除了Windows外，程序接受参数以扩展输出：
- en: '`-l` adds additional information such as permissions, date, and size (also
    called a long listing).'
  id: totrans-424
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`-l`添加额外的信息，如权限、日期和大小（也称为长列表）。'
- en: '`-a` includes hidden files as well (a stands for all).'
  id: totrans-425
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`-a`还包括隐藏文件（a代表所有）。'
- en: '`-h` uses human-friendly sizes (for example, KiB after 1,000 bytes).'
  id: totrans-426
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`-h`使用人类友好的大小（例如，1,000字节后的KiB）。'
- en: For `ls`, we can pass these flags as one large flag, `-alh`, (the order doesn't
    matter) and the `args()` function allows us to do that as a string slice. The
    actual execution of the process child is only done when we check the `status()`
    function of the instance and, here, we are also printing the results. The status
    code (on Linux) represents the success or failure of a particular program when
    it's `zero` or `non-zero` respectively.
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: 对于`ls`，我们可以将这些标志作为一个大标志传递，`-alh`（顺序无关紧要），而`args()`函数允许我们将其作为字符串切片来完成。实际执行进程子代只有在检查实例的`status()`函数时才会进行，在这里，我们也在打印结果。状态码（在Linux上）分别代表特定程序的成功或失败，当它是`zero`或`non-zero`时。
- en: The next part catches the standard output of the program and sets an environment
    variable for it. Environment variables can be a great way to transfer data or
    settings to the subprogram as well (for example, compiler flags for builds and
    keys for command-line APIs). `env` ([https://linux.die.net/man/1/env](https://linux.die.net/man/1/env))
    is a program on Linux (with a PowerShell equivalent) that prints available environment
    variables, so when we capture standard output, we can try to find the variable
    and its value.
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个部分捕获程序的标准输出并为它设置一个环境变量。环境变量也可以是一种将数据或设置传输到子程序的好方法（例如，编译器标志用于构建和命令行API的键）。`env`（[https://linux.die.net/man/1/env](https://linux.die.net/man/1/env)）是Linux上的一个程序（PowerShell有等效版本），它打印可用的环境变量，因此当我们捕获标准输出时，我们可以尝试找到变量及其值。
- en: 'The next part passes data to the `rev` program through the standard input while
    catching standard output. `rev` simply reverses the input data, so we expect the
    output to be the reverse of the input. There are two interesting things to note:'
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个部分通过标准输入将数据传递给`rev`程序，同时捕获标准输出。`rev`简单地反转输入数据，因此我们预计输出将是输入的反转。有两个有趣的事情需要注意：
- en: Getting a handle for standard input is scoped to avoid violating borrowing rules.
  id: totrans-430
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 获取标准输入句柄的范围是为了避免违反借用规则。
- en: Writing and reading from the pipes is done in bytes, which requires parsing
    to convert from/into a string. The `String::from_utf8_lossy()` function does that
    while ignoring invalid data.
  id: totrans-431
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从管道中写入和读取是以字节为单位的，这需要解析以将数据转换为/从字符串转换。`String::from_utf8_lossy()`函数执行这个操作，同时忽略无效数据。
- en: After that, the `main` function returns with a positive empty result (`Ok(())`).
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，`main`函数返回一个正的空结果(`Ok(())`)。
- en: In the last step, as usual, we run the code to see whether it works and, although
    we only have two `println!()` statements with only the exit code of the `ls` command
    in our source file, there is a lot of output. This is due to the default setting
    of passing a subprocess's standard output through the console. What we see here
    is, therefore, the output of the `ls -alh` command on Linux, which will be a little
    different on your machine.
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
  zh: 在最后一步，像往常一样，我们运行代码来查看它是否工作，尽管在我们的源文件中只有两个`println!()`语句，并且只有`ls`命令的退出代码，但输出却很多。这是因为默认设置是通过控制台传递子进程的标准输出。因此，我们看到的是Linux上`ls
    -alh`命令的输出，这在你的机器上可能会有所不同。
- en: Having successfully created and run several commands using Rust, we can now
    go out and create our own applications. We hope that this book helped you with
    that.
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
  zh: 在成功创建和运行了几个Rust命令之后，我们现在可以出去创建自己的应用程序了。我们希望这本书能在这方面帮助你。
