- en: Network Programming in Rust
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Rust网络编程
- en: In this chapter, we'll take a look at what Rust has to offer for network programming.
    We'll start by exploring existing networking primitives in the standard library
    by building a simple Redis clone. This will help us get familiar with the default
    synchronous network I/O model and its limitations. Next, we'll explain how asynchrony
    is a better approach when dealing with network I/O on a large scale. In the process,
    we'll get to know about the abstractions provided by the Rust ecosystem for building
    asynchronous network applications and refactor our Redis server to make it asynchronous
    using third-party crates.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将探讨Rust在网络编程方面能提供什么。我们将从通过构建一个简单的Redis克隆来探索标准库中的现有网络原语开始。这将帮助我们熟悉默认的同步网络I/O模型及其局限性。接下来，我们将解释在处理大规模网络I/O时异步性为何是一种更好的方法。在这个过程中，我们将了解Rust生态系统提供的抽象，用于构建异步网络应用程序，并使用第三方crate重构我们的Redis服务器，使其异步化。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Network programming prelude
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 网络编程序曲
- en: Synchronous network I/O
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 同步网络I/O
- en: Building a simple Redis server
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建简单的Redis服务器
- en: Asynchronous network I/O
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 异步网络I/O
- en: An introduction to `futures` and `tokio` crates
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`futures`和`tokio`crate的介绍'
- en: Network programming prelude
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 网络编程序曲
- en: '"A program is like a poem: you cannot write a poem without writing it."'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '"一个程序就像一首诗：你不写下来就无法创作一首诗。"'
- en: – *E. W. Dijkstra*
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: – *E. W. Dijkstra*
- en: Building a medium through which machines can communicate with each other over
    the internet is a complicated task. There are different kinds of devices that
    communicate over the internet, running different OS and different versions of
    applications, and they need a set of agreed upon rules to exchange messages with
    one another. These rules of communication are called network protocols and the
    messages devices send to each other are referred to as network packets.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 通过构建一种机器可以在互联网上相互通信的媒介是一项复杂的任务。互联网上有不同种类的设备进行通信，运行着不同的操作系统和不同版本的应用程序，它们需要一套共同认可的规则来相互交换信息。这些通信规则被称为网络协议，设备之间发送给对方的信息被称为网络数据包。
- en: For the separation of concerns of various aspects, such as reliability, discoverability,
    and encapsulation, these protocols are divided into layers with higher-layer protocols
    stacked over the lower-layers. Each network packet is composed of information
    from all of these layers. These days, modern operating systems already ship with
    a network protocol stack implementation. In this implementation, each layer provides
    support for the layers above it.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 为了分离各种方面的关注点，如可靠性、可发现性和封装性，这些协议被划分为层，高层协议堆叠在底层之上。每个网络数据包都由所有这些层的信息组成。如今，现代操作系统已经预装了网络协议栈的实现。在这个实现中，每一层都为其上层提供支持。
- en: At the lowest layer, we have the Physical layer and the Data Link layer protocol
    for specifying how packets are transmitted through wires across nodes on the internet
    and how they move in and out of network cards in computers. The protocols on this
    layer are the Ethernet and Token Ring protocols. Above that, we have the IP layer,
    which employs the concept of unique IDs, called IP addresses, to identify nodes
    on the internet. Above the IP layer, we have the Transport layer, which is a protocol
    that provides point-to-point delivery between two processes on the internet. Protocols
    such as TCP and UDP exist at this layer. Above the Transport layer, we have Application
    layer protocols such as HTTP and FTP, both of which are used to build rich applications.
    This allows for a higher level of communication, such as a chat application running
    on mobile devices. The entire protocol stack works in tandem to facilitate these
    kinds of complex interactions between applications running on computers, spread
    across the internet.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在最低层，我们有物理层和数据链路层协议，用于指定如何在互联网上的节点之间通过电线传输数据包，以及它们如何在计算机的网络卡中进出。这一层的协议是以太网和令牌环协议。在其之上，我们有IP层，它使用称为IP地址的唯一ID概念来识别互联网上的节点。在IP层之上，我们有传输层，这是一个在互联网上的两个进程之间提供点对点交付的协议。TCP和UDP等协议存在于这一层。在传输层之上，我们有HTTP和FTP等应用层协议，它们都用于构建丰富的应用程序。这允许实现更高层次的通信，例如在移动设备上运行的聊天应用程序。整个协议栈协同工作，以促进互联网上运行的计算机应用程序之间的这些复杂交互。
- en: 'With devices connecting to each other over the internet and sharing information,
    distributed application architectures started to proliferate. Two models emerged:
    the decentralized model, popularly known as the peer-to-peer model, and the centralized
    model, which is widely known as the client-server model. The later is more common
    out of the two these days. Our focus in this chapter will be on the client-server
    model of building network applications, especially on the Transport layer.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 随着设备通过互联网相互连接并共享信息，分布式应用程序架构开始普及。出现了两种模型：去中心化模型，通常被称为对等网络模型，以及中心化模型，通常被称为客户端-服务器模型。后者在两种模型中更为常见。在本章中，我们将重点关注构建网络应用程序的客户端-服务器模型，特别是在传输层。
- en: In major operating systems, the Transport layer of the network stack is exposed
    to developers under a family of APIs named **Sockets**. It includes a set of interfaces,
    which are used to set up a communication link between two processes. Sockets allow
    you to communicate data back and forth between two processes, either locally or
    remotely, without requiring the developer to have an understanding of the underlying
    network protocol.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在主要操作系统中，网络堆栈的传输层通过名为**套接字**的一系列API向开发者暴露。它包括一组接口，用于在两个进程之间建立通信链路。套接字允许你在两个进程之间，无论是本地还是远程，来回传递数据，而不需要开发者了解底层网络协议。
- en: The Socket API's roots lie in the **Berkley Software Distribution (BSD)**, which
    was the first operating system to provide a networking stack implementation with
    a socket API in 1983\. It serve as the reference implementation for networking
    stacks in major operating systems today. In Unix-like systems, a socket follows
    the same philosophy of *everything is a file* and exposes a file descriptor API.
    This means that one can read and write data from a socket just like files.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: Socket API的根源在于**伯克利软件发行版（BSD**），这是第一个在1983年提供带有套接字API的网络堆栈实现的操作系统。它现在仍然是主要操作系统网络堆栈的参考实现。在类Unix系统中，套接字遵循“一切皆文件”的哲学，并暴露出文件描述符API。这意味着可以从套接字读取和写入数据，就像文件一样。
- en: Sockets are file descriptors (an integer) that point to a descriptor table of
    the process that's managed by the kernel. The descriptor table contains a mapping
    of file descriptors to **file entry** structures, which contains the actual buffer
    for the data that's sent to the socket.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 套接字是文件描述符（一个整数），指向由内核管理的进程的描述符表。描述符表包含文件描述符到**文件条目**结构的映射，该结构包含发送到套接字的数据的实际缓冲区。
- en: 'The Socket API acts primarily at the TCP/IP layer. On this layer, the sockets
    that we create are categorized on various levels:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: Socket API主要在TCP/IP层工作。在这一层，我们创建的套接字根据不同的级别进行分类：
- en: '**Protocol**: Depending on the protocol, we can either have a TCP socket or
    a UDP socket. TCP is a stateful streaming protocol that provides the ability to
    deliver messages in a reliable fashion, whereas UDP is a stateless and unreliable
    protocol.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**协议**：根据协议的不同，我们可以拥有TCP套接字或UDP套接字。TCP是一种有状态的流式协议，它能够以可靠的方式传递消息，而UDP则是一种无状态且不可靠的协议。'
- en: '**Communication kind**: Depending on whether we are communicating with processes
    on the same machine or processes on remote machines, we can either have internet
    sockets or Unix domain sockets*.* Internet sockets are used for exchanging messages
    between processes on remote machines. It is represented by a tuple of an IP address
    and a port. Two processes that want to communicate remotely must use IP sockets.
    Unix domain sockets are used for communication between processes that run on the
    same machine. Here, instead of an IP address-port pair, it takes a filesystem
    path. For instance, databases use Unix domain sockets to expose connection endpoints.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**通信类型**：根据我们是否与同一台机器上的进程或远程机器上的进程进行通信，我们可以使用互联网套接字或Unix域套接字。互联网套接字用于在远程机器上的进程之间交换消息。它由一个IP地址和一个端口号的元组表示。两个想要远程通信的进程必须使用IP套接字。Unix域套接字用于在同一台机器上运行的进程之间的通信。在这里，它使用一个文件系统路径而不是IP地址-端口号对。例如，数据库使用Unix域套接字来公开连接端点。'
- en: '**I/O model**: Depending on how we read and write data to a socket, we can
    create sockets of two kinds: blocking sockets and non-blocking sockets.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**I/O模型**：根据我们如何将数据读入或写入套接字，我们可以创建两种类型的套接字：阻塞套接字和非阻塞套接字。'
- en: 'Now that we know more about sockets, let''s explore the client-server model
    a bit more. In this model of networking, the usual flow of setting up two machines
    to communicate with each other follows this process: the server creates a socket
    and binds it to an IP address-port pair before specifying a protocol, which can
    be TCP or UDP. It then starts listening for connections from clients. The client,
    on the other hand, creates a connecting socket and connects to the given IP address
    and port. In Unix, processes can create a socket using the `socket` system. This
    call gives back a file descriptor that the program can use to perform read and
    write calls to the client or to the server.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们对套接字有了更多的了解，让我们更深入地探讨一下客户端-服务器模型。在这个网络模型中，设置两台机器相互通信的常规流程遵循以下过程：服务器创建一个套接字并将其绑定到一个IP地址-端口号对，然后指定一个协议，可以是TCP或UDP。然后，它开始监听来自客户端的连接。另一方面，客户端创建一个连接套接字并连接到指定的IP地址和端口。在Unix中，进程可以使用`socket`系统调用创建套接字。这个调用会返回一个文件描述符，程序可以使用它来对客户端或服务器执行读写调用。
- en: Rust provides us with the `net` module in the standard library. This contains
    the aforementioned networking primitives on the Transport layer. For communicating
    over TCP, we have the `TcpStream` and `TcpListener` types. For communicating over
    UDP, we have the `UdpSocket` type. The `net` module also provides proper data
    types for representing IP addresses and supports both v4 and v6 versions.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: Rust在标准库中为我们提供了`net`模块。这个模块包含了上述传输层上的网络原语。对于通过TCP进行通信，我们有`TcpStream`和`TcpListener`类型。对于通过UDP进行通信，我们有`UdpSocket`类型。`net`模块还提供了表示IP地址的正确数据类型，并支持v4和v6版本。
- en: Building network applications that are reliable involves several considerations.
    If you are okay with few of the packets getting dropped between message exchanges,
    you can go with UDP sockets, but if you cannot afford to have packets dropped
    or want to have message delivery in sequence, you must use TCP sockets. The UDP
    protocol is fast and came much later to cater to needs where you require minimal
    latency in the delivery of packets and can deal with a few packets being dropped.
    For example, a video chat application uses UDP, but you aren't particularly affected
    if a few of the frames drop from the video stream. UDPs are used in cases where
    you are tolerant of no delivery guarantees. We'll focus our discussion on TCP
    sockets in this chapter, as it's the most used protocol by the majority of network
    applications that need to be reliable.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 构建可靠的网络应用程序需要考虑多个因素。如果你对在消息交换过程中丢失少量数据包没有异议，可以选择UDP套接字，但如果你不能容忍数据包丢失或希望消息按顺序交付，则必须使用TCP套接字。UDP协议速度快，出现较晚，是为了满足需要最小延迟交付数据包且可以处理少量数据包丢失的需求。例如，视频聊天应用程序使用UDP，但如果视频流中丢失几个帧，你并不会特别受到影响。UDP用于那些可以容忍无交付保证的情况。在本章中，我们将重点关注TCP套接字，因为它是大多数需要可靠性的网络应用程序最常用的协议。
- en: Another factor to consider, is how well and efficient your application is able
    to serve clients. From a technical standpoint, this translates to choosing the
    I/O model of sockets.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个需要考虑的因素是，你的应用程序在服务客户端方面有多好、有多高效。从技术角度来看，这相当于选择套接字的I/O模型。
- en: I/O is an acronym for Input/Output, and in this context, it is a catch-all phrase
    that simply denotes reading and writing bytes to sockets.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: I/O是输入/输出的缩写，在这个上下文中，它是一个总称，简单地表示将字节读取和写入套接字。
- en: Choosing between blocking and non-blocking sockets changes its architecture,
    the way we write our code, and how it scales to clients. Blocking sockets give
    you a **synchronous I/O** model, while non-blocking sockets let you do **asynchronous
    I/O**. On platforms that implement the Socket API, such as Unix, sockets are created
    in blocking mode by default. This entails the default I/O model in major network
    stacks following the synchronous model. Let's explore both of these models next.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在阻塞和非阻塞套接字之间进行选择会改变其架构，我们编写代码的方式，以及它如何扩展到客户端。阻塞套接字为你提供了一个**同步I/O**模型，而非阻塞套接字则允许你进行**异步I/O**。在实现Socket
    API的平台（如Unix）上，套接字默认以阻塞模式创建。这意味着在主要的网络堆栈中，默认的I/O模型遵循同步模型。接下来，让我们探讨这两种模型。
- en: Synchronous network I/O
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 同步网络I/O
- en: As we said previously, a socket is created in blocking mode by default. A server
    in blocking mode is synchronous in the sense that each read and write call on
    the socket blocks and waits until it is complete. If another client tries to connect
    to the server, it needs to wait until the server is done serving the previous
    client. This is to say that until the TCP read and write buffers are full, your
    application blocks on the respective I/O operation and any new client connections
    must wait until the buffers are empty and full again.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前所说的，默认情况下，套接字是以阻塞模式创建的。在阻塞模式下，服务器是同步的，这意味着套接字上的每次读写调用都会阻塞并等待完成。如果另一个客户端尝试连接到服务器，它需要等待服务器完成对前一个客户端的服务。也就是说，直到TCP读写缓冲区填满，您的应用程序会在相应的I/O操作上阻塞，任何新的客户端连接都必须等待缓冲区再次为空并填满。
- en: The TCP protocol implementation contains its own read and write buffers on the
    kernel level, apart from the application maintaining any buffers of its own.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: TCP协议在内核级别实现了自己的读写缓冲区，除了应用程序维护自己的任何缓冲区之外。
- en: Rust's standard library networking primitives provide the same synchronous API
    for sockets. To see this model in action, we'll implement something more than
    an echo server. We'll build a stripped down version of Redis. Redis is a data
    structure server and is often used as an in-memory data store. Redis clients and
    servers speak the RESP protocol, which is a simple line-based protocol. While
    the protocol is agnostic of TCP or UDP, Redis implementations mostly use the TCP
    protocol. TCP is a stateful stream-based protocol with no way for servers and
    clients to identify how many bytes to read from the socket to construct a protocol
    message. To account for that, most protocols follow this pattern of using a length
    byte, followed by the same length of payload bytes.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: Rust的标准库网络原语为套接字提供了相同的同步API。为了看到这个模型在行动中的样子，我们将实现一个比回声服务器更复杂的东西。我们将构建Redis的一个简化版本。Redis是一个数据结构服务器，通常用作内存数据存储。Redis客户端和服务器使用RESP协议，这是一个简单的基于行的协议。虽然该协议对TCP或UDP是中立的，但Redis实现主要使用TCP协议。TCP是一个有状态的基于流的协议，服务器和客户端无法识别从套接字中读取多少字节来构建一个协议消息。为了解决这个问题，大多数协议遵循使用长度字节，然后是相同长度的有效载荷字节的模式。
- en: A message in the RESP protocol is similar to most line-based protocols in TCP,
    with the initial byte being a marker byte followed by the length of the payload,
    followed by the payload itself. The message ends with a terminating marker byte.
    The RESP protocol supports various kinds of messages, ranging from simple strings,
    integers, arrays, and bulk strings and so on. A message in the RESP protocol ends
    with a `\r\n` byte sequence. For instance, a success message from the server to
    the client is encoded and sent as `+OK\r\n` (without quotes). `+` indicates a
    success reply, and then follows the strings. The command ends with `\r\n`. To
    indicate if a query has failed, the Redis server replies with `-Nil\r\n`.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: RESP协议中的消息类似于TCP中大多数基于行的协议，初始字节是一个标记字节，后面跟着有效载荷的长度，然后是有效载荷本身。消息以一个终止标记字节结束。RESP协议支持各种类型的消息，从简单的字符串、整数、数组到大量字符串等等。在RESP协议中，消息以`\r\n`字节序列结束。例如，服务器从客户端发送的成功消息编码并发送为`+OK\r\n`（不带引号）。`+`表示成功回复，然后是字符串。命令以`\r\n`结束。为了指示查询是否失败，Redis服务器以`-Nil\r\n`回复。
- en: 'Commands such as `get` and `set` are sent as arrays of bulk strings. For instance,
    a `get foo` command will be sent as follows:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '`get`和`set`等命令作为大量字符串的数组发送。例如，一个`get foo`命令将如下发送：'
- en: '[PRE0]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: In the preceding message, `*2` indicates that we have an array of `2` commands
    and is delimited by `\r\n`. Following that, `$3` indicates that we have a string
    of length `3`, i.e., the `GET` command followed by a `$3` for the string `foo`.
    The command ends with `\r\n`. That's the basics on RESP. We don't have to worry
    about the low-level details of parsing RESP messages, as we'll be using a fork
    of a crate called `resp` to parse incoming byte streams from our client into a
    valid RESP message.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的消息中，`*2`表示我们有一个包含`2`个命令的数组，并由`\r\n`分隔。随后，`$3`表示我们有一个长度为`3`的字符串，即`GET`命令后跟一个表示字符串`foo`的`$3`。命令以`\r\n`结束。这就是RESP协议的基础。我们不必担心解析RESP消息的低级细节，因为我们将会使用一个名为`resp`的crate的分支来解析来自客户端的字节流，并将其转换为有效的RESP消息。
- en: Building a synchronous redis server
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建一个同步的Redis服务器
- en: To make this example short and easy to follow, our Redis clone will implement
    a very small subset of the RESP protocol and will be able to process only `SET`
    and `GET` calls. We'll use the official `redis-cli` that comes with the official
    *Redis* package to make queries against our server. To use the `redis-cli`, we
    can install Redis on Ubuntu by running `apt-get install redis-server.`
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使这个例子简短且易于理解，我们的Redis克隆将实现RESP协议的一个非常小的子集，并且只能处理 `SET` 和 `GET` 调用。我们将使用官方的
    `redis-cli`，它是官方 *Redis* 软件包的一部分，来对我们的服务器进行查询。要使用 `redis-cli`，我们可以在Ubuntu上运行 `apt-get
    install redis-server` 来安装Redis。
- en: 'Let''s create a new project by running `cargo new rudis_sync` and adding the
    following dependencies in our `Cargo.toml` file:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 通过运行 `cargo new rudis_sync` 并在我们的 `Cargo.toml` 文件中添加以下依赖项来创建一个新的项目：
- en: '[PRE1]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'We have named our project `rudis_sync`. We depend on two crates:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将我们的项目命名为 `rudis_sync`。我们依赖于两个crate：
- en: '`lazy_static`: We''ll use this to store our in-memory database.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`lazy_static`：我们将使用这个crate来存储我们的内存数据库。'
- en: '`resp`: This is a forked crate that resides on my GitHub repository. We''ll
    use this to parse the stream of bytes from the client.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resp`：这是一个位于我的GitHub仓库上的forked crate。我们将使用它来解析来自客户端的字节流。'
- en: To make the implementation easier to follow, `rudis_sync` has very minimal error-handling
    integration. When you are done experimenting with the code, you are encouraged
    to implement better error-handling strategies.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使实现更容易理解，`rudis_sync` 具有非常少的错误处理集成。当你完成代码的实验后，我们鼓励你实现更好的错误处理策略。
- en: 'Let''s start with the contents of our `main.rs` file:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从 `main.rs` 文件的内容开始：
- en: '[PRE2]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: We have a bunch of imports, followed by an in-memory `RUDIS_DB` hashmap that's
    declared in a `lazy_static!` block. We are using this as an in-memory database
    to store key and value pairs that are sent by clients. In our `main` function,
    we create a listening address in `addr` from the user-provided argument or use
    `127.0.0.1:6378` as the default. We then create a `TcpListener` instance by calling
    the associated `bind` method, passing the `addr`. This creates a TCP listening
    socket. Later, we call the `incoming` method on `listener`, which then returns
    an iterator of new client connections. For each client connection `stream` that
    is of the `TcpStream` type (a client socket), we call the `handle_client` function,
    passing in the `stream`.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有一系列导入，随后是一个在 `lazy_static!` 块中声明的内存 `RUDIS_DB` hashmap。我们正在使用这个作为内存数据库来存储客户端发送的键值对。在我们的
    `main` 函数中，我们从用户提供的参数创建一个监听地址 `addr` 或使用 `127.0.0.1:6378` 作为默认值。然后我们通过调用关联的 `bind`
    方法并传递 `addr` 来创建一个 `TcpListener` 实例。稍后，我们在 `listener` 上调用 `incoming` 方法，它返回一个新客户端连接的迭代器。对于每个客户端连接
    `stream`，它属于 `TcpStream` 类型（客户端套接字），我们调用 `handle_client` 函数，并传入 `stream`。
- en: 'In the same file, the `handle_client` function is responsible for parsing queries
    that are sent from the client, which would be one of the `GET` or `SET` queries:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在同一文件中，`handle_client` 函数负责解析从客户端发送的查询，这些查询将是 `GET` 或 `SET` 查询之一：
- en: '[PRE3]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The `handle_client` function receives the client `TcpStream` socket in the `stream` variable.
    We wrap our client `stream` in a `BufReader`, which is then passed as a mutable
    reference to the `Decoder::new` method from the `resp` crate. The `Decoder` reads
    bytes from the `stream` to create a RESP `Value` type. We then have a match block
    to check whether our decoding succeeded. If it fails, we print an error message
    and close the socket by calling `shutdown()` and requesting both the reader part
    and writer part of our client socket connection to be closed with the `Shutdown::Both`
    value. The `shutdown` method needs a mutable reference, so we call `get_mut()`
    before that. In a real-world implementation, you obviously need to handle this
    error gracefully.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '`handle_client` 函数接收 `stream` 变量中的客户端 `TcpStream` 套接字。我们将我们的客户端 `stream` 包装在一个
    `BufReader` 中，然后将其作为可变引用传递给 `resp` crate 中的 `Decoder::new` 方法。`Decoder` 从 `stream`
    中读取字节以创建一个 RESP `Value` 类型。然后我们有一个匹配块来检查我们的解码是否成功。如果失败，我们打印一条错误消息，并通过调用 `shutdown()`
    并请求使用 `Shutdown::Both` 值关闭客户端套接字连接的读取部分和写入部分来关闭套接字。`shutdown` 方法需要一个可变引用，所以我们在此之前调用
    `get_mut()`。在实际实现中，显然需要优雅地处理这个错误。'
- en: 'If the decoding succeeds, we call `process_client_request`, which returns the
    `reply` to send back to the client. We write this `reply` to the client by calling
    `write_all` on the client `stream`. The `process_client_request` function is defined
    in `commands.rs` as follows:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 如果解码成功，我们调用 `process_client_request`，它返回要发送回客户端的 `reply`。我们通过在客户端 `stream` 上调用
    `write_all` 将此 `reply` 写入客户端。`process_client_request` 函数在 `commands.rs` 中定义如下：
- en: '[PRE4]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: This function takes the decoded `Value` and matches it on the parsed query.
    In our implementation, we expect the client to send an array of bulk strings,
    so we match on the `Value::Array` variant of `Value`, using `if let`, and store
    the array in `v`. If we match as an `Array` value in the `if` branch, we take
    that array and match on the first entry in `v`, which will be our command type,
    that is, `GET` or `SET`. This is again a `Value::Bulk` variant that wraps the
    command as a string.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 此函数接收解码后的`Value`并在解析的查询上匹配它。在我们的实现中，我们期望客户端发送一个大量字符串的数组，所以我们匹配`Value::Array`的`Value`变体，使用`if
    let`并将数组存储在`v`中。如果在`if`分支中匹配为一个`Array`值，我们取该数组并匹配`v`中的第一个条目，这将是我们命令的类型，即`GET`或`SET`。这同样是一个`Value::Bulk`变体，它将命令作为字符串包装。
- en: We take the reference to the inner string as `s` and match only if the string
    has a `GET` or `SET` as a value. In the case of `GET`, we call `handle_get`, passing
    the `v` array, and in the case of `SET`, we call `handle_set`. In the `else` branch,
    we simply send a `Value::Error` reply to the client with `invalid Command` as
    the description.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将内部字符串的引用记为`s`，并且只有当字符串的值为`GET`或`SET`时才进行匹配。在`GET`的情况下，我们调用`handle_get`函数，传递`v`数组，而在`SET`的情况下，我们调用`handle_set`函数。在`else`分支中，我们简单地向客户端发送一个带有描述`invalid
    Command`的`Value::Error`回复。
- en: The value that's returned by both branches is assigned to the `reply` variable.
    It is then matched for the inner type `r` and turned into `Vec<u8>` by invoking
    the `encode` method on it, which is then returned from the function.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 两个分支返回的值分配给`reply`变量。然后它被匹配为内部类型`r`，并通过调用其上的`encode`方法将其转换为`Vec<u8>`，然后从函数返回。
- en: 'Our `handle_set` and `handle_get` functions are defined in the same file as
    follows:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的`handle_set`和`handle_get`函数定义在同一文件中，如下所示：
- en: '[PRE5]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'In `handle_get()`, we first check whether the `GET` command has no key present
    in the query and fails with an error message. Next, we match on `v[0]`, which
    is the key for the `GET` command, and check whether it exists in our database.
    If it exists, we wrap it in `Value::Bulk` using the map combinator, otherwise
    we return a `Value::Null` reply:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在`handle_get()`函数中，我们首先检查`GET`命令的查询中是否没有键存在，并返回错误信息。接下来，我们在`v[0]`上匹配，它是`GET`命令的键，并检查它是否存在于我们的数据库中。如果存在，我们使用map组合器将其包装在`Value::Bulk`中，否则我们返回一个`Value::Null`回复：
- en: '[PRE6]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: We then store it in a `reply` variable and return it as a `Result` type, that
    is, `Ok(reply)`.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们将其存储在`reply`变量中，并以`Result`类型返回它，即`Ok(reply)`。
- en: A similar thing happens in `handle_set`, where we bail out if we don't have
    enough arguments to the `SET` command. Next, we match on our key and value using
    `&v[0]` and `&v[1]` and insert it into `RUDIS_DB`. As an acknowledgement of the
    `SET` query., we reply with `Ok`.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在`handle_set`中发生类似的事情，如果我们没有足够的参数传递给`SET`命令，我们就退出。接下来，我们使用`&v[0]`和`&v[1]`匹配我们的键和值，并将其插入到`RUDIS_DB`中。作为对`SET`查询的确认，我们回复`Ok`。
- en: 'Back in our `process_client_request` function, once we create the reply bytes,
    we match on the `Result` type and convert them into a `Vec<u8>` by calling `encode()`,
    which is then written to the client. With that walk-through out of the way, it''s
    time to test our client with the official `redis-cli` tool. We''ll run it by invoking `redis-cli
    -p 6378`:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的`process_client_request`函数中，一旦我们创建了回复字节，我们就匹配`Result`类型，并通过调用`encode()`将其转换为`Vec<u8>`，然后写入客户端。随着这个过程的结束，现在是时候用官方的`redis-cli`工具测试我们的客户端了。我们将通过调用`redis-cli
    -p 6378`来运行它：
- en: '![](img/d782e87d-c9b7-4271-b22d-730d1142a9c0.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d782e87d-c9b7-4271-b22d-730d1142a9c0.png)'
- en: 'In the preceding session, we did a few `GET` and `SET` queries with an expected
    reply from `rudis_sync`. Also, here''s our output log from the `rudis_server`
    of our new connection(s):'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的会话中，我们进行了一些`GET`和`SET`查询，并期望从`rudis_sync`得到回复。此外，这是我们的新连接的`rudis_server`的输出日志：
- en: '![](img/25c5a814-0b1d-4c5e-a664-4ff20689f2b8.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![](img/25c5a814-0b1d-4c5e-a664-4ff20689f2b8.png)'
- en: 'But the problem with our server is that we have to wait until the initial client
    has finished being served. To demonstrate this, we''ll introduce a bit of delay
    in our `for` loop that handles new client connections:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 但我们服务器的问题是我们必须等待初始客户端完成服务。为了演示这一点，我们将在处理新客户端连接的`for`循环中引入一点延迟：
- en: '[PRE7]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The `sleep` call simulates a delay in request processing. To see the latencies,
    we''ll start two clients at almost the same time, where one of them makes a `SET`
    request and the other one makes a `GET` request on the same key. Here''s our first
    client, which does the `SET` request:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '`sleep`调用模拟了请求处理中的延迟。为了看到延迟，我们将几乎同时启动两个客户端，其中一个客户端发出`SET`请求，另一个客户端对同一键发出`GET`请求。以下是执行`SET`请求的第一个客户端：'
- en: '![](img/8266832f-8fdc-4618-bdd9-93013e591282.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8266832f-8fdc-4618-bdd9-93013e591282.png)'
- en: 'Here''s our second client, which does a `GET` request on the same key, `foo`:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们的第二个客户端，它在相同的键`foo`上执行`GET`请求：
- en: '![](img/0dbc71fc-b4e1-489e-acb4-725744aa02e2.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0dbc71fc-b4e1-489e-acb4-725744aa02e2.png)'
- en: As you can see, the second client had to wait for almost three seconds to get
    the second `GET` reply.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所看到的，第二个客户端不得不等待近三秒钟才能收到第二个`GET`响应。
- en: 'Due to its nature, the synchronous mode becomes a bottleneck when you need
    to process more than 100,000 (say) clients at the same time, with each client
    taking varying amounts of processing time. To get around this, you usually need
    to spawn a thread for handling each client connection. Whenever a new client connection
    is made, we spawn a new thread and offload the `handle_client` invocation from
    the main thread, allowing the main thread to accept other client connections.
    We can achieve this by using a single line change in our `main` function, like
    so:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 由于其本质，当需要同时处理超过100,000（比如说）个客户端时，同步模式就会成为瓶颈，每个客户端的处理时间各不相同。为了解决这个问题，通常需要为每个客户端连接创建一个线程。每当建立新的客户端连接时，我们就会创建一个新线程，并将`handle_client`调用从主线程卸载，这样主线程就可以接受其他客户端连接。我们可以在`main`函数中通过一行代码实现这一点，如下所示：
- en: '[PRE8]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: This removes the blocking nature of our server, but introduces the overhead
    of spawning a new thread every time a new client connection is received. First,
    there is an overhead of spawning threads and, second, the context switch time
    between threads adds another overhead.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 这消除了我们服务器的阻塞特性，但引入了每次接收到新的客户端连接时都要创建新线程的开销。首先，有创建线程的开销，其次，线程之间的上下文切换时间又增加了额外的开销。
- en: As we can see, our `rudis_sync` server works as expected. But it will soon be
    bottlenecked by the amount of threads our machine can handle. This threading model
    of handling connections worked well until the internet began gaining a wider audience
    and more and more clients connecting to the internet became the norm. Today, however,
    things are different and we need highly efficient servers that can handle millions
    of requests at the same time. It turns out that we can tackle the problem of handling
    more clients on a more foundational level, that is, by using non-blocking sockets.
    Let's explore them next.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所见，我们的`rudis_sync`服务器按预期工作。但很快它将因为机器能处理的线程数量而成为瓶颈。这种处理连接的线程模型在互联网开始获得更广泛的受众，越来越多的客户端连接到互联网成为常态之前工作得很好。然而，如今情况不同了，我们需要能够同时处理数百万请求的高效服务器。实际上，我们可以在更基础的层面上解决处理更多客户端的问题，即通过使用非阻塞套接字。让我们接下来探讨它们。
- en: Asynchronous network I/O
  id: totrans-76
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 异步网络I/O
- en: As we saw in our `rudis_sync` server implementation, the synchronous I/O model
    can be a major bottleneck in handling multiple clients in a given period of time.
    One has to use threads to process more clients. However, there's a better way
    to scale our server. Instead of coping with the blocking nature of sockets, we
    can make our sockets non-blocking. With non-blocking sockets, any read, write,
    or connect operation, on the socket will return immediately, regardless of whether
    the operation completed successfully or not, that is, they don't block the calling
    code if the read and write buffers are partially filled. This is the asynchronous
    I/O model as no client needs to wait for their request completion, and is instead
    notified later of the completion or failure of the request.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在`rudis_sync`服务器实现中看到的，在给定时间段内处理多个客户端时，同步I/O模型可能成为主要瓶颈。必须使用线程来处理更多客户端。然而，有一种更好的方法来扩展我们的服务器。我们不必处理套接字的阻塞特性，我们可以使套接字非阻塞。使用非阻塞套接字，任何读取、写入或连接操作，在套接字上都会立即返回，无论操作是否成功完成，也就是说，如果读取和写入缓冲区部分填满，它们不会阻塞调用代码。这就是异步I/O模型，因为没有客户端需要等待其请求完成，而是稍后会被通知请求的完成或失败。
- en: The asynchronous model is very efficient compared to threads, but it adds more
    complexity to our code. In this model, because an initial read or write call on
    the socket is unlikely to succeed, we need to retry the interested operation again
    at a later time. This process of retrying the operation on the socket is called
    polling. We need to poll the sockets from time to time to see if any of our read/write/connect
    operations can be completed and also maintain state on how many bytes we have
    read or written so far. With large number of incoming socket connections, using
    non-blocking sockets entails having to deal with polling and maintenance of state.This
    soon blows up as a complex state machine. In addition to that polling  is a very
    in-efficient operation. Even if we don't have any events on our sockets. There
    are better approaches, though.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 与线程相比，异步模型非常高效，但它给我们的代码增加了更多复杂性。在这个模型中，由于对套接字的初始读取或写入调用不太可能成功，我们需要在稍后时间再次尝试感兴趣的运算。在套接字上重试运算的过程称为轮询。我们需要不时轮询套接字，以查看我们的读取/写入/连接操作是否可以完成，并维护我们迄今为止已读取或写入的字节数的状态。在大量传入套接字连接的情况下，使用非阻塞套接字意味着必须处理轮询和维护状态。这很快就会变成一个复杂的状态机。此外，轮询是一个非常低效的操作。即使我们没有套接字上的任何事件。尽管如此，还有更好的方法。
- en: On Unix-based platforms, polling mechanism on sockets is done through `poll` and `select`
    system calls, which are available on all Unix platforms. Linux has a better `epoll`
    API in addition to them. Instead of polling the sockets by ourselves, which is
    an inefficient operation, these APIs can tell us when the socket is ready to read
    or write. Where poll and select run a for loop on each requested socket, `epoll`
    runs in `O(1)` to notify any interested party of a new socket event.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在基于Unix的平台，套接字的轮询机制是通过`poll`和`select`系统调用完成的，这些调用在所有Unix平台上都可用。Linux除了它们之外，还有一个更好的`epoll`API。我们不必自己轮询套接字，这是一个低效的操作，这些API可以告诉我们套接字何时准备好读取或写入。与poll和select在每个请求的套接字上运行一个for循环不同，`epoll`以`O(1)`的复杂度通知任何感兴趣的方有新的套接字事件。
- en: The asynchronous I/O model allows you to handle a considerably larger amount
    of sockets than would be possible with the synchronous model, because we are doing
    operations in small chunks and quickly switching to serving other clients. Another
    efficiency is that we don't need to spawn threads, as everything happens in a
    single thread.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 异步I/O模型允许你处理比同步模型多得多的套接字数量，因为我们是在小块操作中进行的，并且快速切换到服务其他客户端。另一个效率是，我们不需要创建线程，因为所有操作都在单个线程中完成。
- en: To write asynchronous network applications with non-blocking sockets, we have
    several high quality crates in the Rust ecosystem.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用非阻塞套接字编写异步网络应用程序，Rust生态系统中有几个高质量的crate。
- en: Async abstractions in Rust
  id: totrans-82
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Rust中的异步抽象
- en: The async network I/O is advantageous, but programming them in their raw form
    is hard. Fortunately, Rust provides us with convenient abstractions in the form
    of third-party crates for working with asynchronous I/O. It alleviates the developer
    from most of the complex state machine handling when dealing with non-blocking
    sockets and the underlying socket polling mechanism. Two of the lower-layer abstractions
    that are available as crates are the `futures` and `mio` crates. Let's understand
    them in brief.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 异步网络I/O具有优势，但以原始形式编程它们是困难的。幸运的是，Rust通过第三方crate为我们提供了方便的抽象，用于处理异步I/O。它减轻了开发者处理非阻塞套接字和底层套接字轮询机制时的大部分复杂状态机处理。可用的底层抽象crate中有两个是`futures`和`mio`crate。让我们简要了解一下它们。
- en: Mio
  id: totrans-84
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Mio
- en: When working with non-blocking sockets, we need a way to check whether the socket
    is ready for the desired operation. The situation is worse when we have thousands,
    or more, sockets to manage. We can use the very inefficient way of running a loop,
    checking for the socket state, and performing the operation once it's ready. But
    there are better ways to do this. In Unix, we had the `poll` system call, to which
    you give the list of file descriptors you want to be monitored for events. It
    was then replaced by the `select` system call, which improved things a bit. However,
    both `select` and `poll` were not scalable as they were basically for loops under
    the hood and the iteration time went up linearly as more and more sockets were
    added to its monitor list.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 当与非阻塞套接字一起工作时，我们需要一种方法来检查套接字是否已准备好所需的操作。当我们有成千上万个或更多的套接字要管理时，情况会更糟。我们可以使用非常低效的方法，通过运行循环、检查套接字状态，并在准备好后执行操作。但还有更好的方法来做这件事。在
    Unix 中，我们有了 `poll` 系统调用，你可以向它提供你想要监控事件的一组文件描述符。然后它被 `select` 系统调用所取代，这稍微改进了事情。然而，`select`
    和 `poll` 都不可扩展，因为它们在底层基本上是循环，随着更多套接字被添加到其监控列表中，迭代时间呈线性增长。
- en: Under Linux, then came `epoll`, which is the current and most efficient file
    descriptor multiplexing API. This is used by most network and I/O applications
    that want to do asynchronous I/O. Other platforms have similar abstractions, such
    as **kqueue** in macOS and BSD. On Windows, we have **IO Completion Ports (IOCP)**.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Linux 下，随后出现了 `epoll`，这是当前最有效率的文件描述符多路复用 API。它被大多数想要进行异步 I/O 的网络和 I/O 应用程序所使用。其他平台也有类似的抽象，例如
    macOS 和 BSD 中的 **kqueue**。在 Windows 上，我们有 **IO Completion Ports (IOCP)**。
- en: It is these low-level abstractions that `mio` abstracts over, providing a cross-platform,
    highly efficient interface to all of these I/O multiplexing APIs. Mio is quite
    a low-level library, but it provides a convenient way to set up a reactor for
    socket events. It provides the same kind of networking primitives such as the
    `TcpStream` type as the standard library does, but these are non-blocking by default.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 正是这些低级抽象，`mio` 才进行了抽象，为所有这些 I/O 多路复用 API 提供了一个跨平台的、高度高效的接口。Mio 是一个非常底层的库，但它提供了一种方便的方式来设置用于套接字事件的反应器。它提供了与标准库相同的网络原语，例如
    `TcpStream` 类型，但这些默认是非阻塞的。
- en: Futures
  id: totrans-88
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Futures
- en: 'Juggling with mio''s socket polling state machine is not very convenient. To
    provide a higher-level API that can be used by application developers, we have
    the `futures` crate. The `futures` crate provides a trait named `Future`, which
    is the core component of the crate. A `future` represents the idea of a computation
    that is not immediately available, but might be available later. Let''s look at
    its type signature of the `Future` trait to get more information about it:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `mio` 的套接字轮询状态机中玩弄并不方便。为了提供一个可以由应用程序开发者使用的更高级别的 API，我们有了 `futures` 包。`futures`
    包提供了一个名为 `Future` 的特质，这是包的核心组件。`future` 代表了一种计算，它目前不可用，但可能以后会可用。让我们看看 `Future`
    特质的类型签名，以了解更多信息：
- en: '[PRE9]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'A `Future` is an associated type trait that defines two types: an `Item` type
    representing the value that the `Future` will resolve to and an `Error` type that
    specifies what error type the future will fail with. They are quite similar to
    the `Result` type in the standard library, but instead of getting the result right
    away, they don''t compute the immediately.'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '`Future` 是一个关联的类型特质，它定义了两种类型：一个表示 `Future` 将要解析到的值的 `Item` 类型，以及一个指定未来将失败时错误类型的
    `Error` 类型。它们与标准库中的 `Result` 类型非常相似，但它们不是立即获取结果，而是不立即计算。'
- en: A `Future` value on its own cannot be used to build asynchronous applications.
    You need some kind of reactor and an event loop to progress the future toward
    completion. By design, the only way to have them succeed with a value or fail
    with an error is to poll them. This operation is represented by the single require
    method known as `poll`. The method `poll` specifies what should be done to progress
    the future. A future can be composed of several things, chained one after another.
    To progress a future, we need a reactor and an event loop implementation, and
    that is provided by the `tokio` crate.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 单独的 `Future` 值不能用来构建异步应用程序。你需要某种类型的反应器和事件循环来推进未来的完成。按照设计，它们成功返回值或失败返回错误的方式只有通过轮询。这个操作由称为
    `poll` 的单个要求方法表示。`poll` 方法指定了如何推进未来。一个未来可以由几个东西组成，一个接一个地链在一起。要推进一个未来，我们需要一个反应器和事件循环实现，这由
    `tokio` 包提供。
- en: Tokio
  id: totrans-93
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Tokio
- en: Combining both of the above mentioned abstractions, and along a work stealing
    scheduler, event loop and a timer implementation we have the `tokio` crate, which
    provides a runtime for driving these futures to completion. With the `tokio` framework,
    you can spawn many futures and have them run concurrently.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 结合上述两种抽象，以及工作窃取调度器、事件循环和计时器实现，我们得到了`tokio` crate，它为驱动这些未来完成提供了运行时。使用`tokio`框架，你可以启动许多未来，并使它们并发运行。
- en: The `tokio` crate was born to provide a go-to solution for building robust and
    high-performance asynchronous networking applications that are agnostic of the
    protocol, yet provides abstractions for general patterns that are common in all
    networking applications. The `tokio` crate is technically a runtime consisting
    of a thread pool, and event loop, and a reactor for I/O events based on mio. By
    runtime, we mean that every web application developed with tokio will have the
    mentioned components above running as part of the application.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '`tokio` crate的诞生是为了提供一个通用的解决方案，用于构建健壮且高性能的异步网络应用程序，这些应用程序对协议不敏感，但提供了适用于所有网络应用程序中常见模式的抽象。从技术上来说，`tokio`
    crate是一个运行时，由线程池、事件循环和基于mio的I/O事件反应器组成。当我们提到运行时时，意味着使用tokio开发的每个Web应用程序都将运行上述组件作为应用程序的一部分。'
- en: Futures in the tokio framework run inside a task. A task is similar to a user
    space thread or a green thread. An executor is responsible for scheduling tasks
    for execution.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在tokio框架中，未来在任务内部运行。任务类似于用户空间线程或绿色线程。执行者负责调度任务以执行。
- en: When a future does not have any data to resolve or is waiting for data to arrive
    at the socket in case of a `TcpStream` client read, it returns a `NotReady` status.
    But, in doing this it also needs to register interest with the reactor to be notified
    again of any new data on the server.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 当一个未来没有要解析的数据，或者在一个`TcpStream`客户端读取的情况下等待数据到达套接字时，它返回一个`NotReady`状态。但是，在这样做的同时，它还需要向反应器注册兴趣，以便在服务器上收到任何新数据的通知。
- en: When a future is created, no work is performed. For the work defined by the
    future to happen, the future must be submitted to an executor. In tokio, tasks
    are user-level threads that can execute futures. In its implementation of the
    `poll` method, a task has to arrange itself to be polled later in case no progress
    can be made. For doing this it has to pass its task handler to the reactor thread.
    The reactor in case of Linux is mio the crate.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 当创建一个未来时，不会执行任何工作。为了使未来定义的工作发生，必须将未来提交给执行者。在tokio中，任务是以用户级线程的形式执行未来的。在其`poll`方法的实现中，任务必须安排自己以便稍后进行轮询，以防无法取得进展。为此，它必须将其任务处理器传递给反应器线程。在Linux的情况下，反应器是mio这个crate。
- en: Building an asynchronous redis server
  id: totrans-99
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建异步Redis服务器
- en: 'Now that we''re familiar with the asynchronous I/O solutions that the Rust
    ecosystem provides, it''s time to revisit our Redis server implementation. We''ll
    port our `rudis_sync` server to the asynchronous version using the `tokio` and
    `futures` crates. As with any asynchronous code, using `futures` and `tokio` can
    be daunting at first, and it can take time getting used to its API. However, We''ll
    try to make things easy to understand here. Let''s start by creating our project
    by running `cargo new rudis_async` with the following dependencies in `Cargo.toml`:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经熟悉了Rust生态系统提供的异步I/O解决方案，是时候回顾我们的Redis服务器实现了。我们将使用`tokio`和`futures` crate将我们的`rudis_sync`服务器移植到异步版本。与任何异步代码一样，一开始使用`futures`和`tokio`可能会感到困惑，并且可能需要时间来适应其API。然而，我们将尽力使这里的内容易于理解。让我们通过运行`cargo
    new rudis_async`并使用以下依赖项在`Cargo.toml`中创建我们的项目开始：
- en: '[PRE10]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'We are using a bunch of crates here:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这里使用了一堆crate：
- en: '`futures`: Provides a cleaner abstraction for dealing with async code'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`futures`：为处理异步代码提供了一个更清晰的抽象。'
- en: '`tokio`: Encapsulates mio and provides a runtime for running asynchronous code'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tokio`：封装mio并提供异步代码的运行时。'
- en: '`lazy_static`: Allows us to create a dynamic global variable that can be mutated'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`lazy_static`：允许我们创建一个可以修改的动态全局变量。'
- en: '`resp`: A crate that can parse Redis protocol messages'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resp`：一个可以解析Redis协议消息的crate。'
- en: '`tokio-codec`: This allows you to convert a stream of bytes from the network
    into a given type, which is parsed as a definite message according to the specified
    codec. A codec converts stream of bytes into a parsed message termed as a **Frame**
    in the tokio ecosystem.'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tokio-codec`：这允许你将网络中的字节流转换为给定的类型，该类型根据指定的编解码器被解析为确定的消息。在tokio生态系统中，编解码器将字节流转换为解析后的消息，称为**帧**。'
- en: '`bytes`: This is used with the tokio codec to efficiently convert a stream
    of bytes into a given *Frame*'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bytes`：这是与 tokio codec 一起使用，以高效地将字节流转换为给定的 *Frame*'
- en: 'Our initial code in `main.rs` follows a similar structure:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在 `main.rs` 中的初始代码遵循类似的结构：
- en: '[PRE11]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'We have a bunch of imports and the same `RUDIS_DB` in a `lazy_static!` block.
    We then have our function `main`:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有一系列导入和 `lazy_static!` 块中的相同 `RUDIS_DB`。然后我们有我们的 `main` 函数：
- en: '[PRE12]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: We parse the string that's been passed in as an argument or use a default address
    of `127.0.0.1:6378`. We then create a new `TcpListener` instance with `addr`.
    This returns us a future in `listener`. We then chain on this future by calling
    `incoming` on and invoke `for_each` on it which takes in a closure and call `handle_client`
    on it. This future gets stored as `server_future`.In the end, we call `tokio::run`
    passing in `server_future`. This creates a main tokio task and schedules the future
    for execution.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 我们解析传递给参数的字符串或使用默认地址 `127.0.0.1:6378`。然后我们使用 `addr` 创建一个新的 `TcpListener` 实例。这返回给我们一个存储在
    `listener` 中的 future。然后我们通过调用 `incoming` 在这个 future 上调用 `for_each`，它接受一个闭包并在其上调用
    `handle_client`。这个 future 被存储为 `server_future`。最后，我们通过传递 `server_future` 调用 `tokio::run`，这创建了一个主要的
    tokio 任务并安排了 future 的执行。
- en: 'In the same file, our `handle_client` function is defined like so:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 在同一文件中，我们的 `handle_client` 函数定义如下：
- en: '[PRE13]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: In `handle_client`, we first split our `TcpStream` into a writer (`tx`) and
    reader (`rx`) half by first converting the stream to a framed future calling framed
    on `RespCodec` receives the `client` connection and converts it into a framed
    future by calling framed on `RudisFrame`. Following that, we call `split` on it,
    which converts the frame into a `Stream` and `Sink` future, respectively. This
    simply gives us a `tx` and `rx` to read and write from the client socket. However,
    when we read this, we get the decoded message. When we write anything to `tx`,
    we write the encoded byte sequence.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `handle_client` 函数中，我们首先将我们的 `TcpStream` 分割成一个写入器（`tx`）和一个读取器（`rx`）部分，首先将流转换为带有
    `RespCodec` 的 framed future，通过调用 `RudisFrame` 上的 framed 接收客户端连接并将其转换为 framed future。随后，我们调用它上的
    `split` 方法，该方法将帧转换为 `Stream` 和 `Sink` future。这仅仅给我们提供了 `tx` 和 `rx` 来从客户端套接字进行读写。然而，当我们读取它时，我们得到解码后的消息。当我们向
    `tx` 写入任何内容时，我们写入编码的字节序列。
- en: On `rx`, we call `and_then` passing the `process_client_request` function, which
    will resolve the future to a decoded frame. We then take the writer half `tx`,
    and call `send_all` with the `reply`. We then spawn the future task by calling
    `tokio::spawn`.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `rx` 上，我们调用 `and_then` 并传递 `process_client_request` 函数，该函数将 future 解析为解码后的帧。然后我们获取写入器部分
    `tx`，并使用 `reply` 调用 `send_all`。然后我们通过调用 `tokio::spawn` 来启动 future 任务。
- en: 'In our `codec.rs` file, we have defined `RudisFrame`, which implements `Encoder`
    and `Decoder` traits from the `tokio-codec` crate:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的 `codec.rs` 文件中，我们定义了 `RudisFrame`，它实现了来自 `tokio-codec` crate 的 `Encoder`
    和 `Decoder` traits：
- en: '[PRE14]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: The `Decoder` implementation specify how to parse incoming bytes into a `resp::Value`
    type, whereas the `Encoder` trait specifies how to encode a `resp::Value` to a
    stream of bytes to the client.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '`Decoder` 实现指定了如何将传入的字节解析为 `resp::Value` 类型，而 `Encoder` trait 指定了如何将 `resp::Value`
    编码为发送到客户端的字节流。'
- en: 'Our `commands.rs` file implementation is the same as the previous one so we''ll
    skip going through that. With that said, let''s try our new server by running
    `cargo run`:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的 `commands.rs` 文件实现与之前相同，所以我们将跳过那部分。话虽如此，让我们通过运行 `cargo run` 来尝试我们的新服务器：
- en: '![](img/29a2da81-24b7-486d-90bd-114ef84b39e5.png)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/29a2da81-24b7-486d-90bd-114ef84b39e5.png)'
- en: 'With the official redis-cli client, we can connect to our server by running:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 使用官方的 redis-cli 客户端，我们可以通过运行以下命令连接到我们的服务器：
- en: '[PRE15]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Here''s a session of running `redis-cli` against `rudis_async` server:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是一个运行 `redis-cli` 对 `rudis_async` 服务器进行会话的示例：
- en: '![](img/b063d555-3e61-454c-a1c7-d34439dbc648.png)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/b063d555-3e61-454c-a1c7-d34439dbc648.png)'
- en: Summary
  id: totrans-127
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: Rust is very well-equipped and suitable for providing higher-performance, quality,
    and security for network applications. While built-in primitives are well-suited
    to a synchronous application model, for asynchronous I/O, Rust provides rich libraries
    with well-documented APIs that help you build high-performance applications.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: Rust 非常适合提供高性能、质量和安全性，适用于网络应用程序。虽然内置原语非常适合同步应用程序模型，但对于异步 I/O，Rust 提供了丰富的库和良好的文档
    API，这有助于你构建高性能应用程序。
- en: In the next chapter, we'll step up the network protocol stack and and learn
    how to build web applications with Rust.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将提升网络协议栈，并学习如何使用 Rust 构建 Web 应用程序。
