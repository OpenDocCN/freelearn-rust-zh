- en: FFI and Embedding – Combining Rust and Other Languages
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Up until this point in the book, we've discussed Rust more or less in isolation.
    Rust was intentionally designed to integrate with other programming languages
    by calling external programming languages through its **Foreign Function Interface**
    (**FFI**) and by being embedded itself. Many modern programming languages offer
    FFI, easy embedding, or both. Python, for instance, can very conveniently call
    out to libraries with C calling conventions and can be embedded with a little
    forethought. Lua, a high-level and garbage-collected language like Python, has
    a convenient FFI and can be embedded without much trouble. Erlang has a small
    handful of FFI interfaces but Erlang is not, itself, easily embedded into user-space
    environments. Amusingly, it's fairly straightforward to compile Erlang into an
    RTOS image.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we'll discuss calling out to foreign code in Rust and embedding
    Rust into foreign programming languages. We'll start off by extending the corewars
    evolver program —feruscore—that we covered at the tail end of [Chapter 8](d4802512-564b-4037-9407-b6035bd38f31.xhtml),
    *High-Level Parallelism – Threadpools, Parallel Iterators, and Processes*. You
    are encouraged to read that material before starting this chapter. After we've
    extended feruscore by embedding a C MARS simulator inside it, we'll move on to
    calling Rust functions from a C program. We'll demonstrate embedding Lua into
    a Rust system for convenient scripting and close the chapter by embedding Rust
    in high-level garbage-collected languages—Python and Erlang.
  prefs: []
  type: TYPE_NORMAL
- en: 'By the end of this chapter, we will have:'
  prefs: []
  type: TYPE_NORMAL
- en: Adapted the feruscore project from the last section to incorporate a C simulator
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Demonstrated the inclusion of Lua code into a Rust project
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Demonstrated the inclusion of Rust code into a C project
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Demonstrated the inclusion of Rust code into a Python project
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Demonstrated the inclusion of Rust code into an Erlang/Elixir project
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Embedding C into Rust – feruscore without processes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When we wrapped up our discussion of feruscore in the previous chapter, we'd
    constructed a program that could discover corewars warriors through simulated
    natural selection. This was done by writing evolved warriors out to disk, using
    Rust's OS process interface to call out to pmars—the de facto standard MARS—and
    competing them to discover their relative fitness. We used Rayon—Rust's very convenient
    data parallelism library—to distribute the workload of competitions between available
    CPUs. Unfortunately, the implementation was pretty slow. Building a tournament
    selection criteria was maybe more difficult to express than we might have hoped—though
    I'm sure there a bright-spark of a reader out there who will improve that substantially
    and wow me. The real pain point was serializing *every* warrior to disk multiple
    times, allocating similar structures repeatedly to establish each round, and then
    eating pmars' allocation and parsing overhead. It's this last step, calling out
    to an external program to run competitions, is something we'll address in this
    chapter. We will also address the other two issues because, well, why not go all-in?
  prefs: []
  type: TYPE_NORMAL
- en: Not all of feruscore's source code appears in this chapter. Some of it was discussed
    in-depth in the previous chapter, some of it—such as benchmarking code—would be
    a rehash of material already covered in the book. The C code is not printed in
    its entirety as it's very dense and very long. You can find the full listing in
    the book's source repository.
  prefs: []
  type: TYPE_NORMAL
- en: The MARS C interface
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Corewars is a venerable game and there are many implementations of MARS out
    there. pMARS, like I mentioned, is the defacto standard, implementing the '94
    ICWS draft and adding later additions, such as new instructions and a thing called
    *p-space*, that we won't go into here. Corewars has never been serious business.
    Many of the MARS available online today have traded code back and forth over the
    years, have been written with varying levels of attention to correctness, and
    sometimes programmed for older machines where multiprocessing was a concern for
    research labs. Most make no distinction between their internal library interface
    and executable consumer, like Rust programs do. Some blessed few are designed
    to be embedded, or, at least, are extractions of older MARS codebases that can
    be extended. Some blessed few of those don't use static globals in their implementations
    and can be embedded in a multiprocessing environment, such as feruscore.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the grand tradition of MARS implementations, we will take an existing, public
    domain MARS, whittle it down to a manageable core, and put a new spin on it. Specifically,
    the feruscore introduced in this chapter embeds exhaust 1.9.2 ([http://corewar.co.uk/pihlaja/exhaust/](http://corewar.co.uk/pihlaja/exhaust/)),
    written by M. Joonas Pihlaja in the early 2000s. Pihlaja seems to have extracted
    select code from pMARS, especially in and around exhaust''s main and parser functions.
    We aren''t after any of that code. What we need is the simulator. This means that
    we can toss out anything to do with parsing, and any support code needed for exhaust''s
    `main` function. The extracted code we require lives in the feruscore project
    root, in `c_src/`. The functions we''ll embed are all implemented in `c_src/sim.c`.
    These are from `c_src/sim.h`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The `sim_alloc_bufs` function is responsible for allocating the internal storage
    of a blank `mars_t`, the structure on which simulation is performed. `sim_clear_core`
    clears `mars_t` between rounds, setting core memory to `DAT`, and resetting any
    warrior queues. `sim_load_warrior` loads the warrior into core memory, the warrior
    really just being a pointer to an array of instructions—`insn_t`—with the `len`
    passed length. `sim_mw` runs the simulation, reading the warrior positions from
    `war_pos_tab`, and writing to `death_tab` when a warrior completely dies.
  prefs: []
  type: TYPE_NORMAL
- en: Creating C-structs from Rust
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now, how do we call these functions from Rust? Moreover, how do we create instances
    of `mars_t` or `insn_t`? Well, recall back in [Chapter 03](605ce307-29ed-4b5a-961e-8d327467b84f.xhtml),
    *The Rust Memory Model – Ownership, References, and Manipulation*, that Rust allows
    control over memory layout in structures. Specifically, all Rust structures are
    implicitly `repr(Rust)`, types aligned to byte boundaries with structure fields
    being reordered as the compiler sees fit, among other details. We also noted the
    existence of a `repr(C)` for structures, in which Rust would lay out a structure's
    memory representation in the same manner as C. That knowledge now comes to bear.
  prefs: []
  type: TYPE_NORMAL
- en: 'What we will do is this. First, we''ll compile our C code as a library and
    rig it to link into feruscore. That''s done by placing a `build.rs` at the root
    of the project and using the cc ([https://crates.io/crates/cc](https://crates.io/crates/cc))
    crate to produce a static archive, like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Cargo will produce `libmars.a` into `target/` when the project is built. But,
    how do we make `insn_t`? We copy the representation. The C side of this project
    defines `insn_t` like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '`uint16_t a` and `uint16_t b` are the *a*-field and *b*-field of the instruction,
     where `uint16_t` is a compressed representation of the `OpCode`, `Modifier`,
    and `Modes` in an instruction. The Rust side of the project defines an instruction
    like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'This is the exact layout of the `inst_t` C. The reader will note that this
    is quite different from the definition of `Instruction` we saw in the previous
    chapter. Also, note that the field names do not matter, only the bit representation.
    The C structure calls the last field of the struct in, but this is a reserved
    keyword in Rust, so it is `ins` in the Rust side. Now, what is going on with that
    `ins` field? Recall that the `Mode` enumeration only had five fields. All we really
    need to encode a mode is three bits, converting the enumeration into numeric representation.
    A similar idea holds for the other components of an instruction. The layout of
    the `ins` field is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'The `Mode` for a-field is encoded in bits 0, 1 and, 2\. The `Mode` for b-field
    is in bits 3, 4, and 5, and so on for the other instruction components. The last
    two bits, 14 and 15, encode a `flag` that is almost always zero. A non-zero flag
    is an indicator to the simulator that the non-zero instruction is the `START`
    instruction—the 0^(th) instruction of a warrior is not necessarily the one executed
    first by MARS. This compact structure requires a little more work on the part
    of the programmer to support it. For instance, the `Instruction` can no longer
    be created directly by the programmer but has to be constructed through a builder.
    The `InstructionBuilder`, defined in `src/instruction.rs`, is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'As always, we have to keep track of the core size. Building the builder is
    straightforward enough, by this point:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Writing a field into the instruction requires a little bit manipulation. Here''s
    writing a `Modifier`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'The constant `MODIFIER_MASK` is defined in a block at the top of the source
    file with the other field masks:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Observe that the relevant bits in the masks are 1 bits. In `InstructionBuilder::modifier`
    we `&=` the negation of the mask, which boolean-ands `ins` with the negation of
    the modifier mask, zero-ing the `Modifier` that was previously there. That done,
    the `Modifier` encoded as u16 is shifted left and boolean-or'ed into place. The
    `trailing_zeros()` function returns the total number of contiguous zeros in the
    lower end of a word, the exact number we need to shift by for each mask. Those
    readers that have done bit-manipulation work in other languages may find this
    to be very clean. I think so as well. Rust's explicit binary form for integers
    makes writing, and later, understanding, masks a breeze. Common bit-manipulation
    operations and queries are implemented on every basic integer type. Very useful.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `OpCode` layout has changed somewhat. We don''t `repr(C)` the enum, as
    the bit representation does not matter. What does matter, since this is enumeration
    is field-less, is which integer the variants cast to. First in the source maps
    to 0, the second to 1, and so forth. The C code has op-codes defined like so in
    `c_src/insn.h`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'The Rust version is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: The other instruction components have been shuffled around just a little bit
    to cope with the changes required by the C code. The good news is, this representation
    is more compact than the one from the previous chapter and should probably be
    maintained, even if all the C code were ported into Rust, a topic we'll get into
    later. But—and I'll spare you the full definition of `InstructionBuilder` because
    once you've seen one set-function you've seen them all—all this bit fiddling does
    make the implementation harder to see, and to correct at a glance. The instruction
    module now has QuickCheck tests to verify that all the fields get set correctly,
    meaning they can be ready right back out again no matter how many times fields
    are set and reset. You are encouraged to examine the QuickCheck tests yourself.
  prefs: []
  type: TYPE_NORMAL
- en: The high-level idea is this—a blank `Instruction` is made and a sequence of
    change orders is run over that Instruction—momentarily shifted into an `InstructionBuilder`
    to allow for modification—and then the changed field is read and confirmed to
    have become the value it was changed to. The technique is inline with what we've
    seen before elsewhere.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, what about that `mars_t`? The C definition, in `c_src/sim.h`, is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'The `nWarriors` field sets how many warriors will be in the simulation, which
    for feruscore is always two cycles controls the number of cycles a round will
    take before ending if both warriors are still alive, processes the maximum number
    of processes available, and `maxWarriorLength` shows the maximum number of instructions
    a warrior may be. All of these are more or less familiar from the last chapter,
    just in a new programming language and with different names. The final three fields
    are pointers to arrays and are effectively private to the simulation function.
    These are allocated and deallocated by `sim_alloc_bufs` and `sim_free_bufs`, respectively.
    The Rust side of this structure looks like so, from `src/mars.rs`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'The only new type here is `WarTable`. Even though our code will never explicitly
    manipulate the warrior table, we do still have to be bit-compatible with C. The
    definition of `WarTable` is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: We could have maybe got away with just making these private fields in `Mars`
    pointers to void in `mars_st`, but that would have reduced type information on
    the C side of the project and this approach might hamper future porting efforts.
    With the type explicit on the Rust side of the project, it's much easier to consider
    rewriting the C functions in Rust.
  prefs: []
  type: TYPE_NORMAL
- en: Calling C functions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that we can create Rust structs with C-bit layout, we can start passing
    that memory down into C. It''s important to understand, this is an inherently
    unsafe activity. The C code might fiddle with memory in a way that breaks Rust''s
    invariants and the only way we can be sure this isn''t true is auditing the C
    code ahead of time. This is the same with fuzzing, which we''ll do too. How do
    we link with `libmars.a`? A small `extern` block will do it, in `src/mars.rs`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'With `#[link(name = "mars")]`, we''re instructing the compiler to link to the
    `libmars.a` produced in the build process. If we were linking to a system library,
    the approach would be the same. The Rust Nomicon section on FFI—referenced in
    the *Further reading* section at the end of this chapter—links to libsnappy, for
    example. The extern block informs the compiler that these functions will need
    to be called with the C ABI, not Rust''s. Let''s compare `sim_load_warrior` side
    by side. Here is the C version:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is the Rust version:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: These are similar. C doesn't have the same mutability concept as Rust, though
    there are const annotations for code that Rust picks up for free. We've enhanced
    that by making all of Instruction's query functions take `&self`. Rule of thumb—unless
    the C is const-correct, you should probably assume the Rust needs a `*mut`. This
    isn't always true, but it saves a fair deal of headache. Now, on that notion,
    the careful reader may note that as I ported exhaust's code into feruscore, I
    adapted it to use `stdint.h`. In the unaltered code, `pos` has the unsigned int
    type or `usize`. The simulator C code assumes `pos` will be at least 32 bits wide,
    hence the explicit conversation to a 32-bit integer. This wasn't entirely necessary,
    but it's good form to used fixed-width types as they minimize surprises moving
    between CPU architectures.
  prefs: []
  type: TYPE_NORMAL
- en: Managing cross-language ownership
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Rust is now aware of the C functions, and we have our internal structs reworked
    to use C layout: it is time to link up the C functions that manipulate `mars_t`
    with our `Mars`. Because we''re sharing ownership of `Mars` between the Rust allocator
    and the C allocator, we''ve got to be careful to initialize the `Mars` struct
    with null pointers in the fields that C will own, like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'This `MarsBuilder` is a builder-pattern for producing a `Mars`. The remainder
    of the implementation works how you might expect:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Back to `MarsBuilder::freeze(self) -> Mars`. This function creates a new `Mars`
    and then passes it immediately into `sim_alloc_bufs`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: '`&mut mars` automatically coerces into `*mut mars` and, as we know from previous
    chapters, dereferencing a raw pointer is unsafe. The fact that it''s *C* dereferencing
    the raw pointer is icing on the cake. Now, let''s take a look at `sim_alloc_bufs`
    and get a sense of what''s going on. In `c_src/sim.c`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: The three fields owned by C—`coreMem`, `queueMem`, and `warTab`—are allocated
    according to the size of the structs being stored and the return is a boolean-and
    of the `malloc` returns, a short way of determining whether `malloc` ever returned
    `NULL`, signaling that no more memory was available on-system. Had we decided
    to add a new field into the Rust struct and not updated the C struct to reflect
    this change, these stores would be too small. Eventually, some code somewhere
    would reach past the bounds of an array and crash. No good, that.
  prefs: []
  type: TYPE_NORMAL
- en: But! We've just called C code from Rust.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s talk about ownership for a second. `Mars` is a structure not wholly
    owned by Rust, and not wholly owned by C. That''s fine and is also not uncommon,
    especially if you''re partially (or completely) porting a C codebase into Rust.
    It does mean we''ve got to be careful about `Drop`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'As we''ve seen in previous chapters, we have to arrange for explicit `Drop`
    when there''s raw memory in use. `Mars` is no exception. The call here to `sim_free_bufs`
    clears up the C-owned memory and Rust takes care of the rest. If cleanup were
    more difficult—as sometimes happens—you''d have to take care to avoid deferencing
    the C-owned pointers post-free. `sim_free_bufs` is a brief implementation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Running the simulation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: All that's left to do is run warriors in simulation. In the previous chapter,
    an `Individual` was responsible for managing its own pmars process. Now, `Mars`
    will be responsible for hosting the competitors, which you may have gleaned from
    the C API. We simply don't have any space in `Individual` to store something,
    and by pushing competition into `Mars`, we can avoid allocation churn on temporary
    `Mars` structures.
  prefs: []
  type: TYPE_NORMAL
- en: 'The compete function that was formerly bound to `Individual` has now been moved
    to `Mars`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'The C API requires that we calculate the warrior offsets and take care to not
    overlap them. The approach taken here is to randomly place the left Individual,
    determine whether it''s in the upper or lower core, and then place the right Individual,
    taking care with both to not place them past the `end` of the core. The actual
    implementation of the competition is `compete_inner`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'We call `Individual::as_ptr() -> (u16, *const Instruction)` to get a raw view
    of the chromosome of the Individual and its length. Without this, we''ve got nothing
    to pass down to the C functions. `warrior_position_table` informs MARS which instructions
    are the start of its competitors. We could search out the `START` flag in the
    warriors and place that in `warrior_position_table`. This is an improvement left
    for the reader. The deaths table will be populated by the simulator code. If both
    warriors die during competition, the array will be `[0, 1]`. The death table is
    populated with `u32::max_value()` to make distinguishing no-result from result
    easy enough. Before starting the competition, we have to clear the simulator—which
    might be filled with instructions from a previous bout:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'If you pull up the `sim_clear_core` implementation, you''ll find a memset to
    0 over `core_mem`. Recall that `DAT` is the 0^(th) variant of the `Instruction`
    enumeration. Unlike `pmars`, this simulator must use `DAT` as a default instruction,
    but it does make resetting the field very fast. `sim_clear_core` also clears up
    the process queue and other C-owned storage. Loading the warriors is a matter
    of plugging in the information we''ve already computed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'If the result is non-zero, that''s an indicator that some serious and non-recoverable
    fault has happened. `sim_load_warrior` is an array operation, writing the warrior
    Instructions into `core_mem` at the defined offsets. We could, very conceivably,
    rewrite the functions of `sim_clear_core` and `sim_load_warrior` in Rust if we
    wanted to. Finally, field cleared and warriors loaded, we are able to simulate:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: The `sim_mw` function returns the total number of warriors left alive at the
    end of the simulation run. If this value is `-1`, there's been some catastrophic,
    unrecoverable error.
  prefs: []
  type: TYPE_NORMAL
- en: Now, because we have a nice type system to play with, we don't really want to
    signal results back to the user with a vector of integers. We preserve the `Winner`
    type seen
  prefs: []
  type: TYPE_NORMAL
- en: 'in the previous chapter, doing a quick conversion before returning:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'You may have noticed that `Winner` implements `Add`, allowing compete to signal
    how many rounds the warriors won. `impl Add for Winner` is also in `src/mars.rs`,
    should you be curious to see it. As a final sanity test around `Mars`, we confirm
    that the Imp will lose to Dwarf more often than other outcomes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: Recall that an Imp can't self-kill, only propagate. The Dwarf bombs core memory
    at regular, increasing offsets. An Imp versus Dwarf competition, then, is a race
    between Imp finding Dwarf's instructions and Dwarf dropping a `DAT` in the path
    of an Imp.
  prefs: []
  type: TYPE_NORMAL
- en: Fuzzing the simulation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Feruscore has been changed in this chapter to include raw memory access in
    both Rust and through FFI. The responsible thing to do is fuzz `Mars` and make
    sure we''re not causing segmentation faults. We''ll use AFL, which we discussed
    back in [Chapter 2](8c61da2f-08c8-40be-89d4-d8afa8510850.xhtml), *Sequential Rust
    Performance and Testing*, and again in [Chapter 5](e2de1ba7-c291-494e-82da-37fee7323c1d.xhtml),
    *Locks – Mutex, Condvar, Barriers, and RWLock*. The fuzz target is `src/bin/fuzz_target.rs`.
    The trick with fuzzing is ensuring stability. That is, AFL can''t really do its
    work if for some input applied multiple times multiple paths come out. Fuzzing
    is more efficient in the case of a deterministic system. We were careful to make
    `Mars::compete_inner` deterministic, where `Mars::compete` uses randomness to
    determine warrior positions. Fuzzing, then, will go through `compete_inner` only.
    The preamble for `fuzz_target` doesn''t contain any new crates:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Remember that AFL passes a byte slice through stdin and the fuzzing target
    is responsible for deserializing that array into something sensible for itself.
    We''ll build up a `Config` structure:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Hopefully, these fields are familiar. The `rounds`, `core_size`, `cycles`,
    and `processes` each affect the MARS environment. The `max_warrior_length`, `left_chromosome_size`,
    and `right_chromosome_size` affect the two individuals that will be made to compete.
    `left` and `right` are those `Individual` instances. `left_pos` and `right_pos`
    set where the warriors will be placed in the MARS core memory. The numbers that
    we''ll deserialize from the byte slice won''t always be entirely sensible, so
    there''ll be some cleanup needed, like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'It doesn''t make any sense for there to be 0 rounds, as an example, so we say
    thatthere must be at least one round. Likewise, we need two processes, desire
    at least four warrior instructions, and so forth. Creating the left and right
    warriors is a matter of passing the byte reader into `Config::mk_individual`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: '`Config::mk_individual` deserializes into `InstructionBuilder`. The whole thing
    is kind of awkward. While we can convert a field-less Enum into an integer, it''s
    not possible to go from an integer to a field-less Enum without some hairy match
    statements:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we''ve established the `InstructionBuilder` and read the `Mode` for a-field
    and b-field out from the byte slice. If a field is added, we''ll have to come
    through here and update the fuzzing code. It''s a real pain. Reading the `Modifier`
    out works the same way:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'As does reading out the `OpCode`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'Producing an instruction is simple enough, thanks to the builder pattern in
    use here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'Moving back up to `Config::new`, we create the left and right positions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'The `adjust_pos` function is a small thing, intended to keep warrior positions
    properly in bounds:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'It''s entirely possible that the warriors will overlap with this calculation.
    That is okay. Our ambition with fuzzing is not to check the logic of the program,
    only to seek out crashes. In fact, if overlapping two warriors causes a crash,
    that''s a fact we need to know. The close of `Config::new` is fairly straightforward:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'After all that, the main function of `fuzz_target` is minimal:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: '`Stdin` is captured and a `Cursor` built from it, which we pass into `Config::new`,
    as explained earlier. The resulting `Config` is used to fuel `MarsBuilder`, and
    the `Mars` is then the arena for competition between the two fuzzing `Individual`
    instances that may or may not overlap. Remember, before running AFL, be sure to
    run `cargo afl build`—release and not cargo build —release. Both will work, but
    the first is significantly faster to discover crashes, as AFL''s instrumentation
    will be inlined in the executable. I''ve found that even a single instance of
    `cargo afl fuzz -i /tmp/in -o /tmp/out target/release/fuzz_target` will run through
    AFL cycles at a good clip. There aren''t many branches in the code and, so, few
    paths for AFL to probe.'
  prefs: []
  type: TYPE_NORMAL
- en: The feruscore executable
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The final thing left to cover is `src/bin/feruscore.rs`. The careful reader
    will have noted that there''s been a suspicious lack of rayon in the implementation
    so far. In fact, rayon is not in use in this version. Here''s the full `Cargo.toml`
    for the project:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'As mentioned at the start of the chapter, there were two issues with feruscore
    aside from calling out to an OS process: repeat allocation of similar structures
    and poor control over tournaments. Viewed a certain way, comparing `Individual`
    fitness is a sorting function. Rayon does have a parallel sorting capability,
    `ParallelSliceMut<T: Send>::par_sort(&mut self)`, where `T: Ord`. We could make
    use of that, defining an `Ord` for `Individual` that allocated a new `Mars` for
    every comparison. Many tiny allocations is a killer for speed, though. A thread-local
    `Mars` could reduce that to a single allocation per thread, but then we''re still
    giving up some control here. For instance, without inspecting rayon''s source,
    can we be sure that population chunks are going to be of roughly equal size? Usually,
    this is not a concern, but it is for us here. Rayon''s requiring that we perform
    a fold and then a reduce step is also extra work we don''t necessarily have to
    do if we adjust our ambitions some.'
  prefs: []
  type: TYPE_NORMAL
- en: One common method to deal with parallelizing genetic algorithms, and the one
    we'll take now, is to make islands that undergo evolution in parallel. The user
    sets a global population, where  this population is split among islands, and threads
    are assigned an island to simulate for some number of generations. After that
    limit of generations is up, the island populations are merged, shuffled, and redistributed
    to islands. This has the benefit of reducing cross-thread communication, which
    potentially comes with cache locality issues.
  prefs: []
  type: TYPE_NORMAL
- en: 'The preamble of `src/bin/feruscore.rs` is straightforward:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'The configuration and reporting globals are somewhat reduced, compared to the
    last chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'The `report` function is almost entirely the same as in last chapter, except there
    are a few less atomic variables to read from. checkpoint is also almost entirely
    the same. We''ll skip reprinting both functions in the interest of space. What
    is new is `sort_by_tournament`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'This function sorts a population by fitness, based on the result of competition
    inside the passed `Mars`. The reader will note that it''s not a true sort in that
    the last element is the most fit, but that the last element is the winner of the
    first tournament, the second to last the winner of the second tournament, and
    so forth. Only `population.len() / 2` competitions are held and the resulting
    champions compare favorably to a population precisely sorted by fitness. The reader
    is encouraged to experiment with their own implementation of `sort_by_tournament`.
    Now, let''s look at the `main` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'The total number of islands in a feruscore run will vary by the number of CPUs
    available on-system. Each island causes two synchronous MPSC channels to be created,
    one for the main thread to push populations into the worker thread and one for
    the worker thread to push populations back to the main. The implementation refers
    to these as `in_*` and `out_*` senders and receivers. You can see again that we''re
    building up a population of random `Individual` warriors and pushing the ringers
    in, though the island population is not `POPULATION_SIZE`, but an even split of
    `POPULATION_SIZE` by the number of available CPUs. The reporting thread is started
    after the island threads have their populations, mostly just to avoid UI spam:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: The report function is much the same as it was in the previous chapter's discussion
    of feruscore and I'll avoid listing it here for brievity's sake.
  prefs: []
  type: TYPE_NORMAL
- en: 'The final chunk of the `main` function is the recombining loop. When the island
    threads finish their competitions, they write into their out sender, which gets
    picked up by the recombination loop:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'Once all the islands have been merged together, the whole lot is shuffled:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'That''s one generation done. We `checkpoint`, this time doing an additional
    tournament to pull the save winners from the global population:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, the population is split back up and sent to the island threads:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, what is island doing? Well, it''s an infinite loop pulling from the population
    assignment receiver:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'Now a `Mars` is allocated above the loop, meaning we''ll only ever do `num_cpu::get()`
    allocations of this structure per feruscore run. Also recall that `Receiver::recv`
    blocks when there is no data in the channel, so island threads don''t burn up
    CPU when there''s no work for them. The interior of the loop should be familiar.
    First, the `Individual` warriors are put into competition:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'Reproduction is done by taking high-ranking members of the population and producing
    two children into the low reaches of the population until the total number of
    children needed per generation is reached:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'New to this implementation, we also introduce random new population members
    just before the newly introduced children:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'Random infusion can help tamp down premature convergence in a population. Remember,
    simulated evolution is a kind of state-space search. Something else that has changed
    is that all members of the population have a chance of mutation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we push the population back up to the recombination thread, having
    worked the population over thoroughly:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'With all the changes made here—cutting back on small allocations, reducing
    total number of competitions per generation, removing pmars parsing plus spawn
    overhead—the implementation is substantially faster. Recall that the implementation
    in the last chapter struggled to peak 500 competitions—or `BATTLES` as the UI
    has it—per second. Here''s a report diagnostic from a recent eight-hour run I
    did:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: That's 14,000 battles per second on an 8,000-sized core memory, or around 650
    generations per hour. Still not blazingly fast, but enough that with some time
    you can start to get pretty mediocre players being produced. Reducing core memory
    size will improve the runtime, as will limiting the maximum length of the warriors.
    Those who are interested in building a better evolver would do well to investigate
    different ways of assessing fitness, of introducing more ringers, and seeing whether
    porting `sim_mw` into Rust wouldn't improve runtime some. This simulator doesn't
    support the full scope of instructions that pMARS does, so that's also an area
    for improvement.
  prefs: []
  type: TYPE_NORMAL
- en: I'd love to hear about what you come up with.
  prefs: []
  type: TYPE_NORMAL
- en: Embedding Lua into Rust
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Many of the programs we've discussed in this book use a *report* thread to notify
    the user of the running behavior of the program. Each of these report functions
    have been coded in Rust, an unchanging part of the executable. What if, however,
    we wanted end-users to be able to supply their own reporting routine? Or, consider
    the cernan project ([https://crates.io/crates/cernan](https://crates.io/crates/cernan)),
    discussed previously in this book, which supports a *programmable filter*, an
    online data-stream filter that can be programmed by end-users without changing
    the cernan binary. How do you pull such a trick off?
  prefs: []
  type: TYPE_NORMAL
- en: A common answer, not just in Rust but in many compiled languages, is to embed
    a Lua interpreter ([https://www.lua.org/](https://www.lua.org/)) and read user
    programs in at startup. It's such a common answer, in fact, that there are many
    Lua embeddings to choose from in the crates ecosystem. We'll use rlua ([https://crates.io/crates/rlua](https://crates.io/crates/rlua))
    here as it's a safe choice and the project documentation is very good. Other Lua
    embeddings suit different ambitions. Cernan uses a different, not necessarily
    safe embedding, for example, because we need to allow end-users to define their
    own functions.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the previous chapter, we wrote a project called `sniffer` whose purpose
    was threefold—collect Ethernet packets on an interface, report about them, and
    echo the Ethernet packet back. Let''s take that program and adapt it so that users
    can decide how to report with custom scripts. The `Cargo.toml` file of the project
    is a little different, including the rlua dependency and dropping the thread-hungry
    alternative executable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: 'The preamble to the sniffer program, defined in `src/bin/sniffer.rs`, holds
    no surprises for us:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: 'We''re importing `Function` and `Lua` from the rlua crate, but that''s about
    all that is new. The `SKIPPED_PACKETS` and `Payload` details are unchanged:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: 'I have removed the echoing of Ethernet packets in this example as it''s not
    necessarily a kind thing to do on a busy Ethernet network. `watch_interface`,
    as a result, is a little more svelte than it used to be:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: 'The `timer` function is also unchanged:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: 'The `main` function now picks up an additional argument, intended to be the
    on-disk path of a Lua function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: 'The function is intended to handle the `Payload::Pulse` that comes in from
    the timer thread. The gather function from the previous chapter no longer exists.
    To actually do something with the user-supplied function, we''ll have to create
    a new Lua VM via `rlua::Lua::new()` and then load the function into it, like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: 'The `eval` function is brief and mostly to do with reading from disk:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: The lua-specific bit there is `lua.eval(s, name)`. This evaluates the Lua code
    read from disk and returns function, a Rust-callable bit of Lua. Any user-supplied
    name in the Lua source itself is ignored and the name exists to add context to
    error messages on the Rust side of things. rlua does not expose loadfile in its
    Rust API, though other Lua embeddings do.
  prefs: []
  type: TYPE_NORMAL
- en: 'The next bit of the `main` function is mostly unchanged, though the packet
    buffer channel has been increased from 10 elements to `100`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, things are going to change. First, we create three Lua tables for storing
    the components of the `Payload::Packet`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: 'In the previous chapter, we used three `HashMap`s but, now, we need something
    we can easily pass into Lua. The main thread is responsible for the role that
    gather used to play: collecting `Payload` instances. This saves a thread and means
    we don''t have to carefully arrange for sending the Lua VM across thread boundaries:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we''ve started pulling payloads from the receiver and have handled `Payload::Packets`
    coming across. Notice how the tables we created just before this loop are now
    being populated. The same basic aggregation is in play; keep a running tally of
    the `Packet` components coming in. A more adventurous reader might extend this
    program to allow for the Lua side to build its own aggregation. Now all that remains
    is to handle `Payload::Pulse`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: 'The `pulse_fn` created earlier is called with a four-tuple of arguments—the
    pulse ID, the `SKIPPED_PACKETS`, and the aggregation tables. We don''t expect
    `pulse_fn` to have any kind of return value, hence the `<_, ()>` bit. This version
    of sniffer includes an example packet function, defined in `examples/pulse.lua`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: 'The reader will note that it does basically the same work as the former gather
    function once did. Running sniffer works the same way as before. Be sure to `cargo
    build --release` and then:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: The allocation-conscious reader will have noticed there's a lot of cloning going
    on here. That's true. The primary compilation is interop with Lua's GC. A safe
    Rust interface must assume that data passed down to Lua will be garbage-collected.
    But, Lua does support a concept of user data, in which the programmer associates
    opaque blobs with Lua functions to manipulate it. Lua also supports light user
    data, which is very similar to user data except that the light variant is associated
    with a pointer to memory. The UserData type in RLua is quite well done and the
    ambitious reader might do well to build a `PacketAggregation` type that implements
    `UserData` to avoid all the cloning.
  prefs: []
  type: TYPE_NORMAL
- en: Combining a high-level language into a systems language is often a game of trade-offs
    between memory management complexity, end-user burden, and initial programming
    difficulty. rlua does an excellent job of landing on the safer side of these trade-offs.
    Something like mond, in use in cernan, less so, but with more flexibility in use.
  prefs: []
  type: TYPE_NORMAL
- en: Embedding Rust
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far, we've seen how to embed C and Lua into Rust. But, what if you want to
    combine Rust into other programming languages? Doing so is a very handy technique
    for improving runtime performance in interpreted languages, making memory-safe
    extensions where once you might have been using C or C++. If your target high-level
    language has difficulty with concurrency embedding, Rust is a further win. Python
    programs suffer in this regard—at least those implemented on CPython or PyPy—because
    of the Global Interpreter Lock, an internal mutex that locks objects' bytecode.
    Offloading computation of large blocks of data into a Rust + Rayon extension,
    for example, can be both straightforward to program and improve computation speed.
  prefs: []
  type: TYPE_NORMAL
- en: 'Well, great. How do we make this sort of thing happen? Rust''s approach is
    simple: if you can embed C, you can embed Rust.'
  prefs: []
  type: TYPE_NORMAL
- en: Into C
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let's embed some Rust into C. The quantiles library ([https://crates.io/crates/quantiles](https://crates.io/crates/quantiles))—discussed
    in [Chapter 4](5a332d94-37e4-4748-8920-1679b07e2880.xhtml), *Sync and Send – the
    Foundation of Rust Concurrency*—implements online summarization algorithms. These
    algorithms are easy to get wrong, in terms of producing incorrect results, but
    more often in storing more points than strictly necessary. A good deal of work
    has gone into quantiles to ensure the algorithms implemented there are near the
    theoretical minimum storage requirements, and so it makes sense to reuse this
    library for online summarization in C, rather than redo all that work.
  prefs: []
  type: TYPE_NORMAL
- en: Specifically, let's expose a `quantiles::ckms::CKMS<f32>` to C ([https://docs.rs/quantiles/0.7.1/quantiles/ckms/struct.CKMS.html](https://docs.rs/quantiles/0.7.1/quantiles/ckms/struct.CKMS.html)).
    We have to make the type concrete as C lacks any manner of generics in its types,
    but that's okay.
  prefs: []
  type: TYPE_NORMAL
- en: The Rust side
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are new things in the `Cargo.toml` file that we need to discuss:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: Note specifically that we're building the embed_quantiles library with `crate-type
    = ["staticlib"]`. What does that mean? The Rust compiler is capable of making
    many kinds of linkages, and usually they're just implicit. For instance, a binary
    is `crate-type = ["bin"]`. There's a longish list of different link types, which
    I've included in the *Further reading* section. The interested reader is encouraged
    to look through them. What we'd like to produce here is a statically linked library,
    otherwise every C programmer that tries to make use of embed_quantiles is going
    to need Rust's shared libraries installed on their system. Not… not great. A staticlib
    crate will archive all the bits of the Rust standard library needed by the Rust
    code. The archive can then be linked to C as normal.
  prefs: []
  type: TYPE_NORMAL
- en: 'Okay, now, if we''re going to produce a static archive that C can call, we''ve
    got to export Rust functions with a C ABI. Put another way, we''ve got to put
    a C skin on top of Rust. C++ programmers will be familiar with this tactic. The
    sole Rust file in this project is `src/lib.rs` and its preamble is what you might
    expect:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: 'We''ve pulled in the quantiles library and have imported `CKMS`. No big deal.
    Check this out, though:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: Hey! There's a bunch of new things. First, `#[no_mangle]`? A static library
    has to export a symbol for the linker to, well, link. These symbols are functions,
    static variables, and so forth. Now, usually Rust is free to fiddle with the names
    that go into a symbol to include information, such as module location or, really,
    whatever else the compiler wants to do. The exact semantics of mangling are undefined,
    as of this writing. If we're going to be calling a function from C, we have to
    have the exact symbol name to refer to. `no_mangle` turns off mangling, leaving
    us with our name as written. It does mean we have to be careful not to cause symbol
    collisions. Similar to importing functions, the `extern C` here means that this
    function should be written out to obey the C ABI. Technically, we could also have
    written this as `extern fn`, leaving the C off as the C ABI is the implicit default.
  prefs: []
  type: TYPE_NORMAL
- en: '`alloc_ckms` allocates a new `CKMS`, returning a mutable pointer to it. Interop
    with C requires raw pointers, which, you know, makes sense. We do have to be very
    conscious of memory ownership when embedding Rust—does Rust own the memory, implying
    we need to provide a free function? Or, does the other language own the memory?
    More often than not, it''s easier to keep ownership with Rust, because to free
    memory, the compiler will need to know the type''s size in memory. By passing
    a pointer out, as we''re doing here, we''ve kept C in the dark about the size
    of `CKMS`. All the C side of this project knows is that it has an *opaque struct* to
    deal with. This is a common tactic in C libraries, for good reason. Here''s freeing
    a `CKMS`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs: []
  type: TYPE_PRE
- en: 'Notice that in `alloc_ckms`, we''re boxing the `CKMS`—forcing it to the heap—and
    in `free_ckms` we''re building a boxed `CKMS` from its pointer. We discussed boxing
    and freeing memory in the context of raw pointers extensively in [Chapter 3](605ce307-29ed-4b5a-961e-8d327467b84f.xhtml),
    *The Rust Memory Model – Ownership, References and Manipulation*. Inserting a
    value into the `CKMS` is straightforward enough:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs: []
  type: TYPE_PRE
- en: 'Querying requires a little explanation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs: []
  type: TYPE_PRE
- en: Signaling error conditions in a C API is tricky. In Rust, we return some kind
    of compound type, such as an `Option`. There's no such thing in C without building
    an error signaling struct for your API. In addition to the error-struct approach
    it's common to either write well-known nonsense into the pointer where the answer
    will be written or return a negative value. C expects to have its answer written
    into a 32-bit float being pointed to by quant, and there's no easy way to write
    nonsense into a numeric value. So, query returns an `i8`; zero on success, negative
    on a failure. A more elaborate API would differentiate failures by returning different
    negative values.
  prefs: []
  type: TYPE_NORMAL
- en: That's it! When you run `cargo build --release`, a static library obeying the
    C ABI will get kicked out into `target/release`. We're ready to link it into a
    C program.
  prefs: []
  type: TYPE_NORMAL
- en: The C side
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Our C program is `c_src/main.c`. We need a few system headers before we can
    define the `embed_quantiles` interface:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs: []
  type: TYPE_PRE
- en: 'The only slightly unusual one is `time.h`. We pull that in because we''re going
    to be pushing random floats into the `CKMS` structure. Not cryptographically secure
    randomness, mind. Here''s the C view of the Rust API we just created:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs: []
  type: TYPE_PRE
- en: 'Notice the `CKMS` struct . That''s the opaque struct. C is now aware there
    is a structure but it doesn''t know how big it is. That''s okay. Each of our functions
    only operate on a pointer to this structure, which C does know the size of. The
    `main` function is brief:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE81]'
  prefs: []
  type: TYPE_PRE
- en: We allocate a `CKMS`, whose error bound is 0.001, load 1 million random floats
    into the `CKMS`, and then query for the 75th quantile, which should be around
    7,500\. Finally, the function frees the `CKMS` and exits. Short and sweet.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, building and linking `libembed_quantiles.a` is fairly easy with a clang
    compiler, and a little fiddly with GCC. I''ve gone ahead and included a Makefile,
    which has been tested on OS X and Linux:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs: []
  type: TYPE_PRE
- en: 'I don''t have a Windows machine to test with so, uh, when this inevitably doesn''t
    work I really do apologize. Hopefully there''s enough here to figure it out quickly.
    Once you have the Makefile in place, you should be able to run make run and see
    something similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE83]'
  prefs: []
  type: TYPE_PRE
- en: The percentile value will move around some, but it ought to be close to 7,500,
    as it is here.
  prefs: []
  type: TYPE_NORMAL
- en: Into Python
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s look at embedding Rust into Python. We''ll write a function to sum up
    the trailing zeros in a cytpes array, built by Python. We can''t link statically
    into Python as the interpreter is already compiled and linked, so we''ll need
    to create a dynamic library. The `Cargo.toml` project reflects this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE84]'
  prefs: []
  type: TYPE_PRE
- en: 'The sole Rust file, `src/lib.rs`, has a single function in it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE85]'
  prefs: []
  type: TYPE_PRE
- en: 'The `tail_zero_count` function takes a pointer to an array of `u16`s and the
    length of that array. It zips through the array, calling `trailing_zeros()` on
    each `u16` and adding the value to a global sum: `zeros`. This global sum is then
    returned. In the top of the project, run `cargo build --release` and you''ll find
    the project''s dynamic library—possibly `libzero_count.dylib`, `libzero_count.dll`,
    or `libzero_count.so`, depending on your host—in `target/release`. So far, so
    good.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Calling this function is now up to Python. Here''s a small example, which lives
    at `zero_count.py` in the root of the project:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE86]'
  prefs: []
  type: TYPE_PRE
- en: 'We import the cytpes and random libraries, then load the shared library—here,
    pegged to OS X''s naming convention—and bind it to `lzc`. Do edit this to read
    `[so|dll]` if you''re running this on an operating system other than OS X. Once
    `lzc` is bound, we use the ctypes API to create a random array of `u16` values
    and call `tail_zero_count` on that array. Python is forced to allocate the full
    array before passing it into Rust using this approach, so don''t increase the
    length too much. Running the program is a matter of calling Python''s `zero_count.py`,
    like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE87]'
  prefs: []
  type: TYPE_PRE
- en: Coping with opaque struct pointers—as we did in the C example—is well-documented
    in the ctypes documentation. Rust will not know the difference; it's just kicking
    out objects conforming to the C ABI.
  prefs: []
  type: TYPE_NORMAL
- en: Into Erlang/Elixir
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this last section of the chapter, we''ll investigate embedding Rust into
    the BEAM, the virtual machine that underpins Erlang and Elixir. The BEAM is a
    sophisticated work-stealing scheduler system that happens to be programmable.
    Erlang processes are small C structs that bounce around between scheduler threads
    and carry enough internal information to allow interpretation for a fixed number
    of instructions. There''s no concept of shared memory in Erlang/Elixir: communication
    between different concurrent actors in the system *must* happen via message passing.
    There are many benefits to this and the VM does a great deal of work to avoid
    copying when possible. Erlang/Elixir processes receive messages into a message
    queue, a double-ended threadsafe queue of the kind we''ve discussed throughout
    the book.'
  prefs: []
  type: TYPE_NORMAL
- en: Erlang and Elixir are rightly known for their efficiency at handling high-scale
    IO in a real-time fashion. Erlang was invented at Ericsson to serve as telephony
    control software, after all. What these languages are not known for is serial
    performance. Sequential computations in Erlang are relatively slow, it's just
    that it's so *easy* to get concurrent computations going that this is sort of
    made up for. Sort of. Sometimes, you need raw, serial performance.
  prefs: []
  type: TYPE_NORMAL
- en: 'Erlang has a few answers for this. A *Port* opens up an external OS process
    with a bidirectional byte stream. We saw an approach much like this in the previous
    chapter with feruscore embedding pmars. A *Port Driver* is a linked shared object,
    often written in C. The Port Driver interface has facilities for giving interrupt
    hints to BEAM''s schedulers and has much to recommend it. A Port Driver *is* a
    process and must be able to handle the things an Erlang process normally does:
    servicing its message queue, dealing with special interrupt signals, cooperatively
    scheduling itself, and so on. These are non-trivial to write. Finally, Erlang
    supports a Natively Implemented Function (NIF) concept. These are simpler than
    Port Drivers and are synchronous, being simply callable functions that happen
    to be written in a language other than Erlang. NIFs are shared libraries and are
    often implemented in C. Both Port Drivers and NIFs have a serious downside: memory
    issues will corrupt the BEAM and knock your application offline. Erlang systems
    tend to be deployed where fault-tolerance is a major factor and segfaulting the
    VM is a big no-no.'
  prefs: []
  type: TYPE_NORMAL
- en: As a result, there's a good deal of interest in the Erlang/Elixir communities
    towards Rust. The Rustler project ([https://crates.io/crates/rustler](https://crates.io/crates/rustler))
    aims to make combining Rust into an Elixir project as NIFs a simple matter. Let's
    take a look at a brief example project, presented by Sonny Scroggin at Code BEAM
    2018 in San Francisco—beamcoin ([https://github.com/blt/beamcoin](https://github.com/blt/beamcoin)).
    We'll discuss the project at SHA `3f510076990588c51e4feb1df990ce54ff921a06`.
  prefs: []
  type: TYPE_NORMAL
- en: The beamcoin project is not listed in its entirety. We've mostly dropped the
    build configuration. You can find the full listing in this book's source repository.
  prefs: []
  type: TYPE_NORMAL
- en: 'The build system for Elixir—the BEAM language that Rustler targets natively—is
    called Mix. Its configuration file is `mix.exs` at the root of the project:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE88]'
  prefs: []
  type: TYPE_PRE
- en: 'There''s a fair bit here that we won''t get into. Note, however, this section:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE89]'
  prefs: []
  type: TYPE_PRE
- en: 'Embedded in the project under `native/beamcoin` is the Rust library we''ll
    be exploring. Its cargo configuration, at `native/beamcoin/Cargo.toml`, is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE90]'
  prefs: []
  type: TYPE_PRE
- en: Nothing too surprising here. A dynamic library, called libbeamcoin, will be
    produced when Rust compiles this and we've seen almost all the dependencies before.
    rustler and `rustler_codegen` are the interface and compiler generators for Rustler,
    respectively. `rustler_codegen` removes a lot of boilerplate C extern work we
    might otherwise have to do. sha2 is a crate from the RustCrypto project that,
    well, implements the sha2 hashing algorithm. Beamcoin is kind of a joke project.
    The idea is to distribute numbers between threads and count the zeros at the back
    of the sha2-256 hash, mining those with a pre-set number of zeros. This would
    be a *very* slow thing to do in Erlang but, as we'll see, is a relatively fast
    computation in Rust. The scoped-pool crate is a threadpooling library that is
    Sendable, meaning it can be placed in a `lazy_static!`
  prefs: []
  type: TYPE_NORMAL
- en: 'The preamble for `src/lib.rs` is straightforward enough:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE91]'
  prefs: []
  type: TYPE_PRE
- en: 'We''ve seen much of this before. The Rustler imports are analogs of the Erlang
    C NIF API. The difficulty of mining is controlled by a top-level usize, called
    `DIFFICULTY`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE92]'
  prefs: []
  type: TYPE_PRE
- en: 'This value controls the total number of zeros that are required to be found
    at the back of a hash before it is declared minable. Here''s our thread pool:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE93]'
  prefs: []
  type: TYPE_PRE
- en: 'I mentioned earlier that the BEAM maintains its own scheduler threads. This
    is true. The beamcoin NIF also maintains its own, separate pool of threads to
    distribute mining over. Now, Rustler reduces boilerplate but cannot totally remove
    it. We must, for instance, tell BEAM which interpreted functions to associate
    with that symbol and pre-define *atoms* for use:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE94]'
  prefs: []
  type: TYPE_PRE
- en: 'An Erlang atom is a named constant. These are extremely common data types in
    Erlang/Elixir programs. The threads in the pool are each given a chunk of the
    positive integers to search, stripped according to their thread number. The pool
    workers use an MPSC channel to communicate back to the mining thread that a result
    has been found:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE95]'
  prefs: []
  type: TYPE_PRE
- en: 'The `search_for_solution` function is a small loop:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE96]'
  prefs: []
  type: TYPE_PRE
- en: 'At the top of the loop, every thread in the pool checks to see whether any
    other thread has mined a beamcoin. If one has, the function exits and the thread
    is available for new work in the pool. Otherwise, `verify_number` is called. That
    function is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE97]'
  prefs: []
  type: TYPE_PRE
- en: The number is passed in, transmuted into a byte array of 8 members, and hashed.
    If the hash has the appropriate number of trailing zero bytes, jackpot is true
    at the end of the function, and the number plus its hash are returned. The careful
    reader will have noted that the Rust module exports a NIF named `native_mine`.
    Erlang NIFs, generally speaking, have a system language component with a BEAM-native
    implementation as a fallback. The system language NIF implementation is called
    `native_*` by tradition.
  prefs: []
  type: TYPE_NORMAL
- en: 'The final piece here is the Elixir module to wrap the native NIF bits. This
    module is called `Beamcoin` and is `lib/beamcoin.ex`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE98]'
  prefs: []
  type: TYPE_PRE
- en: 'After installing Elixir ([https://elixir-lang.org/install.html](https://elixir-lang.org/install.html)),
    you can move to the root of the project, execute `mix deps.get` to get the project''s
    dependencies, and then use `MIX_ENV=prod iex -S mix` to bring up the Elixir repl.
    That latter command should look something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE99]'
  prefs: []
  type: TYPE_PRE
- en: 'At the prompt, type `Beamcoin.mine` and hit *Enter*. After a few seconds, you
    should see:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE100]'
  prefs: []
  type: TYPE_PRE
- en: Or, something like it.
  prefs: []
  type: TYPE_NORMAL
- en: Building NIFs in the BEAM is a complicated topic, one we've hardly touched on
    here. Sonny Scroggin's talk, included in the *Further reading* section, covers
    that nuance in detail. If you're curious about how the BEAM functions, I've included
    a talk of mine on that subject in the *Further reading* section as well. Decades
    of careful effort have gone into the BEAM and it really shows.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we discussed embedding languages in Rust and vice versa. Rust
    is an incredibly useful programming language in its own right, but has been designed
    with care to interoperate with the existing language ecosystem. Delegating difficult
    concurrency work in a memory-unsafe environment into Rust is a powerful model.
    Mozilla's work on Firefox has shown that path to be fruitful. Likewise, there
    are decades' worth of well-tested libraries niche domains—weather modeling, physics,
    amusing programming games from the 1980s—that could, theoretically, be rewritten
    in Rust but are probably better incorporated behind safe interfaces.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter is the last that aims to teach you a new, broad skill. If you've
    made it this far in the book, thank you. It's been a real pleasure writing for
    you. You should, hopefully, now have a solid foundation for doing low-level concurrency
    in Rust and the confidence to read through most Rust codebases you come across.
    There's a lot going on in Rust and I hope it seems more familiar now. In the next,
    and last, chapter of the book, we'll discuss the future of Rust, what language
    features apropos this book are coming soon, and how they might bring new capabilities
    to us.
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*FFI examples written in Rust*, available at [https://github.com/alexcrichton/rust-ffi-examples](https://github.com/alexcrichton/rust-ffi-examples).
    This repository by Alex Crichton is a well-done collection of FFI examples in
    Rust. The documentation in this book on this topic is quite good, but it never
    hurts to pour through working code.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Hacker''s Delight*, Henry Warren Jr. If you enjoyed the bit fiddling present
    in this chapter''s take on feruscore, you''ll love Hacker''s Delight. It''s old
    now and some of its algorithms no longer function on 64-bit words, but it''s still
    well worth reading, especially if you, like me, work to keep fixed-width types
    as small as possible.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Foreign Function Interface*, available at [https://doc.rust-lang.org/nomicon/ffi.html](https://doc.rust-lang.org/nomicon/ffi.html).
    The Nomicon builds a higher-level wrapper for the compression library snappy.
    This wrapper is extended in ways we did not touch on here, specifically with regard
    to C callbacks and vardic function calls.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Global Interpreter Lock*, available at [https://wiki.python.org/moin/GlobalInterpreterLock](https://wiki.python.org/moin/GlobalInterpreterLock). The
    GIL has long been the bane of multiprocessing software written in Python. This
    wiki entry discusses the technical details mandating the GIL and the historical
    attempts to remedy the situation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Guided Tour*, available at [https://github.com/chucklefish/rlua/blob/master/examples/guided_tour.rs](https://github.com/chucklefish/rlua/blob/master/examples/guided_tour.rs). The
    rlua crate includes a guided tour module, which is well-documented and runnable.
    I haven''t seen this approach to documentation in other projects and I warmly
    encourage you to check it out. First, it''s helpful for learning rlua. Second,
    it''s well-written and empathetic to the reader: a fine example of technical writing.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Linkage*, available at [https://doc.rust-lang.org/reference/linkage.html](https://doc.rust-lang.org/reference/linkage.html).
    This is the Rust Reference chapter on linking. The details here are very specific,
    but that''s often necessary when being explicit about linking. The common reader
    will more or less use the information we''ve covered in this chapter but there''s
    always some new domain requiring specific knowledge.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Rust Inside Other Languages*, available at [https://doc.rust-lang.org/1.2.0/book/rust-inside-other-languages.html](https://doc.rust-lang.org/1.2.0/book/rust-inside-other-languages.html).
    This chapter in the Rust Book covers similar ground to this chapter—embedding
    Rust—but at a faster clip and with different high-level languages. Specifically,
    The Book covers embedding Rust into both Ruby and NodeJS, which we did not.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*FFI in Rust - writing bindings for libcpuid*, available at [http://siciarz.net/ffi-rust-writing-bindings-libcpuid/](http://siciarz.net/ffi-rust-writing-bindings-libcpuid/).
    Zbigniew Siciarz has been writing about Rust and writing in Rust for a good while.
    You may know him from his *24 days of Rust* series. In this post, Sicarz documents
    the process of building a safe wrapper for libcpuid, a library whose job is to
    poll the OS for information about the user''s CPU.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Taking Elixir to the Metal with Rust*, Sonny Scroggin, available at [https://www.youtube.com/watch?v=lSLTwWqTbKQ](https://www.youtube.com/watch?v=lSLTwWqTbKQ).
    In this chapter we demonstrated Beamcoin, a combination of Elixir and Rust in
    the same project. Integrating NIFs into a BEAM system is a complicated subject.
    This talk, presented at NDC London 2017, is warmly recommended as an introduction
    to the subject.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Piecemeal Into Space: Reliability, Safety and Erlang Principles*, Brian L.
    Troutwine, available at [https://www.youtube.com/watch?v=pwoaJvrJE_U](https://www.youtube.com/watch?v=pwoaJvrJE_U).
    There''s a great deal of work that''s gone into the BEAM over the decades, earning
    those languages a key place in fault-tolerant software deployments. Exactly how
    the BEAM functions is something of a mystery without inspection. In this talk,
    I cover the BEAM''s semantic model and then discuss it''s implementation at a
    high-level.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
