- en: Robust Trees
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Lists are great for storing a bunch of items, but what about looking up specific
    elements? In the previous chapter, a skip list greatly outperformed a regular
    linked list when simply finding an item. Why? Because it was utilizing an iteration
    strategy that resembles that of a balanced tree structure: there, the internal
    order lets the algorithm strategically skip items. However, that''s only the beginning.
    Many libraries, databases, and search engines are built on trees; in fact, whenever
    a program is compiled, the compiler creates an abstract syntax tree.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Tree-based data structures incorporate all kinds of smart ideas that we will
    explore in this chapter, so you can look forward to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Implementing and understanding a binary search tree
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Learning about self-balancing trees
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How prefix or suffix trees work
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What a priority queue uses internally
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Graphs, the most general tree structure
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Binary search tree
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A tree structure is almost like a linked list: each node has branches—in the
    case of a binary tree, there are two—which represent children of that node. Since
    these children have children of their own, the node count grows exponentially,
    building a hierarchical structure that looks like a regular tree turned on its
    head.'
  prefs: []
  type: TYPE_NORMAL
- en: Binary trees are a subset of these structures with only two branches, typically
    called left and right. However, that does not inherently help the tree's performance.
    This is why using a *binary search tree*, where left represents the smaller or
    equal value to its parent, and right anything that's greater than that parent
    node, was established!
  prefs: []
  type: TYPE_NORMAL
- en: 'If that was confusing, don''t worry; there will be code. First, some vocabulary
    though: what would you call the far ends of the tree? Leaves. Cutting off branches?
    Pruning. The number of branches per node? Branching factor (binary trees have
    a branching factor of 2).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Great, with that out of the way, the nodes can be shown—although they look
    a lot like the doubly linked list from the previous chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Similarly, the tree structure itself is only a pointer to the root node:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Yet before you can get comfortable with the new data structure, the product
    team from the previous chapter is back! You did a great job improving the transaction
    log and they want to continue that progress and build an **Internet of Things**
    (**IoT**) device management platform so users can register a device with a numerical
    name and later search for it. However, the search has to be fast or really fast,
    which is especially critical since many customers have announced the incorporation
    of more than 10,000 devices into the new system!
  prefs: []
  type: TYPE_NORMAL
- en: Isn't this a great opportunity to get more experience with a binary search tree?
  prefs: []
  type: TYPE_NORMAL
- en: IoT device management
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Device management in the IoT space is mostly about storing and retrieving specific
    devices or device twins. These objects typically store addresses, configuration
    values, encryption keys, or other things for small devices so nobody has to connect
    manually. Consequently, keeping an inventory is critical!
  prefs: []
  type: TYPE_NORMAL
- en: 'For now, the product team settled on a numerical "name", to be available faster
    than the competition, and to keep the requirements short:'
  prefs: []
  type: TYPE_NORMAL
- en: Store IoT device objects (containing the IP address, numerical name, and type)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Retrieve IoT objects by numerical name
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Iterate over IoT objects
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'A great use for a tree: the numerical name can be used to create a tree and
    search for it nice and quickly. The basic object for storing this IoT device information
    looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'For simplicity, this object will be used in the code directly (adding generics
    isn''t too tricky, but would go beyond the scope of this book):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Starting with this basic implementation, the requisite operations, `add` and
    `find`, can be implemented.
  prefs: []
  type: TYPE_NORMAL
- en: More devices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Unlike lists, trees make a major decision on insert: which side does the new
    element go to? Starting at the root node, each node''s value is compared to the
    value that is going to be inserted: is this greater than or less than that? Either
    decision will lead down a different subtree (left or right).'
  prefs: []
  type: TYPE_NORMAL
- en: 'This process is (usually recursively) repeated until the targeted subtree is
    `None`, which is exactly where the new value is inserted—as a leaf of the tree.
    If this is the first value going into the tree, it becomes the root node. There
    are some problems with this, and the more experienced programmers will have had
    a strange feeling already: what happens if you insert numbers in ascending order?'
  prefs: []
  type: TYPE_NORMAL
- en: 'These feelings are justified. Inserting in ascending order (for example, `1`,
    `2`, `3`, `4`) will lead to a tree that is basically a list in disguise! This
    is also called a (very) unbalanced tree and won''t have any of the benefits of
    other trees:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'During this chapter, we are going to go a lot more things on balancing trees
    and why that is important in order to achieve high performance. In order to avoid
    this pitfall associated with binary search trees, the first value to insert should
    ideally be the median of all elements since it will be used as the root node,
    as is visible in the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Split into two parts, this code walks the tree recursively to find the appropriate
    position and attaches the new value as a leaf there. Actually, the insert is not
    that different from a regular tree walk in search or iteration.
  prefs: []
  type: TYPE_NORMAL
- en: '**Recursion** is when a function calls itself. Think of the movie Inception—having
    a dream inside a dream inside a dream. it''s the same concept. There are a few
    implications in programming: the original function is disposed of last since it''s
    only finished after all recursive calls return. This also means that everything
    lives on the much smaller stack, which may result in a stack overflow when there
    are too many calls! Typically, recursive algorithms can also be implemented iteratively,
    but they are much harder to understand—so choose wisely!'
  prefs: []
  type: TYPE_NORMAL
- en: Finding the right one
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Having the ability to add devices to the tree, it's even more important to retrieve
    them again. Just like the skip list in the previous chapter, this retrieval ideally
    runs in *O(log n)* time, meaning that the majority of elements are going to be
    skipped when searching.
  prefs: []
  type: TYPE_NORMAL
- en: 'Consequently, if the tree is skewed in one direction, the performance approaches
    *O(n)* and more elements are looked at, thereby making the search slower. Since
    a skewed tree is more like a list, the recursive insert algorithm can overflow
    the stack quickly thanks to the high number of "levels" with only a single item.
    Otherwise, the recursive algorithm is only called as many times as the tree''s
    height, a considerably lower number in a balanced tree. The algorithm itself resembles
    the previously shown insert algorithm:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Although this snippet's purpose is to find a specific node, there is a close
    relationship to enumerating every device—something that the users of this service
    certainly will want to have.
  prefs: []
  type: TYPE_NORMAL
- en: Finding all devices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Walking a tree and executing a callback when visiting each node can be done
    in three ways:'
  prefs: []
  type: TYPE_NORMAL
- en: Pre-order, executing the callback *before descending*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In-order, which executes the callback *after descending left, but before descending
    into the right subtree*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Post-order, where the callback is executed *after descending*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each of these traversal strategies yields a different order of tree elements,
    with in-order producing a sorted output, while pre- and post-order create a more
    structurally oriented sorting. For our users, the in-order walk will provide the
    best experience, since it also lets them reason better regarding the expected
    outcome, and, if displayed in a list, it's easier to navigate.
  prefs: []
  type: TYPE_NORMAL
- en: While implementing this walk is very easy to do recursively, providing an iterator
    is more user-friendly (just like the lists in the previous chapter) and it enables
    a number of added functions, such as `map()` and `filter()`. However, this implementation
    has to be iterative, which makes it more complex and removes some of the efficiency
    of the tree.
  prefs: []
  type: TYPE_NORMAL
- en: 'Therefore, this tree supports a `walk()` function which calls a provided function
    each time it encounters a node, which can be used to fill a vector for the iterator:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'An example of how to build a vector using this walk method is shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: With this walking ability, all requirements are satisfied for now.
  prefs: []
  type: TYPE_NORMAL
- en: Wrap up
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Thanks to their simplicity, binary search trees are beautifully efficient. In
    fact, the entire tree implementation for this section was done in fewer than 90
    lines of Rust code, with functions of about 10 lines each.
  prefs: []
  type: TYPE_NORMAL
- en: A binary tree's efficiency allows for recursion to be used a lot, which typically
    results in functions that are easier to understand compared to their iterative
    counterparts. In the ideal case, that is, when a tree is perfectly balanced, a
    function only has to process *log2(n)* nodes (*n* being the total number of nodes)—19
    in a tree of 1,000,000 elements!
  prefs: []
  type: TYPE_NORMAL
- en: 'Unbalanced trees will decrease performance significantly and they are easily
    created by accident. The most unbalanced tree is created by inserting values that
    are already sorted, creating a very large difference in search performance:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: These results reflect the differences between a skip list and a doubly linked
    list from the previous chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Upsides
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To recap, a binary search tree has a number of great benefits for its users:'
  prefs: []
  type: TYPE_NORMAL
- en: Simple implementation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Efficient and fast search
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Traversal allows for different orderings
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Great for large amounts of unsorted data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Downsides
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'By using a binary search tree, its drawbacks become obvious quickly:'
  prefs: []
  type: TYPE_NORMAL
- en: Worst-case performance is that of a linked list
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Unbalanced trees are easy to create by accident
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Unbalanced trees cannot be "repaired"
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Recursive algorithms can overflow on unbalanced trees
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Obviously, a lot of the deeper issues result from the tree being unbalanced
    in some way—for which there is a solution: self-balancing binary search trees.'
  prefs: []
  type: TYPE_NORMAL
- en: Red-black tree
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'With the previous tree structure, there was a major downside: a previously
    unknown sequence of keys that is inserted into the tree cannot be sorted. Think
    of how most identifiers are generated; they are typically ascending numbers. Shuffling
    these numbers won''t always work, especially when they are gradually added. Since
    this leads to an unbalanced tree (the extreme case behaves just like a list),
    Rudolf Bayer came up with the idea of a special, self-balancing tree: the red-black
    tree.'
  prefs: []
  type: TYPE_NORMAL
- en: 'This tree is a binary search tree that adds logic to rebalance after inserts.
    Within this operation, it is crucial to know when to stop "balancing"—which is
    where the inventor thought to use two colors: red and black.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In literature, the red-black tree is described as a binary search tree that
    satisfies a set of rules:'
  prefs: []
  type: TYPE_NORMAL
- en: The root node is always black
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each other node is either red or black
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All leaves (often `null`/`NIL` values) are considered black
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A red node can only have black children
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Any path from the root to its leaves has the same number of black nodes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'By enforcing these rules, a tree can be programmatically verified to be balanced.
    How are these rules doing that? Rules 4 and 5 provide the answer: if each branch
    has to have the same number of black nodes, neither side can be significantly
    longer than the other unless there were lots of red nodes.'
  prefs: []
  type: TYPE_NORMAL
- en: 'How many of those can there be? At most, as many as there are black nodes—because
    they cannot have red children. Thus, one branch cannot significantly exceed the
    other, making this tree balanced. The code of the validation function illustrates
    this very well:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Like the binary search tree, each node in a tree has two children, with a key
    either greater than, equal to, or less than that of the current node. In addition
    to the key (as in a key-value pair), the nodes store a color that is red on insert,
    and a pointer back to its parent. Why? This is due to the required rebalancing,
    which will be described later. First, this can be a typical node:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Using these nodes, a tree can be created just like a binary search tree. In
    fact, the insert mechanism is exactly the same except for setting the parent pointer.
    Newly inserted nodes are always colored red and, once in place, the tree might
    violate the rules. Only then is it time to find and fix these issues.
  prefs: []
  type: TYPE_NORMAL
- en: After an insert, the tree is in an invalid state that requires a series of steps
    to restore the red-black tree's properties. This series, comprised of rotation
    and recolor*,* starts at the inserted node and goes up the tree until the root
    node is considered valid. In summary, a red-black tree is a binary search tree
    that is rotated and recolored until balance is restored.
  prefs: []
  type: TYPE_NORMAL
- en: '**Recolor** is simply changing the color of a specified node to a specific
    color, which happens as a final step when doing tree rebalancing. **Rotation**
    is an operation of a set of three nodes: the current node, its parent, and its
    grandparent. It is employed to fold list-like chains into trees by rotating either
    left or right around a specified node. The result is a changed hierarchy, with
    either the left or right child of the center node on top, and its children adjusted
    accordingly:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f45acff7-777a-4242-b534-c2464c606330.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Clearly, this example is too simple and it can only happen within the first
    few inserts. Rotations require recolors after redefining the hierarchy of a set
    of nodes. To add further complexity, rotations regularly happen in succession:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/bd2d323f-1996-49ea-a6ba-facdae784fe9.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The preceding tree has had a node inserted and is now violating rule 4: *no
    red children on a red node*. The next step is to determine which steps are required
    to establish balance. For that, the parent''s sibling''s color (that is, the uncle''s
    color) is examined. Red means that a simple recoloring of both siblings to black
    and their parent to red won''t invalidate the tree and will fix the condition.
    This is not the case here (the uncle is `None`, which means black), and some rotation
    is required:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0a1e50d9-be7b-4738-b786-f1c75b648f92.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The first move is to align the nodes into a chain of left children (in this
    case), which is done by rotating around the center node, the insertee''s parent:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b3f8638e-86e6-4b37-bf7b-60c6340b3c60.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Once the chain is aligned, a right rotation of the third node (grandparent)
    creates a valid subtree by elevating the middle node (the "youngest" node/insertee),
    with the former parent and grandparent to the left and right, respectively. Then,
    the new constellation is recolored and the procedure begins anew, centered around
    the root of the new subtree (in this example, though, the tree is already valid):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f007f46a-f3ea-4374-8775-e444dec4c6f7.png)'
  prefs: []
  type: TYPE_IMG
- en: These steps can be repeated until the tree is valid and the root is reached
    (which might be different from what you started off with). This root node is heuristically
    painted black as well, which cannot violate the rules but shortcuts a potential
    red-red violation. For code on the fixing operation, see the following subsections.
  prefs: []
  type: TYPE_NORMAL
- en: The product team has even called this time to put emphasis on their new product
    ideas. The IoT platform is quite popular and customers have been using it a lot—and
    recognized a major slowdown when they kept adding their sequentially numbered
    devices. This resulted in angry calls to customer services, which then turned
    to the product team for help—and now it's time to implement the solution and replace
    the current tree for device management.
  prefs: []
  type: TYPE_NORMAL
- en: Better IoT device management
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The problem that our users face is clear: if a binary search tree encounters
    sorted data (such as incremental IDs), it can only ever append to one side, creating
    an unbalanced tree. A red-black tree is able to handle this at the cost of more
    operations being executed during insert (such as rotating subtrees), which is
    acceptable for the users.'
  prefs: []
  type: TYPE_NORMAL
- en: 'This tree has similar nodes to the binary search tree, with the addition of
    a color field and a parent field, the latter of which triggers a wider change
    compared to the binary search tree. Thanks to the pointer back, the tree nodes
    cannot exclusively own the pointers to the children and parent (because, who owns
    this value, the parent or the child?), which requires a well-known pattern in
    Rust: interior mutability. As discussed in an earlier chapter, `RefCell` owns
    the data''s portion of the memory and handles borrow-checking at runtime so that
    mutable and immutable references can be obtained:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: With that in place, devices can be added.
  prefs: []
  type: TYPE_NORMAL
- en: Even more devices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Once the tree is created, an `add()` function lets the user add a device. The
    tree then proceeds to insert the new key just as if it were a binary search tree—only
    to check and fix any errors immediately afterward. Where a binary search tree
    could use a simple `if` condition to decide the direction it proceeds in, in the
    red-black tree, the direction has a larger impact, and nesting `if` conditions
    will result in chaotic, unreadable code.
  prefs: []
  type: TYPE_NORMAL
- en: 'Thus, let''s create `enum` first, so any time the direction (example, insert,
    position of a node relative to another node, and so on) has to be decided, we
    can rely on that `enum`. The same goes for the tree''s color:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, the `add()` function can use Rust''s match clause to nicely structure
    the two branches:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'One of the primary parts of the code is "checking" two devices, that is, comparing
    them in order to provide a direction that they should be appended to. This comparison
    is done in a separate function to improve maintainability:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: While this tree will append every larger item to the left (which seems unusual),
    the algorithms don't care; they will work regardless—and, by wrapping this into
    its own function, change is quick and easy.
  prefs: []
  type: TYPE_NORMAL
- en: Balancing the tree
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'After the node is added properly, `fix_tree()` takes care of restoring the
    red-black tree''s properties—iteratively. While this is nicely descriptive and
    demonstrative it is long, so let''s break it up into parts. Initially, the function
    determines whether it should stop (or not even start)—which only happens in two
    cases:'
  prefs: []
  type: TYPE_NORMAL
- en: When it's already the root node
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When the parent of the currently inspected node is red
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Clearly, the former is the regular exit criterion as well, as the loop optimizes
    and moves the current pointer (`n` as in node) from the bottom toward the root
    of the tree to stop there:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Once started, the loop immediately goes for the uncle of a particular node
    (that is, the grandparent''s second child) and its color. The uncle node can either
    be black (or `None`) or red, which are the two cases covered next. It is also
    important to find out *which* uncle it is, and therefore which node the current
    pointer points to: a left node or a right node. Let''s take a look at the following
    code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'This information is critical in determining the rotation order in this area
    of the tree. In fact, the two branches will execute the same steps, but mirrored:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: This code contains a large amount of `unwrap()`, `clone()`, and `borrow()` instances,
    a consequence of the interior mutability pattern. In this case, macros could help
    to reduce the code's verbosity.
  prefs: []
  type: TYPE_NORMAL
- en: Once the operations for one part of the tree finishes, the next iteration is
    prepared by checking for a red-red violation to see whether the loop needs to
    continue.
  prefs: []
  type: TYPE_NORMAL
- en: 'After the main loop exits, the pointer to the current node is moved up the
    tree to the root node (which is the function''s return value, after all) and colored
    black. Why? This is a shortcut solution that would otherwise result in another
    iteration requiring many more expensive steps to be executed, and the rules of
    a red-black tree mandate a black root anyway:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: With that shortcut, a valid tree is returned that can be set as the new root.
    However, the main purpose of the tree is to find stuff, which is not that different
    from a regular binary search tree.
  prefs: []
  type: TYPE_NORMAL
- en: Finding the right one, now
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This piece of code can almost be reused from the binary search tree. Other
    than the `borrow()` calls (instead of a simple dereference or `*` operator) adding
    some amount of processing time, they provides a consistent search speed. For greater
    reuse of existing functions, the value to be found is wrapped into a dummy node.
    This way, no additional interface has to be created for comparing nodes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'This is, again, a recursive walk of the tree until the specified value is found.
    Additionally, the "regular" tree walk was also added to the red-black tree variant:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: With these parts fixed, the platform performs consistently fast!
  prefs: []
  type: TYPE_NORMAL
- en: Wrap up
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Red-black trees are great self-balancing binary trees, similar to **AVL** (short
    for **Adelson-Velsky and L****andis**) trees. Both appeared around the same time,
    yet AVL trees are considered to be superior thanks to a lower height difference
    between the branches. Regardless of which tree structure is used, both are significantly
    faster than their less complex sibling, the binary search tree. Benchmarks using
    sorted data on insert (100,000 elements in this case) show how significant the
    difference between a balanced and unbalanced tree is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Another variation of a balanced tree is the 2-3-4 tree, a data structure that
    the red-black tree can be converted into. However, the 2-3-4 tree is, like the
    B-Tree (coming up later in this chapter), non-binary. Therefore, it is briefly
    discussed later in this chapter, but we encourage you to find other sources for
    details.
  prefs: []
  type: TYPE_NORMAL
- en: One major upside to implementing a red-black tree in Rust is the deep understanding
    of borrowing and ownership that follows the reference juggling when rotating,
    or "unpacking", a node's grandfather. It is highly recommended as a programming
    exercise to implement your own version!
  prefs: []
  type: TYPE_NORMAL
- en: Upsides
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A red-black tree has a few desirable properties over a regular binary search
    tree:'
  prefs: []
  type: TYPE_NORMAL
- en: Balance makes searches consistently fast
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Predictable, low-memory usage
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Inserts are reasonably fast
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Simplicity of a binary tree
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Easy to validate
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: However, the data structure has some significant downsides as well, especially
    when planning to implement it!
  prefs: []
  type: TYPE_NORMAL
- en: Downsides
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Speed is great, but can your implementation achieve it? Let''s have a look
    at the downsides of red-black trees:'
  prefs: []
  type: TYPE_NORMAL
- en: Complex implementation, especially in Rust
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Concurrent writes require the entire tree to be locked
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Performance is great compared to binary search trees, but other trees perform
    better at the same complexity
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Skip lists (from the previous chapter) perform similarly with better concurrency
    and simpler implementations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In any case, the red-black tree is a great journey into sophisticated binary
    tree structures. A more exotic binary tree structure is the heap (not to be confused
    with the portion of main memory).
  prefs: []
  type: TYPE_NORMAL
- en: Heaps
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Since binary trees are the most basic forms of trees, there are several variations
    designed for a specific purpose. Where the red-black tree is an advanced version
    of the initial tree, the binary heap is a version of the binary tree that does
    not facilitate search.
  prefs: []
  type: TYPE_NORMAL
- en: 'In fact, it has a specified purpose: finding the maximum or minimum value of
    a node. These heaps (min-heap or max-heap) are built in a way that the root node
    is always the value with the desired property (min or max) so it can be retrieved
    in constant time—that is, it always takes the same number of operations to fetch.
    Once fetched, the tree is restored in a way that the next operation works the
    same. How is this done though?'
  prefs: []
  type: TYPE_NORMAL
- en: Heaps work, irrespective of whether they are min-heaps or max-heaps, because
    a node's children always have the same property as the entire tree. In a max-heap,
    this means that the root node is the maximum value of the sequence, so it has
    to be the greatest value of its children (it's the same with min-heaps, just in
    reverse). While there is no specific order to this (such as the left node being
    greater than the right node), there is a convention to prefer the right node for
    max-heaps and the left for min-heaps.
  prefs: []
  type: TYPE_NORMAL
- en: 'Upon inserting a new node, it is added last and then a place in the tree has
    to be determined. The strategy to do that is simple: look at the parent node;
    if it''s greater (in a max-heap), swap the two, and repeat until this doesn''t
    work or it becomes the root node. We call this operation **upheap**.'
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, this is how removals work. Once removed, the now-empty slot is replaced
    by a leaf of the tree—which is either the smallest (max-heap) or greatest (min-heap)
    value. Then, the same comparisons as with the insert are implemented, but in reverse.
    Comparing and swapping this node with the children restores the heap's properties
    and is called **downheap**.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you paid attention to a node''s journey, there is one detail that will be
    obvious to you: the tree is always "filled". This means that each level is fully
    populated (that is, every node has both children), making it a **complete binary
    tree** that maintains total order. This is a property that lets us implement this
    tree in an array (dynamic or not), making jumps cheap. It will all become clear
    once you see some diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e2060e60-5458-46bd-b9e7-9634b47f8c98.png)'
  prefs: []
  type: TYPE_IMG
- en: Commonly, the heap is used to create a priority queue of some kind, thanks to
    the ability to quickly retrieve the highest- or lowest-valued items. A very basic
    heap can be implemented in Rust as an array, which will provide everything necessary
    to make it work, but won't be as convenient as a `Vec`.
  prefs: []
  type: TYPE_NORMAL
- en: After the great success of the IoT device platform, an add-on has been planned.
    The product team is asking for a way to efficiently process messages that come
    from the devices, so that customers only have to deal with the actual handling
    of the message and skip the "plumbing" code. Since processing can be executed
    at (short) intervals, they require a way to order them quickly—ideally so that
    the device with the most messages can come first.
  prefs: []
  type: TYPE_NORMAL
- en: This sounds like the heap data structure, doesn't it? In fact, it can be a max-heap.
  prefs: []
  type: TYPE_NORMAL
- en: A huge inbox
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Typically, heaps are used as priority queues of all kinds. Queues like that
    exist in any resource-constrained environment (and everywhere else, probably),
    but their purpose is to output things in an ordered fashion. By using the number
    of messages to determine the priority of a message notification, the heap can
    do the heavy lifting of this feature. Before jumping into the hard stuff, though,
    here are the bits containing the information:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'The idea is to use the number of messages as an indicator of which device to
    poll first, which is why the device is required. Using this type, the heap does
    not require any specific node or link types to work:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'There are two interesting points here: the underlying structure is a regular
    `Vec<T>`, which was chosen for its expansion capabilities (Rust''s arrays are
    sized at compile time), and the functionality of `push` or `pop`.'
  prefs: []
  type: TYPE_NORMAL
- en: Another noteworthy modification is that no `Option` is needed, which removes
    a check from the code and makes it easier to read. However, since many of the
    heap's operations work well with a direct, 1-index-based access, indices have
    to be translated before hitting `Vec<T>`.
  prefs: []
  type: TYPE_NORMAL
- en: So how does data get in?
  prefs: []
  type: TYPE_NORMAL
- en: Getting messages in
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Once a message arrives, it is pushed to the back of the array when the upheap
    operation "bubbles up" the item until it finds its proper place. In Rust code,
    this is what that looks like:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Initially, the new notification lives in a `Box` at the back of the `Vec<T>`,
    inserted via `push()`. A simple `while` loop then bubbles up the new addition
    by repeatedly swapping it whenever the `has_more_messages()` function is true.
    When is it true? Let''s see the code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: By encapsulating this function, it's easily possible to change the heap into
    a min-heap should that be required—and the index translations are wrapped away
    here as well.
  prefs: []
  type: TYPE_NORMAL
- en: Getting data out requires doing this process in reverse in a function called
    `pop()`.
  prefs: []
  type: TYPE_NORMAL
- en: Taking messages out
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Removing the first item in a `Vec<T>` is not difficult—in fact, `Vec<T>` ships
    with a `swap_remove()` function that does exactly what a heap needs: removing
    the first element of a `Vec<T>` by replacing it with the last element! This makes
    the code significantly shorter and therefore easier to reason about:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: Obviously, this code is not short though—so what's amiss? The bubbling down.
    Swapping downward requires to look at the children (which are at the positions
    `i * 2` and `i * 2 + 1`) to find out where (or if) the next iteration should proceed.
  prefs: []
  type: TYPE_NORMAL
- en: Wrap up
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The heap data structure is surprisingly simple to implement. There are no lengthy
    unwraps, borrows, or other calls, and the pointer is owned by the `Vec` and can
    easily be swapped. Other than that, the upheap operation is only a `while` loop,
    just like the (slightly more complex) downheap function.
  prefs: []
  type: TYPE_NORMAL
- en: 'There is another typical use case for a heap though: sorting! Consider a bunch
    of numbers going into the heap instead of `MessageNotification` objects—they would
    come out sorted. Thanks to the efficiency of the upheap/downheap operations, the
    worst-case runtime of that sorting algorithm is great—but more on that in [Chapter
    9](a9ba9f9e-59a2-411f-8998-831fe4e69266.xhtml), *Ordering Things*.'
  prefs: []
  type: TYPE_NORMAL
- en: Upsides
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Compact and low-complexity implementation make the binary heap a great candidate
    for requiring any kind of sorting data structure. Other benefits include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: An efficient way to sort lists
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Works well in concurrent situations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A very efficient way to store a sorted array
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yet there are also downsides.
  prefs: []
  type: TYPE_NORMAL
- en: Downsides
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Heaps are generally great, but have two caveats that limit their use:'
  prefs: []
  type: TYPE_NORMAL
- en: Use cases outside of queuing or sorting are rare
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are better ways to sort
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The binary heap was the last of the binary trees, and the next section will
    cover another rather exotic variation of a tree: the trie.'
  prefs: []
  type: TYPE_NORMAL
- en: Trie
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The trie is another interesting data structure—in particular, the way in which
    it is pronounced! Depending on your mother tongue, intuition might dictate a way,
    but—according to Wikipedia—the name was selected thanks to Edward Fredkin, who
    pronounced this type of tree differently, namely like **trie** in re**trie**val.
    Many English speakers resort to saying something along the lines of "try" though.
  prefs: []
  type: TYPE_NORMAL
- en: 'With that out of the way, what does the trie actually do for it to deserve
    a different name? It transpires that using retrieval was not a bad idea: tries
    store strings.'
  prefs: []
  type: TYPE_NORMAL
- en: Imagine having to store the entire vocabulary of this book in a way to find
    out whether certain words are contained within the book. How can this be done
    efficiently?
  prefs: []
  type: TYPE_NORMAL
- en: After the previous sections, you should already have an answer, but if you think
    about strings—they are stored as arrays or lists of `char` instances—it would
    use a good amount of memory. Since each word has to use letters from the English
    alphabet, can't we use that?
  prefs: []
  type: TYPE_NORMAL
- en: 'Tries do something similar. They use characters as nodes in a tree where the
    parent node is the preceding character and all children (limited only by the size
    of the alphabet) are what follows. A trie storing the strings ABB, ABC, CAACB,
    CAACA, BBB, and BBA can be seen in the following trie diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/91d88689-25be-4760-b986-aeb4ebe7937f.png)'
  prefs: []
  type: TYPE_IMG
- en: Storing strings like this enables a very efficient search. You only have to
    walk through the letters in the key that is to be stored to find out (or store)
    whether that string is contained in—for example—a set. In fact, if a string can
    only have a certain size, then the retrieval time is constant and it does not
    matter whether the trie stores 10 or 10 million words. Typically, this is useful
    for set data structures or key-value stores with string keys (such as hashes,
    but more on that later). Just like the binary search tree, this structure has
    a strong hierarchical memory management (that is, no pointers "back up"), making
    it a perfect fit for Rust.
  prefs: []
  type: TYPE_NORMAL
- en: Lately, the product team has looked into the user's device keys once again and
    found that the typical IoT device uses keys that represent a path, and they would
    often look like `countryA/cityB/factoryC/machine1/positionX/sensorY`. Reminded
    of the trees that worked so well earlier, they thought that you could use those
    to improve the directory as well. But you already have a better idea!
  prefs: []
  type: TYPE_NORMAL
- en: More realistic IoT device management
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Paths like that tend to have a huge overlap, since there are countless sensors
    and devices in a single location. Additionally, they are unique thanks to the
    hierarchical properties and are human-readable in case the sensor needs to be
    found. A great fit for a trie!
  prefs: []
  type: TYPE_NORMAL
- en: 'The basis for this trie will be a node type that stores the children, current
    character, and, if it''s a node that concludes a full key, the `IoTDevice` object
    from earlier in this chapter. This is what this looks like in Rust:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'This time, the children is a different data structure as well: a `HashMap`.
    Maps (also called dictionaries, associative arrays) explicitly store a key alongside
    a value and the word "hash" hints at the method, which will be discussed in the
    next chapter. For now, the `HashMap` guarantees a single character to be associated
    with a Node type, leading the way for iteration. On top of that, this data structure
    allows for a get-or-add type operation, which significantly improves code readability.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Since the number of possible word beginnings is similar, the root is a `HashMap`
    as well, giving the trie multiple roots:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: In order to fill up these maps with data, a method to add paths is required.
  prefs: []
  type: TYPE_NORMAL
- en: Adding paths
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The algorithm for inserting a string into a trie can be described in only a
    few sentences: go through each character of the word and trace it down the trie.
    If a node does not yet exist, create it, and add the object with the last entry.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Of course, there are special cases that need to be decided as well: what happens
    when a string already exists? Overwrite or ignore? In the case of this implementation,
    the last write will win—that is, it''s overwriting whatever existed previously:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: Another special case is the root node, since it's not a real node but a `HashMap`
    right away. Once a trie is set up, the most important thing is to get stuff out
    again!
  prefs: []
  type: TYPE_NORMAL
- en: Walking
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Add and search work in a very similar manner: follow the links to the characters
    of the key and return the "value" in the end:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Since the trie does not store strings in any particular order (or even consistently),
    getting the same data out in a predictable way is tricky! Walking it like a binary
    tree works well enough, but will only be deterministic with respect to the insertion
    order, something that should be kept in mind when testing the implementation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: As previously mentioned, this walk is called a breadth-first traversal.
  prefs: []
  type: TYPE_NORMAL
- en: Wrap up
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The trie data structure is a very efficient way of storing and finding strings
    by storing common prefixes, and they are often used in practice. One use case
    is the popular Java search engine Lucene, which uses this structure to store words
    in the search index, but there are plenty of other examples across different fields.
    Additionally, the simplicity is great for implementing a custom trie to store
    entire words or other objects instead of characters.
  prefs: []
  type: TYPE_NORMAL
- en: Upsides
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The inherent prefix is great for efficient storage and, apart from that, there
    are the following benefits:'
  prefs: []
  type: TYPE_NORMAL
- en: Easy implementation facilitates customizing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Minimal memory requirements for sets of strings
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Constant-time retrieval for strings with a known maximum length
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exotic algorithms are available (for example, Burst Sort)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: While the trie is great, it is also fairly simple, which comes with a number
    of downsides.
  prefs: []
  type: TYPE_NORMAL
- en: Downsides
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Tries can work in a lot of shapes and forms, but can''t handle every use case,
    unfortunately. Other disadvantages include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: It has a name that's strange to pronounce
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There is no deterministic order on walking
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are no duplicate keys
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This concludes the more exotic tree varieties. Next up is the B-Tree, which
    is essentially a universal tree!
  prefs: []
  type: TYPE_NORMAL
- en: B-Tree
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As you have noticed, restricting the number of children to 2 (like the binary
    trees earlier) yields a tree that only lets the algorithm decide whether to go
    left or right, and it's easily hardcoded. Additionally, storing only a single
    key-value pair in a node can be seen as a waste of space—after all, the pointers
    can be a lot larger than the actual payload!
  prefs: []
  type: TYPE_NORMAL
- en: 'B-Trees generally store multiple keys and values per node, which can make them
    more space-efficient (the payload-to-pointer ratio is higher). As a tree, each
    of these (key-value) pairs has children, which hold the values between the nodes
    they are located at. Therefore, a B-Tree stores triples of key, value, and child,
    with an additional child pointer to cover any "other" values. The following diagram
    shows a simple B-Tree. Note the additional pointer to a node holding smaller keys:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/8c99ddbf-3f3d-4424-9b49-6c6aed5f7d5c.png)'
  prefs: []
  type: TYPE_IMG
- en: As depicted here, a B-Tree can have varying amounts of those key-value pairs
    (only the keys are visible), but they will have a maximum number of children—defined
    by the *order* parameter. Consequently, a binary search tree can be considered
    an order-2 B-Tree, without the added benefit of being self-balancing.
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to achieve the self-balancing nature, a B-Tree has certain properties
    (as defined by Donald Knuth):'
  prefs: []
  type: TYPE_NORMAL
- en: Each node can only have *order* children
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Each node that is not a leaf node or root has at least *order/2* children
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The root node has at least two children
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: All nodes hold *order - 1* keys when they have *order* children
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: All leaf nodes appear on the same level
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'How does self-balancing work? It is way simpler than a red-black tree. Firstly,
    new keys can only be inserted at the leaf level. Secondly, once the new key has
    found a node, the node is evaluated to the preceding rules—in particular, if there
    are now more than *order - 1* keys. If that is the case, the node has to be split,
    moving the center key to the parent node, as shown in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5bc64dd2-6e9e-48d8-a778-49eef819928d.png)'
  prefs: []
  type: TYPE_IMG
- en: Next, the children are put in their intended position (especially important
    if the elevated node had children) and then the process is repeated up the tree
    until the root node is valid.
  prefs: []
  type: TYPE_NORMAL
- en: 'This process creates something that is called a **fat tree** (as opposed to
    a high tree), which means that adding height is only possible through splitting,
    which doesn''t happen very often. In order to work with the nodes, they contain
    additional information about themselves:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: In this case, the type of node is determined by a property, `node_type`, but
    the entire node could be wrapped into an enumeration as well. Furthermore, a special
    variable holding the "left child" has been attached in order to deal with keys
    lower than what is associated with the triples in the `keys` vector.
  prefs: []
  type: TYPE_NORMAL
- en: Like binary trees, the B-Tree exhibits logarithmic runtime complexity on search
    and insert (*O(log2(n))*) and, with the the simplified rebalancing, they make
    for a great choice for database indices. In fact, many SQL databases (such as
    SQLite and SQL Server) use B-Trees to store those search indices, and B+ Trees
    to store tables thanks to their smart ways of accessing the disk.
  prefs: []
  type: TYPE_NORMAL
- en: The product team has also heard about this and, since the previous attempts
    at the IoT device management solution have been a huge success, they thought about
    replacing the red-black tree with something better! They want to reduce the number
    of bugs by creating a more simplified version of the original database, so the
    requirements actually stay the same.
  prefs: []
  type: TYPE_NORMAL
- en: An IoT database
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As in the previous implementation, this tree builds on the `numerical_id` property
    of `IoTDevice` as keys, and the device object as value. In code, a node looks
    very similar to the previous example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: Instead of triples, this node type uses a synchronized index to find the children
    associated with a specified key-value pair. These pairs are also created ad hoc
    by evaluating the `numerical_id` property of the contained device, thereby also
    simplifying the code and eventual updates to the keys. Something that is missing
    from the node is a parent pointer, which made the entire red-black tree code significantly
    more complex.
  prefs: []
  type: TYPE_NORMAL
- en: 'The tree itself is stored as an `Option` on a boxed node (aliased as `Tree`),
    along with the `order` and `length` properties:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, to check the validity of the tree, here''s a `validate` method that
    recursively finds the minimum and maximum leaf height and checks whether the number
    of children is within bounds (as mentioned in the rules indicated earlier):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: Having established these basic structures, we can move on to how to add new
    devices to the tree.
  prefs: []
  type: TYPE_NORMAL
- en: Adding stuff
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'B-Trees add new entries to their leaves, which then bubble up as nodes grow
    too large. In order to efficiently find a spot, this is done recursively, removing
    and replacing ownership as needed. Here is the `add()` function, which takes care
    of retrieving ownership of the root node and calling the recursive call with an
    existing or new node:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'Except in the case of the root node, the `add_r()` function (the recursive
    call) returns two pieces of information: the key it descended into and—in case
    of a "promotion"—the device and child that are to be added to whichever node it
    returns to. In principle, this function works as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Recursively find the appropriate leaf and perform a sorted insert.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Increment the length if it's not a duplicate.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'If the node now has more keys than are allowed: split.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Return the original node and the key with its new value to the caller.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Place the new node where it came from.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add the promoted key.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Repeat from step 3 until at the root level:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: Since the root node is a special case where a new level is added to the tree,
    this has to be taken care of where the last split is happening—in the `add_r()`
    function. This is as simple as creating a new non-leaf node and adding the former
    root to the left and its sibling to the right, placing the new parent on top as
    the root node.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this implementation, a lot of the heavy lifting is done by the node''s implementation
    of several functions, including `split()`. While this is complex, it encapsulates
    the inner workings of the tree—something that should not be exposed too much so
    as to facilitate change:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: As described previously, splitting yields a new sibling to the original node
    and a new parent to both of them. The sibling will receive the upper half of the
    keys, the original node remains with the lower half, and the one in the center
    becomes the new parent.
  prefs: []
  type: TYPE_NORMAL
- en: Having added several devices, let's talk about how to get them back out.
  prefs: []
  type: TYPE_NORMAL
- en: Searching for stuff
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A B-Tree''s search works just the way binary tree searches do: recursively
    checking each node for the path to follow. In B-Trees, this becomes very convenient
    since it can be done in a loop, in this case, by the `get_device()` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'This function is implemented at the node structure and does a regular linear
    search for the key itself. If it is unable to find that key, the `find_r()` function
    has to decide whether to continue, which it does by evaluating the node type.
    Since leaf nodes don''t have any children, not finding the desired key will end
    the search, returning `None`. Regular nodes allow the search to continue on a
    deeper level of the tree:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: Another method for finding something within the tree's values is walking the
    tree.
  prefs: []
  type: TYPE_NORMAL
- en: Walking the tree
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Similarly to the binary trees earlier in this chapter, walking can be done
    with different strategies, even if there are many more branches to walk. The following
    code shows an in-order tree walking algorithm, where the callback is executed
    between the left child and before descending into the child that is currently
    looked at:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: Thanks to the internal sorting, this walk retrieves the keys in an ascending
    order.
  prefs: []
  type: TYPE_NORMAL
- en: Wrap up
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: B-Trees are awesome. They are widely used in real-world applications, their
    implementation in Rust is not all that complex, and they maintain a great performance
    regardless of insertion order. Furthermore, the tree's order can dramatically
    improve performance by decreasing the tree's height. It is recommended to estimate
    the number of key-value pairs beforehand and adjust the order accordingly.
  prefs: []
  type: TYPE_NORMAL
- en: 'As a benchmark, let''s evaluate the trees by inserting 100,000 unsorted, unique
    elements, and retrieving them using `find()`. Dot size represents the variance,
    while the values shown along the *y* axis are nanoseconds:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/320a2f24-c980-4899-a5cb-27c43debf797.png)'
  prefs: []
  type: TYPE_IMG
- en: The chart output of Unsorted find ()
  prefs: []
  type: TYPE_NORMAL
- en: Other than that, it performs at the level of other trees, with vastly fewer
    lines of code and less code complexity, both of which impact readability and maintainability
    for other developers.
  prefs: []
  type: TYPE_NORMAL
- en: Upsides
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This type of tree achieves great performance with the order parameter set accordingly:'
  prefs: []
  type: TYPE_NORMAL
- en: Less complex to implement than other self-balancing trees
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Widely used in database technology
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Predictable performance thanks to self-balancing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Range queries are possible
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Variants that minimize disk access (B+ Tree)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The tree's downsides are few.
  prefs: []
  type: TYPE_NORMAL
- en: Downsides
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Absolute performance depends significantly on the tree's order; other than that,
    this tree does not have many downsides.
  prefs: []
  type: TYPE_NORMAL
- en: Graphs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In their most generic form, trees are graphs—directed, acyclic graphs. A general
    graph can be described as a collection of connected nodes, sometimes referred
    to as vertices, with certain properties such as whether cycles are allowed. The
    connections between those also have their own name: edges. These edges can have
    certain properties as well, in particular, weights and directions (like one-way
    streets).'
  prefs: []
  type: TYPE_NORMAL
- en: 'By enforcing these constraints, a model can be built that, just like trees,
    reflects a certain reality very well. There is one particular thing that is typically
    represented as a weighted graph: the internet. While, nowadays, this might be
    an oversimplification, with various versions of the Internet Protocol (IPv4 and
    IPv6) and **Network Address Translation** (**NAT**) technologies hiding large
    numbers of participants online, in its earlier days, the internet could be drawn
    as a collection of routers, computers, and servers (nodes) interconnected with
    links (edges) defined by speed and latency (weights).'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following diagram shows a random, undirected, unweighted graph:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d334d74d-a7fe-4d1b-9ae7-afeb995e1afd.png)'
  prefs: []
  type: TYPE_IMG
- en: Other than humans, who can typically see and follow a reasonably efficient path
    through this mesh of interconnected nodes, computers require specific instructions
    to find anything in there! This called for new algorithms that allow for dealing
    with this complexity—which is especially tricky once the number of nodes in the
    mesh exceeds the number of nodes that can be looked at in time. This led to the
    development of many routing algorithms, techniques to finding cycles and segmenting
    the network, or popular NP-hard problems, such as the traveling salesman problem
    or the graph-coloring problem. The traveling salesman problem is defined as follows.
  prefs: []
  type: TYPE_NORMAL
- en: 'Find the optimal (shortest) path between cities without visiting one twice.
    On the left are some cities in Europe; on the right, two possible solutions (dotted
    versus solid lines):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6ab202ba-48ca-4742-a8eb-2c52e0348ebe.png)'
  prefs: []
  type: TYPE_IMG
- en: Today, there are many examples of graphs, the most obvious being a social graph
    (in social networks), but also as part of TensorFlow's deep learning API, state
    machines, and the rise of graph databases that offer a generic query language
    to traverse graphs. Even some less obvious use cases can be found, such as storing
    genetic sequences (nodes being the small parts of the DNA)!
  prefs: []
  type: TYPE_NORMAL
- en: 'To get out of theoretical constructs, how would you represent a graph in a
    program *efficiently*? As a node structure with a list of outbound vertices? How
    would you find a particular node then? A tricky problem! Graphs also have the
    habit of growing quite large, as anyone who ever wanted to serialize object graphs
    to JSON can testify: they run out of memory quite easily.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The best way to work with this data structure is surprisingly simple: a matrix.
    This matrix can either be sparse (that is, a list of lists with varying sizes),
    called an **adjacency list**, or a full-blown matrix (adjacency matrix). Especially
    for a matrix, the size is typically the number of nodes on either side and the
    weights (or Boolean values representing "connected" or "not connected") at each
    crossing. Many implementations will also keep the "real" nodes in its own list,
    using the indices as IDs. The following diagram shows how to display a graph as
    a matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/30d9f986-73f7-43d2-95b7-86c0f0d2fd54.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Rust provides many great tools for implementing really complex graph structures:
    enumerations and pattern-matching provide ways to operate on types of nodes and
    edges with low overhead, while iterators and functional approaches remove the
    need for verbose loops. Let''s look at a generic graph structure in Rust:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: This adjacency list can store nodes and whether they are connected, making this
    a finite, undirected, unweighted graph—great for storing simple relationships
    between objects. Already, a data structure such as this has the ability to implement
    sophisticated routing algorithms or run out of resources on a backtracking algorithm.
    In an adjacency list, each index in the list represents the origin of an edge
    and the contained elements (also lists) are any outbound edges. To traverse the
    graph, start at an origin index and find the next index by searching its edges.
    Then repeat until arriving at the destination node!
  prefs: []
  type: TYPE_NORMAL
- en: 'When the product team heard of this amazing data structure—and they are now
    well aware of your abilities—they came up with a new product: the literal Internet
    of Things (it''s a working title). Their idea is to provide customers with a way
    to model complex sensor placements that would have distance built in! Customers
    can then go and evaluate all sensors that are within a certain range of each other,
    find single points of failure, or plan a route to inspect them quickly.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To summarize, customers should be able to do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Create or add a list of nodes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Connect nodes with their physical distance to each other
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Find the shortest path between two nodes with respect to the distance provided
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Retrieve a list of neighbors of a specified node, up to a certain degree
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Great idea, right? A great fit for graphs as well.
  prefs: []
  type: TYPE_NORMAL
- en: The literal Internet of Things
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In order to get a head start on these requirements, the decision for a graph
    representation has to be made: list or matrix? Both work well, but for explanatory
    reasons, the examples will go with an adjacency list built on top of a vector
    of vectors:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'As previously mentioned, it makes sense to keep the actual values, identifiers,
    or even entire objects in their own list and simply work with indices of the `usize`
    type. The edge structure in this example could be represented as a tuple just
    as well, but it''s way more readable this way:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'Having those two structures in place, adding nodes (or... things) to the graph
    can be done with only a few lines:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'Within that function, there is a crucial check that''s made: every edge has
    to connect to a valid node, otherwise it will not be added to the graph. To achieve
    this, the code looks up the IDs provided in the `edges` parameter in its internal
    node storage to find the index it''s at, something that is done by the `position()`
    function of Rust''s iterator trait. It returns the position of when the provided
    predicate returns true! Similarly, the `filter_map()` function of the iterator
    will only include elements that evaluate to `Some()` (as opposed to `None`) in
    its result set. Therefore, the nodes have to have a setter that also initializes
    the adjacency list:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: Once that's done, the graph is ready to use. How about we go looking for neighbors
    first?
  prefs: []
  type: TYPE_NORMAL
- en: Neighborhood search
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Neighborhood search is a very trivial algorithm: starting from the node provided,
    follow every edge and return what you find. In our case, the degree of the relationship
    is important.'
  prefs: []
  type: TYPE_NORMAL
- en: Just like for the tree algorithms shown previously, recursion is a great choice
    for solving this problem. While an iterative solution will often be more memory-efficient
    (no stack overflows), recursion is way more descriptive once you get the hang
    of it. Additionally, some compilers (and partly `rustc`, but not guaranteed) will
    expand the recursion into a loop, providing the best of both worlds (look for
    tail call optimization)! Obviously, the most important thing is to have a projected
    growth in mind; 100,000 recursive calls are likely to fill up the stack.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, the function to run the neighborhood is implemented two-fold. First,
    the public-facing function takes care of validating input data and sees whether
    the node actually exists:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'With that out of the way, the recursive call can create a list of all its neighbors
    and run the same call on each of them. Returning a set of nodes eliminates the
    duplicates as well:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'Since the recursive call returns the internal representation (that is, indices),
    the outer function translates those back into data the user can understand. This
    function can serve as a basis for other features, such as intersecting the neighborhoods
    of two nodes, and vicinity search. Or, to make it more real, on a sensor outage,
    the company can check whether there is a common device that''s responsible (intersection),
    or if other close-by sensors are reporting similar measurements to rule out malfunctions
    (neighborhood search). Now, let''s move on to something more complex: finding
    the shortest path.'
  prefs: []
  type: TYPE_NORMAL
- en: The shortest path
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This algorithm has its roots in early networking: routers had to decide where
    to forward packets to, without having any knowledge of what''s beyond. They simply
    had to make the best decision without having perfect information! Edsger Dijkstra,
    one of the pioneers of computer science, then came up with a graph-routing algorithm
    that has been named after him: Dijkstra''s algorithm.'
  prefs: []
  type: TYPE_NORMAL
- en: The algorithm works iteratively and goes over each node to add up their weights,
    thereby finding the distance (or cost) of reaching this node. It will then continue
    at the node with the lowest cost, which makes this algorithm a "greedy" algorithm.
    This continues until the desired node is reached or there are no more nodes to
    evaluate.
  prefs: []
  type: TYPE_NORMAL
- en: Algorithms that immediately converge toward what's best right now (**local optimum**)
    in order to find the best overall solution (**global optimum**) are called **greedy
    algorithms**. This, of course, is tricky, since the path to a global optimum might
    require the acceptance of an increased cost! There is no guaranteed way to finding
    the global optimum, so it's about reducing the probability of getting stuck in
    a local optimum. A well-known greedy algorithm in 2018 is stochastic gradient
    descent, which is used to train neural networks.
  prefs: []
  type: TYPE_NORMAL
- en: 'In code, this is what that looks like:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'Since this is a long one, let''s break it down. This is boiler-plate code to
    ensure that both source and destination nodes are nodes in the graph:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: Then, each node gets a tentative weight assigned, which is infinite in the beginning,
    except for the origin node, which has zero cost to reach. The "open" list, which
    contains all the nodes yet to be processed, is conveniently created using Rust's
    range—as it corresponds to the indices we are working with.
  prefs: []
  type: TYPE_NORMAL
- en: The parent array keeps track of each node's parent once the lower cost is established,
    which provides a way to trace back the best possible path!
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: Now, let's plunge into the path-finding. The helper function, `min_index()`,
    takes the current distances and returns the index of the node that is easiest
    (as in lowest distance) to reach next. This node will then be removed from the
    open list. Here's a good point at which to also stop if the destination has been
    reached. For more thoughts on this, see the preceding information box on greedy
    algorithms. Setting `found` to `true` will help distinguish between no result
    and early stopping.
  prefs: []
  type: TYPE_NORMAL
- en: 'For each edge of this node, the new distance is computed and, if lower, inserted
    into a distance list (as seen from the source node). There are a lot of clones
    going on as well, which is due to ensuring not borrowing while updating the vector.
    With `u64` (or `u32`) types, this should not create a large overhead (pointers
    are typically that large too), but for other types, this can be a performance
    pitfall:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'After this loop exits, there is a distance array and a parent array to be prepared
    for returning to the caller. First, trace back the path from the destination to
    the origin node in the parent array, which leads to the reverse optimal path between
    the two nodes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: By strictly following the node with the lowest distance, Dijkstra's algorithm
    achieves a great runtime when stopping early, and runtime can even be improved
    by using more efficient data structures (such as a heap) to fetch the next node
    efficiently.
  prefs: []
  type: TYPE_NORMAL
- en: Modern approaches to shortest paths in a graph typically use the *A** (pronounced
    "a star") algorithm. While it operates on the same principles, it is also a bit
    more complex and would therefore go beyond the scope of this book.
  prefs: []
  type: TYPE_NORMAL
- en: Wrap up
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A graph is surprisingly straightforward to implement: clear ownership in adjacency
    lists or matrices makes them almost effortless to work with! On top of that, there
    are two additional aspects that weren''t yet covered in this implementation: an
    enumeration with an implementation, and using regular operations (here: comparison)
    with this implementation.'
  prefs: []
  type: TYPE_NORMAL
- en: This shows how conforming to standard interfaces provides great ways to interface
    with the standard library or well-known operations in addition to the flexibility
    enumerations provide. With a few lines of code, infinity can be represented and
    worked with in a readable way. It was also a step toward more algorithmic aspects,
    which will be covered later in the book. For now, let's focus on graphs again.
  prefs: []
  type: TYPE_NORMAL
- en: Upsides
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Graph structures are unique and there are rarely other ways of achieving the
    same outcome. Working in this environment enables you to focus deeply on relationships
    and think about problems differently. Following are some upsides of using graphs:'
  prefs: []
  type: TYPE_NORMAL
- en: Are amazing in modeling relationships
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Efficient retrieval of dependencies of a specific node
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Simplify complex abstractions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Enable certain problems to be solved at all
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Whether you choose a matrix or list representation is often a subjective choice
    and, for example, while the matrix provides easy deletes, a list stores edges
    more efficiently in the first place. It's all a trade-off.
  prefs: []
  type: TYPE_NORMAL
- en: Downsides
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This leads us to the downsides of this particular data structure:'
  prefs: []
  type: TYPE_NORMAL
- en: Unable to solve certain problems efficiently (for example, a list of all nodes
    that have a certain property)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More resource-inefficient
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Unsolved problems exist (for example, the traveling salesman problem with a
    high number of cities)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Typically requires a problem to be reconsidered
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With this, we can conclude this chapter about trees and their relatives after
    a summary.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This chapter went deep into trees, starting off with the simplest form: the
    binary search tree. This tree prepares the inserted data for search by creating
    a left and a right branch which hold smaller or greater values. A search algorithm
    can therefore just pick the direction based on the current node and the value
    coming in, thereby skipping a majority of the other nodes.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The regular binary search tree has a major drawback, however: it can become
    unbalanced. Red-black trees provide a solution for that: by rotating subtrees,
    a balanced tree structure is maintained and search performance is guaranteed.'
  prefs: []
  type: TYPE_NORMAL
- en: Heaps are a more exotic use of the tree structure. With their primary use as
    a priority queue, they efficiently produce the lowest or highest number of an
    array in constant time. The upheap and downheap operations repair the structure
    upon insert or removal so that the root is again the lowest (min-heap) or highest
    (max-heap) number.
  prefs: []
  type: TYPE_NORMAL
- en: Another very exotic structure is the trie. They are specialized in holding strings
    and very efficiently find the data associated with a certain string by combining
    the characters as nodes with words "branching off" as required.
  prefs: []
  type: TYPE_NORMAL
- en: To go up in the generalization level, B-Trees are a generic form of a tree.
    They hold several values, with the ranges between them leading to a child node.
    Similar to red-black trees, they are balanced, and adding nodes only happens at
    the leaves where they may be "promoted" to a higher level. Typically, these are
    used in database indices.
  prefs: []
  type: TYPE_NORMAL
- en: 'Last but not least, the most generic form of a tree: the graph. Graphs are
    a flexible way to express constrained relationships, such as no cycles, and directionality.
    Typically, each node has weighted connections (edges) that provide some notion
    of cost of transitioning between the nodes.'
  prefs: []
  type: TYPE_NORMAL
- en: With some of the essential data structures covered, the next chapter will explore
    sets and maps (sometimes called dictionaries). In fact, some of those have already
    been used in this chapter, so the next chapter will focus on implementing our
    own.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: How does a binary search tree skip several nodes when searching?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What are self-balancing trees?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Why is balance in a tree important?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Is a heap a binary tree?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What are good use cases for tries?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What is a B-Tree?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What are the fundamental components of a graph?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
