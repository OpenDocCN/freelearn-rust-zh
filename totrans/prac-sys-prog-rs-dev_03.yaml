- en: '*Chapter 2*: A Tour of the Rust Programming Language'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapter, we looked at the Rust tooling ecosystem for build and
    dependency management, testing, and documentation. These are critical and highly
    developer-friendly tools that give us a strong foundation for starting to work
    on Rust projects. In this chapter, we will build a working example that will serve
    to act as a refresher, and also strengthen key Rust programming concepts.
  prefs: []
  type: TYPE_NORMAL
- en: The goal of this chapter is to get more proficient in core Rust concepts. This
    is essential before diving into the specifics of systems programming in Rust.
    We will achieve this by designing and developing a **command-line interface**
    (**CLI**) in Rust.
  prefs: []
  type: TYPE_NORMAL
- en: The application we will be building is an **arithmetic expression evaluator**.
    Since this is a mouthful, let's see an example.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s assume the user enters the following arithmetic expression on the command
    line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The tool will print out the result **21.79**.
  prefs: []
  type: TYPE_NORMAL
- en: For the user, it appears to be a calculator, but there is a lot involved to
    implement this. This example project will introduce you to the core computer science
    concepts used in parsers and compiler design. It is a non-trivial project that
    allows us to test the depths of core Rust programming, but is not so overly complex
    that it will intimidate you.
  prefs: []
  type: TYPE_NORMAL
- en: Before you continue reading, I would recommend that you clone the code repository,
    navigate to the `chapter2` folder, and execute the `cargo run` command. At the
    command-line prompt, enter a few arithmetic expressions and see the results returned
    by the tool. You can exit the tool with *Ctrl* + *C*. This would give you a better
    appreciation for what you are going to build in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following are the key learning steps for this chapter, which correspond
    to the various stages of building our project:'
  prefs: []
  type: TYPE_NORMAL
- en: Analyzing the problem domain
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Modeling system behavior
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building the tokenizer
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building the parser
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building the evaluator
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dealing with errors
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building a command-line application
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You should have Rustup and Cargo installed in your local development environment.
  prefs: []
  type: TYPE_NORMAL
- en: The GitHub repository for the code in this chapter can be found at [https://github.com/PacktPublishing/Practical-System-Programming-for-Rust-Developers/tree/master/Chapter02](https://github.com/PacktPublishing/Practical-System-Programming-for-Rust-Developers/tree/master/Chapter02).
  prefs: []
  type: TYPE_NORMAL
- en: Analyzing the problem domain
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will define the scope of the project and the technical challenges
    that we need to address.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding and analyzing the problem domain is the first step in building
    any system. It is important to unambiguously articulate the problem we are trying
    to solve, and the boundaries of the system. These can be captured in the form
    of system requirements.
  prefs: []
  type: TYPE_NORMAL
- en: Let's look at the requirements for the CLI tool we are going to build.
  prefs: []
  type: TYPE_NORMAL
- en: The tool should accept an arithmetic expression as input, evaluate it, and provide
    the numerical output as a floating-point number. For example, the expression *1+2*3.2+(4/2-3/2)-2.11+2^4*
    should evaluate to *21.79*.
  prefs: []
  type: TYPE_NORMAL
- en: The arithmetic operations in scope are **addition** (**+**), **subtraction**
    (**-**), **multiplication** (*****), **division** (**/**), **power** (**^**),
    the **negative prefix** (**-**), and expressions enclosed in **parentheses** **()**.
  prefs: []
  type: TYPE_NORMAL
- en: Mathematical functions such as trigonometric and logarithmic functions, absolute,
    square roots, and so on are *not* in scope.
  prefs: []
  type: TYPE_NORMAL
- en: 'With such an expression, the challenges that need to be resolved are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: The user should be able to input an arithmetic expression as *free text* on
    the command line. Numbers, arithmetic operators, and parentheses (if any) should
    be segregated and processed with different sets of rules.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The rules of *operator precedence* must be taken into account (for example,
    multiplication takes precedence over addition).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Expressions enclosed within *parentheses ()* must be given *higher precedence*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The user may not give spaces between the number and operator, but still the
    program must be capable of *parsing inputs with or without spaces* between the
    characters.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If numbers contain a *decimal point*, continue reading the rest of the number
    until an operator or parenthesis is encountered.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Invalid inputs* should be dealt with and the program should abort with a suitable
    error message. Here are some examples of invalid input:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Invalid input 1**: Since we don''t deal with variables in this program, if
    a character is entered, the program should exit with a suitable error message
    (for example, *2 ** *a* is invalid input).'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Invalid input 2**: If only a single parenthesis is encountered (without a
    matching closing parenthesis), the program should exit with an error message.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Invalid input 3**: If the arithmetic operator is not recognized, the program
    should exit with an error message.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: There are clearly other types of edge cases that can cause errors. But we will
    focus only on these. The reader is encouraged to implement other error conditions
    as a further exercise.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we know the scope of what we are going to build, let's design the system.
  prefs: []
  type: TYPE_NORMAL
- en: Modeling the system behavior
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the last section, we confirmed the system requirements. Let''s now design
    the logic for processing the arithmetic expression. The components of the system
    are shown in *Figure 2.1*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.1 – Design of an arithmetic expression evaluator](img/Figure_2.1_B16405.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.1 – Design of an arithmetic expression evaluator
  prefs: []
  type: TYPE_NORMAL
- en: 'The components shown in the preceding figure work together as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: The user enters an arithmetic expression at the command-line input and presses
    the *Enter* key.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The user input is scanned in its entirety and stored in a local variable.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The arithmetic expression (from the user) is scanned. The numbers are stored
    as tokens of the `Numeric` type. Each arithmetic operator is stored as a token
    of that appropriate type. For example, the `+` symbol will be represented as a
    token of type `Add`, and the number `1` will be stored as a token of type `Num`
    with a value of `1`. This is done by the `Lexer` (or `Tokenizer`) module.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: An `1+2*3`, the product of `2` and `3` must be evaluated before the addition
    operator. Also, any sub-expressions enclosed within parentheses must be evaluated
    on a higher priority. The final AST will reflect all such processing rules. This
    is done by the `Parser` module.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: From the constructed AST, the last step is to evaluate each node of the AST
    in the right sequence, and aggregate them to arrive at the final value of the
    complete expression. This is done by the `Evaluator` module.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The final computed value of the expression is displayed on the command line
    as a program output to the user. Alternatively, any error in processing is displayed
    as an error message.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This is the broad sequence of steps for processing. We will now take a look
    at translating this design into Rust code.
  prefs: []
  type: TYPE_NORMAL
- en: Differences between lexers, parsers, and ASTs
  prefs: []
  type: TYPE_NORMAL
- en: '*Lexers* and *parsers* are concepts used in computer science to build *compilers*
    and *interpreters*. A *lexer* (also called a *tokenizer*) splits text (source
    code) into words and assigns a *lexical* meaning to it such as *keyword*, *expression*,
    *operator*, *function call*, and so on. *Lexers* generate tokens (hence the name
    *tokenizer*).'
  prefs: []
  type: TYPE_NORMAL
- en: A *parser* takes the output of the *lexer* and arranges the tokens into a tree
    structure (a tree is a type of data structure). Such a tree structure is also
    called an *AST*. With the *AST*, the compiler can generate machine code and the
    interpreter can evaluate an instruction. *Figure 2.7* of this chapter shows an
    illustration of an *AST*.
  prefs: []
  type: TYPE_NORMAL
- en: The lexing and parsing phases are two different steps in the compilation process,
    but in some cases they are combined. Note that concepts such as *lexers*, *parsers*,
    and *ASTs* have a broader range of applications beyond just compilers or interpreters,
    such as to render HTML web pages or SVG images.
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ve so far seen the high-level design of the system. Let''s now understand
    how the code will be organized. A visual representation of the project structure
    is shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.2 – Code structure for the project](img/Figure_2.2_B16405.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.2 – Code structure for the project
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s check each one of those paths:'
  prefs: []
  type: TYPE_NORMAL
- en: '`src/parsemath`: The module containing the core processing logic'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`src/parsemath/ast.rs`: Contains the AST code'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`src/parsemath/parser.rs`: Contains code for the parser'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`src/parsemath/tokenizer.rs`: Contains code for the tokenizer'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`src/parsemath/token.rs`: Contains the data structures for token and operator
    precedence'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`src/main.rs`: The main command-line application'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let''s now set up the project as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Create a new project with `cargo new chapter2 && cd chapter2`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a folder named `parsemath` under the `src` folder.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Create the following files within the `src/parsemath` folder: `ast.rs`, `token.rs`,
    `tokenizer.rs`, `parser.rs`, and `mod.rs`.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Add the following to `src/parsemath/mod.rs`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note that the Rust module system was used to structure this project. All functionality
    related to parsing is in the `parsemath` folder. The `mod.rs` file in this folder
    indicates this is a Rust module. The `mod.rs` file exports the functions in the
    various files contained in this folder and makes it available to the `main()`
    function. In the `main()` function, we then register the `parsemath` module so
    that the module tree is constructed by the Rust compiler. Overall, the Rust module
    structure helps us organize code in different files in a way that is flexible
    and maintainable.
  prefs: []
  type: TYPE_NORMAL
- en: Important note on code snippets in this chapter
  prefs: []
  type: TYPE_NORMAL
- en: This chapter goes through the design of the command-line tool in detail, supplemented
    by illustrations with diagrams. The code snippets for all the key methods are
    also provided with explanations. However, in some places, a few elements to complete
    the code, such as module imports, test scripts, and definitions of `impl` blocks,
    are not included here but can be directly found in the GitHub repo. Please keep
    this in mind if you choose to code along. Otherwise, you can follow the explanations
    in this chapter in conjunction with the completed code in the code repository.
  prefs: []
  type: TYPE_NORMAL
- en: Also a heads-up that you will see usage of the `?` operator in the upcoming
    sections on building the tokenizer, parser, and evaluator. Just bear in mind that
    *?* is a shortcut for error handling, in order to propagate errors automatically
    from a given function to its calling function. This will be explained in the later
    *Dealing with errors* section.
  prefs: []
  type: TYPE_NORMAL
- en: We're set now. Let's get started.
  prefs: []
  type: TYPE_NORMAL
- en: Building the tokenizer
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The **tokenizer** is the module in our system design that reads one or more
    characters from an arithmetic expression and translates it into a *token*. In
    other words, *input* is a set of characters and *output* is a set of tokens. In
    case you are wondering, examples of tokens are *Add*, *Subtract*, and *Num(2.0)*.
  prefs: []
  type: TYPE_NORMAL
- en: 'We have to first create a data structure for two things:'
  prefs: []
  type: TYPE_NORMAL
- en: To store the *input* arithmetic expression from the user
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To represent the *output* tokens
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the following section, we will delve into how to determine the right data
    structures for the `tokenizer` module.
  prefs: []
  type: TYPE_NORMAL
- en: Tokenizer data structure
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To store the input arithmetic expression, we can choose among the following
    data types:'
  prefs: []
  type: TYPE_NORMAL
- en: String slice
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: String
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will choose the `&str` type, as we do not need to own the value or dynamically
    increase the size of the expression. This is because the user will provide the
    arithmetic expression once, and then the expression won't change for the duration
    of processing.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is one possible representation of the `Tokenizer` data structure:'
  prefs: []
  type: TYPE_NORMAL
- en: src/parsemath/tokenizer.rs
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: If we took this approach, we may run into a problem. To understand the problem,
    let's understand how tokenization takes place.
  prefs: []
  type: TYPE_NORMAL
- en: For the expression *1+21*3.2*, the individual characters scanned will appear
    as eight separate values, *1, +, 2, 1, *, 3, ., 2*.
  prefs: []
  type: TYPE_NORMAL
- en: 'From this, we will have to extract the following five tokens:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Num(1.0)*, *Add*, *Num(21.0)*, *Multiply*, *Num(3.2)*'
  prefs: []
  type: TYPE_NORMAL
- en: In order to accomplish this, we not only need to read a character to convert
    it into a token, but also take a look at the character beyond the next one. For
    example, given the input expression *1+21*3.2*, to tokenize number *21* into *Num(21)*,
    we need to read character *2*, followed by *1*, followed by *** in order to conclude
    that the second operand for the first addition operation has a value of *21*.
  prefs: []
  type: TYPE_NORMAL
- en: In order to accomplish this, we have to convert the string slice into an iterator,
    which not only allows us to iterate through the string slice to read each character,
    but also allows us to *peek* ahead and see value of the character following that.
  prefs: []
  type: TYPE_NORMAL
- en: Let's see how to implement an iterator over the string slice. Rust incidentally
    has a built-in type for this. It's a part of the `str` module in the standard
    library and the struct is called `Chars`.
  prefs: []
  type: TYPE_NORMAL
- en: 'So, the definition of our `Tokenizer` struct could look as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: src/parsemath/tokenizer.rs
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Note that we have changed the type of the `expr` field from a string slice (`&str`)
    to an iterator type (`Chars`). `Chars` is an iterator over the characters of a
    string slice. This will allow us to do iterations on `expr` such as `expr.next()`,
    which will give the value of the next character in the expression. But we also
    need to take a peek at the character following the next character in the input
    expression, for reasons we mentioned earlier.
  prefs: []
  type: TYPE_NORMAL
- en: 'For this, the Rust standard library has a struct called `Peekable` , which
    has a `peek()` method. The usage of `peek()` can be illustrated with an example.
    Let''s take the arithmetic expression `1+2`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Because we will store this expression in the `expr` field of `Tokenizer`, which
    is of the `peekable iterator` type, we can perform `next()` and `peek()` methods
    on it in sequence, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '`expression.next()` returns `1`. The iterator now points to character `1`.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Then, `expression.peek()` returns `+` but does not consume it, and the iterator
    still points to character `1`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Then, `expression.next()` returns `+`, and the iterator now points to character
    `+`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Then, `expression.next()` returns `2`, and the iterator now points to character
    `2`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'To enable such an iteration operation, we will define our `Tokenizer` struct
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: src/parsemath/tokenizer.rs
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: We are still not done with the `Tokenizer` struct. The earlier definition would
    throw a compiler error asking to add a lifetime parameter. *Why is this?,* you
    may ask.
  prefs: []
  type: TYPE_NORMAL
- en: 'Structs in Rust can hold references. But Rust needs explicit lifetimes to be
    specified when working with structs that contain references. That is the reason
    we get the compiler error on the `Tokenizer` struct. To fix this, let''s add lifetime
    annotation:'
  prefs: []
  type: TYPE_NORMAL
- en: src/parsemath/tokenizer.rs
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: You can see that the `Tokenizer` struct has been given a lifetime annotation
    of `'a`. We have done this by declaring the name of the generic lifetime parameter
    `'a` inside angle brackets after the name of the struct. This tells the Rust compiler
    that any reference to the Tokenizer struct cannot outlive the reference to the
    characters it contains.
  prefs: []
  type: TYPE_NORMAL
- en: Lifetimes in Rust
  prefs: []
  type: TYPE_NORMAL
- en: In system languages such as C/C++, operations on references can lead to unpredictable
    results or failures, if the value associated with the reference has been freed
    in memory.
  prefs: []
  type: TYPE_NORMAL
- en: In Rust, every reference has a lifetime, which is the scope for which the lifetime
    is valid. The Rust compiler (specifically, the borrow checker) verifies that the
    lifetime of the reference is not longer than the lifetime of the underlying value
    pointed to by the reference.
  prefs: []
  type: TYPE_NORMAL
- en: How does the compiler know the lifetime of references? Most of the time, the
    compiler tries to infer the lifetime of references (called **elision**). But where
    this is not possible, the compiler expects the programmer to annotate the lifetime
    of the reference explicitly. Common situations where the compiler expects explicit
    lifetime annotations are in *function signatures* where two or more arguments
    are references, and in *structs* where one or more members of the struct are reference
    types.
  prefs: []
  type: TYPE_NORMAL
- en: More details can be found in the Rust documentation, at [https://doc.rust-lang.org/1.9.0/book/lifetimes.html](https://doc.rust-lang.org/1.9.0/book/lifetimes.html).
  prefs: []
  type: TYPE_NORMAL
- en: As explained, the `Tokenizer` struct, we pass the string reference to it, which
    contains the arithmetic expression. As per the conventional rules of variable
    scoping (common to most programming languages), the `expr` variable needs to be
    valid for the duration that the `Tokenizer` object is in existence. If the value
    corresponding to the `expr` reference is deallocated while the `Tokenizer` object
    is in existence, then it constitutes a dangling (invalid) reference scenario.
    To prevent this, we tell the compiler through the lifetime annotation of `<'a>`
    that the `Tokenizer` object cannot outlive the reference it holds in the `expr`
    field.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following screenshot shows the `Tokenizer` data struct:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.3 – The Tokenizer struct](img/Figure_2.3_B16405.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.3 – The Tokenizer struct
  prefs: []
  type: TYPE_NORMAL
- en: We've seen so far how to define the `Tokenizer` struct, which contains the reference
    to input arithmetic expression. We will next take a look at how to represent the
    tokens generated as output from the `Tokenizer`.
  prefs: []
  type: TYPE_NORMAL
- en: To be able to represent the list of tokens that can be generated, we have to
    first consider the data type of these tokens. Since the tokens can be of the `Num`
    type or one of the operator types, we have to pick a data structure that can accommodate
    multiple data types. The data type options are tuples, HashMaps, structs, and
    enums. If we add the constraint that the type of data in a token can be one of
    many predefined *variants* (allowed values), that leaves us with just one option—*enums*.
    We will define the tokens using the `enum` data structure.
  prefs: []
  type: TYPE_NORMAL
- en: 'The representation of tokens in the `enum` data structure is shown in the following
    screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.4 – Token enum](img/Figure_2.4_B16405.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.4 – Token enum
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is the explanation for what value gets stored in the `Token enum`:'
  prefs: []
  type: TYPE_NORMAL
- en: If the `+` character is encountered, the `Add` token is generated.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the `-` character is encountered, the `Subtract` token is generated.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the `*` character is encountered, the `Multiply` token is generated.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the `/` character is encountered, the `Divide` token is generated.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the `^` character is encountered, the `Caret` token is generated.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the `(` character is encountered, the `LeftParen` token is generated.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the `)` character is encountered, the `RightParen` token is generated.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If any number `x` is encountered, the `Num(x)` token is generated.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If `EOF` is encountered (at the end of scanning the entire expression), the
    `EOF` token is generated.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now that we have defined the data structures to capture the *input* (arithmetic
    expression) and *outputs* (tokens) for the `Tokenizer` module, we now can write
    the code to do the actual processing.
  prefs: []
  type: TYPE_NORMAL
- en: Tokenizer data processing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The following screenshot shows the `Tokenizer` with its data elements and methods:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.5 – The Tokenizer with its methods](img/Figure_2.5_B16405.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.5 – The Tokenizer with its methods
  prefs: []
  type: TYPE_NORMAL
- en: 'The `Tokenizer` has two public methods:'
  prefs: []
  type: TYPE_NORMAL
- en: '`new()`: Creates a new tokenizer using the arithmetic expression provided by
    the user'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`next()`: Reads the characters in the expression and return the next token'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following screenshot shows the full design of the `Tokenizer` module:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.6 – Tokenizer module design](img/Figure_2.6_B16405.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.6 – Tokenizer module design
  prefs: []
  type: TYPE_NORMAL
- en: 'The code for the `new()` method is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: src/parsemath/tokenizer.rs
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: You'll notice that we are declaring a lifetime for `Tokenizer` in the `impl`
    line. We are repeating `'a` twice. `Impl<'a>` declares the lifetime `'a`, and
    `Tokenizer<'a>` uses it.
  prefs: []
  type: TYPE_NORMAL
- en: Observations on lifetimes
  prefs: []
  type: TYPE_NORMAL
- en: 'You''ve seen that for `Tokenizer`, we declare its lifetime in three places:'
  prefs: []
  type: TYPE_NORMAL
- en: 1) The declaration of the `Tokenizer` struct
  prefs: []
  type: TYPE_NORMAL
- en: 2) The declaration of the `impl` block for the `Tokenizer` struct
  prefs: []
  type: TYPE_NORMAL
- en: 3) The method signature within the `impl` block
  prefs: []
  type: TYPE_NORMAL
- en: This may seem verbose, but Rust expects us to be specific about lifetimes because
    that's how we can avoid memory-safety issues such as *dangling pointers* or *use-after-free*
    errors.
  prefs: []
  type: TYPE_NORMAL
- en: The `impl` keyword allows us to add functionality to the `Tokenizer` struct.
    The `new()` method accepts a string slice as a parameter that contains a reference
    to the arithmetic expression input by the user. It constructs a new `Tokenizer`
    struct initialized with the supplied arithmetic expression, and returns it from
    the function.
  prefs: []
  type: TYPE_NORMAL
- en: Note that the arithmetic expression is not stored in the struct as a string
    slice, but as a peekable iterator over the string slice.
  prefs: []
  type: TYPE_NORMAL
- en: In this code, `new_expr` represents the string slice, `new_expr.chars()` represents
    an iterator over the string slice, and `new_expr.chars().peekable()` creates a
    peekable iterator over the string slice.
  prefs: []
  type: TYPE_NORMAL
- en: The difference between a regular iterator and peekable iterator is that in the
    former, we can consume the next character in the string slice using the `next()`
    method, while in the latter we can also optionally peek into the next character
    in the slice *without consuming it*. You will see how this works as we write the
    code for the `next()` method of the `Tokenizer`.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will write the code for the `next()` method on the `Tokenizer` by implementing
    the `Iterator` trait on the `Tokenizer` struct. Traits enable us to add behaviors
    to structs (and enums). The `Iterator` trait in the standard library (`std::iter::Iterator`)
    has a method that is required to be implemented with the following signature:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: The method signature specifies that this method can be called on an instance
    of the `Tokenizer` struct and it returns `Option<Token>`. This means that it either
    returns `Some(Token)` or `None`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is the code to implement the `Iterator` trait on the `Tokenizer` struct:'
  prefs: []
  type: TYPE_NORMAL
- en: src/parsemath/tokenizer.rs
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Notice how there are two iterators at play here:'
  prefs: []
  type: TYPE_NORMAL
- en: The `next()` method on `expr` (which is a field within the `Tokenizer` struct)
    returns the next character (we achieved this by assigning a type of `Peekable<Chars>`
    to the `expr` field ).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `next()` method on the `Tokenizer` struct returns a token (we achieved this
    by implementing the `Iterator` trait on the `Tokenizer` struct).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let''s understand stepwise what happens when the `next()` method is called
    on `Tokenizer`:'
  prefs: []
  type: TYPE_NORMAL
- en: The calling program instantiates the `Tokenizer` struct first by calling the
    `new()` method, and then invokes the `next()` method on it. The `next()` method
    on the `Tokenizer` struct reads the next character in the stored arithmetic expression
    by calling `next()` on the `expr` field, which returns the next character in the
    expression.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The returned character is then evaluated using a `match` statement. Pattern
    matching is used to determine what token to return, depending on what character
    is read from the string slice reference in the `expr` field.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the character returned from string slice is an arithmetic operator (*+*,
    *-*, ***, */*, *^*) or if it is a parenthesis, the appropriate `Token` from the
    `Token` `enum` is returned. There is a one-to-one correspondence between the *character*
    and `Token` here.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the character returned is a number, then there is some additional processing
    needed. The reason is, a number may have multiple digits. Also, a number may be
    decimal, in which case it could be of the form *xxx.xxx,* where the amounts of
    digits before and after the decimal are completely unpredictable. So, for numbers,
    we should use the `peekable` iterator on the arithmetic expression to consume
    the next character and *peek* into the character after that to determine whether
    to continue reading the number.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The complete code for the `Tokenizer` can be found in the `tokenizer.rs` file
    in the code folder on GitHub.
  prefs: []
  type: TYPE_NORMAL
- en: Building the parser
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The **parser** is the module in our project that constructs the AST, which is
    a tree of nodes with each node representing a token (a number or an arithmetic
    operator). The AST is a recursive tree structure of token nodes, that is, the
    root node is a token, which contains child nodes that are also tokens.
  prefs: []
  type: TYPE_NORMAL
- en: Parser data structure
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The `parser` is a higher-level entity compared to the `Tokenizer`. While the
    `Tokenizer` converts user input into fine-grained tokens (for example, various
    arithmetic operators), the parser uses the `Tokenizer` outputs to construct an
    overall AST, which is a hierarchy of nodes. The structure of the `AST` constructed
    from the parser is illustrated in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.7 – Our AST](img/Figure_2.7_B16405.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.7 – Our AST
  prefs: []
  type: TYPE_NORMAL
- en: 'In the preceding figure, each of the following are nodes:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Number(2.0)*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Number(3.0)*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Multiply(Number(2.0),Number(3.0))*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Number(6.0)*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Add(Multiply(Number(2.0),Number(3.0)),Number(6.0))*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each of these nodes is stored in a `Box` variable as part of the `Node` enum.
  prefs: []
  type: TYPE_NORMAL
- en: 'The overall design of the `Parser` struct is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.8 – Design of the Parser struct](img/Figure_2.8_B16405.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.8 – Design of the Parser struct
  prefs: []
  type: TYPE_NORMAL
- en: 'As shown in the preceding figure, `Parser` will have two data elements: an
    instance of `Tokenizer` (that we built in the previous section), and the current
    token to indicate up to which point we have evaluated the arithmetic expression.'
  prefs: []
  type: TYPE_NORMAL
- en: Parser methods
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The `Parser` struct will have two public methods:'
  prefs: []
  type: TYPE_NORMAL
- en: '`new()`: To create a new instance of the parser. This `new()` method will create
    a tokenizer instance passing in the arithmetic expression, and then stores the
    first token (returned from `Tokenizer`) in its `current_token` field.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`parse()`: To generate the `AST` (the node tree) from the tokens, which is
    the main output of the parser.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Here is the code for the `new()` method. The code is self-explanatory, it creates
    a new instance of `Tokenizer`, initializing it with the arithmetic expression,
    and then tries to retrieve the first token from the expression. If successful,
    the token is stored in the `current_token` field. If not, `ParseError` is returned:'
  prefs: []
  type: TYPE_NORMAL
- en: src/parsemath/parser.rs
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'The following is the code for the public `parse()` method. It invokes a private
    `generate_ast()` method that does the processing recursively and returns an AST
    (a tree of nodes). If successful, it returns the Node tree; if not, it propagates
    the error received:'
  prefs: []
  type: TYPE_NORMAL
- en: src/parsemath/parser.rs
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'The following image lists all the private and public methods in the `Parser`
    struct:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.9 – Parser methods overview](img/Figure_2.9_B16405.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.9 – Parser methods overview
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s now look at the code for the `get_next_token()` method. This method
    retrieves the next token from the arithmetic expression using the `Tokenizer`
    struct and updates the `current_token` field of the `Parser` struct. If unsuccessful,
    it returns `ParseError`:'
  prefs: []
  type: TYPE_NORMAL
- en: src/parsemath/parser.rs
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Note the empty tuple `()` returned in `Result<(),` `ParseError>`. This means
    if nothing goes wrong, no concrete value is returned.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s the code for the `check_paren()` method. This is a helper method used
    to check whether there are matching pairs of parentheses in the expression. Otherwise,
    an error is returned:'
  prefs: []
  type: TYPE_NORMAL
- en: src/parsemath/parser.rs
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Let's now look at the remaining three private methods that do the bulk of the
    parser processing.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `parse_number()` method takes the current token, and checks for three things:'
  prefs: []
  type: TYPE_NORMAL
- en: Whether the token is a number of the form *Num(i)*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Whether the token has a sign, in case it is a negative number. For example,
    the expression *-2.2 + 3.4* is parsed into AST as *Add(Negative(Number(2.2)),
    Number(3.4))*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Pairs of parenthesis: If an expression is found within pairs of parenthesis,
    it treats it as a multiplication operation. For example, *1*(2+3)* is parsed as
    *Multiply(Number(1.0), Add(Number(2.0), Number(3.0)))*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In case of errors in any of the preceding operations, `ParseError` is returned.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is the code for the `parse_number()` method:'
  prefs: []
  type: TYPE_NORMAL
- en: src/parsemath/parser.rs
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'The `generate_ast()` method is the main workhorse of the module and is invoked
    recursively. It does its processing in the following sequence:'
  prefs: []
  type: TYPE_NORMAL
- en: It processes numeric tokens, negative number tokens, and expressions in parentheses
    using the `parse_number()` method.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It parses each token from the arithmetic expression in a sequence within a loop
    to check if the precedence of the next two operators encountered, and constructs
    `AST` by calling the `convert_token_to_node()` method in such a way that the expression
    containing an operator with higher precedence is executed before an expression
    containing an operator with lower precedence. For example, the expression *1+2*3*
    is evaluated as *Add(Number(1.0), Multiply(Number(2.0), Number(3.0)))*, whereas
    the expression *1*2+3* is evaluated as *Add(Multiply(Number(1.0), Number(2.0)),
    Number(3.0))*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Let''s now look at the code for the `generate_ast()` method:'
  prefs: []
  type: TYPE_NORMAL
- en: src/parsemath/parser.rs
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: We have seen the various methods associated with the parser. Let's now look
    at another key aspect when dealing with arithmetic operators—*operator precedence*.
  prefs: []
  type: TYPE_NORMAL
- en: Operator precedence
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '`enum` for operator precedence is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.10 – Operator precedence enum](img/Figure_2.10_B16405.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.10 – Operator precedence enum
  prefs: []
  type: TYPE_NORMAL
- en: 'The operator precedence `enum` has the following values:'
  prefs: []
  type: TYPE_NORMAL
- en: '`DefaultZero`: The default precedence (lowest priority)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`AddSub`: The precedence applied if the arithmetic operation is addition or
    subtraction'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`MulDiv`: The precedence applied if the arithmetic operation is multiplication
    or division'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Power`: The precedence applied if the caret (`^`) operator is encountered'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Negative`: The precedence applied for the negative (`-`) prefix before a number'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The precedence order increases from top to bottom, that is, `DefaultZero` <
    `AddSub` < `MulDiv` < `Power` < `Negative`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Define the operator precedence `enum` as shown:'
  prefs: []
  type: TYPE_NORMAL
- en: src/parsemath/token.rs
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'The `get_oper_prec()` method is used to get the operator precedence given an
    operator. The following is the code that shows this method in action. Define this
    method in the `impl` block of the `Token` struct:'
  prefs: []
  type: TYPE_NORMAL
- en: src/parsemath/token.rs
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let''s look at the code for `convert_token_to_node()`. This method basically
    constructs the operator-type `AST` nodes by checking whether the token is `Add`,
    `Subtract`, `Multiply`, `Divide`, or `Caret`. In the case of an error, `ParseError`
    is returned:'
  prefs: []
  type: TYPE_NORMAL
- en: src/parsemath/parser.rs
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: We will look in detail at error handling later in the chapter in the *Dealing
    with errors* section. The complete code for `Parser` can be found in the `parser.rs`
    file in the GitHub folder for the chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Building the evaluator
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Once the `AST` (node tree) is constructed in the parser, evaluating the numeric
    value from `AST` is a straightforward operation. The evaluator function parses
    each node in the `AST` tree recursively and arrives at the final value.
  prefs: []
  type: TYPE_NORMAL
- en: For example, if the `AST` node is *Add(Number(1.0),Number(2.0))*, it evaluates
    to *3.0*.
  prefs: []
  type: TYPE_NORMAL
- en: 'If the `AST` node is *Add(Number(1.0),Multiply(Number(2.0),Number(3.0))*:'
  prefs: []
  type: TYPE_NORMAL
- en: It evaluates value of *Number(1.0)* to *1.0*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Then it evaluates *Multiply(Number(2.0), Number(3.0))* to *6.0*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It then adds *1.0* and *6.0* to get the final value of *7.0*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let''s now look at the code for the `eval()` function:'
  prefs: []
  type: TYPE_NORMAL
- en: src/parsemath/ast.rs
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Trait objects
  prefs: []
  type: TYPE_NORMAL
- en: In the `eval()` method, you will notice that the method returns `Box<dyn error::Error>`
    in case of errors. This is an example of a **trait object**. We will explain this
    now.
  prefs: []
  type: TYPE_NORMAL
- en: In the Rust standard library, `error:Error` is a trait. Here, we are telling
    the compiler that the `eval()` method should return something that implements
    the `Error` trait. We don't know at compile time what the exact type being returned
    is; we just know that whatever is returned will implement the `Error` trait. The
    underlying error type is only known at runtime and is not statically determined.
    Here, `dyn error::Error` is a trait object. The use of the `dyn` keyword indicates
    it is a trait object.
  prefs: []
  type: TYPE_NORMAL
- en: When we use trait objects, the compiler does not know at compile time which
    method to call on which types. This is only known at runtime, hence it is called
    *dynamic-dispatch* (when the compiler knows what method to call at compile time,
    it is called *static dispatch*).
  prefs: []
  type: TYPE_NORMAL
- en: Note also that we are boxing the error with `Box<dyn error::Error>`. This is
    because we don't know the size of the error type at runtime, so boxing is a way
    to get around this problem (`Box` is a reference type that has a known size at
    compile time). The Rust standard library helps in boxing our errors by having
    `Box` implement conversion from any type that implements the `Error` trait into
    the trait object `Box<Error>`.
  prefs: []
  type: TYPE_NORMAL
- en: More details can be found in the Rust documentation, at [https://doc.rust-lang.org/book/ch17-02-trait-objects.html](https://doc.rust-lang.org/book/ch17-02-trait-objects.html).
  prefs: []
  type: TYPE_NORMAL
- en: Dealing with errors
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Error handling deals with the question: *how do we communicate program errors
    to users?*'
  prefs: []
  type: TYPE_NORMAL
- en: In our project, errors can occur due to two main reasons—there could be a programming
    error, or an error could occur due to invalid inputs. Let's first discuss the
    Rust approach to error handling.
  prefs: []
  type: TYPE_NORMAL
- en: 'In Rust, errors are first-class citizens in that an error is a data type in
    itself, just like an `integer`, `string`, or `vector`. Because `error` is a data
    type, type checking can happen at compile time. The Rust standard library has
    a `std::error::Error` trait implemented by all errors in the Rust standard library.
    Rust does not use exception handling, but a unique approach where a computation
    can return a `Result` type:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: '`Result<T, E>` is an `enum` with two variants, where `Ok(T)` represents *success*
    and `Err(E)` represents the *error* returned. Pattern matching is used to handle
    the two types of return values from a function.'
  prefs: []
  type: TYPE_NORMAL
- en: To gain greater control over error handling and to provide more user-friendly
    errors for application users, it is recommended to use a custom error type that
    implements the `std::error::Error` trait. All types of errors from different modules
    in the program can then be converted to this custom error type for uniform error
    handling. This is a very effective way to deal with errors in Rust.
  prefs: []
  type: TYPE_NORMAL
- en: 'A lightweight approach to error handling could be to use `Option<T>` as the
    return value from a function, where `T` is any generic type:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: The `Option` type is an `enum` with two variants, `Some(T)` and `None`. If processing
    is successful, a `Some(T)` value is returned, otherwise, `None` is returned from
    the function.
  prefs: []
  type: TYPE_NORMAL
- en: We will use both the `Result` and `Option` types for error handling in our project.
  prefs: []
  type: TYPE_NORMAL
- en: 'The error handling approach chosen for our project is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.11 – Error handling approach](img/Figure_2.11_B16405.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.11 – Error handling approach
  prefs: []
  type: TYPE_NORMAL
- en: 'For our project, the approach for the four modules that contain the core processing
    is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`new()` and `next()`. The `new()` method is fairly simple and just creates
    a new instance of the `Tokenizer` struct and initializes it. No error will be
    returned in this method. However, the `next()` method returns a `Token`, and if
    there is any invalid character in the arithmetic expression, we need to deal with
    this situation and communicate it to the calling code. We will use a lightweight
    error handling approach here, with `Option<Token>` as the return value from the
    `next()` method. If a valid `Token` can be constructed from the arithmetic expression,
    `Some(Token)` will be returned. In the case of invalid input, `None` will be returned.
    The calling function can then interpret `None` as an error condition and take
    care of the necessary handling.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`eval()` function that computes a numeric value given a node tree. We will
    return a vanilla `std::error::Error` in case of an error during processing, but
    it will be a `Boxed` value because otherwise, the Rust compiler will not know
    the size of the error value at compile time. The return type from this method
    is `Result<f64, Box<dyn error::Error>>`. If processing is successful, a numeric
    value (`f64`) is returned, else a `Boxed` error is returned. We could have defined
    a custom error type for this module to avoid the complex `Boxed` error signature,
    but this approach has been chosen to showcase the various ways to do error handling
    in Rust.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`get_oper_prec()`, which returns the operator precedence given an arithmetic
    operator as input. Since we do not see any possibility of errors in this simple
    method, there will be no error type defined in the return value of the method.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Parser` module contains the bulk of the processing logic. Here, a custom error
    type, `ParseError,` will be defined, which has the following structure:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 2.12 – Custom error type](img/Figure_2.12_B16405.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.12 – Custom error type
  prefs: []
  type: TYPE_NORMAL
- en: Our custom error type has two variants, `UnableToParse(String)` and `InvalidOperator(String)`.
  prefs: []
  type: TYPE_NORMAL
- en: The first variant will be a generic error for any type of error during processing,
    and the second variant will be used specifically if there is an invalid arithmetic
    operator provided by the user; for example, *2=3*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s define a custom error type for the parser:'
  prefs: []
  type: TYPE_NORMAL
- en: src/parsemath/parser.rs
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'To print errors, we also need to implement the `Display` trait:'
  prefs: []
  type: TYPE_NORMAL
- en: src/parsemath/parser.rs
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Since `ParseError` will be the main error type returned from processing, and
    because the `AST` module returns a `Boxed` error, we can write code to automatically
    convert any `Boxed` error from the `AST` module into `ParseError` that gets returned
    by `Parser`. The code is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: src/parsemath/parser.rs
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'This code allows us to write code such as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Note in particular the `?` operator. It is a shortcut for the following:'
  prefs: []
  type: TYPE_NORMAL
- en: If `eval()` processing is successful, store the returned value in the `num_value`
    field.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If processing fails, convert the `Boxed` error returned by the `eval()` method
    into `ParseError` and propagate it further to the caller.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This concludes the discussion on the arithmetic expression evaluator modules.
    In the next section, we will take a look at how to call this module from a `main()`
    function.
  prefs: []
  type: TYPE_NORMAL
- en: Putting it all together
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We have seen in previous sections how to design and write code for the various
    processing modules of our project. We will now tie all of them together in a `main()`
    function that serves as the command-line application. This `main()` function will
    do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Display prompts with instructions for the user to enter an arithmetic expression.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Accept an arithmetic expression in the command-line input from the user.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Instantiate `Parser` (returns a `Parser` object instance).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Parse the expression (returns the AST representation of the expression).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Evaluate the expression (computes the mathematical value of the expression).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Display the result to the user in the command-line output.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Invoke `Parser` and evaluate the mathematical expression.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The code for the `main()` function is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: src/main.rs
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: The `main()` function displays a prompt to the user, reads a line from `stdin`
    (the command line), and invokes the `evaluate()` function. If the computation
    is successful, it displays the computed AST and the numerical value. If unsuccessful,
    it prints an error message.
  prefs: []
  type: TYPE_NORMAL
- en: 'The code for the `evaluate()` function is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: src/main.rs
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: The `evaluate()` function instantiates a new `Parser` with the provided arithmetic
    expression, parses it, and then invokes the `eval()` method on the `AST` module.
    Note the use of the `?` operator for automated propagation of any processing errors
    to the `main()` function, where they are handled with a `println!` statement.
  prefs: []
  type: TYPE_NORMAL
- en: 'Run the following command to compile and run the program:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: You can try out various combinations of positive and negative numbers, decimals,
    arithmetic operators, and optional sub-expressions in parentheses. You can also
    check how an invalid input expression will produce an error message.
  prefs: []
  type: TYPE_NORMAL
- en: You can expand this project to add support for mathematical functions such as
    square roots, trigonometric functions, logarithmic functions, and so on. You can
    also add edge cases.
  prefs: []
  type: TYPE_NORMAL
- en: With this, we conclude the first full-length project in this book. I hope this
    project has given you an idea not just of how idiomatic Rust code is written,
    but also of how to think in Rust terms while designing a program.
  prefs: []
  type: TYPE_NORMAL
- en: The complete code for the `main()` function can be found in the `main.rs` file
    in the GitHub folder for this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we built a command-line application from scratch in Rust, without
    using any third-party libraries, to compute the value of the arithmetic expressions.
    We covered many basic concepts in Rust, including data types, how to model and
    design an application domain with Rust data structures, how to split code across
    modules and integrate them, how to structure code within a module as functions,
    how to expose module functions to other modules, how to do pattern matching for
    elegant and safe code, how to add functionality to structs and enums, how to implement
    traits and annotate lifetimes, how to design and propagate custom error types,
    how to box types to make data sizes predictable for the compiler, how to construct
    a recursive node tree and navigate it, how to write code that recursively evaluates
    an expression, and how to specify lifetime parameters for structs.
  prefs: []
  type: TYPE_NORMAL
- en: Congratulations if you successfully followed along and got some working code!
    If you had any difficulties, you can refer to the final code in the GitHub repository.
  prefs: []
  type: TYPE_NORMAL
- en: This example project establishes a strong foundation from which to dig into
    the details of system programming in the upcoming chapters. If you haven't fully
    understood every detail of the code, there is no reason to fret. We will be writing
    a lot more code and reinforcing the concepts of idiomatic Rust code as we go along
    in the coming chapters.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will cover the Rust standard library, and see how it
    supports a rich set of built-in modules, types, traits, and functions to perform
    systems programming.
  prefs: []
  type: TYPE_NORMAL
