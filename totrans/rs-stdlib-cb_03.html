<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Handling Files and the Filesystem</h1>
                </header>
            
            <article>
                
<p>In this chapter, we will cover the following recipes:</p>
<ul>
<li class="mce-root">Working with text files</li>
<li>Handling bytes</li>
<li class="mce-root">Working with binary files</li>
<li class="mce-root">Compressing and decompressing data</li>
<li class="mce-root">Traversing the filesystem</li>
<li class="mce-root">Finding files with glob patterns</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Introduction</h1>
                </header>
            
            <article>
                
<p class="mce-root">In these times of big data, machine learning, and cloud services, you cannot rely on having all of your data always in memory. Rather, you need to be able to effectively inspect and traverse the filesystem and manipulate its content at your leisure.</p>
<p>Examples of things you will be able to do after reading this chapter include configuring files in subdirectories with different naming variations, saving your data in efficient binary formats, reading protocols generated by other programs, and compressing your data in order to send it over the internet at fast speeds.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Working with text files</h1>
                </header>
            
            <article>
                
<p>In this recipe, we will learn how to read, write, create, truncate, and append text files. Armed with this knowledge, you will be able to apply all other recipes to files instead of in-memory strings.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<ol>
<li>Create a Rust project to work on during this chapter with <kbd>cargo new chapter-three</kbd>.</li>
<li>Navigate into the newly created <kbd>chapter-three</kbd> folder. For the rest of this chapter, we will assume that your command line is currently in this directory.</li>
<li>Inside the <kbd>src</kbd> folder, create a new folder called <kbd>bin</kbd>.</li>
<li>Delete the generated <kbd>lib.rs</kbd> file, as we are not creating a library.</li>
<li>In the <kbd>src/bin</kbd> folder, create a file called <kbd>text_files.rs</kbd>.</li>
<li>Add the following code and run it with <kbd>cargo run --bin text_files</kbd>:</li>
</ol>
<pre style="padding-left: 60px">1    use std::fs::{File, OpenOptions};<br/>2    use std::io::{self, BufReader, BufWriter, Lines, Write};<br/>3    use std::io::prelude::*;<br/>4 <br/>5    fn main() {<br/>6      // Create a file and fill it with data<br/>7      let path = "./foo.txt";<br/>8      println!("Writing some data to '{}'", path);<br/>9      write_file(path, "Hello World!\n").expect("Failed to write to <br/>        file");<br/>10     // Read entire file as a string<br/>11     let content = read_file(path).expect("Failed to read file");<br/>12     println!("The file '{}' contains:", path);<br/>13     println!("{}", content);<br/>14 <br/>15     // Overwrite the file<br/>16     println!("Writing new data to '{}'", path);<br/>17     write_file(path, "New content\n").expect("Failed to write to <br/>        file");<br/>18     let content = read_file(path).expect("Failed to read file");<br/>19     println!("The file '{}' now contains:", path);<br/>20     println!("{}", content);<br/>21 <br/>22     // Append data to the file<br/>23     println!("Appending data to '{}'", path);<br/>24     append_file(path, "Some more content\n").expect("Failed to <br/>        append to file");<br/>25     println!("The file '{}' now contains:", path);<br/>26     // Read file line by line as an iterator<br/>27     let lines = read_file_iterator(path).expect("Failed to read <br/>        file");<br/>28     for line in lines {<br/>29       println!("{}", line.expect("Failed to read line"));<br/>30     }<br/>31 <br/>32     append_and_read(path, "Last line in the file, <br/>        goodbye").expect("Failed to read and write file");<br/>       }</pre>
<ol start="7">
<li>These are the functions called by the <kbd>main()</kbd> function:</li>
</ol>
<pre style="padding-left: 60px">37   fn read_file(path: &amp;str) -&gt; io::Result&lt;String&gt; {<br/>38     // open() opens the file in read-only mode<br/>39     let file = File::open(path)?;<br/>40     // Wrap the file in a BufReader<br/>41     // to read in an efficient way<br/>42     let mut buf_reader = BufReader::new(file);<br/>43     let mut content = String::new();<br/>44     buf_reader.read_to_string(&amp;mut content)?;<br/>45     Ok(content)<br/>46   }<br/>47 <br/>48   fn read_file_iterator(path: &amp;str) -&gt;<br/>       io::Result&lt;Lines&lt;BufReader&lt;File&gt;&gt;&gt; {<br/>49     let file = File::open(path)?;<br/>50     let buf_reader = BufReader::new(file);<br/>51     // lines() returns an iterator over lines<br/>52     Ok(buf_reader.lines())<br/>53   }<br/>54 <br/>55 <br/>56   fn write_file(path: &amp;str, content: &amp;str) -&gt; io::Result&lt;()&gt; {<br/>57     // create() opens a file with the standard options<br/>58     // to create, write and truncate a file<br/>59     let file = File::create(path)?;<br/>60     // Wrap the file in a BufReader<br/>61     // to read in an efficient way<br/>62     let mut buf_writer = BufWriter::new(file);<br/>63     buf_writer.write_all(content.as_bytes())?;<br/>64     Ok(())<br/>65   }<br/>66 <br/>67   fn append_file(path: &amp;str, content: &amp;str) -&gt; io::Result&lt;()&gt; {<br/>68     // OpenOptions lets you set all options individually<br/>69     let file = OpenOptions::new().append(true).open(path)?;<br/>70     let mut buf_writer = BufWriter::new(file);<br/>71     buf_writer.write_all(content.as_bytes())?;<br/>72     Ok(())<br/>73   }</pre>
<ol start="8">
<li>Reading and writing on the same handle:</li>
</ol>
<pre style="padding-left: 60px">76   fn append_and_read(path: &amp;str, content: &amp;str) -&gt; io::Result&lt;()<br/>     {<br/>       let file = <br/>77       OpenOptions::new().read(true).append(true).open(path)?;<br/>78     // Passing a reference of the file will not move it<br/>79     // allowing you to create both a reader and a writer<br/>80     let mut buf_reader = BufReader::new(&amp;file);<br/>81     let mut buf_writer = BufWriter::new(&amp;file);<br/>82 <br/>83     let mut file_content = String::new();<br/>84     buf_reader.read_to_string(&amp;mut file_content)?; <br/>85     println!("File before appending:\n{}", file_content);<br/>86 <br/>87     // Appending will shift your positional pointer<br/>88     // so you have to save and restore it<br/>89     let pos = buf_reader.seek(SeekFrom::Current(0))?;<br/>90     buf_writer.write_all(content.as_bytes())?;<br/>91     // Flushing forces the write to happen right now<br/>92     buf_writer.flush()?;<br/>93     buf_reader.seek(SeekFrom::Start(pos))?;<br/>94 <br/>95     buf_reader.read_to_string(&amp;mut file_content)?;<br/>96     println!("File after appending:\n{}", file_content);<br/>97 <br/>98     Ok(())<br/>99   }</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p>Our <kbd>main</kbd> function is split into three parts:</p>
<ol>
<li>Creating a file.</li>
<li>Overwriting a file, which in this context is called <em>truncating.</em></li>
<li>Appending to a file.</li>
</ol>
<p>In the first two parts, we load the entire content of the file into a single <kbd>String</kbd> and display it [11 and 18]. In the last one, we iterate over the individual lines in the file and print them [28].</p>
<p><kbd>File::open()</kbd> opens a file in read-only mode and returns you a handle to it [39]. Because this handle implements the <kbd>Read</kbd> trait, we could now just directly read it into a string with <kbd>read_to_string</kbd>. However, in our examples, we wrap it first in a <kbd>BufReader</kbd>[42]. This is because a dedicated reader can greatly improve the performance of their resource access by collecting read instructions, which is called <em>buffering</em>, and executing them in big batches. For the first reading example, <kbd>read_file</kbd>[37], this doesn't make any difference whatsoever, as we read it all in one go anyway. We still use it because it is a good practice, as it allows us to flexibly change the exact reading mechanisms of our function later on without worrying about performance. If you want to see a function where a <kbd>BufReader</kbd> actually does something, look a little further down, to <kbd>read_file_iterator</kbd>[48]. It appears to read the file line by line. This would be a very inefficient operation when dealing with a large file, which is why a <kbd>BufReader</kbd> actually reads a large chunk of the file in one go and then returns that segment line by line. The result is optimized file reading without us even noticing or caring what is going on in the background, which is pretty convenient.</p>
<p><kbd>File::create()</kbd> creates a new file if it doesn't exist, otherwise it truncates the file. In any case, it returns the same kind of <kbd>File</kbd> handle like <kbd>File::open()</kbd> did before. Another similarity is the <kbd>BufWriter</kbd> we wrap around it. Just like with the <kbd>BufReader</kbd>, we would be able to access our underlying file without it, but use it to optimize future accesses as well.</p>
<p class="mce-root">There are more options than just opening a file in read-only or truncation mode. We can use them by creating our file handle with  <kbd>OpenOptions</kbd>[69], which use the builder pattern we explored in the <em>Using the builder pattern</em> section in <a href="0620f24b-d897-497a-b000-d63a1426c3ff.xhtml" target="_blank">Chapter 1</a>, <em>Learning the Basics</em>. In our example, we are interested in the <kbd>append</kbd> mode, which lets us add content to a file instead of overwriting it on every access.</p>
<div class="packt_infobox">For a full list of all available options, see the OpenOption documentation:<br/>
<a href="https://doc.rust-lang.org/std/fs/struct.OpenOptions.html">https://doc.rust-lang.org/std/fs/struct.OpenOptions.html</a>.<a href="https://doc.rust-lang.org/std/fs/struct.OpenOptions.html"/></div>
<p>We can read and write on the same file handle. For this, when creating the <kbd>ReadBuf</kbd> and <kbd>WriteBuf</kbd>, we pass a reference to the file instead of moving it, as the buffers would otherwise consume the handle, making sharing impossible:</p>
<pre>let mut buf_reader = BufReader::new(&amp;file);<br/>let mut buf_writer = BufWriter::new(&amp;file);</pre>
<p>When doing this, be careful when appending and reading the same handle. The internal pointer that stored the current reading position might get shifted when appending. If you want to first read, then append, and then continue reading, you should save the current position before writing and then restore it afterward.</p>
<p>We can access our current position in the file by calling <kbd>seek(SeekFrom::Current(0))</kbd>[89]. <kbd>seek</kbd> moves our pointer by a certain amount of bytes and returns its new position. <kbd>SeekFrom::Current(0)</kbd> means that the distance we want to move is exactly zero bytes away from where we are right now. Because of this, as we don't move at all, <kbd>seek</kbd> will return our current position.</p>
<p>Then, we append our data using <kbd>flush</kbd>[92]. We have to call this method, as a <kbd>BufWriter</kbd> would normally wait for the actual writing until it is dropped, that is, it is no longer in scope. As we want to read before that happens, we use <kbd>flush</kbd> to force a write.</p>
<p>Finally, we get ready to read again by restoring our position from before, seeking it again:</p>
<pre>buf_reader.seek(SeekFrom::Start(pos))?;</pre>
<p>I invite you to run the code, look at the results, and then compare them with the output after commenting this line out.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">There's more...</h1>
                </header>
            
            <article>
                
<p>Instead of opening up a new file handle in every function, we could open one single handle at the beginning of the program and pass it around to every function that needs it. This is a trade-off—we get more performance if we don't repeatedly lock and unlock a file. In turn, we disallow other processes to access our file while our program is running.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">See also</h1>
                </header>
            
            <article>
                
<ul>
<li><em>Using the builder pattern</em> recipe in <a href="0620f24b-d897-497a-b000-d63a1426c3ff.xhtml" target="_blank">Chapter 1</a>, <em>Learning the Basics</em></li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Handling bytes</h1>
                </header>
            
            <article>
                
<p>When designing your own protocol or using existing ones, you have to be able to comfortably move around and manipulate binary buffers. Luckily, the extended standard library ecosystem provides the <kbd>byteorder</kbd> crate to fulfill all your binary needs with various bits and pieces of reading and writing functionality.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<p>In this chapter, we are going to talk about <em>endianness</em>. It is a way of describing how the values in a buffer are ordered. There are two ways to order them:</p>
<ul>
<li>Put the smallest one first (<em>Little Endian</em>)</li>
<li>Put the biggest one first (<em>Big Endian</em>)</li>
</ul>
<p>Let's try an example. Suppose we wanted to save the hexadecimal value <kbd>0x90AB12CD</kbd>. We first have to split it into bits of <kbd>0x90</kbd>, <kbd>0xAB</kbd>, <kbd>0x12</kbd>, and <kbd>0xCD</kbd>. We now can either store them with the biggest value first (Big Endian), <kbd>0x90 - 0xAB - 0x12 - 0xCD</kbd>, or we could write the smallest number first (Little Endian), <kbd>0xCD - 0x12 - 0xAB - 0x90</kbd>.</p>
<p>As you can see, it's the exact same set of values, but flipped. If this short explanation left you confused, I advise you to look at this excellent explanation by the University of Maryland's Department of Computer Science: <a href="https://web.archive.org/web/20170808042522/http://www.cs.umd.edu/class/sum2003/cmsc311/Notes/Data/endian.html">https://web.archive.org/web/20170808042522/http://www.cs.umd.edu/class/sum2003/cmsc311/Notes/Data/endian.html.</a></p>
<p>There is no <em>better</em> endianness. Both are used in different domains: microprocessors, such as Intel, use Little Endian, and internet protocols, such as TCP, IPv4, IPv6, and UDP, use Big Endian. This is not a rule but rather a convention maintained to be backward compatible. As such, there are exceptions.</p>
<p>When designing your own protocol, orient yourself on the endianness of similar protocols, choose one and simply stick to it.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<p>Follow these steps:</p>
<ol>
<li>
<p>Open the <kbd>Cargo.toml</kbd> file that was generated earlier for you.</p>
</li>
<li>Under <kbd>[dependencies]</kbd>, add the following line:</li>
</ol>
<pre style="padding-left: 60px">byteorder = "1.1.0"</pre>
<ol start="3">
<li>If you want, you can go to <kbd>byteorder</kbd>'s crates.io page (<a href="https://crates.io/crates/byteorder">https://crates.io/crates/byteorder</a>) to check for the newest version and use that one instead.</li>
<li>
<p>In the <kbd>bin</kbd> folder, create a file called <kbd>bytes.rs</kbd>.</p>
</li>
<li>
<p>Add the following code and run it with <kbd>cargo run --bin bytes</kbd>:</p>
</li>
</ol>
<pre style="padding-left: 60px">1    extern crate byteorder;<br/>2    use std::io::{Cursor, Seek, SeekFrom};<br/>3    use byteorder::{BigEndian, LittleEndian, ReadBytesExt,<br/>     WriteBytesExt};<br/>4 <br/>5    fn main() {<br/>6      let binary_nums = vec![2, 3, 12, 8, 5, 0];<br/>7      // Wrap a binary collection in a cursor<br/>8      // to provide seek functionality<br/>9      let mut buff = Cursor::new(binary_nums);<br/>10     let first_byte = buff.read_u8().expect("Failed to read<br/>         byte");<br/>11     println!("first byte in binary: {:b}", first_byte);<br/>12 <br/>13     // Reading advances the internal position,<br/>14     // so now we read the second<br/>15     let second_byte_as_int = buff.read_i8().expect("Failed to<br/>         read byte as int");<br/>16     println!("second byte as int: {}", second_byte_as_int);<br/>17 <br/>18     // Overwrite the current position<br/>19     println!("Before: {:?}", buff);<br/>20     buff.write_u8(123).expect("Failed to overwrite a byte");<br/>21     println!("After: {:?}", buff);<br/>22 <br/>23 <br/>24     // Set and get the current position<br/>25     println!("Old position: {}", buff.position());<br/>26     buff.set_position(0);<br/>27     println!("New position: {}", buff.position());<br/>28 <br/>29     // This also works using the Seek API<br/>30     buff.seek(SeekFrom::End(0)).expect("Failed to seek end");<br/>31     println!("Last position: {}", buff.position());<br/>32 <br/>33     // Read and write in specific endianness<br/>34     buff.set_position(0);<br/>35     let as_u32 = buff.read_u32::&lt;LittleEndian&gt;()<br/>36       .expect("Failed to read bytes");<br/>37     println!(<br/>38       "First four bytes as u32 in little endian order:\t{}",<br/>39        as_u32<br/>40     );<br/>41 <br/>42     buff.set_position(0);<br/>43     let as_u32 = buff.read_u32::&lt;BigEndian&gt;().expect("Failed to<br/>         read bytes");<br/>44     println!("First four bytes as u32 in big endian order:\t{}", <br/>         as_u32);<br/>45 <br/>46     println!("Before appending: {:?}", buff);<br/>47     buff.seek(SeekFrom::End(0)).expect("Failed to seek end");<br/>48     buff.write_f32::&lt;LittleEndian&gt;(-33.4)<br/>49       .expect("Failed to write to end");<br/>50     println!("After appending: {:?}", buff);<br/>51 <br/>52     // Read a sequence of bytes into another buffer<br/>53     let mut read_buffer = [0; 5];<br/>54     buff.set_position(0);<br/>55     buff.read_u16_into::&lt;LittleEndian&gt;(&amp;mut read_buffer)<br/>56       .expect("Failed to read all bytes");<br/>57     println!(<br/>58       "All bytes as u16s in little endian order: {:?}",<br/>59        read_buffer<br/>60     );<br/>61   }</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p>First things first, we need a binary source. In our example, we simply use a vector. Then, we wrap it into a <kbd>Cursor</kbd>, as it provides us with a <kbd>Seek</kbd> implementation and some methods for our convenience.</p>
<p>The <kbd>Cursor</kbd> has an internal position count that keeps track of which byte we are accessing at the moment. As expected, it starts at zero. With <kbd>read_u8</kbd> and <kbd>read_i8</kbd>, we can read the current byte as an unsigned or signed number. This will advance the position by one. Both do the same thing, but return a different type.</p>
<p>Did you notice that we printed the returned byte by using <kbd>{:b}</kbd> as the formatting parameter [11]?</p>
<pre style="padding-left: 30px">println!("first byte in binary: {:b}", first_byte);</pre>
<p>By doing so, we tell the underlying <kbd>format!</kbd> macro to interpret our byte as binary, which is why it will print <kbd>10</kbd> instead of <kbd>2</kbd>. If you want to, try replacing <kbd>{}</kbd> in our other printing calls with  <kbd>{:b}</kbd> and compare the results.</p>
<p>The current position can be read with <kbd>position()</kbd> [25] and set with <kbd>set_position()</kbd>. You can also manipulate your position with the more verbose <kbd>Seek</kbd> API we introduced in the last recipe [30]. When using <kbd>SeekFrom::End</kbd>, keep in mind that this will <em>not</em> count backward from the end. For example, <kbd>SeekFrom::End(1)</kbd> will point to one byte <em>after</em> the end of the buffer and not before. The behavior is defined in this way because, maybe somewhat surprisingly, it is legal to seek past a buffer. This can be useful when writing, as it will simply pad the space between the end of the buffer and the cursor position with zeros.</p>
<p class="mce-root"/>
<p>When dealing with more then one byte, you will need to specify the endianness of the bytes via type annotation. Reading or writing will then advance the position by the number of bytes read or written, which is why, in our example code, we need to frequently reset the position with <kbd>set_position(0)</kbd>. Note that when you write past the end, you will always simply extend the buffer [48].</p>
<p>If you know that you want to read a very specific amount of bytes, like when parsing a well-defined protocol,  you can do so by providing a fixed-size array and filling it by post-fixing your <kbd>read</kbd> with <kbd>_into</kbd>, like this:</p>
<pre style="padding-left: 30px">// Read exactly five bytes<br/>let mut read_buffer = [0; 5];<br/>buff.read_u16_into::&lt;LittleEndian&gt;(&amp;mut read_buffer).expect("Failed to fill buffer");</pre>
<p>When doing so, the read will return an error if the buffer was not filled completely, in which case its contents are undefined.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">There's more...</h1>
                </header>
            
            <article>
                
<p>There are various aliases in the byte order crate to ease your endianness annotation. The <kbd>BE</kbd> alias, for Big Endian, and the <kbd>LE</kbd> alias, for Little Endian, are useful if you don't want to type as much. On the other hand, if you keep forgetting which endianness is used where, you can use <kbd>NativeEndian</kbd>, which sets itself to the default endianness of your operating system, and <kbd>NetworkEndian</kbd>, for Big Endian.</p>
<p>To use them, you will have to drag them into scope like this:</p>
<pre style="padding-left: 30px">use byteorder::{BE, LE, NativeEndian, NetworkEndian};</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Working with binary files</h1>
                </header>
            
            <article>
                
<p>We are now going to combine what we learned in the last two chapters in order to parse and write binary files. This will prove essential when you plan on implementing custom, manual processing of file types such as PDFs, torrents, and ZIPs. It will also come in handy when designing custom file types for your own use cases.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<ol>
<li>
<p>If you haven't done it already in the last chapter, open the <kbd>Cargo.toml</kbd> file that was generated earlier for you.</p>
</li>
<li>Under <kbd>[dependencies]</kbd>, add the following line:</li>
</ol>
<pre style="padding-left: 60px">byteorder = "1.1.0"</pre>
<ol start="3">
<li>If you want, you can go to byteorder's crates.io page (<a href="https://crates.io/crates/byteorder">https://crates.io/crates/byteorder</a>) to check for the newest version and use that one instead.</li>
<li>
<p>In the <kbd>bin</kbd> folder, create a file called <kbd>binary_files.rs</kbd>.</p>
</li>
<li>
<p>Add the following code and run it with <kbd>cargo run --bin binary_files</kbd>:</p>
</li>
</ol>
<pre style="padding-left: 60px">1    extern crate byteorder;<br/>2    use byteorder::{ByteOrder, ReadBytesExt, WriteBytesExt, BE,<br/>     LE};<br/>3    use std::fs::File;<br/>4    use std::io::{self, BufReader, BufWriter, Read};<br/>5    use std::io::prelude::*;<br/>6 <br/>7 <br/>8    fn main() {<br/>9      let path = "./bar.bin";<br/>10     write_dummy_protocol(path).expect("Failed write file");<br/>11     let payload = read_protocol(path).expect("Failed to read<br/>         file");<br/>12     print!("The protocol contained the following payload: ");<br/>13     for num in payload {<br/>14       print!("0x{:X} ", num);<br/>15     }<br/>16     println!();<br/>17   }</pre>
<ol start="6">
<li>Create a binary file:</li>
</ol>
<pre style="padding-left: 60px">19    // Write a simple custom protocol<br/>20    fn write_dummy_protocol(path: &amp;str) -&gt; io::Result&lt;()&gt; {<br/>21      let file = File::create(path)?;<br/>22      let mut buf_writer = BufWriter::new(file);<br/>23 <br/>24      // Let's say our binary file starts with a magic string<br/>25      // to show readers that this is our protocoll<br/>26      let magic = b"MyProtocol";<br/>27      buf_writer.write_all(magic)?;<br/>28 <br/>29      // Now comes another magic value to indicate<br/>30      // our endianness<br/>31      let endianness = b"LE";<br/>32      buf_writer.write_all(endianness)?;<br/>33 <br/>34      // Let's fill it with two numbers in u32<br/>35      buf_writer.write_u32::&lt;LE&gt;(0xDEAD)?;<br/>36      buf_writer.write_u32::&lt;LE&gt;(0xBEEF)?;<br/>37 <br/>38      Ok(())<br/>39    }</pre>
<ol start="7">
<li>Read and parse the file:</li>
</ol>
<pre style="padding-left: 60px">42   fn read_protocol(path: &amp;str) -&gt; io::Result&lt;Vec&lt;u32&gt;&gt; {<br/>43     let file = File::open(path)?;<br/>44     let mut buf_reader = BufReader::new(file);<br/>45 <br/>46     // Our protocol has to begin with a certain string<br/>47     // Namely "MyProtocol", which is 10 bytes long<br/>48     let mut start = [0u8; 10];<br/>49     buf_reader.read_exact(&amp;mut start)?;<br/>50     if &amp;start != b"MyProtocol" {<br/>51       return Err(io::Error::new(<br/>52         io::ErrorKind::Other,<br/>53         "Protocol didn't start with the expected magic string",<br/>54       ));<br/>55     }<br/>56 <br/>57     // Now comes the endianness indicator<br/>58     let mut endian = [0u8; 2];<br/>59     buf_reader.read_exact(&amp;mut endian)?;<br/>60     match &amp;endian {<br/>61       b"LE" =&gt; read_protocoll_payload::&lt;LE, _&gt;(&amp;mut buf_reader),<br/>62       b"BE" =&gt; read_protocoll_payload::&lt;BE, _&gt;(&amp;mut buf_reader),<br/>63       _ =&gt; Err(io::Error::new(<br/>64         io::ErrorKind::Other,<br/>65         "Failed to parse endianness",<br/>66       )),<br/>67     }<br/>68   }<br/>69 <br/>70   // Read as much of the payload as possible<br/>71   fn read_protocoll_payload&lt;E, R&gt;(reader: &amp;mut R) -&gt;<br/>       io::Result&lt;Vec&lt;u32&gt;&gt;<br/>72   where<br/>73   E: ByteOrder,<br/>74   R: ReadBytesExt,<br/>75   {<br/>76     let mut payload = Vec::new();<br/>77     const SIZE_OF_U32: usize = 4;<br/>78     loop {<br/>79     let mut raw_payload = [0; SIZE_OF_U32];<br/>80     // Read the next 4 bytes<br/>81     match reader.read(&amp;mut raw_payload)? {<br/>82     // Zero means we reached the end<br/>83     0 =&gt; return Ok(payload),<br/>84     // SIZE_OF_U32 means we read a complete number<br/>85     SIZE_OF_U32 =&gt; {<br/>86       let as_u32 = raw_payload.as_ref().read_u32::&lt;E&gt;()?;<br/>87       payload.push(as_u32)<br/>88     }<br/>89     // Anything else means the last element was not<br/>90     // a valid u32<br/>91     _ =&gt; {<br/>92       return Err(io::Error::new(<br/>93       io::ErrorKind::UnexpectedEof,<br/>94         "Payload ended unexpectedly",<br/>95       ))<br/>96     }<br/>97   }<br/>98  }<br/>99 }</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p class="mce-root">To demonstrate how to read and write a binary file, we will create a little custom binary protocol. It will start with what is called a <em>magic number</em>, that is, a certain hardcoded value. Our magic number will be the binary representation of the <kbd>MyProtocol</kbd> string. We can put a <kbd>b</kbd> before the string to tell Rust that we want the text to be represented as a binary slice (<kbd>&amp;[u8]</kbd>) instead of a string slice(<kbd>&amp;str</kbd>) [26].</p>
<div class="packt_infobox">Many protocols and files start with magic numbers to indicate what they are. For example, the internal headers of <kbd>.zip</kbd> files start with the magic hex numbers <kbd>0x50</kbd> and <kbd>0x4B</kbd>. These represent the initials <em>PH</em> in ASCII, which is short for the name of its creator Phil Katz. Another example would be PDF; it starts with <kbd>0x25</kbd>, <kbd>0x50</kbd>, <kbd>0x44</kbd>, and <kbd>0x46</kbd>, which stands for <kbd>PDF%</kbd>, followed by a version number.</div>
<p>Afterward, we follow it by the binary representation of either <kbd>LE</kbd> or <kbd>BE</kbd> to tell the reader the endianness of the rest of the data [31]. Finally, we have the payload, which is just an arbitrary amount of <kbd>u32</kbd> numbers, encoded in the aforementioned endianness [35 and 36]. By putting <kbd>0x</kbd> in front of our number, we tell Rust to treat it as a hexadecimal number and convert it into decimal for us. As such, Rust treats <kbd>0xDEAD</kbd> as the same value as <kbd>57005</kbd>.</p>
<p><span>Let's put it all together and</span> write a binary file containing <kbd>MyProtocolLE5700548879</kbd>. Other files we could have created in accordance with our protocol would be <kbd>MyProtocolBE92341739241842518425</kbd> or <kbd>MyProtocolLE0000</kbd>, and so on.</p>
<p>If you read the previous recipes, <kbd>write_dummy_protocol</kbd> should be easy to understand. We use a combination of good old <kbd>write_all</kbd> from the standard library to write our binary texts and <kbd>write_u32</kbd> from <kbd>byteorder</kbd> to write the values that require an endianness.</p>
<p>The reading of the protocol is split into the  <kbd>read_protocol</kbd> and <kbd>read_protocol_payload</kbd> functions. The first verifies the validity of the protocol by reading the magic numbers and then calls the latter, which reads the remaining numbers as the payload.</p>
<p>We validate the magic numbers as follows:</p>
<ol>
<li>As we know the exact size of the magic numbers used, prepare buffers of those exact sizes.</li>
<li>Fill them with just as many bytes.</li>
<li>Compare the bytes with the expected magic number.</li>
<li>If they don't match, return an error.</li>
</ol>
<p>After parsing both magic numbers, we can parse the actual <em>data</em> contained in the payload. Remember, we defined it as an arbitrary amount of <kbd>32</kbd> bit (<kbd>= 4</kbd> bytes) long, unsigned numbers. To parse them, we are going to repeatedly read up to four bytes into a buffer called <kbd>raw_payload</kbd>. We are then going to examine the amount of bytes that were actually read. This number can have three forms in our case, as demonstrated nicely by our <kbd>match</kbd>.</p>
<p>The first value we are interested in is zero, which means that there are no more bytes to read, that is, we have reached the end. In this case, we can return our payload:</p>
<pre style="padding-left: 30px">// Zero means we reached the end<br/>0 =&gt; return Ok(payload),</pre>
<p>The second value is <kbd>SIZE_OF_U32</kbd>, which we have previously defined as four. Receiving this value means that our reader has successfully read four bytes into a four-byte-long buffer. This means that we have successfully read a value! Let's parse it into a <kbd>u32</kbd> and push it into our <kbd>payload</kbd> vector:</p>
<pre style="padding-left: 30px">// SIZE_OF_U32 means we read a complete number<br/>SIZE_OF_U32 =&gt; {<br/>    let as_u32 = raw_payload.as_ref().read_u32::&lt;E&gt;()?;<br/>    payload.push(as_u32)<br/>}</pre>
<p>We have to call <kbd>as_ref()</kbd> on our buffer because a fixed-size array doesn't implement <kbd>Read</kbd>. Since a slice does implement said trait and a reference to an array is implicitly convertible into a slice, we work on a reference to <kbd>raw_payload</kbd> instead.</p>
<p>The third and last value we can expect is everything other than zero or four. In this case, the reader was not able to read four bytes, which means that our buffer ended in something other than a <kbd>u32</kbd> and is malformed. We can react to this by returning an error:</p>
<pre style="padding-left: 30px">// Anything else means the last element was not<br/>// a valid u32<br/>_ =&gt; {<br/>    return Err(io::Error::new(<br/>        io::ErrorKind::UnexpectedEof,<br/>        "Payload ended unexpectedly",<br/>        ))<br/>    }<br/>}</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">There's more...</h1>
                </header>
            
            <article>
                
<p>When reading a malformed protocol, we reuse <kbd>io::ErrorKind</kbd> to show what exactly went wrong. In the recipes of <a href="d2c7b7cb-3060-40b8-adb4-408eee7940a1.xhtml" target="_blank">Chapter 6</a>, <em>Handling Errors</em>, you will learn how to provide your own error to better separate your areas of failure. If you want, you could read them now and then return here to improve our code.</p>
<div class="packt_tip">The errors that need to be pushed into an own variant are:<br/>
<ul>
<li><kbd>InvalidStart</kbd></li>
<li><kbd>InvalidEndianness</kbd></li>
<li><kbd>UnexpectedEndOfPayload</kbd></li>
</ul>
</div>
<p>Another improvement to the code would be to put all of our strings, namely <kbd>MyProtocol</kbd>, <kbd>LE</kbd>, and <kbd>BE</kbd>, into their own constants, as in the following line:</p>
<pre style="padding-left: 30px">const PROTOCOL_START: &amp;[u8] = b"MyProtocol";</pre>
<div class="packt_tip">
<p>The provided code in this recipe and some others doesn't use many constants, as they proved to be somewhat harder to understand in printed form. In real code bases, however, be sure to always put strings that you find yourself copy-pasting into own constants!</p>
</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">See also</h1>
                </header>
            
            <article>
                
<ul>
<li><em>Providing user-defined error types</em> recipes in  <a href="https://cdp.packtpub.com/rust_standard_library_cookbook/wp-admin/post.php?post=81&amp;action=edit#post_151" target="_blank">Chapter 6</a><span>, <em>Handling Errors</em></span></li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Compressing and decompressing data</h1>
                </header>
            
            <article>
                
<p>In today's age of bloated websites and daily new web frameworks, many sites feel way more sluggish than they used (and ought) to. One way to mitigate this is by compressing your resources before sending them and then decompressing them when received. This has become the (often ignored) standard on the web. For this purpose, this recipe will teach you how to compress and decompress any kind of data with different algorithms.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<p>Follow these steps:</p>
<ol>
<li>
<p>Open the <kbd>Cargo.toml</kbd> file that was generated earlier for you.</p>
</li>
<li>
<p>Under <kbd>[dependencies]</kbd>, add the following line:</p>
<pre> flate2 = "0.2.20"</pre>
<p>If you want, you can go to <kbd>flate2</kbd>'s crates.io page (<a href="https://crates.io/crates/flate2">https://crates.io/crates/flate2</a>) to check for the newest version and use that one instead.<a href="https://crates.io/crates/byteorder"/></p>
</li>
<li>
<p>In the <kbd>bin</kbd> folder, create a file called <kbd>compression.rs</kbd>.</p>
</li>
<li>
<p>Add the following code and run it with <kbd>cargo run --bin compression</kbd>:</p>
</li>
</ol>
<pre style="padding-left: 60px">1    extern crate flate2;<br/>2 <br/>3    use std::io::{self, SeekFrom};<br/>4    use std::io::prelude::*;<br/>5 <br/>6    use flate2::{Compression, FlateReadExt};<br/>7    use flate2::write::ZlibEncoder;<br/>8    use flate2::read::ZlibDecoder;<br/>9 <br/>10   use std::fs::{File, OpenOptions};<br/>11   use std::io::{BufReader, BufWriter, Read};<br/>12 <br/>13   fn main() {<br/>14     let bytes = b"I have a dream that one day this nation will<br/>         rise up, \<br/>15     and live out the true meaning of its creed";<br/>16     println!("Original: {:?}", bytes.as_ref());<br/>17     // Conpress some bytes<br/>18     let encoded = encode_bytes(bytes.as_ref()).expect("Failed to<br/>         encode bytes");<br/>19     println!("Encoded: {:?}", encoded);<br/>20     // Decompress them again<br/>21     let decoded = decode_bytes(&amp;encoded).expect("Failed to decode<br/>         bytes");<br/>22     println!("Decoded: {:?}", decoded);<br/>23 <br/>24     // Open file to compress<br/>25     let original = File::open("ferris.png").expect("Failed to<br/>         open file");<br/>26     let mut original_reader = BufReader::new(original);<br/>27 <br/>28     // Compress it<br/>29     let data = encode_file(&amp;mut original_reader).expect("Failed<br/>         to encode file");<br/>30 <br/>31     // Write compressed file to disk<br/>32     let encoded = OpenOptions::new()<br/>33       .read(true)<br/>34       .write(true)<br/>35       .create(true)<br/>36       .open("ferris_encoded.zlib")<br/>37       .expect("Failed to create encoded file");<br/>38     let mut encoded_reader = BufReader::new(&amp;encoded);<br/>39     let mut encoded_writer = BufWriter::new(&amp;encoded);<br/>40     encoded_writer<br/>41       .write_all(&amp;data)<br/>42       .expect("Failed to write encoded file");<br/>43 <br/>44 <br/>45     // Jump back to the beginning of the compressed file<br/>46     encoded_reader<br/>47       .seek(SeekFrom::Start(0))<br/>48       .expect("Failed to reset file");<br/>49 <br/>50     // Decompress it<br/>51     let data = decode_file(&amp;mut encoded_reader).expect("Failed to<br/>         decode file");<br/>52 <br/>53     // Write the decompressed file to disk<br/>54     let mut decoded =<br/>         File::create("ferris_decoded.png").expect("Failed to create<br/>           decoded file");<br/>55     decoded<br/>56       .write_all(&amp;data)<br/>57       .expect("Failed to write decoded file");<br/>58   }</pre>
<ol start="5">
<li>These are the functions doing the actual encoding and decoding:</li>
</ol>
<pre style="padding-left: 60px">61   fn encode_bytes(bytes: &amp;[u8]) -&gt; io::Result&lt;Vec&lt;u8&gt;&gt; {<br/>62     // You can choose your compression algorithm and it's<br/>         efficiency<br/>63     let mut encoder = ZlibEncoder::new(Vec::new(),<br/>         Compression::Default);<br/>64     encoder.write_all(bytes)?;<br/>65     encoder.finish()<br/>66   }<br/>67 <br/>68   fn decode_bytes(bytes: &amp;[u8]) -&gt; io::Result&lt;Vec&lt;u8&gt;&gt; {<br/>69     let mut encoder = ZlibDecoder::new(bytes);<br/>70     let mut buffer = Vec::new();<br/>71     encoder.read_to_end(&amp;mut buffer)?;<br/>72     Ok(buffer)<br/>73   }<br/>74 <br/>75 <br/>76   fn encode_file(file: &amp;mut Read) -&gt; io::Result&lt;Vec&lt;u8&gt;&gt; {<br/>77     // Files have a built-in encoder<br/>78     let mut encoded = file.zlib_encode(Compression::Best);<br/>79     let mut buffer = Vec::new();<br/>80     encoded.read_to_end(&amp;mut buffer)?;<br/>81     Ok(buffer)<br/>82   }<br/>83 <br/>84   fn decode_file(file: &amp;mut Read) -&gt; io::Result&lt;Vec&lt;u8&gt;&gt; {<br/>85     let mut buffer = Vec::new();<br/>86     // Files have a built-in decoder<br/>87     file.zlib_decode().read_to_end(&amp;mut buffer)?;<br/>88     Ok(buffer)<br/>89   }</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p>A lot of the <kbd>main</kbd> function work is just repetition for you from the last few chapters. The real deal happens below it. In <kbd>encode_bytes</kbd>, you can see how to use <em>encoders</em>. You can write to it as much as you want and call <kbd>finish</kbd> when you're done.</p>
<p><kbd>flate2</kbd> gives you several compression options. You can choose your compression strength through the passed <kbd>Compression</kbd> instance:</p>
<pre>let mut encoder = ZlibEncoder::new(Vec::new(), Compression::Default);</pre>
<p><kbd>Default</kbd> is a compromise between speed and size. Your other options are <kbd>Best</kbd>, <kbd>Fast</kbd>, and <kbd>None</kbd>. Additionally, you can specify the encoding algorithm used. <kbd>flate2</kbd> supports zlib, which we use in this recipe, gzip, and plain deflate. If you want to use an algorithm other than zlib, simply replace every mention of it with another supported algorithm. For instance, if you wanted to rewrite the preceding code to use gzip instead, it would look like this:</p>
<pre>use flate2::write::GzEncoder;<br/>let mut encoder = GzEncoder::new(Vec::new(), Compression::Default);</pre>
<p>For a full list of how the specific encoders are called, visit <kbd>flate2</kbd>'s documentation at <a href="https://docs.rs/flate2/">https://docs.rs/flate2/.</a></p>
<p>Because <span>people would often prefer to compress or decompress whole files instead of byte buffers</span>, there are some convenient methods for that. In fact, they are implemented on every type that implements <kbd>Read</kbd>, which means that you can also use them on a <kbd>BufReader</kbd> and many other types. <kbd>encode_file</kbd> and <kbd>decode_file</kbd> use them with <kbd>zlib</kbd> in the form of the following lines:</p>
<pre>let mut encoded = file.zlib_encode(Compression::Best);<br/>file.zlib_decode().read_to_end(&amp;mut buffer)?;</pre>
<p>The same applies to the <kbd>gzip</kbd> and <kbd>deflate</kbd> algorithms.</p>
<p>In our example, we are compressing and decompressing <kbd>ferris.png</kbd>, which is an image of Rust's mascot:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/11ce3c14-a708-46ef-b5d4-7250ea181f6b.jpg" style="width:19.83em;height:13.25em;"/></div>
<p>You can find it in the GitHub repository at <a href="https://github.com/SirRade/rust-standard-library-cookbook/tree/master/chapter_three">https://github.com/SirRade/rust-standard-library-cookbook</a> or you can use any other file you want. If you feel like verifying the compression, you can take a look at the original, compressed, and decompressed files to check how much smaller the compressed one is, and that the original and decompressed ones are identical.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">There's more...</h1>
                </header>
            
            <article>
                
<p>The current <kbd>encode_something</kbd> and <kbd>decode_something</kbd> functions are designed to be as simple to use as possible. However, they waste some performance by allocating <kbd>Vec&lt;u8&gt;</kbd> even though we could pipe the data directly into a writer. When writing a library, it would be nice to give the user both possibilities by adding methods in this way:</p>
<pre style="padding-left: 30px">use std::io::Write;<br/>fn encode_file_into(file: &amp;mut Read, target: &amp;mut Write) -&gt; io::Result&lt;()&gt; {<br/>    // Files have a built-in encoder<br/>    let mut encoded = file.zlib_encode(Compression::Best);<br/>    io::copy(&amp;mut encoded, target)?;<br/>    Ok(())<br/>}</pre>
<p>The user could call them like this:</p>
<pre style="padding-left: 30px">// Compress it<br/>encode_file_into(&amp;mut original_reader, &amp;mut encoded_writer)<br/>    .expect("Failed to encode file");</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Traversing the filesystem</h1>
                </header>
            
            <article>
                
<p>Up until now, we always provided our code with the static location of a certain file. Alas, the real world is seldom so predictable, and some digging is going to be necessary when dealing with data scattered throughout different folders.</p>
<p><kbd>walkdir</kbd> helps us with this by abstracting away the intricacies and inconsistencies of operating systems' representation of the filesystem by unifying them under one common API, which we are going to learn about in this recipe.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<p>This recipe makes heavy use of iterators to manipulate streams of data. If you are not yet familiar with them or need a quick refresher,  you should read the <em>Access collections as Iterators</em> section in <a href="977b8621-cb73-43de-9a2b-4bc9f5583542.xhtml" target="_blank">Chapter 2</a>, <em>Working with Collections</em>, before continuing.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<ol>
<li>
<p>Open the <kbd>Cargo.toml</kbd> file that was generated earlier for you.</p>
</li>
<li>Under <kbd>[dependencies]</kbd>, add the following line:</li>
</ol>
<pre style="padding-left: 60px">walkdir = "2.0.1"</pre>
<ol start="3">
<li>If you want, you can go to <kbd>walkdir</kbd>'s crates.io page (<a href="https://crates.io/crates/walkdir">https://crates.io/crates/walkdir</a>) to check for the newest version and use that one instead.</li>
<li>
<p>In the <kbd>bin</kbd> folder, create a file called <kbd>traverse_files.rs</kbd>.</p>
</li>
<li>
<p>Add the following code and run it with <kbd>cargo run --bin traverse_files</kbd>:</p>
</li>
</ol>
<pre style="padding-left: 60px">1    extern crate walkdir;<br/>2    use walkdir::{DirEntry, WalkDir};<br/>3 <br/>4    fn main() {<br/>5      println!("All file paths in this directory:");<br/>6      for entry in WalkDir::new(".") {<br/>7        if let Ok(entry) = entry {<br/>8          println!("{}", entry.path().display());<br/>9        }<br/>10     }<br/>11 <br/>12     println!("All non-hidden file names in this directory:");<br/>13     WalkDir::new("../chapter_three")<br/>14       .into_iter()<br/>15       .filter_entry(|entry| !is_hidden(entry)) // Look only at <br/>          non-hidden enthries<br/>16       .filter_map(Result::ok) // Keep all entries we have access to<br/>17       .for_each(|entry| {<br/>18         // Convert the name returned by theOS into a Rust string<br/>19         // If there are any non-UTF8 symbols in it, replace them <br/>              with placeholders<br/>20         let name = entry.file_name().to_string_lossy();<br/>21           println!("{}", name)<br/>22       });<br/>23 <br/>24       println!("Paths of all subdirectories in this directory:");<br/>25       WalkDir::new(".")<br/>26         .into_iter()<br/>27         .filter_entry(is_dir) // Look only at directories<br/>28         .filter_map(Result::ok) // Keep all entries we have <br/>            access to<br/>29         .for_each(|entry| {<br/>30           let path = entry.path().display();<br/>31           println!("{}", path)<br/>32         });<br/>33 <br/>34       let are_any_readonly = WalkDir::new("..")<br/>35         .into_iter()<br/>36         .filter_map(Result::ok) // Keep all entries we have <br/>            access to<br/>37         .filter(|e| has_file_name(e, "vector.rs")) // Get the <br/>            ones with a certain name<br/>38         .filter_map(|e| e.metadata().ok()) // Get metadata if the <br/>            OS allows it<br/>39         .any(|e| e.permissions().readonly()); // Check if at <br/>            least one entry is readonly<br/>40       println!(<br/>41         "Are any the files called 'vector.rs' readonly? {}",<br/>42          are_any_readonly<br/>43       );<br/>44 <br/>45      let total_size = WalkDir::new(".")<br/>46        .into_iter()<br/>47        .filter_map(Result::ok) // Keep all entries we have access <br/>           to<br/>48        .filter_map(|entry| entry.metadata().ok()) // Get metadata<br/>           if supported<br/>49        .filter(|metadata| metadata.is_file()) // Keep all files<br/>50        .fold(0, |acc, m| acc + m.len()); // Accumulate sizes<br/>51 <br/>52      println!("Size of current directory: {} bytes", total_size);<br/>53    }</pre>
<ol start="6">
<li>Now, come to the predicates used in this recipe:</li>
</ol>
<pre style="padding-left: 60px">55   fn is_hidden(entry: &amp;DirEntry) -&gt; bool {<br/>56     entry<br/>57       .file_name()<br/>58       .to_str()<br/>59       .map(|s| s.starts_with('.'))<br/>60       .unwrap_or(false) // Return false if the filename is <br/>          invalid UTF8<br/>61   }<br/>62 <br/>63   fn is_dir(entry: &amp;DirEntry) -&gt; bool {<br/>64     entry.file_type().is_dir()<br/>65   }<br/>66 <br/>67   fn has_file_name(entry: &amp;DirEntry, name: &amp;str) -&gt; bool {<br/>68     // Check if file name contains valid unicode<br/>69     match entry.file_name().to_str() {<br/>70     Some(entry_name) =&gt; entry_name == name,<br/>71     None =&gt; false,<br/>72   }<br/>73 }</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p><kbd>walkdir</kbd> consists of three important types:</p>
<ul>
<li><kbd>WalkDir</kbd>: A builder (see the <em>Using the builder pattern</em> section in <a href="0620f24b-d897-497a-b000-d63a1426c3ff.xhtml" target="_blank">Chapter 1</a>, <em>Learning the Basics</em>) for your directory walker</li>
<li><kbd>IntoIter</kbd>: The iterator created by the builder</li>
<li><kbd>DirEntry</kbd>: Represents a single folder or file</li>
</ul>
<p>If you just want to operate on a list of all entries under a root folder, such as in the first example in line [6], you can implicitly use <kbd>WalkDir</kbd> directly as an iterator over different instances of <kbd>DirEntry</kbd>:</p>
<pre>for entry in WalkDir::new(".") {<br/>    if let Ok(entry) = entry {<br/>        println!("{}", entry.path().display());<br/>    }<br/>}</pre>
<p>As you can see, the iterator doesn't directly give you a <kbd>DirEntry</kbd>, but a <kbd>Result</kbd>. This is because there are some cases where accessing a file or folder might prove difficult. For instance, the OS could prohibit you from reading the contents of a folder, hiding the files in it. Or a symlink, which you could enable by calling <kbd>follow_links(true)</kbd> on the <kbd>WalkDir</kbd> instance, could point back to a parent directory, potentially resulting in an endless loop.</p>
<p>Our solution strategy for the errors in this recipe is simple—we just ignore them and carry on with the rest of the entries that didn't report any issues.</p>
<p>When you extract the actual entry, it can tell you a lot about itself. One of those things is its path. Keep in mind, though, that <kbd>.path()</kbd> [8] doesn't just return the path as a string. Actually, it returns a native Rust <kbd>Path</kbd> struct that could be used for further analysis. You could, for example, read a file path's extension by calling <kbd>.extension()</kbd> on it. Or you could get its parent directory by calling <kbd>.parent()</kbd>. Feel free to explore the possibilities by exploring the <kbd>Path</kbd> documentation at <a href="https://doc.rust-lang.org/std/path/struct.Path.html">https://doc.rust-lang.org/std/path/struct.Path.html</a>. In our case, we are only going to display it as a simple string by calling <kbd>.display()</kbd> on it.</p>
<p>When we explicitly convert <kbd>WalkDir</kbd> into an iterator with <kbd>into_iter()</kbd>, we can access a special method that no other iterator has: <kbd>filter_entry</kbd>. It is an optimization over <kbd>filter</kbd> in that it gets called during the traversal. When its predicate returns <kbd>false</kbd> on a directory, the walker won't go into the directory at all! This way, you can gain a lot of performance when traversing big filesystems. In the recipe, we use it while looking for non-hidden files [15]. If you need to operate only on files and never on directories, you should use plain old <kbd>filter</kbd> instead.</p>
<div class="packt_infobox">We define <em>hidden files</em>, by Unix convention, as all directories and files that start with a dot. For this reason, they are sometimes also called <em>dotfiles.</em></div>
<p>In both cases, your filtering requires a predicate. They are usually put in their own function for simplicity and reusability.</p>
<p>Note that <kbd>walkdir</kbd> doesn't just give us the filename as a normal string. Instead, it returns an <kbd>OsStr</kbd>. This is a special kind of string that Rust uses when talking directly to the operating system. The type exists because some operating systems allow invalid UTF-8 in their filenames. When looking at such files in Rust, you have two choices—let Rust try to convert them into UTF-8 and replace all invalid characters with the Unicode Replacement Character (�), or instead handle the error yourself. You can go the first route by calling <kbd>to_string_lossy</kbd> on an <kbd>OsStr</kbd> [20]. The second route is accessible by calling <kbd>to_str</kbd> and checking the returned <kbd>Option</kbd>, like we did in <kbd>has_file_name</kbd>, where we simply discard invalid names.</p>
<p>In this recipe, you can see a splendid example of when to choose a <kbd>for_each</kbd> method call (discussed in the <em>Access collections as Iterators</em> section in <a href="0620f24b-d897-497a-b000-d63a1426c3ff.xhtml" target="_blank">Chapter 1</a>, <em>Learning the Basics</em>, <em>Working with collections</em>) over a <kbd>for</kbd> loop—most of our iterator calls are chained together, and so a <kbd>for_each</kbd> call can naturally be chained into the iterator as well.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">There's more...</h1>
                </header>
            
            <article>
                
<p>If you plan on publishing your application on Unix and Unix only, you can access additional permissions on an entry over its <kbd>.metadata().unwrap().permissions()</kbd> call. Namely, you can see the exact <kbd>st_mode</kbd> bits by calling <kbd>.mode()</kbd> and change them by calling <kbd>set_mode()</kbd> with a new set of bits.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">See also</h1>
                </header>
            
            <article>
                
<ul>
<li><em>Using the builder pattern</em> recipe in <a href="https://cdp.packtpub.com/rust_standard_library_cookbook/wp-admin/post.php?post=81&amp;action=edit#post_24" target="_blank">Chapter 1</a><span>, <em>Learning the Basics</em></span></li>
<li><em>Access collections as iterators</em> recipe in <a href="https://cdp.packtpub.com/rust_standard_library_cookbook/wp-admin/post.php?post=81&amp;action=edit#post_47" target="_blank">Chapter 2</a><span>, <em>Working with Collections</em></span></li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Finding files with glob patterns</h1>
                </header>
            
            <article>
                
<p>As you may have noticed, using <kbd>walkdir</kbd> to filter files based on their name can be a bit clunky at times. Luckily, you can greatly simplify this by using the <kbd>glob</kbd> crate, which brings you its titular patterns, known from Unix, right into Rust.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<p>Follow these steps:</p>
<ol>
<li>
<p>Open the <kbd>Cargo.toml</kbd> file that was generated earlier for you.</p>
</li>
<li>Under <kbd>[dependencies]</kbd>, add the following line:</li>
</ol>
<pre style="padding-left: 60px">glob = "0.2.11"</pre>
<ol start="3">
<li>If you want, you can go to glob's crates.io page (<a href="https://crates.io/crates/glob">https://crates.io/crates/glob</a>) to check for the newest version and use that one instead.</li>
<li>
<p>In the <kbd>bin</kbd> folder, create a file called <kbd>glob.rs</kbd>.</p>
</li>
<li>
<p>Add the following code and run it with <kbd>cargo run --bin glob</kbd>:</p>
</li>
</ol>
<pre style="padding-left: 60px">1    extern crate glob;<br/>2    use glob::{glob, glob_with, MatchOptions};<br/>3 <br/>4    fn main() {<br/>5      println!("All all Rust files in all subdirectories:");<br/>6      for entry in glob("**/*.rs").expect("Failed to read glob<br/>       pattern") {<br/>7        match entry {<br/>8          Ok(path) =&gt; println!("{:?}", path.display()),<br/>9          Err(e) =&gt; println!("Failed to read file: {:?}", e),<br/>10       }<br/>11     }<br/>12 <br/>13     // Set the glob to be case insensitive and ignore hidden<br/>          files<br/>14     let options = MatchOptions {<br/>15       case_sensitive: false,<br/>16       require_literal_leading_dot: true,<br/>17       ..Default::default()<br/>18     };<br/>19 <br/>20 <br/>21     println!(<br/>22       "All files that contain the word \"ferris\" case<br/>          insensitive \<br/>23        and don't contain an underscore:"<br/>24     );<br/>25     for entry in glob_with("*Ferris[!_]*",<br/>       &amp;options).expect("Failed to read glob pattern") {<br/>26       if let Ok(path) = entry {<br/>27         println!("{:?}", path.display())<br/>28       }<br/>29     }<br/>30   }</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p>This crate is pretty small and simple. With <kbd>glob(...)</kbd>, you can create an iterator over all matching files by specifying a <kbd>glob</kbd> pattern. If you aren't familiar with them but remember the regex recipe from earlier (in the <em>Querying with regexes</em> section in <a href="0620f24b-d897-497a-b000-d63a1426c3ff.xhtml" target="_blank">Chapter 1</a>, <em>Learning the Basics</em>), think of them as very simplified regexes used primarily for filenames. Its syntax is nicely described on Wikipedia: <a href="https://en.wikipedia.org/wiki/Glob_%28programming%29">https://en.wikipedia.org/wiki/Glob_(programming)</a>.</p>
<p>As with <kbd>WalkDir</kbd> before, the <kbd>glob</kbd> iterator returns a <kbd>Result</kbd> because the program might not have the permissions to read a filesystem entry. Inside the <kbd>Result</kbd> sits a <kbd>Path</kbd>, which we also touched on in the last recipe. If you want to read the contents of the file, refer to the first recipe in this chapter, which deals with file manipulation.</p>
<p>With <kbd>glob_with</kbd>, you can specify a <kbd>MatchOptions</kbd> instance to change the way <kbd>glob</kbd> searches for files. The most useful options you can toggle are:</p>
<ul>
<li><kbd>case_sensitive</kbd>: This is enabled per default and controls whether lowercase letters (abcd) and uppercase letters (ABCD) should be treated differently or not.</li>
<li><kbd>require_literal_leading_dot</kbd>: This is disabled per default and, when set, prohibits wildcards from matching a leading dot in a filename. This is used when you want to ignore a user's hidden files.</li>
</ul>
<p>You can view the rest of the options in the documentation of <kbd>MatchOption</kbd>: <a href="https://doc.rust-lang.org/glob/glob/struct.MatchOptions.html">https://doc.rust-lang.org/glob/glob/struct.MatchOptions.html</a>.</p>
<p>If you have set the options you care about, you can leave the rest at their default by using the <kbd>..Default::default()</kbd> <em>update syntax</em> discussed in the <em>Providing a default implementation</em> section in <a href="0620f24b-d897-497a-b000-d63a1426c3ff.xhtml" target="_blank">Chapter 1</a><em>, Learning the Basics</em>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">See also</h1>
                </header>
            
            <article>
                
<ul>
<li><em>Querying with Regexes</em> and <em>Providing a default implementation</em> recipes in <span><a href="0620f24b-d897-497a-b000-d63a1426c3ff.xhtml" target="_blank">Chapter 1</a>, <em>Learning the Basics</em></span></li>
</ul>


            </article>

            
        </section>
    </body></html>