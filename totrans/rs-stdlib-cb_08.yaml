- en: Working with Futures
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following recipes:'
  prefs: []
  type: TYPE_NORMAL
- en: Providing futures with a CPU pool and waiting for them
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing error handling for futures
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Combining futures
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using Streams
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using Sinks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using the oneshot channel
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returning futures
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Locking resources with BiLocks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Futures provide the building blocks for asynchronous computations with zero-cost
    abstraction. Asynchronous communication is useful for handling timeouts, computing
    across thread pools, network responses, and any function that does not immediately
    return a value.
  prefs: []
  type: TYPE_NORMAL
- en: In a synchronous block, the computer would execute each command sequentially
    after waiting for each command to return a value. If you were to apply the synchronous
    model when sending an email, you would send the message, stare at your inbox,
    and wait until you have received a response from your recipient.
  prefs: []
  type: TYPE_NORMAL
- en: Fortunately, life does not work synchronously. After we send an email, we could
    switch to another application or get off our chair. We can start performing other
    tasks such as getting the groceries, cooking dinner, or reading a book. Our attention
    can focus on, and perform, other tasks simultaneously. Periodically, we will check
    our inbox for a response from our recipient. The process of periodically checking
    for the new message illustrates the asynchronous model. Unlike humans, computers
    can check for a new message in our inbox and perform other tasks at the same time.
  prefs: []
  type: TYPE_NORMAL
- en: Rust’s futures work by implementing the polling model, which utilizes a central
    component (for example, a piece of software, hardware devices, and network hosts)
    to handle status reports from other components. The central, or master, component
    sends signals to other components repetitively until the master component receives
    an update, an interruption signal, or the polling event has timed out.
  prefs: []
  type: TYPE_NORMAL
- en: To get a better understanding on how concurrency works within Rust's model,
    you can view Alex Crichton's concurrency presentations at [https://github.com/alexcrichton/talks](https://github.com/alexcrichton/talks). Throughout
    our recipes, we will be using the `futures::executor::block_on` function within
    our main thread to return values. This is intentionally done for demonstrative
    purposes only. In a real application, you would use `block_on` within another
    a separate thread and your functions would return some sort of `futures::Future`
    implementation such as `futures::future::FutureResult`.
  prefs: []
  type: TYPE_NORMAL
- en: At the time of writing, futures is performing a lot of developmental changes
    throughout its code base. You can view futures' RFCs (Request For Comments) on
    their official repository at [https://github.com/rust-lang-nursery/futures-rfcs](https://github.com/rust-lang-nursery/futures-rfcs)
  prefs: []
  type: TYPE_NORMAL
- en: Providing futures with a CPU pool and waiting for them
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Futures are usually assigned to a `Task`, which gets assigned to an `Executor`.
    When a task is *awake,* the executor will place the task into a queue, and will call
    `poll()` on the task until the process has been completed. Futures offer us a
    few convenient ways to execute tasks:'
  prefs: []
  type: TYPE_NORMAL
- en: Spawn a future task manually with `futures::executor::block_on()`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using `futures::executor::LocalPool`, which is useful for performing many small
    tasks on a single thread. In our future returns, we would not be required to implement
    `Send` since we are only involving the task on a single thread. However, you are
    required to use `futures::executor::spawn_local()` on the `Executor` if you omit
    the `Send` trait.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using `futures::executor::ThreadPool`, which allows us to offload tasks to other
    threads.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Create a Rust project to work on during this chapter with `cargo new futures`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Navigate into the newly-created `futures` folder. For the rest of this chapter,
    we will assume that your command line is within this directory.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Inside the `src` folder, create a new folder called `bin`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Delete the generated `lib.rs` file, as we are not creating a library.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Open the `Cargo.toml` file that has been generated.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Under `[dependencies]`, add the following lines:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: In the `src/bin` folder, create a file called `pool.rs`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Add the following code and run it with `cargo run —bin pool`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s add our constants, enums, structures, and trait implementations:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s add our first local threaded function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'And now for our locally-spawned threading examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'And now for our thread pool example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'And lastly, our `main` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s start by introducing the `Future` trait:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Implementing the `Future` trait requires only three constraints: an `Item` 
    type, an `Error` type, and a `poll()` function. The actual trait looks as follows:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: The `Poll<Self::Item, Self::Error>` is a type that translates into `Result<Async<T>,
    E>` , where `T = Item` and `E = Error`. This is what our example is using on line
    50.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`poll()` is called upon whenever a `futures::task::Waker` (can also be known
    as a *Task*) is executed with one of our executors located at `futures::executor`,
    or manually woken up by building a `futures::task::Context` and running with a
    future wrapper such as `futures::future::poll_fn`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Now, onto our `local_until()` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '`LocalPool` offers us the ability to run tasks concurrently using a single
    thread. This is useful for functions with minimal complexity, such as traditional
    I/O bound functions. `LocalPools` can have multiple `LocalExecutors` (as we have
    created one on line 65), which can spawn our task. Since our task is single-threaded,
    we do not need to `Box` or add the `Send` trait to our future.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `futures::future::lazy` function will create a new future, from a `FnOnce`
    closure, which becomes the same future as the one that the closure returns (any
    `futures::future::IntoFuture` trait), which in our case that future is `FutureResult<Container,
    Never>`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Executing the `run_until(F: Future)` function from the `LocalPool` will perform
    all of the future tasks until the `Future` (indicated as `F`) has been marked
    as completed. This function will return `Result<<F as Future>::Item, <F as Future>::Error>`
    upon completion. In the example, we are returning `futures::future::ok(Container)`,
    on line 75, so our `F::Item` will be our `Container`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For our `local_spawns_completed()` function:'
  prefs: []
  type: TYPE_NORMAL
- en: First, we set up our `futures::channel::oneshot` channel (which is explained
    later, in the *Using the oneshot channel* section).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will use the `oneshot` channel's `futures::channel::oneshot::Receiver` as
    the future to run until completion within the `run_until()` function. This allows
    us to demonstrate how polling would work until a signal has been received from
    another thread or task (in our example, this happens on line 102 with the `tx.send(...)`
    command).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `LocalExecutor`'s `spawn_local()` is a special `spawn` function that gives
    us the capability of executing future functions without implementing the `Send`
    trait.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Next, our `local_nested()` function:'
  prefs: []
  type: TYPE_NORMAL
- en: We set up our usual `Container` and then declare a reference counter that will
    allow us to keep a value (this would be our `Container`) across multiple executors
    or threads. We do not need to use an atomic reference counter, since we are using
    `spawn_local()`, which performs the future on a green thread (a thread that is
    scheduled by a virtual machine or a runtime library).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The `LocalPool`''s `run(exec: &mut Executor)` function will run any futures
    spawned within the pool until all of the futures have been completed. This also
    includes any executors that may `spawn` additional tasks within other tasks, as
    our example shows.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Onto our `thread_pool()` function:'
  prefs: []
  type: TYPE_NORMAL
- en: An `std::sync::mspc::sync_channel` is created with the intention of blocking
    the thread for demonstration purposes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Next, we created a `ThreadPool` with default settings and called its `spawn(F:
    Box<Future<Item = (), Error = Never> + ''static + Send>)` function, which will
    poll the task until completion whenever we decide to execute the pool.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'After setting up our tasks, we execute the `ThreadPool`''s `run(F: Future)`
    function, which will block the thread in which is invoking `run()` until the `F:
    Future` has been completed. The function will return a value upon the future''s
    completion even if there are other tasks spawned, and running, within the pool. 
    Using the `mspc::sync_channel` earlier helps mitigate this issue, but will block
    the thread upon being invoked.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'With the `ThreadPoolBuilder` , you can:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Set the number of worker threads
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Adjust the stack size
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Set a prefixed name for the pools
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Run a function (with the signature as `Fn(usize) + Send + Sync + 'static`) after
    each worker thread has started, right before the worker thread runs any tasks
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Execute a function (with the signature as `Fn(usize) + Send + Sync + 'static`)
    before each worker thread shuts down
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Handling errors in futures
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In a real application, we would not be returning a value instantly from an asynchronous
    function that directly returns `Async::Ready<T>` or `FutureResult<T, E>`. Network
    requests time out, buffers become full, services become unavailable due to bugs
    or outages, and many more issues pop up on a daily basis. As much as we like to
    build order from chaos, usually chaos wins due to naturally-occurring entropy
    (programmers may know this as *scope creep*) and decay (software updates, new
    computer science paradigms, and so on). Luckily for us, the futures library offers
    us a simple way to implement error handling.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Inside the `bin` folder, create a new file called `errors.rs`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Add the following code and run it with `cargo run --bin errors`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'After that, let''s add our structures and implementations:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'After that, let''s add our generic error handling functions/examples:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'And now for our `panic` functions:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'And finally, our `main` function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s start with the `using_recover()` function:'
  prefs: []
  type: TYPE_NORMAL
- en: Any errors that have occurred within the future will be transformed into `<Self
    as Future>::Item`. Any `<Self as Future>::Error` type can be passed through, since
    we never produce an actual error.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The `futures::executor::block_on(F: Future)` function will run a future until
    completion within the invoking thread. Any tasks within futures'' `default executor`
    will also run on the invoking thread, but completion on the tasks may never occur
    since `F` may finish before the tasks have been completed. If this is the case,
    then the spawned tasks are dropped. `LocalPool` is often recommended for mitigating
    this issue, but for our examples `block_on()` will be sufficient.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All of these error handling functions can be found within the `futures::FutureExt` trait.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, onto our `map_error()` function:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The `<Self as Future>::map_err<E, F>(F: FnOnce(Self::Error) -> E)` function
    will map a future''s (`Self`) error into another error while returning a new future.
    This function is often used in conjunction with combinators, such as select or
    join, since we can guarantee that the futures will have the same error type to
    complete the composition.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Next, the `err_into()` function:'
  prefs: []
  type: TYPE_NORMAL
- en: Transforms the `Self::Error` into another `Error` type using the `std::convert::Into`
    trait
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Like `futures::FutureExt::map_err`, this function is useful for aggregating
    combinators together
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The `or_else()` function:'
  prefs: []
  type: TYPE_NORMAL
- en: If `<Self as Future>` returns an error, `futures::FutureExt::or_else` will execute
    a closure with the following signature:  `FnOnce(Self::Error) -> futures::future::IntoFuture<Item
    = Self::Item>`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Useful for chaining failing combinators together
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The closure will not execute if the future has completed successfully, panics,
    or its future is dropped
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Then the `catch_unwind()` function:'
  prefs: []
  type: TYPE_NORMAL
- en: This function is generally not recommended as a way to handle errors, and is
    only enabled with Rust's `std` option (which is enabled by default)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Future traits implement the `AssertUnwindSafe` trait as `AssertUnwindSafe<F:
    Future>` trait'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'And lastly, the `stream_panics()` function:'
  prefs: []
  type: TYPE_NORMAL
- en: On line 95, this `futures::StreamExt::catch_unwind` function is similar to `futures::FutureExt::catch_unwind`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If a panic occurs, it will be the last element of the stream for the stream
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This feature is only enabled with Rust's `std` option as well
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The `AssertUnwindSafe` trait is also implemented for streams as `AssertUnwindSafe<S:
    Stream>`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The combinators for streams are located in the `futures::StreamExt` trait, which
    has the same functions as `futures::FutureExt` with some additional stream-specific
    combinators such as `split()` and `skip_while()` that may prove to be useful for
    your projects.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[Chapter 6](d2c7b7cb-3060-40b8-adb4-408eee7940a1.xhtml), *Handling Errors*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Combining futures
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Combining, and chaining, our futures allows us to perform multiple operations
    in sequential order and helps organize our code a bit more. They can be used to
    transform, splice, filter, and so on `<Self as Future>::Item`s.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Inside the `bin` folder, create a new file called `combinators.rs`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Add the following code and run it with `cargo run --bin combinators`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s add our `join_all` example function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we will write out our `shared` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'And now for our `select_all` example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we can add our `flatten`, `fuse`, and `inspect` functions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Then we can add our `chaining` example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'And now for our `main` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The `join_all()` function:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Collects results from several futures and returns a new future with the `futures::future::JoinAll<F:
    Future>` trait'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The new future will perform commands for all of the aggregated futures within
    the `futures::future::join_all` call, returning a vector of `Vec<T: Future::Item>`
    in FIFO ordering'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An error will return itself immediately and cancel the other related futures
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'And the `shared()` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '`futures::FutureExt::shared` will create a handle that can be cloned, which
    resolves to the returning value of `<T as futures::future::SharedItem>` which
    can be deferred into `T`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Useful for polling a future on more than one thread
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This method is enabled only when Rust's `std` option is enabled (which it is
    by default)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The underlying result is `futures::future::Shared<Future::Item>`, which implements
    `Send` and `Sync` traits
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using `futures::future::Shared::peek(&self)` will return a value without blocking
    if any single shared handle has been completed
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Next, the `select_all_example()` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '`futures::FutureExt::select_all` returns a new future that selects from a list
    of vectors'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The return value is `futures::future::SelectAll`, which allows us to iterate
    through the results
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The future's item, index of execution, and a list of futures that still need
    to be processed will be returned by this function as soon as one of the futures
    completes its execution
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Then the `flatten()` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '`futures::FutureExt::flatten` will combine futures together with a returning
    result of their items being flattened'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The resultant item must implement the `futures::future::IntoFuture` trait
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Onto the `fuse()` function:'
  prefs: []
  type: TYPE_NORMAL
- en: There is a small chance of `undefined behavior`, such as panicking or blocking
    forever, when polling a future that has already returned a `futures::Async::Ready`
    or `Err` value. The `futures::FutureExt::fuse` function allows us to `poll` the
    future again without worrying about `undefined behavior`, and will always return
    `futures::Async::Pending`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The future that's being fused will be dropped upon completion in order to reclaim
    resources.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The `inspect()` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '`futures::FutureExt::inspect` allows us to peek at an item of a future which
    is useful for when we are chaining combinators.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'And then the `chaining()` function:'
  prefs: []
  type: TYPE_NORMAL
- en: We first create a channel with three values, and `spawn` a thread to send those
    three values to the channel's receiver using the `futures::FutureExt::and_then`
    combinator.  We collect the results on line 130 from the channel.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Then we chain two streams together on line 134 and 135 with the collection occurring
    on line 140\. The result of both streams should be chained together on lines 137
    and 138.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Using a vector* and *Access collections as iterators* recipes in [Chapter
    2](977b8621-cb73-43de-9a2b-4bc9f5583542.xhtml), **Working with Collections**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using Streams
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A stream is a pipeline for events that returns a value asynchronously to the
    invoker. `Streams` are more useful for items that require the `Iterator` trait,
    while `Futures` are more apt for `Result` values. When an error occurs throughout
    a stream, the error will not halt the stream, and polling on the stream will still
    return other results until the `None` value has been returned.
  prefs: []
  type: TYPE_NORMAL
- en: '`Streams` and `Channels` can be a bit confusing for some.  `Streams` are used
    for continuous, buffered data, and `Channels` are more suited for completed messages
    between endpoints.'
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Inside the `bin` folder, create a new file called `streams.rs`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Add the following code and run it with `cargo run --bin streams`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let''s add our constants, implementations, and so on:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Our `quick_streams` example would be:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'There are several ways to iterate through streams; let''s add them to our code
    base:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'And now for our channeling example:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Dealing with errors and channels can be done as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'We can even work with buffers and channels together. Let''s add our `channel_buffer`
    function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Just because we''re using the futures crate doesn''t mean everything has to
    be concurrent. Add the following example to demonstrate how to block with channels:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Sometimes we''ll need concepts such as unbounded channels; let''s add our `channel_unbounded`
    function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'And now we can add our `main` function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'First, let''s talk about the `QuickStream` structure:'
  prefs: []
  type: TYPE_NORMAL
- en: The `poll_next()` function will continuously be invoked, and with each iteration,
    `i`'s ticks attribute will be decremented by `1`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Polling will stop when the ticks attribute reaches `0` and returns `futures::Async::Ready<None>`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Within the `quick_streams()` function:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We build a `futures::task::Context` by using `futures::future::poll_on(f: FnMut(|cx:
    Context|))`, so that we can explicitly invoke `QuickStream`''s `poll_next()` function
    on lines 42 and 50'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Since we have declared `10` ticks on line 38, our first two `block_on`'s `poll_next()`
    calls should yield `9` and `8`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The next `block_on` call, on line 57, will keep polling `QuickStream` until
    `futures::Async::Ready<None>` is returned from the ticks attribute equaling zero
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Within `iterate_streams()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '`futures::stream::iter_ok` will convert an `Iterator` into a `Stream`, which
    will always be ready to return the next value'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`futures::stream::iter_result` does the same thing as `iter_ok`, except we
    use `Result` values instead of `Ok` values'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: On lines 78 through 89, we iterate through the stream's results and print out
    some information depending on whether the value was `Ok` or an `Error` type. If
    the `None` type has been returned from our stream, then we will break the loop
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lines 92 through 95 show an alternative way of iterating through a stream's
    `Ok` results by using the `into_iter()` calls
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lines 97 through 99 show an alternative way of iterating through a stream's
    `Result` return types
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Loops, iterated results, and `collect()` calls are synchronous. We used this
    functions for demonstrative/educational purposes only. Combinators such as `map()`,
    `filter()`, `and_then()`, etc. would be used in a real application for streams
    and channels.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `channel_threads()` function:'
  prefs: []
  type: TYPE_NORMAL
- en: On line 107, we define the maximum number of sends we want to attempt.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: On line 108, we declare a channel to send messages to. Channel capacity is the
    `buffer size (the argument of futures::channel::mpsc::channel) + the number of
    senders` (each sender is guaranteed a slot within the channel). Channels will
    return a `futures::channel::mpsc::Receiver<T>`, which implements the `Stream`
    trait, and a `futures::channel::mpsc::Sender<T>`, which implements the `Sink`
    trait.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lines 110 through 120 is where we `spawn` a thread and attempt to send 10 signals,
    looping until each send is sent successfully.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We collect, and display, our results on line 122 through 125, and join our threads
    on line 127.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The `channel_error()` section:'
  prefs: []
  type: TYPE_NORMAL
- en: On line 131, we declare our channel with a `0 usize` buffer as the argument,
    which gives us one slot for the initial sender
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We send the first message successfully on line 133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lines 136 through 139 should fail, since we are trying to send a message to
    a channel that is considered full (since we did not receive the value, drop the
    initial sender, flush the stream, and so on)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'On line 146, we use the sender''s `futures::channel::mpsc::Sender::try_send(&mut
    self, msg: T)` functions, which won''t block our thread unless we don''t drop/invoke
    the sender''s destroyer method using `drop(T)` on line 147'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Polling the stream any additional times after receiving the last value will
    always return `None`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Next, the `channel_buffer()` function:'
  prefs: []
  type: TYPE_NORMAL
- en: We set up a future closure with `poll_fn()` on line 162.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We check to see if our sender is ready to be polled with its `futures::sink::poll_ready(&mut
    self, cx: &mut futures::task::Context)` method on lines 163 through 165.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sinks have a method called `futures::sink::start_send(&mut self, item: <Self
    as Sink>::SinkItem) -> Result<(), <Self as Sink>::SinkError>`, which prepares
    the message to be delivered, but won''t until we flush or close the sink. `poll_flush()`
    is often used to guarantee that every message has been sent from the sink.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Polling the stream for the next value will also alleviate space within the
    sink/sender using the `futures::stream::poll_next(&mut self, cx: &mut futures::task::Context)`
    method, as we have done on line 179.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We can check if our sender is ready, as we have done on line 182 using the `futures::Async::is_ready(&self)
    -> bool` method.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Our final value should be `22` and displayed to the console from line 192.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Then the `channel_threads_blocking()` function:'
  prefs: []
  type: TYPE_NORMAL
- en: First, we set up our channels on lines 201 and 202.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Then we `spawn` a thread that will map all of `tx_2`'s errors into a `panic!`
    (line 205), and then we send the value of `10` to our first channel while joining
    a second sender with the `()` value (line 206). On line 208, we send the value
    of `30` and another empty value `()` to our second channel.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: On line 211 we poll the second channel, which would hold a value of `()`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: On line 212 we poll the first channel, which would hold a value of `10`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We drop the second channel's receiver (line 215), since we need to close or
    flush for the second `tx_2.send()` call on line 208 (`tx_2` is known as variable
    `b` on this line).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: After performing the drop, we can finally return our second value from the first
    channel's sender, which should be `30`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'And the `channel_unbounded()` function:'
  prefs: []
  type: TYPE_NORMAL
- en: On line 225 we declare an `unbounded channel`, which means that sending messages
    to this channel will always succeed as long as the receiver is not closed. Messages
    will be buffered on an as-needed basis, and since this channel is unbounded, our
    application can exhaust our available memory.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lines 227 through 232 `spawn` a thread that collects all of the receiver's messages
    (line 228), and we iterate through them on line 229\. The item on line 230 is
    a tuple of the index in which the message was received and the message's value
    (in our case, this is always 1).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lines 237 through 241 is what will `spawn` the number of threads (using the
    `MAX_THREADS` constant) as well as the number of times that we want to send per
    thread using the `MAX_THREADS` constant.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lines 244 we will drop (which closes) the channel's sender so that we may collect
    all of the messages from line 228.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We join the spawned thread with our current thread on line 246, which will execute
    the collection and iterations commands (lines 228 through 231).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using Sinks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Sinks are the *sending-side* of channels, sockets, pipes, and so on, in which
    messages can be sent from the sink asynchronously. Sinks communicate by initiating
    a send signal, and then the rest is polled. One thing to watch out for when using
    sinks is that they can run out of sending space, which will prevent more messages
    from being sent.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Inside the `bin` folder, create a new file called `sinks.rs`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Add the following code and run it with `cargo run --bin sinks`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s add our examples with using vectors as `sinks`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'We can map/transform our `sinks` values. Let''s add our `mapping_sinks` example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'We can even send messages to multiple `sinks`. Let''s add our `fanout` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we''ll want to implement a structure for a customized sink. Sometimes
    our application will require us to manually flush our `sinks` instead of doing
    it automatically. Let''s add our `ManualSink` structure:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'And now for our `manual flush` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'And lastly, we can add our `main` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'First, let''s take a look at the `futures::Sink` trait itself:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'We are already familiar with the `Item` and `Error` concepts from futures and
    streams, so we will move on to the required functions:'
  prefs: []
  type: TYPE_NORMAL
- en: '`poll_ready` must be invoked with the returning value of `Ok(futures::Async::Ready(()))`
    before each attempt at using `start_send`. If the sink receives an error, the
    sink will no longer be able to receive items.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`start_send`, as stated previously, prepares the message to be delivered, but
    won''t until we flush or close the sink. If the sink uses buffers, the `Sink::SinkItem`
    won''t be processed until the buffer has been fully completed.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`poll_flush` will flush the sink, which will allow us to collect items that
    are currently being processed. `futures::Async::Ready` will return if the sink
    does not have any more items within the buffer, otherwise, the sink will return
    `futures::Async::Pending`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`poll_close` will flush and close the sink, following the same return rules
    as `poll_flush`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Now, onto our `vector_sinks()` function:'
  prefs: []
  type: TYPE_NORMAL
- en: Sinks are implemented for `Vec<T>` types, so we can declare a mutable vector
    and use the `start_send()` function, which will immediately poll our values into
    the vector on lines 13 through 15.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'On line 28 we use the `futures::SinkExt::send(self, item: Self::SinkItem)`,
    which will complete after the item has been processed and flushed through the
    sink. `futures::SinkExt::send_all` is recommended for batching multiple items
    to send through, versus having to manually flush between each send call (as demonstrated
    on line 43).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Our `mapping_sinks()` function:'
  prefs: []
  type: TYPE_NORMAL
- en: Line 51 demonstrates how you can map/manipulate elements within a sink using
    the `futures::SinkExt::with` function. This function produces a new sink that
    iterates through each item and sends the final value *as a future* to the *parent* sink.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Line 60 illustrates the `futures::SinkExt::flat_with_map` function that has
    mostly the same functionality as the `futures::SinkExt::with` function except
    each iterated item is sent as a stream value to the *parent* sink and will return
    an `Iterator::flat_map` value instead of a `Iterator::map`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Next, the `fanout()` function:'
  prefs: []
  type: TYPE_NORMAL
- en: The `futures::SinkExt::fanout` function allows us to send messages to multiple
    sinks at one time, as we have done on line 72.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'And then `manual_flush()`:'
  prefs: []
  type: TYPE_NORMAL
- en: We first implement our own `Sink` trait with the `ManualSink<T>` construct (lines
    81 through 135). Our `ManualSink`'s `poll_flush` method will only return `Async::Ready()`
    if our data vector is empty, otherwise, we are going to push the task (`futures::task::Waker`)
    into a queue line through the `waiting_tasks` attribute. We use the `waiting_tasks`
    attribute within our `force_flush()` function (line 128) in order to manually
    *wake up* our tasks (line 130).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: On lines 138 through 140, we build our `ManualSink<Option<i32>>` and start sending
    some values.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We use `poll_fn` on line 142 in order to quickly build a `futures::task::Context`
    so that we may pass this value down to our underlying poll calls.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: On line 144 we manually call our `poll_flush()` function, which will not execute
    our actual tasks since they are placed within the `waiting_tasks` attribute.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Until we invoke `force_flush()`, our sink will not return any values (as indicated
    on lines 150-151). Once this function has been called upon and the underlying
    `Waker` tasks have finished executing, then we can see the messages (line 152)
    that we sent earlier (lines 139 and 140).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using the oneshot channel
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Oneshot channels are useful for when you need to send only one message to a
    channel. The oneshot channel is applicable for tasks that really only need to
    be updated/notified once, such as whether or not a recipient has read your message,
    or as a final destination within a task pipeline to notify the end user that the
    task has been completed.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Inside the `bin` folder, create a new file called `oneshot.rs`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Add the following code and run it with `cargo run --bin oneshot`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Within our `send_example()` function:'
  prefs: []
  type: TYPE_NORMAL
- en: On lines 13 through 15, we set up three `oneshot` channels.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: On lines 20 through 23 we use `futures::stream::futures_ordered`, which will
    convert a list (any `IntoIterator` value) of futures into a `Stream` yielding
    results on a first in, first out (FIFO) basis. If any underlying futures do not
    complete before the next future is invoked, this function will wait until the
    long-running future has been completed and will then internally re-sort that future
    into its proper order.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Line 25 shows us that we can push additional futures into the `futures_ordered`
    iterator separately.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Line 28 demonstrates another function that doesn't rely on sorting on a FIFO
    basis, called `futures::stream::futures_unordered`. This function will have better
    performance than its counterpart `futures_ordered`, but for our example, we are
    not sending enough values to make a difference.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: On lines 31 through 33 we send values to our channels, mimicking the process
    of returning values from an API, a database, and so on. If the send is successful
    then `Ok(())` will be returned, otherwise, an `Err` type will be returned.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: And on our last two lines (35 and 36), we collect our `futures_ordered` values
    and display them to the console.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Next, the `check_if_closed()` function:'
  prefs: []
  type: TYPE_NORMAL
- en: Our channel should remain open until we explicitly drop/destroy the receiver
    (or send a value to the channel). We can check the status of our receiver by invoking
    the `futures::channel::oneshot::Sender::is_canceled(&self) -> bool` function,
    which we have done on lines 42 and 45.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Then the `check_if_ready()` function:'
  prefs: []
  type: TYPE_NORMAL
- en: On line 50 we explicitly assign a value to the oneshot's receiver, which would
    put our receiver in a state of pending (since it already has a value).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We drop our receiver on line 55 and we can check if our receiver is ready by
    using our sender's `futures::channel::oneshot::Sender::poll_cancel` function,
    which we use on lines 57 and 58\. `poll_cancel` will return `Ok(Async::Ready)`
    if the receiver has been dropped or `Ok(Async::Pending)` if the receiver has not
    been dropped.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returning futures
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The `Future` trait relies on three main ingredients: a type, an error, and
    a `poll()` function that returns a `Result<Async<T>, E>` structure. The `poll()`
    method will never block the main thread, and `Async<T>` is an enumerator with
    two variants: `Ready(T)` and `Pending`. Periodically, the `poll()` method will
    be invoked by a task’s context''s `waker()` trait, located in `futures::task::context::waker`,
    until a value is ready to be returned.'
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the `src/bin` folder, create a file called `returning.rs`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Add the following code and run it with `cargo run —bin returning`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'Now comes the implementations for the structs:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we''ll want to add our `helper` functions and our `Async` function for
    adding points to our players:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'And finally, the actual usage:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s start by introducing the structures that participate in this example:'
  prefs: []
  type: TYPE_NORMAL
- en: '`PlayerStatus` is an enumerator for maintaining a *global* state on the player''s
    instance. The variants are:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Loading`, which is the initial state'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Default`, which is applied after we are done loading the player''s stats'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Jumping` is a special state that won''t allow us to add points to the player''s
    scoreboard due to the rules of the game'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Player` holds our player''s main attributes, along with a special attribute
    called ticks that stores the amount of cycles that we want to run through with
    `poll()` before assigning the player''s status from `Loading` to `Default`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Now, onto our implementations:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Jumping down to the `fn set_status(&mut self, status: PlayerStatus) -> FutureResult<&mut
    Self, Never>` function on our `Player` structure, we will notice a return value
    of `FutureResult`, which tells futures that this function will immediately return
    a computed value from the `result()`, `ok()`, or `err()` functions from `futures::futures`. 
    This is useful for quickly prototyping our application while being able to utilize
    our `executors` and futures combinators.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'At the `fn add_points(&mut self, points: u32) -> Async<&mut Self>` function
    we return our `Async` value immediately, since we currently do not have a server
    to use, but we would implement the `Async<T>` value over `FutureResult` for functions
    that require computations asynchronously.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We mimic the time it takes for a network request using our player's `ticks`
    attribute. `Poll<I, E>` will keep executing as long as we are returning `Async::Pending`
    (line [x]).  The executor needs to know whether or not a task needs to be polled
    again. The task's `Waker` trait is what handles these notifications, and we can
    manually invoke it using `cx.waker().wake()` on line 83 . Once our player's `ticks`
    attribute reaches zero we send an `Async::Ready(self)` signal, which tells the
    executor to no longer poll this function.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For our `async_add_points()` helper method:'
  prefs: []
  type: TYPE_NORMAL
- en: We return `Box<Future<Item = Player, Error = Never> + Send`, which tells futures
    that this function will eventually return a value of `Player` (since we `Never`
    return an error).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `+ Send` part of the return is not necessary for our current code base,
    but in the future, we may want to offload some of these tasks onto other threads
    which executors require. Spawning across threads requires us to return the `futures::prelude::Never`
    type as an error and a `'static` variable as well.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When calling future functions with combinators (such as `then` and `and_then`),
    we will need to return a `Never` error type or the same error type as every other
    future function that is being called within the same combinator flow.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Finally, onto our main block:'
  prefs: []
  type: TYPE_NORMAL
- en: We use the `futures::future::join_all` function, which accepts any `IntoIterator`
    that contains all `InfoFuture` trait elements (which should be all future functions).
    This either collects and returns `Vec<T>` sorted FIFO, or cancels executing as
    soon as the first error returns from any of the future functions within the collection,
    which becomes the returning value for the `join_all()` call.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`then()` and `and_then()` are combinators that internally use `future::Chain`
    and return a `Future` trait value, which allows us to add more combinators if
    we wanted. See the *Using combinators and utilities* section for more information
    on combinators.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`block_on()` is an executor method that handles any future function or value
    as its input and returns a `Result<Future::Item, Future::Error>`. When running
    this method, the function containing the method will block until the future(s)
    have been completed. Spawned tasks will execute on the default executor, but they
    may not be completed before `block_on` finishes its task(s). If `block_on()` finishes
    before the spawned tasks, then those spawned tasks will be dropped.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We can also use `block_on()` as a quick way to run our cycles/ticks and execute
    task(s), which invokes our `poll()` functions. We used this method on line 124
    for *initially loading players* onto the game.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The `box()` method for returning futures does cause an additional allocation
    to the heap. Another method of returning futures relies on using a `nightly` version
    of Rust or for this issue  [https://github.com/rust-lang/rust/issues/34511](https://github.com/rust-lang/rust/issues/34511)
    to be resolved. The new `async_add_points()` method would return an implied `Future`
    trait and would look as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: Rust may cause `undefined behavior` if we were to call `poll()` more than once
    for a future. This problem can be mitigated by converting the future into a stream
    by using the `into_stream()` method or using the `fuse()` adapter, which adds
    a tiny bit of runtime overhead.
  prefs: []
  type: TYPE_NORMAL
- en: Tasks are usually executed/polled from using an `executor` such as the `block_on()`
    helper function. You can manually execute tasks by creating a `task::Context`
    and calling `poll()` directly from the task. As a general rule, it is recommended
    to not invoke `poll()` manually and to have an executor manage polling automatically.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Boxing data* recipe in [Chapter 5](6b8b0c3c-2644-4684-b1f4-b1e08d62450c.xhtml),
    *Advanced Data Structures*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Chapter 7](ca93ce61-1a86-4588-9da0-766bed49876f.xhtml), *Parallelism and Rayon*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Locking resources with BiLocks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: BiLocks are used when we need to store a value across multiple threads with
    up to two owners associated with that value. Applicable uses for a BiLock type
    would be splitting TCP/UDP data for reading and writing, or adding a layer between
    a sink and a stream (for logging, monitoring, and so on), or it can be a sink
    and a stream at the same time.
  prefs: []
  type: TYPE_NORMAL
- en: When using futures with an additional crate (such as tokio or hyper), knowing
    BiLocks can help us wrap data around the other crate's common methods. This would
    allow us to build futures and concurrency on top of existing crates without having
    to wait until the crate's maintainers support concurrency explicitly. BiLocks
    are a very low-level utility, but understanding how they work can help us further
    down the road with our (web) applications.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will mostly focus on networking with Rust, but we will
    also get to practice integrating futures with other crates. BiLocks can be used
    throughout these next examples, if you wanted to split a TCP/UDP stream in a mutex
    state, although it is not necessary to do so with the crates that we will be using.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the `src/bin` folder, create a file called `bilocks.rs`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Add the following code and run it with `cargo run —bin bilocks`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: First, we need to implement a fake `futures::task::Waker` for when we create
    a new context (this is what our `FakeWaker` structure is for on lines 11 through
    14)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Since BiLocks require two owners, we will divide the ownership into two different
    structures, called `Reader<T>` (on lines 16 through 18) and `Writer<T>` (on lines
    20 through 22)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Our `split() -> (Reader<u32>, Writer<u32>)` function is just to structure/organize
    our code a bit better, and when calling `BiLock::new(t: T)` the return type is
    a tuple of two `futures_util::lock::BiLock` elements'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Now that the preliminary code has been explained, let''s dive into our `main()`
    function:'
  prefs: []
  type: TYPE_NORMAL
- en: On lines 30 through 34 we set up a new `LocalPool`, `LocalExecutor`, `Waker`
    (`FakeWaker`), and a `LocalMap` (map storage of local data within tasks) for creating
    a new `Context`, since we will be polling our locks manually for demonstration
    purposes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lines 38 and 40 use the `futures_util::lock::BiLock::poll_lock` function, which
    returns an `Async<futures_util::lock::BiLockGuard<T>>` value if the lock is available.
    If the lock is not available then the function will return `Async::Pending`. The
    lock (the `BiLockGuard<T>`) will unlock when the reference is dropped.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: On line 42 we execute `writer.lock.lock()`, which will block the lock and a
    `BiLockAcquire<T>` will be returned, which is a future that can be polled. When
    `BiLockAcquire` is polled, a `Poll<BiLockAcquired<T>, ()>` value is returned and
    that value can be dereferenced mutably.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: On line 48, we can now see that the lock is currently in an `Async::Pending`
    state, which would not allow us to lock the BiLock again, as shown on lines 51
    through 57.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: After modifying our lock's value (line 49), we should now unlock it (line 59)
    so that the other owner can reference it (lines 61 through 64).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When we call `BiLockAcquired::unlock()` (line 68), the original `BiLock<T>`
    is returned and the lock is officially unlocked.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'On line 69 we perform `futures_util::lock::BiLock::reunite(other: T)`, which
    recovers the value of the lock and destroys the *two halves* of the BiLock references
    (presuming that `T` is the other half of the BiLock from the `BiLock::new()` call).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
