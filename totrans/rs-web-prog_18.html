<html><head></head><body>
		<div id="_idContainer201">
			<h1 id="_idParaDest-334" class="chapter-number"><a id="_idTextAnchor335"/>18</h1>
			<h1 id="_idParaDest-335"><a id="_idTextAnchor336"/>Queuing Tasks with Redis</h1>
			<p>Receiving requests, performing an action, and then returning a response to the user can solve a lot of problems in web programming. However, there are times when this simple approach will simply not cut it. For instance, when I was working at MonolithAi, we had a functionality where the user would be able to put in data and parameters and then train a machine learning model on that data at a click of a button. However, trying to train a machine learning model before sending a response to the user would simply take too long. The connection would probably time out. To solve this, we had a <strong class="bold">Redis</strong> queue and a pool of workers consuming tasks. The training task would be put into the queue and one of the workers would work on training the model when they got round to it. The HTTP server would accept the request from the user, post the training task to the queue, and respond to the user that the task was posted. When the model was trained, the user would get an update. Another example could be a food ordering application where the food order goes through a series of steps such as confirming the order, processing the order, and then delivering the order. </p>
			<p>Considering the MonolithAi example, it is not hard to see why learning how to implement queuing in web programming is not only useful but also gives the developer another solution, increasing the number of problems they can solve. </p>
			<p>In this chapter, we will cover the following topics: </p>
			<ul>
				<li>Laying out the queuing project, describing the components and <span class="No-Break">approach needed</span></li>
				<li>Building an HTTP server </li>
				<li>Building a <span class="No-Break">polling worker</span></li>
				<li>Getting our application running <span class="No-Break">with Redis</span></li>
				<li>Defining tasks <span class="No-Break">for workers</span></li>
				<li>Defining messages for the <span class="No-Break">Redis queue</span></li>
				<li>Integrating routing in the HTTP server </li>
				<li>Running all servers and workers <span class="No-Break">in Docker</span></li>
			</ul>
			<p>By the end of this chapter, you will be able to build a single Rust program that can either be a worker or server depending on the environment variable passed into it. You will also be able to serialize a range of tasks in the form of different structs and insert them into the Redis queue, enabling these structs to be queued and transported across different servers. This will not only give you the skillset to implement queues but also utilize Redis to implement many other solutions, such as multiple servers receiving messages through a broadcast via a Redis <span class="No-Break">pub/sub channel.</span></p>
			<h1 id="_idParaDest-336"><a id="_idTextAnchor337"/>Technical requirements</h1>
			<p>In this chapter, we will be purely focusing on how to build workers using Tokio and Hyper on a Redis queue. Therefore, we will not be relying on any previous code as we are building our own <span class="No-Break">new server.</span></p>
			<p>The code for this chapter can be found <span class="No-Break">at </span><a href="https://github.com/PacktPublishing/Rust-Web-Programming-2nd-Edition/tree/main/chapter18"><span class="No-Break">https://github.com/PacktPublishing/Rust-Web-Programming-2nd-Edition/tree/main/chapter18</span></a><span class="No-Break">.</span></p>
			<h1 id="_idParaDest-337"><a id="_idTextAnchor338"/>Breaking down our project</h1>
			<p>In our system, we<a id="_idIndexMarker1443"/> have a series of tasks that need to be executed. However, these tasks take a long time to complete. If we were to just have a normal server handling the tasks, the server will end up being choked and multiple users will receive a delayed experience. If the task is too long, then the users’ connection might <span class="No-Break">time out.</span></p>
			<p>To avoid degrading users’ experience when long tasks are needed, we utilize a queuing system. This is where an HTTP server receives a request from the user. The long task associated with the request is then sent to a first-in-first-out queue to be processed by a pool of workers. Because the task is in the queue, there is nothing more the HTTP server can do apart from respond to the user that the task has been sent and that their request has been processed. Due to the ebbs and flows of traffic, we will not need all our workers and HTTP servers when the traffic is low. However, we will need to create and connect extra HTTP servers and workers when the traffic increases, as seen in the <span class="No-Break">following diagram:</span></p>
			<div>
				<div id="_idContainer195" class="IMG---Figure">
					<img src="image/Figure_18.1_B18722.jpg" alt="Figure 18.1 – Our approach to processing lengthy tasks"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 18.1 – Our approach to processing lengthy tasks</p>
			<p>Considering the<a id="_idIndexMarker1444"/> preceding diagram, we will need the <span class="No-Break">following infrastructure:</span></p>
			<ul>
				<li><strong class="bold">Redis database</strong>: To store the tasks in <span class="No-Break">the queue</span></li>
				<li><strong class="bold">HTTP server</strong>: To send tasks to the queue to <span class="No-Break">be processed</span></li>
				<li><strong class="bold">Worker</strong>: To pull/pop/poll/process tasks from <span class="No-Break">the queue</span></li>
			</ul>
			<p>We could build <a id="_idIndexMarker1445"/>individual applications for the worker and the HTTP server. However, this would increase complexity for no gain. With two separate applications, we would have to maintain two separate Docker images. We would also duplicate a lot of code as the tasks that the HTTP server sends to the Redis queue must be the same tasks that the worker picks up and processes. There could end up being a mismatch between the fields passed from the HTTP server to the worker for a particular task. We can prevent this mismatch by having task structs that have a range of fields for the input and a run function to execute the task with those fields. Serialization traits for these task structs can enable us to pass the fields over the queue and receive them. </p>
			<p>When it comes to building an HTTP server and worker, we can build the server so that environment variables are checked once the program is started. If the environment variable states that the application is a worker, the application can then spin up an actor that polls the queue. If the environment variable states that the application is an HTTP server, the application can then run an HTTP server and listen for requests. </p>
			<p>For our task queue project, we have the <span class="No-Break">following outline:</span></p>
			<pre class="source-code">
├── Cargo.toml
├── docker-compose.yml
└── src
    ├── main.rs
    └── tasks
        ├── add.rs
        ├── mod.rs
        ├── multiply.rs
        └── subtract.rs</pre>
			<p>We will define the<a id="_idIndexMarker1446"/> server entry point in the <strong class="source-inline">src/main.rs</strong> file. We will then define our task structs in the <strong class="source-inline">src/tasks/</strong> directory. In terms of our dependencies in our <strong class="source-inline">Cargo.toml</strong> file, we have <span class="No-Break">the following:</span></p>
			<pre class="source-code">
[dependencies]
bincode = "1.0"
bytes = "1.2.1"
redis = "0.22.1"
serde_json = "1.0.86"
tokio = { version = "1", features = ["full"] }
hyper = { version = "0.14.20", features = ["full"] }
serde = { version = "1.0.136", features = ["derive"] }</pre>
			<p>None of these dependencies should be new to you apart from the <strong class="source-inline">bytes</strong> and <strong class="source-inline">bincode</strong> crates. We will use <strong class="source-inline">bytes</strong> to convert our struct into HTTP responses and <strong class="source-inline">bincode</strong> to serialize structs into binary to be stored <span class="No-Break">in Redis.</span></p>
			<p>With the approach that we have just laid out in this section, we will be able to build a simple task-processing queue where we can assure that the task definitions between the servers and workers are always in sync. With our approach defined, we can move on to the first <a id="_idIndexMarker1447"/>part of a task’s journey, which is the HTTP server. </p>
			<h1 id="_idParaDest-338"><a id="_idTextAnchor339"/>Building the HTTP server</h1>
			<p>For our HTTP<a id="_idIndexMarker1448"/> server, we need to carry out the <span class="No-Break">following steps:</span></p>
			<ol>
				<li>Define a struct that deserializes the HTTP request body. </li>
				<li>Define a function that handles the incoming request. </li>
				<li>Define pathways for the program to run based on <span class="No-Break">environment variables.</span></li>
				<li>Run a server that listens for incoming requests. </li>
			</ol>
			<p>We are not going to section off individual sections for each step as we have covered all of these steps/processes in the previous chapter. Before we carry out all the steps, we must import the following into the <span class="No-Break"><strong class="source-inline">src/main.rs</strong></span><span class="No-Break"> file:</span></p>
			<pre class="source-code">
use hyper::{Body, Request, Response, Server};
use hyper::body;
use hyper::service::{make_service_fn, service_fn};
use std::net::SocketAddr;
use std::env;
use serde::{Serialize, Deserialize};
use serde_json;
use bytes::{BufMut, BytesMut};</pre>
			<p>You should be familiar with all these imports apart from the <strong class="source-inline">bytes</strong> import, which we will cover when defining the HTTP handle function. First, we will define a trivial struct to serialize the incoming HTTP request bodies with the <span class="No-Break">following code:</span></p>
			<pre class="source-code">
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct IncomingBody {
    pub one: String,
    pub two: i32
}</pre>
			<p>This is the same approach to our Actix Web applications. We will be able to annotate our task structs with the <strong class="source-inline">Serialize</strong> and <strong class="source-inline">Deserialize</strong> traits. </p>
			<p>Now that we have defined the <strong class="source-inline">IncomingBody</strong> struct, we can define our <strong class="source-inline">handle</strong> function with the <a id="_idIndexMarker1449"/><span class="No-Break">following code:</span></p>
			<pre class="source-code">
async fn handle(req: Request&lt;Body&gt;) -&gt; 
    Result&lt;Response&lt;Body&gt;, &amp;'static str&gt; {
    let bytes = body::to_bytes(req.into_body()).await
                                               .unwrap();
    let response_body: IncomingBody = 
        serde_json::from_slice(&amp;bytes).unwrap();
    let mut buf = BytesMut::new().writer();
    serde_json::to_writer(&amp;mut buf, 
                          &amp;response_body).unwrap();
    Ok(Response::new(Body::from(buf.into_inner().freeze())))
}</pre>
			<p>It must be noted that we are calling the <strong class="source-inline">freeze</strong> function when returning our body. This <strong class="source-inline">freeze</strong> function converts the mutable bytes to immutable, preventing any buffer modifications. Here, we can see that we are accepting a generic body with the request. We can then use <strong class="source-inline">serde</strong> to serialize the body and the <strong class="source-inline">BytesMut</strong> struct (which is essentially just a contiguous slice of memory) to return the body to the user, essentially creating an echo server. </p>
			<p>We can now define the <strong class="source-inline">main</strong> function, which is the entry point with the <span class="No-Break">following code:</span></p>
			<pre class="source-code">
#[tokio::main]
async fn main() {
    let app_type = env::var("APP_TYPE").unwrap();
    match app_type.as_str() {
        "server" =&gt; {
            . . .
        },
        "worker" =&gt; {
            println!("worker not defined yet");
        }
        _ =&gt; {
            panic!("{} app type not supported", app_type);
        }
    }
}</pre>
			<p>Here we can see that the <a id="_idIndexMarker1450"/>environment variable <strong class="source-inline">"APP_TYPE"</strong> is extracted. Depending on what the app type is, we have different blocks of code being executed. For now, we will just print out a statement that the worker is not defined if the app type is a <strong class="source-inline">"worker"</strong>. We also state that the program is going to panic if the app type is neither a <strong class="source-inline">"server"</strong> nor a <strong class="source-inline">"worker"</strong> type. </p>
			<p>In our server block, we defined <strong class="source-inline">addr</strong> and <strong class="source-inline">server</strong> with the <span class="No-Break">following code:</span></p>
			<pre class="source-code">
let addr = SocketAddr::from(([0, 0, 0, 0], 3000));
let server = Server::bind(&amp;addr).serve(make_service_fn( |_conn| {
    async {
        Ok::&lt;_, hyper::Error&gt;(service_fn( move |req| {
            async {handle(req).await}
        }))
    }
}));
if let Err(e) = server.await {
    eprintln!("server error: {}", e);
}</pre>
			<p>This is very similar to our server code in the previous chapter. </p>
			<p>We then run the server with the <span class="No-Break">following command:</span></p>
			<pre class="console">
APP_TYPE=server cargo run</pre>
			<p>We can then <a id="_idIndexMarker1451"/>send the <span class="No-Break">following request:</span></p>
			<div>
				<div id="_idContainer196" class="IMG---Figure">
					<img src="image/Figure_18.2_B18722.jpg" alt="Figure 18.2 – A request to our HTTP server"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 18.2 – A request to our HTTP server</p>
			<p>Here, we can see that our server works and echoes the same body that was sent to the server. We can now<a id="_idIndexMarker1452"/> move on to building our worker application. </p>
			<h1 id="_idParaDest-339"><a id="_idTextAnchor340"/>Building the polling worker</h1>
			<p>Our worker is <a id="_idIndexMarker1453"/>essentially looping and polling a queue in Redis. If there is a message in the queue, the worker will then execute the task that has been extracted from the queue. For building the polling worker section, the worker will be creating a struct, inserting the struct into the Redis queue, and then extracting that inserted struct from the queue to print out. This is not our desired behavior but this does mean that we can test to see how our queue insertion works quickly. By the end of the chapter, our HTTP servers will be inserting tasks and our workers will be <span class="No-Break">consuming tasks.</span></p>
			<p>We do not want the worker to be polling the Redis queue constantly without any rest. To reduce the polling to a reasonable rate, we will need to make the worker sleep during each loop. Therefore, we must import the following in the <strong class="source-inline">src/main.rs</strong> file to enable us to get our <span class="No-Break">worker sleeping:</span></p>
			<pre class="source-code">
use std::{thread, time};</pre>
			<p>We can now move to the section where the worker is run to define our worker code in the following section in the <span class="No-Break"><strong class="source-inline">main</strong></span><span class="No-Break"> function:</span></p>
			<pre class="source-code">
match app_type.as_str() {
    "server" =&gt; {
        . . .
    },
    "worker" =&gt; {
      // worker code is going to be inserted here
        . . .
    }
    _ =&gt; {
        panic!("{} app type not supported", app_type);
    }
}</pre>
			<p>Our worker code takes the following <span class="No-Break">general outline:</span></p>
			<pre class="source-code">
let client = 
    redis::Client::open("redis://127.0.0.1/").unwrap();
loop {
    . . .
}</pre>
			<p>Here, we can see that we define the Redis client and then run the worker on an infinite loop. In this loop, we will be establishing a connection with Redis, polling the queue in Redis, and then removing the connection. We can establish and remove the connection in the loop because the task will take a long time. There is no point in holding onto a Redis connection throughout the duration of a task. </p>
			<p>Unfortunately, at the point of writing this book, the Rust Redis crate does not have a simple implementation of queues. However, this should not hold us back. If we know the raw commands<a id="_idIndexMarker1454"/> needed to get Redis to implement our queue, we can implement our own queues. Redis performs like a SQL database. If you know the commands, you can implement your own logic like in SQL. </p>
			<p>Inside our infinite loop, we are going to create a generic struct that has the <strong class="source-inline">Serialize</strong> and <strong class="source-inline">Deserialize</strong> traits implemented, then serialize the struct into binary with the <span class="No-Break">following code:</span></p>
			<pre class="source-code">
let body = IncomingBody{one: "one".to_owned(), two: 2};
let bytes = bincode::serialize(&amp;body).unwrap();</pre>
			<p>Our struct is now a vector of bytes. We will then establish a connection with Redis and push <strong class="source-inline">"some_queue"</strong> with the <strong class="source-inline">"LPUSH"</strong> command to the queue, which inserts the value at the head of the queue, with the <span class="No-Break">following code:</span></p>
			<pre class="source-code">
let outcome: Option&lt;Vec&lt;u8&gt;&gt;;
{
    let mut con = client.get_connection().unwrap();
    let _ : () = redis::cmd("LPUSH").arg("some_queue")
                                    .arg(bytes.clone())
                                    .query(&amp;mut con)
                                    .unwrap();
    // pop our task from the queue
    outcome = redis::cmd("LPOP").arg("some_queue")
                                .query(&amp;mut con)
                                .unwrap();
}</pre>
			<p>We have <strong class="source-inline">Option&lt;Vec&lt;u8&gt;&gt;</strong> because there may not be anything in the queue. If there is nothing in the queue, then the outcome will be none. Right now, we will never get a none because we are directly inserting tasks into the queue before we extract a task from the queue. However, in periods of low traffic, our workers will be polling queues that could <a id="_idIndexMarker1455"/>be empty for a while. </p>
			<p>Now that we have our outcome, we can process it with the following <span class="No-Break"><strong class="source-inline">match</strong></span><span class="No-Break"> statement:</span></p>
			<pre class="source-code">
match outcome {
    Some(data) =&gt; {
        . . .
    },
    None =&gt; {
        . . .
    }
}</pre>
			<p>If we have some data, we will merely deserialize the binary data and print out the struct with the <span class="No-Break">following code:</span></p>
			<pre class="source-code">
let deserialized_struct: IncomingBody = 
    bincode::deserialize(&amp;data).unwrap();
println!("{:?}", deserialized_struct);</pre>
			<p>If there is nothing in the queue, the <strong class="source-inline">outcome</strong> is <strong class="source-inline">None</strong>, and we can just sleep for five seconds before running the loop again with the <span class="No-Break">following code:</span></p>
			<pre class="source-code">
let five_seconds = time::Duration::from_secs(5);
tokio::time::sleep(five_seconds).await;</pre>
			<p>With this, our worker is ready to be tested. You can always do more when building an async program like this. However, to avoid bloating this chapter, we will stick with our basic application. If you want to further your understanding of Redis, you could investigate building a pub/sub system where one worker continuously polls the queue and the other workers are switched off with an actor listening for a message on a channel. When a main worker gets a new task, the main worker can publish a message to a channel, waking up other workers. If you really want to push yourself, you could investigate Kubernetes controllers and have a main worker spin up and destroy worker pods, depending on <a id="_idIndexMarker1456"/>the traffic. However, these projects will be beyond the scope of this book. </p>
			<p>To get our application working within the scope of one chapter, we must move on to getting our application running with Redis. </p>
			<h1 id="_idParaDest-340"><a id="_idTextAnchor341"/>Getting our application running with Redis</h1>
			<p>Running our <a id="_idIndexMarker1457"/>application with Redis locally will require us to<a id="_idIndexMarker1458"/> use Redis with Docker, export the <strong class="source-inline">APP_TYPE</strong> environment variable as <strong class="source-inline">"worker"</strong>, and then run our application with Cargo. For our Redis, our <strong class="source-inline">docker-compose.yml</strong> file takes the <span class="No-Break">following form:</span></p>
			<pre class="source-code">
version: "3.7"
services:
    redis:
      container_name: 'queue-redis'
      image: 'redis'
      ports:
        - '6379:6379'</pre>
			<p>We can then export our <strong class="source-inline">APP_TYPE</strong> environment variable with the <span class="No-Break">following command:</span></p>
			<pre class="console">
export APP_TYPE=worker</pre>
			<p>We can then run our application with the <span class="No-Break">following command:</span></p>
			<pre class="console">
cargo run</pre>
			<p>When we run our application, we will get the <span class="No-Break">following printout:</span></p>
			<pre class="console">
IncomingBody { one: "one", two: 2 }
IncomingBody { one: "one", two: 2 }
IncomingBody { one: "one", two: 2 }
IncomingBody { one: "one", two: 2 }
. . .</pre>
			<p>The printout of the <strong class="source-inline">IncomingBody</strong> struct will be infinite because we are running an infinite loop. However, what<a id="_idIndexMarker1459"/> this shows is that the following<a id="_idIndexMarker1460"/> mechanism is running <span class="No-Break">and working:</span></p>
			<div>
				<div id="_idContainer197" class="IMG---Figure">
					<img src="image/Figure_18.3_B18722.jpg" alt="Figure 18.3 – Our process of how we insert and extract data from a Redis queue"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 18.3 – Our process of how we insert and extract data from a Redis queue</p>
			<p>Although our worker is working with a Redis queue, it is merely printing out the struct that was put into the Redis queue. In the next section, we build functionality into the structs that we <a id="_idIndexMarker1461"/>are<a id="_idIndexMarker1462"/> inserting into the Redis queue so our worker can perform <span class="No-Break">the tasks.</span></p>
			<h1 id="_idParaDest-341"><a id="_idTextAnchor342"/>Defining tasks for workers</h1>
			<p>When it comes to<a id="_idIndexMarker1463"/> running our tasks, we need fields so we can pass them in as inputs to the task being run. Our tasks also need a <strong class="source-inline">run</strong> function so we can choose when to run tasks as running a task takes a long time. We can define a basic addition task in our <strong class="source-inline">src/tasks/add.rs</strong> file with the <span class="No-Break">following code:</span></p>
			<pre class="source-code">
use std::{thread, time};
use serde::{Serialize, Deserialize};
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct AddTask {
    pub one: i32,
    pub two: i32
}
impl AddTask {
    pub fn run(self) -&gt; i32 {
        let duration = time::Duration::from_secs(20);
        thread::sleep(duration);
        return self.one + self.two
    }
}</pre>
			<p>None of this code should be a shock. We will implement the <strong class="source-inline">Serialize</strong> and <strong class="source-inline">Deserialize</strong> traits so we can insert the task into the Redis Queue. We can then use a <strong class="source-inline">sleep</strong> function to simulate a long task. Finally, we merely add the two numbers together. For our task in the <strong class="source-inline">src/tasks/multiply.rs</strong> file, the <strong class="source-inline">run</strong> function takes the <span class="No-Break">following form:</span></p>
			<pre class="source-code">
impl MultiplyTask {
    pub fn run(self) -&gt; i32 {
        let duration = time::Duration::from_secs(20);
        thread::sleep(duration);
        return self.one * self.two
    }
}</pre>
			<p>It should not be a<a id="_idIndexMarker1464"/> surprise to find out that the <strong class="source-inline">run</strong> function in the <strong class="source-inline">src/tasks/subtract.rs</strong> file has the <span class="No-Break">following structure:</span></p>
			<pre class="source-code">
impl SubtractTask {
    pub fn run(self) -&gt; i32 {
        let duration = time::Duration::from_secs(20);
        thread::sleep(duration);
        return self.one - self.two
    }
}</pre>
			<p>Now, we want to implement one of our tasks to see whether we can pull a task struct out of a Redis queue and run it. We make the tasks accessible from the module with the following code in the <span class="No-Break"><strong class="source-inline">src/tasks/mod.rs</strong></span><span class="No-Break"> file:</span></p>
			<pre class="source-code">
pub mod add;
pub mod multiply;
pub mod subtract;</pre>
			<p>In our <strong class="source-inline">src/main.rs</strong> file, we initially import the tasks with the <span class="No-Break">following code:</span></p>
			<pre class="source-code">
mod tasks;
use tasks::{
    add::AddTask, 
    subtract::SubtractTask, 
    multiply::MultiplyTask
};</pre>
			<p>We can now implement one of our tasks in our worker block of code. At the start of this worker block of code, we will swap the <strong class="source-inline">IncomingBody</strong> struct with the <strong class="source-inline">AddTask</strong> struct using the <a id="_idIndexMarker1465"/><span class="No-Break">following code:</span></p>
			<pre class="source-code">
let body = AddTask{one: 1, two: 2};</pre>
			<p>Nothing else needs to change apart from what we do with the <strong class="source-inline">Some</strong> part of the <strong class="source-inline">outcome</strong> <strong class="source-inline">match</strong> statement, which now takes the <span class="No-Break">following form:</span></p>
			<pre class="source-code">
let deserialized_struct: AddTask = 
    bincode::deserialize(&amp;data).unwrap();
println!("{:?}", deserialized_struct.run());</pre>
			<p>Here, we can see that we deserialized the binary data into an <strong class="source-inline">AddTask</strong> struct, ran the <strong class="source-inline">run</strong> function, and then printed out the outcome. In a real application, we would be inserting the result to a database or sending the result to another server using HTTP. However, in this chapter, we are merely interested in seeing how queuing tasks are executed. We have covered database inserts and HTTP requests many times in the book. </p>
			<p>If we run our worker application now, we will get a 15-second delay and then the <span class="No-Break">following printout:</span></p>
			<pre class="console">
3</pre>
			<p>If we wait another 15 seconds, we will get another printout that is the same. This shows that our tasks are being pulled from the Redis queue, deserialized, and then ran in the exact same manner that we expect them to as one added to two is three. However, there is a problem here. We can only send and receive the <strong class="source-inline">AddTask</strong> struct. This is not useful as we have two other tasks and we would like to support all of them. Therefore, we must move on <a id="_idIndexMarker1466"/>to defining messages that can support a range of tasks. </p>
			<h1 id="_idParaDest-342"><a id="_idTextAnchor343"/>Defining messages for the Redis queue</h1>
			<p>To support multiple<a id="_idIndexMarker1467"/> tasks, we must do a two-step approach to packaging our tasks to be inserted into the Redis queue. This means that we will serialize the task struct into <strong class="source-inline">Vec&lt;u8&gt;</strong>, then add this vector of bytes to another struct that has a field denoting what type of task is in the message. We can define this process by first importing the <strong class="source-inline">Serialize</strong> and <strong class="source-inline">Deserialize</strong> traits in the <strong class="source-inline">src/tasks/mod.rs</strong> file with the <span class="No-Break">following code:</span></p>
			<pre class="source-code">
use serde::{Serialize, Deserialize};</pre>
			<p>We can then define the <strong class="source-inline">enum</strong> task type and message struct with the <span class="No-Break">following code:</span></p>
			<pre class="source-code">
#[derive(Debug, Clone, Serialize, Deserialize)]
use add::AddTask;
use multiply::MultiplyTask;
use subtract::SubtractTask;
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum TaskType {
    ADD(AddTask),
    MULTIPLY(MultiplyTask),
    SUBTRACT(SubtractTask)
}
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TaskMessage {
    pub task: TaskType
}</pre>
			<p>Our message struct is now ready to package a range of tasks to be inserted into the Redis queue. In our <strong class="source-inline">src/main.rs</strong> file, we can import the <strong class="source-inline">TaskType</strong> and <strong class="source-inline">TaskMessage</strong> structs with the <span class="No-Break">following code:</span></p>
			<pre class="source-code">
mod tasks;
use tasks::{
    add::AddTask, 
    TaskType, 
    TaskMessage
};</pre>
			<p>We are now ready to <a id="_idIndexMarker1468"/>rewrite our infinite loop in the worker block of code. We initially create <strong class="source-inline">AddTask</strong>, serialize <strong class="source-inline">AddTask</strong>, and then package this serialized task into the <strong class="source-inline">TaskMessage</strong> with the <span class="No-Break">following code:</span></p>
			<pre class="source-code">
let body = AddTask{one: 1, two: 2};
let message = TaskMessage{task: TaskType::ADD(body)};
let serialized_message = bincode::serialize(&amp;message).unwrap();</pre>
			<p>We will then establish a Redis connection, then push our serialized message to the Redis queue with the <span class="No-Break">following code:</span></p>
			<pre class="source-code">
let mut con = client.get_connection().unwrap();
let _ : () = redis::cmd("LPUSH").arg("some_queue")
                                .arg(serialized_message
                                .clone())
                                .query(&amp;mut con).unwrap();</pre>
			<p>We will then pop the task from the Redis queue and drop the connection with the <span class="No-Break">following code:</span></p>
			<pre class="source-code">
let outcome: Option&lt;Vec&lt;u8&gt;&gt; = 
    redis::cmd("RPOP").arg("some_queue").query(&amp;mut con)
    .unwrap();
std::mem::drop(con);</pre>
			<p>We are now moving our <strong class="source-inline">TaskMessage</strong> struct in and out of the Redis queue. We must process <strong class="source-inline">TaskMessage</strong> if there is one. Inside the <strong class="source-inline">match</strong> block of the <strong class="source-inline">Some</strong> statement of <strong class="source-inline">outcome</strong>, we must deserialize the bytes we got from the Redis queue, then match the task type with the <a id="_idIndexMarker1469"/><span class="No-Break">following code:</span></p>
			<pre class="source-code">
let deserialized_message: TaskMessage = 
    bincode::deserialize(&amp;data).unwrap();
match deserialized_message.task {
    TaskType::ADD(task) =&gt; {
        println!("{:?}", task.run());
    },
    TaskType::MULTIPLY(task) =&gt; {
        println!("{:?}", task.run());
    },
    TaskType::SUBTRACT(task) =&gt; {
        println!("{:?}", task.run());
    }
}</pre>
			<p>This now enables us to handle individual tasks that we have pulled from the Redis queue and ran. </p>
			<p>Our worker now supports all three of our tasks! However, we are currently just creating messages and then directly consuming these messages in the worker. We need to enable the HTTP server to accept a range of different requests to send a range of different tasks to the Redis queue to be consumed by the workers. </p>
			<h1 id="_idParaDest-343"><a id="_idTextAnchor344"/>Integrating routing in the HTTP server</h1>
			<p>We are now at the <a id="_idIndexMarker1470"/>stage of getting our HTTP server to accept incoming requests to create a range of tasks depending on what the URI is. To get our HTTP to support multiple tasks, we essentially must rewrite the <strong class="source-inline">handle</strong> function in the <strong class="source-inline">src/main.rs</strong> file. Before we rewrite the <strong class="source-inline">main</strong>  function, we must import what we need with the <span class="No-Break">following code:</span></p>
			<pre class="source-code">
use hyper::body;
use hyper::http::StatusCode;</pre>
			<p>We are importing these things because we are going to return a <strong class="source-inline">NOT_FOUND</strong> status code if the wrong URI is passed. We also going to be extracting data from the body of the incoming request. Before we refactor our <strong class="source-inline">handle</strong> function, we need to change our <strong class="source-inline">IncomingBody</strong> struct to take in two integers taking the <span class="No-Break">following form:</span></p>
			<pre class="source-code">
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct IncomingBody {
    pub one: i32,
    pub two: i32
}</pre>
			<p>Inside our <strong class="source-inline">handle</strong> function, we can define our Redis client, clean our URI by removing trailing slashes, and extract the data from the incoming request with the <span class="No-Break">following code:</span></p>
			<pre class="source-code">
let client = 
    redis::Client::open("redis://127.0.0.1/").unwrap();
let task_type = req.uri().to_string().replace("/", "")"");
let body_bytes = 
    body::to_bytes(req.into_body()).await.unwrap();
let body: IncomingBody = 
    _json::from_slice(&amp;body_bytes).unwrap();</pre>
			<p>We can see that we can extract the task type from the URI. Right now, we will support <strong class="source-inline">add</strong>, <strong class="source-inline">subtract</strong>, and <strong class="source-inline">multiply</strong>. We now have everything we need from the incoming request; we can construct the appropriate task based on the URI with the <span class="No-Break">following code:</span></p>
			<pre class="source-code">
let message_type: TaskType;
match task_type.as_str() {
    "add" =&gt; {
        let body = AddTask{one: body.one, 
                           two: body.two};
        message_type = TaskType::ADD(body);
    },
    "multiply" =&gt; {
        let body = MultiplyTask{one: body.one, 
                                two: body.two};
        message_type = TaskType::MULTIPLY(body);
    },
    "subtract" =&gt; {
        let body = SubtractTask{one: body.one, 
                                two: body.two};
        message_type = TaskType::SUBTRACT(body);
    },
    _ =&gt; {
        . . .
    }
}</pre>
			<p>We can see that no <a id="_idIndexMarker1471"/>matter what the task is, we need the task struct to be packed into our <strong class="source-inline">TaskType</strong> enum, which can be serialized into a binary vector for our message to be sent to the Redis queue. For the last part of the <strong class="source-inline">match</strong> statement, which catches all task requests that do not match with “add”, “multiply”, or “subtract”,  we merely return a <strong class="source-inline">NOT_FOUND</strong> HTTP response with the <span class="No-Break">following code:</span></p>
			<pre class="source-code">
let response = 
    Response::builder().status(StatusCode::NOT_FOUND)
    .body(Body::from("task not found"));
return Ok(response.unwrap())</pre>
			<p>We now have everything we need to create a generic task message that can be inserted into a Redis queue. With this information, we can create our <strong class="source-inline">TaskMessage</strong> struct and serialize <strong class="source-inline">TaskMessage</strong> after the <strong class="source-inline">match</strong> statement that we have just covered with the <span class="No-Break">following code:</span></p>
			<pre class="source-code">
let message = TaskMessage{task_type: message_type, 
    task: bytes};
let serialized_message = 
    bincode::serialize(&amp;message).unwrap();</pre>
			<p>We will then make a<a id="_idIndexMarker1472"/> Redis connection, push the serialized message to a Redis queue, and then drop the Redis connection with the <span class="No-Break">following code:</span></p>
			<pre class="source-code">
let mut con = client.get_connection().unwrap();
let _ : () = redis::cmd("LPUSH").arg("some_queue")
                                .arg(serialized_message
                                .clone())
                                .query(&amp;mut con).unwrap();</pre>
			<p>Finally, we return an <strong class="source-inline">Ok</strong> HTTP response stating that the task has been sent with the <span class="No-Break">following code:</span></p>
			<pre class="source-code">
Ok(Response::new(Body::from("task sent")))</pre>
			<p>Our <strong class="source-inline">handle</strong> function is now complete. All we need to do now is remove the code that inserts an <strong class="source-inline">AddTask</strong> struct to the Redis queue in the worker code block. We are removing the task insertion code from the worker code block because we no longer need the worker to insert tasks. The removal of the insertion code takes the <span class="No-Break">following form:</span></p>
			<pre class="source-code">
let client = 
    redis::Client::open("redis://127.0.0.1/").unwrap();
loop {
    let outcome: Option&lt;Vec&lt;u8&gt;&gt; = {
        let mut con = client.get_connection()
                            .unwrap();
        redis::cmd("RPOP").arg("some_queue")
                          .query(&amp;mut con)
                          .unwrap()
    };
    match outcome {
        . . .
    }
}</pre>
			<p>We are now ready <a id="_idIndexMarker1473"/>to package these workers and HTTP servers in Docker so we can run our application with as many workers as we want. </p>
			<h1 id="_idParaDest-344"><a id="_idTextAnchor345"/>Running it all in Docker</h1>
			<p>We are now at the<a id="_idIndexMarker1474"/> stage where we can run our entire application in Docker. This enables us to have multiple workers pulling from the same Redis queue. First, we need to define the <strong class="source-inline">Dockerfile</strong> for the build of our worker/server image. We are going to have a distroless build for the Docker build with the <span class="No-Break">following code:</span></p>
			<pre class="source-code">
FROM rust:1.62.1 as build
ENV PKG_CONFIG_ALLOW_CROSS=1
WORKDIR /app
COPY . .
cargo build --release 
FROM gcr.io/distroless/cc-debian10
COPY --from=build /app/target/release/task_queue 
/usr/local/bin/task_queue
EXPOSE 3000
ENTRYPOINT ["task_queue"]</pre>
			<p>This distroless build should not be a surprise at this point in the book. We are merely compiling the<a id="_idIndexMarker1475"/> application and then copying the static binary into the distroless image. Before we run the build in any way, we must ensure that we do not copy over excessive files from the <strong class="source-inline">target</strong> directory into our Docker build with the following code in the <strong class="source-inline">.</strong><span class="No-Break"><strong class="source-inline">dockerignore</strong></span><span class="No-Break"> file:</span></p>
			<pre class="source-code">
./target
.github</pre>
			<p>Our build is now ready. We can define the <strong class="source-inline">docker-compose.yml</strong> with the <span class="No-Break">following outline:</span></p>
			<pre class="source-code">
version: "3.7"
services:
    server_1:
        . . .
    worker_1:
        . . .
    worker_2:
        . . .
    worker_3:
        . . .
    redis:
      container_name: 'queue-redis'
      image: 'redis'
      ports:
        - '6379:6379'</pre>
			<p>Here, we can see that<a id="_idIndexMarker1476"/> we have three workers and one server. Our server takes the <span class="No-Break">following form:</span></p>
			<pre class="source-code">
server_1:
    container_name: server_1
    image: server_1
    build: 
      context: .
    environment:
      - 'APP_TYPE=server'
      - 'REDIS_URL=redis://redis:6379'
    depends_on:
        redis:
          condition: service_started
    restart: on-failure
    ports:
    - "3000:3000"
    expose:
      - 3000</pre>
			<p>Here, we can see that we can expose the port, point out that the build context is in the current directory, and that our container should start once Redis has started. </p>
			<p>A standard worker takes the <span class="No-Break">following form:</span></p>
			<pre class="source-code">
worker_1:
    container_name: worker_1
    image: worker_1
    build: 
      context: .
    environment:
      - 'APP_TYPE=worker'
      - 'REDIS_URL=redis://redis:'
    depends_on:
        redis:
          condition: service_started
    restart: on-failure</pre>
			<p>We can imagine that <a id="_idIndexMarker1477"/>other workers have the same structure as the preceding worker, which is true. If we want to add another worker, we can have the exact spec as <strong class="source-inline">worker_1</strong> except we just increase the number attached to the image and container name resulting in the new worker being called  <strong class="source-inline">worker_2</strong>. You may have noticed that we have added <strong class="source-inline">REDIS_URL</strong> to the environment variables. This is because the workers and servers are having to access the Redis database outside of their container. Passing localhost into the Redis client will result in a failure to connect to Redis as a result. Therefore, we must get rid of all references to the Redis client and replace those references with the <span class="No-Break">following code:</span></p>
			<pre class="source-code">
let client = 
    redis::Client::open(env::var("REDIS_URL").unwrap())
    .unwrap();</pre>
			<p>If we spin up <strong class="source-inline">docker_compose</strong> now and send a range of different HTTP requests to the server, we get the <span class="No-Break">following printout:</span></p>
			<pre class="console">
. . .
queue-redis  | 1:M 30 Oct 2022 18:42:52.334 * 
RDB memory usage when created 0.85 Mb
queue-redis  | 1:M 30 Oct 2022 18:42:52.334 * 
Done loading RDB, keys loaded: 0, keys expired: 0.
queue-redis  | 1:M 30 Oct 2022 18:42:52.334 * 
DB loaded from disk: 0.002 seconds
queue-redis  | 1:M 30 Oct 2022 18:42:52.334 * 
Ready to accept connections
worker_1     | empty queue
worker_3     | empty queue
worker_1     | empty queue
worker_3     | empty queue
worker_2     | multiply: 9
worker_3     | multiply: 25
worker_1     | multiply: 8
worker_3     | empty queue
worker_3     | empty queue
worker_2     | multiply: 4
worker_2     | empty queue
. . .</pre>
			<p>It is a big printout, but<a id="_idIndexMarker1478"/> we can see that Redis spins up and there are multiple workers polling the Redis queue. We can also see that multiple workers are processing multiple tasks at the same time. Examples of how to make the request to the server are <span class="No-Break">depicted here:</span></p>
			<div>
				<div id="_idContainer198" class="IMG---Figure">
					<img src="image/Figure_18.4_B18722.jpg" alt="Figure 18.4 – An example of sending a request to our server for multiply"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 18.4 – An example of sending a request to our server for multiply</p>
			<div>
				<div id="_idContainer199" class="IMG---Figure">
					<img src="image/Figure_18.5_B18722.jpg" alt="Figure 18.5 – An example of sending a request to our server for subtract"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 18.5 – An example of sending a request to our server for subtract</p>
			<div>
				<div id="_idContainer200" class="IMG---Figure">
					<img src="image/Figure_18.6_B18722.jpg" alt="Figure 18.6 – An example of sending a request to our server for add"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 18.6 – An example of sending a request to our server for add</p>
			<p>Here we have it! We have a server that accepts requests. Depending on the URI, our server constructs a task, packages it into a message, and then sends it to a Redis queue. We then have<a id="_idIndexMarker1479"/> multiple workers polling the Redis queue to process the <span class="No-Break">long tasks.</span></p>
			<h1 id="_idParaDest-345"><a id="_idTextAnchor346"/>Summary</h1>
			<p>In this chapter, we built an application that could be run as either a worker or a server. We then built structs that could be serialized and inserted into a Redis queue. This allowed our workers to consume these tasks and then process them in their own time. You now have the power to build systems that process long tasks without having to hold up the HTTP server. The mechanism of serializing Rust structs and inserting them into Redis does not just stop at processing large tasks. We could serialize Rust structs and send them over pub/sub channels in Redis to other Rust servers, essentially creating an actor model approach on a bigger scale. With our distroless images, these Rust servers are only roughly the size of 50 MB, making this concept scalable. We also explored applying raw commands to Redis, which gives you the freedom and confidence to fully embrace what Redis has to offer. A high-level list of all the commands you can do to Redis is given in the <em class="italic">Further reading</em> section. You will be shocked at what you can do, and I hope you get as excited as me thinking of all the solutions you can achieve with Redis when looking through the available commands. </p>
			<p>We have come to the end of the book. I am grateful that you have gotten this far, and I am always happy when readers reach out. Rust is truly a revolutionary programming language. With Rust, we have been able to build and deploy fast tiny servers. We have explored async programming and the actor model. We have built deployment pipelines. Your journey is not over; there is always more to learn. However, I hope that I have exposed you to fundamental concepts in such a way that you can go forward and read further documentation, practice, and someday push the boundaries of web programming. </p>
			<h1 id="_idParaDest-346"><a id="_idTextAnchor347"/>Further reading </h1>
			<ul>
				<li>The Redis documentation on pushing to <span class="No-Break">queues: </span><a href="https://redis.io/commands/lpush/"><span class="No-Break">https://redis.io/commands/lpush/</span></a></li>
				<li>A concise list of raw Redis <span class="No-Break">commands: </span><a href="https://www.tutorialspoint.com/redis/redis_lists.htm"><span class="No-Break">https://www.tutorialspoint.com/redis/redis_lists.htm</span></a></li>
				<li>The Redis Rust crate <span class="No-Break">documentation: </span><a href="https://docs.rs/redis/latest/redis/"><span class="No-Break">https://docs.rs/redis/latest/redis/</span></a></li>
			</ul>
		</div>
	</body></html>