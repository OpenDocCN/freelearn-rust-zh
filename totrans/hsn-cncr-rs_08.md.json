["```rs\n[package]\nname = \"overwhelmed_tcp_server\"\nversion = \"0.1.0\"\nauthors = [\"Brian L. Troutwine <brian@troutwine.us>\"]\n\n[dependencies]\nclap = \"2.31\"\nslog = \"2.2\"\nslog-term = \"2.4\"\nslog-async = \"2.3\"\n\n[[bin]]\nname = \"server\"\n\n[[bin]]\nname = \"client\"\n```", "```rs\n#[macro_use]\nextern crate slog;\nextern crate clap;\nextern crate slog_async;\nextern crate slog_term;\n\nuse clap::{App, Arg};\nuse slog::Drain;\nuse std::io::{self, BufRead, BufReader, BufWriter, Write};\nuse std::net::{TcpListener, TcpStream};\n```", "```rs\nuse std::sync::atomic::{AtomicUsize, Ordering};\nuse std::thread;\n\nstatic TOTAL_STREAMS: AtomicUsize = AtomicUsize::new(0);\n```", "```rs\nfn main() {\n    let decorator = slog_term::TermDecorator::new().build();\n    let drain = slog_term::CompactFormat::new(decorator).build().fuse();\n    let drain = slog_async::Async::new(drain).build().fuse();\n    let root = slog::Logger::root(drain, o!());\n```", "```rs\n    let matches = App::new(\"server\")\n        .arg(\n            Arg::with_name(\"host\")\n                .long(\"host\")\n                .value_name(\"HOST\")\n                .help(\"Sets which hostname to listen on\")\n                .takes_value(true),\n        )\n        .arg(\n            Arg::with_name(\"port\")\n                .long(\"port\")\n                .value_name(\"PORT\")\n                .help(\"Sets which port to listen on\")\n                .takes_value(true),\n        )\n        .get_matches();\n\n    let host: &str = matches.value_of(\"host\").unwrap_or(\"localhost\");\n    let port = matches\n        .value_of(\"port\")\n        .unwrap_or(\"1987\")\n        .parse::<u16>()\n        .expect(\"port-no not valid\");\n```", "```rs\n    let listener = TcpListener::bind((host, port)).unwrap();\n```", "```rs\n    let server = root.new(o!(\"host\" => host.to_string(),\n                             \"port\" => port));\n    info!(server, \"Server open for business! :D\");\n\n    let mut joins = Vec::new();\n    for stream in listener.incoming() {\n        if let Ok(stream) = stream {\n            let stream_no = TOTAL_STREAMS.fetch_add(1, \n            Ordering::Relaxed);\n            let log = root.new(o!(\"stream-no\" => stream_no,\n                   \"peer-addr\" => stream.peer_addr()\n                                  .expect(\"no peer address\")\n                                  .to_string()));\n            let writer = BufWriter::new(\n                             stream.try_clone()\n                             .expect(\"could not clone stream\"));\n            let reader = BufReader::new(stream);\n            match handle_client(log, reader, writer) {\n                Ok(handler) => {\n                    joins.push(handler);\n                }\n                Err(err) => {\n                    error!(server, \n                           \"Could not make client handler. {:?}\",\n                           err);\n                }\n            }\n        } else {\n            info!(root, \"Shutting down! {:?}\", stream);\n        }\n    }\n\n    info!(\n        server,\n        \"No more incoming connections. Draining existing connections.\"\n    );\n    for jh in joins {\n        if let Err(err) = jh.join() {\n            info!(server, \n                  \"Connection handler died with error: {:?}\", \n                  err);\n        }\n    }\n}\n```", "```rs\nfn handle_client(\n    log: slog::Logger,\n    mut reader: BufReader<TcpStream>,\n    mut writer: BufWriter<TcpStream>,\n) -> io::Result<thread::JoinHandle<()>> {\n    let builder = thread::Builder::new();\n    builder.spawn(move || {\n        let mut buf = String::with_capacity(2048);\n\n        while let Ok(sz) = reader.read_line(&mut buf) {\n            info!(log, \"Received a {} bytes: {}\", sz, buf);\n            writer\n                .write_all(&buf.as_bytes())\n                .expect(\"could not write line\");\n            buf.clear();\n        }\n        TOTAL_STREAMS.fetch_sub(1, Ordering::Relaxed);\n    })\n}\n```", "```rs\n> cargo run --release --bin server\n    Finished release [optimized] target(s) in 0.26 secs\n     Running `target/release/server`\nhost: localhost\n port: 1987\n  Apr 22 21:31:14.001 INFO Server open for business! :D\n```", "```rs\n> telnet localhost 1987\nTrying ::1...\nConnected to localhost.\nEscape character is '^]'.\nhello server\n```", "```rs\nstream-no: 0\n peer-addr: [::1]:65219\n  Apr 22 21:32:54.943 INFO Received a 14 bytes: hello server\n```", "```rs\n#[macro_use]\nextern crate slog;\nextern crate clap;\nextern crate slog_async;\nextern crate slog_term;\n\nuse clap::{App, Arg};\nuse slog::Drain;\nuse std::net::TcpStream;\nuse std::sync::atomic::{AtomicUsize, Ordering};\nuse std::{thread, time};\n\nstatic TOTAL_STREAMS: AtomicUsize = AtomicUsize::new(0);\n```", "```rs\nfn report(log: slog::Logger) {\n    let delay = time::Duration::from_millis(1000);\n    let mut total_streams = 0;\n    loop {\n        let streams_per_second = TOTAL_STREAMS.swap(0, Ordering::Relaxed);\n        info!(log, \"Total connections: {}\", total_streams);\n        info!(log, \"Connections per second: {}\", streams_per_second);\n        total_streams += streams_per_second;\n        thread::sleep(delay);\n    }\n}\n```", "```rs\nfn main() {\n    let decorator = slog_term::TermDecorator::new().build();\n    let drain = slog_term::CompactFormat::new(decorator).build().fuse();\n    let drain = slog_async::Async::new(drain).build().fuse();\n    let root = slog::Logger::root(drain, o!());\n\n    let matches = App::new(\"server\")\n        .arg(\n            Arg::with_name(\"host\")\n                .long(\"host\")\n                .value_name(\"HOST\")\n                .help(\"Sets which hostname to listen on\")\n                .takes_value(true),\n        )\n        .arg(\n            Arg::with_name(\"port\")\n                .long(\"port\")\n                .value_name(\"PORT\")\n                .help(\"Sets which port to listen on\")\n                .takes_value(true),\n        )\n        .get_matches();\n\n    let host: &str = matches.value_of(\"host\").unwrap_or(\"localhost\");\n    let port = matches\n        .value_of(\"port\")\n        .unwrap_or(\"1987\")\n        .parse::<u16>()\n        .expect(\"port-no not valid\");\n\n    let client = root.new(o!(\"host\" => host.to_string(), \"port\" => port));\n    info!(client, \"Client ready to be mean. >:)\");\n```", "```rs\n    let reporter_log = root.new(o!(\"meta\" => \"report\"));\n    let _ = thread::spawn(|| report(reporter_log));\n```", "```rs\n    let mut streams = Vec::with_capacity(2048);\n    loop {\n        match TcpStream::connect((host, port)) {\n            Ok(stream) => {\n                TOTAL_STREAMS.fetch_add(1, Ordering::Relaxed);\n                streams.push(stream);\n            }\n            Err(err) => error!(client, \n                               \"Connection rejected with error: {:?}\", \n                               err),\n        }\n    }\n}\n```", "```rs\n> cargo run --release --bin client\n    Finished release [optimized] target(s) in 0.22 secs\n     Running `target/release/client`\nhost: localhost\n port: 1987\n  Apr 22 21:50:49.200 INFO Client ready to be mean. >:)\nmeta: report\n Apr 22 21:50:49.200 INFO Total connections: 0\n Apr 22 21:50:49.201 INFO Connections per second: 0\n Apr 22 21:50:50.200 INFO Total connections: 0\n Apr 22 21:50:50.200 INFO Connections per second: 1160\n Apr 22 21:50:51.204 INFO Total connections: 1160\n Apr 22 21:50:51.204 INFO Connections per second: 1026\n Apr 22 21:50:52.204 INFO Total connections: 2186\n Apr 22 21:50:52.204 INFO Connections per second: 915\n```", "```rs\n[package]\nname = \"fixed_threads_server\"\nversion = \"0.1.0\"\nauthors = [\"Brian L. Troutwine <brian@troutwine.us>\"]\n\n[dependencies]\nclap = \"2.31\"\nslog = \"2.2\"\nslog-term = \"2.4\"\nslog-async = \"2.3\"\nthreadpool = \"1.7\"\n\n[[bin]]\nname = \"server\"\n\n[[bin]]\nname = \"client\"\n```", "```rs\n#[macro_use]\nextern crate slog;\nextern crate clap;\nextern crate slog_async;\nextern crate slog_term;\nextern crate threadpool;\n\nuse clap::{App, Arg};\nuse slog::Drain;\nuse std::io::{BufRead, BufReader, BufWriter, Write};\nuse std::net::{TcpListener, TcpStream};\nuse std::sync::atomic::{AtomicUsize, Ordering};\nuse threadpool::ThreadPool;\n\nstatic TOTAL_STREAMS: AtomicUsize = AtomicUsize::new(0);\n```", "```rs\nfn handle_client(\n    log: slog::Logger,\n    mut reader: BufReader<TcpStream>,\n    mut writer: BufWriter<TcpStream>,\n) -> () {\n    let mut buf = String::with_capacity(2048);\n\n    while let Ok(sz) = reader.read_line(&mut buf) {\n        info!(log, \"Received a {} bytes: {}\", sz, buf);\n        writer\n            .write_all(&buf.as_bytes())\n            .expect(\"could not write line\");\n        buf.clear();\n    }\n    TOTAL_STREAMS.fetch_sub(1, Ordering::Relaxed);\n}\n```", "```rs\nfn main() {\n    let decorator = slog_term::TermDecorator::new().build();\n    let drain = slog_term::CompactFormat::new(decorator).build().fuse();\n    let drain = slog_async::Async::new(drain).build().fuse();\n    let root = slog::Logger::root(drain, o!());\n\n    let matches = App::new(\"server\")\n        .arg(\n            Arg::with_name(\"host\")\n                .long(\"host\")\n                .value_name(\"HOST\")\n                .help(\"Sets which hostname to listen on\")\n                .takes_value(true),\n        )\n        .arg(\n            Arg::with_name(\"port\")\n                .long(\"port\")\n                .value_name(\"PORT\")\n                .help(\"Sets which port to listen on\")\n                .takes_value(true),\n        )\n        .arg(\n            Arg::with_name(\"max_connections\")\n                .long(\"max_connections\")\n                .value_name(\"CONNECTIONS\")\n                .help(\"Sets how many connections (thus,\\\n                       threads) to allow simultaneously\")\n                .takes_value(true),\n        )\n        .get_matches();\n\n    let host: &str = matches.value_of(\"host\").unwrap_or(\"localhost\");\n    let port = matches\n        .value_of(\"port\")\n        .unwrap_or(\"1987\")\n        .parse::<u16>()\n        .expect(\"port-no not valid\");\n    let max_connections = matches\n        .value_of(\"max_connections\")\n        .unwrap_or(\"256\")\n        .parse::<u16>()\n        .expect(\"max_connections not valid\");\n```", "```rs\n    let listener = TcpListener::bind((host, port)).unwrap();\n    let server = root.new(o!(\"host\" => host.to_string(), \"port\" => port));\n    info!(server, \"Server open for business! :D\");\n```", "```rs\n    let pool: ThreadPool = threadpool::Builder::new()\n        .num_threads(max_connections as usize)\n        .build();\n```", "```rs\n    for stream in listener.incoming() {\n        if let Ok(stream) = stream {\n            if pool.active_count() == (max_connections as usize) {\n                info!(\n                    server,\n                    \"Max connection condition reached, rejecting incoming\"\n                );\n            } else {\n                let stream_no = TOTAL_STREAMS.fetch_add(\n                                    1, \n                                    Ordering::Relaxed\n                                );\n                let log = root.new(o!(\"stream-no\" => stream_no,\n                   \"peer-addr\" => stream.peer_addr()\n                                  .expect(\"no peer address\")\n                                  .to_string()));\n                let writer = BufWriter::new(stream.try_clone()\n                             .expect(\"could not clone stream\"));\n                let reader = BufReader::new(stream);\n                pool.execute(move || handle_client(log, reader, writer));\n            }\n        } else {\n            info!(root, \"Shutting down! {:?}\", stream);\n        }\n    }\n```", "```rs\n    info!(\n        server,\n        \"No more incoming connections. \\\n         Draining existing connections.\"\n    );\n    pool.join();\n}\n```", "```rs\n[package]\n\nname = \"threadpool\"\nversion = \"1.7.1\"\nauthors = [\"The Rust Project Developers\", \"Corey Farwell <coreyf@rwell.org>\", \"Stefan Schindler <dns2utf8@estada.ch>\"]\nlicense = \"MIT/Apache-2.0\"\nreadme = \"README.md\"\nrepository = \"https://github.com/rust-threadpool/rust-threadpool\"\nhomepage = \"https://github.com/rust-threadpool/rust-threadpool\"\ndocumentation = \"https://docs.rs/threadpool\"\ndescription = \"\"\"\nA thread pool for running a number of jobs on a fixed set of worker threads.\n\"\"\"\nkeywords = [\"threadpool\", \"thread\", \"pool\", \"threading\", \"parallelism\"]\ncategories = [\"concurrency\", \"os\"]\n\n[dependencies]\nnum_cpus = \"1.6\"\n```", "```rs\n#[derive(Clone, Default)]\npub struct Builder {\n    num_threads: Option<usize>,\n    thread_name: Option<String>,\n    thread_stack_size: Option<usize>,\n}\n```", "```rs\n    pub fn build(self) -> ThreadPool {\n        let (tx, rx) = channel::<Thunk<'static>>();\n\n        let num_threads = self.num_threads.unwrap_or_else(num_cpus::get);\n\n        let shared_data = Arc::new(ThreadPoolSharedData {\n            name: self.thread_name,\n            job_receiver: Mutex::new(rx),\n            empty_condvar: Condvar::new(),\n            empty_trigger: Mutex::new(()),\n            join_generation: AtomicUsize::new(0),\n            queued_count: AtomicUsize::new(0),\n            active_count: AtomicUsize::new(0),\n            max_thread_count: AtomicUsize::new(num_threads),\n            panic_count: AtomicUsize::new(0),\n            stack_size: self.thread_stack_size,\n        });\n\n        // Threadpool threads\n        for _ in 0..num_threads {\n            spawn_in_pool(shared_data.clone());\n        }\n\n        ThreadPool {\n            jobs: tx,\n            shared_data: shared_data,\n        }\n    }\n```", "```rs\ntype Thunk<'a> = Box<FnBox + Send + 'a>;\n```", "```rs\ntrait FnBox {\n    fn call_box(self: Box<Self>);\n}\n\nimpl<F: FnOnce()> FnBox for F {\n    fn call_box(self: Box<F>) {\n        (*self)()\n    }\n}\n```", "```rs\n        let shared_data = Arc::new(ThreadPoolSharedData {\n            name: self.thread_name,\n            job_receiver: Mutex::new(rx),\n            empty_condvar: Condvar::new(),\n            empty_trigger: Mutex::new(()),\n            join_generation: AtomicUsize::new(0),\n            queued_count: AtomicUsize::new(0),\n            active_count: AtomicUsize::new(0),\n            max_thread_count: AtomicUsize::new(num_threads),\n            panic_count: AtomicUsize::new(0),\n            stack_size: self.thread_stack_size,\n        });\n```", "```rs\nimpl ThreadPoolSharedData {\n    fn has_work(&self) -> bool {\n        self.queued_count.load(Ordering::SeqCst) > 0 || \n        self.active_count.load(Ordering::SeqCst) > 0\n    }\n\n    /// Notify all observers joining this pool if there\n    /// is no more work to do.\n    fn no_work_notify_all(&self) {\n        if !self.has_work() {\n            *self.empty_trigger\n                .lock()\n                .expect(\"Unable to notify all joining threads\");\n            self.empty_condvar.notify_all();\n        }\n    }\n}\n```", "```rs\n        for _ in 0..num_threads {\n            spawn_in_pool(shared_data.clone());\n        }\n\n        ThreadPool {\n            jobs: tx,\n            shared_data: shared_data,\n        }\n    }\n}\n```", "```rs\nfn spawn_in_pool(shared_data: Arc<ThreadPoolSharedData>) {\n    let mut builder = thread::Builder::new();\n    if let Some(ref name) = shared_data.name {\n        builder = builder.name(name.clone());\n    }\n    if let Some(ref stack_size) = shared_data.stack_size {\n        builder = builder.stack_size(stack_size.to_owned());\n    }\n```", "```rs\n    builder\n        .spawn(move || {\n            // Will spawn a new thread on panic unless it is cancelled.\n            let sentinel = Sentinel::new(&shared_data);\n```", "```rs\nstruct Sentinel<'a> {\n    shared_data: &'a Arc<ThreadPoolSharedData>,\n    active: bool,\n}\n```", "```rs\nimpl<'a> Sentinel<'a> {\n    fn new(shared_data: &'a Arc<ThreadPoolSharedData>) -> Sentinel<'a> {\n        Sentinel {\n            shared_data: shared_data,\n            active: true,\n        }\n    }\n\n    /// Cancel and destroy this sentinel.\n    fn cancel(mut self) {\n        self.active = false;\n    }\n}\n```", "```rs\nimpl<'a> Drop for Sentinel<'a> {\n    fn drop(&mut self) {\n        if self.active {\n            self.shared_data.active_count.fetch_sub(1, Ordering::SeqCst);\n            if thread::panicking() {\n                self.shared_data.panic_count\n                    .fetch_add(1, Ordering::SeqCst);\n            }\n            self.shared_data.no_work_notify_all();\n            spawn_in_pool(self.shared_data.clone())\n        }\n    }\n}\n```", "```rs\n            loop {\n                // Shutdown this thread if the pool has become smaller\n                let thread_counter_val = shared_data\n                                             .active_count\n                                             .load(Ordering::Acquire);\n                let max_thread_count_val = shared_data\n                                             .max_thread_count\n                                             .load(Ordering::Relaxed);\n                if thread_counter_val >= max_thread_count_val {\n                    break;\n                }\n```", "```rs\n                let message = {\n                    // Only lock jobs for the time it takes\n                    // to get a job, not run it.\n                    let lock = shared_data\n                        .job_receiver\n                        .lock()\n                        .expect(\"Worker thread unable to \\\n                                lock job_receiver\");\n                    lock.recv()\n                };\n```", "```rs\n                let job = match message {\n                    Ok(job) => job,\n                    // The ThreadPool was dropped.\n                    Err(..) => break,\n                };\n```", "```rs\n                shared_data.active_count.fetch_add(1, Ordering::SeqCst);\n                shared_data.queued_count.fetch_sub(1, Ordering::SeqCst);\n\n                job.call_box();\n\n                shared_data.active_count.fetch_sub(1, Ordering::SeqCst);\n                shared_data.no_work_notify_all();\n            }\n\n            sentinel.cancel();\n        })\n        .unwrap();\n}\n```", "```rs\n    pub fn execute<F>(&self, job: F)\n    where\n        F: FnOnce() + Send + 'static,\n    {\n        self.shared_data.queued_count.fetch_add(1, Ordering::SeqCst);\n        self.jobs\n            .send(Box::new(job))\n            .expect(\"ThreadPool::execute unable to send job into queue.\");\n    }\n```", "```rs\n    pub fn join(&self) {\n        // fast path requires no mutex\n        if self.shared_data.has_work() == false {\n            return ();\n        }\n\n        let generation = self.shared_data\n                             .join_generation\n                             .load(Ordering::SeqCst);\n        let mut lock = self.shared_data.empty_trigger.lock().unwrap();\n\n        while generation == self.shared_data\n                                .join_generation \n                                .load(Ordering::Relaxed)\n            && self.shared_data.has_work()\n        {\n            lock = self.shared_data.empty_condvar.wait(lock).unwrap();\n        }\n\n        // increase generation if we are the first thread to\n        // come out of the loop\n        self.shared_data.join_generation.compare_and_swap(\n            generation,\n            generation.wrapping_add(1),\n            Ordering::SeqCst,\n        );\n    }\n```", "```rs\n[package]\nname = \"sniffer\"\nversion = \"0.1.0\"\nauthors = [\"Brian L. Troutwine <brian@troutwine.us>\"]\n\n[dependencies]\npnet = \"0.21\"\n\n[[bin]]\nname = \"sniffer\"\n\n[[bin]]\nname = \"poor_threading\"\n```", "```rs\nextern crate pnet;\n\nuse pnet::datalink::Channel::Ethernet;\nuse pnet::datalink::{self, DataLinkReceiver, DataLinkSender, \n                     MacAddr, NetworkInterface};\nuse pnet::packet::ethernet::{EtherType, EthernetPacket, \n                             MutableEthernetPacket};\nuse pnet::packet::{MutablePacket, Packet};\nuse std::collections::HashMap;\nuse std::sync::mpsc;\nuse std::{env, thread};\n```", "```rs\nfn main() {\n    let interface_name = env::args().nth(1).unwrap();\n    let interface_names_match = |iface: &NetworkInterface| {\n        iface.name == interface_name\n    };\n\n    // Find the network interface with the provided name\n    let interfaces: Vec<NetworkInterface> = datalink::interfaces();\n    let interface = interfaces\n        .into_iter()\n        .filter(interface_names_match)\n        .next()\n        .unwrap();\n```", "```rs\n    let (snd, rcv) = mpsc::sync_channel(10);\n\n    let _ = thread::spawn(|| gather(rcv));\n    let timer_snd = snd.clone();\n    let _ = thread::spawn(move || timer(timer_snd));\n```", "```rs\nfn timer(snd: mpsc::SyncSender<Payload>) -> () {\n    use std::{thread, time};\n    let one_second = time::Duration::from_millis(1000);\n\n    let mut pulses = 0;\n    loop {\n        thread::sleep(one_second);\n        snd.send(Payload::Pulse(pulses)).unwrap();\n        pulses += 1;\n    }\n}\n```", "```rs\nenum Payload {\n    Packet {\n        source: MacAddr,\n        destination: MacAddr,\n        kind: EtherType,\n    },\n    Pulse(u64),\n}\n```", "```rs\nfn gather(rcv: mpsc::Receiver<Payload>) -> () {\n    let mut sources: HashMap<MacAddr, u64> = HashMap::new();\n    let mut destinations: HashMap<MacAddr, u64> = HashMap::new();\n    let mut ethertypes: HashMap<EtherType, u64> = HashMap::new();\n\n    while let Ok(payload) = rcv.recv() {\n        match payload {\n            Payload::Pulse(id) => {\n                println!(\"REPORT {}\", id);\n                println!(\"    SOURCES:\");\n                for (k, v) in sources.iter() {\n                    println!(\"        {}: {}\", k, v);\n                }\n                println!(\"    DESTINATIONS:\");\n                for (k, v) in destinations.iter() {\n                    println!(\"        {}: {}\", k, v);\n                }\n                println!(\"    ETHERTYPES:\");\n                for (k, v) in ethertypes.iter() {\n                    println!(\"        {}: {}\", k, v);\n                }\n            }\n            Payload::Packet {\n                source: src,\n                destination: dst,\n                kind: etype,\n            } => {\n                let mut destination = destinations.entry(dst).or_insert(0);\n                *destination += 1;\n\n                let mut source = sources.entry(src).or_insert(0);\n                *source += 1;\n\n                let mut ethertype = ethertypes.entry(etype).or_insert(0);\n                *ethertype += 1;\n            }\n        }\n    }\n}\n```", "```rs\n    let iface_handler = match datalink::channel(&interface, \n                                                Default::default()) {\n        Ok(Ethernet(tx, rx)) => {\n            let snd = snd.clone();\n            thread::spawn(|| watch_interface(tx, rx, snd))\n        }\n        Ok(_) => panic!(\"Unhandled channel type\"),\n        Err(e) => panic!(\n            \"An error occurred when creating the datalink channel: {}\",\n            e\n        ),\n    };\n\n    iface_handler.join().unwrap();\n}\n```", "```rs\nfn watch_interface(\n    mut tx: Box<DataLinkSender>,\n    mut rx: Box<DataLinkReceiver>,\n    snd: mpsc::SyncSender<Payload>,\n) {\n    loop {\n        match rx.next() {\n            Ok(packet) => {\n                let packet = EthernetPacket::new(packet).unwrap();\n```", "```rs\n                {\n                    let payload: Payload = Payload::Packet {\n                        source: packet.get_source(),\n                        destination: packet.get_destination(),\n                        kind: packet.get_ethertype(),\n                    };\n                    let thr_snd = snd.clone();\n                    thread::spawn(move || {\n                        thr_snd.send(payload).unwrap();\n                    });\n                }\n```", "```rs\n                tx.build_and_send(1, packet.packet().len(), \n                                  &mut |new_packet| \n                {\n                    let mut new_packet = \n                        MutableEthernetPacket::new(new_packet).unwrap();\n\n                    // Create a clone of the original packet\n                    new_packet.clone_from(&packet);\n\n                    // Switch the source and destination\n                    new_packet.set_source(packet.get_destination());\n                    new_packet.set_destination(packet.get_source());\n                });\n            }\n            Err(e) => {\n                panic!(\"An error occurred while reading: {}\", e);\n            }\n        }\n    }\n}\n```", "```rs\nfn watch_interface(\n    mut tx: Box<DataLinkSender>,\n    mut rx: Box<DataLinkReceiver>,\n    snd: mpsc::SyncSender<Payload>,\n) {\n    loop {\n        match rx.next() {\n            Ok(packet) => {\n                let packet = EthernetPacket::new(packet).unwrap();\n\n                let payload: Payload = Payload::Packet {\n                    source: packet.get_source(),\n                    destination: packet.get_destination(),\n                    kind: packet.get_ethertype(),\n                };\n                if snd.try_send(payload).is_err() {\n                    SKIPPED_PACKETS.fetch_add(1, Ordering::Relaxed);\n                }\n```", "```rs\nfn gather(rcv: mpsc::Receiver<Payload>) -> () {\n    let mut sources: HashMap<MacAddr, u64> = HashMap::new();\n    let mut destinations: HashMap<MacAddr, u64> = HashMap::new();\n    let mut ethertypes: HashMap<EtherType, u64> = HashMap::new();\n\n    while let Ok(payload) = rcv.recv() {\n        match payload {\n            Payload::Pulse(id) => {\n                println!(\"REPORT {}\", id);\n                println!(\n                    \"    SKIPPED PACKETS: {}\",\n                    SKIPPED_PACKETS.swap(0, Ordering::Relaxed)\n                );\n```", "```rs\nREPORT 6\n    SKIPPED PACKETS: 75\n    SOURCES:\n        ff:ff:ff:ff:ff:ff: 1453\n        00:23:6a:00:51:6e: 2422\n        5c:f9:38:8b:4a:b6: 1034\n    DESTINATIONS:\n        33:33:ff:0b:62:e8: 1\n        33:33:ff:a1:90:82: 1\n        33:33:00:00:00:01: 1\n        00:23:6a:00:51:6e: 2414\n        5c:f9:38:8b:4a:b6: 1032\n        ff:ff:ff:ff:ff:ff: 1460\n    ETHERTYPES:\n        Ipv6: 4\n        Ipv4: 1999\n        Arp: 2906\n```", "```rs\n[package]\nname = \"smalliters\"\nversion = \"0.1.0\"\nauthors = [\"Brian L. Troutwine <brian@troutwine.us>\"]\n\n[dependencies]\n```", "```rs\nuse std::iter::Iterator;\nuse std::mem;\n```", "```rs\nmacro_rules! unsized_iter {\n    ($name:ident, $int:ty, $max:expr) => {\n```", "```rs\nunsized_iter!(SmallU8, u8, u8::max_value());\nunsized_iter!(SmallU16, u16, u16::max_value());\nunsized_iter!(SmallU32, u32, u32::max_value());\nunsized_iter!(SmallU64, u64, u64::max_value());\nunsized_iter!(SmallUsize, usize, usize::max_value());\n```", "```rs\nmacro_rules! unsized_iter {\n    ($name:ident, $int:ty, $max:expr) => {\n        #[derive(Default)]\n        pub struct $name {\n            cur: $int,\n            done: bool,\n        }\n```", "```rs\n#[derive(Default)]\npub struct SmallU8 {\n    cur: u8,\n    done: bool,\n}\n```", "```rs\n        impl Iterator for $name {\n            type Item = $int;\n\n            fn next(&mut self) -> Option<$int> {\n                if self.done {\n                    return None;\n                }\n                let old = self.cur;\n                if old == $max {\n                    self.done = true;\n                }\n                self.cur = self.cur.saturating_add(1);\n                return Some(old);\n            }\n```", "```rs\n            fn size_hint(&self) -> (usize, Option<usize>) {\n                let size = mem::size_of::<$int>() * 8;\n                let total = 2_usize.pow(size as u32);\n                let remaining = total - (self.cur as usize);\n                (remaining, Some(remaining))\n            }\n        }\n    };\n}\n```", "```rs\nsized_iter!(SmallI8, i8, i8::min_value());\nsized_iter!(SmallI16, i16, i16::min_value());\nsized_iter!(SmallI32, i32, i32::min_value());\nsized_iter!(SmallI64, i64, i64::min_value());\nsized_iter!(SmallIsize, isize, isize::min_value());\n```", "```rs\nmacro_rules! sized_iter {\n    ($name:ident, $int:ty, $min:expr) => {\n        #[derive(Default)]\n        pub struct $name {\n            cur: $int,\n            done: bool,\n        }\n\n        impl Iterator for $name {\n            type Item = $int;\n\n            fn next(&mut self) -> Option<$int> {\n                if self.done {\n                    return None;\n                }\n```", "```rs\n                let old = self.cur;\n                if self.cur == 0 {\n                    self.cur = -1;\n                } else if self.cur.is_negative() && self.cur == $min {\n                    self.done = true;\n                } else if self.cur.is_positive() {\n                    self.cur *= -1;\n                    self.cur -= 1;\n                } else if self.cur.is_negative() {\n                    self.cur *= -1;\n                }\n                return Some(old);\n            }\n```", "```rs\n            fn size_hint(&self) -> (usize, Option<usize>) {\n                let size = mem::size_of::<$int>() * 8;\n                let total = 2_usize.pow(size as u32);\n                let remaining = total - ((self.cur.abs() * 2) as usize);\n                (remaining, Some(remaining))\n            }\n        }\n    };\n}\n```", "```rs\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    macro_rules! sized_iter_test {\n        ($test_name:ident, $iter_name:ident, $int:ty) => {\n            #[test]\n            fn $test_name() {\n                let i = $iter_name::default();\n                let size = mem::size_of::<$int>() as u32;\n                assert_eq!(i.count(), 2_usize.pow(size * 8));\n            }\n        };\n    }\n\n    sized_iter_test!(i8_count_correct, SmallI8, i8);\n    sized_iter_test!(i16_count_correct, SmallI16, i16);\n    sized_iter_test!(i32_count_correct, SmallI32, i32);\n    // NOTE: These take forever. Uncomment if you have time to burn.\n    // sized_iter_test!(i64_count_correct, SmallI64, i64);\n    // sized_iter_test!(isize_count_correct, SmallIsize, isize);\n```", "```rs\n    macro_rules! unsized_iter_test {\n        ($test_name:ident, $iter_name:ident, $int:ty) => {\n            #[test]\n            fn $test_name() {\n                let i = $iter_name::default();\n                let size = mem::size_of::<$int>() as u32;\n                assert_eq!(i.count(), 2_usize.pow(size * 8));\n            }\n        };\n    }\n\n    unsized_iter_test!(u8_count_correct, SmallU8, u8);\n    unsized_iter_test!(u16_count_correct, SmallU16, u16);\n    unsized_iter_test!(u32_count_correct, SmallU32, u32);\n    // NOTE: These take forever. Uncomment if you have time to burn.\n    // unsized_iter_test!(u64_count_correct, SmallU64, u64);\n    // unsized_iter_test!(usize_count_correct, SmallUsize, usize);\n}\n```", "```rs\n[dependencies]\nrand = \">= 0.3, < 0.5\"\nnum_cpus = \"1.2\"\nlibc = \"0.2.16\"\nlazy_static = \"1\"\n```", "```rs\nuse rayon::prelude::*;\n\nfn sum_of_squares(input: &[i32]) -> i32 {\n    input.par_iter()\n         .map(|&i| i * i)\n         .sum()\n}\n```", "```rs\nfn sum_of_squares(input: &[i32]) -> i32 {\n    input.iter()\n         .map(|&i| i * i)\n         .sum()\n}\n```", "```rs\n#[derive(Debug)]\npub struct Iter<'data, T: 'data + Sync> {\n    slice: &'data [T],\n}\n```", "```rs\nimpl<'data, T: Sync + 'data> ParallelIterator for Iter<'data, T> {\n    type Item = &'data T;\n\n    fn drive_unindexed<C>(self, consumer: C) -> C::Result\n        where C: UnindexedConsumer<Self::Item>\n    {\n        bridge(self, consumer)\n    }\n\n    fn opt_len(&self) -> Option<usize> {\n        Some(self.len())\n    }\n}\n```", "```rs\npub trait UnindexedConsumer<I>: Consumer<I> {\n    /// Splits off a \"left\" consumer and returns it. The `self`\n    /// consumer should then be used to consume the \"right\" portion of\n    /// the data. (The ordering matters for methods like find_first –\n    /// values produced by the returned value are given precedence\n    /// over values produced by `self`.) Once the left and right\n    /// halves have been fully consumed, you should reduce the results\n    /// with the result of `to_reducer`.\n    fn split_off_left(&self) -> Self;\n\n    /// Creates a reducer that can be used to combine the results from\n    /// a split consumer.\n    fn to_reducer(&self) -> Self::Reducer;\n}\n```", "```rs\npub trait Consumer<Item>: Send + Sized {\n    /// The type of folder that this consumer can be converted into.\n    type Folder: Folder<Item, Result = Self::Result>;\n\n    /// The type of reducer that is produced if this consumer is split.\n    type Reducer: Reducer<Self::Result>;\n\n    /// The type of result that this consumer will ultimately produce.\n    type Result: Send;\n\n    /// Divide the consumer into two consumers, one processing items\n    /// `0..index` and one processing items from `index..`. Also\n    /// produces a reducer that can be used to reduce the results at\n    /// the end.\n    fn split_at(self, index: usize) -> (Self, Self, Self::Reducer);\n\n    /// Convert the consumer into a folder that can consume items\n    /// sequentially, eventually producing a final result.\n    fn into_folder(self) -> Self::Folder;\n\n    /// Hint whether this `Consumer` would like to stop processing\n    /// further items, e.g. if a search has been completed.\n    fn full(&self) -> bool;\n}\n```", "```rs\npub trait Folder<Item>: Sized {\n    type Result;\n\n    fn consume(self, item: Item) -> Self;\n\n    fn consume_iter<I>(mut self, iter: I) -> Self\n        where I: IntoIterator<Item = Item>\n    {\n        for item in iter {\n            self = self.consume(item);\n            if self.full() {\n                break;\n            }\n        }\n        self\n    }\n\n    fn complete(self) -> Self::Result;\n\n    fn full(&self) -> bool;\n}\n```", "```rs\npub trait Reducer<Result> {\n    fn reduce(self, left: Result, right: Result) -> Result;\n}\n```", "```rs\npub fn bridge<I, C>(par_iter: I, consumer: C) -> C::Result\n    where I: IndexedParallelIterator,\n          C: Consumer<I::Item>\n```", "```rs\nimpl<'data, T: Sync + 'data> IndexedParallelIterator for Iter<'data, T> {\n    fn drive<C>(self, consumer: C) -> C::Result\n        where C: Consumer<Self::Item>\n    {\n        bridge(self, consumer)\n    }\n\n    fn len(&self) -> usize {\n        self.slice.len()\n    }\n\n    fn with_producer<CB>(self, callback: CB) -> CB::Output\n        where CB: ProducerCallback<Self::Item>\n    {\n        callback.callback(IterProducer { slice: self.slice })\n    }\n}\n```", "```rs\n{\n    let len = par_iter.len();\n    return par_iter.with_producer(Callback {\n                                      len: len,\n                                      consumer: consumer,\n                                  });\n```", "```rs\n    struct Callback<C> {\n        len: usize,\n        consumer: C,\n    }\n\n    impl<C, I> ProducerCallback<I> for Callback<C>\n        where C: Consumer<I>\n    {\n        type Output = C::Result;\n        fn callback<P>(self, producer: P) -> C::Result\n            where P: Producer<Item = I>\n        {\n            bridge_producer_consumer(self.len, producer, self.consumer)\n        }\n    }\n}\n```", "```rs\nimpl<'data, T: 'data + Sync> Producer for IterProducer<'data, T> {\n    type Item = &'data T;\n    type IntoIter = ::std::slice::Iter<'data, T>;\n\n    fn into_iter(self) -> Self::IntoIter {\n        self.slice.into_iter()\n    }\n\n    fn split_at(self, index: usize) -> (Self, Self) {\n        let (left, right) = self.slice.split_at(index);\n        (IterProducer { slice: left }, IterProducer { slice: right })\n    }\n}\n```", "```rs\npub fn bridge_producer_consumer<P, C>(len: usize, producer: P,\n                                      consumer: C) -> C::Result\n    where P: Producer,\n          C: Consumer<P::Item>\n{\n    let splitter = LengthSplitter::new(producer.min_len(), \n                                       producer.max_len(), len);\n    return helper(len, false, splitter, producer, consumer);\n```", "```rs\n    fn helper<P, C>(len: usize,\n                    migrated: bool,\n                    mut splitter: LengthSplitter,\n                    producer: P,\n                    consumer: C)\n                    -> C::Result\n        where P: Producer,\n              C: Consumer<P::Item>\n    {\n        if consumer.full() {\n            consumer.into_folder().complete()\n        } else if splitter.try(len, migrated) {\n            let mid = len / 2;\n            let (left_producer, right_producer) = producer.split_at(mid);\n            let (left_consumer, right_consumer, \n                 reducer) = consumer.split_at(mid);\n            let (left_result, right_result) =\n                join_context(|context| {\n                    helper(mid, context.migrated(), splitter,\n                           left_producer, left_consumer)\n                }, |context| {\n                    helper(len - mid, context.migrated(), splitter,\n                           right_producer, right_consumer)\n                });\n            reducer.reduce(left_result, right_result)\n        } else {\n            producer.fold_with(consumer.into_folder()).complete()\n        }\n    }\n}\n```", "```rs\n                join_context(|context| {\n                    helper(mid, context.migrated(), splitter,\n                           left_producer, left_consumer)\n                }, |context| {\n                    helper(len - mid, context.migrated(), splitter,\n                           right_producer, right_consumer)\n                });\n```", "```rs\npub fn join_context<A, B, RA, RB>(oper_a: A, oper_b: B) -> (RA, RB)\n    where A: FnOnce(FnContext) -> RA + Send,\n          B: FnOnce(FnContext) -> RB + Send,\n          RA: Send,\n          RB: Send\n{\n```", "```rs\n    registry::in_worker(|worker_thread, injected| unsafe {\n        log!(Join { worker: worker_thread.index() });\n\n        // Create virtual wrapper for task b; this all has to be\n        // done here so that the stack frame can keep it all live\n        // long enough.\n        let job_b = StackJob::new(|migrated| \n                                  oper_b(FnContext::new(migrated)),\n                                  SpinLatch::new());\n        let job_b_ref = job_b.as_job_ref();\n        worker_thread.push(job_b_ref);\n```", "```rs\n    #[inline]\n    pub unsafe fn push(&self, job: JobRef) {\n        self.worker.push(job);\n        self.registry.sleep.tickle(self.index);\n```", "```rs\npub struct WorkerThread {\n    /// the \"worker\" half of our local deque\n    worker: Deque<JobRef>,\n\n    index: usize,\n\n    /// are these workers configured to steal breadth-first or not?\n    breadth_first: bool,\n\n    /// A weak random number generator.\n    rng: UnsafeCell<rand::XorShiftRng>,\n\n    registry: Arc<Registry>,\n}\n```", "```rs\npub fn in_worker<OP, R>(op: OP) -> R\n    where OP: FnOnce(&WorkerThread, bool) -> R + Send, R: Send\n{\n    unsafe {\n        let owner_thread = WorkerThread::current();\n        if !owner_thread.is_null() {\n            // Perfectly valid to give them a `&T`: this is the\n            // current thread, so we know the data structure won't be\n            // invalidated until we return.\n            op(&*owner_thread, false)\n        } else {\n            global_registry().in_worker_cold(op)\n        }\n    }\n}\n```", "```rs\nstatic mut THE_REGISTRY: Option<&'static Arc<Registry>> = None;\nstatic THE_REGISTRY_SET: Once = ONCE_INIT;\n\n/// Starts the worker threads (if that has not already happened). If\n/// initialization has not already occurred, use the default\n/// configuration.\nfn global_registry() -> &'static Arc<Registry> {\n    THE_REGISTRY_SET.call_once(|| unsafe { init_registry(ThreadPoolBuilder::new()).unwrap() });\n    unsafe { \n        THE_REGISTRY.expect(\"The global thread pool \\\n                            has not been initialized.\") \n    }\n}\n```", "```rs\nunsafe fn init_registry(builder: ThreadPoolBuilder) -> Result<(), ThreadPoolBuildError> {\n    Registry::new(builder).map(|registry| \n                                THE_REGISTRY = Some(leak(registry))\n                              )\n}\n```", "```rs\nimpl Registry {\n    pub fn new(mut builder: ThreadPoolBuilder) \n           -> Result<Arc<Registry>, ThreadPoolBuildError> \n    {\n        let n_threads = builder.get_num_threads();\n        let breadth_first = builder.get_breadth_first();\n\n        let inj_worker = Deque::new();\n        let inj_stealer = inj_worker.stealer();\n        let workers: Vec<_> = (0..n_threads)\n            .map(|_| Deque::new())\n            .collect();\n        let stealers: Vec<_> = workers.iter().map(|d| \n                                                  d.stealer()\n                                              ).collect();\n\n        let registry = Arc::new(Registry {\n            thread_infos: stealers.into_iter()\n                .map(|s| ThreadInfo::new(s))\n                .collect(),\n            state: Mutex::new(RegistryState::new(inj_worker)),\n            sleep: Sleep::new(),\n            job_uninjector: inj_stealer,\n            terminate_latch: CountLatch::new(),\n            panic_handler: builder.take_panic_handler(),\n            start_handler: builder.take_start_handler(),\n            exit_handler: builder.take_exit_handler(),\n        });\n```", "```rs\n        // If we return early or panic, make sure to terminate \n        // existing threads.\n        let t1000 = Terminator(&registry);\n\n        for (index, worker) in workers.into_iter().enumerate() {\n            let registry = registry.clone();\n            let mut b = thread::Builder::new();\n            if let Some(name) = builder.get_thread_name(index) {\n                b = b.name(name);\n            }\n            if let Some(stack_size) = builder.get_stack_size() {\n                b = b.stack_size(stack_size);\n            }\n            if let Err(e) = b.spawn(move || unsafe { \n                main_loop(worker, registry, index, breadth_first) \n            }) {\n                return Err(ThreadPoolBuildError::new(\n                               ErrorKind::IOError(e))\n                           )\n            }\n        }\n\n        // Returning normally now, without termination.\n        mem::forget(t1000);\n\n        Ok(registry.clone())\n    }\n```", "```rs\n    #[inline]\n    pub unsafe fn take_local_job(&self) -> Option<JobRef> {\n        if !self.breadth_first {\n            self.worker.pop()\n        } else {\n            loop {\n                match self.worker.steal() {\n                    Steal::Empty => return None,\n                    Steal::Data(d) => return Some(d),\n                    Steal::Retry => {},\n                }\n            }\n        }\n    }\n```", "```rs\n        // Execute task a; hopefully b gets stolen in the meantime.\n        let status_a = unwind::halt_unwinding(move || \n                           oper_a(FnContext::new(injected)));\n        let result_a = match status_a {\n            Ok(v) => v,\n            Err(err) => join_recover_from_panic(worker_thread, \n                                                &job_b.latch, \n                                                err),\n        };\n```", "```rs\n        while !job_b.latch.probe() {\n            if let Some(job) = worker_thread.take_local_job() {\n                if job == job_b_ref {\n                    // Found it! Let's run it.\n                    //\n                    // Note that this could panic, but it's ok if we \n                    // unwind here.\n                    log!(PoppedRhs { worker: worker_thread.index() });\n                    let result_b = job_b.run_inline(injected);\n                    return (result_a, result_b);\n                } else {\n                    log!(PoppedJob { worker: worker_thread.index() });\n                    worker_thread.execute(job);\n                }\n            } else {\n                // Local deque is empty. Time to steal from other\n                // threads.\n                log!(LostJob { worker: worker_thread.index() });\n                worker_thread.wait_until(&job_b.latch);\n                debug_assert!(job_b.latch.probe());\n                break;\n            }\n        }\n\n        return (result_a, job_b.into_result());\n    })\n```", "```rs\n    fn map<F, R>(self, map_op: F) -> Map<Self, F>\n        where F: Fn(Self::Item) -> R + Sync + Send,\n              R: Send\n    {\n        map::new(self, map_op)\n    }\n```", "```rs\n    fn sum<S>(self) -> S\n        where S: Send + Sum<Self::Item> + Sum<S>\n    {\n        sum::sum(self)\n    }\n```", "```rs\npub fn sum<PI, S>(pi: PI) -> S\n    where PI: ParallelIterator,\n          S: Send + Sum<PI::Item> + Sum\n{\n    pi.drive_unindexed(SumConsumer::new())\n}\n```", "```rs\nJMP -2\n```", "```rs\n;redcode-94\n;name Rave\n;author Stefan Strack\n;strategy Carpet-bombing scanner based on Agony and Medusa's\n;strategy (written in ICWS'94)\n;strategy Submitted: @date@\n;assert CORESIZE==8000\n\nCDIST   equ 12\nIVAL    equ 42\nFIRST   equ scan+OFFSET+IVAL\nOFFSET  equ (2*IVAL)\nDJNOFF  equ -431\nBOMBLEN equ CDIST+2\n\n        org comp\n\nscan    sub.f  incr,comp\ncomp    cmp.i  FIRST,FIRST-CDIST        ;larger number is A\n        slt.a  #incr-comp+BOMBLEN,comp  ;compare to A-number\n        djn.f  scan,<FIRST+DJNOFF       ;decrement A- and B-number\n        mov.ab #BOMBLEN,count\nsplit   mov.i  bomb,>comp               ;post-increment\ncount   djn.b  split,#0\n        sub.ab #BOMBLEN,comp\n        jmn.b  scan,scan\nbomb    spl.a  0,0\n        mov.i  incr,<count\nincr    dat.f  <0-IVAL,<0-IVAL\n        end\n```", "```rs\nMOV.I 0 1\n```", "```rs\n> pmars -b -r 1000 imp.red rave.red\nImp by Alexander Dewdney scores 537\nRave by Stefan Strack scores 1926\nResults: 0 463 537\n```", "```rs\n[package]\nname = \"feruscore\"\nversion = \"0.1.0\"\nauthors = [\"Brian L. Troutwine <brian@troutwine.us>\"]\n\n[dependencies]\nrand = \"0.4\"\nrayon = \"1.0\"\ntempdir = \"0.3\"\n```", "```rs\nextern crate rand;\nextern crate rayon;\nextern crate tempdir;\n\npub mod individual;\npub mod instruction;\n```", "```rs\n#[derive(PartialEq, Eq, Copy, Clone, Debug)]\npub struct Instruction {\n    pub opcode: OpCode,\n    pub modifier: Modifier,\n    pub a_mode: Mode,\n    pub a_offset: Offset,\n    pub b_mode: Mode,\n    pub b_offset: Offset,\n}\n```", "```rs\nimpl Instruction {\n    pub fn random(core_size: u16) -> Instruction {\n        Instruction {\n            opcode: OpCode::random(),\n            modifier: Modifier::random(),\n            a_mode: Mode::random(),\n            a_offset: Offset::random(core_size / 32),\n            b_mode: Mode::random(),\n            b_offset: Offset::random(core_size / 32),\n        }\n    }\n```", "```rs\n    pub fn serialize(&self, w: &mut Write) -> io::Result<usize> {\n        let mut total_written = 0;\n        self.opcode.serialize(w)?;\n        total_written += w.write(b\".\")?;\n        self.modifier.serialize(w)?;\n        total_written += w.write(b\" \")?;\n        total_written += match self.a_mode {\n            Mode::Immediate => w.write(b\"#\")?,\n            Mode::Direct => w.write(b\"$\")?,\n            Mode::Indirect => w.write(b\"*\")?,\n            Mode::Decrement => w.write(b\"{\")?,\n            Mode::Increment => w.write(b\"}\")?,\n        };\n        self.a_offset.serialize(w)?;\n        total_written += w.write(b\", \")?;\n        total_written += match self.b_mode {\n            Mode::Immediate => w.write(b\"#\")?,\n            Mode::Direct => w.write(b\"$\")?,\n            Mode::Indirect => w.write(b\"@\")?,\n            Mode::Decrement => w.write(b\"<\")?,\n            Mode::Increment => w.write(b\">\")?,\n        };\n        total_written += self.b_offset.serialize(w)?;\n        total_written += w.write(b\"\\n\")?;\n        Ok(total_written)\n    }\n}\n```", "```rs\n#[derive(PartialEq, Eq, Copy, Clone, Debug)]\npub enum Modifier {\n    A,\n    B,\n    AB,\n    BA,\n    F,\n    X,\n    I,\n}\n```", "```rs\nimpl Modifier {\n    pub fn random() -> Modifier {\n        match thread_rng().gen_range(0, 7) {\n            0 => Modifier::A,\n            1 => Modifier::B,\n            2 => Modifier::AB,\n            3 => Modifier::BA,\n            4 => Modifier::F,\n            5 => Modifier::X,\n            6 => Modifier::I,\n            _ => unreachable!(),\n        }\n    }\n\n    pub fn serialize(&self, w: &mut Write) -> io::Result<usize> {\n        match *self {\n            Modifier::A => w.write(b\"A\"),\n            Modifier::B => w.write(b\"B\"),\n            Modifier::AB => w.write(b\"AB\"),\n            Modifier::BA => w.write(b\"BA\"),\n            Modifier::F => w.write(b\"F\"),\n            Modifier::X => w.write(b\"X\"),\n            Modifier::I => w.write(b\"I\"),\n        }\n    }\n}\n```", "```rs\n#[derive(Debug)]\npub struct Individual {\n    chromosome: Vec<Option<Instruction>>,\n}\n```", "```rs\nimpl Individual {\n    pub fn new(chromosome_size: u16, core_size: u16) -> Individual {\n        let mut chromosome = Vec::with_capacity(chromosome_size as usize);\n        chromosome.par_extend((0..(chromosome_size as usize))\n                  .into_par_iter().map(|_| {\n            if thread_rng().gen_weighted_bool(OpCode::total() * 2) {\n                None\n            } else {\n                Some(Instruction::random(core_size))\n            }\n        }));\n        Individual { chromosome }\n    }\n```", "```rs\nmap(|_| {\n    if thread_rng().gen_weighted_bool(OpCode::total() * 2) {\n        None\n    } else {\n        Some(Instruction::random(core_size))\n    }\n})\n```", "```rs\n    pub fn serialize(&self, w: &mut Write) -> io::Result<usize> {\n        let mut total_wrote = 0;\n        for inst in &self.chromosome {\n            if let Some(inst) = inst {\n                total_wrote += inst.serialize(w)?;\n            } else {\n                break;\n            }\n        }\n        Ok(total_wrote)\n    }\n```", "```rs\n    pub fn mutate(&mut self, mutation_chance: u32, core_size: u16) -> () {\n        self.chromosome.par_iter_mut().for_each(|gene| {\n            if thread_rng().gen_weighted_bool(mutation_chance) {\n                *gene = if thread_rng().gen::<bool>() {\n                    Some(Instruction::random(core_size))\n                } else {\n                    None\n                };\n            }\n        });\n    }\n```", "```rs\n    pub fn reproduce(&self, partner: &Individual, \n                     child: &mut Individual) -> () \n    {\n        for (idx, (lgene, rgene)) in self.chromosome\n            .iter()\n            .zip(partner.chromosome.iter())\n            .enumerate()\n        {\n            child.chromosome[idx] = if thread_rng().gen::<bool>() {\n                *lgene\n            } else {\n                *rgene\n            };\n        }\n    }\n```", "```rs\n    pub fn compete(&self, other: &Individual) -> Winner {\n        let dir = TempDir::new(\"simulate\")\n                      .expect(\"could not make tempdir\");\n\n        let l_path = dir.path().join(\"left.red\");\n        let mut lfp = BufWriter::new(File::create(&l_path)\n                          .expect(\"could not write lfp\"));\n        self.serialize(&mut lfp).expect(\"could not serialize\");\n        drop(lfp);\n\n        let r_path = dir.path().join(\"right.red\");\n        let mut rfp = BufWriter::new(File::create(&r_path)\n                          .expect(\"could not write rfp\"));\n        other.serialize(&mut rfp).expect(\"could not serialize\");\n        drop(rfp);\n```", "```rs\n        let output = Command::new(\"pmars\")\n            .arg(\"-r\") // Rounds to play\n            .arg(format!(\"{}\", ROUNDS))\n            .arg(\"-b\") // Brief mode (no source listings)\n            .arg(&l_path)\n            .arg(&r_path)\n            .output()\n            .expect(\"failed to execute process\");\n```", "```rs\n        let result_line = ::std::str::from_utf8(&output.stdout)\n            .expect(\"could not parse output\")\n            .lines()\n            .last()\n            .expect(\"no output\");\n```", "```rs\n        let pieces = result_line.split(' ').collect::<Vec<&str>>();\n\n        let l_wins = pieces[1].parse::<u16>()\n                         .expect(\"could not parse l_wins\");\n        let r_wins = pieces[2].parse::<u16>()\n                         .expect(\"could not parse r_wins\");\n        let ties = pieces[3].parse::<u16>()\n                         .expect(\"could not parse ties\");\n        assert_eq!((l_wins + r_wins + ties) as usize, ROUNDS);\n```", "```rs\n        tally_fitness(l_wins as usize);\n        tally_fitness(r_wins as usize);\n```", "```rs\nfn tally_fitness(score: usize) -> () {\n    assert!(score <= ROUNDS);\n\n    match score {\n        0...10 => FITNESS_00010.fetch_add(1, Ordering::Relaxed),\n        11...20 => FITNESS_11020.fetch_add(1, Ordering::Relaxed),\n        21...30 => FITNESS_21030.fetch_add(1, Ordering::Relaxed),\n        31...40 => FITNESS_31040.fetch_add(1, Ordering::Relaxed),\n        41...50 => FITNESS_41050.fetch_add(1, Ordering::Relaxed),\n        51...60 => FITNESS_51060.fetch_add(1, Ordering::Relaxed),\n        61...70 => FITNESS_61070.fetch_add(1, Ordering::Relaxed),\n        71...80 => FITNESS_71080.fetch_add(1, Ordering::Relaxed),\n        81...90 => FITNESS_81090.fetch_add(1, Ordering::Relaxed),\n        91...100 => FITNESS_91100.fetch_add(1, Ordering::Relaxed),\n        _ => unreachable!(),\n    };\n}\n```", "```rs\n        if l_wins > r_wins {\n            Winner::Left(l_wins)\n        } else if l_wins < r_wins {\n            Winner::Right(r_wins)\n        } else {\n            Winner::Tie\n        }\n    }\n}\n```", "```rs\npub fn imp(chromosome_sz: u16) -> Individual {\n    let mut chromosome = vec![\n        // MOV.I $0, $1\n        Some(Instruction {\n            opcode: OpCode::Mov,\n            modifier: Modifier::I,\n            a_mode: Mode::Direct,\n            a_offset: Offset { offset: 0 },\n            b_mode: Mode::Direct,\n            b_offset: Offset { offset: 1 },\n        }),\n    ];\n    for _ in 0..(chromosome_sz - chromosome.len() as u16) {\n        chromosome.push(None);\n    }\n    Individual { chromosome }\n}\n```", "```rs\nextern crate feruscore;\nextern crate rand;\nextern crate rayon;\n\nuse feruscore::individual::*;\nuse rand::{thread_rng, Rng};\nuse rayon::prelude::*;\nuse std::collections::VecDeque;\nuse std::fs::File;\nuse std::fs::{self, DirBuilder};\nuse std::io::{self, BufWriter};\nuse std::path::{Path, PathBuf};\nuse std::sync::atomic::{AtomicUsize, Ordering};\nuse std::{thread, time};\n```", "```rs\n// configuration\nconst POPULATION_SIZE: u16 = 256; // NOTE must be powers of two\nconst CHROMOSOME_SIZE: u16 = 25; // Must be <= 100\nconst PARENTS: u16 = POPULATION_SIZE / 8;\nconst CHILDREN: u16 = PARENTS * 2;\nconst RANDOS: u16 = POPULATION_SIZE - (PARENTS + CHILDREN);\nconst CORE_SIZE: u16 = 8000;\nconst GENE_MUTATION_CHANCE: u32 = 100;\n\n// reporting\nstatic GENERATIONS: AtomicUsize = AtomicUsize::new(0);\nstatic REGIONAL_BATTLES: AtomicUsize = AtomicUsize::new(0);\nstatic FINALS_BATTLES: AtomicUsize = AtomicUsize::new(0);\nstatic STATE: AtomicUsize = AtomicUsize::new(0);\nstatic NEW_PARENTS: AtomicUsize = AtomicUsize::new(0);\n```", "```rs\nfn main() {\n    let _ = thread::spawn(report);\n```", "```rs\n    let mut population: Vec<Individual> = \n        Vec::with_capacity(POPULATION_SIZE as usize);\n    let mut children: Vec<Individual> = \n        Vec::with_capacity(CHILDREN as usize);\n    let mut parents: VecDeque<Individual> = \n        VecDeque::with_capacity(PARENTS as usize);\n    population.par_extend(\n        (0..POPULATION_SIZE)\n            .into_par_iter()\n            .map(|_| Individual::new(CHROMOSOME_SIZE, CORE_SIZE)),\n    );\n    population.pop();\n    population.pop();\n    population.push(ringers::imp(CHROMOSOME_SIZE));\n    population.push(ringers::dwarf(CHROMOSOME_SIZE));\n```", "```rs\n    loop {\n        // tournament, fitness and selection of parents\n        STATE.store(0, Ordering::Release);\n        while parents.len() < PARENTS as usize {\n            thread_rng().shuffle(&mut population);\n            let res = population\n                .into_par_iter()\n                .fold(|| (None, Vec::new()), regional_tournament)\n                .reduce(|| (None, Vec::new()), finals_tournament);\n            population = res.1;\n            parents.push_back(res.0.unwrap());\n            NEW_PARENTS.fetch_add(1, Ordering::Relaxed);\n        }\n```", "```rs\nfold<T, ID, F>(self, identity: ID, fold_op: F) \n    -> Fold<Self, ID, F> \nwhere\n    F: Fn(T, Self::Item) -> T + Sync + Send,\n    ID: Fn() -> T + Sync + Send,\n    T: Send,\n```", "```rs\nreduce<OP, ID>(self, identity: ID, op: OP) \n    -> Self::Item \nwhere\n    OP: Fn(Self::Item, Self::Item) -> Self::Item + Sync + Send,\n    ID: Fn() -> Self::Item + Sync + Send,\n```", "```rs\nfn regional_tournament(\n    (chmp, mut population): (Option<Individual>, Vec<Individual>),\n    indv: Individual,\n) -> (Option<Individual>, Vec<Individual>) {\n    if let Some(chmp) = chmp {\n        REGIONAL_BATTLES.fetch_add(1, Ordering::Relaxed);\n        match chmp.compete(&indv) {\n            Winner::Left(_) | Winner::Tie => {\n                population.push(indv);\n                (Some(chmp), population)\n            }\n            Winner::Right(_) => {\n                population.push(chmp);\n                (Some(indv), population)\n            }\n        }\n    } else {\n        (Some(indv), population)\n    }\n}\n```", "```rs\nfn finals_tournament(\n    (left, mut lpop): (Option<Individual>, Vec<Individual>),\n    (right, rpop): (Option<Individual>, Vec<Individual>),\n) -> (Option<Individual>, Vec<Individual>) {\n    if let Some(left) = left {\n        lpop.extend(rpop);\n        if let Some(right) = right {\n            FINALS_BATTLES.fetch_add(1, Ordering::Relaxed);\n            match left.compete(&right) {\n                Winner::Left(_) | Winner::Tie => {\n                    lpop.push(right);\n                    (Some(left), lpop)\n                }\n                Winner::Right(_) => {\n                    lpop.push(left);\n                    (Some(right), lpop)\n                }\n            }\n        } else {\n            (Some(left), lpop)\n        }\n    } else {\n        assert!(lpop.is_empty());\n        (right, rpop)\n    }\n}\n```", "```rs\n        STATE.store(1, Ordering::Release);\n        while children.len() < CHILDREN as usize {\n            let parent0 = parents.pop_front().expect(\"no parent0\");\n            let parent1 = parents.pop_front().expect(\"no parent1\");\n            let mut child = population.pop().expect(\"no child\");\n            parent0.reproduce(&parent1, &mut child);\n            children.push(child);\n            parents.push_back(parent0);\n            parents.push_back(parent1);\n        }\n```", "```rs\n        assert_eq!(children.len(), CHILDREN as usize);\n        assert_eq!(parents.len(), PARENTS as usize);\n        assert_eq!(population.len(), RANDOS as usize);\n\n        population.append(&mut children);\n```", "```rs\n        STATE.store(2, Ordering::Release);\n        population.par_iter_mut().for_each(|indv| {\n            let _ = indv.mutate(GENE_MUTATION_CHANCE, CORE_SIZE);\n        });\n```", "```rs\n        let generation = GENERATIONS.fetch_add(1, Ordering::Relaxed);\n        if generation % 100 == 0 {\n            checkpoint(generation, &parents)\n                .expect(\"could not checkpoint\");\n        }\n\n        for parent in parents.drain(..) {\n            population.push(parent);\n        }\n    }\n}\n```", "```rs\nfn checkpoint(generation: usize, best: &VecDeque<Individual>) -> io::Result<()> {\n    let root: PathBuf = Path::new(\"/tmp/feruscore/checkpoints\")\n                            .join(generation.to_string());\n    DirBuilder::new().recursive(true).create(&root)?;\n    assert!(fs::metadata(&root).unwrap().is_dir());\n\n    for (idx, indv) in best.iter().enumerate() {\n        let path = root.join(format!(\"{:04}.red\", idx));\n        let mut fp = BufWriter::new(File::create(&path)\n                         .expect(\"could not write lfp\"));\n        indv.serialize(&mut fp)?;\n    }\n\n    Ok(())\n}\n```", "```rs\nGENERATION(0):\n    STATE:          Tournament\n    RUNTIME (sec):  4\n    GENS/s:         0\n    PARENTS:        2\n       PARENTS/s:   1\n    BATTLES:        660\n       R_BATTLES/s: 131\n       F_BATTLES/s: 25\n    FITNESS:\n        00...10:    625\n        11...20:    1\n        21...30:    3\n        31...40:    0\n        41...50:    130\n        51...60:    3\n        61...60:    0\n        71...70:    0\n        81...80:    0\n        91...100:   550\n```", "```rs\nGENERATION(45):\n    STATE:          Tournament\n    RUNTIME (sec):  25297\n    GENS/s:         0\n    PARENTS:        8\n       PARENTS/s:   0\n    BATTLES:        1960\n       R_BATTLES/s: 12\n       F_BATTLES/s: 1\n    FITNESS:\n        00...10:    3796\n        11...20:    0\n        21...30:    0\n        31...40:    0\n        41...50:    0\n        51...60:    0\n        61...60:    0\n        71...70:    0\n        81...80:    0\n        91...100:   118\n```"]