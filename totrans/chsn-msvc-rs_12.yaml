- en: Scalable Microservices Architecture
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter describes the scalability of microservices. In this chapter, we
    will learn how to create microservices that use messages for passing interaction
    with other microservices. You will get acquainted with RabbitMQ message broker
    and how to use it in Rust with `lapin` crate.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will cover the following concepts related to microservices scalability in
    this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Scalable microservices design
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to avoid bottlenecks in your app
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What are message brokers?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to use RabbitMQ with Rust
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To build scalable microservices you, need an infrastructure or resources to
    run multiple microservices in parallel. But for demonstration purposes, we will
    use Docker, which provides the ability to run multiple instances of our applications.
    We also need Docker to start a RabbitMQ instance.
  prefs: []
  type: TYPE_NORMAL
- en: To build all the examples, you will need version 1.31 of the Rust compiler.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can get all the code for the examples in this chapter from the project
    on GitHub: [https:/](https://github.com/PacktPublishing/Hands-On-Microservices-with-Rust/tree/master/Chapter12)[/github.com/PacktPublishing/Hands-On-Microservices-with-Rust/tree/master/Chapter12](https://github.com/PacktPublishing/Hands-On-Microservices-with-Rust/tree/master/Chapter12).'
  prefs: []
  type: TYPE_NORMAL
- en: Scalable architecture
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We avoid monoliths, and microservices can handle more requests per second if
    you develop them in the right way, but using microservices doesn't mean you have
    a scalable application effortlessly. It makes any part of an application flexible
    for scaling, and you have to write loosely coupled microservices that can run
    in many instances.
  prefs: []
  type: TYPE_NORMAL
- en: Basic ideas
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To make an application scalable, you can choose one of two approaches.
  prefs: []
  type: TYPE_NORMAL
- en: In the first case, you can start more copies of the whole application. You may
    think it's impossible, but imagine a service that earns money from ads and provides
    a service to convert images into PDFs. This service can be scaled this way, and
    you can handle as many requests as the customers need, if you have enough hardware,
    of course.
  prefs: []
  type: TYPE_NORMAL
- en: The second approach is to split the application into separate services that
    handle the same types of task, and you can run as many instances of the services
    as you want. For example, your application is an online store and you have issues
    with load on servers with images or static assets. This problem is simple to solve,
    because you can use a **content delivery network** (**CDN**) or buy an extra server
    where you can put the necessary static files, run NGINX, and add this server to
    the DNS records of your domain. But for microservices, you can't always use this
    approach. This requires ingenuity. But the recipe is clear. You have to achieve
    loose coupling for your microservices when you add extra microservices to handle
    specific tasks or to speed up some processes by caching, or using other tricks.
  prefs: []
  type: TYPE_NORMAL
- en: To have a more abstract services interaction layer, you can use message brokers
    that know nothing about your application, but provide the ability to send messages
    from one microservice to another and return the result.
  prefs: []
  type: TYPE_NORMAL
- en: Message brokers and queues
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Message brokers translate messages from one application to another. Clients
    of message brokers use APIs to send messages that are serialized to a specific
    format and subscribe to queues to be notified about all the new messages. There
    is the **AMQP** (short for **Advanced Message Queuing Protocol**) protocol, which
    provides a common API that's compatible with different products.
  prefs: []
  type: TYPE_NORMAL
- en: The main concept of message brokers is the queue. It is an abstraction that
    represents an entity used to collect messages until they will be consumed by clients.
  prefs: []
  type: TYPE_NORMAL
- en: Why is the concept of message brokers cool? Because it's the simplest way to
    achieve loose coupling for services and maintain the possibility of smooth updates.
    You can use a common message format and write microservices to read specific types
    of messages. It helps you to reroute all paths of messages. For examples, you
    can add a specific handler for the specific message type, or set a balancing rule
    to load more powerful services.
  prefs: []
  type: TYPE_NORMAL
- en: There are a lot of message brokers that can be used, depending on your needs.
    Some popular products are described in the following sections.
  prefs: []
  type: TYPE_NORMAL
- en: RabbitMQ
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: RabbitMQ is the most popular message broker. This message broker supports the
    AMQP protocol. It's fast and reliable. It also facilitates the creation of short-lifetime
    queues for implementing client-server interactions based on messages. We will
    use this message broker to create an example of a scalable application.
  prefs: []
  type: TYPE_NORMAL
- en: Kafka
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Apache Kafka was originally created by LinkedIn and was donated to the Apache
    Software Foundation. It's implemented with Scala and works like a log that commits
    all information and provides access to it. It differs from traditional AMQP brokers,
    because it maintains a commit log that helps to achieve durable message storage.
  prefs: []
  type: TYPE_NORMAL
- en: Application bottlenecks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Any part of an application can be a bottleneck. At first, you may have issues
    with the infrastructure used by microservices, such as databases or message brokers.
    Scaling these parts is a complex concept, but here we will only touch upon the
    bottlenecks of microservices.
  prefs: []
  type: TYPE_NORMAL
- en: When you create a microservice, you may encounter problems with the quantity
    of requests it can handle. It depends on multiple factors. You can use a concept
    such as the actors model to spread a load across threads and event loops.
  prefs: []
  type: TYPE_NORMAL
- en: If you have issues with CPU performance, you can create a separate worker that
    handles CPU-intensive tasks and schedules tasks with message brokers to achieve
    loose coupling, because you can add more workers at any time to handle more requests.
  prefs: []
  type: TYPE_NORMAL
- en: It you have I/O-intensive tasks, you can use load balancers to direct load to
    a specific service, but your microservice should be replaceable and shouldn't
    keep a persistent state, but can load it from a database. It allows you to use
    products such as Kubernetes to scale your applications automatically.
  prefs: []
  type: TYPE_NORMAL
- en: You should also split large tasks into small and separate microservices by logical
    domain. For example, create a separate microservice for handling accounts and
    another to render and show shopping carts in the online store. You can also add
    another microservice that processes payments, and they interact with each other
    with messages transferred by a message broker.
  prefs: []
  type: TYPE_NORMAL
- en: Let's create an application that can be scaled by running extra instances of
    some of its components.
  prefs: []
  type: TYPE_NORMAL
- en: Scalable application with Rust and RabbitMQ
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will write an application that decodes QR codes from images
    to textual strings. We will create two services—one to handle incoming requests
    and for decoding tasks, and the second is a worker that will receive tasks and
    decode images to strings and return the result to a server. To implement interaction
    between services, we will use RabbitMQ. For the server and worker implementations,
    we will use the Actix framework. Before we start coding, let's start a RabbitMQ
    instance with Docker.
  prefs: []
  type: TYPE_NORMAL
- en: Bootstrap message broker for testing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To start RabbitMQ, we will use the official image for Docker from DockerHub,
    located here: [https://hub.docker.com/_/rabbitmq/](https://hub.docker.com/_/rabbitmq/).
    We have already used Docker to start instances of databases. Starting RabbitMQ
    is similar:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: We started a container called `test-rabbit` and forward port `5672` to the same
    port of the container. RabbitMQ images also exposes ports `4369`, `5671`, and
    `25672`. If you want to use the advanced features of the message broker, you need
    to open these ports too.
  prefs: []
  type: TYPE_NORMAL
- en: If you want to start an instance of RabbitMQ and have access to it from other
    containers, you can set the `--hostname` arguments for the `run` command and use
    the provided name from other containers to connect to the RabbitMQ instance.
  prefs: []
  type: TYPE_NORMAL
- en: 'When a message broker instance starts, you may need to get some statistics
    from it. The `rabbitmqctl` command can be executed inside the container using
    the `exec` command from Docker:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'It prints the available commands. Add any of them to the command, like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding command activates tracing all the messages pushed to queues,
    which you can see with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'It prints the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Now, we can create a microservice that uses the message broker for interaction
    with the worker.
  prefs: []
  type: TYPE_NORMAL
- en: Dependencies
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Create a new library crate (in which we will add two binaries later) called `rabbit-actix`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see, we are using the 2018 edition of Rust. We need a pretty big
    pile of crates:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: It's important to note that we use the `actix` framework with the `actix-web`
    crate. If you are not familiar with this crate, you can read more about it in
    [Chapter 11](5b7dd2c1-d623-4422-83a7-e05681230ee9.xhtml), *Involving Concurrency
    with Actors and Actix Crate*. We also use the `image` crate to work with image
    formats, because this crate is used by `queens-rock` and implements a decoder
    for QR codes. We also use the `askama` crate to render HTML pages with posted
    tasks, and we use the `indexmap` crate to get an ordered hash map that keeps elements
    insertion order. To create unique names for the tasks, we will use the UUID4 format,
    which is implemented in the `uuid` crate.
  prefs: []
  type: TYPE_NORMAL
- en: 'To interact with RabbitMQ, we will use the `lapin-futures` crate, but we renamed
    it `lapin` because there are two implementations of this crate. The one that we
    use is based on the `futures` crate, and there is also the`lapin-async` crate
    version based on the `mio` crate. We will use the `lapin-futures` crate first,
    and name it `lapin`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Add the first binary with a server implementation pointing to the `src/server.rs`
    file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Add the second binary for a worker that will be implemented in the `src/worker.rs`
    file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'We already use the `askama` crate as a dependency for the main code, but we
    also need it as a dependency for the `build.rs` script. Add this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding dependency needs to rebuild templates to embed them into code.
    Add the following code to a new `build.rs` script:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: All the dependencies are prepared, and we can create an abstract type to interact
    with queues in a message broker.
  prefs: []
  type: TYPE_NORMAL
- en: Abstract queue interaction actor
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Add the `src/queue_actor.rs` actor, and let's create an actor that uses an abstract
    handler to process incoming messages and can send new messages to a queue. It
    also has to create all the necessary queues in RabbitMQ and subscribe to new events
    in the corresponding queue.
  prefs: []
  type: TYPE_NORMAL
- en: Dependencies
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To create an actor, we need the following dependencies:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: First, we use the `ensure_queue` function from the super module, which creates
    a new queue, but we will implement it later in this chapter. `spawn_client` lets
    us create a new `Client` connected to a message broker. We will use the `wrap_future`
    function, which converts any `Future` object into an `ActorFuture`, which can
    be spawned in the `Context` environment of the Actix framework.
  prefs: []
  type: TYPE_NORMAL
- en: Let's explore the types from the `lapin` crate. The `Channel` struct represents
    a connection channel with the RabbitMQ instance. `BasicConsumeOptions` represents
    options used for the `basic_consume` method of the `Channel` call to subscribe
    to new events in a queue. `BasicProperties` types are used as parameters for the `basic_publish`
    method call of the `Channel` type for add properties such as correlation IDs to
    distinct recipients of the message, or set the required quality level for delivery.
    `BasicPublishOptions` is used for the `basic_publish` call to set extra options
    for a message publishing activity.
  prefs: []
  type: TYPE_NORMAL
- en: We also need the `Error` type from the `lapin` crate, but we renamed it `LapinError` because
    we also use the generic  `Error` from the `failure` crate. The `Delivery` struct
    represents an incoming message delivered from a queue. The `FieldTable` type is
    used as a parameter for the `basic_consume` method call of the `Channel` type.
    The `ShortString` type is a simple alias to a `String` that is used as a name
    of a queue in the `lapin` crate. The `Uuid` type is imported from the `uuid` crate
    to generate unique correlation IDs for messages to identify the origin of a message.
  prefs: []
  type: TYPE_NORMAL
- en: Now, we can declare the abstract handler for our messages.
  prefs: []
  type: TYPE_NORMAL
- en: Abstract messages handler
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Create the `QueueHandler` struct in the `queue_actor.rs` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '`QueueHandler` is a trait that has two associated types and three methods.
    It requires a `static` lifetime for types that will implement the `QueueHandler`
    trait, because instances of this trait will be used as fields of actors that have
    a static lifetime as well.'
  prefs: []
  type: TYPE_NORMAL
- en: This trait has the `Incoming` associated type, which represents the incoming
    message type and requires the type to implement the `Deserialize` trait to be
    deserializable, because RabbitMQ transfers byte arrays only and you have to decide
    which format to use for serialization. The `Outgoing` associated type has to implement
    the `Serialize` trait to be serializable as a bytes array to be sent as an outgoing
    message.
  prefs: []
  type: TYPE_NORMAL
- en: '`The QueueHandler`  trait also has `incoming` and `outgoing` methods. The first
    returns the name of a queue to consume incoming messages. The second method returns
    the name of a queue in which an actor will write sending messages. There is also
    a `handle` method, which takes a reference to `TaskId` and incoming messages of the `Self::Incoming`
    associated type. The method returns a `Result` with an optional `Self::Outgoing`
    instance. If the implementation returns `None` then no messages will be sent to
    the outgoing channel. However, you can use a special `SendMessage` type to send
    a message later. We will declare this type later, after we add the actor''s struct.'
  prefs: []
  type: TYPE_NORMAL
- en: Actor
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Add a new struct called `QueueActor` and add a type parameter that implements the `QueueHandler`
    trait:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: The struct has a reference to a connection `Channel` to RabbitMQ. We build it
    over `TcpStream`. The struct also has a `handler` field that contains an instance
    of a handler that implements `QueueHandler`.
  prefs: []
  type: TYPE_NORMAL
- en: 'This struct also has to implement the `Actor` trait to become an actor. We
    also added a `started` method. It remains empty, but it''s a good place to create
    all the queues. For example, you can create a message type that will attach a
    `Stream` of messages to this actor. With this approach, you can start consuming
    any queue at any time:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'We will initialize all the queues in the `new` method to interrupt actor creation
    if something goes wrong:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: We call the `spawn_client` function, which we will implement later, to create
    a `Client` that's connected to a message broker. The function returns a `Channel`
    instance, which is created by the connected `Client`. We use `Channel` to ensure
    the queue we need exists, or create it with `ensure_queue`. This method is implemented
    later in this chapter. We use the result of the `QueueHandler::outgoing` method
    to get the name of the queue to create.
  prefs: []
  type: TYPE_NORMAL
- en: This method expects `SystemRunner` to execute `Future` objects immediately by
    calling the `block_on` method. It lets us get a `Result` and interrupts other
    activities if the method call fails.
  prefs: []
  type: TYPE_NORMAL
- en: After that, we create a queue using the name we get with the `QueueHandler::incoming`
    method call. We will consume messages from this queue and use the `basic_consume`
    method of a `Channel` that starts listening for new messages. To call `basic_consume`,
    we also created default values of the `BasicConsumeOptions` and `FieldTable` types.
    `basic_consume` returns a `Future` that will be resolved to a `Stream` value.
    We use the `block_on` method call of the `SystemRunner` instance to execute this
    `Future` to get a `Stream` instance to attach it to `QueueActor`. We create the
    `QueueActor` instance using the `create` method call, which expects a closure,
    which in turn takes a reference to a `Context`.
  prefs: []
  type: TYPE_NORMAL
- en: Handling an incoming stream
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We used the `basic_consume` method of a `Channel` to create a `Stream` that
    returns `Delivery` objects from a queue. Since we want to attach that `Stream`
    to the actor, we have to implement `StreamHandler` for the `QueueActor` type:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Our `StreamHandler` implementation expects a `Delivery` instance. RabbitMQ expects
    that a client will send an acknowledgement when it consumes the delivered message.
    We do it with the `basic_ack` method call of a `Channel` instance stored as a
    field of `QueueActor`. This method call returns a `Future` instance that we will
    `spawn` in a `Context` to send an acknowledgement that the message was received.
  prefs: []
  type: TYPE_NORMAL
- en: RabbitMQ requires a consumer to notify with every message that is processed.
    If a consumer doesn't do this, then the message is left hanging in the queue.
    But you can set the `no_ack` field of the `BasicConsumeOptions` struct to `true`
    and the message will be marked as delivered as soon as the consumer reads it.
    But if your application fails before the message is processed, you will lose the
    message. It's only suitable for non-critical messages.
  prefs: []
  type: TYPE_NORMAL
- en: We use the `process_message` method that we will implement later to process
    a message using the `QueueHandler` instance. If this method returns a not `None`
    value, we will use it as a response message and send it to an outgoing queue using
    the `send_message` method, which we will also implement later in this chapter.
    But now we will add a message to initiate an outgoing message.
  prefs: []
  type: TYPE_NORMAL
- en: Sending a new message
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '`QueueActor` has to send a new message, because we will use this actor to send
    tasks to a worker. Add the corresponding struct:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Implement the `Message` trait for this type:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: We need to set the `Result` type to `TaskId`, because we will generate a new
    task ID for a new message to process the response with a handler later. If you
    are not familiar with the Actix framework and message, return to [Chapter 11](5b7dd2c1-d623-4422-83a7-e05681230ee9.xhtml),
    *In**volving Concurrency with Actors and Actix Crate*.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `Handler` of this message type will generate a new UUID and convert it
    into a `String`. Then, the method will use the `send_message` method to send a
    message to an outgoing queue:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Now, we have to implement the `process_message` and `send_message` methods of
    `QueueActor`.
  prefs: []
  type: TYPE_NORMAL
- en: Utility methods
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s add the `process_message` method, which processes incoming `Delivery`
    items:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: First, we have to get a unique ID associated with a message. If you remember,
    we used the UUID in this case. We stored it in the correlation ID field of the
    message.
  prefs: []
  type: TYPE_NORMAL
- en: A correlation ID represents a value that is associated with a message as a tag
    for the response. This information is used to implement **Remote Procedure Calls**
    (**RPC**s) over RabbitMQ. If you skipped [Chapter 6](fd4bf12a-bb05-469b-a230-163cee412261.xhtml),
    *Reactive Microservices - Increasing Capacity and Performance*, you can return
    to it to read more about RPCs.
  prefs: []
  type: TYPE_NORMAL
- en: We use JSON format for our messages, and we parse using `serde_json` to create
    incoming data that is stored in the `data` field of the `Delivery` instance. If
    a deserialization was successful, we take the value of the `Self::Incoming` type.
    Now, we have all the information we need to call the `handle` method of the `QueueHandler`
    instance—the correlation ID and a deserialized incoming message. The handler returns
    a `Self::Outgoing` message instance, but we won't serialize it immediately for
    sending, because it will use the `send_message` method that we used to process
    incoming messages. Let's implement it.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `send_message` method takes a correlation ID and an outgoing value to prepare
    and send a message:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: First, the method serializes a value to binary data. If the value is serialized
    to JSON successfully, we prepare options and properties to call the `basic_publish`
    method of a `Channel` to send a message to an outgoing queue. It's worth noting
    that we associated the provided correlation ID to the `BasicProperties` struct
    that's used with the `basic_publish` call. Publishing a message returns a `Future`
    instance, which we have to spawn in the context of an `Actor`. If we can't serialize
    a value, we will log an error.
  prefs: []
  type: TYPE_NORMAL
- en: Now, we can finish implementing the library part of the crate by adding the `spawn_client`
    and `ensure_queue` functions.
  prefs: []
  type: TYPE_NORMAL
- en: Crate
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Add the following imports to the `src/lib.rs` source file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: You are familiar with some types. Let's discuss some of the new ones. `Client`
    represents a client that connects to RabbitMQ. The `Channel` type will be created
    as a result of a connection and is returned by a `Client`. `QueueDeclareOptions` is
    used as a parameter for the `queue_declare` method call of a `Channel`. `ConnectionOptions`
    is necessary to establish a connection, but we will use default values. `Queue`
    represents a queue in RabbitMQ.
  prefs: []
  type: TYPE_NORMAL
- en: 'We need two queues: one for requests and one for responses. We will specify
    the destination of messages with the correlation ID. Add the following constants
    to be used as the names of queues:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'To spawn a `Client` and create a `Channel`, we will add the `spawn_client`
    function, which creates a `Client` and produces a `Channel` from it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: The implementation of the preceding function is simple enough. We create a `TcpStream`
    from a constant address with the `connect` method call. You can make the address
    parameter configurable if necessary. The `connect` method returns a `Future` that
    we use to create a combinator that maps to a new `Client` connected to RabbitMQ.
    We use `block_on` of `SystemRunner` to execute that `Future` immediately. It returns
    a `Client` and a `Heartbeat` instance. The `Client` instance is used to create
    an instance of `Channel`. The `Heartbeat` instance is a task that pings RabbitMQ
    with a connection that has to be spawned as a concurrent activity in the event
    loop. We use `actix::spawn` to run it, because we don't have the `Context` of
    an `Actor`.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we call the `create_channel` method of a `Client` to create a `Channel`.
    But the method returns a `Future`, which we also execute with the `block_on` method.
    Now, we can return the created `Channel` and implement the `ensure_queue` method,
    which expects that `Channel` instance as a parameter.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `ensure_queue` method creates the option to call the `queue_declare` method,
    which creates a queue inside RabbitMQ:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: We fill `QueueDeclareOptions` with default parameters, but set the `auto_delete`
    field to `true`, because we want the created queues to be deleted when an application
    ends. It's suitable for testing purposes. In this method, we won't execute a `Future`
    that is returned by the `queue_declare` method immediately. We return it as is
    to enable the calling environment to make a combinator with the returned `Queue`
    value.
  prefs: []
  type: TYPE_NORMAL
- en: We have implemented all the necessary parts to create a server and a worker.
    Now, we need to declare request and response types to use them in a worker and
    in a server.
  prefs: []
  type: TYPE_NORMAL
- en: Request and response
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The request type called `QrRequest` contains data about the QR image:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'It implements the `Message` trait from `actix`, which is to be set as an associated
    type of `QueueHandler`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'The response type is represented by the `QrResponse` enumeration:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'It contains two variants: `Succeed` for successful results and `Failed` for
    errors. It is similar to the `Result` type of the standard library, but we decided
    to add our own type to have a chance to override the serialization behavior when
    we need it. But we can construct this response from a `Result` instance by implementing
    the `From` trait. It''s useful because we can use a function to construct a value
    that returns the `Result` type. Look at the implementation here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: '`QrResponse` also has to implement the `Message` trait:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: The library crate is ready to be used to create a worker and a server. Let's
    start by implementing a worker.
  prefs: []
  type: TYPE_NORMAL
- en: Worker
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The worker will consume all the messages from the requests queue and try to
    decode them as QR images to strings.
  prefs: []
  type: TYPE_NORMAL
- en: Dependencies
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We need the following types for the implementation of a worker:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: We imported all the necessary types earlier in this chapter. We also imported
    two types for decoding QR images. `GenericImageView` provides the `to_luma` method
    to convert an image into grayscale. The `Scanner` method is a decoder of QR codes
    provided as grayscale images.
  prefs: []
  type: TYPE_NORMAL
- en: Handler
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We need to create an empty struct, because our worker doesn''t have a state
    and will only transform incoming messages:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'We use the `WorkerHandler` struct as the handler for the queue and use it with
    `QueueActor` later. Implement the `QueueHandler` trait, which is required by `QueueActor`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: Since this handler takes requests and prepares responses, we set `QrRequest`
    as the `Incoming` type and `QrResponse` as the `Outgoing` type. The `incoming`
    method returns the value of the `REQUESTS` constant that we will use as a name
    for incoming queues. The `outgoing` method returns the `RESPONSES` constant, which
    is used as the name for the queue of outgoing messages.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `handle` method of `QueueHandler` takes a request and calls the `scan`
    method with data. Then, it converts the `Result` into a `QrResponse` and returns
    it. Let''s implement the `scan` method, which decodes images:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: The implementation of the function is not important from a microservices point
    of view, and I will describe it shortly—it loads an `Image` from the provided
    bytes, converts the `Image` to grayscale with the `to_luma` method, and provides
    the returned value as an argument for a `Scanner`. Then, it uses the `scan` method
    to decode the QR code and extracts the first `Code` converted to a `String`.
  prefs: []
  type: TYPE_NORMAL
- en: main function
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now, we can add a `main` function to spawn an actor with the decoding worker:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: This method starts a `System` and creates an instance of `QueueActor` with an
    instance of `WorkerHandler`. That's all. It's really simple—with `QueueActor`,
    it's enough to implement `QueueHandler` to make a processor to a queue. Let's
    create a server in a similar way.
  prefs: []
  type: TYPE_NORMAL
- en: Server
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To implement a server, we don't just implement `QueueHandler`. We also have
    to implement handlers for HTTP requests. We will also use the `actix` and `actix-web`
    crates.
  prefs: []
  type: TYPE_NORMAL
- en: Dependencies
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Add the following types to the `server.rs` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: You should be familiar with all the types, because we used most of them in the
    previous chapters, excluding `MultipartItem` and `MultipartError`. Both of these
    types are used to extract uploaded files from POST requests.
  prefs: []
  type: TYPE_NORMAL
- en: Shared state
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We will also add the `SharedTasks` type alias, which represents an `IndexMap`
    wrapped with `Mutex` and `Arc`. We will use this type to store all the tasks and
    statuses for them:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: '`Record` is a struct that contains the unique identifier of the task, and is
    used as the correlation ID for the message. It also has a `timestamp` that denotes
    when the task was posted, and a `Status` that represents the status of the task:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: '`Status` is an enumeration that has two variants: `InProgress`, when a task
    is sent to a worker; and `Done`, when a worker returns a response as a `QrResponse`
    value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'We need to implement the `Display` trait for `Status`, because we will use
    it to render the HTML template. Implement the trait:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'We will show three statuses: in progress, succeed, and failed.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Our server needs a shared state. We will use the `State` struct with a map
    of tasks and an address of `QueueActor` and `ServerHandler`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: Now, we can implement `ServerHandler` and spawn an actor with it.
  prefs: []
  type: TYPE_NORMAL
- en: Server handler
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To consume responses from a worker, our server has to start `QueueActor` with
    a handler that will update the shared state of a server. Create a `ServerHandler`
    struct that keeps a copy of the `SharedTasks` reference:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'Implement the `QueueHandler` for this struct:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: The handler of the server has to use the `RESPONSES` queue to consume responses,
    and `REQUESTS` as the outgoing queue to send requests. Correspondingly, set `QrResponse`
    to the `Incoming` type and `QrRequest` to the `Outgoing` type.
  prefs: []
  type: TYPE_NORMAL
- en: The `handle` method locks a `Mutex` stored in the `tasks` field to get access
    to `IndexMap` and update the `status` field of `Record` if the record exists for
    a corresponding task ID. The ID of the task will be automatically extracted by
    `QueueActor` and is provided to this method by an immutable reference. It's time
    to implement all the necessary HTTP handlers.
  prefs: []
  type: TYPE_NORMAL
- en: Requests handlers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We need three handlers for requests: an index page to show the name of the
    microservice, a handler for rendering all tasks and their statuses, and an uploading
    handler for posing new tasks with QR codes.'
  prefs: []
  type: TYPE_NORMAL
- en: Index handler
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '`index_handler` returns some text with the name of this microservice:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: Tasks handler
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '`tasks_handler` locks a `Mutex` with `IndexMap` to iterate over all `Record`
    values to render them as a part of the `Tasks` struct:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'If you remember, we added the `askama` crate to render templates. Create a `templates`
    folder in the root of project and add a `tasks.html` file with some HTML code
    that contains at least the following rendering table:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'This is a part of the full template that you can find in the examples folder
    for this book, but the preceding code contains code for rendering a table with
    all the tasks extracted from the `Tasks` struct, which is  implemented as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: Derive the `Template` type for this struct and attach the template with the `template`
    attribute. `askama` will embed the template into your code. That's very convenient.
  prefs: []
  type: TYPE_NORMAL
- en: Upload handler
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '`upload_handler` is a bit complex, because it takes POST requests with a form
    that contains the uploaded image:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'The implementation gets a `Stream` of `MultipartItem`, the value of which could
    be either `Filed` or `Nested`. We use the following function to collect all items
    in a single uniform `Stream` of `Vec<u8>` objects:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: Then, we extract the first item with the `into_future` method. If the value
    exists, we map it to `QrRequest` and use the address of `QueueActor` to `send`
    a request to a worker.
  prefs: []
  type: TYPE_NORMAL
- en: You may ask whether it is possible if a worker returns a result if the ID of
    task wasn't set. Potentially, it's possible. If you want to have a reliable changing
    of `State`, you should implement an actor that works with the `State` instance
    exclusively.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, the handler constructs a `HttpResponse` value that redirects the client
    to the `/tasks` path.
  prefs: []
  type: TYPE_NORMAL
- en: Now, we can connect each part in a single function.
  prefs: []
  type: TYPE_NORMAL
- en: main function
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We have already created functions that create app instances of `actix` in [Chapter
    11](5b7dd2c1-d623-4422-83a7-e05681230ee9.xhtml), *In**volving Concurrency with
    Actors and Actix Crate*. Return to that chapter if you don''t remember how to
    attach handlers and a state to an application, and look at the `main` function,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: This function creates a `System` instance with a new method that returns a `SystemRunner`
    instance, which we will use to start `QueueActor` with `ServerHandler` inside.
    Then, it creates a `State` instance with the address of the spawned actor and
    fills the `App` object with all the necessary handlers.
  prefs: []
  type: TYPE_NORMAL
- en: When we start a `SystemRunner`, it creates an actor and connects to RabbitMQ
    to create all the necessary queues and starts consuming the responses.
  prefs: []
  type: TYPE_NORMAL
- en: A good practice is to create the same queues from all the applications that
    use it, because you can't know which part will be started first—the server or
    the worker. That's why we implemented the creation of all the queues in the `new`
    method of `QueueAction`. All queues will be available before any piece of code
    uses them.
  prefs: []
  type: TYPE_NORMAL
- en: We are ready to test this example.
  prefs: []
  type: TYPE_NORMAL
- en: Testing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let's build and run the server and worker of the application. You should start
    a container with a RabbitMQ instance, as we did in this chapter in the *Bootstrap
    message broker for testing* section. Then, use `cargo build` to build all the parts.
  prefs: []
  type: TYPE_NORMAL
- en: 'When compilation has finished, start a server instance:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'Also, start a worker instance with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'When both parts have started, you can explore RabbitMQ with the `rabbitmqctl`
    command and explore your queues:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'It prints both the queues that were created by the actors:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'If you want to see all connected consumers, you can do that with the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'It prints `responses-consumer`, which represents a server instance, and `requests-consumer`,
    which represents a worker instance:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that everything is connected to RabbitMQ, we can open `http://localhost:8080/tasks`
    in a browser. You will see an empty table and a form to upload a QR code. Choose
    a file and upload it using the form. It will refresh the page and you will see
    your task in progress:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d48e3f3d-fc8c-45ec-b298-d526a231ab5c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'If the worker works properly and if you refresh the page after short period
    of time, you will see the decoded QR code:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/239f03f8-e6da-434f-81a2-598cf7ba722b.png)'
  prefs: []
  type: TYPE_IMG
- en: As you can see, the server and worker interact with a message that was delivered
    by RabbitMQ.
  prefs: []
  type: TYPE_NORMAL
- en: Let's discuss the benefits and drawbacks of this solution.
  prefs: []
  type: TYPE_NORMAL
- en: How to scale this application
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The example we created in this chapter uses two parts that work separately and
    use RabbitMQ to exchange tasks and results.
  prefs: []
  type: TYPE_NORMAL
- en: Scaling this application is very easy—you just need to start as many workers
    as you want, and they don't have to work on the same server. You can run workers
    on a distributed cluster of servers. If your workers can't handle a load, you
    can start extra workers that will consume waiting tasks immediately and start
    the decoding process.
  prefs: []
  type: TYPE_NORMAL
- en: But this system has a potential bottleneck – the message broker. For this example,
    you can simply handle it if you start extra independent message brokers; for example,
    RabbitMQ support multiple instances with its clustering feature. Your server can
    have multiple connections with multiple message brokers, but you can't spawn as
    many servers as you want because they will have different sets of tasks.
  prefs: []
  type: TYPE_NORMAL
- en: Is it possible to share a list of tasks? Yes, you can use a traditional database
    or storage, such as Redis, but it becomes another bottleneck, because it's hard
    to use the same database instance for millions of clients.
  prefs: []
  type: TYPE_NORMAL
- en: How can we handle the bottleneck with a database? You can split the tasks list
    by client and keep the list for a specific client on one instance of storage.
    If you want to provide a feature where your clients share tasks with each other,
    you can create shared lists and store them in a database, which won't have a heavy
    load in this case.
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, scaling is an undefined process, and you have to do some experimenting
    to achieve the desired result. But in any case, you should strive for separate
    tasks across microservices and use messages or RPCs to get loose coupling for
    your application, as well as good performance.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we discussed the important topic of scalable microservices.
    We started with the basics and continued with implementing two services that use
    RabbitMQ as a message broker to interact with each other. The example we created
    decodes QR codes to be processed by a separate worker. The benefit of the implemented
    application is that you can start as many workers as you want.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will learn how to test and debug microservices using
    unit tests, integration tests, and debuggers.
  prefs: []
  type: TYPE_NORMAL
