- en: Sequential Rust Performance and Testing
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 顺序Rust性能和测试
- en: '"Make it work, then make it beautiful, then if you really, really have to,
    make it fast."'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '"先让它工作，然后让它美观，然后如果你真的、真的需要，再让它快速。"'
- en: '- *Joe Armstrong*'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '- *乔·阿姆斯特朗*'
- en: In the previous chapter, we discussed the basics of modern computer architectures—the
    CPU and its function, memory hierarchies, and their interplay. We left off with
    a brief introduction to debugging and performance analysis of Rust programs. In
    this chapter, we'll continue that discussion, digging into the performance characteristics
    of sequential Rust programs, deferring, for now, considerations of concurrent
    performance. We'll also be discussing testing techniques for demonstrating the
    fitness for purpose of a Rust program. Why, in a book about parallel programming,
    would we wish to devote an entire chapter to just sequential programs? The techniques
    we'll discuss in this sequential setting are applicable and vital to a parallel
    setting. What we gain here is the meat of the concern—being fast *and* correct—without
    the complication that parallel programming brings, however, we'll come to that
    in good time. It is also important to understand that the production of fast parallel
    code comes part and parcel with the production of fast sequential code. That's
    on account of there being a cold, hard mathematical reality that we'll deal with
    throughout the book.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们讨论了现代计算机架构的基础——CPU及其功能、内存层次结构及其相互作用。我们简要介绍了Rust程序的调试和性能分析。在本章中，我们将继续这一讨论，深入探讨顺序Rust程序的性能特性，暂时推迟对并发性能的考虑。我们还将讨论用于展示Rust程序适用性的测试技术。为什么在一本关于并行编程的书中，我们会专门用一整章来讨论顺序程序？我们在这种顺序环境中所讨论的技术适用于并行环境，并且至关重要。在这里我们所获得的是关注的重点——快速且正确——尽管如此，我们将在适当的时候讨论并行编程。同样重要的是要理解，快速并行代码的生产与快速顺序代码的生产是密不可分的。这是因为我们将在整本书中处理的一个冷酷、严峻的数学现实。
- en: 'By the close of the chapter, we will:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，我们将：
- en: Have learned about Amdahl's and Gustafson's laws
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 已经了解了Amdahl定律和Gustafson定律
- en: Have investigated the internals of the Rust standard library `HashMap`
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 已经调查了Rust标准库`HashMap`的内部结构
- en: Be able to use QuickCheck to perform randomized validating of an alternative
    HashMap implementation
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 能够使用QuickCheck对替代HashMap实现进行随机验证
- en: Be able to use American Fuzzy Lop to demonstrate the lack of crashes in the
    same
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 能够使用American Fuzzy Lop来演示同一
- en: Have used Valgrind and Linux Perf to examine the performance of Rust software
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 已使用Valgrind和Linux Perf来检查Rust软件的性能
- en: Technical requirements
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: This chapter requires a working Rust installation. The details of verifying
    your installation are covered in [Chapter 1](5f3aec9d-fd53-48ff-9ba8-43ce13e91cff.xhtml),
    *Preliminaries – Machine Architecture and Getting Started with Rust*. The Valgrind
    suite of tools will be used here. Many operating systems bundle valgrind packages
    but you can find further installation instructions for your system at [valgrind.org](http://valgrind.org/).
    Linux Perf is used and is bundled by many Linux distributions. Any other software
    required for this chapter is installed as a part of the text.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 本章需要安装一个可工作的Rust环境。验证安装的详细步骤在[第1章](5f3aec9d-fd53-48ff-9ba8-43ce13e91cff.xhtml)，*预备知识——机器架构和Rust入门*中有所介绍。这里将使用Valgrind工具集。许多操作系统捆绑了valgrind包，但您可以在[http://valgrind.org/](http://valgrind.org/)找到您系统的进一步安装说明。Linux
    Perf也被许多Linux发行版捆绑。本章所需的其他任何软件都将作为文本的一部分安装。
- en: 'You can find the source code for this book''s projects on GitHub: [https://github.com/PacktPublishing/Hands-On-Concurrency-with-Rust](https://github.com/PacktPublishing/Hands-On-Concurrency-with-Rust).
    The source code for this chapter is under `Chapter02`.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在GitHub上找到本书项目的源代码：[https://github.com/PacktPublishing/Hands-On-Concurrency-with-Rust](https://github.com/PacktPublishing/Hands-On-Concurrency-with-Rust)。本章的源代码位于`Chapter02`目录下。
- en: Diminishing returns
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 递减回报
- en: 'The hard truth is that there''s a diminishing return when applying more and
    more concurrent computational resources to a problem. Performing parallel computations
    implies some coordination overhead—spawning new threads, chunking data, and memory
    bus issues in the presence of barriers or fences, depending on your CPU. Parallel
    computing is not free. Consider this `Hello, world!` program:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 严峻的事实是，当将越来越多的并发计算资源应用于问题时，回报是递减的。执行并行计算意味着一些协调开销——在存在屏障或围栏的情况下，创建新线程、分块数据和内存总线问题。并行计算不是免费的。考虑这个`Hello,
    world!`程序：
- en: '[PRE0]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Straightforward enough, yeah? Compile and run it 100 times:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 很简单，对吧？编译并运行它100次：
- en: '[PRE1]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Now, consider basically the same program but involving the overhead of spawning
    a thread:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，考虑基本上相同的程序，但涉及到创建线程的开销：
- en: '[PRE2]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Compile and run it 100 times:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 编译并运行它100次：
- en: '[PRE3]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: This implies a thread-spawn time on my test system of 0.24 milliseconds. That
    is, of course, without any synchronization. The point is, it's not free. It's
    also not magic. Say you have a program that runs on a single processor in 24 hours
    and there are parts of the program that will have to be done sequentially and
    which, added together, consume 1 hour of the total runtime. The remaining 23 hours
    represent computations that can be run in parallel. If this computation is important
    and needs to be done in a hurry, the temptation is going to be to chuck in as
    much hardware as possible. How much of an improvement should you expect?
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着在我的测试系统中线程创建的时间为0.24毫秒。当然，这是在没有任何同步的情况下。关键是，这并不是免费的。它也不是魔法。假设你有一个程序在一个处理器上运行需要24小时，并且程序中有一部分必须顺序执行，总共消耗了总运行时间的1小时。剩下的23小时代表可以并行运行的计算。如果这个计算很重要并且需要尽快完成，那么可能会倾向于投入尽可能多的硬件。你应该期望有多大的改进？
- en: One well-known answer to this question is Amdahl's law. It states that the speedup
    of a computation is proportional to the inverse of the percentage of time taken
    by the sequential bit plus the percentage of the parallel time divided by the
    total new computation units, *1/(s + p / N)*. As *N* tends toward infinity, *1/s
    == 1/(1-p),* in our example, *1/(1 - (23/24)) = 24*. That is, the maximum factor
    speedup you can ever hope to see is 24 times, with infinite additional capacity.
    Ouch.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个问题的一个众所周知的答案是阿姆达尔定律。它表明计算的加速与顺序部分所占时间的倒数加上并行时间所占百分比除以总新计算单元数成比例，即*1/(s +
    p / N)*。当*N*趋向于无穷大时，*1/s == 1/(1-p)*，在我们的例子中，*1/(1 - (23/24)) = 24*。也就是说，你所能期望的最大加速因子是24倍，具有无限额外的容量。哎呀。
- en: 'Amdahl''s law is a touch pessimistic, as noted by John Gustafson in his 1988
    Reevaluating Amdahl''s Law:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 阿姆达尔定律有点悲观，正如John Gustafson在1988年重新评估阿姆达尔定律时所指出的：
- en: '"At Sandia National Laboratories, we are currently engaged in research involving
    massively-parallel processing. There is considerable skepticism regarding the
    viability of massive parallelism; the skepticism centers around Amdahl''s law,
    an argument put forth by Gene Amdahl in 1967 that even when the fraction of serial
    work in a given problem is small, say s, the maximum speedup obtainable from even
    an infinite number of parallel processors is only 1/s. We now have timing results
    for a 1024-processor system that demonstrate that the assumptions underlying Amdahl''s
    1967 argument are inappropriate for the current approach to massive ensemble parallelism."'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: “在桑迪亚国家实验室，我们目前正在研究涉及大规模并行处理的项目。对于大规模并行化的可行性存在相当多的怀疑；这种怀疑主要集中在阿姆达尔定律上，这是Gene
    Amdahl在1967年提出的一个论点，即即使在一个给定问题中串行工作的比例很小，比如说s，那么从无限数量的并行处理器中获得的最大加速比也只有1/s。我们现在有一个1024处理器系统的计时结果，证明了阿姆达尔1967年论点背后的假设对于当前的大规模并行方法是不适当的。”
- en: Gustafson argues that real workloads will take the time factor of a computation
    as fixed and vary the input work accordingly. In some hypothetical, very important
    computations we'd see 24 hours as acceptable and, on increasing the total number
    of processors available, then rush to figure out how to add in more computation
    so as to get the time back up to one day. As we increase the total workload, the
    serial portion of the computation tends towards zero. This is, itself, maybe somewhat
    optimistic and is certainly not applicable to problems where there's no more datasets
    available. Communication overhead is not included in either analysis.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 古斯塔夫森认为，实际的工作负载会将计算的时间因素视为固定，并相应地调整输入工作量。在一些假设的、非常重要的计算中，我们会认为24小时是可以接受的，并且随着可用的处理器总数增加，我们会急忙找出如何增加更多的计算，以便将时间恢复到一天。随着总工作量的增加，计算的串行部分趋向于零。这本身可能有些乐观，并且显然不适用于没有更多数据集可用的问题。通信开销没有包含在这两种分析中。
- en: Ultimately, what has to be internalized is this—performing computations in parallel
    is subject to diminishing returns. Exactly how that take shape depends strongly
    on your problem, the machine, and so on, but it's there. What the programmer must
    do to bend that curve is shrink the percentage of time spent in serial computation,
    either by increasing the relative portion of parallel computation per Gustafson
    with a larger dataset or by optimizing the serial computation's runtime. The remainder
    of this chapter will be focused on the latter approach—improving the runtime of
    serial computations.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，必须内化的东西是——并行计算会带来递减的回报。具体如何形成取决于你的问题、机器等等，但这是事实。程序员必须做的是弯曲这条曲线，即减少串行计算所占的时间百分比，要么通过增加每个古斯塔夫森的并行计算相对部分，使用更大的数据集，要么通过优化串行计算的运行时间。本章的剩余部分将专注于后者——提高串行计算的运行时间。
- en: Performance
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 性能
- en: In this section, we'll focus on the serial performance of a common data structure—associative
    arrays. We'll apply the tools we learned about in the previous chapter to probe
    different implementations. We'll focus on the associative array because it is
    fairly well-trod territory, studied in introductory computer science courses,
    and is available in most higher-level languages by default, Rust being no exception
    save the higher-level bit. We'll look at Rust's associative array first, which
    is called `std::collections::HashMap`.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将关注一个常见数据结构的串行性能——关联数组。我们将应用上一章中学习的工具来探测不同的实现。我们将关注关联数组，因为它是一个相当熟悉的领域，在计算机科学入门课程中研究过，并且在大多数高级语言中默认可用，Rust也不例外，除了高级位之外。我们将首先查看Rust的关联数组，它被称为`std::collections::HashMap`。
- en: Standard library HashMap
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 标准库HashMap
- en: Let's poke around in `HashMap`'s internals. A good starting place, I find, for
    inspecting unfamiliar Rust data structures is jumping into the source to the struct
    definition itself. Especially in the Rust codebase, there will be public `rustdoc`
    comments and private comments explaining implementation ambitions. The reader
    is warmly encouraged to inspect the `HashMap` comments for themselves. In this
    book, we're inspecting Rust at SHA `da569fa9ddf8369a9809184d43c600dc06bd4b4d`.
    The comments of `src/libstd/collections/hash/map.rs` explain that the `HashMap`
    is implemented with linear probing Robin Hood bucket stealing. Linear probing
    implies that we'll find `HashMap` implemented in terms of a cell storage—probably
    a contiguous memory structure for reasons we'll discuss shortly—and should be
    able to understand the implementation pretty directly, linear probing being a
    common method of implementing associative arrays. Robin Hood bucket stealing is
    maybe less common, but the private comments describe it as *the main performance
    trick in this hashmap* and then goes on to quote Pedro Celis' 1986 *Robin Hood
    Hashing:*
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们探索一下`HashMap`的内部结构。我发现，检查不熟悉的数据结构的一个好起点是直接跳到源代码中的结构定义本身。特别是在Rust代码库中，会有公共的`rustdoc`注释和私有的注释来解释实现目标。鼓励读者亲自检查`HashMap`的注释。在这本书中，我们检查的是Rust的SHA
    `da569fa9ddf8369a9809184d43c600dc06bd4b4d`。`src/libstd/collections/hash/map.rs`中的注释解释说，`HashMap`是用线性探测罗宾汉桶窃取实现的。线性探测意味着我们将发现`HashMap`是用单元格存储实现的——可能是因为我们将讨论的原因，它可能是一个连续的内存结构，并且应该能够直接理解实现，线性探测是实现关联数组的常用方法。罗宾汉桶窃取可能不太常见，但私有的注释将其描述为“这个哈希表中的主要性能技巧”，然后引用了Pedro
    Celis 1986年的*罗宾汉哈希法*：
- en: '"If an insertion collides with an existing element, and that element''s "probe
    distance" (how far away the element is from its ideal location) is higher than
    how far we''ve already probed, swap the elements."'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '"如果一个插入操作与现有元素冲突，并且该元素的“探测距离”（元素与其理想位置的距离）高于我们已探测的距离，则交换这两个元素。"'
- en: 'If you pull the thesis yourself, you''ll further find:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你亲自提取论文，你还会进一步发现：
- en: '"(Robin Hood Hashing) leads to a new search algorithm which requires less than
    2.6 probes on average to perform a successful search even when the table is nearly
    full. Unsuccessful searches require only O(ln n) probes."'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '"(罗宾汉哈希)导致了一种新的搜索算法，该算法在表几乎满的情况下平均只需要2.6次探测即可成功搜索。不成功的搜索只需要O(ln n)次探测。"'
- en: 'Not bad. Here''s `HashMap`:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 还不错。这里是`HashMap`：
- en: '[PRE4]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Okay, so, it interacts with `RawTable<K, V>` and we can jump to that definition:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 好吧，所以，它与`RawTable<K, V>`交互，我们可以跳转到那个定义：
- en: '[PRE5]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'But it''s maybe not the most illuminating struct definition either. Common
    operations on a collection are often a good place to dig in, so let''s look at
    `HashMap::insert`:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 但也许这不是最具有启发性的结构定义。集合上的常见操作通常是深入挖掘的好地方，所以让我们看看`HashMap::insert`：
- en: '[PRE6]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'And then on into `HashMap::reserve`:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 然后进入`HashMap::reserve`：
- en: '[PRE7]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Whether `reserve` expands the underlying storage capacity because we''ve got
    near the current total capacity of that storage or to reduce probe lengths, `HashMap::resize`
    is called. That''s:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 是因为我们的存储接近当前总容量，所以`reserve`扩展了底层存储容量，还是为了减少探测长度，`HashMap::resize`被调用。这表示：
- en: '[PRE8]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'We''re back at `RawTable` and have a lead on a structure called `Bucket`:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 我们回到了`RawTable`，并且对名为`Bucket`的结构有了线索：
- en: '[PRE9]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Okay, we''re going in some circles here. The bucket parameterizes the table
    on `M` rather than the table holding some collection of buckets. The `RawBucket`
    is described as an unsafe view of a `RawTable` bucket of which there are two variants—`EmptyBucket`
    and `FullBucket`. These variants are used to populate a `BucketState` enumeration:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 好吧，我们在这里绕了一些圈子。桶参数化表是基于`M`而不是表持有一些桶的集合。`RawBucket`被描述为`RawTable`桶的不安全视图，其中有两个变体——`EmptyBucket`和`FullBucket`。这些变体用于填充`BucketState`枚举：
- en: '[PRE10]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Here, we can see it being used back in `HashMap::insert_hashed_ordered`:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到它在`HashMap::insert_hashed_ordered`中被使用：
- en: '[PRE11]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'If we explore down into `empty.push(hash, k, v)`, we find ourselves at the
    following:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们深入到`empty.push(hash, k, v)`，我们会发现以下内容：
- en: '[PRE12]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Tidy. `ptr::write(self.raw.pair(), (key, value))` demonstrates that we''re
    working with a structure built out of raw memory pointer manipulation, befitting
    a structure that will see a lot of use in critical `paths`. `self.raw.pair()`,
    which returns the appropriate offset to move `(key, value)` into, matching the
    `HashMap::insert` move semantics we''re already familiar with. Take a look at
    the definition of `RawBucket`:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 整洁。`ptr::write(self.raw.pair(), (key, value))`展示了我们正在使用由原始内存指针操作构建的结构，这对于将在关键`路径`中大量使用的结构来说很合适。`self.raw.pair()`返回将`(key,
    value)`移动到其中的适当偏移量，与我们已经熟悉的`HashMap::insert`移动语义相匹配。看看`RawBucket`的定义：
- en: '[PRE13]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Here, we''ve got two raw pointers:  `hash_start` and `pair_start`. The former
    is the first location in memory of our stored pairs'' hashes, the latter is the
    first location in the memory of the pairs. What this ends up being is contiguous
    storage in memory of two sets of data, which is about what you''d expect. The
    table module documentation refers to this approach as *unzipped* arrays. `RawTable`
    holds the capacity and the data, kind of. In reality, the data held by `RawTable`
    is carefully placed in memory, as we''ve seen, but there''s no *owner* as the
    Rust type system understands it. That''s where `marker: marker::PhantomData<(K,
    V)>` comes in. `PhantomData` instructs the compiler to behave as if `RawTable<K,
    V>` owns pairs of `(K, V)`, even though with all the unsafe pointer manipulation
    we''re doing that can''t actually be proven by Rust. We human observers can determine
    by inspection that `RawTable` owns its data via `RawTable::raw_bucket_at` as it
    computes where in memory the data exists:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '这里，我们有两个原始指针：`hash_start`和`pair_start`。前者是我们存储对哈希的第一个内存位置，后者是对的。这对数据在内存中是连续存储的，这正如你所期望的。表模块文档将这种方法称为*未压缩*数组。`RawTable`持有容量和数据，某种程度上。实际上，`RawTable`持有的数据被仔细地放置在内存中，正如我们所看到的，但没有*所有者*，正如Rust类型系统所理解的那样。这就是`marker:
    marker::PhantomData<(K, V)>`的作用。`PhantomData`指示编译器表现得好像`RawTable<K, V>`拥有`(K,
    V)`对，尽管由于我们正在进行的所有不安全指针操作，这实际上不能通过Rust来证明。我们可以通过检查确定`RawTable`通过`RawTable::raw_bucket_at`拥有其数据，因为它计算数据在内存中的位置：'
- en: '[PRE14]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Well, by inspection and testing, as you can see at the bottom of the module.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 好吧，通过检查和测试，正如您可以在模块底部看到的那样。
- en: Naive HashMap
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 简单的 HashMap
- en: How else could we implement an associative array in Rust and how would it compare
    to standard library's `HashMap`? The standard library `HashMap` is clever, clearly,
    storing just enough information to reduce the total probes from ideal offsets
    by sharing information between modifications to the underlying table. In fact,
    the comments in the table module assert that the design we've just worked through
    is *a lot faster* than a table structured as `Vec<Option<(u64, K, V)>>`—where
    `u64` is the key hash, but presumably still using Robin Hood hashing and linear
    probing. What if we went even simpler? We'll support only two operations—`insert`
    and `lookup`—to keep things straightforward for ourselves. We'll also keep more
    or less the same type constraints as `HashMap` so we compare similar things.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还能如何实现 Rust 中的关联数组，它与标准库中的 `HashMap` 又将如何比较？显然，标准库的 `HashMap` 是巧妙的，它只存储足够的信息来减少从理想偏移量到总探测次数，通过在底层表的修改之间共享信息来实现。实际上，表模块中的注释断言，我们刚刚完成的设计与作为
    `Vec<Option<(u64, K, V)>>` 结构的表相比要快得多——其中 `u64` 是键哈希，但可能仍然使用 Robin Hood 哈希和线性探测。如果我们做得更简单会怎样呢？我们将只支持两种操作——`insert`
    和 `lookup`——以保持事情简单明了。我们还将保持与 `HashMap` 类似的大致类型约束，以便比较类似的事物。
- en: 'Start a new Rust project called `naive_hashmap`:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 开始一个新的 Rust 项目，命名为 `naive_hashmap`：
- en: '[PRE15]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Edit `naive_hashmap/Cargo.toml` to look like so:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 编辑 `naive_hashmap/Cargo.toml` 以看起来像这样：
- en: '[PRE16]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Don''t worry too much right now about some of the development dependencies,
    they''ll be explained in due course. Please note that in the following discussion
    we will run compilation commands against the project before all the code has been
    discussed. If you are following along with the book''s pre-written source code
    open already, you should have no issues. If you are writing the source out as
    the book goes along, you will need to comment targets out. Now, open `naive_hashmap/src/lib.rs`
    and add the following preamble:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 目前不必过于担心一些开发依赖项，它们将在适当的时候解释。请注意，在接下来的讨论中，我们将在所有代码讨论之前对项目运行编译命令。如果您正在跟随书中预先编写的源代码，应该没有问题。如果您在书中进行编写，则需要注释掉目标。现在，打开
    `naive_hashmap/src/lib.rs` 并添加以下前言：
- en: '[PRE17]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Most crate roots begin with a fairly long preamble, and `naive_hashmap` is
    no exception. Next up, our `HashMap` struct:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数 crate 根开始都有一个相当长的前言，`naive_hashmap` 也不例外。接下来是我们的 `HashMap` 结构：
- en: '[PRE18]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'How does our naive `HashMap` differ from the standard library''s `HashMap`
    we''ve seen so far? The naive implementation maintains the parameterized hasher
    and type constraints, plus a constraint on `V` to implement the `Debug` trait
    for ease of fiddling. The primary difference, in terms of underlying structure,
    is the use of a `Vec`—as called out in the comments of the standard library `HashMap`—but
    without an `Option` wrapper. We''re not implementing a delete operation so there''s
    no reason to have an `Option` but, even if we were, the plan for this implementation
    would be to rely solely on `Vec::remove`. The fact that it is less than ideal
    that `Vec::remove` shifts all elements from the right of the removal index to
    the left should be well understood. Folks, this won''t be a fast implementation.
    Now:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的简单 `HashMap` 与我们迄今为止看到的标准库 `HashMap` 有何不同？简单实现维护了参数化哈希器和类型约束，以及 `V` 实现的 `Debug`
    特性约束，以便于调整。在底层结构方面，主要区别在于使用了 `Vec`——正如标准库 `HashMap` 的注释所指出的——但没有使用 `Option` 包装器。我们不实现删除操作，因此没有必要使用
    `Option`，即使我们这样做，这个实现的计划也将完全依赖于 `Vec::remove`。`Vec::remove` 将移除索引右侧的所有元素向左移动的事实应该被充分理解。朋友们，这不会是一个快速的实现。现在：
- en: '[PRE19]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Our naive implementation is following along with the standard library here,
    implementing a `HashMap` that is parameterized on `RandomState`—so users don't
    have to think about the underlying hasher—and in which the hasher is swappable,
    via `HashMap::with_hasher`. The Rust team chose to implement `RandomState` in
    terms of a verified cryptographically secure hash algorithm, befitting a language
    that is intended for use on the public internet. Some users won't desire this
    property—opting instead for a much faster, potentially vulnerable hash—and will
    swap `RandomState` out for something else. Our naive `HashMap` retains this ability.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的朴素实现在这里遵循标准库，实现了一个参数化为`RandomState`的`HashMap`——这样用户就不必考虑底层的哈希器——并且哈希器可以通过`HashMap::with_hasher`进行交换。Rust团队选择以经过验证的密码学安全哈希算法来实现`RandomState`，这对于一个打算在公共互联网上使用的语言来说很合适。一些用户可能不会希望这个属性——而是选择一个更快、可能存在漏洞的哈希算法——并将`RandomState`替换为其他东西。我们的朴素`HashMap`保留了这种能力。
- en: 'Let''s examine insertion into our naive `HashMap`:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们检查我们的朴素`HashMap`的插入操作：
- en: '[PRE20]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Our naive implementation maintains the API of the standard library `HashMap`
    but that''s about it. The key is hashed and then a linear search is done through
    the entire data store to find an index in that store where one of two conditions
    hold:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的朴素实现保持了标准库`HashMap`的API，但仅此而已。键被哈希处理，然后在整个数据存储中进行线性搜索以找到满足以下两个条件之一的索引：
- en: Our new hash is greater than some hash in the store, in which case we can insert
    our key/value pair
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们的新哈希值大于存储中的某个哈希值，在这种情况下，我们可以插入我们的键值对
- en: Our new hash is equal to some hash in the store, in which case we can replace
    the existing value
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们的新哈希值等于存储中的某个哈希值，在这种情况下，我们可以替换现有的值
- en: 'Key/value pairs are stored in terms of their ordered hashes. The expense of
    an insert includes:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 键值对按照它们的有序哈希值存储。插入的开销包括：
- en: Hashing the key
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对键进行哈希处理
- en: Searching for the insert index, a linear operation to the number of stored key/value
    pairs
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 搜索插入索引，这是一个与存储的键值对数量成线性关系的操作
- en: Potentially shifting key/value pairs in memory to accommodate a new key to the
    store
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可能将内存中的键值对进行移位以适应存储中新的键
- en: 'Lookup follows a similar scheme:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 查找遵循类似的方案：
- en: '[PRE21]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The key is hashed and a linear search is done for that exact hash in storage.
    Here, we only pay the cost for:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 键被哈希处理，并在存储中进行针对该特定哈希值的线性搜索。在这里，我们只支付以下成本：
- en: Hashing the key
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对键进行哈希处理
- en: Searching for the retrieval offset, if one exists
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果存在，搜索检索偏移量
- en: 'Let''s take a moment and consider this before asking ourselves if our program
    is *fast* if it is *correct*. The usual way of demonstrating fitness for purpose
    of software is through unit testing, a minimal setup for which is built right
    into the Rust language. Unit testing is two processes wrapped into a single method.
    When writing unit tests, a programmer will:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们询问程序是否*快速*且*正确*之前，让我们花点时间考虑这一点。证明软件适用性的通常方式是通过单元测试，Rust语言中直接内置了这种最小设置。单元测试是两个过程封装在一个方法中。当编写单元测试时，程序员将：
- en: Produce *example data* that exercises some code path in the software
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成*示例数据*以测试软件中的某些代码路径
- en: Write further code to demonstrate that when the example data is applied to the
    system under test, a desirable property/properties holds
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 编写更多代码以证明当示例数据应用于测试的系统时，存在一个或多个期望的属性
- en: This is a good testing methodology for demonstrating that the happy path of
    a system under test works as expected. The weak point of unit testing comes in
    the first process, where the programmer must think very hard and produce an example
    dataset that exercises the correct code paths, demonstrates the lack of edge cases,
    and so on. Human beings are poor at this task, owing to it being tedious, biased
    toward demonstrating the functioning of a thing made by one's own hands, chronic
    blind spots, or otherwise. What we *are* pretty good at doing is cooking up high-level
    properties for our systems that must always hold or hold in particular situations.
    Fortunately for us programmers, *computers* are exceptionally good at doing tedious,
    repetitive tasks and the generation of example data for tests is such a thing.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个很好的测试方法，用于证明被测试系统的“快乐路径”按预期工作。单元测试的弱点在于第一个过程，程序员必须非常努力地思考并生成一个示例数据集，以锻炼正确的代码路径，证明没有边缘情况，等等。人类在这方面做得不好，因为这项任务很繁琐，倾向于证明自己亲手制作的东西的功能，存在慢性盲点，或者其它原因。我们*擅长*做的是为我们的系统制定高级属性，这些属性必须始终成立或在特定情况下成立。幸运的是，对于程序员来说，*计算机*在执行繁琐、重复的任务以及为测试生成示例数据方面非常出色。
- en: Testing with QuickCheck
  id: totrans-89
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用QuickCheck进行测试
- en: 'With that in mind, in this book, we''ll make extensive use of *property-based*
    testing, also called *generative* testing by some literature. Property-based testing
    has a slightly different, if similar, workflow to unit testing. When writing property
    tests, the programmer will:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到这一点，在这本书中，我们将广泛使用*基于属性的测试*，某些文献也称之为*生成性测试*。基于属性的测试与单元测试有略微不同但相似的流程。当编写属性测试时，程序员将：
- en: Produce a method for generating valid inputs to a system under test
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为被测试系统生成有效输入的方法
- en: Write further code to demonstrate that for all valid inputs that a desirable
    property or property of the system holds
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 编写更多代码来证明对于所有有效的输入，系统的一个期望属性或属性始终成立
- en: 'Property-based testing is exceptionally good at finding corner cases in software,
    wacky inputs that the programmer might not have dreamed up, or, as happens from
    time to time, even understand as potentially problematic. We''ll use Andrew Gallant''s
    QuickCheck, a tool that is patterned from Haskell QuickCheck, introduced by Koen
    Claessen and John Hughes in their 2000 *QuickCheck: A Lightweight Tool for Random
    Testing of Haskell Programs*. First, a little preamble to get us into the testing
    module:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '基于属性的测试在发现软件中的边缘情况方面非常出色，这些边缘情况是程序员可能没有想到的，或者，有时甚至不理解为潜在的问题。我们将使用Andrew Gallant的QuickCheck，这是一个从Haskell
    QuickCheck模式而来的工具，由Koen Claessen和John Hughes在2000年的论文《QuickCheck: A Lightweight
    Tool for Random Testing of Haskell Programs》中介绍。首先，一些前言，以便我们进入测试模块：'
- en: '[PRE22]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'If we were to unit test our naive `HashMap`, we''d probably write a test where
    a particular arbitrary key/value pair would be inserted and then we''d assert
    the ability to retrieve the same value with that same key. How does this map to
    property-based testing? The property is that if we perform an insertion on an
    empty `HashMap` with a key `k` of value `v` and immediately perform a retrieval
    of `k`, we''ll receive `v` back out. Here it is:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们要对我们的简单`HashMap`进行单元测试，我们可能会编写一个测试，在其中插入一个特定的任意键/值对，然后断言能够使用相同的键检索相同的值。这与基于属性的测试有何关联？属性是，如果我们对一个空的`HashMap`执行插入操作，键为`k`，值为`v`，然后立即检索`k`，我们将返回`v`。下面是具体做法：
- en: '[PRE23]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'The test is named `get_what_you_give` and is annotated `#[test]` as per usual
    Rust tests. What''s different is this test has a property `inner` function that
    encodes the property we elaborated on earlier and a call out to QuickCheck for
    actually running the property test, by default 100 times, with different inputs.
    Exactly how QuickCheck manages this is pretty swell. Per the Claessen and Hughes
    paper, QuickCheck implements the `Arbitrary` trait for many of the types available
    in the standard library. QuickCheck defines `Arbitrary` like so, in `quickcheck/src/arbitrary.rs` :'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 测试名为`get_what_you_give`，并按照惯例用`#[test]`进行注释。不同之处在于这个测试有一个名为`inner`的属性函数，它编码了我们之前详细阐述的属性，并调用QuickCheck来实际运行属性测试，默认情况下100次，使用不同的输入。QuickCheck如何管理这一点非常出色。根据Claessen和Hughes的论文，QuickCheck为标准库中许多类型实现了`Arbitrary`特质。QuickCheck定义`Arbitrary`如下，在`quickcheck/src/arbitrary.rs`中：
- en: '[PRE24]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The `Gen` parameter is a wrapper around `rand:Rng` with some extra machinery
    for controlling distributions. The two functions are `arbitrary` and `shrink`.
    The purpose of `arbitrary` is easy to explain: it generates new, random instances
    of a type that is `Arbitrary`. The `shrink` function is a little more complicated
    to get across. Let''s say we''ve produced a function that takes a vector of `u16` but
    just so happens to have a bug and will crash if a member of the vector is `0`.
    A QuickCheck test will likely find this but the first arbitrary vector it generates
    may have a thousand members and a bunch of `0` entries. This is not a very useful
    failure case to begin diagnosis with. After a failing case is found by QuickCheck
    the case is shrunk, per the definition of `Arbitrary::shrink`. Our hypothetical
    vector will be cut in half and if that new case is also a failure then it''ll
    be shrunk by half again and so on until it no longer fails, at which point—hopefully—our
    failing case is a much more viable diagnosis tool.'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '`Gen` 参数是 `rand:Rng` 的包装器，包含一些额外的机制来控制分布。这两个函数是 `arbitrary` 和 `shrink`。`arbitrary`
    的作用很容易解释：它生成新的、随机的 `Arbitrary` 类型实例。`shrink` 函数稍微复杂一些。假设我们已生成一个接受 `u16` 向量的函数，但恰好有一个错误，如果向量中的某个成员是
    `0`，它就会崩溃。QuickCheck 测试可能会找到这个问题，但第一个生成的任意向量可能有上千个成员和许多 `0` 条目。这不是一个非常有用的失败案例来开始诊断。一旦
    QuickCheck 找到失败的案例，根据 `Arbitrary::shrink` 的定义，该案例将被收缩。我们的假设向量将被减半，如果新的案例也是失败的，那么它将再次减半，以此类推，直到它不再失败，此时——希望如此——我们的失败案例将是一个更有用的诊断工具。'
- en: 'The implementation of `Arbitrary` for `u16` is a touch complicated due to macro
    use, but if you squint some, it''ll become clear:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 由于宏的使用，`u16` 的 `Arbitrary` 实现有些复杂，但如果你眯起眼睛看，它就会变得清晰：
- en: '[PRE25]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Arbitrary instances are generated by `unsigned_arbitrary!`, each of which in
    turn generates a shrinker via `unsigned_shrinker!`. This macro is too long to
    reprint here but the basic idea is to remove half of the unsigned integer on every
    shrink again, until zero is hit, at which point give up shrinking.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 通过 `unsigned_arbitrary!` 生成任意实例，每个实例随后通过 `unsigned_shrinker!` 生成一个收缩器。这个宏太长了，无法在这里重印，但基本思路是在每次收缩时移除无符号整数的一半，直到达到零，此时放弃收缩。
- en: 'Fifteen years after the original QuickCheck paper, John Hughes summarized his
    experience in the intervening 15 years with his 2016 *Experiences with QuickCheck:
    Testing the Hard Stuff and Staying Sane*. Hughes noted that many property-based
    tests in the wild don''t generate primitive types. The domain of applications
    in which primitive types are sufficient tends to be those rare, blessed pure functions
    in a code base. Instead, as many functions in a program are inherently stateful,
    property-based tests tend to generate arbitrary *actions* against a stateful system,
    *modeling* the expected behavior and validating that the system under test behaves
    according to its model.'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '在原始 QuickCheck 论文发表后的 15 年里，John Hughes 总结了他在接下来的 15 年中的经验，并在他的 2016 年论文 *Experiences
    with QuickCheck: Testing the Hard Stuff and Staying Sane* 中进行了总结。Hughes 指出，野外许多基于属性的测试并不生成原始类型。原始类型足够的应用领域往往是代码库中那些罕见的、受祝福的纯函数。相反，由于程序中的许多函数本质上是状态性的，基于属性的测试倾向于生成对状态系统的任意
    *动作*，*模拟* 预期的行为，并验证被测试的系统是否按照其模型行为。'
- en: 'How does that apply to our naive `HashMap`? The system under test is the naive
    HashMap, that''s clear enough. Our actions are:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 这如何应用到我们的天真 `HashMap` 上？被测试的系统是天真 HashMap，这很清楚。我们的动作是：
- en: '`INSERT` key value'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`INSERT` 键值'
- en: '`LOOKUP` key'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`LOOKUP` 键'
- en: 'Hopefully, that''s straightforward. What about a model? In this particular
    instance, we''re in luck. Our model is written for us: the standard library''s
    `HashMap`. We need only confirm that if the same actions are applied to both our
    naive `HashMap` and the standard `HashMap` in the same order then we''ll get the
    same returns from both the model and system under test. How does that look? First,
    we need actions:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 希望这很简单。那么模型呢？在这个特定的情况下，我们很幸运。我们的模型已经为我们编写好了：标准库的 `HashMap`。我们只需要确认，如果将相同的动作按相同的顺序应用到我们的天真
    `HashMap` 和标准 `HashMap` 上，那么模型和被测试系统将得到相同的返回值。这看起来如何？首先，我们需要动作：
- en: '[PRE26]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Our `Action<T>` is parameterized on a `T: Arbitrary` and all values via the
    Insert are pegged as `u16`s. This is done primarily for convenience''s sake. Both
    key and value could be arbitrary or concrete types, depending on the preference
    of the tester. Our `Arbitrary` definition is as follows:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '我们的`Action<T>`在`T: Arbitrary`上参数化，并且所有通过插入操作传递的值都被标记为`u16`。这样做主要是为了方便。键和值可以是任意类型或具体类型，具体取决于测试者的偏好。我们的`Arbitrary`定义如下：'
- en: '[PRE27]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Either action is equally likely to happen and any instance of `T` or `u16`
    is valid for use. The validation of our naive `HashMap` against the standard library''s
    `HashMap`:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 任何操作发生的可能性都是相同的，并且`T`或`u16`的任何实例都可以用于。我们对原始`HashMap`与标准库中的`HashMap`的验证：
- en: '[PRE28]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Hopefully, this looks familiar to our previous QuickCheck test. Again, we have
    an inner property function that does the actual work and we request that QuickCheck
    run this property test over arbitrary vectors of `Action<u8>`. For every action
    present in the vector we apply them to both the model and the system under test,
    validating that the results are the same. The `u8` type was intentionally chosen
    here compared to a large domain type such as `u64.` One of the key challenges
    of writing QuickCheck tests is probing for extremely unlikely events. QuickCheck
    is blind in the sense that it's possible for the same path to be chosen through
    the program for each run if that path is the most likely path to be chosen. While
    millions of QuickCheck tests can give high confidence in fitness for purpose the
    blind nature of the runs means that QuickCheck should also be paired with tools
    known as fuzzers. These do not check the correct function of a program against
    a model. Instead, their sole purpose is to validate the absence of program crashes.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 希望这看起来与我们的先前的QuickCheck测试相似。再次强调，我们有一个内部属性函数执行实际工作，并要求QuickCheck在任意的`Action<u8>`向量上运行这个属性测试。对于向量中存在的每个操作，我们将它们应用于模型和被测试的系统，验证结果是否相同。这里故意选择了`u8`类型，而不是像`u64`这样的大域类型。编写QuickCheck测试的一个关键挑战是探测极端不可能发生的事件。QuickCheck是盲目的，因为如果某个路径是最可能被选择的路径，那么每次运行都可能会选择相同的路径。虽然数百万的QuickCheck测试可以提供对用途适用性的高信心，但运行的无视性质意味着QuickCheck也应该与称为模糊测试器的工具一起使用。这些工具不会检查程序的正确功能与模型是否一致。相反，它们的唯一目的是验证程序崩溃的缺失。
- en: Testing with American Fuzzy Lop
  id: totrans-114
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用美国模糊跳蚤进行测试
- en: 'In this book, we''ll make use of American Fuzzy Lop, a best-of-breed fuzzer
    commonly used in other systems languages. AFL is an external tool that takes a
    corpus of inputs, an executable that reads inputs from `STDIN`, and mutates the
    corpus with a variety of heuristics to find crashing inputs. Our aim is to seek
    out crash bugs in naive `HashMap`, this implies that we''re going to need some
    kind of program to run our `HashMap` in. In fact, if you''ll recall back to the
    project''s `Cargo.toml`, we already had the infrastructure for such in place:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 在这本书中，我们将使用美国模糊跳蚤（American Fuzzy Lop），这是一种在其他系统语言中广泛使用的最佳模糊测试工具。AFL是一个外部工具，它接受输入数据集、从`STDIN`读取输入的可执行文件，并使用各种启发式方法对数据集进行变异以找到崩溃的输入。我们的目标是寻找原始`HashMap`中的崩溃错误，这意味着我们需要某种程序来运行我们的`HashMap`。实际上，如果你还记得项目的`Cargo.toml`文件，我们已经为此建立了基础设施：
- en: '[PRE29]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'The source for `naive_interpreter` is a little goofy looking but otherwise
    uneventful:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '`naive_interpreter`的源代码看起来有点古怪，但除此之外并无异常：'
- en: '[PRE30]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Lines are read from `stdin`, and these lines are split along spaces and interpreted
    as commands, either `LOOKUP` or `INSERT` and these are interpreted into actions
    on the naive `HashMap`. The corpus for an AFL run can live pretty much anywhere.
    By convention, in this book we''ll store the corpus in-project in a top-level
    resources/directory. Here''s `resources/in/mixed_gets_puts`:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 行从`stdin`读取，这些行沿空格分割并解释为命令，要么是`LOOKUP`要么是`INSERT`，这些命令被解释为对原始`HashMap`的操作。AFL运行的数据集可以几乎存储在任何地方。按照惯例，在这本书中，我们将数据集存储在项目的顶层`resources/directory`目录中。这里是`resources/in/mixed_gets_puts`：
- en: '[PRE31]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'The larger your input corpus, the more material AFL has to mutate and the faster—maybe—you''ll
    find crashing bugs. Even in a case such as naive `HashMap` where we can be reasonably
    certain that there will be no crashing bugs—owing to the lack of pointer manipulation
    and potentially fatal integer operations—it''s worthwhile building up a good corpus
    to support future efforts. After building a release of the project, getting an
    AFL run going is a cargo command away:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 您的输入语料库越大，AFL可以变异的材料就越多，也许您会发现崩溃的漏洞越快。即使在像简单的`HashMap`这样的情况下，我们可以合理地确信不会有崩溃的漏洞——由于缺乏指针操作和可能致命的整数运算——建立良好的语料库来支持未来的努力也是值得的。在构建项目的发布版本后，启动AFL运行只需一个cargo命令：
- en: '[PRE32]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'This says to execute `target/release/naive_interpreter` under AFL with input
    corpus at `resources/in` and to output any failing cases under `resources/out`.
    Such crashes often make excellent unit tests. Now, the trick with fuzzing tools
    in general is they''re not part of any kind of quick-cycle test-driven development
    loop. These tool runs are long and often get run on dedicated hardware overnight
    or over many days. Here, for example, is the AFL run I had going while writing
    this chapter:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 这表示在AFL下执行`target/release/naive_interpreter`，输入语料库位于`resources/in`，并将任何失败的案例输出到`resources/out`。这样的崩溃通常是非常好的单元测试。现在，模糊工具的一般技巧是它们不是任何快速循环测试驱动开发循环的一部分。这些工具运行时间很长，通常在专用硬件上过夜或持续多天。例如，这是我在编写本章时进行的AFL运行：
- en: '![](img/8b4a6366-3c4e-4fa5-80fc-182300d5a773.png)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8b4a6366-3c4e-4fa5-80fc-182300d5a773.png)'
- en: There's a fair bit of information here but consider that the AFL runtime indicator
    is measured in days. One key advantage to the use of AFL compared to other fuzzers
    is the prominence of AFL in the security community. There are a good many papers
    describing its implementation and the interpretation of its, uh, *comprehensive*
    interface. You are warmly encouraged to scan the *Further reading* section of
    this chapter for more information.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有很多信息，但请考虑AFL运行时指标是以天为单位的。与其他模糊器相比，使用AFL的一个关键优势是AFL在安全社区中的突出地位。有许多论文描述了其实现及其，嗯，*全面*的接口。强烈建议您浏览本章的*进一步阅读*部分以获取更多信息。
- en: Performance testing with Criterion
  id: totrans-126
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Criterion进行性能测试
- en: 'We can now be fairly confident that our naive `HashMap` has the same behavior
    as the standard library for the properties we''ve checked. But how does the runtime
    performance of naive `HashMap` stack up? To answer this, we''ll write a benchmark,
    but not a benchmark using the unstable Bencher subsystem that''s available in
    the nightly channel. Instead, we''ll use Jorge Aparicio''s criterion—inspired
    by the Haskell tool of the same name by Bryan O''Sullivan—which is available on
    stable and does statistically valid sampling of runs. All Rust benchmark code
    lives under the top-level `benches/` directory and criterion benchmarks are no
    different. Open `benches/naive.rs` and give it this preamble:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以相当有信心，我们简单的`HashMap`在已检查的属性上与标准库具有相同的行为。但简单的`HashMap`的运行时性能如何？为了回答这个问题，我们将编写一个基准测试，但不是使用夜间渠道中可用的不稳定Bencher子系统编写的基准测试。相反，我们将使用Jorge
    Aparicio的criterion——受Bryan O'Sullivan同名的Haskell工具的启发——它可在稳定版上使用，并进行了统计上有效的运行采样。所有Rust基准测试代码都位于顶级`benches/`目录下，criterion基准测试也不例外。打开`benches/naive.rs`并给它这个前言：
- en: '[PRE33]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'This benchmark incorporates pseudorandomness to produce an interesting run.
    Much like unit tests, handcrafted datasets in benchmarks will trend towards some
    implicit bias of the author, harming the benchmark. Unless, of course, a handcrafted
    dataset is exactly what''s called for. Benchmarking programs well is a non-trivial
    amount of labor. The `Rng` we use is `XorShift`, a pseudo-random generator known
    for its speed and less cryptographic security. That suits our purposes here:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 这个基准测试通过伪随机性产生有趣的运行。与单元测试类似，基准测试中的手工数据集往往会倾向于作者的某些隐含偏见，从而损害基准测试。除非，当然，手工数据集正是所需的。编写良好的基准测试程序是一项相当繁重的工作。我们使用的`Rng`是`XorShift`，这是一种以速度著称的伪随机生成器，其加密安全性较低。这符合我们的需求：
- en: '[PRE34]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'The first benchmark, named `insert_and_lookup_native`, performs pseudo-random
    insertions and lookups against the naive `HashMap.` The careful reader will note
    that `XorShiftRng` is given the same seed every benchmark. This is important.
    While we want to avoid handcrafting a benchmark dataset, we do want it to be the
    same every run, else the benchmark comparisons have no basis. That noted, the
    rest of the benchmark shouldn''t be much of a surprise. Generate random actions,
    apply them, and so forth. As we''re interested in the times for standard library
    `HashMap` we have a benchmark for that, too:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个基准测试，命名为 `insert_and_lookup_native`，对原始的 `HashMap` 进行了伪随机的插入和查找操作。细心阅读的读者会注意到，`XorShiftRng`
    在每个基准测试中都使用了相同的种子。这很重要。虽然我们希望避免手动制作基准测试数据集，但我们确实希望每次运行时数据集都是相同的，否则基准测试比较就没有依据。值得注意的是，基准测试的其余部分不应该有太多惊喜。生成随机操作，应用它们，等等。由于我们对标准库中的
    `HashMap` 的时间感兴趣，因此我们也为它创建了一个基准测试：
- en: '[PRE35]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Criterion offers, as of writing this book, a method for comparing two functions
    *or* comparing a function run over parameterized inputs but not both. That''s
    an issue for us here, as we''d like to compare two functions over many inputs.
    To that end, this benchmark relies on a small macro called `insert_lookup!`:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写本书时，Criterion 提供了一种比较两个函数的方法，或者比较一个在参数化输入上运行的函数，但不同时比较两者。这在我们这里是个问题，因为我们想比较多个输入上的两个函数。为此，这个基准测试依赖于一个名为
    `insert_lookup!` 的小宏：
- en: '[PRE36]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'The meat here is we create two `Fun` for comparison called `naive` and `standard,`
    then use `Criterion::bench_functions` to run a comparison between the two. In
    the invocation of the macro, we evaluate `insert_and_lookup_*` from `1` to `100_000`,
    with it being the total number of insertions to be performed against the standard
    and naive `HashMap`s. Finally, we need the criterion group and main function in
    place:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 这里关键是，我们创建了两个用于比较的 `Fun`，分别称为 `naive` 和 `standard`，然后使用 `Criterion::bench_functions`
    运行两个之间的比较。在宏的调用中，我们评估 `insert_and_lookup_*` 从 `1` 到 `100_000`，这是对标准和原始 `HashMap`
    进行插入操作的总数。最后，我们需要设置 criterion 组和主函数：
- en: '[PRE37]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Running criterion benchmarks is no different to executing Rust built-in benchmarks:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 运行 criterion 基准测试与执行 Rust 内置基准测试没有区别：
- en: '[PRE38]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: And so forth. Criterion also helpfully produces gnuplot graphs of your runtimes,
    if gnuplot is installed on your benchmark system. This is highly recommended.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 以此类推。如果基准测试系统中安装了 gnuplot，Criterion 还会友好地生成你的运行时 gnuplot 图形。这强烈推荐。
- en: Inspecting with the Valgrind Suite
  id: totrans-140
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Valgrind 套件进行检查
- en: 'Your specific benchmarking output will likely vary but it''s pretty clear that
    the naive implementation is, well, not very fast. What tools do we have available
    to us to diagnose the issues with our code, guide us toward hot spots for optimization,
    or help convince us of the need for better algorithms? We''ll now leave the realm
    of Rust-specific tools and dip into tools familiar to systems programmers at large.
    If you''re not familiar with them personally that''s a-okay—we''ll describe their
    use and there are plenty of external materials available for the motivated reader.
    Okay, first, we''re going to need some programs that exercise our naive `HashMap`
    and the standard `HashMap`. `naive_interpreter` would work, but it''s doing a
    lot of extra things that''ll muddy the water some. To that end, for examination
    purposes, we''ll need two programs, one to establish a baseline and one for our
    implementation. Our baseline, called `bin/standard.rs`:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 您的特定基准测试输出可能会有所不同，但很明显，原始实现并不快。我们有哪些工具可用来诊断我们代码的问题，引导我们找到优化的热点，或者帮助我们确信需要更好的算法？现在，我们将离开
    Rust 特定工具的领域，深入到系统程序员熟悉的工具。如果您不熟悉它们，那也没关系——我们将描述它们的使用方法，并且对于有志于阅读的读者来说，有大量的外部材料可用。好吧，首先，我们需要一些程序来测试我们的原始
    `HashMap` 和标准 `HashMap`。`naive_interpreter` 可以工作，但它做了很多额外的操作，这可能会使问题复杂化。为此，为了检验目的，我们需要两个程序，一个用于建立基线，一个用于我们的实现。我们的基线，称为
    `bin/standard.rs`：
- en: '[PRE39]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Our test article program is exactly the same, save the preamble is a bit different:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的测试文章程序与之前完全相同，只是前言略有不同：
- en: '[PRE40]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Easy enough and similar in spirit to the benchmark code explored earlier. Now,
    let''s set our baselines. First up, memory allocations:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 这很容易，与之前探索的基准测试代码精神相似。现在，让我们设置基线。首先，内存分配：
- en: '[PRE41]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Seven total allocations, seven total frees, and a grand total of 2,032 bytes
    allocated. Running memcheck against naive has the same result:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 总共分配了七个内存块，释放了七个内存块，总共分配了 2,032 字节。对原始的 memcheck 运行结果相同：
- en: '[PRE42]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'The naive run is noticeably slower, so it''s not allocating memory that kills
    us. As so little memory gets allocated by these programs we''ll skip Valgrind
    massif—it''s unlikely to turn up anything useful. Valgrind cachegrind should be
    interesting though. Here''s baseline:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 原始运行速度明显较慢，所以不是分配内存让我们陷入困境。由于这些程序分配的内存如此之少，我们将跳过Valgrind massif——它不太可能发现任何有用的信息。Valgrind
    cachegrind应该很有趣。以下是基线：
- en: '[PRE43]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Let''s break this up some:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们分拆一下：
- en: '[PRE44]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'The first section details our instruction cache behavior. `I refs: 25,733,614`
    tells us that the standard program executed 25,733,614 instructions in all. This
    is often a useful comparison between closely related implementations, as we''ll
    see here in a bit. Recall that cachegrind simulates a machine with two levels
    of instruction and data caching, the first level of caching being referred to
    as `I1` or `D1` for instruction or data caches and the last level cache being
    prefixed with `LL`. Here, we see the first and last level instruction caches each
    missed around 2,500 times during our 25 million instruction run. That squares
    with how tiny our program is. The second section is as follows:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '第一部分详细说明了我们的指令缓存行为。`I refs: 25,733,614`告诉我们标准程序总共执行了25,733,614条指令。这通常是在密切相关实现之间进行比较的有用方法，正如我们稍后将看到的那样。回想一下，cachegrind模拟了一个具有两级指令和数据缓存的机器，第一级缓存被称为`I1`或`D1`（指令或数据缓存），最后一级缓存以`LL`开头。在这里，我们看到第一级和最后一级指令缓存在我们的2,500万条指令运行中各自缺失了大约2,500次。这与我们的程序如此之小相符。第二部分如下：'
- en: '[PRE45]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'This is the data cache behavior, split into the two cache layers previously
    discussed and further divided into read and writes. The first line tells us that
    5,400,581 total reads and writes were made to the caches, 2,774,345 reads and
    2,626,236 writes. These totals are then further divided by first level and last
    level caches. Here it turns out that the standard library `HashMap` does real
    well, a `D1` miss rate of 5.1% and a `LLd` miss rate of 0.7%. That last percentage
    is key: the higher it is, the more our program is accessing main memory. Doing
    so, as you''ll recall from [Chapter 1](5f3aec9d-fd53-48ff-9ba8-43ce13e91cff.xhtml),
    *Preliminaries – Machine Architecture and Getting Started with Rust*, is painfully
    slow. The third section is as follows:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 这是数据缓存行为，分为之前讨论的两个缓存层，并进一步细分为读取和写入。第一行告诉我们，总共对缓存进行了5,400,581次读取和写入，其中2,774,345次读取和2,626,236次写入。然后这些总数进一步按第一级和最后一级缓存进行划分。这里我们发现标准库的`HashMap`表现很好，`D1`缺失率为5.1%，`LLd`缺失率为0.7%。最后一个百分比是关键：它越高，我们的程序访问主内存的次数就越多。如您在[第1章](5f3aec9d-fd53-48ff-9ba8-43ce13e91cff.xhtml)，“预备知识——机器架构和Rust入门”中回忆的那样，这样做会非常慢。第三部分如下：
- en: '[PRE46]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'This focuses on the combined behavior of data and instruction cache accesses
    to the LL cache. Personally, I don''t often find this section illuminating compared
    to the previously discussed sections. Your mileage may vary. The final section
    is as follows:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 这侧重于数据缓存和指令缓存访问LL缓存的组合行为。就我个人而言，我并不经常发现这一部分与之前讨论的部分相比有启发。您的体验可能会有所不同。最后一部分如下：
- en: '[PRE47]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: This details the branch misprediction behavior of our program. We're drowning
    out the standard library's `HashMap` by branching so extensively in the runner
    program but it will still serve to establish some kind of baseline. The first
    line informs us that 3,008,198 total branches were taken during execution. The
    majority—3,006,105—were conditional branches, branches that jump to a location
    based on some condition. This squares with the number of conditional statements
    we have in the runner. The small majority of branches were indirect, meaning they
    jumped to offsets in memory based on the results of previous instructions. Overall,
    our branch misprediction rate is 10.5%.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 这详细说明了我们程序的分支预测错误行为。在运行程序中，我们通过广泛的分支来淹没标准库的`HashMap`，但这仍然有助于建立某种基线。第一行告诉我们，在执行过程中共进行了3,008,198次分支。其中大多数——3,006,105次——是条件分支，即基于某些条件的跳转。这与我们在运行程序中的条件语句数量相符。少数分支是间接的，意味着它们根据先前指令的结果跳转到内存中的偏移量。总的来说，我们的分支预测错误率是10.5%。
- en: Alright, how does the naive `HashMap` implementation stack up?
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 好吧，原始的`HashMap`实现表现如何？
- en: '[PRE48]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'Already there are some standouts. Firstly, naive executed 15,385,395,657 instructions
    compared to the 25,733,614 of baseline. The naive implementation is simply doing
    much, much more work than that standard library is. At this point, without looking
    at any further data, it''s reasonable to conclude that the program under inspection
    is fundamentally flawed: a rethink of the algorithm is in order. No amount of
    micro-optimization will fix this. But, that was understood; it''s why the program
    is called *naive* to start with. The second major area of concern is that the
    `D1` cache miss rate is just shy of 20% higher than baseline, not to ignore that
    there are simply just more reads and writes to the first level cache than at baseline.
    Curiously, the naive implementation suffers fewer `LLd` cache misses compared
    to baseline—10,494 to 34,105\. No hypothesis there. Skipping on ahead to the branch
    misprediction section, we find that naive stays on-theme and performs drastically
    more branches than standard but with a lower total number of mispredictions. This
    squares with an algorithm dominated by linear seek and compares, as naive is.'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 已经有一些突出的地方。首先，简单实现执行了15,385,395,657条指令，而基准值只有25,733,614条。简单实现实际上比标准库做了多得多的工作。在这个阶段，不查看任何进一步的数据，合理地得出结论：正在检查的程序存在根本性的缺陷：需要重新思考算法。任何微优化都无法解决这个问题。但是，这一点是事先就理解的；这也是为什么程序一开始就被称作“简单”的原因。第二个主要关注点是，`D1`缓存的未命中率比基准值高出近20%，不容忽视的是，与基准值相比，对第一级缓存的读写操作要多得多。奇怪的是，与基准值相比，简单实现受`LLd`缓存未命中的影响更小——10,494比34,105。这里没有假设。跳过分支预测部分，我们发现简单实现保持了主题，并且比标准实现执行了更多的分支，但总的误预测数量较少。这与以线性查找和比较为主的算法相吻合，正如简单实现一样。
- en: Inspecting with Linux perf
  id: totrans-163
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Linux perf进行检测
- en: It's worth keeping in mind that Valgrind's cachegrind is a simulation. If you
    have access to a Linux system you can make use of the perf tool to get real, honest
    numbers about your program's cache performance and more. This is highly recommended
    and something we'll do throughout this book. Like git, perf is many tools arranged
    under a banner—perf—with its own subcommands that have their own options.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，Valgrind的cachegrind是一个模拟。如果你有Linux系统的访问权限，可以使用perf工具获取关于程序缓存性能的真正、真实的数据以及更多。这非常推荐，并且我们将在整本书中这样做。像git一样，perf是一个带有自己子命令和各自选项的工具集——perf。
- en: It is a tool well worth reading the documentation for. Anyhow, what does the
    standard look like under perf?
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个值得阅读文档的工具。无论如何，在perf下标准看起来是什么样的？
- en: '[PRE49]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: How does the naive implementation stand up?
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 简单实现的效果如何？
- en: '[PRE50]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'This squares pretty well with the Valgrind simulation and leads to the same
    conclusion: too much work is being done to insert. Too many branches, too many
    instructions, the well-studied reader will have seen this coming a mile off, it''s
    just worthwhile to be able to put a thing you know to numbers.'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 这与Valgrind模拟的结果相当吻合，并得出相同的结论：插入的工作量过多。分支过多，指令过多，经验丰富的读者会提前看到这一点，但能够将已知的事物用数字表示出来是值得的。
- en: A better naive HashMap
  id: totrans-170
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更好的简单HashMap
- en: 'How can we do better than our naive implementation? Obviously, there''s scope
    for algorithmic improvement—we could implement any kind of probing—but if we''re
    trying to compete with standard library''s HashMap it''s likely that we have a
    specialized reason for doing so. A specialized reason implies we know something
    unique about our data, or are willing to make a trade-off that a general data
    structure cannot. Speaking broadly, the main goals one should have when building
    software at the limit of machine performance are as follows:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何比简单实现做得更好？显然，有算法改进的空间——我们可以实现任何类型的探测——但如果我们要与标准库的HashMap竞争，那么我们很可能有特定的原因。特定的原因意味着我们对我们知道的数据有独特的了解，或者愿意做出一般数据结构无法做出的权衡。广泛地说，在构建接近机器性能极限的软件时，应该有以下主要目标：
- en: Improve the underlying algorithm, reducing total work done.
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 改进底层算法，减少总工作量。
- en: 'Improve cache locality of data accesses. This may mean:'
  id: totrans-173
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提高数据访问的缓存局部性。这可能意味着：
- en: Keeping your working-set in L1 cache
  id: totrans-174
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 保持你的工作集在L1缓存中
- en: Compressing your data to fit better into cache.
  id: totrans-175
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 压缩你的数据以更好地适应缓存。
- en: 'Avoid branch mispredictions. This may mean:'
  id: totrans-176
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 避免分支预测。这可能意味着：
- en: Shaving off branches entirely when possible
  id: totrans-177
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在可能的情况下完全消除分支
- en: Constraining the probability distribution of your branches.
  id: totrans-178
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 限制你分支的概率分布。
- en: How does that apply here? Well, say we knew that for our application `K == u8`
    but we still have an unconstrained `V`. `u8` is a key with low cardinality and
    we ought to be able to trade a little memory to build a faster structure for `u8`
    keys. Unfortunately, Rust does not yet have type specialization in a stable channel.
    Type specialization is *very important* for producing high-performance software
    without breaking abstractions. It allows the programmer to define an abstract
    interface and implementation for such and then, at a later date, specialize some
    of the parameterized types into concrete form with a special purpose implementation.
    Rust RFC 1210 ([https://github.com/rust-lang/rfcs/pull/1210/files#diff-b652f1feca90247198ee29514ac22cf3](https://github.com/rust-lang/rfcs/pull/1210/files#diff-b652f1feca90247198ee29514ac22cf3))
    details how specialization in Rust will work and Rust PR 31844 ([https://github.com/rust-lang/rust/issues/31844](https://github.com/rust-lang/rust/issues/31844))
    tracks the ongoing implementation, which is to say, all of this is only exposed
    in nightly. This chapter sticks to stable and so, unfortunately, we'll need to
    create a new HashMap rather than specializing. The reader is encouraged to try
    out specialization for themselves. It's quite nice.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 这如何应用到我们这里呢？好吧，假设我们知道对于我们的应用程序`K == u8`，但我们仍然有一个不受约束的`V`。`u8`是一个基数低的键，我们应该能够通过牺牲一点内存来为`u8`键构建一个更快的结构。不幸的是，Rust在稳定渠道中还没有类型特殊化。类型特殊化对于在不破坏抽象的情况下生产高性能软件非常重要。它允许程序员定义一个抽象接口和实现，然后在以后，将一些参数化类型专门化为具有特殊目的的实现的具体形式。Rust
    RFC 1210 ([https://github.com/rust-lang/rfcs/pull/1210/files#diff-b652f1feca90247198ee29514ac22cf3](https://github.com/rust-lang/rfcs/pull/1210/files#diff-b652f1feca90247198ee29514ac22cf3))详细说明了Rust中的特殊化将如何工作，Rust
    PR 31844 ([https://github.com/rust-lang/rust/issues/31844](https://github.com/rust-lang/rust/issues/31844))跟踪了正在进行的实现，也就是说，所有这些都只暴露在nightly版本中。这一章坚持使用稳定版本，因此，不幸的是，我们将需要创建一个新的HashMap而不是进行特殊化。鼓励读者亲自尝试特殊化。这相当不错。
- en: 'We''ll park our `HashMapU8` implementation in `naive_hashmap/src/lib.rs`. The
    implementation is quite small:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将`HashMapU8`实现放在`naive_hashmap/src/lib.rs`中。实现相当小：
- en: '[PRE51]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'The idea here is simple—`u8` is a type with such cardinality that we can rework
    every possible key into an array offset. The value for each key is an `Option<V>`,
    `None` if no value has ever been set for the key, and `Some` otherwise. No hashing
    needs to be done and, absent specialization, we drop the type requirements for
    that. Every `HashMapU8` will reserve `256 * ::core::mem::size_of::<Option<V>>()`
    bytes. Being that there''s unsafe code in this implementation, it''s worthwhile
    doing an AFL run to search for crashes. The interpreter for the specialized map
    is similar to the naive interpreter, except that we now take care to parse for
    `u8` keys:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的想法很简单——`u8`是一种具有如此基数的数据类型，我们可以将每个可能的键重新组合成一个数组偏移量。每个键的值是一个`Option<V>`，如果没有为键设置过值，则为`None`，否则为`Some`。不需要进行哈希处理，并且在没有特殊化处理的情况下，我们放弃了该类型的要求。每个`HashMapU8`将保留`256
    * ::core::mem::size_of::<Option<V>>()`字节。鉴于这个实现中存在不安全代码，进行一次AFL运行以搜索崩溃是值得的。专门化映射的解释器与原始解释器类似，只是我们现在注意解析`u8`键：
- en: '[PRE52]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'I''ll spare you the AFL output but, as a reminder, here''s how you run the
    specialized interpreter through:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 我将省略AFL输出，但作为提醒，以下是运行专门解释器的方法：
- en: '[PRE53]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'Producing a criterion benchmark will be very similar to the approach taken
    for the naive implementation, save that we''ll swap out a few names here and there.
    We''ll skip listing the code with the hopes that you''ll be able to reproduce
    it as desired. The results, however, are promising:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 生成标准基准测试的方法将与原始实现的方法非常相似，只是我们会在这里和那里替换一些名称。我们将跳过列出代码，希望你能按照自己的需求进行复现。然而，结果是有希望的：
- en: '[PRE54]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'In a like manner to `naive.rs` and `standard.rs` from previously, we''ve also
    got a `specialized.rs` runner which, to avoid duplication, we''ll avoid listing
    here. Let''s run specialized through Valgrind cachegrind:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 与之前的`naive.rs`和`standard.rs`类似，我们还有一个`specialized.rs`运行器，为了避免重复，我们在这里将不列出。让我们通过Valgrind
    cachegrind运行专门化：
- en: '[PRE55]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'Compared to the standard `valgrind` run, we''re doing around 1/5 the total
    number of instructions and with substantially fewer `D1` and `LLd` misses. No
    surprise here. Our *hash* for `HashMapU8` is an exceedingly cheap pointer offset
    and the size of the storage is going to fit comfortably into the cache. Linux
    perf tells a similar story:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 与标准的`valgrind`运行相比，我们执行的总指令数大约是1/5，并且`D1`和`LLd`缺失的数量也显著减少。这并不奇怪。我们的`HashMapU8`的哈希是一个极其便宜的指针偏移量，存储的大小将舒适地适应缓存。Linux
    perf也有类似的故事：
- en: '[PRE56]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'Phew! Let''s summarize our efforts:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 呼吸！让我们总结一下我们的努力：
- en: '| name | Task Clock (ms) | Instructions | Branches | Branch Misses | Cache
    References | Cache Misses |'
  id: totrans-193
  prefs: []
  type: TYPE_TB
  zh: '| 名称 | 任务时钟（毫秒） | 指令 | 分支 | 分支缺失 | 缓存引用 | 缓存缺失 |'
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-194
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- |'
- en: '| specialized | 1.433884 | 6,141,529 | 749,155 | 59,914 | 74,760 | n/a |'
  id: totrans-195
  prefs: []
  type: TYPE_TB
  zh: '| 专用 | 1.433884 | 6,141,529 | 749,155 | 59,914 | 74,760 | n/a |'
- en: '| standard | 6.923765 | 26,234,708 | 2,802,334 | 290,475 | 635,526 | 67,304
    |'
  id: totrans-196
  prefs: []
  type: TYPE_TB
  zh: '| 标准 | 6.923765 | 26,234,708 | 2,802,334 | 290,475 | 635,526 | 67,304 |'
- en: '| naive | 1323.724713 | 15,390,499,356 | 4,428,637,974 | 204,132 | 455,719,875
    | 21,311 |'
  id: totrans-197
  prefs: []
  type: TYPE_TB
  zh: '| 原始 | 1323.724713 | 15,390,499,356 | 4,428,637,974 | 204,132 | 455,719,875
    | 21,311 |'
- en: Summary
  id: totrans-198
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: What should we understand from all of this? To produce software that operates
    at the edge of the machine's ability, you must understand some important things.
    Firstly, if you aren't measuring your program, you're only guessing. Measuring
    runtime, as criterion does, is important but a coarse insight. *Where is my program
    spending its time?* is a question the Valgrind suite and perf can answer, but
    you've got to have benchmarks in place to contextualize your questions. Measuring
    and then validating behavior is also an important chunk of this work, which is
    why we spent so much time on QuickCheck and AFL. Secondly, have a goal in mind.
    In this chapter, we've made the speed of standard library `HashMap` our goal but,
    in an actual code base, there's always going to be places to polish and improve.
    What matters is knowing what needs to happen to solve the problem at hand, which
    will tell you where your time needs to be spent. Thirdly, understand your machine.
    Modern superscalar, parallel machines are odd beasts to program and, without giving
    a thought to their behaviors, it's going to be tough understanding why your program
    behaves the way it does. Finally, algorithms matter above all else. Our naive
    `HashMap` failed to perform well because it was a screwy idea to perform an average
    O(n/2) operations for every insertion, which we proved out in practice. Standard
    library's `HashMap` is a good, general-purpose structure based on linear probing
    and clearly, a lot of thought went into making it function well for a variety
    of cases. When your program is too slow, rather than micro-optimizing, take a
    step back and consider the problem space. Are there better algorithms available,
    is there some insight into the data that can be exploited to shift the algorithm
    to some other direction entirely?
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该从所有这些中理解什么？为了生产能够在机器能力边缘运行的软件，你必须理解一些重要的事情。首先，如果你没有测量你的程序，你只是在猜测。像criterion那样测量运行时间是很重要的，但这是一个粗略的洞察。*我的程序在哪里花费了时间？*
    是Valgrind套件和perf可以回答的问题，但你必须要有基准来为你的问题提供上下文。测量然后验证行为也是这项工作的重要部分，这就是为什么我们在QuickCheck和AFL上花费了这么多时间。其次，有一个目标在心中。在本章中，我们将标准库`HashMap`的速度作为我们的目标，但在实际的代码库中，总会有需要抛光和改进的地方。重要的是要知道需要做什么来解决当前的问题，这将告诉你你的时间需要花在哪里。第三，了解你的机器。现代的超标量、并行机器编程很奇怪，如果不考虑它们的行为，理解你的程序为什么会以这种方式运行将会很困难。最后，算法是最重要的。我们的原始`HashMap`未能良好地执行，因为我们为每次插入执行平均O(n/2)操作的想法是错误的，我们在实践中证明了这一点。标准库的`HashMap`是一个基于线性探测的通用结构，很明显，在使其适用于各种情况时投入了大量的思考。当你的程序运行得太慢时，与其进行微优化，不如退一步考虑问题空间。是否有更好的算法可用，是否有关于数据的洞察可以用来将算法转向其他方向？
- en: That's performance work in a nutshell. Pretty satisfying, in my opinion.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是性能工作的精髓。在我看来，相当令人满意。
- en: Further reading
  id: totrans-201
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: In this chapter, we covered measuring and improving the performance of a serial
    Rust program while demonstrating the program's fitness for purpose. This is a
    huge area of work and there's a deep well of literature to pull from.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们介绍了如何测量和改进串行Rust程序的性能，同时展示了程序适合其用途。这是一个巨大的工作领域，有大量的文献可供参考。
- en: '*Rust''s std::collections is absolutely horrible*, available at [https://www.reddit.com/r/rust/comments/52grcl/rusts_stdcollections_is_absolutely_horrible/](https://www.reddit.com/r/rust/comments/52grcl/rusts_stdcollections_is_absolutely_horrible/). The
    original poster admitted the title is a bit on the click-baity side but the discussion
    on Reddit is well worth reading. The original author of standard library''s `HashMap`
    weighs in on the design decisions in the implementation.'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Rust的std::collections绝对糟糕*，可在[https://www.reddit.com/r/rust/comments/52grcl/rusts_stdcollections_is_absolutely_horrible/](https://www.reddit.com/r/rust/comments/52grcl/rusts_stdcollections_is_absolutely_horrible/)找到。原文作者承认标题有点吸引点击，但Reddit上的讨论值得一读。标准库`HashMap`的原始作者对实现中的设计决策进行了评论。'
- en: '*Robin Hood Hashing*, 1985, Pedro Celis. This thesis introduced the Robin Hood
    hashing strategy for constructing associative arrays and is the foundation for
    the implementation you''ll find in Rust. The paper also goes into further search
    strategies that didn''t find their way into Rust''s implementation but should
    be of interest to readers with ambitions toward building hashing search structures.'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*罗宾汉哈希法*，1985年，Pedro Celis。这篇论文介绍了用于构建关联数组的罗宾汉哈希策略，是Rust中实现的基础。论文还探讨了没有进入Rust实现但可能对有志于构建哈希搜索结构的读者感兴趣的进一步搜索策略。'
- en: '*Robin Hood hashing*, Emmanuel Goossaert, available at [http://codecapsule.com/2013/11/11/robin-hood-hashing/](http://codecapsule.com/2013/11/11/robin-hood-hashing/).
    The Rust standard library HashMap makes continued reference to this blog post
    and its follow-on, linked in the text. The description here is of a higher-level
    than that of Celis'' thesis and potentially easier to understand as a result.'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*罗宾汉哈希法*，Emmanuel Goossaert，可在[http://codecapsule.com/2013/11/11/robin-hood-hashing/](http://codecapsule.com/2013/11/11/robin-hood-hashing/)找到。Rust标准库的HashMap持续引用这篇博客文章及其后续文章，文中均有链接。这里的描述比Celis的论文更高级，因此可能更容易理解。'
- en: '*Denial of Service via Algorithmic Complexity Attacks*, 2003, Scott Crosby
    and Dan Wallach. This paper outlines a denial of service attack on network services
    by exploiting algorithmic blow-ups in their implementations. The consequence of
    this paper influenced Rust''s decision to ship a safe-by-default HashMap.'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*通过算法复杂性攻击拒绝服务*，2003年，Scott Crosby和Dan Wallach。这篇论文概述了通过利用网络服务实现中的算法爆炸来进行的拒绝服务攻击。这篇论文的后果影响了Rust决定默认提供安全的HashMap。'
- en: '*QuickCheck: Lightweight Tool for Random Testing of Haskell Programs*, 2000,
    Koen Claessen and John Hughes. This paper introduces the QuickCheck tool for Haskell
    and introduces property-based testing to the world. The research here builds on
    previous work into randomized testing but is novel for realizing that computers
    had got fast enough to support type-directed generation as well as shipping with
    the implementation in a single page appendix. Many, many subsequent papers have
    built on this one to improve the probing ability of property testers.'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*QuickCheck：用于Haskell程序随机测试的轻量级工具*，2000年，Koen Claessen和John Hughes。这篇论文介绍了QuickCheck工具用于Haskell，并将基于属性的测试引入了世界。这里的研究建立在之前的随机测试工作之上，但新颖之处在于意识到计算机已经足够快，可以支持类型指导的生成，并在单页附录中提供实现。许多后续论文都基于这一篇来提高属性测试器的探测能力。'
- en: '*An Evaluation of Random Testing*, 1984, Joe Duran and Simeon Ntafos. The 1970s
    and 1980s were an interesting time for software testing. Formal methods were seen
    as being just around the corner and the preferred testing methods relied on intimate
    knowledge of the program''s structure. Duran and Ntafos evaluated the ideal techniques
    of the day against random generation of data and found that randomness compared
    favorably with significantly less programmer effort. This paper put random testing
    on the map.'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*随机测试评估*，1984年，Joe Duran和Simeon Ntafos。20世纪70年代和80年代是软件测试的有趣时期。形式方法被视为即将到来，而首选的测试方法依赖于对程序结构的深入了解。Duran和Ntafos将当时的理想技术与方法随机生成数据进行了比较，发现随机性与显著减少程序员的工作量相比更有优势。这篇论文将随机测试推向了舞台。'
- en: '*Experiences with QuickCheck: Testing the Hard Stuff and Staying Sane*, 2016,
    John Hughes. This paper is a follow-on to the original QuickCheck paper by Claessen
    and Hughes in which Hughes describes his subsequent fifteen years of experience
    doing property testing. The techniques laid out in this paper are a significant
    evolution of those presented in the 2000 paper and well-worth studying by anyone
    doing property tests as a part of their work. That ought to be most people, is
    my take.'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*使用QuickCheck的经验：测试困难的东西并保持理智*，2016年，约翰·休斯。这篇论文是Claessen和休斯最初QuickCheck论文的后续，休斯在其中描述了他随后的十五年在做属性测试方面的经验。这篇论文中阐述的技术是对2000年论文中提出的技术的重要发展，对于任何将属性测试作为其工作一部分的人来说都值得研究。我的看法是，这应该是大多数人。'
- en: '*American Fuzzy Lop website*, available at [http://lcamtuf.coredump.cx/afl](http://lcamtuf.coredump.cx/afl/). AFL
    is the product of a long tail of research into efficiently mutating inputs for
    the purpose of triggering bugs. As of writing this book, it is best of breed and
    has a long trophy list to show for it. The website has links to AFL''s documentation
    and relevant research to understand its function in deeper detail.'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*美国模糊跳鼠网站*，可在[http://lcamtuf.coredump.cx/afl](http://lcamtuf.coredump.cx/afl/)找到。AFL是针对高效变异输入以触发错误的研究成果。截至撰写本书时，它是同类产品中的佼佼者，并拥有长长的奖杯列表。网站提供了AFL的文档和相关研究，以深入了解其功能。'
- en: '*Compact Data Structures: A Practical Approach*, 2016, Gonzalo Navarro. One
    of the major techniques of exploiting cache locality is to shrink the individual
    elements of a working set, implying more elements are available in the working
    set. Compact data structures, those that can be operated on, at, or near their
    information theory minimal representation, is an ongoing and exciting area. Navarro''s
    book is excellent and well-worth studying for anyone who is interested in exploring
    this avenue of optimization.'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*紧凑数据结构：实用方法*，2016年，贡萨洛·纳瓦罗。利用缓存局部性的主要技术之一是缩小工作集的各个元素，这意味着工作集中有更多的元素可用。紧凑数据结构，那些可以在其信息理论最小表示上进行操作的数据结构，是一个持续且令人兴奋的研究领域。纳瓦罗的书籍非常出色，对于任何对探索这一优化途径感兴趣的人来说都值得研究。'
- en: '*vec_map*, various authors. `vec_map` is a Rust crate that exploits the same
    ideas as this chapter''s `HashMapU8` but in a generic implementation, with full
    compatibility to the standard library HashMap. The source code is quite interesting
    and warmly recommended.'
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*vec_map*，多位作者。`vec_map`是一个Rust crate，它利用了本章`HashMapU8`相同的思想，但在一个通用实现中，与标准库HashMap完全兼容。源代码非常有趣，强烈推荐。'
- en: '*Reevaluating Amdahl''s Law*, 1988, John Gustafson. This is an exceptionally
    short paper and clearly explains Amdahl''s formulation as well as Gustafson''s
    objection to its underlying assumptions. That the paper is describing an interpretation
    in which the serial portion is shrunk is clear only after a few readings, or once
    some kind soul explains this to you.'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*重新评估Amdahl定律*，1988年，约翰·古斯塔夫森。这是一篇非常简短的论文，清楚地解释了Amdahl的公式以及古斯塔夫森对其基本假设的反对。只有在阅读了几次之后，或者有人向你解释之后，才能清楚地看出这篇论文描述的是一个将串行部分缩小的解释。'
- en: '*Tracking issue for specialization (RFC 1210)*, available at [https://github.com/rust-lang/rust/issues/31844](https://github.com/rust-lang/rust/issues/31844).This
    issue is a pretty good insight into the way the Rust community goes about stabilizing
    a major feature. The original RFC is from 2016\. Pretty much ever since the point
    it was accepted that there''s been a feature flag in nightly for experimentation
    and a debate on the consequences of making the work stable.'
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*跟踪特殊化问题（RFC 1210）*，可在[https://github.com/rust-lang/rust/issues/31844](https://github.com/rust-lang/rust/issues/31844)找到。这个问题很好地揭示了Rust社区如何稳定一个主要功能的方式。原始的RFC来自2016年。从那时起，几乎每次接受之后，nightly版本中都有一个功能标志用于实验，并且关于使工作稳定的影响的辩论一直在进行。'
