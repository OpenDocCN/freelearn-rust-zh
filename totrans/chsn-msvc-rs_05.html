<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Understanding Asynchronous Operations with Futures Crate</h1>
                </header>
            
            <article>
                
<p>Rust is a modern language and has many approaches and crates that we can use to implement microservices. We can split these into two categories—synchronous frameworks and asynchronous frameworks. If you want to write synchronous microservices, you can implement a handler as a sequence of expressions and methods calls. But writing asynchronous code is hard in Rust, because it doesn't use a garbage collector and you have to take into account the lifetimes of all objects, including callbacks. This is not a simple task, because you can't stop the execution at any line of the code. Instead, you have to write code that won't block the execution for a long period of time. This challenge can be elegantly solved with the <kbd>futures</kbd> crate.</p>
<p>In this chapter, you will learn about how the  <kbd>futures</kbd> crate works. We will study two basic types—<kbd>Future</kbd> and <kbd>Stream</kbd>. We will also explore the <strong>Multi-Producer Single-Consumer</strong> (<strong>MPSC</strong>) module, which is an alternative to a similar module of the <kbd>std</kbd> crate, but supports asynchronous access to channels. <span>At the end of the сhapter, we will create a microservice that uses <kbd>Future</kbd> and <kbd>Stream</kbd> traits to process incoming data and return a processed result to a client.<br/></span></p>
<p><span>The <kbd>futures</kbd> crate contains asynchronous primitives only. We will also use the <kbd>tokio</kbd> crate, which provides asynchronous input and output capabilities to read and write image files for our microservice.</span></p>
<p>We will cover the following topics in this chapter:</p>
<ul>
<li>Basic asynchronous types</li>
<li>Creating an image service</li>
</ul>
<p> </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Technical requirements</h1>
                </header>
            
            <article>
                
<p>This chapter requires Rust installation. We will develop microservices using the <kbd>futures</kbd> and <kbd>tokio</kbd> crates.</p>
<p>You can find the source code of the projects of this chapters on GitHub: <a href="https://github.com/PacktPublishing/Hands-On-Microservices-with-Rust/tree/master/Chapter04">https://github.com/PacktPublishing/Hands-On-Microservices-with-Rust/tree/master/Chapter04</a>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Basic asynchronous types</h1>
                </header>
            
            <article>
                
<p>Microservices can be implemented in two different ways—synchronously and asynchronously. The approach refers to when the next task has to wait for the completion of the current task. To run tasks in parallel using code, we have to run a pool of threads and run tasks in the threads of the pool. The asynchronous approach is when you use non-blocking operations and a single thread performs multiple tasks. If an operation can't be completed, it returns a flag that means the task has not yet completed and we have to try to run it again later.</p>
<p>In the past, Rust developers used synchronous operations only, which meant that if we wanted to read data from a socket, we would have to block an executing thread. Modern operating systems have two approaches to avoid blocking—non-blocking input/output functions, and a scalable I/O event notification system, such as <strong>epoll</strong>.</p>
<p>Asynchronous activity refers to the ability to use the resources of the working for multiple concurrent activities. In contrast to synchronous handlers, asynchronous handlers use non-blocking operations. If resources are not available to finish the handler, it will be suspended until the next attempt to get access to resources. There is a well-established approach that involves a reactor and promises. A reactor allows a developer to run multiple activities in the same thread, while a promise represents a delayed result that will be available later. A reactor keeps a set of promises and continues to poll until it is completed and the result is returned.</p>
<p>Since the standard Rust library doesn't contain useful modules to write asynchronous applications and to work with reactors and promises, you need a third-party crate. An example of this type of crate is the <kbd>futures</kbd> crate, which we have used indirectly by using the <kbd>hyper</kbd> crate. It's now time to explore this crate in detail. In this section, we will discuss the different types of the <kbd>futures</kbd> crate that are available, how to use channels to pass messages between tasks, and how to use reactors, which are needed to run tasks.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Basic types of future crate</h1>
                </header>
            
            <article>
                
<p>The <kbd>futures</kbd> crate was created to provide Rust developers zero-cost abstractions for asynchronous programming. The crate fits the borrowing system of Rust and helps to create types that poll resources and return results when they are available.</p>
<p>For everyday use, you need only a few types of the <kbd>futures</kbd> crate. The three basic types are <kbd>Future</kbd>, <kbd>Stream</kbd>, and <kbd>Sink</kbd>. Let's explore all of these types in detail.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Using the Future trait</h1>
                </header>
            
            <article>
                
<p><kbd>Future</kbd> is a trait that returns a result in the future and represents an operation that can't be completed immediately. Like the <kbd>Result</kbd> enumeration, <kbd>Future</kbd> has two outcome variants that are represented by the associated types <kbd>Item</kbd> and <kbd>Error</kbd>. The trait has a <kbd>poll</kbd> method, which is what retrieves the result. This method will be called by a reactor until it returns <kbd>Error</kbd> or an <kbd>Async::Ready</kbd> value. <kbd>Async</kbd> is an enumeration that has both <kbd>Ready</kbd> and <kbd>Pending</kbd> variants, which are used to represent a result of an asynchronous operation. <kbd>Ready</kbd> means the value is ready to use, while <kbd>Pending</kbd> means the value is not yet available and will be ready later.</p>
<p>As you can see, <kbd>Future</kbd> is used for a similar purpose to <kbd>Result</kbd>. Unlike <kbd>Result</kbd>, however, <kbd>Future</kbd> is a trait, which means the implementation is not specified and many types can implement it. A useful feature is the <kbd>FutureExt</kbd> trait which can be implemented for all the  <kbd>Future</kbd> instances. This has multiple methods to process the result in a delayed manner. For example, if we want to convert an obtained value to another type, the trait has a <kbd>map</kbd> method for this purpose. Take a look at the following:</p>
<pre>let fut = future::ok(10u64);<br/>let mapped_fut = fut.map(|x| x as f64);</pre>
<p>In this example, we created a <kbd>FutureResult</kbd> struct from a constant. This type implements the <kbd>Future</kbd> trait and represents a value that is immediately ready. Afterward, we called the <kbd>map</kbd> method from <kbd>FutureExt</kbd> for <kbd>FutureResult</kbd>, which expects a closure and returns.</p>
<p>You have to use a reactor to get the result for types that implement the <kbd>Future</kbd> trait. We will discuss reactors later in this section. Remember that you can't get the result immediately and use it in the next expression; instead, you have to create chains of futures or streams to get the appropriate result. Keep reading! We will now look into the <kbd>Stream</kbd> trait.</p>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Using the Stream trait</h1>
                </header>
            
            <article>
                
<p><kbd>Stream</kbd> is a trait that represents a sequence of deferred items. It works in a similar way to the <kbd>Iterator</kbd> trait, but it uses the poll method to get the next <kbd>Item</kbd> or to return <kbd>Error</kbd> in the case of failure. The stream can either be incoming data from a socket or data that can be read from a file. <kbd>Stream</kbd> can be converted to <kbd>Future</kbd> and vice versa if the <kbd>Future</kbd> instance returns a <kbd>Stream</kbd>.</p>
<p>To use streams effectively, you should learn the methods of the <kbd>StreamExt</kbd> trait. This lets you make a chain to process every item of the stream or even join multiple streams into one. For example, you can filter some elements from <kbd>Stream</kbd> using the <kbd>filter</kbd> method with a predicate:</p>
<pre class="rust rust-example-rendered"><span class="kw">let</span> <span class="ident">stream</span> <span class="op">=</span> <span class="ident">stream</span>::<span class="ident">iter_ok</span>::<span class="op">&lt;</span>_, ()<span class="op">&gt;</span>(<span class="macro">vec</span><span class="macro">!</span>[-1, 0, <span class="number">1, 2, 3</span>]);<br/>let filtered_stream = stream.filter(|x| x &gt; 0);</pre>
<p>The <kbd>iter_ok</kbd> <span>method</span><span> </span><span>creates a</span> <kbd>Stream</kbd> <span>from the </span><kbd>Iterator</kbd><span>. It is useful if you want to provide your own values from a</span> <kbd>Vec</kbd> <span>instance.</span></p>
<p>A useful feature is the conversion of a <kbd>Future</kbd> instance that contains a <kbd>Stream</kbd> as a result to just a <kbd>Stream</kbd>. For example, when you try to connect by TCP using the <kbd>TcpStream::connect</kbd> method of the <kbd>tokio</kbd> crate, it will return <kbd>ConnectFuture</kbd>, which implements the <kbd>Future</kbd> trait and returns a <kbd>TcpStream</kbd> instance.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Using Sink to send data back</h1>
                </header>
            
            <article>
                
<p><kbd>Future</kbd> and <kbd>Stream</kbd> objects supply data from a source, but if you want to send a piece of data to the source, you have to use <kbd>Sink</kbd> objects. <kbd>Sink</kbd> is a trait that is similar to <kbd>Stream</kbd>, but works in the opposite direction. It contains two associated types—<kbd>SinkItem</kbd> and <kbd>SinkError</kbd>. The first determines the type of item that can be sent using a specific sink. The second represents an error if the sending process goes wrong. To interact with a <kbd>Sink</kbd>, you should use the methods of the <kbd>SinkExt</kbd> trait, which<span> contains</span> <kbd>send</kbd><span> </span><span>methods</span><span> </span><span>to send an item to a recipient. The <kbd>send</kbd> method returns a </span><kbd>Send</kbd> <span>struct that implements</span><span> the </span><kbd>Future</kbd> <span>trait, which means you can't send an item immediately. The call of</span><span> the </span><kbd>send</kbd> <span>methods returns a future that has to be executed with a reactor. If you are not concerned about the result of the sending process, you can use</span><span> the </span><kbd>spawn</kbd> <span>method to send the future in a separate task.</span></p>
<p>The <kbd>Sink</kbd> object comes with <kbd>Stream</kbd> and you have to call the split method of <kbd>StreamExt</kbd> to get an instance of <kbd>Sink</kbd> attached to a stream. This call returns a tuple with both <kbd>SplitSink</kbd> and  <kbd>SplitStream</kbd> objects. These are necessary to let you read an input and write an output concurrently. Later, both of these can be reunited using the <kbd>reunite</kbd> method of any of these objects. If you are writing a complex interaction, you have to use a <kbd>Sink</kbd> trait many times. It's hard to do this using <kbd>split</kbd> every time, but there are two alternative approaches that you can use. The first is to implement all interactions in a separate implementation of the <kbd>Stream</kbd> trait and work with a <kbd>Stream</kbd> and a <kbd>Sink</kbd> using the <kbd>poll</kbd> method. The second approach is to <kbd>split</kbd> a sink and <kbd>join</kbd> it with a <kbd>Receiver</kbd> object of a channel. You can then use a <kbd>Sender</kbd> of this channel to send an item without splitting the stream every time. We will implement an example of this kind of interaction in the next section, in which we will discuss channels.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The channel module</h1>
                </header>
            
            <article>
                
<p>Concurrent activities often need to interact with each other. It's likely that you are already familiar with the <kbd>mpsc</kbd> module of the standard library, which uses blocking operations to send in channels, but this is not suitable for a sophisticated reactor that blocks completely if any operation blocks the working thread. Fortunately, however, there is the <kbd>channel</kbd> module in the <kbd>futures</kbd> crate which is capable of carrying out cross-task communication. The <kbd>channel</kbd> module contains two modules—<kbd>mpsc</kbd> and <kbd>oneshot</kbd>. Let's look at both.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Channels for sending multiple messages</h1>
                </header>
            
            <article>
                
<p>As a rule, channels are a one-way interaction primitive. A channel has a sender to send messages and a receiver to extract messages. Internally, a channel works as an array or list that is protected from data races (when two or more threads try to write the same memory cell) using an atomic flag or lock-free data types. Channels implement one of the queue access patterns we will discuss in the following sections.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Single-Producer Single-Consumer </h1>
                </header>
            
            <article>
                
<p>This approach means that only one producer can send messages and only one consumer can read them. In Rust, this means we have a single <kbd>Sender</kbd> and a single <kbd>Receiver</kbd>, neither of which can be cloned. The standard library has an internal implementation of a <strong>Single-Produce Single-Consumer</strong> (<strong>SPSC</strong>) queue, but this type is not available for users. If you need this type of queue, try the <kbd>bounded-spsc-queue</kbd> crate.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Multi-Producer Single-Consumer</h1>
                </header>
            
            <article>
                
<p>This is the most popular queue type in Rust. Both the standard library and the <kbd>futures</kbd> crate provide this kind of channel. It's popular because channels are often used to provide access to a resource that lives in a single thread for other multiple threads. For this type of queue, the <kbd>Sender</kbd> can be cloned, but the <kbd>Receiver</kbd> can't.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Multi-Producer Multi-Consumer </h1>
                </header>
            
            <article>
                
<p>This type of queue allows us to use a <kbd>Sender</kbd> and a <kbd>Receiver</kbd> with any amount of threads. Both the <kbd>Sender</kbd> and the <kbd>Receiver</kbd> can be cloned and used in multiple threads. If multiple threads read messages from <kbd>Receiver</kbd>, you can't predict which thread will get a specific message. You can find this functionality in the <kbd>crossbeam-channel</kbd> crate.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Example of usage</h1>
                </header>
            
            <article>
                
<p>To send a message from one thread to another, you are likely to use the <kbd>mpsc</kbd> module of the standard library. The <kbd>mpsc</kbd> module of the <kbd>futures</kbd> crate works in a similar way, but the <kbd>Sender</kbd> returns the <kbd>Sink</kbd> instance when you call the <kbd>send</kbd> method to send an item to the message stream. The <kbd>Receiver</kbd> implements the <kbd>Stream</kbd> trait, which means you have to use a reactor to poll the stream for new messages:</p>
<pre>fn multiple() {<br/>    let (tx_sink, rx_stream) = mpsc::channel::&lt;u8&gt;(8);<br/>    let receiver = rx_stream.fold(0, |acc, value| {<br/>        future::ok(acc + value)<br/>    }).map(|x| {<br/>        println!("Calculated: {}", x);<br/>    });<br/>    let send_1 = tx_sink.clone().send(1);<br/>    let send_2 = tx_sink.clone().send(2);<br/>    let send_3 = tx_sink.clone().send(3);<br/>    let execute_all = future::join_all(vec![<br/>        to_box(receiver),<br/>        to_box(send_1),<br/>        to_box(send_2),<br/>        to_box(send_3),<br/>    ]).map(drop);<br/>    drop(tx_sink);<br/>    tokio::run(execute_all);<br/>}</pre>
<p>In this example, we created a channel that delivers messages of the <kbd>u8</kbd> type. We used the <kbd>fold</kbd> method of the <kbd>Receiver</kbd> to add all the values and print the result when the channel is closed. We used the <kbd>Sender</kbd> to <kbd>send</kbd> values to the <kbd>Receiver</kbd>. At the end, we combined all the futures to a single future with the <kbd>future::join_all</kbd> method and passed the resultant future to an executor of the <kbd>tokio</kbd> crate. The <kbd>join_all</kbd> function expects a <kbd>Vec</kbd> of specific types that implements the <kbd>Future</kbd> trait. We added the <kbd>to_box</kbd> function which converts a type into a <kbd>Future</kbd> with the <kbd>IntoFuture</kbd> trait, drops the result and an error, and boxes it:</p>
<pre>fn to_box&lt;T&gt;(fut :T) -&gt; Box&lt;dyn Future&lt;Item=(), Error=()&gt; + Send&gt;<br/>where<br/>    T: IntoFuture,<br/>    T::Future: Send + 'static,<br/>    T::Item: 'static,<br/>    T::Error: 'static,<br/>{<br/>    let fut = fut.into_future().map(drop).map_err(drop);<br/>    Box::new(fut)<br/>}</pre>
<p>To close the <kbd>Sender</kbd>, all we need to do is drop it. If we don't drop the <kbd>Sender</kbd>, the channel remains open and <kbd>tokio::run</kbd> will never finish.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">One-shot</h1>
                </header>
            
            <article>
                
<p>The <kbd>oneshot</kbd> module implements a channel of a single message. It also has its own <kbd>Sender</kbd> and <kbd>Receiver</kbd> types, but these work in a different way. The <kbd>Sender</kbd> has a <kbd>send</kbd> method that completes <kbd>oneshot</kbd> and consumes an instance completely. <kbd>Sender</kbd> doesn't need to implement the <kbd>Sink</kbd> trait, because we can't send multiple items. It has a preallocated cell for an item that will be put into the cell immediately and we don't have any queue.</p>
<p>The <kbd>Receiver</kbd> implements the <kbd>Future</kbd> trait, which means you have to use a reactor to get an item from it:</p>
<pre>fn single() {<br/>    let (tx_sender, rx_future) = oneshot::channel::&lt;u8&gt;();<br/>    let receiver = rx_future.map(|x| {<br/>        println!("Received: {}", x);<br/>    });<br/>    let sender = tx_sender.send(8);<br/>    let execute_all = future::join_all(vec![<br/>        to_box(receiver),<br/>        to_box(sender),<br/>    ]).map(drop);<br/>    tokio::run(execute_all);<br/>}</pre>
<p>In this example, we created a <kbd>Sender</kbd> and a <kbd>Receiver</kbd> for a <kbd>oneshot</kbd> channel. The sender is an object that will be consumed with the <kbd>send</kbd> method call. The <kbd>Receiver</kbd> implements the <kbd>Future</kbd> trait and we can use the <kbd>map</kbd> method to get access to a value.</p>
<p>Previously, we mentioned that we can send messages to <kbd>Sink</kbd> from multiple sources. Let's implement this example using channels.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Using channels to use Sink in multiple places</h1>
                </header>
            
            <article>
                
<p>As mentioned previously, you can use a channel to send data with <kbd>Sink</kbd> from different places and at any time. Look at the following example:</p>
<pre>fn alt_udp_echo() -&gt; Result&lt;(), Error&gt; {<br/>    let from = "0.0.0.0:12345".parse()?;<br/>    let socket = UdpSocket::bind(&amp;from)?;<br/>    let framed = UdpFramed::new(socket, LinesCodec::new());<br/>    let (sink, stream) = framed.split();<br/>    let (tx, rx) = mpsc::channel(16);<br/>    let rx = rx.map_err(|_| other("can't take a message"))<br/>        .fold(sink, |sink, frame| {<br/>            sink.send(frame)<br/>        });<br/>    let process = stream.and_then(move |args| {<br/>        tx.clone()<br/>            .send(args)<br/>            .map(drop)<br/>            .map_err(other)<br/>    }).collect();<br/>    let execute_all = future::join_all(vec![<br/>        to_box(rx),<br/>        to_box(process),<br/>    ]).map(drop);<br/>    Ok(tokio::run(execute_all))<br/>}</pre>
<p>This example creates a <kbd>UdpSocket</kbd> instance that represents a UDP socket and binds it to the <kbd>0.0.0.0:12345</kbd> address. After that, we wrap a socket with the <kbd>UdpFramed</kbd> type, which implements a <kbd>Stream</kbd> of data that is generated with the provided codec. We will use <kbd>LinesCodec</kbd> from the <kbd>tokio::codec</kbd> module. This reads an input and uses a line delimiter to split the data into pieces that represent lines of text.</p>
<p>We will split the framed stream and create a channel to send the UDP datagrams from different places. We will get familiar with the channel module in the next section and learn how tasks can interact with each other asynchronously using the <kbd>Sender</kbd> and <kbd>Receiver</kbd> objects.</p>
<p>The <kbd>channel</kbd> method returns the <kbd>Sender</kbd> and <kbd>Receiver</kbd> objects. We use the <kbd>Receiver</kbd> to forward all incoming messages to a <kbd>Sink</kbd> of the UDP connection and we read all data from the stream and send it back with the channel. This echo server can be implemented more effectively without channels, but we have used them here for demonstrative purposes. To send a message, we used a <kbd>Sender</kbd> of the created channel. The advantage of this approach is that you can clone and use a sender instance everywhere to send messages to a channel at any time. </p>
<p>Sometimes, <kbd>Future</kbd> and <kbd>Stream</kbd> differ with regard to their <kbd>Item</kbd>  or  <kbd>Error</kbd> type parameters. To counteract this, we add an  <kbd>other</kbd> method that wraps any error instance with the <kbd>io::Error</kbd>  type. We use this function to convert one error type to another:</p>
<pre>fn other&lt;E&gt;(err: E) -&gt; io::Error<br/>where<br/>    E: Into&lt;Box&lt;std::error::Error + Send + Sync&gt;&gt;,<br/>{<br/>    io::Error::new(io::ErrorKind::Other, err)<br/>}</pre>
<p>You can compile this echo server and check how it works using the netcat utility. You should install this if your operating system doesn't contain it already. Type the <kbd>nc</kbd> command with the <kbd>--verbose</kbd> (short form: <kbd>-v</kbd>), <kbd>--udp</kbd> (short form: <kbd>-u</kbd>), and <kbd>--no-dns</kbd> (short form: <kbd>-n</kbd>) arguments and enter any text. As an example, we have typed <em>"</em>Text Message<em>"</em>:</p>
<pre><strong>$ nc -vnu 0.0.0.0 12345</strong><br/><strong>Ncat: Version 7.60 ( https://nmap.org/ncat )</strong><br/><strong>Ncat: Connected to 0.0.0.0:12345.</strong><br/><strong>Text Message</strong><br/><strong>Text Message</strong><br/><strong>^C</strong></pre>
<p>As you can see, the server has sent us back the provided string. All these examples used an executor to run the tasks concurrently. Before we start to implement a server, let's learn how executors work.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Executors</h1>
                </header>
            
            <article>
                
<p>Since asynchronous tasks can be executed in a single thread, we need a way to execute all tasks, even if some tasks generate new tasks during execution. There are two approaches to run all tasks:</p>
<ul>
<li>Run futures and collect streams directly with blocking</li>
<li>Use an executor to run futures and streams</li>
</ul>
<p>Let's explore them both in the following sections.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Running futures and streams with blocking</h1>
                </header>
            
            <article>
                
<p>The first approach is to use the <kbd>block_on</kbd> or <kbd>block_on_stream</kbd> functions of the <kbd>executor</kbd> module. Both functions block the current thread to wait for the result. It is a naive approach that is not very flexible, but it is great in the following circumstances:</p>
<ul>
<li>If you have only one task</li>
<li>If none of your tasks read or write streams</li>
<li>If you want to complete the task from a separate thread that can be blocked</li>
</ul>
<p>You should remember that you must not call this function in asynchronous code, because the call will block the executor and your program will stop working.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Using an executor</h1>
                </header>
            
            <article>
                
<p>The second approach is to execute all tasks with an <kbd>Executor</kbd>  instance. This allows you to run multiple tasks in a single thread, even if some tasks can't be completed immediately. To use an <kbd>Executor</kbd>, you have to create and run it, but it will block the current thread and you should add all the necessary tasks to be executed at the start.</p>
<p>For example, if you want to open a socket and process the stream of every incoming connection, you have to create a main <kbd>Future</kbd> that will read the <kbd>Stream</kbd> of incoming connections and spawn a handler for processing the <kbd>Stream</kbd> of the data of the connection using the <kbd>tokio::spawn</kbd> method. After you have created it, you have to <kbd>spawn</kbd> the whole processing future with the executor. Take a look at the following example:</p>
<pre>fn send_spawn() {<br/>    let (tx_sink, rx_stream) = mpsc::channel::&lt;u8&gt;(8);<br/>    let receiver = rx_stream.fold(0, |acc, value| {<br/>        println!("Received: {}", value);<br/>        future::ok(acc + value)<br/>    }).map(drop);<br/>    let spawner = stream::iter_ok::&lt;_, ()&gt;(1u8..11u8).map(move |x| {<br/>        let fut = tx_sink.clone().send(x).map(drop).map_err(drop);<br/>        tokio::spawn(fut);<br/>    }).collect();<br/>    let execute_all = future::join_all(vec![<br/>        to_box(spawner),<br/>        to_box(receiver),<br/>    ]).map(drop);<br/>    tokio::run(execute_all);<br/>}</pre>
<p>In this example, we have created a channel. We have also created a stream from a sequence of integers using the <kbd>stream::iter_ok</kbd> method. We send all items of the stream to the channel, which reads all the incoming values and prints them to a console. We have already dealt with a similar example. In the current version, we use the <kbd>tokio::spawn</kbd> function to spawn a task in an executor of the current thread.</p>
<p>As you can see, to use the <kbd>futures</kbd> crate, you have to build chains of handlers. The resultant code is hard to maintain and improve. To simplify asynchronous code, the Rust compiler has started to support the <kbd>async</kbd>/<kbd>await</kbd> syntax.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The async/await syntax</h1>
                </header>
            
            <article>
                
<p>Some programming languages, such as JavaScript and C#, have <kbd>async</kbd> and <kbd>await</kbd> operators which help to write asynchronous code that looks like synchronous code. The nightly version of the Rust compiler supports a new syntax and adds <kbd>async</kbd> and <kbd>await</kbd> (actually, this is a macro) keywords to the language to simplify the writing of asynchronous applications. The new code might look as follows:</p>
<pre>async fn http_get(addr: &amp;str) -&gt; Result&lt;String, std::io::Error&gt; {<br/>    let mut conn = await!(NetwrokStream::connect(addr))?;<br/>    let _ = await!(conn.write_all(b"GET / HTTP/1.0\r\n\r\n"))?;<br/>    let mut buf = vec![0;1024];<br/>    let len = await!(conn.read(&amp;mut buf))?;<br/>    let res = String::from_utf8_lossy(&amp;buf[..len]).to_string();<br/>    Ok(res)<br/>}</pre>
<p>This is not stable yet and may be changed before release. <kbd>async</kbd> is a new keyword that converts a standard function to asynchronous. <kbd>await!</kbd> is a macro that is built in in unstable Rust versions. It suspends the execution of a function and waits for the result from a <kbd>Future</kbd> instance provided to <kbd>await!</kbd> as argument. This macro uses the generators feature to interrupt execution until the <kbd>Future</kbd> under <kbd>await!</kbd> has been completed.</p>
<p>In the remaining part of this chapter, we are going to look at a proxy that uses streams to process incoming and outgoing data.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Creating an image service</h1>
                </header>
            
            <article>
                
<p>In this section, we will create a microservice that allows clients to upload images and then download them. At first, we implement a handler to upload images and save them to a filesystem asynchronously using the <kbd>tokio</kbd> crate. After that, we will implement a downloading handler that allows the user to download original images from files that were uploaded before.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Uploading images</h1>
                </header>
            
            <article>
                
<p>Let's start implementing a microservice to store and serve images with an uploading files feature. To get incoming files, we have to read an incoming <kbd>Stream</kbd> of a <kbd>Request</kbd>. The <kbd>Stream</kbd> might be huge, so we shouldn't hold the whole file in memory. We will read the incoming data in chunks and write them immediately to a file. Let's create the <kbd>main</kbd> function of our microservice:</p>
<pre>fn main() {<br/>    let files = Path::new("./files");<br/>    fs::create_dir(files).ok();<br/>    let addr = ([127, 0, 0, 1], 8080).into();<br/>    let builder = Server::bind(&amp;addr);<br/>    let server = builder.serve(move || {<br/>        service_fn(move |req| microservice_handler(req, &amp;files))<br/>    });<br/>    let server = server.map_err(drop);<br/>    hyper::rt::run(server);<br/>}</pre>
<p>This looks like the other examples that we've created but here we set a <kbd>std::path::Path</kbd> to a directory that will keep all incoming files. We will create the directory with the path we set before using the <kbd>create_dir</kbd> function of the <kbd>std::fs</kbd> module. If the creation of the directory fails, we will ignore it, but for production code it's better to stop creating a server and return an <kbd>Error</kbd> or print the necessary information. This is suitable for demonstrative purposes, but it's not reliable, because locally stored files can be lost in the server and your service will be corrupted. In real microservices, you may prefer to use a third-party service, such as AWS S3, to store and deliver files to clients.</p>
<p>After we create a directory to store files, we will start a <kbd>Server</kbd> with a <kbd>microservice_handler</kbd> that we will define later. Pay attention to when we pass a reference to a <kbd>Path</kbd>. Providing a path as a parameter is useful if you want to set another folder using command-line arguments.</p>
<p>We can now define the <kbd>microservice_handler</kbd> function that will handle four cases:</p>
<ul>
<li>Returning an index page on the <kbd>/</kbd> path</li>
<li>Storing a file to the <kbd>/upload</kbd> path</li>
<li>Returning the uploaded file with the <kbd>/download</kbd> path</li>
<li>Returning 404 errors for other requests</li>
</ul>
<p>The function has the following definition:</p>
<pre>fn microservice_handler(req: Request&lt;Body&gt;, files: &amp;Path)<br/>    -&gt; Box&lt;Future&lt;Item=Response&lt;Body&gt;, Error=std::io::Error&gt; + Send&gt;</pre>
<p>This is a similar handler definition to that we used in <a href="621dffeb-7f43-4c11-9ac5-00a366dc8d9f.xhtml">Chapter 2</a>, <em>Developing a Microservice with Hyper Crate</em>, and <a href="751f86d9-59ce-4966-beb8-cd743b521373.xhtml">Chapter 3</a>,<span> </span><em><span class="cdp-organizer-chapter-title"><span class="cdp-organize-title-label">Logging and Configuring Your Microservices</span></span></em>, but we use <kbd>std::io::Error</kbd> instead of <kbd>hyper::Error</kbd>. This is because we are not only working with requests and responses, but we are also using a filesystem that can cause errors of other types. We also expect an argument of the <kbd>Path</kbd> type to determine a directory in which we will store files.</p>
<p>Lets add a <kbd>match</kbd> expression to match the parameters of an incoming request. We will consider only two branches here—the first is when a client sends a GET request to the root path, and the second is for all other requests. We will add other branches later:</p>
<pre>match (req.method(), req.uri().path().to_owned().as_ref()) {<br/>    (&amp;Method::GET, "/") =&gt; {<br/>        Box::new(future::ok(Response::new(INDEX.into())))<br/>    },<br/>    _ =&gt; {<br/>        response_with_code(StatusCode::NOT_FOUND)<br/>    },<br/>}</pre>
<p>We used similar pattern matching in <a href="621dffeb-7f43-4c11-9ac5-00a366dc8d9f.xhtml">Chapter 2</a>, <em>Developing a Microservice with Hyper Crate</em>. Previously, we had a <kbd>match</kbd> expression to check the method and the path of incoming requests. This time, we need a copy of <kbd>Uri::path</kbd>, because we will need to use a path copy in regular expressions of other branches later.</p>
<p>The <kbd>response_with_code</kbd> function returns a <kbd>Future</kbd> instance now, instead of <kbd>Request</kbd>:</p>
<pre>fn response_with_code(status_code: StatusCode)<br/>    -&gt; Box&lt;Future&lt;Item=Response&lt;Body&gt;, Error=Error&gt; + Send&gt;<br/>{<br/>    let resp = Response::builder()<br/>        .status(status_code)<br/>        .body(Body::empty())<br/>        .unwrap();<br/>    Box::new(future::ok(resp))<br/>}</pre>
<p>Let's add the remaining branches to the <kbd>match</kbd> expression. Let's add one to handle the uploading of files:</p>
<pre>(&amp;Method::POST, "/upload") =&gt; {<br/>    let name: String = thread_rng().sample_iter(&amp;Alphanumeric).take(20).collect();<br/>    let mut filepath = files.to_path_buf();<br/>    filepath.push(&amp;name);<br/>    let create_file = File::create(filepath);<br/>    let write = create_file.and_then(|file| {<br/>        req.into_body()<br/>            .map_err(other)<br/>            .fold(file, |file, chunk| {<br/>            tokio::io::write_all(file, chunk)<br/>                .map(|(file, _)| file)<br/>        })<br/>    });<br/>    let body = write.map(|_| {<br/>        Response::new(name.into())<br/>    });<br/>    Box::new(body)<br/>}</pre>
<p>This request-handling branch expects the <kbd>POST</kbd> method and the <kbd>"/upload"</kbd> path. We don't check the user credentials and we allow everyone to upload a file, but in a real microservice, you should filter incoming traffic to avoid spam or malicious use.</p>
<p>In the first line of the branch, we generate a random name for the incoming file. We can provide the client with an opportunity to set the name of the file, but this is a dangerous practice. If you don't check the paths of incoming requests, a client can request a file from any folder in the server. We take an instance of random number generator that implements the <kbd>Rng</kbd> trait with <kbd>thread_rng</kbd> function call of the <kbd>rand</kbd> crate. Afterward, we use the generator to get an <kbd>Iterator</kbd> of samples by the <kbd>sample_iter</kbd> method call of the <kbd>Rng</kbd> trait and provide an <kbd>Alphanumeric</kbd> distribution to it that generates random characters and digits. We take 20 items from the iterator and collect them in a <kbd>String</kbd>. Then, we convert the <kbd>files</kbd> variable to <kbd>PathBuf</kbd> using the <kbd>to_path_buf</kbd> method and add the generated filename to the path.</p>
<p>In the next line, we create a <kbd>File</kbd> with the generated name. Here lies the most important difference of asynchronous applications—we use the <kbd>tokio::fs::File</kbd> type instead of the <kbd>std::fs::File</kbd> type, so we return a <kbd>Future</kbd> instance instead of a file reference. The future will be completed when the file is created. After that, we use the created file to write some data to this file asynchronously. The <kbd>tokio::fs::File</kbd> type wraps <kbd>std::fs::File</kbd>, but implements the <kbd>AsyncRead</kbd> and <kbd>AsyncWrite</kbd> traits. At any time, you can call the <kbd>into_std</kbd> method to unwrap the standard <kbd>File</kbd> type. Before we do this, however, we will write an incoming stream to the created file. Let's take a closer look at the <kbd>tokio</kbd> crate and some important issues to do with the asynchronous reading and writing of files.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The tokio crate</h1>
                </header>
            
            <article>
                
<p>The <kbd>tokio</kbd> crate provides the functionality to work with the network connections of files in an asynchronous manner. It includes wrappers for the TCP and UDP sockets—<kbd>TcpStream</kbd> and <kbd>UdpSocket</kbd>. It also includes types to access a filesystem through the <kbd>Future</kbd> and <kbd>Stream</kbd> traits. There is no cross-platform approach to work with files asynchronously, because operating systems have their own implementations of non-blocking APIs. Some operating systems, however, don't have good asynchronous APIs at all. To provide cross-platform asynchronous access to filesystems, <kbd>tokio</kbd> uses the <kbd>tokio_threadpool</kbd> crate, which has a <kbd>blocking</kbd> method that runs a task in a separate thread. This helps to implement asynchronous interaction for types that can block the thread using input/output operations. It isn't the most effective way to interact with a filesystem, but it does allow us to convert synchronous APIs to asynchronous. The <kbd>tokio</kbd> crate also contains an <kbd>Executor</kbd> trait and a <kbd>Timer</kbd> module. We've considered executors before. The <kbd>timer</kbd> module contains the <kbd>Timeout</kbd> and <kbd>Interval</kbd> types to create a <kbd>Future</kbd> and a <kbd>Stream</kbd> that generate values whenever a specified time period has elapsed.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Asynchronous input/output of files</h1>
                </header>
            
            <article>
                
<p>We now have to create a chain to read all incoming chunks and write them to the created file. As you might remember, <kbd>File::create</kbd> returns a <kbd>Future</kbd> that returns a <kbd>File</kbd> instance. We won't take the result immediately, because I/O operations take some time and can cause the current running thread to be blocked. We have to use the <kbd>Future::and_then</kbd> method to move the result (when it is ready) to other <kbd>Future</kbd> instance that will send all chunks to the file. To do that, we will use a <kbd>Body</kbd> instance that we get with the <kbd>into_body</kbd> method call of the <kbd>Request</kbd> that is stored in the <kbd>req</kbd> variable. The <kbd>Body</kbd> implements a <kbd>Stream</kbd> of the <kbd>Chunk</kbd> instances, but it can produce a <kbd>hyper::Error</kbd>. Since <kbd>File::create</kbd> can produce an <kbd>io::Error</kbd>, we have to convert the <kbd>hyper::Error</kbd> to an <kbd>io::Error</kbd> using the <kbd>other</kbd> function call as follows:</p>
<pre>fn other&lt;E&gt;(err: E) -&gt; Error<br/>where<br/>    E: Into&lt;Box&lt;std::error::Error + Send + Sync&gt;&gt;,<br/>{<br/>    Error::new(ErrorKind::Other, err)<br/>}</pre>
<p>The preceding function creates an <kbd>io::Error</kbd> with <kbd>ErrorKind::Other</kbd> based on any <kbd>Error</kbd> provided with the single argument. We use the <kbd>other</kbd> function with the <kbd>map_err</kbd> of the <kbd>StreamExt</kbd> to convert failures of the stream to <kbd>io::Error</kbd>. When the <kbd>Stream</kbd> of the <kbd>Body</kbd> is compatible with the type of error, we can create a <kbd>Future</kbd> that will move incoming binary data to the file. To do that, we can use a <kbd>fold</kbd> method of a <kbd>StreamExt</kbd> trait. If you are familiar with functional programming, you might know how this works already. The <kbd>fold</kbd> function takes two arguments—an initial value, which will be reused in every iteration, and a function, which carries out some processing with the initial value. Processing functions have to return a <kbd>Future</kbd> instance on every call, with one condition—the <kbd>Future</kbd> has to return the same type as the type of the initial value.</p>
<p>We will provide a <kbd>File</kbd> instance as an initial value and we will call <kbd>tokio::io::write_all</kbd> to write an incoming chunk of the request's body to a file. The <kbd>write_all</kbd> function expects an output stream and a binary slice. It returns a <kbd>Future</kbd>, which returns a tuple with an output stream and a provided slice on success. We have to use the <kbd>map</kbd> method of the returned <kbd>Future</kbd> to drop the slice and keep the file. The resultant chain will <kbd>fold</kbd> the whole <kbd>Stream</kbd> to a <kbd>Future</kbd>, which will return a filled <kbd>File</kbd> instance when all chunks are written to the file. We store this <kbd>Future</kbd> to write a variable and use the map method of <kbd>FutureExt</kbd> to drop the file instance (the real file with the written data will remain on the drive), and return a <kbd>Response</kbd> with the name of the stored file.</p>
<p>We have now successfully implemented file uploading. We should now discuss how to upload files using HTML forms and add a downloading feature to our service.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Multipart form requests</h1>
                </header>
            
            <article>
                
<p>So far in this chapter, we have used requests with binary bodies. This is suitable for microservices, but if you want to send files with an HTML form, you should use a request with a <kbd>multipart/form-data</kbd> type of content. This allows a client to include multiple files in a single request, but it also needs a parser to split files from the body of a request. The <kbd>hyper</kbd> crate doesn't include a parser for multipart requests, and you can use other crates such as the <kbd>multipart</kbd> crate to parse requests instead. This, however, doesn't work asynchronously, so you should use the <kbd>multipart-async</kbd> crate with the latest versions of the <kbd>hyper</kbd> crate. You can also implement multipart requests yourself. To implement this, you can create a struct that implements the <kbd>Stream</kbd> trait and parses incoming chunks of data. Multipart requests have the <kbd>multipart/form-data</kbd> content type with a boundary value such as <kbd>boundary=53164434ae464234f</kbd>. Its body contains a separator and the embedded files:</p>
<pre class="mce-root">--------------------------53164434ae464234f<br/>Content-Disposition: form-data; name="first_file"; filename="file1.txt"<br/>Content-Type: text/plain<br/>Contents of the file1.txt<br/>--------------------------53164434ae464234f<br/>Content-Disposition: form-data; name="second_file"; filename="file2.txt"<br/>Content-Type: text/plain<br/>Contents of the file2.txt<br/>--------------------------53164434ae464234f</pre>
<p>Your stream has to implement <strong><kbd>Stream&lt;Item=FileEntry&gt;</kbd></strong>, which reads a request and extracts files using the provided boundary.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Downloading images</h1>
                </header>
            
            <article>
                
<p>Let's implement a branch to download images. The handler can download files using the  <kbd>/download/filename</kbd> path. To extract the name of the file, we use a regular expression:</p>
<pre>lazy_static! {<br/>    static ref DOWNLOAD_FILE: Regex = Regex::new("^/download/(?P&lt;filename&gt;\\w{20})?$").unwrap();<br/>}</pre>
<p>We will use <kbd>startwith</kbd> to detect the <kbd>/download</kbd> part of the path. Take a look at the implementation:</p>
<pre>(&amp;Method::GET, path) if path.starts_with("/download") =&gt; {<br/>    if let Some(cap) = DOWNLOAD_FILE.captures(path) {<br/>            let filename = cap.name("filename").unwrap().as_str();<br/>            let mut filepath = files.to_path_buf();<br/>            filepath.push(filename);<br/>            let open_file = File::open(filepath);<br/>            let body = open_file.map(|file| {<br/>                let chunks = FileChunkStream::new(file);<br/>                Response::new(Body::wrap_stream(chunks))<br/>            });<br/>            Box::new(body)<br/>    } else {<br/>        response_with_code(StatusCode::NOT_FOUND)<br/>    }<br/>}</pre>
<p>In this example, we expect a <kbd>GET</kbd> method and check that the paths match with the <kbd>DOWNLOAD_FILE</kbd> regular expression. We use the name <kbd>"filename"</kbd> to extract a string with the name of the file. Since we have the filepath variable with a path to a folder, we convert the <kbd>Path</kbd> value to the <kbd>PathBuf</kbd>  type using the <kbd>to_path_buf</kbd> method of the <kbd>Path</kbd> instance and push a filename to it. After that, we use the file type of the <kbd>tokio</kbd> crate to open a file, which has asynchronous reading and writing capabilities to work with the file's content. The <kbd>open</kbd> method of the file returns an <kbd>OpenFuture</kbd> instance that resolves to a <kbd>File</kbd> instance when it is successful.</p>
<p>We wrap a file with <kbd>FileChunkStream</kbd>, imported from the <kbd>hyper_staticfile</kbd> crate. This stream reads a <kbd>File</kbd> and returns chunks of bytes. The body has a <kbd>wrap_stream</kbd> method and we can send the whole stream as a response. When the stream is forwarded to a client, the opened <kbd>File</kbd> will be closed when the stream is dropped. </p>
<p>The last thing we should do is return a <kbd>Body</kbd> instance.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">sendfile for sending files</h1>
                </header>
            
            <article>
                
<p>Forwarding files from one file to another is not effective, because this approach copies every chunk of data to the memory before sending it. Popular servers such as <strong>NGINX</strong> use the <kbd>sendfile</kbd> system call to send files from one file descriptor to another. This helps to save a lot of resources, because <kbd>sendfile</kbd> allows for zero copy, which means that we can write the buffer directly to the necessary device. To use <kbd>sendfile</kbd> with <kbd>tokio</kbd>, you have to implement a wrapper for it, but I don't think it's a good idea to serve static files with a microservice. You may prefer to use NGINX for this task or use object storage such as <strong>AWS S3</strong>, which can provide static files to a client.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Testing the service</h1>
                </header>
            
            <article>
                
<p>The image service is now ready for testing. Compile it, download any image from the internet, and use <kbd>curl</kbd> to upload it to our service:</p>
<pre><strong>$ curl https://www.rust-lang.org/logos/rust-logo-128x128.png | curl -X POST --data-binary @- localhost:8080/upload</strong><br/><br/>I4tcxkp9SnAjkbJwzy0m</pre>
<p>This request downloads the Rust logo and uploads it to our microservice. It will return the name of the uploaded image with a response. Put it after the <kbd>/download/</kbd> path and try to download it with your browser:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/3ce9c8aa-0ed8-44bf-95ca-45091bfeef1d.png" style="width:24.00em;height:22.00em;"/></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In this chapter, we have examined the <kbd>futures</kbd> and <kbd>tokio</kbd> crates. The <kbd>futures</kbd> crate contains types to work with delayed results and streams. We have compared the <kbd>Future</kbd> and <kbd>Result</kbd> types and the <kbd>Stream</kbd> and <kbd>Iterator</kbd> types. After that, we implemented a microservice that stores images and sends them back to the client.</p>
<p>We will improve microservice of this chapter using threads and background tasks in <a href="ba240208-414e-4dd4-bba8-8bd2658949cd.xhtml">Chapter 10</a>, <em>Background Tasks and Thread Pools in Microservices</em>. But in the next chapter, we will take a look at reactive microservices and using remote procedure calls as an alternative way to implement of microservices.</p>


            </article>

            
        </section>
    </body></html>