<html><head></head><body>
		<div><h1 id="_idParaDest-107"><em class="italic"><a id="_idTextAnchor123"/>Chapter 10</em>: Optimizing Rust and WebAssembly</h1>
			<p>So far, we have seen how Rust makes it easy to create and run WebAssembly modules and various tools provided by the Rust community. We will cover the following sections in this chapter:</p>
			<ul>
				<li>Minimizing the WebAssembly modules</li>
				<li>Analyzing the memory model in the WebAssembly module </li>
				<li>Analyzing the WebAssembly module with Twiggy</li>
			</ul>
			<h1 id="_idParaDest-108"><a id="_idTextAnchor124"/>Technical requirements</h1>
			<p>You can find the code files present in this chapter on GitHub at <a href="https://github.com/PacktPublishing/Practical-WebAssembly">https://github.com/PacktPublishing/Practical-WebAssembly</a>.</p>
			<h1 id="_idParaDest-109"><a id="_idTextAnchor125"/>Minimizing the WebAssembly modules </h1>
			<p><code>wasm-bindgen</code> is a complete suite that generates the binding JavaScript file (along with polyfills) for <a id="_idIndexMarker456"/>the WebAssembly module. In previous chapters, we saw how <code>wasm-bindgen</code> provides libraries and makes it easy to pass complex objects between JavaScript and WebAssembly. But in the WebAssembly world, it is important to optimize the generated binary for size and performance. </p>
			<p>Let's see how we can further optimize the WebAssembly modules:</p>
			<ol>
				<li>Create a WebAssembly application with all the necessary toolchains:<pre>$ npm init rust-webpack wasm-rust
🦀 Rust + 🕸 WebAssembly + Webpack = ❤</pre></li>
			</ol>
			<p>This previous command creates a new Rust and JavaScript-based application with webpack as the bundler.</p>
			<ol>
				<li value="2">Go into the generated <code>wasm-rust</code> directory:<pre>cd wasm-rust</pre></li>
			</ol>
			<p>The Rust source files are present in the <code>src</code> directory and the JavaScript files are available in the <code>js</code> directory. We have webpack configured for running the application.</p>
			<ol>
				<li value="3">Remove all <a id="_idIndexMarker457"/>the code from <code>src/lib.rs</code> and replace it with the following:<pre>use wasm_bindgen::prelude::*;
 
#[cfg(feature = "wee_alloc")]
#[global_allocator]
static ALLOC: wee_alloc::WeeAlloc =
  wee_alloc::WeeAlloc::INIT;
#[wasm_bindgen]
pub fn is_palindrome(input: &amp;str) -&gt; bool {
    let s = input.to_string().to_lowercase();
    s == s.chars().rev().collect::&lt;String&gt;()
}</pre></li>
			</ol>
			<p>We import <code>wasm_bindgen</code> and then enable <code>wee_alloc</code>, which does a much smaller memory allocation.</p>
			<p>We go on to define the <code>is_palindrome</code> function, which takes <code>&amp;str</code> as input and returns <code>bool</code>. Inside this function, we check whether the given string is a palindrome or not.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">Find <a id="_idIndexMarker458"/>out more about the difference between <code>&amp;str</code> and <code>String</code> at <a href="https://users.rust-lang.org/t/whats-the-difference-between-string-and-str/10177/9">https://users.rust-lang.org/t/whats-the-difference-between-string-and-str/10177/9</a>.</p>
			<ol>
				<li value="4">Now, remove all the lines from <code>js/index.js</code> and replace them with the following content:<pre>const rust = import('../pkg/index.js');
rust.then(module =&gt; {
    console.log(module.is_palindrome('tattarrattat'));
  // returns true
});</pre><p class="callout-heading">Note</p><p class="callout">We are importing from <code>../pkg/index.js</code> here. The <code>wasm-pack</code> command will generate the <code>binding</code> file and <code>wasm</code> file inside the <code>pkg</code> folder.</p></li>
				<li>Next, build <a id="_idIndexMarker459"/>the application with the following command:<pre><strong class="bold">$ npm run build</strong>
<strong class="bold">// comments, logs are elided</strong>
<strong class="bold">   Asset     Size   Chunks    Chunk Names</strong>
<strong class="bold">   0.js   9.84 KiB       0  [emitted]</strong>
<strong class="bold">   0fd5cbc32a547ac3295c.module.wasm    115 KiB       0</strong>
<strong class="bold">     [emitted] [immutable]</strong>
<strong class="bold">   index.html  179 bytes          [emitted]</strong>
<strong class="bold">   index.js    901 KiB   index  [emitted]</strong>
<strong class="bold">     index</strong></pre></li>
			</ol>
			<p>You can run the application with the <code>npm run start</code> command. This command opens the browser and loads the application. </p>
			<ol>
				<li value="6">Now, open the developer tools and check the logs in the console.</li>
			</ol>
			<p>The WebAssembly module generated by the Rust compiler is not completely optimized. We can optimize the WebAssembly modules further. In the JavaScript world, every byte matters.</p>
			<ol>
				<li value="7">Now, open <code>Cargo.toml</code> and add the following content:<pre>[profile.dev]
opt-level = 'z'
lto = true
debug = false</pre></li>
			</ol>
			<p>Also, remove the <code>[profile.release]</code> section completely. The <code>[profile.dev]</code> section instructs the compiler on how to profile the code generated <a id="_idIndexMarker460"/>in the dev build. The <code>[profile.release]</code> section is used only for the release build.</p>
			<p>We instruct the compiler to use <code>opt-level = z</code> for generating the code. The <code>opt-level</code> setting is similar to the LLVM compiler's <code>-O1/2/3/...</code>.</p>
			<p>The valid <a id="_idIndexMarker461"/>options of the <code>opt-level</code> setting are as follows:</p>
			<ul>
				<li><code>0</code> – no optimizations; also turns on <code>cfg(debug_assertions)</code></li>
				<li><code>1</code> – basic optimizations </li>
				<li><code>2</code> – some optimizations </li>
				<li><code>3</code> – all optimizations </li>
				<li><code>s</code> – optimize for binary size </li>
				<li><code>z</code> – optimize for binary size, but also turn off loop vectorization</li>
			</ul>
			<p>LLVM supports link-time optimizations to better optimize code by using whole program analysis. But link-time optimization comes at the cost of longer linking time. We can enable LLVMs link-time optimization using the lto option.</p>
			<p>The lto supports <a id="_idIndexMarker462"/> the following options:</p>
			<ul>
				<li><code>false</code> – performs "thin local LTO”.  This means the link-time optimizations are done only on the local crate. Note: there will not be any link-time optimizations when the number of Codegen units is 1 or <code>opt-level</code> is 0. </li>
				<li><code>true</code> or "fat" – performs "fat" LTO.  This means the link-time optimizations are done across all crates in the dependency graph.  </li>
				<li><code>thin</code> – performs "thin" LTO. This is a faster version of “fat”, that optimizes at a faster rate. </li>
				<li><code>off</code> – disables LTO.</li>
			</ul>
			<ol>
				<li value="8">Next, run <code>npm run build</code>:<pre><strong class="bold">$ npm run build</strong>
<strong class="bold">// comments, logs are elided</strong>
<strong class="bold">   Asset   Size   Chunks   Chunk Names</strong>
<strong class="bold">   0.js  9.84 KiB     0  [emitted]</strong>
<strong class="bold">   b5e867dd3d25627d7122.module.wasm  50.8 KiB       0</strong>
<strong class="bold">     [emitted] [immutable]</strong>
<strong class="bold">   index.js   901 KiB   index  [emitted]</strong>
<strong class="bold">     index</strong></pre></li>
			</ol>
			<p>The generated <a id="_idIndexMarker463"/>WebAssembly binary is 50.8 KB. The generated binary is ~44% smaller in size. That is a huge win for us. We can further optimize the binary using Binaryen's <code>wasm-opt</code> tool:</p>
			<pre><strong class="bold">$ /path/to/build/directory/of/binaryen/wasm-opt -Oz</strong>
<strong class="bold">  b5e867dd3d25627d7122.module.wasm -o opt-gen.wasm</strong>
<strong class="bold">$ l</strong>
<strong class="bold">-rw-r--r--    1 sendilkumar  staff    45K May  8 17:43</strong>
<strong class="bold"> opt-gen.wasm</strong></pre>
			<p>It reduces another 5 KB. We have used the <code>-Oz</code> pass, but we can pass in other passes to further optimize the generated binary.</p>
			<p>We have <a id="_idIndexMarker464"/>seen how to minimize the WebAssembly module using Rust. Next, we will analyze the memory model in the WebAssembly module.</p>
			<h1 id="_idParaDest-110"><a id="_idTextAnchor126"/>Analyzing the memory model in the WebAssembly module  </h1>
			<p>Inside the JavaScript engine, WebAssembly and JavaScript run at different locations. Crossing <a id="_idIndexMarker465"/>the boundaries between JavaScript and WebAssembly will always have a cost attached to it. The browser <a id="_idIndexMarker466"/>vendors implemented cool hacks and workarounds to reduce this cost, but when your applications cross this boundary, this boundary crossing will often soon become a major performance bottleneck for your application. It is very important to design WebAssembly applications in a way that reduces boundary crossing. But once the application grows, it becomes difficult to manage this boundary crossing. To prevent boundary crossing, WebAssembly modules come with the memory module.</p>
			<p>The memory section in the WebAssembly module is a vector of linear memories.</p>
			<p>A linear memory <a id="_idIndexMarker467"/>model is a memory-addressing technique in which the memory is organized in a single contagious address space. It is also<a id="_idTextAnchor127"/> known as the Flat memory model.</p>
			<p>The linear memory model makes it easier to understand, program, and represent the memory. But it also has huge disadvantages, such as high execution time for rearranging elements in memory and wasting a lot of memory area.</p>
			<p>Here, the memory represents a vector of raw bytes containing uninterpreted data. WebAssembly uses resizable array buffers to hold the raw bytes of memory. It is important to note that this memory that is created is accessible and mutable from both JavaScript and WebAssembly.</p>
			<h2 id="_idParaDest-111"><a id="_idTextAnchor128"/>Sharing memory between JavaScript and WebAssembly using Rust</h2>
			<p>We have <a id="_idIndexMarker468"/>already seen how to share <a id="_idIndexMarker469"/>the memory between JavaScript and WebAssembly. Let's share memory using Rust in this example:</p>
			<ol>
				<li value="1">Create a new Rust project using Cargo:<pre><strong class="bold">$ cargo new --lib memory_world</strong></pre></li>
				<li>Open the project in your favorite editor and replace <code>src/lib.rs</code> with the following content:<pre>#![no_std]
 
use core::panic::PanicInfo;
use core::slice::from_raw_parts_mut;
 
#[no_mangle]
fn memory_to_js() {
    let obj: &amp;mut [u8];
 
    unsafe {
      obj = from_raw_parts_mut::&lt;u8&gt;(0 as *mut u8, 1);
    }
 
    obj[0] = 13;
}
 
#[panic_handler]
fn panic(_info: &amp;PanicInfo) -&gt; !{
    loop{}
} </pre></li>
			</ol>
			<p>The Rust file starts with <code>#![no_std]</code>. This instructs the compiler not<a id="_idTextAnchor129"/> to include the Rust Standard Library while generating the WebAssembly module. This will reduce the binary size a lot. Next, we define a function called <code>memory_to_js</code>. This function creates an <code>obj</code> in memory and shares it with JavaScript. In the function definition, we create a slice of <code>u32</code> called <code>obj</code>. Next, we assign <a id="_idIndexMarker470"/>some raw memory to <code>obj</code>. Here, we are dealing with raw memory. Hence, we wrap the code <a id="_idIndexMarker471"/>inside an <code>unsafe</code> block. The memory object is global and it is mutable by both JavaScript and WebAssembly. Hence, we use <code>from_raw_parts_mut</code> to instantiate the object. Finally, we assign a value to the first element in the shared array buffer.</p>
			<ol>
				<li value="3">Create an <code>index.html</code> file and add the following content:<pre>&lt;script&gt;
    ( async() =&gt; {
         const bytes = await fetch("target/wasm32-
         unknown-unknown/debug/memory_world.wasm");
         const response = await bytes.arrayBuffer();
         const result = await
           WebAssembly.instantiate(response, {});
         result.exports.memory_to_js();
         const memObj = new
           UInt8Array(result.exports.memory.buffer, 0)
           .slice(0, 1);
         console.log(memObj[0]); // 13
    })();
&lt;/script&gt;</pre></li>
			</ol>
			<p>We create an anonymous asynchronous JavaScript function that will be invoked as soon as the script is loaded. We fetch the WebAssembly binary inside the anonymous function. Next, we create <code>ArrayBuffer</code> and instantiate the module <a id="_idIndexMarker472"/>to the <code>result</code> object. We then <a id="_idIndexMarker473"/>call the <code>memory_to_js</code> method in the WebAssembly module (note the <code>exports</code> keyword, since the function is exported from the WebAssembly module). This instantiates the memory and assigns the first element in the shared array buffer to <code>13</code>:</p>
			<pre>const memObj = new
 UInt8Array(result.exports.memory.buffer, 0)
   .slice(0, 1);
console.log(memObj[0]); // 13</pre>
			<p>Next, we call the memory object that is exported from WebAssembly using <code>result.export.memory.buffer</code> and convert it into <code>UInt8Array</code> using a new <code>UInt8Array()</code>. Next, we extract the first element using <code>slice(0,1)</code>. This way, we can pass and retrieve values between JavaScript and WebAssembly without any overhead. The memory is accessed via <code>load</code> and <code>store</code> binary instructions. The <code>load</code> operation copies data from the main memory to register. The <code>store</code> operation copies data from the main memory. These binary instructions are accessed with the offset and the alignment. The alignment is in base-2 logarithmic representation. The memory address should be a multiple of four. This is called alignment restriction. This alignment restriction makes the hardware much faster.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">It is important to note that WebAssembly currently provides only a 32-bit address range. In the future, WebAssembly might provide a 64-bit address range.</p>
			<p>We have seen how to share memory between JavaScript and WebAssembly by creating the memory in Rust. Next, we will create a memory object on the JavaScript side and use it inside the Rust application.</p>
			<h2 id="_idParaDest-112"><a id="_idTextAnchor130"/>Creating a memory object in JavaScript to use in the Rust application</h2>
			<p>Unlike JavaScript, Rust is not dynamically typed. The memory created in JavaScript has no way to tell WebAssembly (or the Rust code) what to allocate and when to free them. We need <a id="_idIndexMarker474"/>to explicitly inform WebAssembly <a id="_idIndexMarker475"/>how to allocate the memory and, most importantly, when and how to free them (to avoid any leaks).</p>
			<p>We use the <code>WebAssembly.memory()</code> constructor to create the memory in JavaScript. The memory constructor takes in an object to set the defaults. The object has the following options:</p>
			<ul>
				<li><code>initial</code> – the initial size of the memory</li>
				<li><code>maximum</code> – the maximum size of the memory (optional)</li>
				<li><code>shared</code> – to denote whether to use the shared memory</li>
			</ul>
			<p>The units for <code>initial</code> and <code>maximum</code> are WebAssembly pages, where a page refers to 64 KB.</p>
			<p>We change the HTML file as follows:</p>
			<pre>&lt;script&gt;
     ( async() =&gt; {
        const memory = new WebAssembly.Memory({initial: 10,
          maximum:100}); // -&gt; 1
        const bytes = await fetch("target/wasm32-unknown-
          unknown/debug/memory_world.wasm");
        const response = await bytes.arrayBuffer();
        const instance = await
          WebAssembly.instantiate(response, 
          { js: { mem: memory } }); // -&gt;2
        const s = new Set([1, 2, 3]);
        let jsArr = Uint8Array.from(s); // -&gt; 3
        const len = jsArr.length;
        let wasmArrPtr = instance.exports.malloc(length);
          // -&gt; 4
        let wasmArr = new
          Uint8Array(instance.exports.memory.buffer,
          wasmArrPtr, len); // -&gt; 5
        wasmArr.set(jsArr); // -&gt; 6
        const sum = instance.exports.accumulate
          (wasmArrPtr, len); // -&gt; 7
        console.log(sum);
    })();
&lt;/script&gt;</pre>
			<p>In <code>// -&gt; 1</code>, the memory is initialized with the <code>WebAssembly.Memory()</code> constructor. We <a id="_idIndexMarker476"/>passed in the initial and <a id="_idIndexMarker477"/>maximum size of the memory, that is, 640 KB and 6.4 MB, respectively.</p>
			<p>In <code>// -&gt; 2</code>, we're instantiating the WebAssembly module along with the memory object.</p>
			<p>In <code>// -&gt; 3</code>, we then create <code>typedArray</code> (<code>UInt8Array</code>) with values <code>1</code>, <code>2</code>, and <code>3</code>.</p>
			<p>In <code>// -&gt; 4</code>, we see how, as WebAssembly modules do not have any clue about the objects that are created out of the memory, the memory needs to be allocated. We have to manually write the allocation and freeing of memory in WebAssembly. In this step, we send the length of the array and allocate that memory. This gives us a pointer to the location of the memory.</p>
			<p>In <code>// -&gt; 5</code>, we create a new <code>typedArray</code> with the buffer (total available memory), the memory offset (<code>wasmAttrPtr</code>), and the length of the memory.</p>
			<p>In <code>// -&gt; 6</code>, we set the locally created <code>typedArray</code> (in <em class="italic">step 3</em>) to <code>typedArray</code> created in <em class="italic">step 5</em>.</p>
			<p>In <code>//-&gt; 7</code>, finally, we send the pointer to the memory and the length to the WebAssembly module, where we fetch the value from the memory by using the pointer to the memory and the length.</p>
			<p>On the <a id="_idIndexMarker478"/>Rust side, replace the contents <a id="_idIndexMarker479"/>of <code>src/lib.rs</code> with the following:</p>
			<pre>use std::alloc::{alloc, dealloc,  Layout};
use std::mem;
 
#[no_mangle]
fn accumulate(data: *mut u8, len: usize) -&gt; i32 {
    let y = unsafe { std::slice::from_raw_parts(data as
      *const u8, len) };
    let mut sum = 0;
    for i in 0..len {
        sum = sum + y[i];
    }
    sum as i32
}
 
#[no_mangle]
fn malloc(size: usize) -&gt; *mut u8 {
    let align = std::mem::align_of::&lt;usize&gt;();
    if let Ok(layout) = Layout::from_size_align(size,
      align) {
        unsafe {
            if layout.size() &gt; 0 {
                let ptr = alloc(layout);
                if !ptr.is_null() {
                    return ptr
                }
            } else {
                return align as *mut u8
            }
        }
    }
    std::process::abort
}</pre>
			<p>We imported <code>alloc</code>, <code>dealloc</code>, and <code>Layout</code> from <code>std::alloc</code> and <code>std::mem</code> to play with <a id="_idIndexMarker480"/>the raw memory. The first <a id="_idIndexMarker481"/>function, <code>accumulate</code>, takes in <code>data</code>, which is the pointer where the data starts, and <code>len</code>, the length of the memory to read. First, we create a slice from the raw memory using <code>std::slice::from_raw_parts</code> by passing the pointer, <code>data</code>, and length, <code>len</code>. Note that this is an unsafe operation. Next, we run through the items in the array and add all the elements. Finally, we return the value as <code>i32</code>.</p>
			<p>The <code>malloc</code> function is used to custom-allocate the memory since the WebAssembly module has no clue about the type of information sent and how to read/understand it. <code>malloc</code> helps us to allocate the memory as required without any panic.</p>
			<p>Run the previous code using <code>python -m http.server</code> and load the web page in a browser to see the results in the developer tools.</p>
			<h1 id="_idParaDest-113"><a id="_idTextAnchor131"/>Analyzing the WebAssembly module with Twiggy</h1>
			<p>The Rust-to-WebAssembly binaries are more likely to create a bloated binary. Proper care should <a id="_idIndexMarker482"/>be taken when creating WebAssembly binaries. The trade-off between the level of optimization, the time <a id="_idIndexMarker483"/>to compile, and various other factors should be considered while producing binaries. But most of the preceding work is done by the compiler by defa<a id="_idTextAnchor132"/>ult. Either Emscripten or the <code>rustc</code> compiler ensures the elimination of dead code along with various options on the optimization level (<code>-O0</code> to <code>z</code>). We can choose the one that fits us.</p>
			<p>Twiggy is a code size profiler. It uses the call graph to determine the origins of a function and provides meta-information about the function. The meta-information includes the size of each function in binary and its cost. Twiggy provides an overview of what is in the binary. With that information, we can optimize the binary further Let's install and use Twiggy to optimize the binary:.</p>
			<ol>
				<li value="1">Install Twiggy by running the following command:<pre><strong class="bold">$ cargo install twiggy</strong></pre></li>
				<li>Once installed, the <code>twiggy</code> command will be available in the command line, which we can check with the following command:<pre><strong class="bold">$ twiggy</strong>
<strong class="bold">twiggy-opt 0.6.0</strong>
<strong class="bold">...</strong>
<strong class="bold">Use `twiggy` to make your binaries slim!</strong>
<strong class="bold"> </strong>
<strong class="bold">USAGE:</strong>
<strong class="bold">    twiggy &lt;SUBCOMMAND&gt;</strong>
<strong class="bold"> </strong>
<strong class="bold">FLAGS:</strong>
<strong class="bold">    -h, --help Prints help information</strong>
<strong class="bold">    -V, --version Prints version information</strong>
<strong class="bold"> </strong>
<strong class="bold">SUBCOMMANDS:</strong>
<strong class="bold">    diff         Diff the old and new versions of a</strong>
<strong class="bold">                 binary to see what sizes changed.</strong>
<strong class="bold">    dominators   Compute and display the dominator</strong>
<strong class="bold">                 tree for a binary's call graph.</strong>
<strong class="bold">    garbage      Find and display code and data that</strong>
<strong class="bold">                 is not transitively referenced by any</strong>
<strong class="bold">                 exports or public functions.</strong>
<strong class="bold">    help         Prints this message or the help of</strong>
<strong class="bold">                 the given subcommand(s)</strong>
<strong class="bold">    monos        List the generic function</strong>
<strong class="bold">                 monomorphizations that are</strong>
<strong class="bold">                 contributing to code bloat.</strong>
<strong class="bold">    paths        Find and display the call paths </strong>
<strong class="bold">                 to a function in the given binary's</strong>
<strong class="bold">                 call graph.</strong>
<strong class="bold">    top          List the top code size offenders in a</strong>
<strong class="bold">                 binary.</strong></pre></li>
				<li>Create <a id="_idIndexMarker484"/>a folder to test-drive <a id="_idIndexMarker485"/>Twiggy:<pre><strong class="bold">$ mkdir twiggy-world</strong></pre></li>
				<li>Create a file called <code>add.wat</code> and add the following content:<pre><strong class="bold">$ touch add.wat</strong>
<strong class="bold">(module</strong>
<strong class="bold">    (func $add (param $lhs i32) (param $rhs i32)</strong>
<strong class="bold">      (result i32)</strong>
<strong class="bold">        get_local $lhs</strong>
<strong class="bold">        get_local $rhs</strong>
<strong class="bold">        i32.add)</strong>
<strong class="bold">    (export "add" (func $add))</strong>
<strong class="bold">)</strong></pre></li>
				<li>Once <a id="_idIndexMarker486"/>you have defined the WebAssembly <a id="_idIndexMarker487"/>text format, compile it to the WebAssembly module using <code>wabt</code>:<pre><strong class="bold">$ /path/to/build/directory/of/wabt/wat2wasm add.wat</strong></pre></li>
				<li>The preceding command generates an <code>add.wasm</code> file. To get the call paths in the binary, run Twiggy with the <code>paths</code> option:<pre><strong class="bold">$ twiggy paths add.wasm</strong>
<strong class="bold">Shallow Bytes │ Shallow % │ Retaining Paths</strong>
<strong class="bold">───────────────┼───────────┼───────────────────────────</strong>
<strong class="bold">             9 </strong><strong class="bold">┊</strong><strong class="bold">    21.95% </strong><strong class="bold">┊</strong><strong class="bold"> code[0]</strong>
<strong class="bold">               </strong><strong class="bold">┊</strong><strong class="bold">           </strong><strong class="bold">┊</strong><strong class="bold">   </strong><strong class="bold">⬑</strong><strong class="bold"> export "add"</strong>
<strong class="bold">             8 </strong><strong class="bold">┊</strong><strong class="bold">    19.51% </strong><strong class="bold">┊</strong><strong class="bold"> wasm magic bytes</strong>
<strong class="bold">             6 </strong><strong class="bold">┊</strong><strong class="bold">    14.63% </strong><strong class="bold">┊</strong><strong class="bold"> type[0]: (i32, i32) -&gt; i32</strong>
<strong class="bold">               </strong><strong class="bold">┊</strong><strong class="bold">           </strong><strong class="bold">┊</strong><strong class="bold">   </strong><strong class="bold">⬑</strong><strong class="bold"> code[0]</strong>
<strong class="bold">               </strong><strong class="bold">┊</strong><strong class="bold">           </strong><strong class="bold">┊</strong><strong class="bold">       </strong><strong class="bold">⬑</strong><strong class="bold"> export "add"</strong>
<strong class="bold">             6 </strong><strong class="bold">┊</strong><strong class="bold">    14.63% </strong><strong class="bold">┊</strong><strong class="bold"> export "add"</strong>
<strong class="bold">             6 </strong><strong class="bold">┊</strong><strong class="bold">    14.63% </strong><strong class="bold">┊</strong><strong class="bold"> code section headers</strong>
<strong class="bold">             3 </strong><strong class="bold">┊</strong><strong class="bold">     7.32% </strong><strong class="bold">┊</strong><strong class="bold"> type section headers</strong>
<strong class="bold">             3 </strong><strong class="bold">┊</strong><strong class="bold">     7.32% </strong><strong class="bold">┊</strong><strong class="bold"> export section headers</strong></pre></li>
			</ol>
			<p>The <code>twiggy paths</code> command shows the call path for the functions, the number of bytes <a id="_idIndexMarker488"/>they occupy inside the binary, and <a id="_idIndexMarker489"/>their percentage. The actual added code is 9 bytes and it occupies 21.95% of the total binary size.</p>
			<p>Let's explore various subcommands in Twiggy:</p>
			<ul>
				<li><code>top</code></li>
				<li><code>monos</code></li>
				<li><code>garbage</code></li>
			</ul>
			<h2 id="_idParaDest-114"><a id="_idTextAnchor133"/>top</h2>
			<p>The <code>twiggy top</code> command <a id="_idIndexMarker490"/>will list the code size of <a id="_idIndexMarker491"/>each block. It lists, in descending order, the size of the function, the percentage of the size in the end binary and the block section:</p>
			<pre><strong class="bold">$ twiggy top add.wasm</strong>
<strong class="bold">Shallow Bytes │ Shallow % │ Item</strong>
<strong class="bold">───────────────┼───────────┼───────────────────────────</strong>
<strong class="bold">             9 </strong><strong class="bold">┊</strong><strong class="bold">    21.95% </strong><strong class="bold">┊</strong><strong class="bold"> code[0]</strong>
<strong class="bold">             8 </strong><strong class="bold">┊</strong><strong class="bold">    19.51% </strong><strong class="bold">┊</strong><strong class="bold"> wasm magic bytes</strong>
<strong class="bold">             6 </strong><strong class="bold">┊</strong><strong class="bold">    14.63% </strong><strong class="bold">┊</strong><strong class="bold"> type[0]: (i32, i32) -&gt; i32</strong>
<strong class="bold">             6 </strong><strong class="bold">┊</strong><strong class="bold">    14.63% </strong><strong class="bold">┊</strong><strong class="bold"> export "add"</strong>
<strong class="bold">             6 </strong><strong class="bold">┊</strong><strong class="bold">    14.63% </strong><strong class="bold">┊</strong><strong class="bold"> code section headers</strong>
<strong class="bold">             3 </strong><strong class="bold">┊</strong><strong class="bold">     7.32% </strong><strong class="bold">┊</strong><strong class="bold"> type section headers</strong>
<strong class="bold">             3 </strong><strong class="bold">┊</strong><strong class="bold">     7.32% </strong><strong class="bold">┊</strong><strong class="bold"> export section headers</strong>
<strong class="bold">            41 </strong><strong class="bold">┊</strong><strong class="bold">   100.00% </strong><strong class="bold">┊</strong><strong class="bold"> </strong><strong class="bold">Σ</strong><strong class="bold"> [7 Total Rows]</strong>
<strong class="bold">The usage of the twiggy top is as follows</strong>
<strong class="bold">USAGE: twiggy top &lt;input&gt; -n &lt;max_items&gt; -o</strong>
<strong class="bold"> &lt;output_destination&gt; --format &lt;output_format&gt; <a id="_idTextAnchor134"/>--mode</strong>
<strong class="bold"> &lt;parse_mode&gt;</strong></pre>
			<p>List the <a id="_idIndexMarker492"/>top n details using <code>-n</code> followed by the number of entries to show:</p>
			<pre><strong class="bold">$ twiggy top add.wasm -n 3</strong>
<strong class="bold">Shallow Bytes │ Shallow % │ Item</strong>
<strong class="bold">───────────────┼───────────┼───────────────────────────</strong>
<strong class="bold">             9 </strong><strong class="bold">┊</strong><strong class="bold">    21.95% </strong><strong class="bold">┊</strong><strong class="bold"> code[0]</strong>
<strong class="bold">             8 </strong><strong class="bold">┊</strong><strong class="bold">    19.51% </strong><strong class="bold">┊</strong><strong class="bold"> wasm magic bytes</strong>
             <strong class="bold">6 </strong><strong class="bold">┊</strong><strong class="bold">    14.63% </strong><strong class="bold">┊</strong><strong class="bold"> type[0]: (i32, i32) -&gt; i32</strong>
<strong class="bold">            18 </strong><strong class="bold">┊</strong><strong class="bold">    43.90% </strong><strong class="bold">┊</strong><strong class="bold"> ... and 4 more.</strong>
<strong class="bold">            41 </strong><strong class="bold">┊</strong><strong class="bold">   100.00% </strong><strong class="bold">┊</strong><strong class="bold"> </strong><strong class="bold">Σ</strong><strong class="bold"> [7 Total Rows]</strong></pre>
			<p>Similarly, we can <a id="_idIndexMarker493"/>format the output to JSON format using the <code>--format</code> flag:</p>
			<pre>$ twiggy top add.wasm -n 3 --format json
[{"name":"code[0]","shallow_size":9,"shallow_size_percent":
21.951219512195124},{"name":"wasm magic
bytes","shallow_size":8,"shallow_size_percent":19.512195121
95122},{"name":"type[0]: (i32, i32) -&gt;
i32","shallow_size":6,"shallow_size_percent":14.63414634146
3413}]</pre>
			<p>The <code>top</code> command is extremely useful when you want to track down the biggest code blocks and then optimize them separately.</p>
			<h2 id="_idParaDest-115"><a id="_idTextAnchor135"/>monos</h2>
			<p>In the <a id="_idIndexMarker494"/>JavaScript world, monomorphization increases performance. But it also bloats the code size (for example, in generics). Since we have to create the implementation of a generic function dynamically for every type, we have to be very careful when using generics and monomorphic code.</p>
			<p>Twiggy has a <a id="_idIndexMarker495"/>subcommand called <code>monos</code> that will list the code bloating due to monomorphization:</p>
			<pre>$ twiggy monos pkg/index_bg.wasm
Apprx. Bloat Bytes │ Apprx. Bloat % │ Bytes │ %      │ Monomorphizations
────────────────────┼────────────────┼───────┼────────┼───────────────────────────────────────────────────────────────────
                  4 ┊          0.01% ┊    32 ┊  0.06% ┊ core::ptr::drop_in_place
                    ┊                ┊    28 ┊  0.05% ┊     core::ptr::drop_in_place::h9684ba572bb4c2f9
                    ┊                ┊     4 ┊  0.01% ┊     core::ptr::drop_in_place::h00c08aab80423b88
                  0 ┊          0.00% ┊  5437 ┊ 10.44% ┊ dlmalloc::dlmalloc::Dlmalloc::malloc
                    ┊                ┊  5437 ┊ 10.44% ┊     dlmalloc::dlmalloc::Dlmalloc::malloc::hb0329e71e24f7e2f
                  0 ┊          0.00% ┊  1810 ┊  3.48% ┊ &lt;char as core::fmt::Debug&gt;::fmt
                    ┊                ┊  1810 ┊  3.48% ┊     &lt;char as core::fmt::Debug&gt;::fmt::h5472f29c33f4c4c9
                  0 ┊          0.00% ┊  1126 ┊  2.16% ┊ dlmalloc::dlmalloc::Dlmalloc::free
                    ┊                ┊  1126 ┊  2.16% ┊     dlmalloc::dlmalloc::Dlmalloc::free::h7ab57ecacfa2b1c3
                  0 ┊          0.00% ┊  1123 ┊  2.16% ┊ core::str::slice_error_fail
                    ┊                ┊  1123 ┊  2.16% ┊     core::str::slice_error_fail::h26278b2259fb6582
                  0 ┊          0.00% ┊   921 ┊  1.77% ┊ core::fmt::Formatter::pad
                    ┊                ┊   921 ┊  1.77% ┊     core::fmt::Formatter::pad::hb011277a1901f9f7
                  0 ┊          0.00% ┊   833 ┊  1.60% ┊ dlmalloc::dlmalloc::Dlmalloc::dispose_chunk
                    ┊                ┊   833 ┊  1.60% ┊     dlmalloc::dlmalloc::Dlmalloc::dispose_chunk::he00c681454a3c3b7
                  0 ┊          0.00% ┊   787 ┊  1.51% ┊ core::fmt::write
                    ┊                ┊   787 ┊  1.51% ┊     core::fmt::write::hb395f946a5ce2cab
                  0 ┊          0.00% ┊   754 ┊  1.45% ┊ core::fmt::Formatter::pad_integral
                    ┊                ┊   754 ┊  1.45% ┊     core::fmt::Formatter::pad_integral::h05ee6133195a52bc
                  0 ┊          0.00% ┊   459 ┊  0.88% ┊ alloc::string::String::push
                    ┊                ┊   459 ┊  0.88% ┊     alloc::string::String::push::he03a5b89b77597a1
                  0 ┊          0.00% ┊  4276 ┊  8.21% ┊ ... and 64 more.
                  4 ┊          0.01% ┊ 17558 ┊ 33.73% ┊ Σ [85 Total Rows]
....</pre>
			<p>We are <a id="_idIndexMarker496"/>using the <code>index_bg.wasm</code> example <a id="_idIndexMarker497"/>from the <em class="italic">Minimizing the WebAssembly modules</em> section of this chapter.</p>
			<p><code>monos</code> is extremely useful for us to understand the occurrence of any bloating caused by generic parameters, which can then be changed to a simpler function with generics.</p>
			<h2 id="_idParaDest-116"><a id="_idTextAnchor136"/>garbage</h2>
			<p>At times, it is <a id="_idIndexMarker498"/>important to find code that is not used anymore but is kept <a id="_idIndexMarker499"/>in the final binary due to some other reasons. These functions are referenced somewhere but not used anywhere and the compiler will not know when and where to remove them.</p>
			<p>We can use Twiggy's <code>garbage</code> command to list all the code and data that is not transitively referenced:</p>
			<pre>$ twiggy garbage add.wasm
Bytes │ Size % │ Garbage Item
───────┼────────┼─────────────────────────────────────────
   109 ┊  0.21% ┊ custom section 'producers'
   109 ┊  0.21% ┊ Σ [1 Total Rows]
27818 ┊ 53.44% ┊ 1 potential false-positive data segments</pre>
			<p>WebAssembly modules consist of a data section. But sometimes, we might not use the data straight away in the WebAssembly module but in some other places where it is imported. As you can see here, Twiggy's <code>garbage</code> subcommand shows those potentially false values.</p>
			<h1 id="_idParaDest-117"><a id="_idTextAnchor137"/>Summary</h1>
			<p>In this chapter, we have seen how to optimize the WebAssembly binary using Rust, how to map memory between JavaScript and Rust, and finally, how to analyze a WebAssembly module using Twiggy. </p>
			<p>The WebAssembly ecosystem is still in its early days and it promises better performance. The WebAssembly binary addresses a few gaps in the JavaScript ecosystem, such as size-efficient compact binaries, enabling streaming compilation, and properly typed binaries. These features make WebAssembly smaller and faster. Rust, on the other hand, provides first-in-class support for generating a WebAssembly module and <code>wasm-bindgen</code> is the best tool available that makes it easier to transfer complex objects in Rust and WebAssembly. </p>
			<p>I hope that you now understand the basics of WebAssembly and how Rust makes it easier to generate WebAssembly modules. I can't wait to see what you will be shipping with Rust and WebAssembly.</p>
		</div>
	</body></html>