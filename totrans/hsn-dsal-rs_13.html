<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Assessments</h1>
                </header>
            
            <article>
                


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Chapter 1</h1>
                </header>
            
            <article>
                
<p><strong>What are traits and how are they different from interfaces?</strong></p>
<p>Traits are pieces of functionality shared across components. They can contain code as well as associated types, and can be implemented for any type and generics independently. Interfaces, on the other hand, describe the public methods a class provides, without an implementation and typically with inheritance. Rust only has traits.</p>
<p><strong>Why doesn't Rust have a garbage collector?</strong></p>
<p><span>Garbage collection is required to free up unused heap memory that is generated from a running the program.</span> Rust avoids this by providing a static code analysis at compile-time that forces the user to think of variable lifetimes. These lifetimes are very strictly defined and require a lifetime scope to own or borrow memory so that the compiler knows when it's not being used without an explicit statement. </p>
<p><strong>Name three examples of how lifetimes are created in Rust (explicitly and</strong><br/>
<strong>implicitly)!</strong></p>
<p>Any three that you can come up with are great, but here are mine: Functions, scopes (simply create one using <kbd>{}</kbd>), and closures (lambda functions).</p>
<p><strong>Why is immutability for variables important?</strong></p>
<p>It guarantees that only read operations take place, thereby avoiding any side effects.</p>
<p><strong>What does the Sync marker trait do?</strong></p>
<p>It marks a structure as safe to access from multiple threads. </p>
<p><strong>Where can you go to participate in the Rust community?</strong></p>
<p>Go to <a href="https://github.com/rust-lang">https://github.com/rust-lang</a> (opening issues, submitting code, discussions, and so on) or <a href="https://www.rust-lang.org/community">www.rust-lang.org/community</a>, where all the current community resources (such as the forum and chats) are kept.</p>
<p><strong>Why are RFCs preferred over PRs?</strong></p>
<p>To contribute changes to the Rust programming language, <kbd>cargo</kbd>, or <kbd>crates.io</kbd>, the traditional fork-then-change-and-PR (pull request) won't work (especially if there are major changes). RFCs are the formal process required for substantial changes to either of the three projects and allow the wider community to discuss and evaluate the proposed changes, as well as contribute to them. This is the Rust community's effort to effectively govern something as fundamental as a programming language.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Chapter 2</h1>
                </header>
            
            <article>
                
<p><strong>What does cargo do?</strong></p>
<p>Read and write access to repositories, run tests, dependency management (download, update, and managing the dependency tree), executing the build process, and providing a central interface for additional tooling.</p>
<p><strong>Does cargo provide linting support?</strong></p>
<p><kbd>cargo</kbd> itself doesn't, but there are additional tools, such as <kbd>clippy</kbd> (<a href="https://github.com/rust-lang/rust-clippy">https://github.com/rust-lang/rust-clippy</a>), that work seamlessly with <kbd>cargo</kbd>.</p>
<p><strong>In which cases is the Cargo.lock file important to publish?</strong></p>
<p>For libraries. The file is used by cargo to determine the exact versions of the dependency tree. As a consequence, there should not be any version issues caused by unintentionally updated dependencies.</p>
<p><strong>What are the requirements to publish to crates.io?</strong></p>
<p>Passing tests, no uncommitted files in the repository, a valid account, and an available spot on <kbd>crates.io</kbd>.</p>
<p><strong>What is Wasm and why should you care?</strong></p>
<p>Wasm is a compilation target that can be executed in traditional JavaScript environments, such as browsers or the Node runtime. This skips the compilation steps required for JavaScript as well as its garbage collection, so Wasm binaries are better suited for (near-) real-time applications with a browser UI component. They can be simply run in the JavaScript world. </p>
<p><strong>How are tests organized in a Rust project?</strong></p>
<p>Tests can either be added to each file in a module, annotated by <kbd>#[tests]</kbd> and <kbd>#[test]</kbd>, as well as <kbd>#[bench]</kbd>. These can also be placed into their own file structure under <kbd>test/</kbd> in the component's directory. Additionally, Rust supports doctests, which are executed when the docstring (<kbd>///</kbd>) has an example section that contains code. </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Chapter 3</h1>
                </header>
            
            <article>
                
<p><strong>How are Sized types different from other types?</strong></p>
<p>Sized means that the size of a type instance is known at runtime, so it doesn't contain a growing data type. For example, <kbd>str</kbd> is typically not a sized type <span>–</span> <kbd>String</kbd> is. </p>
<p><strong>How does Clone differ from Copy?</strong></p>
<p>Clone is an explicit call to the <kbd>clone()</kbd> function; copy happens implicitly, for example, at assignments. Since Clone is explicitly called, it usually does a deep copy on the underlying data structure. </p>
<p><strong>What are the main drawbacks of immutable data structures?</strong></p>
<p>Immutable data structures can have worse absolute performances since they can't use the optimizations that regular data structures provide. Additionally, updates on the data that's contained is impossible, making it a very inefficient choice for constantly changing data.</p>
<p><strong>How can applications benefit from immutable data structures?</strong></p>
<p>They implicitly keep track of changes and work well across threads without side effects or the need for locking. </p>
<p><strong>Think about an immutable list that you want to work on—how would you </strong><strong>distribute it across multiple threads?</strong></p>
<p>Depending on the task, it can be split into <em>n</em> chunks, where <em>n</em> is the number of threads. However, this requires you to create <em>n</em> copies of the list—or at least a move per each. Alternatively, the list can be made accessible across threads, providing only the indices to represent the chunks to work on. </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Chapter 4</h1>
                </header>
            
            <article>
                
<p><strong>Why is a linked list tricky to implement in Rust?</strong></p>
<p>Rust's ownership principle makes it hard to implement non-hierarchical structures, such as the doubly-linked list. There, it's unclear which node owns which area of the memory, since both neighbors hold a reference that can't be invalid. </p>
<p><strong>How does Rust's standard library, LinkedList&lt;T&gt;, work?</strong></p>
<p>It's a doubly-linked list: individual nodes are interlinked, just like the implementation in this chapter.</p>
<p><strong>What is the difference between a doubly-linked list and a skip list?</strong></p>
<p>A skip list has multiple levels where nodes are linked together to achieve a tree-like search performance. Therefore, the skip list has to be ordered and stores multiple pointers to successors and predecessors. The doubly-linked list has only two links (forward and backward), doesn't need to be sorted, and achieves linear search performance at best.</p>
<p><strong>Does a dynamic array outperform a skip list for element access?</strong></p>
<p>Yes, if the skip list doesn't use a dynamic array as a base!</p>
<p><strong>Why is a dynamic array a great choice for CPU caching?</strong></p>
<p>The data is stored in a large continuous portion of the memory, with the elements stored one after the other. Caching always builds on blocks of memory, which is why caching several elements that are likely processed after each other makes the dynamic array well-suited for that. </p>
<p><strong>What is another growth strategy for dynamic arrays?</strong></p>
<p>Memory can be doubled, increased by a certain amount each time, or logarithmically so that it grows fast in the beginning and slows down later on. </p>
<p><strong>Rust takes arrays seriously, so what does the dynamic array use internally?</strong></p>
<p>It uses a boxed slice. </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Chapter 5</h1>
                </header>
            
            <article>
                
<p><strong>How does a binary search tree skip several nodes when searching?</strong></p>
<p>By following one branch, it skips one subtree every time the decision for one branch is made. A subtree can be anything from a single node to all nodes except one.</p>
<p><strong>What are self-balancing trees?</strong></p>
<p>Trees that use some kind of logic to (roughly) equalize the number of nodes in each subtree. This ensures that all tree algorithms work at the best possible efficiency.</p>
<p><strong>Why is balance in a tree important?</strong></p>
<p>If a tree is skewed, any algorithm operating on it will encounter an uneven amount of work depending on the subtree it works on. The mismatch is the assumption that every branch of the tree leads to the same amount of work (for example, the same number of comparisons to make), which is what makes the tree data structure efficient. </p>
<p><strong>Is a heap a binary tree?</strong></p>
<p>Yes. Each node has two children. </p>
<p><strong>What are good use cases for tries?</strong></p>
<p>Here are mine: A trie set is a very efficient data structure for guaranteeing uniqueness, there are sequence prediction methods based on tries, and they can do a lossless data compression. </p>
<p><strong>What is a B-Tree?</strong></p>
<p>A B-Tree is a tree with a defined level that relates to the number of children in each node. Thus, it is a self-balancing generalization of all trees: a level 2 B-Tree is akin to a binary tree, but more children will make the data structure more efficient and avoid unnecessary heights.</p>
<p><strong>What are the fundamental components of a graph?</strong></p>
<p>Graphs are nodes that are connected with edges. These nodes typically have a value; the value on the edges is referred to as weights. In a general graph, there are no directions on the edges, but further constraints can make it directed, acyclic, or otherwise limited. Graphs are the superstructure of all lists and trees.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Chapter 6</h1>
                </header>
            
            <article>
                
<p><strong>What makes a good hash function?</strong></p>
<p>It depends on the use case. Cryptography should minimize collisions, message digests should maximize hash differences on minor input differences, and bloom filters should do the reverse. </p>
<p><strong>How can you estimate the suitability of a hash function for a particular task?</strong></p>
<p>By using plots and tests to get a sense of how the output hashes are distributed and whether that's what you're looking for. Histograms and scatter plots work well to see the distribution of values. Also, search the internet for potential breaches or weaknesses and the original paper.</p>
<p><strong>Is a checksum hash useful in other ways?</strong></p>
<p>They can also be useful to determine whether two texts or files are equal, which can be used for finding matches quickly or to check whether the content is the content that was transferred or whether the content has been tampered with. </p>
<p><strong>What are two ways to implement a map?</strong></p>
<p>Using trees or using hashing.</p>
<p><strong>What are buckets?</strong></p>
<p>Buckets are the hash values that are mapped onto the underlying data structure. Hashes might output <kbd>u64</kbd>, but <kbd>Vec&lt;T&gt;</kbd> only has a length of 100. Therefore, multiple hashes share an index in <kbd>Vec&lt;T&gt;</kbd>, which is called a bucket.</p>
<p><strong>Can a set replace a list? </strong></p>
<p>Only if uniqueness is a required constraint for the contents. </p>
<p><strong>What makes a set useful?</strong></p>
<p>Quick and specialized set operations, such as union, intersect, difference, and fast "contains" lookups, as well as the ability to guarantee uniqueness with better efficiency.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Chapter 7</h1>
                </header>
            
            <article>
                
<p><strong>Which<span> </span>std::collections<span> </span>data structure is not discussed here?</strong></p>
<p><kbd>BinaryHeap</kbd> (<a href="https://doc.rust-lang.org/std/collections/struct.BinaryHeap.html">https://doc.rust-lang.org/std/collections/struct.BinaryHeap.html</a>).</p>
<p><strong>How does<span> </span>Vec&lt;T&gt;<span> </span>or<span> </span>VecDeque&lt;T&gt;<span> </span>grow, as of 2018?</strong></p>
<p>They double (or more) their size when more space is required. </p>
<p><strong>Is<span> </span>LinkedList&lt;T&gt;<span> </span>a good default data structure?</strong></p>
<p>No. It doesn't provide index access and is generally slower than <kbd>Vec&lt;T&gt;</kbd>, thanks to the internal memory structure, but provides the same basic features. </p>
<p><strong>What hashing implementation does the 2018<span> </span>HashMap&lt;T&gt; use by default?</strong></p>
<p>SipHashing. There are others that are on their way into the standard library, such as the <kbd><span>hashbrown</span></kbd> crate (<a href="https://github.com/Amanieu/hashbrown">https://github.com/Amanieu/hashbrown</a>).</p>
<p><strong>What are three benefits of<span> </span>BTreeMap&lt;T&gt; over HashMap&lt;T&gt;?</strong></p>
<p>Use any three, but here are some suggestions:</p>
<ul>
<li>Ordered keys</li>
<li>Lower computational intensity (no hashing required)</li>
<li>No hash function required—good performance regardless</li>
</ul>
<p><strong>I</strong><strong>s the internal tree of<span> </span>BTreeMap&lt;T&gt; wider or higher?</strong></p>
<p>Wider, thanks to a larger number of children (up to <em>2 * level - 1</em>) for efficient CPU caching.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Chapter 8</h1>
                </header>
            
            <article>
                
<p><strong>Why estimate runtime complexity over something such as the number of statements?</strong></p>
<p>Runtime complexity is more about the projected growth alongside the main input parameter. In a way, it <em>is</em> counting the number of statements and you would likely arrive at the same conclusion. The statements that are being counted are the subset that matters most.</p>
<p><strong>How does runtime complexity relate to math functions?</strong></p>
<p>In two ways: mathematical functions can be described the same way as functions in programming, since they rest on the same fundamental construct; and math functions are used to express the runtime complexity itself, in particular the logarithmic and exponential functions. </p>
<p><strong>Is the complexity class that is typically provided the best or worst case?</strong></p>
<p>The worst case, since this will be the slowest/most inefficient case.</p>
<p><strong>Why are loops important in estimating complexity?</strong></p>
<p>Loops are great constructs that repeatedly execute statements and, depending on the growth parameter, will drive the function's runtime complexity.</p>
<p><strong>Is O(n log(n)) a better or worse runtime complexity than O(log(n))?</strong></p>
<p><em>O(log(n))</em> is clearly a better runtime complexity. Try replacing the <em>n</em> with three numbers of your choice and calculate <em>log(n)</em> versus <em>n * log(n)</em>. </p>
<p><strong>What are some common known complexity classes?</strong></p>
<p><em>O(n)</em>, <em>O(log(n)</em>, <em>O(n²)</em>, and <em>O(2<sup>n</sup>)</em>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Chapter 9</h1>
                </header>
            
            <article>
                
<p><strong>What is information retrieval?</strong></p>
<p>All disciplines surrounding storage, search, ranking, tokenization, analysis, and a general understanding of an information structure. It's everything that a good search engine does well.</p>
<p><strong>Do modern search engines and databases use simple search algorithms?</strong></p>
<p>Yes. Regardless of the abstraction on top of the search index, the storing of tokens is often done in a linear, append-only fashion that allows for efficient search (binary search) on these segments. </p>
<p><strong>Why does the linear search have O(n) runtime complexity?</strong></p>
<p>In case an element doesn't exist in the sequence, it has to walk over all <em>n</em> items to be sure. </p>
<p><strong>What does jump search do better than linear search?</strong></p>
<p>It skips parts of the list since, in an ordered list, certain locations can be ruled out based on the sorting. Therefore, it <span>significantly </span>reduces the number of elements that are searched for linearly.</p>
<p><strong>What is binary search and why is it comparable to a tree?</strong></p>
<p>Binary search splits the input sequence in half and only continues on the part that has to contain the element. Drawing these parts visually (including those that have been skipped) looks just like a binary tree, which is why the two parts are effectively branches. </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Chapter 10</h1>
                </header>
            
            <article>
                
<p><strong>Why is sorting an important aspect of programming?</strong></p>
<p>Establishing a predictable order so that algorithms can make assumptions based on the content (for example, for search) will <span>enable it to perform much better</span>. Another important aspect is user experience in user interfaces, or to establish a semantic link between data points (for example, a time series can now have trends).</p>
<p><strong>What makes values bubble up in bubble sort?</strong></p>
<p>By repeatedly swapping a pair of elements when going through the sequence, elements that belong on the opposite end (or close to it) will have to swap places with every other element on the way. Therefore, the large number "bubbles up."</p>
<p><strong>Why is shell sort useful?</strong></p>
<p>It achieves solid sorting performances, yet it's not as complex as merge sort and uses less computational resources. This makes it great in scenarios where hardware can be bottlenecked (embedded devices) or other sorting approaches aren't available (for example, if the standard library is not supported).</p>
<p><strong>Can heap sort outperform bubble sort in its best case?</strong></p>
<p>No. Bubble sort's best case is simply iterating the list <span>–</span> <em>O(n)</em>. Heap sort, on the other hand, always has to build a heap, regardless of the sequence being already sorted or not <span>–</span> <em>O(n log n)</em>.</p>
<p><strong>What do merge sort and quicksort have in common?</strong></p>
<p>The divide-and-conquer approach: both split the sequence into smaller pieces so that they can work on those separately.</p>
<p><strong>What are hybrid sorting algorithms?</strong></p>
<p>Hybrid sorting algorithms use the strengths of at least two different approaches. Timsort, for example, uses insertion sort for smaller sequences (for example, under 20 items) but merge sort for larger ones.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Chapter 11</h1>
                </header>
            
            <article>
                
<p><strong>What is the difference between PRNGs and RNGs?</strong></p>
<p>Pseudo-random number generators (PRNGs) use a process to generate a close-to-random sequence of numbers that are as statistically independent as possible. Random number generators (RNGs) try to use true randomness (for example, phenomena from the physical world that cannot be predicted) to generate random numbers.</p>
<p><strong>What crate provides random number generators in Rust?</strong></p>
<p><kbd>rand</kbd> is the most important one.</p>
<p><strong>How can backtracking solve combinatorial problems?</strong></p>
<p>Backtracking recursively tries out possible combinations and evaluates their validity as soon as possible. This allows you to backtrack the bad solutions and save good solutions.</p>
<p><strong>What is dynamic programming?</strong></p>
<p>A programming technique that saves and uses common intermediate solutions to improve the algorithm's runtime complexity.</p>
<p><strong>How are metaheuristics a problem-agnostic approach to solving hard problems?</strong></p>
<p>Metaheuristics use generally applicable strategies to find the best solution. These strategies can be inspired by nature (natural selection, animal behavior, physical processes) and repeatedly generate and evaluate parameters to improve the next solution. If the generation and validation of a problem is supplied by the user, the approach can be problem-agnostic and since the strategies take care of converging toward the best solution, they can provide a best guess in predictable time.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Chapter 12</h1>
                </header>
            
            <article>
                
<p><strong>Where is Rust's implementation of generic algorithms on collections?</strong></p>
<p>The slice primitive type.</p>
<p><strong>When is linear search better than binary search?</strong></p>
<p>If the sequence is short and not sorted—the time it takes to sort it would be longer than a simple linear search.</p>
<p><strong><em>Potential job interview question:</em> What are stable and unstable sorting algorithms?</strong></p>
<p>Stable sorting algorithms maintain a relative order between equal elements, while unstable sorting algorithms don't. This means that if there are sequences of the same number, the entire block will show up in the sorted collection exactly in the same order.</p>
<p><strong>What is a bad behavior of Quicksort that pattern-defeating Quicksort mitigates?</strong></p>
<p>The choice of bad pivots is the most important problem that is mitigated. This is done by employing strategies to improve the selection or, if all else fails, use heap sort to achieve at least a <em>O(n log n)</em> runtime complexity (instead of quicksort's <em>O(n²)</em>). </p>


            </article>

            
        </section>
    </body></html>