<html><head></head><body><div id="sbo-rt-content"><div id="_idContainer106">&#13;
			<h1 id="_idParaDest-159"><em class="italic"><a id="_idTextAnchor158"/>Chapter 9</em>: Structuring a Python Flask App for Rust</h1>&#13;
			<p>In the previous chapter, we managed to solve a real-world problem with Rust. However, we also learned an important lesson, that is, the good implementation of code, such as adding vectors or merging dataframes, along with third-party modules, such as <strong class="source-inline">NumPy</strong>, can outperform badly implemented self-coded Rust solutions. However, we know that comparing implementation to implementation, Rust is a lot faster than Python. We already understand how to fuse Rust with a standard Python script. However, Python is used for more than just running scripts. A popular use for Python is in web applications.</p>&#13;
			<p>In this chapter, we will build a Flask web application with NGINX, a database, and a message bus implemented by the <strong class="source-inline">Celery</strong> package. This message bus will allow our application to process heavy tasks in the background while we return a web HTTP request. The web application and message bus will be wrapped in Docker containers and deployed to <strong class="source-inline">docker-compose</strong>. However, nothing is preventing us from deploying the application onto a cloud platform if desired. </p>&#13;
			<p>In this chapter, we will cover the following topics:</p>&#13;
			<ul>&#13;
				<li>Building a basic Flask application</li>&#13;
				<li>Defining a database access layer</li>&#13;
				<li>Building a message bus</li>&#13;
			</ul>&#13;
			<p>This chapter will enable us to build a foundation for deployable Python web applications that have a range of features and services. This foundation allows us to discover how to fuse Rust with Python web applications that are wrapped in Docker containers. </p>&#13;
			<h1 id="_idParaDest-160"><a id="_idTextAnchor159"/>Technical requirements</h1>&#13;
			<p>The code and data for this chapter can be found at <a href="https://github.com/PacktPublishing/Speed-up-your-Python-with-Rust/tree/main/chapter_nine">https://github.com/PacktPublishing/Speed-up-your-Python-with-Rust/tree/main/chapter_nine</a>.</p>&#13;
			<p>In addition to this, we will be using <strong class="source-inline">docker-compose</strong> on top of Docker to orchestrate our Docker containers. This can be installed by following the instructions at <a href="https://docs.docker.com/compose/install/">https://docs.docker.com/compose/install/</a>.</p>&#13;
			<p>In this chapter, we will be building a Docker-contained Flask application, which is available via the GitHub repository at <a href="https://github.com/maxwellflitton/fib-flask">https://github.com/maxwellflitton/fib-flask</a>.</p>&#13;
			<h1 id="_idParaDest-161"><a id="_idTextAnchor160"/>Building a basic Flask application</h1>&#13;
			<p>Before we begin <a id="_idIndexMarker604"/>adding any additional features such as a database to an application, we have to ensure that that we can get a basic Flask application up and running with everything that we need. This application will take in a number and return a Fibonacci number. Additionally, we will need to make sure that this application can run in its own Docker container if we were to deploy it. By the end of this section, our application should have the following structure:</p>&#13;
			<p class="source-code">├── deployment</p>&#13;
			<p class="source-code">│   ├── docker-compose.yml</p>&#13;
			<p class="source-code">│   └── nginx</p>&#13;
			<p class="source-code">│       ├── Dockerfile</p>&#13;
			<p class="source-code">│       └── nginx.conf</p>&#13;
			<p class="source-code">├── src</p>&#13;
			<p class="source-code">│   ├── Dockerfile</p>&#13;
			<p class="source-code">│   ├── __init__.py</p>&#13;
			<p class="source-code">│   ├── app.py</p>&#13;
			<p class="source-code">│   ├── fib_calcs</p>&#13;
			<p class="source-code">│   │   ├── __init__.py</p>&#13;
			<p class="source-code">│   │   └── fib_calculation.py</p>&#13;
			<p class="source-code">│   └── requirements.txt</p>&#13;
			<p>Here, you can see that the application is housed in the <strong class="source-inline">src</strong> directory. When running our application, we must ensure that the <strong class="source-inline">PYTHONPATH</strong> path is set to <strong class="source-inline">src</strong>. The code required for our deployment exists in the <strong class="source-inline">deployment</strong> directory. To build an application so that it can <a id="_idIndexMarker605"/>run in Docker, perform the following steps:</p>&#13;
			<ol>&#13;
				<li>Build an entry point for our application. </li>&#13;
				<li>Build a Fibonacci number calculation module.</li>&#13;
				<li>Build a Docker image for our application.</li>&#13;
				<li>Build our NGINX service.</li>&#13;
			</ol>&#13;
			<p>Once we have completed all of these steps, we will have a basic Flask application that can be run on a server. Now, let's explore each of these steps in detail in the following subsections.</p>&#13;
			<h2 id="_idParaDest-162"><a id="_idTextAnchor161"/>Building an entry point for our application</h2>&#13;
			<p>Here are the steps <a id="_idIndexMarker606"/>to perform:</p>&#13;
			<ol>&#13;
				<li value="1">Before we can build our entry point, we need to install the Flask module using the following command:<p class="source-code"><strong class="bold">pip install flask</strong></p></li>&#13;
				<li>Once this is done, we have all we need to create a basic Flask application by defining the entry point in the <strong class="source-inline">src/app.py</strong> file using the following code:<p class="source-code">from flask import Flask</p><p class="source-code">app = Flask(__name__)</p><p class="source-code">@app.route("/")</p><p class="source-code">def home():</p><p class="source-code">    return "home for the fib calculator"</p><p class="source-code">if __name__ == "__main__":</p><p class="source-code">    app.run(use_reloader=True, port=5002, \</p><p class="source-code">      threaded=True)</p></li>&#13;
			</ol>&#13;
			<p>Here, observe <a id="_idIndexMarker607"/>that we can define a basic route with the decorator. We can run our application by running the <strong class="source-inline">src/app.py</strong> script; this will run our server locally, enabling us to access all of the routes that we have defined. Passing the <strong class="source-inline">http://127.0.0.1:5002</strong> URL into our browser will give us the following view:</p>&#13;
			<div>&#13;
				<div id="_idContainer099" class="IMG---Figure">&#13;
					<img src="Images/Figure_9.01_B17720.jpg" alt="Figure 9.1 – The main view of our local Flask server&#13;&#10;" width="568" height="139"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="figure-caption">Figure 9.1 – The main view of our local Flask server</p>&#13;
			<p>Now that our basic server is running, we can move on to build a Fibonacci number calculator module.</p>&#13;
			<h2 id="_idParaDest-163"><a id="_idTextAnchor162"/>Building our Fibonacci number calculator module</h2>&#13;
			<p>Here are the<a id="_idIndexMarker608"/> steps to <a id="_idIndexMarker609"/>perform:</p>&#13;
			<ol>&#13;
				<li value="1">In this example, our application is simple. As a result, we can define our module's functionality within one file in one class. We define it within the <strong class="source-inline">src/fib_calcs/fib_calculation.py</strong> file using the following code:<p class="source-code">class FibCalculation:</p><p class="source-code">    def __init__(self, input_number: int) -&gt; None:</p><p class="source-code">        self.input_number: int = input_number</p><p class="source-code">        self.fib_number: int = self.recur_fib(</p><p class="source-code">            n=self.input_number</p><p class="source-code">        )</p><p class="source-code">    @staticmethod</p><p class="source-code">    def recur_fib(n: int) -&gt; int:</p><p class="source-code">        if n &lt;= 1:</p><p class="source-code">            return n</p><p class="source-code">        else:</p><p class="source-code">            return (FibCalculation.recur_fib(n - 1) +</p><p class="source-code">                    FibCalculation.recur_fib(n - 2))</p><p>Here, notice that our class merely takes in an input number and automatically populates the <strong class="source-inline">self.fib_number</strong> attribute with the calculated Fibonacci number. </p></li>&#13;
				<li>Once that <a id="_idIndexMarker610"/>is done, we <a id="_idIndexMarker611"/>can define a view that accepts an integer through the URL, passes it to our <strong class="source-inline">FibCalculation</strong> class, and returns the calculated Fibonacci number as a string to the user in our <strong class="source-inline">src/app.py</strong> file using the following code:<p class="source-code">from fib_calcs.fib_calculation import FibCalculation</p><p class="source-code">. . .</p><p class="source-code">@app.route("/calculate/&lt;int:number&gt;")</p><p class="source-code">def calculate(number):</p><p class="source-code">    calc = FibCalculation(input_number=number)</p><p class="source-code">    return f"you entered {calc.input_number} " \</p><p class="source-code">           f"which has a Fibonacci number of " \</p><p class="source-code">           f"{calc.fib_number}"</p></li>&#13;
				<li>Rerunning<a id="_idIndexMarker612"/> our server and <a id="_idIndexMarker613"/>passing the <strong class="source-inline">http://127.0.0.1:5002/calculate/10</strong> URL into our browser will give us the following view:</li>&#13;
			</ol>&#13;
			<div>&#13;
				<div id="_idContainer100" class="IMG---Figure">&#13;
					<img src="Images/Figure_9.02_B17720.jpg" alt="Figure 9.2 – Calculating the view of our local Flask server&#13;&#10;" width="730" height="135"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="figure-caption">Figure 9.2 – Calculating the view of our local Flask server</p>&#13;
			<p>Now our application performs its intended purpose: it calculates a Fibonacci number based on the input. There is more to views with Flask; however, this book is not a web development textbook. If you want to learn how to build more comprehensive API endpoints, we advise that you look into the Flask API and <strong class="source-inline">Marshmallow</strong> packages. References to both are available in the <em class="italic">Further reading</em> section. Now, we need to make our application deployable so that we can use it in a range of settings for our next step.</p>&#13;
			<h2 id="_idParaDest-164"><a id="_idTextAnchor163"/>Building a Docker image for our application </h2>&#13;
			<p>For our application to be<a id="_idIndexMarker614"/> usable, we must build a Docker image of our application that accepts requests. Then, we must protect it with another container call that acts as an ingress. NGINX performs load balancing, caching, streaming, and the redirecting of traffic. Our application will be run using the Gunicorn package, which, essentially, runs multiple workers of our application at the same time. For each request, NGINX asks which Gunicorn worker the request should go to and redirects it, as shown in the following diagram:</p>&#13;
			<p class="figure-caption">  </p>&#13;
			<div>&#13;
				<div id="_idContainer101" class="IMG---Figure">&#13;
					<img src="Images/Figure_9.03_B17720.jpg" alt="Figure 9.3 – The flow of requests for our application&#13;&#10;" width="1149" height="538"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="figure-caption">Figure 9.3 – The flow of requests for our application</p>&#13;
			<p>We can achieve the layout defined in the preceding diagram by performing the following steps:</p>&#13;
			<ol>&#13;
				<li value="1">Before we build a<a id="_idIndexMarker615"/> Docker image, we must make sure the requirements for our application are handled. Therefore, we must install Gunicorn using <strong class="source-inline">pip</strong> with the following command:<p class="source-code"><strong class="bold">pip install gunicorn</strong></p></li>&#13;
				<li>We must make sure that we are in the <strong class="source-inline">src</strong> directory because we are going to dump all of our application dependencies into a file called <strong class="source-inline">requirements.txt</strong> using the following command:<p class="source-code"><strong class="bold"> pip freeze &gt; requirements.txt</strong></p><p>This gives us a text file with a list of all the dependencies that our application needs in order to run. Right now, all we need is Flask and Gunicorn.</p></li>&#13;
				<li>With this, we can start coding our Docker file so that we can build application images of our application. First, in our <strong class="source-inline">src/Dockerfile</strong> file, we should define the operating system that is required with the following code:<p class="source-code">FROM python:3.6.13-stretch</p><p>This means that our image is running a stripped-down version of Linux with Python installed.</p></li>&#13;
				<li>Now that we have the<a id="_idIndexMarker616"/> correct operating system, we should define our app's directory and copy all of our application files into the image using the following code:<p class="source-code"># Set the working directory to /app</p><p class="source-code">WORKDIR /app</p><p class="source-code"># Copy the current directory contents into the </p><p class="source-code">  container at /app</p><p class="source-code">ADD . /app</p></li>&#13;
				<li>Now that all of our application files are in the image, we install system updates and then install the <strong class="source-inline">python-dev</strong> package. This is so that we can include extensions with the code given here:<p class="source-code">RUN apt-get update -y</p><p class="source-code">RUN apt-get install -y python3-dev python-dev gcc</p><p>This will enable us to compile our Rust code in our application and use database binaries.</p><p>Our system has now been set up, so we can move on to install our requirements using the following code:</p><p class="source-code">RUN pip install --upgrade pip setuptools wheel</p><p class="source-code">RUN pip install -r requirements.txt</p><p>Everything is in place to define our system. Nothing is stopping us from running our application. </p></li>&#13;
				<li>To do this, we expose the port and run our application using the following code:<p class="source-code">EXPOSE 5002</p><p class="source-code">CMD ["gunicorn", "-w 4", "-b", "0.0.0.0:5002", \</p><p class="source-code">  "app:app"]</p><p>Note that when<a id="_idIndexMarker617"/> we create a container from the image, we run <strong class="source-inline">CMD</strong> with the parameters defined in the list. We state that we have four workers with the <strong class="source-inline">-w 4</strong> parameter. Then, we define the URL and port that we are listening to. Our final parameter is <strong class="source-inline">app:app</strong>. This states that our application is housed in the <strong class="source-inline">app.py</strong> file, and our application in that file is the <strong class="source-inline">Flask</strong> object under the variable name of <strong class="source-inline">app</strong>. </p></li>&#13;
				<li>We can now build our application image using the following command:<p class="source-code"><strong class="bold">docker build . -t flask-fib</strong></p><p>The result is a very long stream of console printouts, but essentially, our Docker image is built with the <strong class="source-inline">flask-fib</strong> tag. </p></li>&#13;
				<li>We can then inspect our images using the following command:<p class="source-code"><strong class="bold">docker image ls</strong></p><p>Running this command gives us an image that has been created in the following form:</p><p class="source-code"><strong class="bold">REPOSITORY      TAG         IMAGE ID</strong></p><p class="source-code"><strong class="bold">flask-fib</strong><strong class="bold">       latest      0cdb0c979ac1</strong></p><p class="source-code"><strong class="bold">CREATED          SIZE</strong></p><p class="source-code"><strong class="bold">33 minutes ago   1.05GB</strong></p></li>&#13;
			</ol>&#13;
			<p>This is important. We will need to reference our image later when we are running our application with NGINX, which we will define next.</p>&#13;
			<h2 id="_idParaDest-165"><a id="_idTextAnchor164"/>Building our NGINX service </h2>&#13;
			<p>When it comes to <a id="_idIndexMarker618"/>Docker and NGINX, we are lucky in that we do not have to build a Dockerfile that defines our NGINX image. NGINX has released an official image that we can download and use for free. However, we do have to alter its configuration. NGINX is fairly important; this is because it gives us the ability to control how incoming requests are processed. We can redirect the requests to different services depending on parts of the URL. Additionally, we can control the size of the data, the duration of the connection, and configure HTTPS traffic. NGINX can also act as a load balancer. In this example, we are going to configure NGINX in the simplest format to get it running. However, it must be noted that NGINX is a vast topic in itself; a reference to a useful NGINX book is provided in the <em class="italic">Further reading</em> section.</p>&#13;
			<p>We can build our NGINX service and connect it to our Flask application by performing the following steps:</p>&#13;
			<ol>&#13;
				<li value="1">We will configure our NGINX container with what we code in the <strong class="source-inline">deployment/nginx/nginx.conf</strong> file. In this file, we declare our worker processes and error log, as follows:<p class="source-code">worker_processes  auto;</p><p class="source-code">error_log  /var/log/nginx/error.log warn;</p><p>Here, we have defined <strong class="source-inline">worker_processes</strong> as <strong class="source-inline">auto</strong>. This is where we automatically detect the number of CPU cores available, setting the number of processes to the number of CPU cores. </p></li>&#13;
				<li>Now, we have to define the maximum number of connections that a worker can entertain at a time using the following code:<p class="source-code">events {</p><p class="source-code">    worker_connections  512;</p><p class="source-code">}</p><p>It must be noted that the number that is chosen here is the default number for NGINX.</p></li>&#13;
				<li>All that is now left for us to do is to define our HTTP listener. This can be achieved with the following code:<p class="source-code">http {</p><p class="source-code">    server {</p><p class="source-code">           listen 80;</p><p class="source-code">           location / {</p><p class="source-code">                proxy_pass http://flask_app:5002/;</p><p class="source-code">           }</p><p class="source-code">    }</p><p class="source-code">}</p><p>Here, observe<a id="_idIndexMarker619"/> that we listen to port <strong class="source-inline">80</strong>, which is the standard outside listening port. Then, we state that if there is any pattern to our URL, we pass it to our <strong class="source-inline">flask_app</strong> container at port <strong class="source-inline">5002</strong>. We can stack multiple locations in the <strong class="source-inline">http</strong> section if we wish. For instance, if we have another app, we can route the request to the other application if the URL tail starts with <strong class="source-inline">/another_app/</strong> using the following code:</p><p class="source-code">           location /another_app {</p><p class="source-code">                proxy_pass http://another_app:5002/;</p><p class="source-code">           }</p><p class="source-code">           location / {</p><p class="source-code">                proxy_pass http://flask_app:5002/;</p><p class="source-code">           }</p></li>&#13;
			</ol>&#13;
			<p>Our configuration file for our NGINX is complete. Again, there are many more configuration parameters; we are just running the bare minimum. More resources on these parameters<a id="_idIndexMarker620"/> are signposted in the <em class="italic">Further reading</em> section. Considering that our NGINX configuration file is complete, for the next step, we have to run it alongside our Flask application. </p>&#13;
			<h2 id="_idParaDest-166"><a id="_idTextAnchor165"/>Connecting and running our Nginx service </h2>&#13;
			<p>To run our application and NGINX together, we will be using <strong class="source-inline">docker-compose</strong>. This allows us to define multiple Docker containers at the same time that can talk to each other. Nothing is stopping us from running <strong class="source-inline">docker-compose</strong> on a server to achieve a basic setup. However, more advanced systems such as Kubernetes can help with the orchestration of Docker containers <a id="_idIndexMarker621"/>across multiple servers<a id="_idIndexMarker622"/> if needed. In addition to this, different cloud platforms offer out-of-the-box load balancers. Perform the following steps:</p>&#13;
			<ol>&#13;
				<li value="1">In our <strong class="source-inline">deployment/docker-compose.yml</strong> file, we state what version of <strong class="source-inline">docker-compose</strong> we are using with the following code:<p class="source-code">version: "3.7"</p></li>&#13;
				<li>Now that this has been implemented, we can define our services along with our first service, which is our Flask application. This is defined with the following code:<p class="source-code">services:</p><p class="source-code">    flask_app:</p><p class="source-code">        container_name: fib-calculator</p><p class="source-code">        image: "flask-fib:latest"</p><p class="source-code">        restart: always</p><p class="source-code">        ports:</p><p class="source-code">          - "5002:5002"</p><p class="source-code">        expose:</p><p class="source-code">            - 5002</p><p>In the preceding code, we reference the image that we built with the latest release. For instance, if we changed the image and rebuilt it, then our <strong class="source-inline">docker-compose</strong> setup would use this. We also give it a container name, so we know the container status when checking the running containers. Additionally, we state that we accept traffic through port <strong class="source-inline">5002</strong>, and we route it to our container's port <strong class="source-inline">5002</strong>. Because we have chosen this path, we also expose port <strong class="source-inline">5002</strong>. If we run our <strong class="source-inline">docker-compose</strong> setup now, we could access our application with<a id="_idIndexMarker623"/> the <strong class="source-inline">http://localhost:5002</strong> URL. However, if this was running on a server and port <strong class="source-inline">5002</strong> was <a id="_idIndexMarker624"/>not accessible to outside traffic, then we would not be able to access it. </p></li>&#13;
				<li>Considering this, we can define our NGINX in our <strong class="source-inline">deployment/docker-compose.yml</strong> file using the following code:<p class="source-code">    nginx:</p><p class="source-code">        container_name: 'nginx'</p><p class="source-code">        image: "nginx:1.13.5"</p><p class="source-code">        ports:</p><p class="source-code">          - "80:80"</p><p class="source-code">        links:</p><p class="source-code">            - flask_app</p><p class="source-code">        depends_on:</p><p class="source-code">            - flask_app</p><p class="source-code">        volumes:</p><p class="source-code">          - ./nginx/nginx.conf:/etc/nginx/nginx.conf</p><p>Here, you can see that we rely on the third-party NGINX image and that we route the outside port of <strong class="source-inline">80</strong> to port <strong class="source-inline">80</strong>. Also, we link to our Flask application, and we depend on it, meaning that <strong class="source-inline">docker-compose</strong> will ensure that our Flask application is up and running before we run our NGINX service. In the <strong class="source-inline">volumes</strong> section, we replace the standard configuration file with the configuration file that we defined in the previous step. As a result, our NGINX service will run the configuration that we defined. It must be noted that this configuration switch will happen every time we run <strong class="source-inline">docker-compose</strong>. This means that if we change our configuration file and then run <strong class="source-inline">docker-compose</strong> again, we will see the changes. So, we have done everything to get our application up and running. Now we can test it.</p></li>&#13;
				<li>Testing our <a id="_idIndexMarker625"/>application is as easy as <a id="_idIndexMarker626"/>running the following command:<p class="source-code"><strong class="bold">Docker-compose up</strong></p><p>Our services will boot up, and we will get the following printout:</p><p class="source-code"><strong class="bold">Starting fib-calculator ... done</strong></p><p class="source-code"><strong class="bold">Starting nginx          ... done</strong></p><p class="source-code"><strong class="bold">Attaching to fib-calculator, nginx</strong></p><p class="source-code"><strong class="bold">fib-calculator | [2021-08-20 18:43:14 +0000] [1] </strong></p><p class="source-code"><strong class="bold">[INFO]</strong></p><p class="source-code"><strong class="bold">Starting gunicorn 20.1.0</strong></p><p class="source-code"><strong class="bold">fib-calculator | [2021-08-20 18:43:14 +0000] [1] </strong></p><p class="source-code"><strong class="bold">[INFO] </strong></p><p class="source-code"><strong class="bold">Listening at: http://0.0.0.0:5002 (1)</strong></p><p class="source-code"><strong class="bold">fib-calculator | [2021-08-20 18:43:14 +0000] [1] </strong></p><p class="source-code"><strong class="bold">[INFO] </strong></p><p class="source-code"><strong class="bold">Using worker: sync</strong></p><p class="source-code"><strong class="bold">fib-calculator | [2021-08-20 18:43:14 +0000] [8] </strong></p><p class="source-code"><strong class="bold">[INFO] </strong></p><p class="source-code"><strong class="bold">Booting worker with pid: 8</strong></p><p class="source-code"><strong class="bold">fib-calculator | [2021-08-20 18:43:14 +0000] [9] </strong></p><p class="source-code"><strong class="bold">[INFO] </strong></p><p class="source-code"><strong class="bold">Booting worker with pid: 9</strong></p><p class="source-code"><strong class="bold">. . .</strong></p><p class="source-code"><strong class="bold">nginx</strong><strong class="bold">        | /docker-entrypoint.sh: Configuration </strong></p><p class="source-code"><strong class="bold">complete; </strong></p><p class="source-code"><strong class="bold">ready for start up</strong></p><p>Here, notice that both of our services spin up without any problems. Our Flask application starts Gunicorn, starts listening at port <strong class="source-inline">5002</strong>, and boots up workers to process requests. Following this, our NGINX service looks for a range of configurations before<a id="_idIndexMarker627"/> concluding that the configuration is complete and that it is ready to<a id="_idIndexMarker628"/> start up. Also, note that the NGINX started after our Flask application was started. This is because we stated that our NGINX was dependent on our Flask application when building our <strong class="source-inline">docker-compose</strong> file.</p><p>Now, we can directly hit our localhost URL without having to specify a port because we are listening to the outside port of <strong class="source-inline">80</strong> with our NGINX. This gives us results similar to the following:</p></li>&#13;
			</ol>&#13;
			<div>&#13;
				<div id="_idContainer102" class="IMG---Figure">&#13;
					<img src="Images/Figure_9.04_B17720.jpg" alt="Figure 9.4 – Interacting with our fully containerized Flask application&#13;&#10;" width="367" height="73"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="figure-caption">Figure 9.4 – Interacting with our fully containerized Flask application</p>&#13;
			<p>Now we have a fully containerized application that runs. This is at a ready state, so in the next chapter, we can test to see whether our Rust integration with our application will actually work in a real-life scenario. Now that we have gotten our application running, we can move on to build our data access layer. This will allow us to store and get data from a database. </p>&#13;
			<h1 id="_idParaDest-167"><a id="_idTextAnchor166"/>Defining our data access layer</h1>&#13;
			<p>Now we have an application <a id="_idIndexMarker629"/>that takes in a number and calculates a Fibonacci number based on it. However, a database lookup is quicker than a calculation. We will use this fact to optimize our application by initially performing a database lookup when a number is submitted. If it is not there, we calculate the number, store it in the database, and then return it to the user. Before we start building, we will have to install the following packages using <strong class="source-inline">pip</strong>:</p>&#13;
			<ul>&#13;
				<li><strong class="source-inline">pyml</strong>: This package helps in loading parameters for our application from a <strong class="source-inline">.yml</strong> file.</li>&#13;
				<li><strong class="source-inline">sqlalchemy</strong>: This package enables our application to map Python objects to databases for storing and querying. </li>&#13;
				<li><strong class="source-inline">alembic</strong>: This package helps in tracking and applying changes to the database from the application.</li>&#13;
				<li><strong class="source-inline">psycopg2-binary</strong>: This is the binary that will enable our application to connect to the database. </li>&#13;
			</ul>&#13;
			<p>Now that we have installed all that we need, we can enable our application to store and get Fibonacci numbers by performing the following steps:</p>&#13;
			<ol>&#13;
				<li value="1">Define a PostgreSQL database in <strong class="source-inline">docker-compose</strong>.</li>&#13;
				<li>Build a config loading system.</li>&#13;
				<li>Define a data access layer.</li>&#13;
				<li>Build database models.</li>&#13;
				<li>Set up the application database migration system.</li>&#13;
				<li>Apply the database access layer to the fib calculation view.</li>&#13;
			</ol>&#13;
			<p>Once we have<a id="_idIndexMarker630"/> completed these steps, our application will take the following form: </p>&#13;
			<p class="source-code">├── deployment</p>&#13;
			<p class="source-code">│   . . .</p>&#13;
			<p class="source-code">├── docker-compose.yml</p>&#13;
			<p class="source-code">├── src</p>&#13;
			<p class="source-code">│   . . .</p>&#13;
			<p class="source-code">│   ├── config.py</p>&#13;
			<p class="source-code">│   ├── config.yml</p>&#13;
			<p class="source-code">│   ├── data_access.py</p>&#13;
			<p class="source-code">│   ├── fib_calcs</p>&#13;
			<p class="source-code">│   │   . . .</p>&#13;
			<p class="source-code">│   ├── models</p>&#13;
			<p class="source-code">│   │   ├── __init__.py</p>&#13;
			<p class="source-code">│   │   └── database</p>&#13;
			<p class="source-code">│   │       ├── __init__.py</p>&#13;
			<p class="source-code">│   │       └── fib_entry.py</p>&#13;
			<p class="source-code">│   └── requirements.txt</p>&#13;
			<p>Our deployment file <a id="_idIndexMarker631"/>structure has not changed. We have added a <strong class="source-inline">docker-compose.yml</strong> file to our root as it will enable us to access the database when we are developing our application. In addition to this, we have added a data access file to enable us to connect to the database along with a <strong class="source-inline">models</strong> module to enable mapping objects to the database. This structure will result in a containerized Flask application that has access to a database. Next, we will begin defining our Docker container for our database. </p>&#13;
			<h2 id="_idParaDest-168"><a id="_idTextAnchor167"/>Defining a PostgreSQL database in docker-compose </h2>&#13;
			<p>To define our <a id="_idIndexMarker632"/>database container, we apply<a id="_idIndexMarker633"/> the following code to both the <strong class="source-inline">deployment/docker-compose.yml</strong> file and the <strong class="source-inline">docker-compose.yml</strong> file:</p>&#13;
			<p class="source-code">    Postgres:</p>&#13;
			<p class="source-code">      container_name: 'fib-dev-Postgres</p>&#13;
			<p class="source-code">      image: 'postgres:11.2'</p>&#13;
			<p class="source-code">      restart: always</p>&#13;
			<p class="source-code">      ports:</p>&#13;
			<p class="source-code">        - '5432:5432'</p>&#13;
			<p class="source-code">      environment:</p>&#13;
			<p class="source-code">        - 'POSTGRES_USER=user'</p>&#13;
			<p class="source-code">        - 'POSTGRES_DB=fib'</p>&#13;
			<p class="source-code">        - 'POSTGRES_PASSWORD=password'</p>&#13;
			<p>Here, you can observe that we are relying on the official third-party Postgres image. Instead of defining a configuration file, as we did with the NGINX service, we define the password, database name, and user using the environment variables. When we are running our local environment and developing our application, we will run our <strong class="source-inline">docker-compose</strong> file in the root. Now we have defined our database; in the next section, we can build our config system. </p>&#13;
			<h2 id="_idParaDest-169"><a id="_idTextAnchor168"/>Building a config loading system </h2>&#13;
			<p>Essentially, our <a id="_idIndexMarker634"/>configuration system loads parameters from a <strong class="source-inline">.yml</strong> file inside the Flask application by performing these steps:</p>&#13;
			<ol>&#13;
				<li value="1">Our application might require different parameters depending on the system. Because of this, we must build an object that loads parameters from a <strong class="source-inline">.yml</strong> file and serves them as a dictionary throughout the application. In our <strong class="source-inline">src/config.py</strong> file, first, we import what we need with the following code:<p class="source-code">import os</p><p class="source-code">import sys</p><p class="source-code">from typing import Dict, List</p><p class="source-code">import yaml</p><p>We will be using the <strong class="source-inline">sys</strong> module to take in the arguments that were passed into our application while running it. We use the <strong class="source-inline">os</strong> module to check whether the config file that we have specified in the arguments exists. </p></li>&#13;
				<li>Our global parameters object can be built using the following code:<p class="source-code">class GlobalParams(dict):</p><p class="source-code">    def __init__(self) -&gt; None:</p><p class="source-code">        super().__init__()</p><p class="source-code">        self.update(self.get_yml_file())</p><p class="source-code">    @staticmethod</p><p class="source-code">    def get_yml_file() -&gt; Dict:</p><p class="source-code">        file_name = sys.argv[-1]</p><p class="source-code">        if ".yml" not in file_name:</p><p class="source-code">            file_name = "config.yml"</p><p class="source-code">        if os.path.isfile(file_name):</p><p class="source-code">            with open("./{}".format(file_name)) as \</p><p class="source-code">              file:</p><p class="source-code">                data = yaml.load(file, </p><p class="source-code">                       Loader=yaml.FullLoader)</p><p class="source-code">            return data</p><p class="source-code">        raise FileNotFoundError(</p><p class="source-code">            "{} config file is not available".</p><p class="source-code">                format(file_name)</p><p class="source-code">        )</p><p class="source-code">    @property</p><p class="source-code">    def database_meta(self) -&gt; Dict[str, str]:</p><p class="source-code">        db_string: str = self.get("DB_URL")</p><p class="source-code">        buffer: List[str] = db_string.split("/")</p><p class="source-code">        second_buffer: List[str] = buffer[- \</p><p class="source-code">          2].split(":")</p><p class="source-code">        third_buffer: List[str] = \</p><p class="source-code">          second_buffer[1].split("@")</p><p class="source-code">        return {</p><p class="source-code">            "DB_URL": db_string,</p><p class="source-code">            "DB_NAME": buffer[-1],</p><p class="source-code">            "DB_USER": second_buffer[0],</p><p class="source-code">            "DB_PASSWORD": third_buffer[0],</p><p class="source-code">            "DB_LOCATION":f"{third_buffer[1]} \</p><p class="source-code">              :{second_buffer[-1]}",</p><p class="source-code">        }</p><p>Here, you can observe that our <strong class="source-inline">GlobalParams</strong> class directly inherits from the dictionary class. This means that we have all the functionality of a dictionary. In addition to this, note that we do not pass any arguments into our Python program specifying which <strong class="source-inline">.yml</strong> file to load; instead, we simply revert to the standard <strong class="source-inline">config.yml</strong> file. This is because we will use our configuration file for migrations to the database. It will be difficult to pass in our parameters when <a id="_idIndexMarker635"/>performing database migrations. If we want to change the configuration, it is best to get the new data and write it to the config file.</p></li>&#13;
				<li>Now that our config parameters class has been defined, we can add the database URL to our <strong class="source-inline">src/config.yml</strong> file using the following code:<p class="source-code">DB_URL: \</p><p class="source-code">"postgresql://user:password@localhost:5432/fib"</p></li>&#13;
			</ol>&#13;
			<p>Now that we have access to our database URL, in the next step, we can build our database access layer.</p>&#13;
			<h2 id="_idParaDest-170"><a id="_idTextAnchor169"/>Building our data access layer </h2>&#13;
			<p>Our database access <a id="_idIndexMarker636"/>will be defined in the <strong class="source-inline">src/data_access.py</strong> file. Once this is done, we can import the data access layer from the <strong class="source-inline">src/data_access.py</strong> file anywhere in the Flask application. This is so that we can access the database anywhere inside the Flask application. We can build this by performing the following steps:</p>&#13;
			<ol>&#13;
				<li value="1">First of all, we have to import what we need using the following code:<p class="source-code">from flask import _app_ctx_stack</p><p class="source-code">from sqlalchemy import create_engine</p><p class="source-code">from sqlalchemy.ext.declarative import </p><p class="source-code">declarative_base</p><p class="source-code">from sqlalchemy.orm import sessionmaker, </p><p class="source-code">scoped_session</p><p class="source-code">from config import GlobalParams</p><p>Here, we will use the <strong class="source-inline">_app_ctx_stack</strong> object to ensure that our session is in the context of the Flask request. Following this, we import all of the other <strong class="source-inline">sqlalchemy</strong> dependencies to ensure that our access has a session maker and an engine. We have to avoid going into excessive detail with database management as this book focuses on fusing Rust with Python and we are merely using SQLAlchemy to explore database integration with Rust. However, we should be able to get a feel for what the session, engine, and base do.</p></li>&#13;
				<li>Now that we have<a id="_idIndexMarker637"/> imported everything we need, we can build our database engine using the following code:<p class="source-code">class DbEngine:</p><p class="source-code">    def __init__(self) -&gt; None:</p><p class="source-code">        params = GlobalParams()</p><p class="source-code">        self.base = declarative_base()</p><p class="source-code">        self.engine = create_engine(params.get</p><p class="source-code">          ("DB_URL"),</p><p class="source-code">                                   echo=True,</p><p class="source-code">                                   pool_recycle=3600,</p><p class="source-code">                                   pool_size=2,</p><p class="source-code">                                   max_overflow=1,</p><p class="source-code">                                   connect_args={</p><p class="source-code">                                  'connect_timeout': 5</p><p class="source-code">                                    })</p><p class="source-code">        self.session = scoped_session(sessionmaker(</p><p class="source-code">            bind=self.engine</p><p class="source-code">        ), scopefunc=_app_ctx_stack)</p><p class="source-code">        self.url = params.get("DB_URL")</p><p class="source-code">dal = DbEngine()</p><p>Now we have a<a id="_idIndexMarker638"/> class that can give us database sessions, a database connection, and a base. However, it must be noted that we initiated the <strong class="source-inline">DbEngine</strong> class and assigned it to the <strong class="source-inline">dal</strong> variable; however, we didn't import the <strong class="source-inline">DbEngine</strong> class outside of this file. Instead, we import the <strong class="source-inline">dal</strong> variable to be used for interactions with the database. If we import the <strong class="source-inline">DbEngine</strong> class outside of this file during initiation and use it whenever we want to interact with the database, we will create multiple database sessions per request and these sessions will struggle to close. Even something as small as a couple of users will grind your database to a halt with too many hanging connections. Now that our database connection has been defined, in the next step, we can move on to build our database models.</p></li>&#13;
				<li>In our database model, we can have a unique ID, input number, and fib number. Our model is defined in the <strong class="source-inline">src/models/database/fib_entry.py</strong> file with the following code:<p class="source-code">from typing import Dict</p><p class="source-code">from sqlalchemy import Column, Integer</p><p class="source-code">from data_access import dal</p><p class="source-code">class FibEntry(dal.base):</p><p class="source-code">    __tablename__ = "fib_entries"</p><p class="source-code">    id = Column(Integer, primary_key=True)</p><p class="source-code">    input_number = Column(Integer)</p><p class="source-code">    calculated_number = Column(Integer)</p><p class="source-code">    @property</p><p class="source-code">    def package(self) -&gt; Dict[str, int]:</p><p class="source-code">        return {</p><p class="source-code">            "input_number": self.input_number,</p><p class="source-code">            "calculated_number": \</p><p class="source-code">              self.calculated_number</p><p class="source-code">        }</p></li>&#13;
			</ol>&#13;
			<p>Here, you can see <a id="_idIndexMarker639"/>that the code is straightforward. We pass <strong class="source-inline">dal.base</strong> through our model to add the model to the metadata. Then, we define the table name that will be in the database and model fields, which are <strong class="source-inline">id</strong>, <strong class="source-inline">input_number</strong>, and <strong class="source-inline">calculated_number</strong>. Our database model has now been defined, so we can import and use it throughout our application. Additionally, we will use this in the next step to manage the database migrations. </p>&#13;
			<h2 id="_idParaDest-171"><a id="_idTextAnchor170"/>Setting up the application database migration system</h2>&#13;
			<p>Migrations are a <a id="_idIndexMarker640"/>useful tool for keeping track of all the changes made to our database. If we make a change in a database model or define one, we need to translate those changes to our database. We can achieve this by performing the following steps:</p>&#13;
			<ol>&#13;
				<li value="1">For our database management, we are going to lean on the <strong class="source-inline">alembic</strong> package. Once we have navigated inside the <strong class="source-inline">src/</strong> directory, we run the following command:<p class="source-code"><strong class="bold">alembic init alembic</strong></p><p>This will generate a range of scripts and files. We are interested in the <strong class="source-inline">src/alembic/env.py</strong> file; we are going to alter this so that we can connect our <strong class="source-inline">alembic</strong> scripts and commands to our database. </p></li>&#13;
				<li>Next, we must import the <strong class="source-inline">os</strong> and <strong class="source-inline">sys</strong> modules, as we will be using them to import our models and load our configuration file. We import the modules using the following code:<p class="source-code">import sys</p><p class="source-code">import os</p></li>&#13;
				<li>Following<a id="_idIndexMarker641"/> this, we use the <strong class="source-inline">os</strong> module to append the path that is in the <strong class="source-inline">src/</strong> directory with the following code:<p class="source-code">from alembic import context</p><p class="source-code"># this is the Alembic Config object, which provides</p><p class="source-code"># access to the values within the .ini file in use.</p><p class="source-code">Config = context.config</p><p class="source-code"># Interpret the config file for Python logging.</p><p class="source-code"># This line sets up loggers basically.</p><p class="source-code">fileConfig(config.config_file_name)</p><p class="source-code"># add the src to our import path</p><p class="source-code">sys.path.append(os.path.join(</p><p class="source-code">    os.path.dirname(os.path.abspath(__file__)), </p><p class="source-code">    "../")</p><p class="source-code">)</p></li>&#13;
				<li>Now that we<a id="_idIndexMarker642"/> have configured our import path, we can import our parameters and database engine. Then, we add our database URL to our <strong class="source-inline">alembic</strong> database URL using the following code:<p class="source-code"># config the database url for migrations</p><p class="source-code">from config import GlobalParams</p><p class="source-code">params = GlobalParams()</p><p class="source-code">section = config.config_ini_section</p><p class="source-code">db_params = params.database_meta</p><p class="source-code">config.set_section_option(section, 'sqlalchemy.url', </p><p class="source-code">                          params.get('DB_URL'))</p><p class="source-code">from data_access import dal</p><p class="source-code">db_engine = dal</p><p class="source-code">from models.database.fib_entry import FibEntry</p><p class="source-code">target_metadata = db_engine.base.metadata</p></li>&#13;
				<li>With this, you can observe that the autogenerated function gets our config, which then executes the migrations with the following code:<p class="source-code">def run_migrations_offline():</p><p class="source-code">    url = config.get_main_option("sqlalchemy.url")</p><p class="source-code">    context.configure(</p><p class="source-code">        url=url,</p><p class="source-code">        target_metadata=target_metadata,</p><p class="source-code">        literal_binds=True,</p><p class="source-code">        dialect_opts={"paramstyle": "named"},</p><p class="source-code">        render_as_batch=True</p><p class="source-code">    )</p><p class="source-code">    with context.begin_transaction():</p><p class="source-code">        context.run_migrations()</p></li>&#13;
				<li>Now that we<a id="_idIndexMarker643"/> have our configuration system linked up to our database migrations, we have to make sure <strong class="source-inline">docker-compose</strong> is running because our database has to be live. We can generate a migration using the following command:<p class="source-code"><strong class="bold">alembic revision --autogenerate -m create-fib-entry </strong></p><p>This gives us the following printout:</p><p class="source-code"><strong class="bold">INFO  [alembic.runtime.migration] Context impl </strong></p><p class="source-code"><strong class="bold">PostgresqlImpl.</strong></p><p class="source-code"><strong class="bold">INFO  [alembic.runtime.migration] Will assume </strong></p><p class="source-code"><strong class="bold">transactional DDL.</strong></p><p class="source-code"><strong class="bold">INFO  [alembic.autogenerate.compare] Detected added </strong></p><p class="source-code"><strong class="bold">table</strong> <strong class="bold">'fib_entries'</strong></p><p>You can observe that in our <strong class="source-inline">src/alembic/versions/</strong> file, there is an autogenerated script that creates our table with the following code:</p><p class="source-code"># revision identifiers, used by Alembic.</p><p class="source-code">Revision = '40b83d85c278'</p><p class="source-code">down_revision = None</p><p class="source-code">branch_labels = None</p><p class="source-code">depends_on = None</p><p class="source-code">def upgrade():</p><p class="source-code">    op.create_table('fib_entries',</p><p class="source-code">    sa.Column('id', sa.Integer(), nullable=False),</p><p class="source-code">    sa.Column('input_number', sa.Integer(),\ </p><p class="source-code">      nullable=True),</p><p class="source-code">    sa.Column('calculated_number', sa.Integer(), \ </p><p class="source-code">     nullable=True),</p><p class="source-code">    sa.PrimaryKeyConstraint('id')</p><p class="source-code">    )</p><p class="source-code">def downgrade():</p><p class="source-code">    op.drop_table('fib_entries')</p><p>Here, if we<a id="_idIndexMarker644"/> upgrade, the <strong class="source-inline">upgrade</strong> function will run, and if we downgrade, the <strong class="source-inline">downgrade</strong> function will run. We can upgrade our database using the following command:</p><p class="source-code"><strong class="bold">alembic upgrade head</strong></p><p>This gives us the following printout:</p><p class="source-code"><strong class="bold">INFO  [alembic.runtime.migration] Context impl </strong></p><p class="source-code"><strong class="bold">PostgresqlImpl.</strong></p><p class="source-code"><strong class="bold">INFO  [alembic.runtime.migration] Will assume </strong></p><p class="source-code"><strong class="bold">transactional DDL.</strong></p><p class="source-code"><strong class="bold">INFO  [alembic.runtime.migration] Running upgrade  -&gt; </strong></p><p class="source-code"><strong class="bold">40b83d85c278, create-fib-entry</strong></p></li>&#13;
			</ol>&#13;
			<p>Our <a id="_idIndexMarker645"/>migration has worked. In the next step, we will interact with the database in our application. </p>&#13;
			<h2 id="_idParaDest-172"><a id="_idTextAnchor171"/>Building database models</h2>&#13;
			<p>Now that we have a <a id="_idIndexMarker646"/>database that has our application models applied to it, we can interact with our database in the application. This can be done by importing our data access layer and data model into the view that is using them and, well, use them: </p>&#13;
			<ol>&#13;
				<li value="1">For our example, we will be implementing our view inside the <strong class="source-inline">src/app/app.py</strong> file. First, we import the data access layer and model using the following code:<p class="source-code">from data_access import dal</p><p class="source-code">from models.database.fib_entry import FibEntry</p><p>With these imports, we can alter our calculation view to check whether the number exists in the database and return the number from the database if it does. </p></li>&#13;
				<li>If it is not available in the database, then we calculate it, save the result in the database, and return the result using the following code:<p class="source-code">@app.route("/calculate/&lt;int:number&gt;")</p><p class="source-code">def calculate(number):</p><p class="source-code">    fib_calc = dal.session.query(FibEntry).filter_by(</p><p class="source-code">           input_number=number).one_or_none()</p><p class="source-code">    if fib_calc is None:</p><p class="source-code">        calc = FibCalculation(input_number=number)</p><p class="source-code">        new_calc = FibEntry(input_number=number,</p><p class="source-code">                  calculated_number=calc.fib_number)</p><p class="source-code">        dal.session.add(new_calc)</p><p class="source-code">        dal.session.commit()</p><p class="source-code">        return f"you entered {calc.input_number} " \</p><p class="source-code">               f"which has a Fibonacci number of " \</p><p class="source-code">               f"{calc.fib_number}"</p><p class="source-code">    return f"you entered {fib_calc.input_number} " </p><p class="source-code">       f"which has an existing Fibonacci number of " </p><p class="source-code">           f"{fib_calc.calculated_number}"</p><p>Here, you can<a id="_idIndexMarker647"/> observe that our interactions with the database are straightforward. </p></li>&#13;
				<li>Now we have to make sure that when our request has finished, our database sessions are expired, closed, and removed using the following code:<p class="source-code">@app.teardown_request</p><p class="source-code">def teardown_request(*args, **kwargs):</p><p class="source-code">    dal.session.expire_all()</p><p class="source-code">    dal.session.remove()</p><p class="source-code">    dal.session.close()</p></li>&#13;
			</ol>&#13;
			<p>So, we have a safe and fully functioning interaction with our database. You are now aware of the fundamentals of interacting with a database using our application. You can achieve other, more complex database queries by reading the SQLAlchemy documentation about the specifics of the database, other database queries, and insertions as a way to map syntax. If we run our application locally and hit our calculation view twice, we will get the first and second results, as shown in the following screenshot:</p>&#13;
			<div>&#13;
				<div id="_idContainer103" class="IMG---Figure">&#13;
					<img src="Images/Figure_9.05_B17720.jpg" alt="Figure 9.5 – The top part is the first request (calculated), and the &#13;&#10;bottom part is the second request (database call)&#13;&#10;" width="924" height="474"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="figure-caption">Figure 9.5 – The top part is the first request (calculated), and the bottom part is the second request (database call)</p>&#13;
			<p>Our database is working<a id="_idIndexMarker648"/> the way we expect it to. Now the application is fully functioning, and you can move on to the next section if you wish, as this is enough to test Rust code in a Flask application, which we will do in the next chapter. However, if you want to understand how we apply the database in our deployment section, we will cover this next.</p>&#13;
			<h2 id="_idParaDest-173"><a id="_idTextAnchor172"/>Applying the database access layer to the fib calculation view</h2>&#13;
			<p>Adding a database to our <a id="_idIndexMarker649"/>deployment is a matter <a id="_idIndexMarker650"/>of adding it to our <strong class="source-inline">docker-compose</strong> deployment and updating our configuration file to map to the database service in the <strong class="source-inline">docker-compose</strong> deployment. We can achieve this by performing the following steps: </p>&#13;
			<ol>&#13;
				<li value="1">First, we have to refactor our <strong class="source-inline">deployment/docker-compose.yml</strong> file using the following code:<p class="source-code">services:</p><p class="source-code">    flask_app:</p><p class="source-code">        container_name: fib-calculator</p><p class="source-code">        image: "flask-fib:latest"</p><p class="source-code">        restart: always</p><p class="source-code">        ports:</p><p class="source-code">          - "5002:5002"</p><p class="source-code">        expose:</p><p class="source-code">            - 5002</p><p class="source-code">        depends_on:</p><p class="source-code">          - postgres</p><p class="source-code">        links:</p><p class="source-code">          - postgres</p><p class="source-code">    nginx:</p><p class="source-code">        . . .</p><p class="source-code">    postgres:</p><p class="source-code">        container_name: 'fib-live-postgres'</p><p class="source-code">        image: 'postgres:11.2'</p><p class="source-code">        restart: always</p><p class="source-code">        ports:</p><p class="source-code">            - '5432:5432'</p><p class="source-code">        environment:</p><p class="source-code">            - 'POSTGRES_USER=user'</p><p class="source-code">            - 'POSTGRES_DB=fib'</p><p class="source-code">            - 'POSTGRES_PASSWORD=password'</p><p>You can observe that we have a slightly different name for our database container. This is to ensure that there are no clashes with our development database. Additionally, we have declared that our Flask application is dependent on and linked to our database. </p></li>&#13;
				<li>We also<a id="_idIndexMarker651"/> have to point our<a id="_idIndexMarker652"/> Flask application to the Docker database. To do this, we have to have a different configuration file for our Flask application. We can manage the configuration file switch in <strong class="source-inline">src/Dockerfile</strong> for the Flask application. This can be done using the following code:<p class="source-code"># Copy the current directory contents into the </p><p class="source-code">  container at /app</p><p class="source-code">ADD . /app</p><p class="source-code">RUN rm ./config.yml</p><p class="source-code">RUN mv live_config.yml config.yml</p><p class="source-code">. . .</p><p>Here, we remove the <strong class="source-inline">config.yml</strong> file and then change the filename of the <strong class="source-inline">live_config.yml</strong> file to <strong class="source-inline">config.yml</strong>.</p></li>&#13;
				<li>Then, we have to make our <strong class="source-inline">src/live_config.yml</strong> file with the following content:<p class="source-code">DB_URL: "postgresql://user:password@postgres:5432/fib"</p><p>Here, we have changed <strong class="source-inline">@localhost</strong> to <strong class="source-inline">@postgres</strong> because the classification of our service is called <strong class="source-inline">postgres</strong>. </p></li>&#13;
				<li>Following this, we can rebuild our Flask image using the following command:<p class="source-code"><strong class="bold">docker build . -t flask-fib</strong></p></li>&#13;
				<li>Now we can run our <strong class="source-inline">docker-compose</strong> deployment, but we will have to run our migrations while our <strong class="source-inline">docker-compose</strong> deployment is running. This is because our Flask application will not cause an error if it is out of sync with the database until we try and make a query to the database, so running <strong class="source-inline">docker-compose</strong> before migrating is fine if we make no requests. When we make the migration, we must do this while the database in <strong class="source-inline">docker-compose</strong> is running; otherwise, the migration will not be able to connect to the database. We can <a id="_idIndexMarker653"/>run the migration<a id="_idIndexMarker654"/> while <strong class="source-inline">docker-compose</strong> is running using the following command:<p class="source-code"><strong class="bold">docker exec -it fib-calculator alembic upgrade head</strong></p></li>&#13;
			</ol>&#13;
			<p>This runs the migrations on our Flask container. It is not advised that you only have your live configuration files within your application code. A favorite method of mine is to upload an encrypted configuration file in AWS S3 and pull it in Kubernetes as it starts up a pod. This is beyond the scope of this book, as this is not a web development book. However, it is important to keep methods such as this in mind for further reading if needed. </p>&#13;
			<p>Right now, there is not much to complain about when it comes to calculating Fibonacci numbers with our Flask application. However, when we try and calculate a large number, we will be waiting for a long time, and this will keep the request hanging. To prevent this from occurring, in the next section, we are going to implement a message bus. This is so that while our application is processing large numbers in the background, we can return a message telling the users to be patient.</p>&#13;
			<h1 id="_idParaDest-174"><a id="_idTextAnchor173"/>Building a message bus </h1>&#13;
			<p>For this section, we will be<a id="_idIndexMarker655"/> using the <strong class="source-inline">Celery</strong> and <strong class="source-inline">Redis</strong> packages to build and run our message bus. Once we have completed this section, our mechanism will take a form that is similar to the following:</p>&#13;
			<div>&#13;
				<div id="_idContainer104" class="IMG---Figure">&#13;
					<img src="Images/Figure_9.06_B17720.jpg" alt="Figure 9.6 – A message bus with Flask and Celery&#13;&#10;" width="1354" height="468"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="figure-caption">Figure 9.6 – A message bus with Flask and <strong class="source-inline">Celery</strong></p>&#13;
			<p>As shown in the preceding diagram, we have two processes running. One is running our Flask application, while the other is running <strong class="source-inline">Celery</strong>, which handles queuing and processing tasks. To <a id="_idIndexMarker656"/>make this work, we are going to perform the following steps:</p>&#13;
			<ol>&#13;
				<li value="1">Build a <strong class="source-inline">Celery</strong> broker for Flask.</li>&#13;
				<li>Build a Fibonacci calculation task for <strong class="bold">Celery</strong>.</li>&#13;
				<li>Update our calculation view with <strong class="source-inline">Celery</strong>.</li>&#13;
				<li>Define our <strong class="source-inline">Celery</strong> service in Docker.</li>&#13;
			</ol>&#13;
			<p>Before we embark on these steps, we have to install the following packages using <strong class="source-inline">pip</strong>:</p>&#13;
			<ul>&#13;
				<li><strong class="source-inline">Celery</strong>: This is the message bus broker that we are going to use.</li>&#13;
				<li><strong class="source-inline">Redis</strong>: This is the storage system that <strong class="source-inline">Celery</strong> is going to use.</li>&#13;
			</ul>&#13;
			<p>Now that we have installed the requirements, we have to remember to update the <strong class="source-inline">src/requirements.txt</strong> file with <strong class="source-inline">Celery</strong> and Redis for our Docker builds. Now that we have all of our dependencies installed, we can start building our <strong class="source-inline">Celery</strong> broker, as demonstrated next.</p>&#13;
			<h2 id="_idParaDest-175"><a id="_idTextAnchor174"/>Building a Celery broker for Flask </h2>&#13;
			<p>Essentially, our <strong class="source-inline">Celery</strong><a id="_idIndexMarker657"/> broker is a storage system that will store data<a id="_idIndexMarker658"/> concerning the tasks we have sent to it. We can set up our storage system and connect it to our <strong class="source-inline">Celery</strong> system using the following steps:</p>&#13;
			<ol>&#13;
				<li value="1">We are going to build our own module when building our task queue. Inside the <strong class="source-inline">src/</strong> directory, our task queue module will take the following structure:<p class="source-code">└── task_queue</p><p class="source-code">    ├── __init__.py</p><p class="source-code">    ├── engine.py</p><p class="source-code">    └── fib_calc_task.py</p><p>Our <strong class="source-inline">engine.py</strong> file will host a constructor for <strong class="source-inline">Celery</strong> that considers the context of the Flask application. </p></li>&#13;
				<li>We will build our Fibonacci calculation <strong class="source-inline">Celery</strong> task in the <strong class="source-inline">fib_calc_task.py</strong> file. In our <strong class="source-inline">engine.py</strong> file, we can build our constructor using the following code:<p class="source-code">from celery import Celery</p><p class="source-code">from config import GlobalParams</p><p class="source-code">def make_celery(flask_app):</p><p class="source-code">    params = GlobalParams()</p><p class="source-code">    celery = Celery(</p><p class="source-code">        backend=params.get("QUEUE_BACKEND"),</p><p class="source-code">        broker=params.get("QUEUE_BROKER")</p><p class="source-code">    )</p><p class="source-code">    celery.conf.update(flask_app.config)</p><p class="source-code">    class ContextTask(celery.Task):</p><p class="source-code">        def __call__(self, *args, **kwargs):</p><p class="source-code">            with flask_app.app_context():</p><p class="source-code">                return self.run(*args, **kwargs)</p><p class="source-code">    celery.Task = ContextTask</p><p class="source-code">    return celery</p><p>The <strong class="source-inline">backend</strong> and <strong class="source-inline">broker</strong> parameters will point to the storage; we will define them later. Here, you can observe that we must pass the Flask application into the function, construct the <strong class="source-inline">Celery</strong> class, and fuse a <strong class="source-inline">Celery</strong> task object with the Flask application context and then return it. When it comes to defining an entry point for running <a id="_idIndexMarker659"/>our <strong class="source-inline">Celery</strong> process, we should place it in<a id="_idIndexMarker660"/> the same file as our Flask application. This is because we want to use the same Docker build and, thus, image for the Flask application and <strong class="source-inline">Celery</strong> process.</p></li>&#13;
				<li>To achieve this, we import our <strong class="source-inline">Celery</strong> constructor and pass the Flask application through it, in the <strong class="source-inline">src/app.py</strong> file, using the following code:<p class="source-code">. . .</p><p class="source-code">from task_queue.engine import make_celery</p><p class="source-code">app = Flask(__name__)</p><p class="source-code">celery = make_celery(app)</p><p class="source-code">. . .</p></li>&#13;
				<li>Now, when we run our <strong class="source-inline">Celery</strong> broker, we will point it at our <strong class="source-inline">src/app.py</strong> file and the <strong class="source-inline">Celery</strong> object inside it. Additionally, we must define our backend storage system. Because we are using Redis, we can define these parameters in our <strong class="source-inline">src/config.yml</strong> file using the following code:<p class="source-code">QUEUE_BACKEND: "redis://localhost:6379/0"</p><p class="source-code">QUEUE_BROKER: "redis://localhost:6379/0"</p></li>&#13;
			</ol>&#13;
			<p>Now that we have defined our <strong class="source-inline">Celery</strong> broker, in the next step, we can build our Fibonacci calculation task.</p>&#13;
			<h2 id="_idParaDest-176"><a id="_idTextAnchor175"/>Building a Fibonacci calculation task for Celery </h2>&#13;
			<p>When it comes to running our<a id="_idIndexMarker661"/> <strong class="source-inline">Celery</strong> task, we <a id="_idIndexMarker662"/>need to build another constructor. However, instead of passing in our Flask application, we pass in our <strong class="source-inline">Celery</strong> broker. We can achieve this in the <strong class="source-inline">src/task_queue/fib_calc_task.py</strong> file using the following code:</p>&#13;
			<p class="source-code">from data_access import dal</p>&#13;
			<p class="source-code">from fib_calcs.fib_calculation import FibCalculation</p>&#13;
			<p class="source-code">from models.database.fib_entry import FibEntry</p>&#13;
			<p class="source-code">def create_calculate_fib(input_celery):</p>&#13;
			<p class="source-code">    @input_celery.task()</p>&#13;
			<p class="source-code">    def calculate_fib(number):</p>&#13;
			<p class="source-code">        calculation = FibCalculation(input_number=number)</p>&#13;
			<p class="source-code">        fib_entry = FibEntry(</p>&#13;
			<p class="source-code">            input_number=calculation.input_number,</p>&#13;
			<p class="source-code">            calculated_number=calculation.fib_number</p>&#13;
			<p class="source-code">        )</p>&#13;
			<p class="source-code">        dal.session.add(fib_entry)</p>&#13;
			<p class="source-code">        dal.session.commit()</p>&#13;
			<p class="source-code">    return calculate_fib</p>&#13;
			<p>The preceding<a id="_idIndexMarker663"/> logic is like our standard calculation<a id="_idIndexMarker664"/> view. We can import it into our <strong class="source-inline">src/app.py</strong> file and pass our <strong class="source-inline">Celery</strong> broker to it using the following code:</p>&#13;
			<p class="source-code">. . .</p>&#13;
			<p class="source-code">from task_queue.engine import make_celery</p>&#13;
			<p class="source-code">app = Flask(__name__)</p>&#13;
			<p class="source-code">celery = make_celery(app)</p>&#13;
			<p class="source-code">from task_queue.fib_calc_task import create_calculate_fib</p>&#13;
			<p class="source-code">calculate_fib = create_calculate_fib(input_celery=celery)</p>&#13;
			<p class="source-code">. . .</p>&#13;
			<p>Now that we have our task defined and fused with our <strong class="source-inline">Celery</strong> broker and Flask application, in the next step, we can add our <strong class="source-inline">Celery</strong> task to the calculation view if the number is too large. </p>&#13;
			<h2 id="_idParaDest-177"><a id="_idTextAnchor176"/>Updating our calculation view</h2>&#13;
			<p>With our view, we<a id="_idIndexMarker665"/> must check to see whether our input number is less than <strong class="source-inline">31</strong> and not in the database. If it is, we run our standard existing code. However, if the input number is <strong class="source-inline">30</strong> or above, we will send the calculation to the <strong class="source-inline">Celery</strong> broker and return a message telling the user that it has been sent to the queue. We can do this using the following code:</p>&#13;
			<p class="source-code">@app.route("/calculate/&lt;int:number&gt;")</p>&#13;
			<p class="source-code">def calculate(number):</p>&#13;
			<p class="source-code">    fib_calc = dal.session.query(FibEntry).filter_by(</p>&#13;
			<p class="source-code">                       input_number=number).one_or_none()</p>&#13;
			<p class="source-code">    if fib_calc is None:</p>&#13;
			<p class="source-code">        if number &lt; 31:</p>&#13;
			<p class="source-code">            calc = FibCalculation(input_number=number)</p>&#13;
			<p class="source-code">            new_calc = FibEntry(input_number=number,</p>&#13;
			<p class="source-code">                                calculated_number=calc.</p>&#13;
			<p class="source-code">                                fib_number)</p>&#13;
			<p class="source-code">            dal.session.add(new_calc)</p>&#13;
			<p class="source-code">            dal.session.commit()</p>&#13;
			<p class="source-code">            return f"you entered {calc.input_number} " \</p>&#13;
			<p class="source-code">                   f"which has a Fibonacci number of " \</p>&#13;
			<p class="source-code">                   f"{calc.fib_number}"</p>&#13;
			<p class="source-code">        calculate_fib.delay(number)</p>&#13;
			<p class="source-code">        return "calculate fib sent to queue because " \</p>&#13;
			<p class="source-code">               "it's above 30"</p>&#13;
			<p class="source-code">    return f"you entered {fib_calc.input_number} " \</p>&#13;
			<p class="source-code">           f"which has an existing Fibonacci number of " \</p>&#13;
			<p class="source-code">           f"{fib_calc.calculated_number}"</p>&#13;
			<p>Now our <a id="_idIndexMarker666"/><strong class="source-inline">Celery</strong> process with our task has been fully built. In the next step, we will define our Redis service in <strong class="source-inline">docker-compose</strong>.</p>&#13;
			<h2 id="_idParaDest-178"><a id="_idTextAnchor177"/>Defining our Celery service in Docker</h2>&#13;
			<p>When it comes to our <a id="_idIndexMarker667"/><strong class="source-inline">Celery</strong> service, remember that we used <a id="_idIndexMarker668"/>Redis as a storage mechanism. Considering this, we define our Redis service in our developed <strong class="source-inline">docker-compose.yml</strong> file using the following code:</p>&#13;
			<p class="source-code">. . .</p>&#13;
			<p class="source-code">    redis:</p>&#13;
			<p class="source-code">      container_name: 'main-dev-redis'</p>&#13;
			<p class="source-code">      image: 'redis:5.0.3'</p>&#13;
			<p class="source-code">      ports:</p>&#13;
			<p class="source-code">        - '6379:6379'</p>&#13;
			<p>Now running our whole system in develop mode requires running our developed <strong class="source-inline">docker-compose</strong> file at the root of our project. Additionally, we run the Flask application by running our <strong class="source-inline">app.py</strong> file with Python, where <strong class="source-inline">PYTHONPATH</strong> is set to <strong class="source-inline">src</strong>. </p>&#13;
			<p>Following this, we open another Terminal window, navigate the Terminal inside the <strong class="source-inline">src</strong> directory, and run the following command:</p>&#13;
			<p class="source-code">celery -A app.celery worker -l info</p>&#13;
			<p>This is where we<a id="_idIndexMarker669"/> point <strong class="source-inline">Celery</strong> to the <strong class="source-inline">app.py</strong> file. We state that the<a id="_idIndexMarker670"/> object is called <strong class="source-inline">Celery</strong>, that it is a worker, and that the logging is at the <strong class="source-inline">info</strong> level. Running this gives us the following printout:</p>&#13;
			<p class="source-code">-------------- celery@maxwells-MacBook-Pro.</p>&#13;
			<p class="source-code">--- ***** ----- local v5.1.2 (sun-harmonics)</p>&#13;
			<p class="source-code">-- ******* ---- Darwin-20.2.0-x86_64-i386-64bit</p>&#13;
			<p class="source-code">- *** --- * --- 2021-08-22 23:24:14</p>&#13;
			<p class="source-code">- ** ---------- [config]</p>&#13;
			<p class="source-code">- ** ---------- .&gt; app:         __main__:0x7fd0796d0ed0</p>&#13;
			<p class="source-code">- ** ---------- .&gt; transport:   redis://localhost:6379/0</p>&#13;
			<p class="source-code">- ** ---------- .&gt; results:     redis://localhost:6379/0</p>&#13;
			<p class="source-code">- *** --- * --- .&gt; concurrency: 4 (prefork)</p>&#13;
			<p class="source-code">-- ******* ---- .&gt; task events: OFF (enable -E to</p>&#13;
			<p class="source-code">--- ***** -----    monitor tasks in this worker)</p>&#13;
			<p class="source-code"> -------------- [queues]</p>&#13;
			<p class="source-code">                .&gt; celery  exchange=celery(direct) </p>&#13;
			<p class="source-code">key=celery               </p>&#13;
			<p class="source-code">[tasks]</p>&#13;
			<p class="source-code">  . task_queue.fib_calc_task.calculate_fib</p>&#13;
			<p class="source-code">[2021-08-22 23:24:14,385: INFO/MainProcess] Connected </p>&#13;
			<p class="source-code">to redis://localhost:6379/0</p>&#13;
			<p class="source-code">[2021-08-22 23:24:14,410: INFO/MainProcess] mingle: </p>&#13;
			<p class="source-code">searching for neighbors</p>&#13;
			<p class="source-code">[2021-08-22 23:24:15,476: INFO/MainProcess] mingle: </p>&#13;
			<p class="source-code">all alone</p>&#13;
			<p class="source-code">[2021-08-22 23:24:15,514: INFO/MainProcess] </p>&#13;
			<p class="source-code">celery@maxwells-MacBook-Pro.local ready.</p>&#13;
			<p class="source-code">[2021-08-22 23:24:39,822: INFO/MainProcess] </p>&#13;
			<p class="source-code">Task task_queue.fib_calc_task.calculate_fib</p>&#13;
			<p class="source-code">[c3241a5f-3208-48f7-9b0a-822c30aef94e] received</p>&#13;
			<p>The preceding<a id="_idIndexMarker671"/> printout shows us that our task has been registered <a id="_idIndexMarker672"/>and that four processes have been spun up. Hitting the calculation view with our <strong class="source-inline">Celery</strong> processes using a number higher than <strong class="source-inline">30</strong> gives us the following view:</p>&#13;
			<div>&#13;
				<div id="_idContainer105" class="IMG---Figure">&#13;
					<img src="Images/Figure_9.07_B17720.jpg" alt="Figure 9.7 – The bottom shows the first request with Celery, and the top shows the&#13;&#10; second request with Celery&#13;&#10;" width="918" height="472"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="figure-caption">Figure 9.7 – The bottom shows the first request with <strong class="source-inline">Celery,</strong> and the top shows the  second request with <strong class="source-inline">Celery</strong></p>&#13;
			<p>Our Flask <a id="_idIndexMarker673"/>application with a database and <strong class="source-inline">Celery</strong> message<a id="_idIndexMarker674"/> bus is now fully working locally. You can stop here if you wish, as this is enough to test Rust code in <strong class="source-inline">Celery</strong> in the next chapter. However, if you want to learn how to apply <strong class="source-inline">Celery</strong> to the deployment section, continue with this section.</p>&#13;
			<p>Applying <strong class="source-inline">Celery</strong> to our <strong class="source-inline">docker-compose</strong> deployment is straightforward. Remember that we have the same entry point, so there is no need for a new image. Instead, all we have to do is change the command that we run when spinning up our <strong class="source-inline">Celery</strong> container. This can be done in our <strong class="source-inline">deployment/docker-compose.yml</strong> file using the following code:</p>&#13;
			<p class="source-code">. . .</p>&#13;
			<p class="source-code">    main_cache:</p>&#13;
			<p class="source-code">        container_name: 'main-live-redis'</p>&#13;
			<p class="source-code">        image: 'redis:5.0.3'</p>&#13;
			<p class="source-code">        ports:</p>&#13;
			<p class="source-code">            - '6379:6379'</p>&#13;
			<p class="source-code">    queue_worker:</p>&#13;
			<p class="source-code">        container_name: fib-worker</p>&#13;
			<p class="source-code">        image: "flask-fib:latest"</p>&#13;
			<p class="source-code">        restart: always</p>&#13;
			<p class="source-code">        entrypoint: "celery -A app.celery worker -l info"</p>&#13;
			<p class="source-code">        ports:</p>&#13;
			<p class="source-code">            - "5003:5003"</p>&#13;
			<p class="source-code">        expose:</p>&#13;
			<p class="source-code">            - 5003</p>&#13;
			<p class="source-code">        depends_on:</p>&#13;
			<p class="source-code">            - main_cache</p>&#13;
			<p class="source-code">        links:</p>&#13;
			<p class="source-code">            - main_cache</p>&#13;
			<p>Here, you can observe that we pull the same image for our <strong class="source-inline">queue_worker</strong> service. However, we change the <strong class="source-inline">CMD</strong> tag in our Docker build using the <strong class="source-inline">entrypoint</strong> tag in <strong class="source-inline">docker-compose</strong>. So, when our <strong class="source-inline">queue_worker</strong> service is built, it will run the <strong class="source-inline">Celery</strong> command <a id="_idIndexMarker675"/>running the <strong class="source-inline">Celery</strong> workers, as opposed to running<a id="_idIndexMarker676"/> the Flask web application. Following this, we need to add some more parameters to our <strong class="source-inline">live_config.yml</strong> file using the following code:</p>&#13;
			<p class="source-code">QUEUE_BACKEND: "redis://main_cache:6379/0"</p>&#13;
			<p class="source-code">QUEUE_BROKER: "redis://main_cache:6379/0"</p>&#13;
			<p>Here, we have named our Redis service as opposed to the localhost. This is so that our packaged <strong class="source-inline">Celery</strong> worker and Flask application will connect to our Redis service in the <strong class="source-inline">docker-compose</strong> deployment. After running the <strong class="source-inline">docker-compose</strong> deployment, we can repeat the requests demonstrated in <em class="italic">Figure 9.6</em> with <strong class="source-inline">localhost</strong> as opposed to <strong class="source-inline">127.0.0.1:5002</strong>. With this, our Flask application is ready to deploy with a database and task queue. Technically, our setup can be deployed and used on a server. I have done this, and it works just fine. However, for more advanced systems and control, it is advised that you carry out some further reading. Additional references about deploying Flask applications in Docker to cloud services such as Amazon Web Services are listed in the <em class="italic">Further reading</em> section.  </p>&#13;
			<h1 id="_idParaDest-179"><a id="_idTextAnchor178"/>Summary</h1>&#13;
			<p>In this chapter, we built a Python Flask application that had access to a database and message bus to allow the queuing of heavy tasks in the background. Following this, we wrapped our services in Docker containers and deployed them in a simple <strong class="source-inline">docker-compose</strong> file with NGINX. Additionally, we learned how to build our <strong class="source-inline">Celery</strong> worker and Flask application in the same Dockerfile using the same build. This made our code easier to maintain and deploy. We also managed our migrations for our database using <strong class="source-inline">alembic</strong> and a configuration file, which was then switched to another configuration file when we were deploying our application. While this is not a web development textbook, we have covered all of the essentials when it comes to structuring a Flask web application. </p>&#13;
			<p>Further details regarding database queries, data serialization, or HTML and CSS rendering are covered, in a straightforward manner, in the Flask documentation. We have covered all of the difficult stuff. Now, we can experiment with Rust and how it can be fused with a Python web application, not just in a development setting but a live setting where the application is running in a Docker container while communicating with other Docker containers. In the next chapter, we will fuse Rust with our Flask application. This is so that it can work with the development and deployment settings.</p>&#13;
			<h1 id="_idParaDest-180"><a id="_idTextAnchor179"/>Questions</h1>&#13;
			<ol>&#13;
				<li value="1">What do we change in the URI when we switch from development to deployment on <strong class="source-inline">docker-compose</strong> to communicate with another service?</li>&#13;
				<li>Why do we use configuration files?</li>&#13;
				<li>Do we really need <strong class="source-inline">alembic</strong> to manage the database?</li>&#13;
				<li>What do we have to do to our database engine to ensure our database does not get flooded with hanging sessions?</li>&#13;
				<li>Do we need Redis for our <strong class="source-inline">Celery</strong> worker process?</li>&#13;
			</ol>&#13;
			<h1 id="_idParaDest-181"><a id="_idTextAnchor180"/>Answers</h1>&#13;
			<ol>&#13;
				<li value="1">We switch the <strong class="source-inline">localhost</strong> part of the URI to the tag of the <strong class="source-inline">docker-compose</strong> service. </li>&#13;
				<li>Configuration files enable us to switch contexts easily; for instance, switching from development to live. Additionally, if our <strong class="source-inline">Celery</strong> service needs to talk to a different database for some reason, this can be done with minimal effort; simply changing the configuration file will work. It is also a security issue. Hardcoding database URIs will expose these credentials to anyone who has access to the code and will be in the GitHub repository history. Store the configuration file in a different space such as AWS S3, which gets pulled when the service is deployed.</li>&#13;
				<li>Technically, no. We can simply write SQL scripts and run them in sequence. When I was working in financial technology, this was actually a thing that we had to do. While this can give you more freedom, it does take more time and is more error-prone. Using <strong class="source-inline">alembic</strong> will save you time, errors, and work for pretty much most of your needs. </li>&#13;
				<li>We initiate our database engine once in the same file where our engine is defined. We never initiate it again, and we import this initiated engine anywhere we need. Not doing so will lead to our database to a grinding halt with dangling sessions and not very helpful error messages that will have you running around in circles on the internet with vague half-baked answers. Additionally, we have to close our sessions in the Flask teardown function for all requests.  </li>&#13;
				<li>Yes and no. We require a storage mechanism such as Redis; however, we can also use RabbitMQ or MongoDB instead of Redis if needed. </li>&#13;
			</ol>&#13;
			<h1 id="_idParaDest-182"><a id="_idTextAnchor181"/>Further reading</h1>&#13;
			<ul>&#13;
				<li><em class="italic">Nginx HTTP Server – Fourth Edition: Harness the power of Nginx</em> by Fjordvald M. and Nedelcu C. (2018) (Packt)</li>&#13;
				<li>The official Flask documentation – Pallets (2021): <a href="https://flask.palletsprojects.com/en/2.0.x/%0D">https://flask.palletsprojects.com/en/2.0.x/</a></li>&#13;
				<li><em class="italic">Hands-On Docker for Microservices with Python</em> by Jaime Buelta (2019) (Packt)</li>&#13;
				<li><em class="italic">AWS Certified Developer – Associate Guide – Second Edition</em> by Vipul Tankariya and Bhavin Parmar (2019) (Packt) </li>&#13;
				<li>The SQLAlchemy query reference documentation (2021): <a href="https://docs.sqlalchemy.org/en/14/orm/loading_objects.html%0D">https://docs.sqlalchemy.org/en/14/orm/loading_objects.html</a></li>&#13;
			</ul>&#13;
		</div>&#13;
	</div></body></html>