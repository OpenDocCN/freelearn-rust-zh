<html><head></head><body><div><p>&#13;
			<h1 id="_idParaDest-159"><em class="italic"><a id="_idTextAnchor158"/>Chapter 9</em>: Structuring a Python Flask App for Rust</h1>&#13;
			<p>In the previous chapter, we managed to solve a real-world problem with Rust. However, we also learned an important lesson, that is, the good implementation of code, such as adding vectors or merging dataframes, along with third-party modules, such as <code>NumPy</code>, can outperform badly implemented self-coded Rust solutions. However, we know that comparing implementation to implementation, Rust is a lot faster than Python. We already understand how to fuse Rust with a standard Python script. However, Python is used for more than just running scripts. A popular use for Python is in web applications.</p>&#13;
			<p>In this chapter, we will build a Flask web application with NGINX, a database, and a message bus implemented by the <code>Celery</code> package. This message bus will allow our application to process heavy tasks in the background while we return a web HTTP request. The web application and message bus will be wrapped in Docker containers and deployed to <code>docker-compose</code>. However, nothing is preventing us from deploying the application onto a cloud platform if desired. </p>&#13;
			<p>In this chapter, we will cover the following topics:</p>&#13;
			<ul>&#13;
				<li>Building a basic Flask application</li>&#13;
				<li>Defining a database access layer</li>&#13;
				<li>Building a message bus</li>&#13;
			</ul>&#13;
			<p>This chapter will enable us to build a foundation for deployable Python web applications that have a range of features and services. This foundation allows us to discover how to fuse Rust with Python web applications that are wrapped in Docker containers. </p>&#13;
			<h1 id="_idParaDest-160"><a id="_idTextAnchor159"/>Technical requirements</h1>&#13;
			<p>The code and data for this chapter can be found at <a href="https://github.com/PacktPublishing/Speed-up-your-Python-with-Rust/tree/main/chapter_nine">https://github.com/PacktPublishing/Speed-up-your-Python-with-Rust/tree/main/chapter_nine</a>.</p>&#13;
			<p>In addition to this, we will be using <code>docker-compose</code> on top of Docker to orchestrate our Docker containers. This can be installed by following the instructions at <a href="https://docs.docker.com/compose/install/">https://docs.docker.com/compose/install/</a>.</p>&#13;
			<p>In this chapter, we will be building a Docker-contained Flask application, which is available via the GitHub repository at <a href="https://github.com/maxwellflitton/fib-flask">https://github.com/maxwellflitton/fib-flask</a>.</p>&#13;
			<h1 id="_idParaDest-161"><a id="_idTextAnchor160"/>Building a basic Flask application</h1>&#13;
			<p>Before we begin <a id="_idIndexMarker604"/>adding any additional features such as a database to an application, we have to ensure that that we can get a basic Flask application up and running with everything that we need. This application will take in a number and return a Fibonacci number. Additionally, we will need to make sure that this application can run in its own Docker container if we were to deploy it. By the end of this section, our application should have the following structure:</p>&#13;
			<pre>├── deployment</pre>&#13;
			<pre>│   ├── docker-compose.yml</pre>&#13;
			<pre>│   └── nginx</pre>&#13;
			<pre>│       ├── Dockerfile</pre>&#13;
			<pre>│       └── nginx.conf</pre>&#13;
			<pre>├── src</pre>&#13;
			<pre>│   ├── Dockerfile</pre>&#13;
			<pre>│   ├── __init__.py</pre>&#13;
			<pre>│   ├── app.py</pre>&#13;
			<pre>│   ├── fib_calcs</pre>&#13;
			<pre>│   │   ├── __init__.py</pre>&#13;
			<pre>│   │   └── fib_calculation.py</pre>&#13;
			<pre>│   └── requirements.txt</pre>&#13;
			<p>Here, you can see that the application is housed in the <code>src</code> directory. When running our application, we must ensure that the <code>PYTHONPATH</code> path is set to <code>src</code>. The code required for our deployment exists in the <code>deployment</code> directory. To build an application so that it can <a id="_idIndexMarker605"/>run in Docker, perform the following steps:</p>&#13;
			<ol>&#13;
				<li>Build an entry point for our application. </li>&#13;
				<li>Build a Fibonacci number calculation module.</li>&#13;
				<li>Build a Docker image for our application.</li>&#13;
				<li>Build our NGINX service.</li>&#13;
			</ol>&#13;
			<p>Once we have completed all of these steps, we will have a basic Flask application that can be run on a server. Now, let's explore each of these steps in detail in the following subsections.</p>&#13;
			<h2 id="_idParaDest-162"><a id="_idTextAnchor161"/>Building an entry point for our application</h2>&#13;
			<p>Here are the steps <a id="_idIndexMarker606"/>to perform:</p>&#13;
			<ol>&#13;
				<li value="1">Before we can build our entry point, we need to install the Flask module using the following command:<pre><strong class="bold">pip install flask</strong></pre></li>&#13;
				<li>Once this is done, we have all we need to create a basic Flask application by defining the entry point in the <code>src/app.py</code> file using the following code:<pre>from flask import Flask
app = Flask(__name__)
@app.route("/")
def home():
    return "home for the fib calculator"
if __name__ == "__main__":
    app.run(use_reloader=True, port=5002, \
      threaded=True)</pre></li>&#13;
			</ol>&#13;
			<p>Here, observe <a id="_idIndexMarker607"/>that we can define a basic route with the decorator. We can run our application by running the <code>src/app.py</code> script; this will run our server locally, enabling us to access all of the routes that we have defined. Passing the <code>http://127.0.0.1:5002</code> URL into our browser will give us the following view:</p>&#13;
			<p>&#13;
				<div>&#13;
					<img src="img/Figure_9.01_B17720.jpg" alt="Figure 9.1 – The main view of our local Flask server&#13;&#10;" width="568" height="139"/>&#13;
				</p>&#13;
			</p>&#13;
			<p class="figure-caption">Figure 9.1 – The main view of our local Flask server</p>&#13;
			<p>Now that our basic server is running, we can move on to build a Fibonacci number calculator module.</p>&#13;
			<h2 id="_idParaDest-163"><a id="_idTextAnchor162"/>Building our Fibonacci number calculator module</h2>&#13;
			<p>Here are the<a id="_idIndexMarker608"/> steps to <a id="_idIndexMarker609"/>perform:</p>&#13;
			<ol>&#13;
				<li value="1">In this example, our application is simple. As a result, we can define our module's functionality within one file in one class. We define it within the <code>src/fib_calcs/fib_calculation.py</code> file using the following code:<pre>class FibCalculation:
    def __init__(self, input_number: int) -&gt; None:
        self.input_number: int = input_number
        self.fib_number: int = self.recur_fib(
            n=self.input_number
        )
    @staticmethod
    def recur_fib(n: int) -&gt; int:
        if n &lt;= 1:
            return n
        else:
            return (FibCalculation.recur_fib(n - 1) +
                    FibCalculation.recur_fib(n - 2))</pre><p>Here, notice that our class merely takes in an input number and automatically populates the <code>self.fib_number</code> attribute with the calculated Fibonacci number. </p></li>&#13;
				<li>Once that <a id="_idIndexMarker610"/>is done, we <a id="_idIndexMarker611"/>can define a view that accepts an integer through the URL, passes it to our <code>FibCalculation</code> class, and returns the calculated Fibonacci number as a string to the user in our <code>src/app.py</code> file using the following code:<pre>from fib_calcs.fib_calculation import FibCalculation
. . .
@app.route("/calculate/&lt;int:number&gt;")
def calculate(number):
    calc = FibCalculation(input_number=number)
    return f"you entered {calc.input_number} " \
           f"which has a Fibonacci number of " \
           f"{calc.fib_number}"</pre></li>&#13;
				<li>Rerunning<a id="_idIndexMarker612"/> our server and <a id="_idIndexMarker613"/>passing the <code>http://127.0.0.1:5002/calculate/10</code> URL into our browser will give us the following view:</li>&#13;
			</ol>&#13;
			<p>&#13;
				<p>&#13;
					<img src="img/Figure_9.02_B17720.jpg" alt="Figure 9.2 – Calculating the view of our local Flask server&#13;&#10;" width="730" height="135"/>&#13;
				</p>&#13;
			</p>&#13;
			<p class="figure-caption">Figure 9.2 – Calculating the view of our local Flask server</p>&#13;
			<p>Now our application performs its intended purpose: it calculates a Fibonacci number based on the input. There is more to views with Flask; however, this book is not a web development textbook. If you want to learn how to build more comprehensive API endpoints, we advise that you look into the Flask API and <code>Marshmallow</code> packages. References to both are available in the <em class="italic">Further reading</em> section. Now, we need to make our application deployable so that we can use it in a range of settings for our next step.</p>&#13;
			<h2 id="_idParaDest-164"><a id="_idTextAnchor163"/>Building a Docker image for our application </h2>&#13;
			<p>For our application to be<a id="_idIndexMarker614"/> usable, we must build a Docker image of our application that accepts requests. Then, we must protect it with another container call that acts as an ingress. NGINX performs load balancing, caching, streaming, and the redirecting of traffic. Our application will be run using the Gunicorn package, which, essentially, runs multiple workers of our application at the same time. For each request, NGINX asks which Gunicorn worker the request should go to and redirects it, as shown in the following diagram:</p>&#13;
			<p class="figure-caption">  </p>&#13;
			<p>&#13;
				<p>&#13;
					<img src="img/Figure_9.03_B17720.jpg" alt="Figure 9.3 – The flow of requests for our application&#13;&#10;" width="1149" height="538"/>&#13;
				</p>&#13;
			</p>&#13;
			<p class="figure-caption">Figure 9.3 – The flow of requests for our application</p>&#13;
			<p>We can achieve the layout defined in the preceding diagram by performing the following steps:</p>&#13;
			<ol>&#13;
				<li value="1">Before we build a<a id="_idIndexMarker615"/> Docker image, we must make sure the requirements for our application are handled. Therefore, we must install Gunicorn using <code>pip</code> with the following command:<pre><strong class="bold">pip install gunicorn</strong></pre></li>&#13;
				<li>We must make sure that we are in the <code>src</code> directory because we are going to dump all of our application dependencies into a file called <code>requirements.txt</code> using the following command:<pre><strong class="bold"> pip freeze &gt; requirements.txt</strong></pre><p>This gives us a text file with a list of all the dependencies that our application needs in order to run. Right now, all we need is Flask and Gunicorn.</p></li>&#13;
				<li>With this, we can start coding our Docker file so that we can build application images of our application. First, in our <code>src/Dockerfile</code> file, we should define the operating system that is required with the following code:<pre>FROM python:3.6.13-stretch</pre><p>This means that our image is running a stripped-down version of Linux with Python installed.</p></li>&#13;
				<li>Now that we have the<a id="_idIndexMarker616"/> correct operating system, we should define our app's directory and copy all of our application files into the image using the following code:<pre># Set the working directory to /app
WORKDIR /app
# Copy the current directory contents into the 
  container at /app
ADD . /app</pre></li>&#13;
				<li>Now that all of our application files are in the image, we install system updates and then install the <code>python-dev</code> package. This is so that we can include extensions with the code given here:<pre>RUN apt-get update -y
RUN apt-get install -y python3-dev python-dev gcc</pre><p>This will enable us to compile our Rust code in our application and use database binaries.</p><p>Our system has now been set up, so we can move on to install our requirements using the following code:</p><pre>RUN pip install --upgrade pip setuptools wheel
RUN pip install -r requirements.txt</pre><p>Everything is in place to define our system. Nothing is stopping us from running our application. </p></li>&#13;
				<li>To do this, we expose the port and run our application using the following code:<pre>EXPOSE 5002
CMD ["gunicorn", "-w 4", "-b", "0.0.0.0:5002", \
  "app:app"]</pre><p>Note that when<a id="_idIndexMarker617"/> we create a container from the image, we run <code>CMD</code> with the parameters defined in the list. We state that we have four workers with the <code>-w 4</code> parameter. Then, we define the URL and port that we are listening to. Our final parameter is <code>app:app</code>. This states that our application is housed in the <code>app.py</code> file, and our application in that file is the <code>Flask</code> object under the variable name of <code>app</code>. </p></li>&#13;
				<li>We can now build our application image using the following command:<pre><code>flask-fib</code> tag. </p></li>&#13;
				<li>We can then inspect our images using the following command:<pre><strong class="bold">docker image ls</strong></pre><p>Running this command gives us an image that has been created in the following form:</p><pre><strong class="bold">REPOSITORY      TAG         IMAGE ID</strong>
<strong class="bold">flask-fib</strong><strong class="bold">       latest      0cdb0c979ac1</strong>
<strong class="bold">CREATED          SIZE</strong>
<strong class="bold">33 minutes ago   1.05GB</strong></pre></li>&#13;
			</ol>&#13;
			<p>This is important. We will need to reference our image later when we are running our application with NGINX, which we will define next.</p>&#13;
			<h2 id="_idParaDest-165"><a id="_idTextAnchor164"/>Building our NGINX service </h2>&#13;
			<p>When it comes to <a id="_idIndexMarker618"/>Docker and NGINX, we are lucky in that we do not have to build a Dockerfile that defines our NGINX image. NGINX has released an official image that we can download and use for free. However, we do have to alter its configuration. NGINX is fairly important; this is because it gives us the ability to control how incoming requests are processed. We can redirect the requests to different services depending on parts of the URL. Additionally, we can control the size of the data, the duration of the connection, and configure HTTPS traffic. NGINX can also act as a load balancer. In this example, we are going to configure NGINX in the simplest format to get it running. However, it must be noted that NGINX is a vast topic in itself; a reference to a useful NGINX book is provided in the <em class="italic">Further reading</em> section.</p>&#13;
			<p>We can build our NGINX service and connect it to our Flask application by performing the following steps:</p>&#13;
			<ol>&#13;
				<li value="1">We will configure our NGINX container with what we code in the <code>deployment/nginx/nginx.conf</code> file. In this file, we declare our worker processes and error log, as follows:<pre>worker_processes  auto;
error_log  /var/log/nginx/error.log warn;</pre><p>Here, we have defined <code>worker_processes</code> as <code>auto</code>. This is where we automatically detect the number of CPU cores available, setting the number of processes to the number of CPU cores. </p></li>&#13;
				<li>Now, we have to define the maximum number of connections that a worker can entertain at a time using the following code:<pre>events {
    worker_connections  512;
}</pre><p>It must be noted that the number that is chosen here is the default number for NGINX.</p></li>&#13;
				<li>All that is now left for us to do is to define our HTTP listener. This can be achieved with the following code:<pre>http {
    server {
           listen 80;
           location / {
                proxy_pass http://flask_app:5002/;
           }
    }
}</pre><p>Here, observe<a id="_idIndexMarker619"/> that we listen to port <code>80</code>, which is the standard outside listening port. Then, we state that if there is any pattern to our URL, we pass it to our <code>flask_app</code> container at port <code>5002</code>. We can stack multiple locations in the <code>http</code> section if we wish. For instance, if we have another app, we can route the request to the other application if the URL tail starts with <code>/another_app/</code> using the following code:</p><pre>           location /another_app {
                proxy_pass http://another_app:5002/;
           }
           location / {
                proxy_pass http://flask_app:5002/;
           }</pre></li>&#13;
			</ol>&#13;
			<p>Our configuration file for our NGINX is complete. Again, there are many more configuration parameters; we are just running the bare minimum. More resources on these parameters<a id="_idIndexMarker620"/> are signposted in the <em class="italic">Further reading</em> section. Considering that our NGINX configuration file is complete, for the next step, we have to run it alongside our Flask application. </p>&#13;
			<h2 id="_idParaDest-166"><a id="_idTextAnchor165"/>Connecting and running our Nginx service </h2>&#13;
			<p>To run our application and NGINX together, we will be using <code>docker-compose</code>. This allows us to define multiple Docker containers at the same time that can talk to each other. Nothing is stopping us from running <code>docker-compose</code> on a server to achieve a basic setup. However, more advanced systems such as Kubernetes can help with the orchestration of Docker containers <a id="_idIndexMarker621"/>across multiple servers<a id="_idIndexMarker622"/> if needed. In addition to this, different cloud platforms offer out-of-the-box load balancers. Perform the following steps:</p>&#13;
			<ol>&#13;
				<li value="1">In our <code>deployment/docker-compose.yml</code> file, we state what version of <code>docker-compose</code> we are using with the following code:<pre>version: "3.7"</pre></li>&#13;
				<li>Now that this has been implemented, we can define our services along with our first service, which is our Flask application. This is defined with the following code:<pre>services:
    flask_app:
        container_name: fib-calculator
        image: "flask-fib:latest"
        restart: always
        ports:
          - "5002:5002"
        expose:
            - 5002</pre><p>In the preceding code, we reference the image that we built with the latest release. For instance, if we changed the image and rebuilt it, then our <code>docker-compose</code> setup would use this. We also give it a container name, so we know the container status when checking the running containers. Additionally, we state that we accept traffic through port <code>5002</code>, and we route it to our container's port <code>5002</code>. Because we have chosen this path, we also expose port <code>5002</code>. If we run our <code>docker-compose</code> setup now, we could access our application with<a id="_idIndexMarker623"/> the <code>http://localhost:5002</code> URL. However, if this was running on a server and port <code>5002</code> was <a id="_idIndexMarker624"/>not accessible to outside traffic, then we would not be able to access it. </p></li>&#13;
				<li>Considering this, we can define our NGINX in our <code>deployment/docker-compose.yml</code> file using the following code:<pre>    nginx:
        container_name: 'nginx'
        image: "nginx:1.13.5"
        ports:
          - "80:80"
        links:
            - flask_app
        depends_on:
            - flask_app
        volumes:
          - ./nginx/nginx.conf:/etc/nginx/nginx.conf</pre><p>Here, you can see that we rely on the third-party NGINX image and that we route the outside port of <code>80</code> to port <code>80</code>. Also, we link to our Flask application, and we depend on it, meaning that <code>docker-compose</code> will ensure that our Flask application is up and running before we run our NGINX service. In the <code>volumes</code> section, we replace the standard configuration file with the configuration file that we defined in the previous step. As a result, our NGINX service will run the configuration that we defined. It must be noted that this configuration switch will happen every time we run <code>docker-compose</code>. This means that if we change our configuration file and then run <code>docker-compose</code> again, we will see the changes. So, we have done everything to get our application up and running. Now we can test it.</p></li>&#13;
				<li>Testing our <a id="_idIndexMarker625"/>application is as easy as <a id="_idIndexMarker626"/>running the following command:<pre><code>5002</code>, and boots up workers to process requests. Following this, our NGINX service looks for a range of configurations before<a id="_idIndexMarker627"/> concluding that the configuration is complete and that it is ready to<a id="_idIndexMarker628"/> start up. Also, note that the NGINX started after our Flask application was started. This is because we stated that our NGINX was dependent on our Flask application when building our <code>docker-compose</code> file.</p><p>Now, we can directly hit our localhost URL without having to specify a port because we are listening to the outside port of <code>80</code> with our NGINX. This gives us results similar to the following:</p></li>&#13;
			</ol>&#13;
			<p>&#13;
				<p>&#13;
					<img src="img/Figure_9.04_B17720.jpg" alt="Figure 9.4 – Interacting with our fully containerized Flask application&#13;&#10;" width="367" height="73"/>&#13;
				</p>&#13;
			</p>&#13;
			<p class="figure-caption">Figure 9.4 – Interacting with our fully containerized Flask application</p>&#13;
			<p>Now we have a fully containerized application that runs. This is at a ready state, so in the next chapter, we can test to see whether our Rust integration with our application will actually work in a real-life scenario. Now that we have gotten our application running, we can move on to build our data access layer. This will allow us to store and get data from a database. </p>&#13;
			<h1 id="_idParaDest-167"><a id="_idTextAnchor166"/>Defining our data access layer</h1>&#13;
			<p>Now we have an application <a id="_idIndexMarker629"/>that takes in a number and calculates a Fibonacci number based on it. However, a database lookup is quicker than a calculation. We will use this fact to optimize our application by initially performing a database lookup when a number is submitted. If it is not there, we calculate the number, store it in the database, and then return it to the user. Before we start building, we will have to install the following packages using <code>pip</code>:</p>&#13;
			<ul>&#13;
				<li><code>pyml</code>: This package helps in loading parameters for our application from a <code>.yml</code> file.</li>&#13;
				<li><code>sqlalchemy</code>: This package enables our application to map Python objects to databases for storing and querying. </li>&#13;
				<li><code>alembic</code>: This package helps in tracking and applying changes to the database from the application.</li>&#13;
				<li><code>psycopg2-binary</code>: This is the binary that will enable our application to connect to the database. </li>&#13;
			</ul>&#13;
			<p>Now that we have installed all that we need, we can enable our application to store and get Fibonacci numbers by performing the following steps:</p>&#13;
			<ol>&#13;
				<li value="1">Define a PostgreSQL database in <code>docker-compose</code>.</li>&#13;
				<li>Build a config loading system.</li>&#13;
				<li>Define a data access layer.</li>&#13;
				<li>Build database models.</li>&#13;
				<li>Set up the application database migration system.</li>&#13;
				<li>Apply the database access layer to the fib calculation view.</li>&#13;
			</ol>&#13;
			<p>Once we have<a id="_idIndexMarker630"/> completed these steps, our application will take the following form: </p>&#13;
			<pre>├── deployment</pre>&#13;
			<pre>│   . . .</pre>&#13;
			<pre>├── docker-compose.yml</pre>&#13;
			<pre>├── src</pre>&#13;
			<pre>│   . . .</pre>&#13;
			<pre>│   ├── config.py</pre>&#13;
			<pre>│   ├── config.yml</pre>&#13;
			<pre>│   ├── data_access.py</pre>&#13;
			<pre>│   ├── fib_calcs</pre>&#13;
			<pre>│   │   . . .</pre>&#13;
			<pre>│   ├── models</pre>&#13;
			<pre>│   │   ├── __init__.py</pre>&#13;
			<pre>│   │   └── database</pre>&#13;
			<pre>│   │       ├── __init__.py</pre>&#13;
			<pre>│   │       └── fib_entry.py</pre>&#13;
			<pre>│   └── requirements.txt</pre>&#13;
			<p>Our deployment file <a id="_idIndexMarker631"/>structure has not changed. We have added a <code>docker-compose.yml</code> file to our root as it will enable us to access the database when we are developing our application. In addition to this, we have added a data access file to enable us to connect to the database along with a <code>models</code> module to enable mapping objects to the database. This structure will result in a containerized Flask application that has access to a database. Next, we will begin defining our Docker container for our database. </p>&#13;
			<h2 id="_idParaDest-168"><a id="_idTextAnchor167"/>Defining a PostgreSQL database in docker-compose </h2>&#13;
			<p>To define our <a id="_idIndexMarker632"/>database container, we apply<a id="_idIndexMarker633"/> the following code to both the <code>deployment/docker-compose.yml</code> file and the <code>docker-compose.yml</code> file:</p>&#13;
			<pre>    Postgres:</pre>&#13;
			<pre>      container_name: 'fib-dev-Postgres</pre>&#13;
			<pre>      image: 'postgres:11.2'</pre>&#13;
			<pre>      restart: always</pre>&#13;
			<pre>      ports:</pre>&#13;
			<pre>        - '5432:5432'</pre>&#13;
			<pre>      environment:</pre>&#13;
			<pre>        - 'POSTGRES_USER=user'</pre>&#13;
			<pre>        - 'POSTGRES_DB=fib'</pre>&#13;
			<pre>        - 'POSTGRES_PASSWORD=password'</pre>&#13;
			<p>Here, you can observe that we are relying on the official third-party Postgres image. Instead of defining a configuration file, as we did with the NGINX service, we define the password, database name, and user using the environment variables. When we are running our local environment and developing our application, we will run our <code>docker-compose</code> file in the root. Now we have defined our database; in the next section, we can build our config system. </p>&#13;
			<h2 id="_idParaDest-169"><a id="_idTextAnchor168"/>Building a config loading system </h2>&#13;
			<p>Essentially, our <a id="_idIndexMarker634"/>configuration system loads parameters from a <code>.yml</code> file inside the Flask application by performing these steps:</p>&#13;
			<ol>&#13;
				<li value="1">Our application might require different parameters depending on the system. Because of this, we must build an object that loads parameters from a <code>.yml</code> file and serves them as a dictionary throughout the application. In our <code>src/config.py</code> file, first, we import what we need with the following code:<pre>import os
import sys
from typing import Dict, List
import yaml</pre><p>We will be using the <code>sys</code> module to take in the arguments that were passed into our application while running it. We use the <code>os</code> module to check whether the config file that we have specified in the arguments exists. </p></li>&#13;
				<li>Our global parameters object can be built using the following code:<pre>class GlobalParams(dict):
    def __init__(self) -&gt; None:
        super().__init__()
        self.update(self.get_yml_file())
    @staticmethod
    def get_yml_file() -&gt; Dict:
        file_name = sys.argv[-1]
        if ".yml" not in file_name:
            file_name = "config.yml"
        if os.path.isfile(file_name):
            with open("./{}".format(file_name)) as \
              file:
                data = yaml.load(file, 
                       Loader=yaml.FullLoader)
            return data
        raise FileNotFoundError(
            "{} config file is not available".
                format(file_name)
        )
    @property
    def database_meta(self) -&gt; Dict[str, str]:
        db_string: str = self.get("DB_URL")
        buffer: List[str] = db_string.split("/")
        second_buffer: List[str] = buffer[- \
          2].split(":")
        third_buffer: List[str] = \
          second_buffer[1].split("@")
        return {
            "DB_URL": db_string,
            "DB_NAME": buffer[-1],
            "DB_USER": second_buffer[0],
            "DB_PASSWORD": third_buffer[0],
            "DB_LOCATION":f"{third_buffer[1]} \
              :{second_buffer[-1]}",
        }</pre><p>Here, you can observe that our <code>GlobalParams</code> class directly inherits from the dictionary class. This means that we have all the functionality of a dictionary. In addition to this, note that we do not pass any arguments into our Python program specifying which <code>.yml</code> file to load; instead, we simply revert to the standard <code>config.yml</code> file. This is because we will use our configuration file for migrations to the database. It will be difficult to pass in our parameters when <a id="_idIndexMarker635"/>performing database migrations. If we want to change the configuration, it is best to get the new data and write it to the config file.</p></li>&#13;
				<li>Now that our config parameters class has been defined, we can add the database URL to our <code>src/config.yml</code> file using the following code:<pre>DB_URL: \
"postgresql://user:password@localhost:5432/fib"</pre></li>&#13;
			</ol>&#13;
			<p>Now that we have access to our database URL, in the next step, we can build our database access layer.</p>&#13;
			<h2 id="_idParaDest-170"><a id="_idTextAnchor169"/>Building our data access layer </h2>&#13;
			<p>Our database access <a id="_idIndexMarker636"/>will be defined in the <code>src/data_access.py</code> file. Once this is done, we can import the data access layer from the <code>src/data_access.py</code> file anywhere in the Flask application. This is so that we can access the database anywhere inside the Flask application. We can build this by performing the following steps:</p>&#13;
			<ol>&#13;
				<li value="1">First of all, we have to import what we need using the following code:<pre>from flask import _app_ctx_stack
from sqlalchemy import create_engine
from sqlalchemy.ext.declarative import 
declarative_base
from sqlalchemy.orm import sessionmaker, 
scoped_session
from config import GlobalParams</pre><p>Here, we will use the <code>_app_ctx_stack</code> object to ensure that our session is in the context of the Flask request. Following this, we import all of the other <code>sqlalchemy</code> dependencies to ensure that our access has a session maker and an engine. We have to avoid going into excessive detail with database management as this book focuses on fusing Rust with Python and we are merely using SQLAlchemy to explore database integration with Rust. However, we should be able to get a feel for what the session, engine, and base do.</p></li>&#13;
				<li>Now that we have<a id="_idIndexMarker637"/> imported everything we need, we can build our database engine using the following code:<pre>class DbEngine:
    def __init__(self) -&gt; None:
        params = GlobalParams()
        self.base = declarative_base()
        self.engine = create_engine(params.get
          ("DB_URL"),
                                   echo=True,
                                   pool_recycle=3600,
                                   pool_size=2,
                                   max_overflow=1,
                                   connect_args={
                                  'connect_timeout': 5
                                    })
        self.session = scoped_session(sessionmaker(
            bind=self.engine
        ), scopefunc=_app_ctx_stack)
        self.url = params.get("DB_URL")
dal = DbEngine()</pre><p>Now we have a<a id="_idIndexMarker638"/> class that can give us database sessions, a database connection, and a base. However, it must be noted that we initiated the <code>DbEngine</code> class and assigned it to the <code>dal</code> variable; however, we didn't import the <code>DbEngine</code> class outside of this file. Instead, we import the <code>dal</code> variable to be used for interactions with the database. If we import the <code>DbEngine</code> class outside of this file during initiation and use it whenever we want to interact with the database, we will create multiple database sessions per request and these sessions will struggle to close. Even something as small as a couple of users will grind your database to a halt with too many hanging connections. Now that our database connection has been defined, in the next step, we can move on to build our database models.</p></li>&#13;
				<li>In our database model, we can have a unique ID, input number, and fib number. Our model is defined in the <code>src/models/database/fib_entry.py</code> file with the following code:<pre>from typing import Dict
from sqlalchemy import Column, Integer
from data_access import dal
class FibEntry(dal.base):
    __tablename__ = "fib_entries"
    id = Column(Integer, primary_key=True)
    input_number = Column(Integer)
    calculated_number = Column(Integer)
    @property
    def package(self) -&gt; Dict[str, int]:
        return {
            "input_number": self.input_number,
            "calculated_number": \
              self.calculated_number
        }</pre></li>&#13;
			</ol>&#13;
			<p>Here, you can see <a id="_idIndexMarker639"/>that the code is straightforward. We pass <code>dal.base</code> through our model to add the model to the metadata. Then, we define the table name that will be in the database and model fields, which are <code>id</code>, <code>input_number</code>, and <code>calculated_number</code>. Our database model has now been defined, so we can import and use it throughout our application. Additionally, we will use this in the next step to manage the database migrations. </p>&#13;
			<h2 id="_idParaDest-171"><a id="_idTextAnchor170"/>Setting up the application database migration system</h2>&#13;
			<p>Migrations are a <a id="_idIndexMarker640"/>useful tool for keeping track of all the changes made to our database. If we make a change in a database model or define one, we need to translate those changes to our database. We can achieve this by performing the following steps:</p>&#13;
			<ol>&#13;
				<li value="1">For our database management, we are going to lean on the <code>alembic</code> package. Once we have navigated inside the <code>src/</code> directory, we run the following command:<pre><code>src/alembic/env.py</code> file; we are going to alter this so that we can connect our <code>alembic</code> scripts and commands to our database. </p></li>&#13;
				<li>Next, we must import the <code>os</code> and <code>sys</code> modules, as we will be using them to import our models and load our configuration file. We import the modules using the following code:<pre>import sys
import os</pre></li>&#13;
				<li>Following<a id="_idIndexMarker641"/> this, we use the <code>os</code> module to append the path that is in the <code>src/</code> directory with the following code:<pre>from alembic import context
# this is the Alembic Config object, which provides
# access to the values within the .ini file in use.
Config = context.config
# Interpret the config file for Python logging.
# This line sets up loggers basically.
fileConfig(config.config_file_name)
# add the src to our import path
sys.path.append(os.path.join(
    os.path.dirname(os.path.abspath(__file__)), 
    "../")
)</pre></li>&#13;
				<li>Now that we<a id="_idIndexMarker642"/> have configured our import path, we can import our parameters and database engine. Then, we add our database URL to our <code>alembic</code> database URL using the following code:<pre># config the database url for migrations
from config import GlobalParams
params = GlobalParams()
section = config.config_ini_section
db_params = params.database_meta
config.set_section_option(section, 'sqlalchemy.url', 
                          params.get('DB_URL'))
from data_access import dal
db_engine = dal
from models.database.fib_entry import FibEntry
target_metadata = db_engine.base.metadata</pre></li>&#13;
				<li>With this, you can observe that the autogenerated function gets our config, which then executes the migrations with the following code:<pre>def run_migrations_offline():
    url = config.get_main_option("sqlalchemy.url")
    context.configure(
        url=url,
        target_metadata=target_metadata,
        literal_binds=True,
        dialect_opts={"paramstyle": "named"},
        render_as_batch=True
    )
    with context.begin_transaction():
        context.run_migrations()</pre></li>&#13;
				<li>Now that we<a id="_idIndexMarker643"/> have our configuration system linked up to our database migrations, we have to make sure <code>docker-compose</code> is running because our database has to be live. We can generate a migration using the following command:<pre><code>src/alembic/versions/</code> file, there is an autogenerated script that creates our table with the following code:</p><pre># revision identifiers, used by Alembic.
Revision = '40b83d85c278'
down_revision = None
branch_labels = None
depends_on = None
def upgrade():
    op.create_table('fib_entries',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('input_number', sa.Integer(),\ 
      nullable=True),
    sa.Column('calculated_number', sa.Integer(), \ 
     nullable=True),
    sa.PrimaryKeyConstraint('id')
    )
def downgrade():
    op.drop_table('fib_entries')</pre><p>Here, if we<a id="_idIndexMarker644"/> upgrade, the <code>upgrade</code> function will run, and if we downgrade, the <code>downgrade</code> function will run. We can upgrade our database using the following command:</p><pre><strong class="bold">alembic upgrade head</strong></pre><p>This gives us the following printout:</p><pre><strong class="bold">INFO  [alembic.runtime.migration] Context impl </strong>
<strong class="bold">PostgresqlImpl.</strong>
<strong class="bold">INFO  [alembic.runtime.migration] Will assume </strong>
<strong class="bold">transactional DDL.</strong>
<strong class="bold">INFO  [alembic.runtime.migration] Running upgrade  -&gt; </strong>
<strong class="bold">40b83d85c278, create-fib-entry</strong></pre></li>&#13;
			</ol>&#13;
			<p>Our <a id="_idIndexMarker645"/>migration has worked. In the next step, we will interact with the database in our application. </p>&#13;
			<h2 id="_idParaDest-172"><a id="_idTextAnchor171"/>Building database models</h2>&#13;
			<p>Now that we have a <a id="_idIndexMarker646"/>database that has our application models applied to it, we can interact with our database in the application. This can be done by importing our data access layer and data model into the view that is using them and, well, use them: </p>&#13;
			<ol>&#13;
				<li value="1">For our example, we will be implementing our view inside the <code>src/app/app.py</code> file. First, we import the data access layer and model using the following code:<pre>from data_access import dal
from models.database.fib_entry import FibEntry</pre><p>With these imports, we can alter our calculation view to check whether the number exists in the database and return the number from the database if it does. </p></li>&#13;
				<li>If it is not available in the database, then we calculate it, save the result in the database, and return the result using the following code:<pre>@app.route("/calculate/&lt;int:number&gt;")
def calculate(number):
    fib_calc = dal.session.query(FibEntry).filter_by(
           input_number=number).one_or_none()
    if fib_calc is None:
        calc = FibCalculation(input_number=number)
        new_calc = FibEntry(input_number=number,
                  calculated_number=calc.fib_number)
        dal.session.add(new_calc)
        dal.session.commit()
        return f"you entered {calc.input_number} " \
               f"which has a Fibonacci number of " \
               f"{calc.fib_number}"
    return f"you entered {fib_calc.input_number} " 
       f"which has an existing Fibonacci number of " 
           f"{fib_calc.calculated_number}"</pre><p>Here, you can<a id="_idIndexMarker647"/> observe that our interactions with the database are straightforward. </p></li>&#13;
				<li>Now we have to make sure that when our request has finished, our database sessions are expired, closed, and removed using the following code:<pre>@app.teardown_request
def teardown_request(*args, **kwargs):
    dal.session.expire_all()
    dal.session.remove()
    dal.session.close()</pre></li>&#13;
			</ol>&#13;
			<p>So, we have a safe and fully functioning interaction with our database. You are now aware of the fundamentals of interacting with a database using our application. You can achieve other, more complex database queries by reading the SQLAlchemy documentation about the specifics of the database, other database queries, and insertions as a way to map syntax. If we run our application locally and hit our calculation view twice, we will get the first and second results, as shown in the following screenshot:</p>&#13;
			<p>&#13;
				<p>&#13;
					<img src="img/Figure_9.05_B17720.jpg" alt="Figure 9.5 – The top part is the first request (calculated), and the &#13;&#10;bottom part is the second request (database call)&#13;&#10;" width="924" height="474"/>&#13;
				</p>&#13;
			</p>&#13;
			<p class="figure-caption">Figure 9.5 – The top part is the first request (calculated), and the bottom part is the second request (database call)</p>&#13;
			<p>Our database is working<a id="_idIndexMarker648"/> the way we expect it to. Now the application is fully functioning, and you can move on to the next section if you wish, as this is enough to test Rust code in a Flask application, which we will do in the next chapter. However, if you want to understand how we apply the database in our deployment section, we will cover this next.</p>&#13;
			<h2 id="_idParaDest-173"><a id="_idTextAnchor172"/>Applying the database access layer to the fib calculation view</h2>&#13;
			<p>Adding a database to our <a id="_idIndexMarker649"/>deployment is a matter <a id="_idIndexMarker650"/>of adding it to our <code>docker-compose</code> deployment and updating our configuration file to map to the database service in the <code>docker-compose</code> deployment. We can achieve this by performing the following steps: </p>&#13;
			<ol>&#13;
				<li value="1">First, we have to refactor our <code>deployment/docker-compose.yml</code> file using the following code:<pre>services:
    flask_app:
        container_name: fib-calculator
        image: "flask-fib:latest"
        restart: always
        ports:
          - "5002:5002"
        expose:
            - 5002
        depends_on:
          - postgres
        links:
          - postgres
    nginx:
        . . .
    postgres:
        container_name: 'fib-live-postgres'
        image: 'postgres:11.2'
        restart: always
        ports:
            - '5432:5432'
        environment:
            - 'POSTGRES_USER=user'
            - 'POSTGRES_DB=fib'
            - 'POSTGRES_PASSWORD=password'</pre><p>You can observe that we have a slightly different name for our database container. This is to ensure that there are no clashes with our development database. Additionally, we have declared that our Flask application is dependent on and linked to our database. </p></li>&#13;
				<li>We also<a id="_idIndexMarker651"/> have to point our<a id="_idIndexMarker652"/> Flask application to the Docker database. To do this, we have to have a different configuration file for our Flask application. We can manage the configuration file switch in <code>src/Dockerfile</code> for the Flask application. This can be done using the following code:<pre># Copy the current directory contents into the 
  container at /app
ADD . /app
RUN rm ./config.yml
RUN mv live_config.yml config.yml
. . .</pre><p>Here, we remove the <code>config.yml</code> file and then change the filename of the <code>live_config.yml</code> file to <code>config.yml</code>.</p></li>&#13;
				<li>Then, we have to make our <code>src/live_config.yml</code> file with the following content:<pre>DB_URL: "postgresql://user:password@postgres:5432/fib"</pre><p>Here, we have changed <code>@localhost</code> to <code>@postgres</code> because the classification of our service is called <code>postgres</code>. </p></li>&#13;
				<li>Following this, we can rebuild our Flask image using the following command:<pre><strong class="bold">docker build . -t flask-fib</strong></pre></li>&#13;
				<li>Now we can run our <code>docker-compose</code> deployment, but we will have to run our migrations while our <code>docker-compose</code> deployment is running. This is because our Flask application will not cause an error if it is out of sync with the database until we try and make a query to the database, so running <code>docker-compose</code> before migrating is fine if we make no requests. When we make the migration, we must do this while the database in <code>docker-compose</code> is running; otherwise, the migration will not be able to connect to the database. We can <a id="_idIndexMarker653"/>run the migration<a id="_idIndexMarker654"/> while <code>docker-compose</code> is running using the following command:<pre><strong class="bold">docker exec -it fib-calculator alembic upgrade head</strong></pre></li>&#13;
			</ol>&#13;
			<p>This runs the migrations on our Flask container. It is not advised that you only have your live configuration files within your application code. A favorite method of mine is to upload an encrypted configuration file in AWS S3 and pull it in Kubernetes as it starts up a pod. This is beyond the scope of this book, as this is not a web development book. However, it is important to keep methods such as this in mind for further reading if needed. </p>&#13;
			<p>Right now, there is not much to complain about when it comes to calculating Fibonacci numbers with our Flask application. However, when we try and calculate a large number, we will be waiting for a long time, and this will keep the request hanging. To prevent this from occurring, in the next section, we are going to implement a message bus. This is so that while our application is processing large numbers in the background, we can return a message telling the users to be patient.</p>&#13;
			<h1 id="_idParaDest-174"><a id="_idTextAnchor173"/>Building a message bus </h1>&#13;
			<p>For this section, we will be<a id="_idIndexMarker655"/> using the <code>Celery</code> and <code>Redis</code> packages to build and run our message bus. Once we have completed this section, our mechanism will take a form that is similar to the following:</p>&#13;
			<p>&#13;
				<p>&#13;
					<img src="img/Figure_9.06_B17720.jpg" alt="Figure 9.6 – A message bus with Flask and Celery&#13;&#10;" width="1354" height="468"/>&#13;
				</p>&#13;
			</p>&#13;
			<p class="figure-caption">Figure 9.6 – A message bus with Flask and <code>Celery</code></p>&#13;
			<p>As shown in the preceding diagram, we have two processes running. One is running our Flask application, while the other is running <code>Celery</code>, which handles queuing and processing tasks. To <a id="_idIndexMarker656"/>make this work, we are going to perform the following steps:</p>&#13;
			<ol>&#13;
				<li value="1">Build a <code>Celery</code> broker for Flask.</li>&#13;
				<li>Build a Fibonacci calculation task for <strong class="bold">Celery</strong>.</li>&#13;
				<li>Update our calculation view with <code>Celery</code>.</li>&#13;
				<li>Define our <code>Celery</code> service in Docker.</li>&#13;
			</ol>&#13;
			<p>Before we embark on these steps, we have to install the following packages using <code>pip</code>:</p>&#13;
			<ul>&#13;
				<li><code>Celery</code>: This is the message bus broker that we are going to use.</li>&#13;
				<li><code>Redis</code>: This is the storage system that <code>Celery</code> is going to use.</li>&#13;
			</ul>&#13;
			<p>Now that we have installed the requirements, we have to remember to update the <code>src/requirements.txt</code> file with <code>Celery</code> and Redis for our Docker builds. Now that we have all of our dependencies installed, we can start building our <code>Celery</code> broker, as demonstrated next.</p>&#13;
			<h2 id="_idParaDest-175"><a id="_idTextAnchor174"/>Building a Celery broker for Flask </h2>&#13;
			<p>Essentially, our <code>Celery</code><a id="_idIndexMarker657"/> broker is a storage system that will store data<a id="_idIndexMarker658"/> concerning the tasks we have sent to it. We can set up our storage system and connect it to our <code>Celery</code> system using the following steps:</p>&#13;
			<ol>&#13;
				<li value="1">We are going to build our own module when building our task queue. Inside the <code>src/</code> directory, our task queue module will take the following structure:<pre>└── task_queue
    ├── __init__.py
    ├── engine.py
    └── fib_calc_task.py</pre><p>Our <code>engine.py</code> file will host a constructor for <code>Celery</code> that considers the context of the Flask application. </p></li>&#13;
				<li>We will build our Fibonacci calculation <code>Celery</code> task in the <code>fib_calc_task.py</code> file. In our <code>engine.py</code> file, we can build our constructor using the following code:<pre>from celery import Celery
from config import GlobalParams
def make_celery(flask_app):
    params = GlobalParams()
    celery = Celery(
        backend=params.get("QUEUE_BACKEND"),
        broker=params.get("QUEUE_BROKER")
    )
    celery.conf.update(flask_app.config)
    class ContextTask(celery.Task):
        def __call__(self, *args, **kwargs):
            with flask_app.app_context():
                return self.run(*args, **kwargs)
    celery.Task = ContextTask
    return celery</pre><p>The <code>backend</code> and <code>broker</code> parameters will point to the storage; we will define them later. Here, you can observe that we must pass the Flask application into the function, construct the <code>Celery</code> class, and fuse a <code>Celery</code> task object with the Flask application context and then return it. When it comes to defining an entry point for running <a id="_idIndexMarker659"/>our <code>Celery</code> process, we should place it in<a id="_idIndexMarker660"/> the same file as our Flask application. This is because we want to use the same Docker build and, thus, image for the Flask application and <code>Celery</code> process.</p></li>&#13;
				<li>To achieve this, we import our <code>Celery</code> constructor and pass the Flask application through it, in the <code>src/app.py</code> file, using the following code:<pre>. . .
from task_queue.engine import make_celery
app = Flask(__name__)
celery = make_celery(app)
. . .</pre></li>&#13;
				<li>Now, when we run our <code>Celery</code> broker, we will point it at our <code>src/app.py</code> file and the <code>Celery</code> object inside it. Additionally, we must define our backend storage system. Because we are using Redis, we can define these parameters in our <code>src/config.yml</code> file using the following code:<pre>QUEUE_BACKEND: "redis://localhost:6379/0"
QUEUE_BROKER: "redis://localhost:6379/0"</pre></li>&#13;
			</ol>&#13;
			<p>Now that we have defined our <code>Celery</code> broker, in the next step, we can build our Fibonacci calculation task.</p>&#13;
			<h2 id="_idParaDest-176"><a id="_idTextAnchor175"/>Building a Fibonacci calculation task for Celery </h2>&#13;
			<p>When it comes to running our<a id="_idIndexMarker661"/> <code>Celery</code> task, we <a id="_idIndexMarker662"/>need to build another constructor. However, instead of passing in our Flask application, we pass in our <code>Celery</code> broker. We can achieve this in the <code>src/task_queue/fib_calc_task.py</code> file using the following code:</p>&#13;
			<pre>from data_access import dal</pre>&#13;
			<pre>from fib_calcs.fib_calculation import FibCalculation</pre>&#13;
			<pre>from models.database.fib_entry import FibEntry</pre>&#13;
			<pre>def create_calculate_fib(input_celery):</pre>&#13;
			<pre>    @input_celery.task()</pre>&#13;
			<pre>    def calculate_fib(number):</pre>&#13;
			<pre>        calculation = FibCalculation(input_number=number)</pre>&#13;
			<pre>        fib_entry = FibEntry(</pre>&#13;
			<pre>            input_number=calculation.input_number,</pre>&#13;
			<pre>            calculated_number=calculation.fib_number</pre>&#13;
			<pre>        )</pre>&#13;
			<pre>        dal.session.add(fib_entry)</pre>&#13;
			<pre>        dal.session.commit()</pre>&#13;
			<pre>    return calculate_fib</pre>&#13;
			<p>The preceding<a id="_idIndexMarker663"/> logic is like our standard calculation<a id="_idIndexMarker664"/> view. We can import it into our <code>src/app.py</code> file and pass our <code>Celery</code> broker to it using the following code:</p>&#13;
			<pre>. . .</pre>&#13;
			<pre>from task_queue.engine import make_celery</pre>&#13;
			<pre>app = Flask(__name__)</pre>&#13;
			<pre>celery = make_celery(app)</pre>&#13;
			<pre>from task_queue.fib_calc_task import create_calculate_fib</pre>&#13;
			<pre>calculate_fib = create_calculate_fib(input_celery=celery)</pre>&#13;
			<pre>. . .</pre>&#13;
			<p>Now that we have our task defined and fused with our <code>Celery</code> broker and Flask application, in the next step, we can add our <code>Celery</code> task to the calculation view if the number is too large. </p>&#13;
			<h2 id="_idParaDest-177"><a id="_idTextAnchor176"/>Updating our calculation view</h2>&#13;
			<p>With our view, we<a id="_idIndexMarker665"/> must check to see whether our input number is less than <code>31</code> and not in the database. If it is, we run our standard existing code. However, if the input number is <code>30</code> or above, we will send the calculation to the <code>Celery</code> broker and return a message telling the user that it has been sent to the queue. We can do this using the following code:</p>&#13;
			<pre>@app.route("/calculate/&lt;int:number&gt;")</pre>&#13;
			<pre>def calculate(number):</pre>&#13;
			<pre>    fib_calc = dal.session.query(FibEntry).filter_by(</pre>&#13;
			<pre>                       input_number=number).one_or_none()</pre>&#13;
			<pre>    if fib_calc is None:</pre>&#13;
			<pre>        if number &lt; 31:</pre>&#13;
			<pre>            calc = FibCalculation(input_number=number)</pre>&#13;
			<pre>            new_calc = FibEntry(input_number=number,</pre>&#13;
			<pre>                                calculated_number=calc.</pre>&#13;
			<pre>                                fib_number)</pre>&#13;
			<pre>            dal.session.add(new_calc)</pre>&#13;
			<pre>            dal.session.commit()</pre>&#13;
			<pre>            return f"you entered {calc.input_number} " \</pre>&#13;
			<pre>                   f"which has a Fibonacci number of " \</pre>&#13;
			<pre>                   f"{calc.fib_number}"</pre>&#13;
			<pre>        calculate_fib.delay(number)</pre>&#13;
			<pre>        return "calculate fib sent to queue because " \</pre>&#13;
			<pre>               "it's above 30"</pre>&#13;
			<pre>    return f"you entered {fib_calc.input_number} " \</pre>&#13;
			<pre>           f"which has an existing Fibonacci number of " \</pre>&#13;
			<pre>           f"{fib_calc.calculated_number}"</pre>&#13;
			<p>Now our <a id="_idIndexMarker666"/><code>Celery</code> process with our task has been fully built. In the next step, we will define our Redis service in <code>docker-compose</code>.</p>&#13;
			<h2 id="_idParaDest-178"><a id="_idTextAnchor177"/>Defining our Celery service in Docker</h2>&#13;
			<p>When it comes to our <a id="_idIndexMarker667"/><code>Celery</code> service, remember that we used <a id="_idIndexMarker668"/>Redis as a storage mechanism. Considering this, we define our Redis service in our developed <code>docker-compose.yml</code> file using the following code:</p>&#13;
			<pre>. . .</pre>&#13;
			<pre>    redis:</pre>&#13;
			<pre>      container_name: 'main-dev-redis'</pre>&#13;
			<pre>      image: 'redis:5.0.3'</pre>&#13;
			<pre>      ports:</pre>&#13;
			<pre>        - '6379:6379'</pre>&#13;
			<p>Now running our whole system in develop mode requires running our developed <code>docker-compose</code> file at the root of our project. Additionally, we run the Flask application by running our <code>app.py</code> file with Python, where <code>PYTHONPATH</code> is set to <code>src</code>. </p>&#13;
			<p>Following this, we open another Terminal window, navigate the Terminal inside the <code>src</code> directory, and run the following command:</p>&#13;
			<pre>celery -A app.celery worker -l info</pre>&#13;
			<p>This is where we<a id="_idIndexMarker669"/> point <code>Celery</code> to the <code>app.py</code> file. We state that the<a id="_idIndexMarker670"/> object is called <code>Celery</code>, that it is a worker, and that the logging is at the <code>info</code> level. Running this gives us the following printout:</p>&#13;
			<pre>-------------- celery@maxwells-MacBook-Pro.</pre>&#13;
			<pre>--- ***** ----- local v5.1.2 (sun-harmonics)</pre>&#13;
			<pre>-- ******* ---- Darwin-20.2.0-x86_64-i386-64bit</pre>&#13;
			<pre>- *** --- * --- 2021-08-22 23:24:14</pre>&#13;
			<pre>- ** ---------- [config]</pre>&#13;
			<pre>- ** ---------- .&gt; app:         __main__:0x7fd0796d0ed0</pre>&#13;
			<pre>- ** ---------- .&gt; transport:   redis://localhost:6379/0</pre>&#13;
			<pre>- ** ---------- .&gt; results:     redis://localhost:6379/0</pre>&#13;
			<pre>- *** --- * --- .&gt; concurrency: 4 (prefork)</pre>&#13;
			<pre>-- ******* ---- .&gt; task events: OFF (enable -E to</pre>&#13;
			<pre>--- ***** -----    monitor tasks in this worker)</pre>&#13;
			<pre> -------------- [queues]</pre>&#13;
			<pre>                .&gt; celery  exchange=celery(direct) </pre>&#13;
			<pre>key=celery               </pre>&#13;
			<pre>[tasks]</pre>&#13;
			<pre>  . task_queue.fib_calc_task.calculate_fib</pre>&#13;
			<pre>[2021-08-22 23:24:14,385: INFO/MainProcess] Connected </pre>&#13;
			<pre>to redis://localhost:6379/0</pre>&#13;
			<pre>[2021-08-22 23:24:14,410: INFO/MainProcess] mingle: </pre>&#13;
			<pre>searching for neighbors</pre>&#13;
			<pre>[2021-08-22 23:24:15,476: INFO/MainProcess] mingle: </pre>&#13;
			<pre>all alone</pre>&#13;
			<pre>[2021-08-22 23:24:15,514: INFO/MainProcess] </pre>&#13;
			<pre>celery@maxwells-MacBook-Pro.local ready.</pre>&#13;
			<pre>[2021-08-22 23:24:39,822: INFO/MainProcess] </pre>&#13;
			<pre>Task task_queue.fib_calc_task.calculate_fib</pre>&#13;
			<pre>[c3241a5f-3208-48f7-9b0a-822c30aef94e] received</pre>&#13;
			<p>The preceding<a id="_idIndexMarker671"/> printout shows us that our task has been registered <a id="_idIndexMarker672"/>and that four processes have been spun up. Hitting the calculation view with our <code>Celery</code> processes using a number higher than <code>30</code> gives us the following view:</p>&#13;
			<p>&#13;
				<p>&#13;
					<img src="img/Figure_9.07_B17720.jpg" alt="Figure 9.7 – The bottom shows the first request with Celery, and the top shows the&#13;&#10; second request with Celery&#13;&#10;" width="918" height="472"/>&#13;
				</p>&#13;
			</p>&#13;
			<p class="figure-caption">Figure 9.7 – The bottom shows the first request with <code>Celery,</code> and the top shows the  second request with <code>Celery</code></p>&#13;
			<p>Our Flask <a id="_idIndexMarker673"/>application with a database and <code>Celery</code> message<a id="_idIndexMarker674"/> bus is now fully working locally. You can stop here if you wish, as this is enough to test Rust code in <code>Celery</code> in the next chapter. However, if you want to learn how to apply <code>Celery</code> to the deployment section, continue with this section.</p>&#13;
			<p>Applying <code>Celery</code> to our <code>docker-compose</code> deployment is straightforward. Remember that we have the same entry point, so there is no need for a new image. Instead, all we have to do is change the command that we run when spinning up our <code>Celery</code> container. This can be done in our <code>deployment/docker-compose.yml</code> file using the following code:</p>&#13;
			<pre>. . .</pre>&#13;
			<pre>    main_cache:</pre>&#13;
			<pre>        container_name: 'main-live-redis'</pre>&#13;
			<pre>        image: 'redis:5.0.3'</pre>&#13;
			<pre>        ports:</pre>&#13;
			<pre>            - '6379:6379'</pre>&#13;
			<pre>    queue_worker:</pre>&#13;
			<pre>        container_name: fib-worker</pre>&#13;
			<pre>        image: "flask-fib:latest"</pre>&#13;
			<pre>        restart: always</pre>&#13;
			<pre>        entrypoint: "celery -A app.celery worker -l info"</pre>&#13;
			<pre>        ports:</pre>&#13;
			<pre>            - "5003:5003"</pre>&#13;
			<pre>        expose:</pre>&#13;
			<pre>            - 5003</pre>&#13;
			<pre>        depends_on:</pre>&#13;
			<pre>            - main_cache</pre>&#13;
			<pre>        links:</pre>&#13;
			<pre>            - main_cache</pre>&#13;
			<p>Here, you can observe that we pull the same image for our <code>queue_worker</code> service. However, we change the <code>CMD</code> tag in our Docker build using the <code>entrypoint</code> tag in <code>docker-compose</code>. So, when our <code>queue_worker</code> service is built, it will run the <code>Celery</code> command <a id="_idIndexMarker675"/>running the <code>Celery</code> workers, as opposed to running<a id="_idIndexMarker676"/> the Flask web application. Following this, we need to add some more parameters to our <code>live_config.yml</code> file using the following code:</p>&#13;
			<pre>QUEUE_BACKEND: "redis://main_cache:6379/0"</pre>&#13;
			<pre>QUEUE_BROKER: "redis://main_cache:6379/0"</pre>&#13;
			<p>Here, we have named our Redis service as opposed to the localhost. This is so that our packaged <code>Celery</code> worker and Flask application will connect to our Redis service in the <code>docker-compose</code> deployment. After running the <code>docker-compose</code> deployment, we can repeat the requests demonstrated in <em class="italic">Figure 9.6</em> with <code>localhost</code> as opposed to <code>127.0.0.1:5002</code>. With this, our Flask application is ready to deploy with a database and task queue. Technically, our setup can be deployed and used on a server. I have done this, and it works just fine. However, for more advanced systems and control, it is advised that you carry out some further reading. Additional references about deploying Flask applications in Docker to cloud services such as Amazon Web Services are listed in the <em class="italic">Further reading</em> section.  </p>&#13;
			<h1 id="_idParaDest-179"><a id="_idTextAnchor178"/>Summary</h1>&#13;
			<p>In this chapter, we built a Python Flask application that had access to a database and message bus to allow the queuing of heavy tasks in the background. Following this, we wrapped our services in Docker containers and deployed them in a simple <code>docker-compose</code> file with NGINX. Additionally, we learned how to build our <code>Celery</code> worker and Flask application in the same Dockerfile using the same build. This made our code easier to maintain and deploy. We also managed our migrations for our database using <code>alembic</code> and a configuration file, which was then switched to another configuration file when we were deploying our application. While this is not a web development textbook, we have covered all of the essentials when it comes to structuring a Flask web application. </p>&#13;
			<p>Further details regarding database queries, data serialization, or HTML and CSS rendering are covered, in a straightforward manner, in the Flask documentation. We have covered all of the difficult stuff. Now, we can experiment with Rust and how it can be fused with a Python web application, not just in a development setting but a live setting where the application is running in a Docker container while communicating with other Docker containers. In the next chapter, we will fuse Rust with our Flask application. This is so that it can work with the development and deployment settings.</p>&#13;
			<h1 id="_idParaDest-180"><a id="_idTextAnchor179"/>Questions</h1>&#13;
			<ol>&#13;
				<li value="1">What do we change in the URI when we switch from development to deployment on <code>docker-compose</code> to communicate with another service?</li>&#13;
				<li>Why do we use configuration files?</li>&#13;
				<li>Do we really need <code>alembic</code> to manage the database?</li>&#13;
				<li>What do we have to do to our database engine to ensure our database does not get flooded with hanging sessions?</li>&#13;
				<li>Do we need Redis for our <code>Celery</code> worker process?</li>&#13;
			</ol>&#13;
			<h1 id="_idParaDest-181"><a id="_idTextAnchor180"/>Answers</h1>&#13;
			<ol>&#13;
				<li value="1">We switch the <code>localhost</code> part of the URI to the tag of the <code>docker-compose</code> service. </li>&#13;
				<li>Configuration files enable us to switch contexts easily; for instance, switching from development to live. Additionally, if our <code>Celery</code> service needs to talk to a different database for some reason, this can be done with minimal effort; simply changing the configuration file will work. It is also a security issue. Hardcoding database URIs will expose these credentials to anyone who has access to the code and will be in the GitHub repository history. Store the configuration file in a different space such as AWS S3, which gets pulled when the service is deployed.</li>&#13;
				<li>Technically, no. We can simply write SQL scripts and run them in sequence. When I was working in financial technology, this was actually a thing that we had to do. While this can give you more freedom, it does take more time and is more error-prone. Using <code>alembic</code> will save you time, errors, and work for pretty much most of your needs. </li>&#13;
				<li>We initiate our database engine once in the same file where our engine is defined. We never initiate it again, and we import this initiated engine anywhere we need. Not doing so will lead to our database to a grinding halt with dangling sessions and not very helpful error messages that will have you running around in circles on the internet with vague half-baked answers. Additionally, we have to close our sessions in the Flask teardown function for all requests.  </li>&#13;
				<li>Yes and no. We require a storage mechanism such as Redis; however, we can also use RabbitMQ or MongoDB instead of Redis if needed. </li>&#13;
			</ol>&#13;
			<h1 id="_idParaDest-182"><a id="_idTextAnchor181"/>Further reading</h1>&#13;
			<ul>&#13;
				<li><em class="italic">Nginx HTTP Server – Fourth Edition: Harness the power of Nginx</em> by Fjordvald M. and Nedelcu C. (2018) (Packt)</li>&#13;
				<li>The official Flask documentation – Pallets (2021): <a href="https://flask.palletsprojects.com/en/2.0.x/%0D">https://flask.palletsprojects.com/en/2.0.x/</a></li>&#13;
				<li><em class="italic">Hands-On Docker for Microservices with Python</em> by Jaime Buelta (2019) (Packt)</li>&#13;
				<li><em class="italic">AWS Certified Developer – Associate Guide – Second Edition</em> by Vipul Tankariya and Bhavin Parmar (2019) (Packt) </li>&#13;
				<li>The SQLAlchemy query reference documentation (2021): <a href="https://docs.sqlalchemy.org/en/14/orm/loading_objects.html%0D">https://docs.sqlalchemy.org/en/14/orm/loading_objects.html</a></li>&#13;
			</ul>&#13;
		</div>&#13;
	</div></body></html>