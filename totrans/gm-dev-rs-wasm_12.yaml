- en: '*Chapter 9*: Testing, Debugging, and Performance'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this book, we've built an entire game using two tools to test our logic –
    that is, a compiler and our eyes. If the game doesn't compile, it's broken, and
    if **Red Hat Boy** (**RHB**) doesn't look right, it's broken – simple enough.
    Fortunately, the compiler provides a lot of tools to make sure we don't make mistakes.
    Let's be honest, though – it's not enough.
  prefs: []
  type: TYPE_NORMAL
- en: Developing a game can be a long process, especially if you're a hobbyist. When
    you only have 4 hours to work on it in a given week, they can't all be spent fighting
    the same bug. To ensure our game works, we need to test it, find mistakes, and
    make sure it's not too slow. That's what we're going to be doing here.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Creating automated tests
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Debugging the game
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Measuring performance with the browser
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: After completing this chapter, you'll be able to fix the bugs we've written
    so far and make sure they don't happen again.
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we'll use the Chrome developer tools to debug the code and
    monitor performance. Other browsers also ship with robust developer tools, but
    for the screenshots and directions in this chapter, we'll be using Chrome.
  prefs: []
  type: TYPE_NORMAL
- en: The source code for this chapter is available at [https://github.com/PacktPublishing/Game-Development-with-Rust-and-WebAssembly/tree/chapter_9](https://github.com/PacktPublishing/Game-Development-with-Rust-and-WebAssembly/tree/chapter_9).
  prefs: []
  type: TYPE_NORMAL
- en: 'Check out the following video to see the Code in Action: [https://bit.ly/3NKppLk](https://bit.ly/3NKppLk)'
  prefs: []
  type: TYPE_NORMAL
- en: Creating automated tests
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In an ideal world, every system would have a large amount of testing, both
    automated and manual, that''s done by developers and QA. Some ways to test your
    game is working correctly involve doing the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Using types to prevent programmer errors
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Playing the game yourself
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Performing automated unit tests
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Performing automated integration tests
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: So far, we've only used the first two, which is an unfortunately common approach
    in real-world code. This can be suitable for personal or hobby projects but it
    isn't robust enough for production applications, particularly those written by
    a team.
  prefs: []
  type: TYPE_NORMAL
- en: 'Almost any application can benefit from automated, programmer-written unit
    tests and as a program becomes even larger, it begins to benefit from integration
    tests as well. There''s not a consistent definition of the differences between
    these two types of tests as you tend to know them when you see them, but fortunately,
    we can use the Rust definitions. Rust and Cargo provide two kinds of testing:'
  prefs: []
  type: TYPE_NORMAL
- en: Unit tests via `cargo test`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Integration tests via `wasm-pack test`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Unit tests tend to be programmer-centric. They are written at the method or
    function level, with minimal dependencies. You may have a test for every branch
    of an `if/else` statement, while in the case of a loop, you may have tests for
    when a list has 0, 1, or many entries. These tests are small and fast and should
    run in seconds or less. These are my preferred form of testing.
  prefs: []
  type: TYPE_NORMAL
- en: Integration tests tend to look at the app at a higher level. In the case of
    our code, the integration tests automate the browser and will work based on an
    event (such as a mouse click) throughout the program. These tests take longer
    to write, are harder to maintain, and often fail for mysterious reasons. So, why
    write them? Unit tests typically do not test parts of your application or they
    may only do so in small doses. This can lead to a situation where your unit tests
    all pass but the game doesn't work. Most systems will have fewer integration tests
    than unit tests because of their disadvantages, but they will need them for their
    benefits.
  prefs: []
  type: TYPE_NORMAL
- en: In Rust, unit tests are written side by side with a module and run with `cargo
    test`. In our setup, they will run as part of a Rust executable, running directly
    on the machine. Integration tests are stored in the `tests` directory and only
    have access to things your crate makes public. They run in the browser – potentially
    a headless one – with `wasm-pack test`. Unit tests can test internal methods directly,
    while integration tests must use your crate as a real program would.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs: []
  type: TYPE_NORMAL
- en: 'Ham Vocke has a very detailed article on the *Test Pyramid* that describes
    one way to organize all of your tests in a system: [https://martinfowler.com/articles/practical-test-pyramid.html](https://martinfowler.com/articles/practical-test-pyramid.html).'
  prefs: []
  type: TYPE_NORMAL
- en: Test-driven development
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: I have a confession to make. I usually write all my code in a test-driven style,
    where you write a test then make it fail for each step in the development process.
    Had we followed that process during the development of this book, we'd likely
    have quite a few tests – perhaps more than 100\. In addition, **test-driven development**
    (**TDD**) exerts a lot of pressure on the design that tends to lead to more loosely
    coupled code. So, why didn't we do this?
  prefs: []
  type: TYPE_NORMAL
- en: Well, TDD has its downsides, with perhaps the largest being we'd generate a
    lot more code in the form of tests. We've already written a *lot* of code in this
    book, so imagine trying to follow along with the tests too – you can see why I
    felt it was best to leave out the kind of testing I normally write. *Test-Driven
    Rust* isn't the title of this book after all. However, just because we didn't
    write tests first doesn't mean we don't want to be sure our code works. That's
    why, in many cases, we used the type system as the first line of defense against
    mistakes, such as using the typestate pattern for state transitions. The type
    system is one of the advantages of using Rust instead of JavaScript for this game.
  prefs: []
  type: TYPE_NORMAL
- en: This isn't to say that automated testing cannot provide value for our program.
    The Rust ecosystem places a high value on testing, so much so that a testing framework
    is built into Cargo and is automatically set up for any Rust program. With unit
    tests, we can test algorithms such as collision detection or our famous state
    machines. We can make sure that the game still does what we expect, although we
    can't test whether a game is fun or pretty. For that, you'll have to play the
    game until you hate it, but a game is a lot more fun if the basics work. We can
    use tests, along with types, to ensure the code works as expected so that we can
    turn our focus to whether or not it's fun. To do that, we'll need to set up the
    test runner and then write some tests that run outside of the browser and inside
    the browser.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: If you're interested in TDD, Kent Beck's book *Test-Driven Development By Example*
    is still an excellent resource ([https://amzn.to/3o1R663](https://amzn.to/3o1R663)).
    For a web-based approach that uses TypeScript and React, you can take a look at
    an excellent book called *Build Your Own Spreadsheet* at [https://buildyourownspreadsheet.com/](https://buildyourownspreadsheet.com/).
  prefs: []
  type: TYPE_NORMAL
- en: Getting started
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As we mentioned earlier, Rust has built-in capabilities for running tests –
    both unit and integration. Unfortunately, the template we used way back in [*Chapter
    1*](B17151_01_Final_PG_ePub.xhtml#_idTextAnchor015), *Hello WebAssembly*, still
    has an out-of-date setup at the time of writing. If it hasn''t been fixed, running
    `cargo test` at the command prompt will fail to compile, let alone run the tests.
    Fortunately, there are not a lot of mistakes. There''s just some out-of-date `async`
    code for a browser test we won''t be using in the automatically generated tests.
    Those tests are in the `tests` directory in the `app.rs` file. This is traditionally
    where integration tests are put in Cargo projects. We''ll change that setup shortly
    by using unit tests, but first, let''s get this to compile by deleting the incorrect
    `async_test` setup test. In `app.rs`, you can delete that function and the `#[wasm_bindgen_test(async)]`
    macro above it so that your `app.rs` file looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: After this book has been published, the template will be fixed and will likely
    compile. I'm going to assume this, regardless of you changing the code, so that
    it matches what is here going forward.
  prefs: []
  type: TYPE_NORMAL
- en: Some of the `use` declarations aren't needed anymore, but they will be short
    so you can leave them in and ignore the warnings. Now, `app.rs` contains two tests
    – one that will run in a JavaScript environment, such as the browser, and one
    that will run as a native Rust test. Both of these are just examples, where `1`
    is still equal to `1`. To run the native Rust tests, you can run `cargo test`,
    as you might be accustomed to. That will run the `rust_test` function, which is
    annotated with the `test` macro. You can run the browser-based tests, which are
    annotated with the `wasm_bindgen_test` macro, via the `wasm-pack test --headless
    --chrome` command. This will run the web tests using the Chrome browser, in a
    headless environment. You can also use `--firefox`, `--safari`, and `--node` if
    you wish, but you must specify what JavaScript environment you'll be running them
    in. Note that `--node` isn't going to work since it doesn't have a browser.
  prefs: []
  type: TYPE_NORMAL
- en: We'll start writing tests using the `#[test]` macro, which runs Rust code in
    the native environment, just like writing a standard Rust program. The simplest
    thing to test is a pure function, so let's try that.
  prefs: []
  type: TYPE_NORMAL
- en: Pure functions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '`#[test]` annotation and run with `cargo test`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The current setup runs our only Rust test in the `test/app.rs` file, which
    makes it, as far as Cargo is concerned, an integration test. I don''t like that
    and prefer to use the Rust convention of writing unit tests in the file where
    the code is executed. In this first example, we''ll test the `intersects` function
    on `Rect`, which is a pure function that is complicated enough to mess up. We''ll
    add this test to the bottom of `engine.rs` because that''s where `Rect` is defined,
    and we''ll run it with `cargo test`. Let''s add a test to the bottom of the module
    for the `intersect` method on `Rect`, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Much of this is documented in the Rust book at [https://bit.ly/3bNBH3H](https://bit.ly/3bNBH3H),
    but a little review never hurts anyone. We start by using the `#[cfg(test)]` attribute
    macro to tell Cargo not to compile and run this code except when we''re running
    tests. Then, we create a `tests` module using the `mod` keyword to isolate our
    tests from the rest of the code. After that, we import the `engine` code with
    `use super::*`. Then, we write our test by writing a function, `two_rects_that_intersect_on_the_left`,
    which is annotated with the `#[test]` macro so that the test runner can pick it
    up. The rest of this is a pretty standard test. It creates two rectangles, where
    the second overlaps the first, and then makes sure that the `intersects` function
    returns `true`. You can run this test with `cargo test`, where you''ll see the
    following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: You'll see two sets of results. The first result references our new test, `two_rects_that_intersect_on_the_left`,
    which will pass. Then, you will see `rust_test` run, which will also pass. The
    `rust_test` test is in `tests\app.rs` and was created with the project skeleton.
    It is run as an integration test because it is in the `tests` directory – this
    is the Cargo standard. The difference between unit tests and integration tests
    is that the integration tests are run as a separate crate and use the production
    code as a separate library. This means they use the code in the same way a user
    of your crate would, but they cannot call internal or private functions. It's
    easier to get complete coverage when you're running unit tests with the caveat
    that they may be less realistic. Our code is not meant to be used as a crate,
    so we won't be using many integration tests.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we''ve written our first unit test for our code, we can write a lot
    more tests for this `intersects` method, including when the following occurs:'
  prefs: []
  type: TYPE_NORMAL
- en: When the rectangles overlap on the top or bottom
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When the rectangles overlap on the right
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When the rectangles *don't* overlap – that is, when the function returns false
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We should have a test for every branch in the `intersects` function. We leave
    these tests as an exercise for you since repeating them would be redundant. As
    our code base grows, it would be ideal if much of our code could easily be tested
    like this, but unfortunately, for this game, a lot of it interacts with the browser,
    so we will have two different ways to test that. The first way is to replace the
    browser with a stub so that we don't need to run browser-based tests. We'll do
    that in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Hiding the Browser module
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Way back in [*Chapter 3*](B17151_03_Final_PG_ePub.xhtml#_idTextAnchor063), *Creating
    a Game Loop*, we separated browser functions into a `browser` module. We can use
    this as a **seam** to inject test versions of the browser functions that will
    run as native Rust code and allow us to write tests.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: The term **seam** comes from the book *Working Effectively with Legacy Code*,
    by Michael Feathers ([https://amzn.to/3kas1Fa](https://amzn.to/3kas1Fa)). It's
    written in C++ and Java but is still the best book on legacy code you can find.
    A seam is a place where you can insert test behavior to replace real behavior,
    while an **enabling point** is a point in the code that allows that to happen.
  prefs: []
  type: TYPE_NORMAL
- en: 'A seam is somewhere we can alter the behavior of the program without altering
    the code in that place. Look at the following code from the `game` module:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: We'd like to test that when the game goes from the `GameOver` state to the `Ready`
    state, the UI is hidden. We can do this with integration tests by checking whether
    the `div` property that contains the UI is empty after this transition. We may
    want to do this, but such tests are frequently a little harder to write and maintain.
    This is especially true as the game grows. Another approach, which we'll use here,
    is to replace the `browser` module with a version of it that doesn't interact
    with the browser. The seam is `hide_ui`, which is a behavior we can replace without
    actually changing the code, while the enabling point is the `use` declaration,
    which is where we brought in the `browser` module.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can enable using a test version of the `browser` module with conditional
    compilation. In the same way that the `#[cfg(test)]` macro only includes the `test`
    module when compiling in test mode, we can import different versions of the `browser`
    module with `cfg` directives, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The preceding code can be found at the top of the `game` module, where we were
    previously importing `crate::browser`. Here, we can use the `mod` keyword to bring
    the contents of the `test_browser` module in from the `src/game/test_browser.rs`
    file, but only when we're running a `test` build. Then, we can use `test_browser
    as browser` to make the functions available via `browser::` calls – again, only
    in test builds – in the same way as we call the `browser` production code. Finally,
    we can add the `#[cfg(not(test))]` annotation to `use crate::browser` to prevent
    the real `browser` code from being imported into the test.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: I first saw this technique on Klausi's Weblog at [https://bit.ly/3ENxhWQ](https://bit.ly/3ENxhWQ),
    but it is fairly common in Rust code.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you do this and run `cargo test`, you''ll see a lot of errors, such as ``
    cannot find function `fetch_json` in module `browser` ``, because even though
    we''re importing a test module, we haven''t filled it in with any code. In this
    situation, it''s a good idea to follow the compiler errors, which will point out
    that there''s no file yet in `src/game/test_browser.rs`. It will also list the
    functions that are used in the `game` module but aren''t defined in our `test_browser.rs`
    file. To get past this, you can create the `test_browser.rs` file and bring in
    the bare minimum that''s needed to get back to compiling, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see, only four functions are used in `game` that have been defined
    in `browser`, and we''ve filled in just enough to compile. To use this for testing,
    we''re going to need to place simulated implementations with some sort of state
    they keep track of. The other thing you may notice is that `JsValue` and `HtmlElement`
    are both being used in this code since they won''t work when you run Rust native
    tests. They require a browser runtime, so to continue along this path, we''ll
    eventually need to make test versions of `HtmlElement` and `JsValue` or create
    wrapper types for them, potentially in the `engine` module. Let''s leave those
    as is for now, though, and try to write our first test using the standard Rust
    testing framework. We''ll want to test the state machine change I mentioned previously
    by setting up the game in the `GameOver` state and transitioning to the `Running`
    state, then checking that the UI was hidden. The *beginning* of that test looks
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Oh boy – that's a lot of code to test a few lines of Rust, and it's not even
    a complete test yet. It's just setting up the game in the state that we need it
    to be in *before* we transition into a `Ready` state. A lot is being revealed
    about our design, specifically that it's what I may call *naïve'*. It's very hard
    to construct objects, and while the `game`, `engine`, and `browser` modules are
    separate, they are still pretty tightly coupled. It works but it in a fashion
    that only solves the problem in front of us. That's completely acceptable – we
    had specific goals to build a small endless runner and we did it, but this also
    means that if we wanted to start extending our game engine so that it's more flexible,
    we would need to make further changes. I tend to view software design more like
    sculpting than constructing. You start with a big block of code and chip away
    at it until it looks like what you want, rather than a blueprint that you follow
    to get the perfect house.
  prefs: []
  type: TYPE_NORMAL
- en: 'Some of the aspects of our design that this test is revealing are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: It's not easy to create new `Walk` structures.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `game` module is far more coupled to `web-sys` and `wasm-bindgen` than we
    thought.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We made the intentional choice not to try and create perfect abstractions early
    in the project. This is one of the reasons we didn't write this code in a test-driven
    style initially. TDD would have strongly pushed in the direction of further abstraction
    and layering, which would have hidden the game code we're trying to learn here.
    As an example, instead of using `HtmlImageElement` or `AudioBuffer`, we may have
    written wrappers or abstractions around those objects (we already have an `Image`
    struct), which is probably better for growing our project in the medium to long
    term but is harder to understand in the short term.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is a long-winded way of saying that this code is now hard to write isolated
    unit tests for because we didn''t build it with them in mind. If you were able
    to run this test, you would see the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: It turns out that even though we replaced the production `browser` with `test_browser`,
    we're still trying to call browser code. I have already pointed out `HtmlElement`
    and `JsValue`, but this test also includes `AudioBuffer` and `AudioBufferOptions`.
    As is, this code doesn't compile without more feature flags being enabled and
    changes being made to `engine`. It's just too tightly coupled to the browser still.
  prefs: []
  type: TYPE_NORMAL
- en: The act of trying to use this code in a test harness demonstrated the power
    of coupling, and it is often useful to take legacy code and get it into a harness
    to identify these dependency problems and break them. Unfortunately, this is a
    time-consuming process that we are not going to continue using in this section,
    although it may appear on my blog at [paytonrules.com](http://paytonrules.com)
    at some point. Instead, we'll test this code via a test that runs in the browser.
  prefs: []
  type: TYPE_NORMAL
- en: Browser tests
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: At the beginning of this chapter, I mentioned that there were **unit tests**
    and **browser tests**. The distinction is that while browser tests may test the
    same behavior as a unit test, they automate the desired behavior in a headless
    browser. This makes the test more realistic, but also slower and more prone to
    breaking for flaky reasons. I prefer my systems to have a large base of unit tests
    and a smaller number of more integrated tests to make sure everything is all wired
    together correctly, but we can't always get what we want.
  prefs: []
  type: TYPE_NORMAL
- en: 'Instead, we''ll get what we need – verification of the behavior – by skipping
    dependency-breaking techniques for legacy code and writing a test that runs in
    the browser. We''ll remove the code that added the `test_browser` module, as well
    as the `test_browser` file itself. We''ll keep the test we wrote previously and
    make two changes for it to compile, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Add `AudioBufferOptions` to the list of `web-sys` features in `Cargo.toml`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the `engine` module, make the `buffer` field on the `Sound` struct public
    so that we can create `Sound` directly in this test.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'These two changes will get the code compiling, but it won''t make it run in
    the tests yet. For that, we need to make a couple of changes. First, we need to
    change the `#[test]` macro to `#[wasm_bindgen_test]`. Then, we need to add two
    statements to our `test` module, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'The first line to add is `use wasm_bindgen_test::wasm_bindgen_test` so that
    the macro is present. The second is `wasm_bindgen_test::wasm_bindgen_test_configure!(run_in_browser);`.
    This directive tells the test runner to run in the browser so that the code can
    interact with the DOM, similar to how the application does. This test won''t run
    in `cargo test`, so you''ll need to use the `wasm-pack test --headless –chrome`
    command. This will run the web tests in a headless version of the Chrome browser.
    When you run them, you should see the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we have a test that''s running and passing, but the only problem is that
    we don''t have any assertions. We''ve written an "arrange" step but we haven''t
    checked the results. The point of this test was to make sure that the UI was hidden
    when the state transition happened, so we''ll need to update the test to check
    that. We can do this by adding the action and assertion steps, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we start the test by inserting the `div` property, along with the `ui`
    ID, into the document – after all, that is in `index.html` in the game. Then,
    `browser::draw_ui` draws the UI to the browser, even though the browser is running
    headlessly, so we don''t see it. We continue by creating `WalkTheDogState` in
    the `GameOver` state; on the next line, we have it transition to `Ready` via the
    `state.new_game()` method. Finally, we check that the UI was cleared by finding
    the `div` property and checking its `child_element_count`. If it''s `0`, the code
    is right, and this test will pass. If you run this test, you''ll see that this
    test *does* pass, so you will probably want to comment out the `let next_state:
    WalkTheDogState<Ready> = state.``()` line and run it again just to make sure it
    fails when the transition happens.'
  prefs: []
  type: TYPE_NORMAL
- en: This is still a very long test but at least it's working. The test can be cleaned
    up by creating some factory methods in the various modules so that structs are
    easier to create. You'll notice that the test is full of `unwrap` calls. This
    is because, in a test, I want things to crash right away if they aren't as expected.
    Unfortunately, browser-based tests with the `wasm_bindgen_test` macro do not let
    you return a `Result` for readability as standard Rust tests do yet. This is another
    reason you should try and make your tests run as native Rust tests.
  prefs: []
  type: TYPE_NORMAL
- en: Async tests
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One of the biggest challenges of testing web applications, whether they're Wasm
    or traditional JavaScript ones, is code that occurs `async` block or function.
    Imagine calling a function in an `async` test and then immediately trying to verify
    it worked. By definition, you can't, because it's running asynchronously and may
    not have finished yet. Fortunately, `wasm_bindgen_test` handles this rather easily
    by making the test's functions `async` themselves.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s look at a simpler example and try to write a test for the `load_json`
    function in the `browser` module:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'This can be found in the `browser` module. Here, we start with the boilerplate
    to set up a `tests` module, import both `browser` and `wasm_bindgen_test`, and
    configure the test to run in the browser. The test itself is only two lines. Try
    to load a `JSON` file that doesn''t exist and report an error. The key difference
    between this is that the test is `async`, which allows us to use `await` in the
    test and write the assertion without adding any "wait for" logic. This is great,
    but there are a couple of things to keep in mind:'
  prefs: []
  type: TYPE_NORMAL
- en: If `fetch_json` can hang, this test will hang.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This test will try to load a file. Ideally, we don't want to do this in a unit
    test.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This test will run and pass. We could test all of the `browser` functions this
    way, accepting that the `browser` module's tests will use the filesystem as needed.
    That's probably what I would do if I was handed this system in a professional
    environment. You could work very hard to stub out the actual browser on these
    tests, but to do so would remove its ability to prevent defects. After all, if
    you remove the browser from the `browser` module, then how do you know you got
    the code right?
  prefs: []
  type: TYPE_NORMAL
- en: 'If I was given this code and asked to maintain it, I would likely adopt the
    following strategies:'
  prefs: []
  type: TYPE_NORMAL
- en: Curse the name of the jerk who wrote it without tests (me!).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Write tests for code as I need to change it. If it doesn't change, don't bother.
    Go ahead and use browser automation, as we did previously.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Over time, move more code that depends on `wasm-bindgen` and `web-sys` into
    the `browser` module so that `engine` and `game` can stub it out.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Write as many tests as possible as Rust-native tests, and then make the browser-based
    unit tests native whenever possible.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As for integration tests, I doubt I would write any integration tests in the
    Cargo sense. For Cargo libraries, all the integration tests are written in the
    `tests` directory and compiled as a separate package. This is a great idea when
    you're writing a library that's going to be consumed by other people, but we are
    writing an application and aren't providing an API. The integration tests I would
    write would be any tests that use the real browser, but those are integration
    tests in the sense that they are integrated with the web browser, not that they
    run as Rust integration tests.
  prefs: []
  type: TYPE_NORMAL
- en: However, we can't just rely on adding tests to make sure our code works. Sometimes,
    we just have to debug it. Let's dig into that next.
  prefs: []
  type: TYPE_NORMAL
- en: Debugging the game
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To debug a traditional program, be it in Java, C#, or C++, we must set breakpoints
    and step through the code. In JavaScript, we can type the word `debugger` to set
    a breakpoint, but although WebAssembly runs in the browser, it isn't JavaScript.
    So, how do we debug it?
  prefs: []
  type: TYPE_NORMAL
- en: There's a lot of conflicting information about debugging with WebAssembly. How
    do you debug WebAssembly? Well, according to the official Rust WebAssembly documentation,
    it's simple – you can't!
  prefs: []
  type: TYPE_NORMAL
- en: Unfortunately, the debugging story for WebAssembly is still immature. On most
    Unix systems, DWARF is used to encode the information that a debugger needs to
    provide source-level inspection of a running program. There is an alternative
    format that encodes similar information on Windows. Currently, there is no equivalent
    for WebAssembly. Therefore, debuggers currently provide limited utility, and we
    end up stepping through raw WebAssembly instructions emitted by the compiler,
    rather than the Rust source text we authored.
  prefs: []
  type: TYPE_NORMAL
- en: – [https://rustwasm.github.io/docs/book/reference/debugging.html](https://rustwasm.github.io/docs/book/reference/debugging.html)
  prefs: []
  type: TYPE_NORMAL
- en: So, there you have it – no debugging, section over. That was easy.
  prefs: []
  type: TYPE_NORMAL
- en: But it's not that simple. Of course, you can debug your application – you just
    can't use your browser's developer tools to step through the Rust code in a debugger.
    The technology isn't there yet. But that doesn't mean we don't debug; it just
    means we'll take more of an old-school approach to debugging.
  prefs: []
  type: TYPE_NORMAL
- en: Earlier, I mentioned that when I write code, I typically write a lot of tests.
    I also typically don't use a debugger very often. If we break our code into smaller
    chunks that can be easily exercised by tests, a debugger is rarely required. That
    said, we didn't do that for this project, so we'll need a way to debug existing
    code. We'll start by logging, then getting stack traces, and finally using linters
    to prevent bugs before they happen.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: 'The reality is not as cut and dry as the Rust Wasm site would state. Chrome
    developer tools have added support for the `wasm-bindgen` at the time of writing.
    You can see progress on this issue here: [https://github.com/rustwasm/wasm-bindgen/issues/2389](https://github.com/rustwasm/wasm-bindgen/issues/2389).
    By the time you read this book, the debugging tools may be modernized in Rust
    Wasm, as well as in browsers outside of Chrome, but for the time being, we must
    use more traditional tools such as `println!` and logging.'
  prefs: []
  type: TYPE_NORMAL
- en: Log versus error versus panic
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'If you''ve been following along and got confused at some point, then you''ve
    probably used the `log!` macro we wrote in [*Chapter 3*](B17151_03_Final_PG_ePub.xhtml#_idTextAnchor063),
    *Creating a Game Loop*, to see what was going on. If you have been doing that,
    congratulations! You''ve been debugging the same way I did when I wrote the code
    originally. Print line debugging is still standard in many languages and it''s
    pretty much the only form of debugging that''s guaranteed to work anywhere. If
    you haven''t done that, then it looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding example, we are logging `KeyState` on every tick through the
    `update` function. This isn''t a great log because it''s going to show an empty
    `KeyState` 60 times a second, but it''s good enough for our purposes. However,
    there''s one flaw in this log: `KeyState` doesn''t implement the `Debug` trait.
    You can add it by adding the `derive(Debug)` annotation to the `KeyState` struct,
    like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'When you add this, the console will log all your key state changes, which will
    be useful if your keyboard input is broken:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.1 – Logging KeyState](img/Figure_9.01_B17151.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.1 – Logging KeyState
  prefs: []
  type: TYPE_NORMAL
- en: 'In general, any `pub struct` should `use` `#[derive(Debug)]`, but this isn''t
    the default option since it could make compile times long on large projects. When
    in doubt, go ahead and `use` `#[derive(Debug)]` and log the information. Now,
    maybe `log!` isn''t noticeable enough for you, and you want the text to be bright,
    obvious, and red. For that, you''ll need to use `console.error` in JavaScript
    and write a macro such as the `log` macro, which we already have in the `browser`
    module. This macro looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'This is the same as the `log` macro but uses the `error` function on the `console`
    object. There are two advantages to the `error` function. The first is that it''s
    red, while the other is that it also will show you the stack trace. Here''s an
    example of `error` being called when the player is knocked out in Chrome:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.2 – Error log](img/Figure_9.02_B17151.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.2 – Error log
  prefs: []
  type: TYPE_NORMAL
- en: It's not the most readable stack trace in the world, but after seeing a few
    lines of the `console::error_1` function, you can see that this log was called
    from `WalkTheDogState<Walking>::end_game`. This log is really for true errors,
    as opposed to just informational logging, and this stack trace may not show up
    clearly in all browsers. You'll also want to be cautious with leaving this log
    in the production code as you may not want to expose this much information to
    a curious player. We'll want to make sure it's not in the production deployment,
    which we'll create in [*Chapter 10*](B17151_10_Final_PG_ePub.xhtml#_idTextAnchor226),
    *Continuous Deployment*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, if you want to make sure the program stops when an error occurs, we''ll
    want to go ahead and use the `panic`! macro. Some errors are recoverable but many
    are not, and we don''t want our program to limp along in a broken state. In [*Chapter
    1*](B17151_01_Final_PG_ePub.xhtml#_idTextAnchor015), *Hello WebAssembly*, we included
    the `console-error-panic-hook` crate so that if the program were to panic, we''d
    get a stack trace. Let''s replace calling `error`! with calling `panic`! and see
    the difference:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.3 – Panic log'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_9.03_B17151.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 9.3 – Panic log
  prefs: []
  type: TYPE_NORMAL
- en: Here, you can see it looks a little different, but the information is mostly
    the same. There is one thing at the very top where it says `src/game.rs:829`,
    which tells you exactly where `panic` was called. In general, you will probably
    prefer to use `panic` compared to `error` if you need to have the error in your
    production code because that kind of error should be rare and fail fast. The `error`
    function is more useful during debugging, so you'll end up removing those.
  prefs: []
  type: TYPE_NORMAL
- en: There's another kind of error that we've been ignoring at times, and that's
    the warnings and errors that are given to you by the compiler and linter. We can
    use the Rust ecosystem's tools to detect mistakes before we ever run the program.
    Let's look into that now.
  prefs: []
  type: TYPE_NORMAL
- en: Linting and Clippy
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'One of the features that makes the Rust compiler great is that it has a linter
    built into it, in addition to the warnings and errors it already provides. If
    you''re unfamiliar, a linter is a static code analysis tool that typically finds
    style errors and, potentially, logic errors above and beyond what the compiler
    can find. The term comes from the lint you find on clothing, so you can think
    of using a linter like rubbing a lint brush on your code. We''ve been getting
    some warnings from the compiler that we''ve been ignoring for a while now, most
    of which look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'These are all cases where an error could occur, but we probably don''t want
    to crash if it does, so panicking or calling `unwrap` isn''t an option. Propagating
    the `Result` type is an option, but I don''t think we want to prevent moving from
    one state to another if there''s a small browser issue. So, instead, we''ll use
    the `error` case to log here. You can see it at `https://bit.ly/3q1936N` in the
    sample source code. Let''s modify the code so that we log any errors:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we have changed the `browser::hide_ui()` line to `if let Err(err) = browser::hide_ui()`
    and we log if an error occurs. We can see what that error log will look like by
    forcing `hide_ui` to return an error for a moment:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.4 – A fake error'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_9.04_B17151.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 9.4 – A fake error
  prefs: []
  type: TYPE_NORMAL
- en: The stack trace is cut off in book form, but you can see that we got an error
    log with `Error hiding the browser` and then `This is the error in the hide_ui
    function`, which is the error message I forced into `hide_ui`. The stack trace
    also shows `game::Ready`, which would show you that you were transitioning into
    the `Ready` state if you had infinite room to show the entire message.
  prefs: []
  type: TYPE_NORMAL
- en: Every single warning that's being generated should be dealt with. Most of the
    warnings are the same kind – that is, `Result` types where the `Err` variant is
    ignored. These can be removed by handling the `Err` case with a log or by calling
    `panic` if the game should truly crash at this time. For the most part, I've used
    the `if let` pattern but if `request_animation_frame` fails, then I just use `unwrap`.
    I don't see how the game could work if that's failing.
  prefs: []
  type: TYPE_NORMAL
- en: 'There is one more warning we''ve been ignoring that we should address, as shown
    here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'This warning is a little unique because we used this function *for debugging*.
    You may not want to draw rectangles in your game, but it''s essential for debugging
    collision boxes, as we did in [*Chapter 5*](B17151_05_Final_PG_ePub.xhtml#_idTextAnchor114),
    *Collision Detection*, so we''ll want it to be available. To keep it around, let''s
    annotate it with the `allow` keyword, like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'This should leave the compilation error-free, but there''s one more tool we
    can use to see whether our code could be improved. If you''ve spent much time
    in the Rust ecosystem, then you''ve probably heard of `Cargo.toml` file but to
    the current system itself. Installation is simple, and you may have done it at
    some point and forgotten about it, but if you haven''t, it''s one shell command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Once you've installed Clippy, you can run `cargo clippy` and see all the other
    ways we wrote bad Rust code.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: When the code is great, I wrote it and you followed along. When it's bad, we
    did it together. I don't make the rules.
  prefs: []
  type: TYPE_NORMAL
- en: 'When I run `cargo clippy`, I get `17` warnings, but your number could be different,
    depending on when you run it. I''m not going to go through each one, but let''s
    highlight one error:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'The `rightmost` function in the `game` module can be made to use one less reference
    and be made more flexible. `help` here is great because it tells me exactly what
    to do to fix it. So, let''s change the `rightmost` function signature so that
    it looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: This doesn't fix any bugs but it does remove a Clippy warning and makes the
    method more flexible.
  prefs: []
  type: TYPE_NORMAL
- en: 'It''s very common for Clippy to inform you of better idioms you could be using.
    One Clippy warning I wanted to highlight looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'I had this error occur quite a bit in earlier versions of the code. I wasn''t
    aware that the `matches!` macro existed before I ran Clippy, but what it does
    is handle the exact case where you need to check whether an `enum` is a specific
    case you''re looking for. That''s why the code now uses what Clippy suggests,
    which is in `impl` `RedHatBoyStateMachine`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: Tip
  prefs: []
  type: TYPE_NORMAL
- en: Many editors make it very easy to enable Clippy as part of syntax checking so
    that you don't need to run it explicitly. If you can enable it, you should do
    so.
  prefs: []
  type: TYPE_NORMAL
- en: Many of the other errors are about overusing `clone` and using `into` when it
    isn't necessary. I highly recommend going through the code and fixing those, taking
    another moment to understand why they were flagged. In [*Chapter 10*](B17151_10_Final_PG_ePub.xhtml#_idTextAnchor226),
    *Continuous Deployment*, we'll add Clippy to our build process so that we don't
    have to keep putting up with these errors.
  prefs: []
  type: TYPE_NORMAL
- en: At this point, the code has been tested (a little) and we've handled every compiler
    error and warning we can think of. It's safe to say that the game works, but is
    it fast enough? The next thing to check is its performance. So, let's do that
    now.
  prefs: []
  type: TYPE_NORMAL
- en: Measuring performance with a browser
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The first step in debugging performance is answering the question, *Do you have
    a performance problem?* Too many developers, especially game developers, worry
    too early about performance and introduce complex code for a performance gain
    that just isn't there.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, do you know why so much of this code uses `i16` and `f16`? Well,
    when I was going back to school a few years ago, I took a game optimization class
    in C++, where our final project needed to optimize a particle system. The biggest
    performance gains were to convert 32-bit integers into 16-bit integers. As my
    professor would say, "*We got to the moon on 16-bit!*" So, when I was writing
    this code, I internalized the lesson and made the variables 16-bit unless they
    were being sent to JavaScript, where everything is 32-bit anyway. Well, allow
    me to quote directly from the WebAssembly specification (found at [https://webassembly.github.io/spec/core/syntax/types.html](https://webassembly.github.io/spec/core/syntax/types.html)):'
  prefs: []
  type: TYPE_NORMAL
- en: Number types classify numeric values.
  prefs: []
  type: TYPE_NORMAL
- en: The *i32* and *i64* types classify 32- and 64-bit integers, respectively. Integers
    are not inherently signed or unsigned; their interpretation is determined by individual
    operations.
  prefs: []
  type: TYPE_NORMAL
- en: The *f32* and *f64* types classify 32- and 64-bit floating-point data, respectively.
    They correspond to the respective binary floating-point representations, also
    known as single and double precision, as defined by the IEEE 754-2019 standard
    (Section 3.3).
  prefs: []
  type: TYPE_NORMAL
- en: 'It turns out that WebAssembly doesn''t support a 16-bit numeric value, so all
    of the optimization to `i16` is pointless. It''s not harming anything and it''s
    not worth going back to change it, but it reinforces the first rule of optimization:
    **measure first**. With that in mind, let''s investigate two different ways to
    measure the performance of our game.'
  prefs: []
  type: TYPE_NORMAL
- en: Frame rate counter
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There are two ways our game can perform poorly: by using too much memory and
    slowing the frame rate. The second of those is far more important, especially
    for a small game like this, so we''ll want to start looking at frame rate first.
    If the frame rate consistently lags, our game loop will account for it as best
    it can, but the game will look jittery and respond poorly. So, we need to know
    the current frame rate, and the best way to do that is to draw it on the screen.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ll start by adding a function, `draw_text`, that will draw arbitrary text
    on the screen. This is debug text, so similarly to the `draw_rect` function, we''ll
    need to disable the warning that says the code is unused. Writing text is a function
    of `Renderer` in the `engine` module, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: We've hardcoded the font here because this is for debugging purposes only, so
    it's not worth customizing. Now, we need to add a frame rate calculator to the
    game loop, which is in the `start` method of `GameLoop` in the `engine` module.
    You can refresh your memory on how it works by reviewing [*Chapter 3*](B17151_03_Final_PG_ePub.xhtml#_idTextAnchor063),
    *Creating a Game Loop*. The frame rate can be calculated by taking the difference
    between the last two frames, dividing by 1,000, to get from milliseconds to seconds,
    and calculating its inverse (which is 1 divided by the number). This is simple
    but it will lead to the frame rate fluctuating wildly on screen and won't show
    very useful information. What we can do instead is update the frame rate every
    second so that we can get a fairly stable indicator of performance on screen.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s add that code to the `engine` module. We''ll start with a standalone
    function that will calculate the frame rate every second in the `start` method,
    as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: Oh no – it's an `unsafe` function! It's the first one in this book, and probably
    the last. We're using an `unsafe` function here because of the `static mut` variables
    – that is, `FRAMES_COUNTED`, `TOTAL_FRAME_TIME`, and `FRAME_RATE` – which are
    not safe in a multithreaded environment. We know that this function won't be called
    in a multithreaded way, and we also know that if it was called, it would just
    show a weird frame rate value. It's not something I generally recommend, but in
    this case, we don't want to pollute `GameLoop` or the `engine` module with those
    values or put them in thread-safe types. After all, we wouldn't want to have our
    frame rate calculator take too long because of a bunch of `Mutex` lock calls.
    So, we'll accept that this debugging function is `unsafe`, shiver in fear for
    a moment, and move on.
  prefs: []
  type: TYPE_NORMAL
- en: The function starts by setting up the initial `FRAMES_COUNTED`, `TOTAL_FRAME_TIME`,
    and `FRAME_RATE` values. On each call to `draw_frame_rate`, we update `TOTAL_FRAME_TIME`
    and the number of `FRAMES_COUNTED`. When `TOTAL_FRAME_TIME` has passed `1000`,
    this means that 1 second has elapsed, since `TOTAL_FRAME_TIME` is in milliseconds.
    We can set `FRAME_RATE` to the number of `FRAMES_COUNTED` because that's the literal
    `draw_text` function we just created. This function is going to be called last
    on every frame, which is important because if it isn't, we would draw the game
    right over the top of the frame rate. If we didn't draw the frame rate on every
    frame, we also wouldn't see it except for brief flickers on the screen, which
    is hardly suitable for debugging.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s add the call to `GameLoop`, in the `start` function, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'The `game_loop.accumlated_delta` line has changed slightly, pulling the calculation
    for the length of the frame into a temporary variable, `frame_time`. Then, after
    drawing, we check whether we are in debug/development mode through the check for
    `if cfg!(debug_assertions)`. This will ensure that this doesn''t show up in the
    deployed code. If we are in debug mode, we call `draw_frame_rate` inside an `unsafe`
    block. We send that function `renderer` and `frame_time`, which we just pulled
    into a temporary variable. Adding this code gives us a clear measurement of the
    frame rate on the screen:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.5 – Showing the frame rate](img/Figure_9.05_B17151.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.5 – Showing the frame rate
  prefs: []
  type: TYPE_NORMAL
- en: On my machine, the frame rate is a steady `60`, with an occasional blip that
    isn't consistent. That's great unless you're writing a chapter on debugging performance
    issues. Then, you may have a problem.
  prefs: []
  type: TYPE_NORMAL
- en: 'Fortunately, in early drafts, there was one time when the frame rate dropped,
    and that was when the RHB crashed into a rock. When the `index.html`. In other
    words, we must delete the highlighted code in `index.html`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: If you delete the preloaded assets, you should see the see frame rate dip briefly.
    Displaying the frame rate is a great way to make sure that you, as a developer,
    see performance issues right away. If the frame rate dips, then you've got a problem,
    just like we have when we don't preload the assets. Sometimes, we need more than
    just a frame rate counter. So, let's leave the preload code deleted and see the
    performance problem in the browser debugger.
  prefs: []
  type: TYPE_NORMAL
- en: Browser debugger
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Every modern browser has developer tools, but I''ll be using Chrome for this
    section as it''s the one most popular with developers. In general, they all look
    similar to each other. To get performance information, I must start the game and
    open the developer tools in Chrome. Then, I must right-click and click **Inspect**,
    though there are plenty of other ways to open the tools. From there, I must click
    the **Performance** tab and start recording. Then, I must run RHB into a rock
    and stop recording. Since I know I''ve got a specific spot with a performance
    dip, I want to get to it as quickly as possible to hide any noise in the debugger
    from other code. After I do that, I will see a graph, like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.6 – The Performance tab](img/Figure_9.06_B17151.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.6 – The Performance tab
  prefs: []
  type: TYPE_NORMAL
- en: 'That''s a lot of noise, but you can see that the graph changes. There''s a
    pink blob on the **Frames** row, which shows that something happened there. I
    can select the section that looks like a hill with my cursor and drag it to zoom
    in on it. Now, I will see the following screen:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.7 – Dropped frames](img/Figure_9.07_B17151.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.7 – Dropped frames
  prefs: []
  type: TYPE_NORMAL
- en: Here, you can see that one frame was **115.8 ms**. I opened the **Frames** section
    (see how the gray arrow next to **Frames** points down) to see what was drawn
    on those frames – our poor knocked-out RHB. A frame that's 115.8 ms is way too
    long, and if you hover your mouse over that, it will show you **dropped frames**.
    Beneath the **Frames** section, there's the **Main** section, which shows what
    the application was doing. I've highlighted **Recalculate Style** here, which
    is taking **33.55 ms** according to the **ToolTip** window, which shows up after
    I roll my mouse over it.
  prefs: []
  type: TYPE_NORMAL
- en: '`index.html` file, which should speed up recalculating the layout. If you do
    that and remeasure your performance, you''ll see something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.8 – No dropped frames!'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_9.08_B17151.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 9.8 – No dropped frames!
  prefs: []
  type: TYPE_NORMAL
- en: 'Was this worth worrying about? Possibly – it is noticeable to see the button
    load, but it''s not worth extending this chapter to fix it. You know how to fix
    it, and you know how to find the issue in the **Performance** tab, and that''s
    what''s important for now. Anyway, we have another question to answer: how much
    memory is this game taking up?'
  prefs: []
  type: TYPE_NORMAL
- en: Checking memory
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When I was writing this game, I would frequently leave it running all day in
    the background, only to have my browser become very unresponsive as it started
    taking up all my computer's memory. I began to suspect that the game had a memory
    leak, so I started investigating. You may think it's impossible to have a memory
    leak in Rust due to its guarantees, and it is harder, but remember that a lot
    of our code talks to JavaScript, where we don't necessarily have the same guarantees.
    Fortunately, we can check this with the same tools we have been using to test
    performance.
  prefs: []
  type: TYPE_NORMAL
- en: 'Go ahead and clear the performance data by clicking **no sign** in the top-left
    corner. Then, start another recording and play for a little while. This time,
    don''t try to die right away; go ahead and let the game play for a bit. Then,
    stop recording and look at the performance data again, this time ensuring you
    click the **Memory** button. Now, you can a look at the results, which may look
    like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.9 – Memory profiling'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_9.09_B17151.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 9.9 – Memory profiling
  prefs: []
  type: TYPE_NORMAL
- en: Can you see that blue wave at the bottom of the screen, which shows **HEAP**
    in the bottom right-hand corner? This shows that our memory grows and then is
    periodically reclaimed. This may not be ideal as we'd like memory to be constant,
    but we aren't trying to control things to that degree at this time. Chrome, and
    most browsers, run their garbage collectors in separate threads so that they won't
    affect performance as much as you may think. It would be worth experimenting and
    creating a memory budget in the application and keeping all the allocations in
    that budget, but that's outside the scope of this book. Fortunately, the memory
    is reclaimed and it doesn't look like the game is growing uncontrollably.
  prefs: []
  type: TYPE_NORMAL
- en: After further investigation, it turned out that the problem with my browser
    was caused by my company's bug tracker, which uses far more memory than this little
    game! If you're seeing performance issues, make sure you account for other tabs,
    browser extensions, and anything else that might be slowing down your computer
    outside of the game.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter was a little different than the previous ones because, in many
    ways, our game is complete! But of course, it's not perfect, which is why we spent
    some time looking at ways we can investigate defects and bullet-proof the code
    base.
  prefs: []
  type: TYPE_NORMAL
- en: We dug into automated testing, writing unit tests for our transitions, and writing
    integration tests that run in the browser. We now have logging for any unforeseen
    errors and stack traces if the code crashes, both of which are necessary diagnostics
    for debugging challenging errors. Then, we used the linter and Clippy to clean
    up our code and remove subtle issues that the compiler can't catch. Finally, we
    investigated performance issues in the browser and found that we had none!
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we'll get those tests into a CI/CD setup and even deploy
    them to production. What are we waiting for? Let's ship this thing!
  prefs: []
  type: TYPE_NORMAL
