<html><head></head><body><div class="chapter" title="Chapter&#xA0;8.&#xA0;Concurrency and Parallelism"><div class="titlepage" id="aid-1TVKI2"><div><div><h1 class="title"><a id="ch08"/>Chapter 8. Concurrency and Parallelism</h1></div></div></div><p>As a modern systems-level programming language, Rust has to have a good story for executing code concurrently and parallely on many processors simultaneously. And indeed, it does; Rust provides a wide selection of concurrency and parallel tools. Its type system is strong enough to write concurrent primitives that have properties unlike anything that existed before. Particularly, it can encode a wide selection of memory safe parallel abstractions that are also guaranteed to be data-race free while not employing a garbage collector. This is mind blowing as no other language can do this. All these features are not ingrained in the language itself, but they are provided by libraries, so improved or new versions can always be built. Developers should choose the tool that is right for the job at hand, or they can improve on or develop new tools.</p><p>We will discuss the following topics in this chapter:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Concurrency and threads</li><li class="listitem">Shared mutable state</li><li class="listitem">Communication through channels</li><li class="listitem">Synchronous and asynchronous communication</li></ul></div><div class="section" title="Concurrency and threads"><div class="titlepage"><div><div><h1 class="title"><a id="ch08lvl1sec59"/>Concurrency and threads</h1></div></div></div><p>A system is concurrent<a id="id267" class="indexterm"/> when several computations are being executed at the same time and are potentially interacting with each other. The computations can only run in parallel (that is, simultaneously) when they are being executed on different cores or processors.</p><p>An executing Rust program consists<a id="id268" class="indexterm"/> of a collection of native operating system (OS) threads; the OS is also responsible for their scheduling. The unit of computation in Rust is called a <code class="literal">thread</code>, which is a type that is defined in the <code class="literal">std::thread</code> module. Each thread has its own stack and local state.</p><p>Until now, our Rust programs only had one thread, the <code class="literal">main</code> thread, corresponding with the execution of the <code class="literal">main()</code> function. However, a Rust program can create lots of threads to work simultaneously when this is needed. Each thread (not only <code class="literal">main()</code>) can act as a parent and generate any number of child threads.</p><p>The following action can be done on the data:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">It can be shared across threads (refer to the <span class="emphasis"><em>Shared mutable state through atomic types</em></span> section)</li><li class="listitem">It can be sent between threads (refer to the <span class="emphasis"><em>Communication through channels</em></span> section)</li></ul></div><div class="section" title="Creating threads"><div class="titlepage"><div><div><h2 class="title"><a id="ch08lvl2sec36"/>Creating threads</h2></div></div></div><p>A <code class="literal">thread</code> can be <a id="id269" class="indexterm"/>created by spawning it; this creates an independent detached child thread that can generally outlive its parent. This is demonstrated in the following code snippet:</p><div class="informalexample"><pre class="programlisting">// code from Chapter 8/code/thread_spawn.rs:
<span class="strong"><strong>use std::thread;</strong></span>
fn main() {
<span class="strong"><strong>    thread::spawn(move || {</strong></span>
<span class="strong"><strong>    println!("Hello from the goblin in the spawned thread!");</strong></span>
<span class="strong"><strong>    });</strong></span>
}</pre></div><p>The <code class="literal">spawn</code> argument is a closure (here without parameters, so <code class="literal">||</code>), which is scheduled to execute independently from the parent (here, this is the <code class="literal">main()</code>) thread. Note that this is a moving closure, which takes ownership of the variables in context. Our closure here is a simple print statement, but in a real example, this could be replaced by a heavy and/or time-consuming operation.</p><p>However, when we execute this code, we normally don't see any output; why does this happen? It turns out that <code class="literal">main()</code> is a bad parent (as far as threading is concerned) and doesn't wait for its children to end properly; when the end of <code class="literal">main()</code> shuts down the program, it terminates other threads even if they are still running. The output of the spawned thread becomes visible if we let <code class="literal">main()</code> pause for a brief moment before it terminates. This can be done with the <code class="literal">thread::sleep_ms</code> method, which takes an unsigned 32-bit integer in milliseconds:</p><div class="informalexample"><pre class="programlisting">  fn main() {
    thread::spawn(move || { …  });
<span class="strong"><strong>    thread::sleep_ms(50);</strong></span>
}</pre></div><p>This now prints out: <code class="literal">Hello from the goblin in the spawned thread!</code>.</p><p>In general, this period of pause is not needed; children threads that are spawned can live longer than their parent thread and continue to execute when their parent has already stopped.</p><p>A better practice <a id="id270" class="indexterm"/>in this case, however, is to capture the join handle that <code class="literal">spawn</code> returns in a variable. Calling the <code class="literal">join()</code> method on <code class="literal">handle</code> will block the parent thread and make it wait until the child thread has finished its execution. It returns a <code class="literal">Result</code> instance; <code class="literal">unwrap()</code> will take the value from <code class="literal">Ok</code> and return the result of the child thread (which is <code class="literal">()</code> in this case because it is a print statement) or panic in the <code class="literal">Err</code> case:</p><div class="informalexample"><pre class="programlisting">fn main() {
<span class="strong"><strong>  let handle = thread::spawn(move || {</strong></span>
        println!("Hello from the goblin in the spawned thread!");
<span class="strong"><strong>  });</strong></span>
// do other work in the meantime
<span class="strong"><strong>  let output = handle.join().unwrap();</strong></span>
  println!("{:?}", output); // ()
}</pre></div><p>If no other work has to be done while the child thread is executing, we can also write this:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>thread::spawn(move || { </strong></span>
<span class="strong"><strong>// work done in child thread </strong></span>
<span class="strong"><strong>}).join();</strong></span>
</pre></div><p>In this case, we are waiting synchronously for the child thread to finish, so there is no good reason to start a new thread.</p></div><div class="section" title="Starting a number of threads"><div class="titlepage"><div><div><h2 class="title"><a id="ch08lvl2sec37"/>Starting a number of threads</h2></div></div></div><p>Each thread has its <a id="id271" class="indexterm"/>own stack and local state, and by default, no data is shared between threads unless it is immutable data. Generating threads is a very lightweight process since starting tens of thousands of threads only takes a few seconds. The following program does just that and prints out the numbers from 0 to 9,999:</p><div class="informalexample"><pre class="programlisting">// code from Chapter 8/code/many_threads.rs:	
use std::thread;
static NTHREADS: i32 = 10000;
fn main() {
    for i in 0..NTHREADS {
        let _ = thread::spawn(move || {
            println!("this is thread number {}", i)
        });
    }
}</pre></div><p>Since the numbers are printed in independent threads, the order is not preserved in the output; so, for example, it could start with:</p><div class="informalexample"><pre class="programlisting">this is thread number 1
this is thread number 3
this is thread number 4
this is thread number 2
this is thread number 6
this is thread number 5
this is thread number 0
…</pre></div><p>A question that often <a id="id272" class="indexterm"/>arises is: how many threads do I have to spawn? The basic rule is that CPU-intensive tasks have the same number of threads as CPU cores. This number can be retrieved in Rust by using the <code class="literal">num_cpus</code> crate. Let's make a new project with <code class="literal">cargo new many_threads --bin</code>:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Add the crate dependency to <code class="literal">Cargo.toml</code>:<div class="informalexample"><pre class="programlisting">[dependencies]
num_cpus = "*"</pre></div></li><li class="listitem">Then, change <code class="literal">main.rs</code> to the following code:<div class="informalexample"><pre class="programlisting">extern crate num_cpus;
fn main() {
  let ncpus = num_cpus::get();
  println!("The number of cpus in this machine is: {}", ncpus);
}</pre></div></li><li class="listitem">From within the <code class="literal">many_threads</code> folder, do a cargo build to install the crate and compile the code. Executing the program with cargo run gives the following output (dependent on the computer): <code class="literal">The number of cpus in this machine is: 8</code>.</li></ul></div><p>Now, you can start this (or any other) number of threads in a pool. This functionality is provided by the <code class="literal">threadpool</code> crate, which we can get by adding the <code class="literal">threadpool = "*"</code> to the <code class="literal">Cargo.toml</code> dependency and doing a cargo build. Add the following code to the start of the file:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>extern crate threadpool;</strong></span>

use std::thread;
<span class="strong"><strong>use threadpool::ThreadPool;</strong></span>
</pre></div><p>And, this code to the <code class="literal">main()</code> function:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>let pool = ThreadPool::new(ncpus);</strong></span>
for i in 0..ncpus {
<span class="strong"><strong>   	pool.execute(move || {</strong></span>
        println!("this is thread number {}", i)
   });
}
thread::sleep_ms(50);</pre></div><p>When executed, the preceding code yields the following output:</p><div class="informalexample"><pre class="programlisting">this is thread number 0
this is thread number 5
this is thread number 7
this is thread number 3
this is thread number 4
this is thread number 1
this is thread number 6
this is thread number 2</pre></div><p>A thread pool is used for <a id="id273" class="indexterm"/>running a number of jobs on a fixed set of parallel worker threads; it creates the given number of worker threads and replenishes the pool if any thread panics.</p></div><div class="section" title="Panicking threads"><div class="titlepage"><div><div><h2 class="title"><a id="ch08lvl2sec38"/>Panicking threads</h2></div></div></div><p>What happens when one of the spawned<a id="id274" class="indexterm"/> threads gets into a panic? This causes no problem as the threads are isolated from each other; only the panicking thread will crash after it frees its resources, but the parent thread is not affected. In fact, the parent can test the <code class="literal">is_err</code> return value from spawn as follows:</p><div class="informalexample"><pre class="programlisting">// code from Chapter 8/code/panic_thread.rs:	
use std::thread;
fn main() {
  let result = thread::spawn(move || {
      panic!("I have fallen into an unrecoverable trap!");
  }).join();
  if result.is_err() {
   println!("This child has panicked");
  }
}</pre></div><p>The preceding code prints out:</p><div class="informalexample"><pre class="programlisting">thread '&lt;unnamed&gt;' panicked at 'I' have fallen into an unrecoverable trap!'
This child has panicked</pre></div><p>Otherwise, to put it another way, the thread is the unit of failure isolation.</p></div><div class="section" title="Thread-safety"><div class="titlepage"><div><div><h2 class="title"><a id="ch08lvl2sec39"/>Thread-safety</h2></div></div></div><p>Traditional programming with threads<a id="id275" class="indexterm"/> is very difficult to get right if you allow the different threads to work on the same mutable data, the so-called shared memory. When two or more threads simultaneously change data, then data corruption (also called data racing) can occur due to the unpredictability of the threads' scheduling. In general, data (or a type) is said to be thread-safe when its contents will not be corrupted by the execution of different threads. Other languages offer no such help, but the Rust compiler simply forbids non thread-safe situations to occur. The same ownership strategy that pervades Rust to prevent memory safety errors also makes you write safe concurrent programs. Consider the following program:</p><div class="informalexample"><pre class="programlisting">// code from Chapter 8/code/not_shared.rs:
use std::thread;
fn main() {
    let mut health = 12;
    for i in 2..5 {
        thread::spawn(move || {
            health *= i;
        });
    }
    thread::sleep_ms(2000);
    println!("{}", health); // 12
}</pre></div><p>Our initial <code class="literal">health</code> is 12, but there are 3 fairies who can double, triple, and quadruple our health. We let each of them do this in a different thread, and after the threads are finished, we expect a <code class="literal">health</code> of 288 (which equates to 12 * 2 * 3 * 4). However, after their magical actions, our <code class="literal">health</code> is still at 12, even if we wait long enough to ensure that the threads are finished. Clearly, the three threads worked on a copy of our variable and not on the variable itself. Rust does not allow the <code class="literal">health</code> variable to be shared among the threads to prevent data corruption. In the next section, we will explore how we can use mutable variables that are shared between threads.</p></div></div></div>
<div class="section" title="The shared mutable state"><div class="titlepage" id="aid-1UU542"><div><div><h1 class="title"><a id="ch08lvl1sec60"/>The shared mutable state</h1></div></div></div><p>So, how can we <a id="id276" class="indexterm"/>make the <code class="literal">not_shared.rs</code> program give us the correct result? Rust provides tools, the so-called atomic types from the <code class="literal">std::sync::atomic</code> submodule, to handle shared mutable state safely. In order to share data, you need to wrap the data in some of the sync primitives, such as <code class="literal">Arc</code>, <code class="literal">Mutex</code>, <code class="literal">RwLock</code>, <code class="literal">AtomicUSize</code>, and so on.</p><p>Basically, the principle of locking is used, which is similar to that used by operating systems and database systems—exclusive access to a resource is given to the thread that has obtained a lock (which is also called a <code class="literal">mutex</code> and comes from mutually exclusive) on the resource. A lock can only be obtained by one thread at a time. In this way, two threads cannot change this resource at the same time, so no data races can occur; locking atomicity is enforced when required. When the thread that has acquired the lock has done its work, the lock is removed and another thread can then work with the data. In Rust, this is done with the generic <code class="literal">Mutex&lt;T&gt;</code> type from the <code class="literal">std::sync</code> module; <code class="literal">sync</code> comes from synchronize, which is exactly what we want to do with our threads. The <code class="literal">Mutex</code> ensures that only one thread can change the contents of our data at a time. We must make an instance of this type by wrapping our data as follows:</p><div class="informalexample"><pre class="programlisting">// code from Chapter 8/code/thread_safe.rs:	
<span class="strong"><strong>let data = Mutex::new(health);</strong></span>
</pre></div><p>Now, within the <code class="literal">for</code> loop, immediately after we spawn the new thread, we place a lock on the <code class="literal">health</code> object:</p><div class="informalexample"><pre class="programlisting">     for i in 2..5 {	
       thread::spawn(move || {
<span class="strong"><strong>            let mut health = data.lock().unwrap();</strong></span>
            // do other things
       }
     }</pre></div><p>The call to <code class="literal">lock()</code> will return a reference to the value inside the <code class="literal">Mutex</code> and block any other calls to <code class="literal">lock()</code> until that reference goes out of scope, which will happen at the end of the thread closure. Then, the thread does its work and the lock is automatically removed. However, we still get an error: <code class="literal">capture of moved value: 'data'</code> message. This means that data cannot be moved to another thread multiple times.</p><p>This problem can be solved by using an equivalent of the <code class="literal">Rc</code> pointer from the <span class="emphasis"><em>Reference counting</em></span> section of <a class="link" title="Chapter 6. Pointers and Memory Safety" href="part0056.xhtml#aid-1LCVG2">Chapter 6</a>, <span class="emphasis"><em>Pointers and Memory Safety</em></span>. Indeed, the situation here is very similar; all the<a id="id277" class="indexterm"/> threads need a reference to the same data, which is our health variable. So, we apply the same techniques from <a class="link" title="Chapter 6. Pointers and Memory Safety" href="part0056.xhtml#aid-1LCVG2">Chapter 6</a>, <span class="emphasis"><em>Pointers and Memory Safety</em></span> here—we make an <code class="literal">Rc</code> pointer to our data, and then we make a <code class="literal">clone()</code> of the pointer for each reference that is needed. However, a simple <code class="literal">Rc</code> pointer is not thread-safe; therefore, we need a special version of it that is thread-safe, the so called atomic reference counted pointer or <code class="literal">Arc&lt;T&gt;</code>. Atomic means that it is safe across threads, and it is also generic. So, we envelop our health variable inside an <code class="literal">Arc</code> pointer as follows:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>  let data = Arc::new(Mutex::new(health));</strong></span>
</pre></div><p>And, in the <code class="literal">for</code> loop, we make a new pointer to the <code class="literal">Mutex</code> with <code class="literal">clone</code>:</p><div class="informalexample"><pre class="programlisting">  for i in 2..5 {
      let mutex = data.clone();
      thread::spawn(move || { 
         let mut health = mutex.lock().unwrap();
         *health *= i;
      });
  }</pre></div><p>So, each thread now works with a copy of the pointer obtained by <code class="literal">clone()</code>. The <code class="literal">Arc</code> instance will keep track of the number of references to <code class="literal">health</code>. A call to <code class="literal">clone()</code> will increment the reference count on health. The <code class="literal">mutex</code> reference goes out of scope at the end of the thread closure, which will decrement the reference count. <code class="literal">Arc</code> will free the associated health resource when that reference count becomes zero.</p><p>Calling <code class="literal">lock()</code> gives the active thread exclusive access to the data. In principle, acquiring the lock might fail, so it returns a <code class="literal">Result&lt;T, E&gt;</code> object. In the preceding code, we assume that everything is okay. The <code class="literal">unwrap()</code> function is a quick means to return a reference to the data, but in the case of a failure, it panics.</p><p>Quite a few steps<a id="id278" class="indexterm"/> were involved here. So, we will repeat the code in its entirety again, but this time, we will provide robust error handling by replacing <code class="literal">unwrap()</code>. Digest each line with the explanations explained earlier:</p><div class="informalexample"><pre class="programlisting">// code from Chapter 8/code/thread_safe.rs:
use std::thread;
use std::sync::{Arc, Mutex};
fn main() {
  let mut health = 12;
  println!("health before: {:?}", health);
  let data = Arc::new(Mutex::new(health));
  for i in 2..5 {
        let mutex = data.clone();
        thread::spawn(move || {
            let health = mutex.lock();
            match health {
                // health is multiplied by i:
                Ok(mut health) =&gt; *health *= i,
                Err(str) =&gt; println!("{}", str)
            }
        }).join().unwrap();
    };
    health = *data.lock().unwrap();
    println!("health after: {:?}", health);
}</pre></div><p>This prints out:</p><div class="informalexample"><pre class="programlisting">health before: 12
health after: 288</pre></div><p>( 288 is indeed equal to 12 * 2 * 3 * 4 ). We join the threads to give them time to do their work; data is a reference, so we need to dereference it to obtain the <code class="literal">health</code> value:</p><div class="informalexample"><pre class="programlisting">health = *data.lock().unwrap();</pre></div><p>The mechanism outlined in the preceding section using a combined <code class="literal">Mutex</code> and <code class="literal">Arc</code> is advisable when the shared data occupies a significant amount of memory; this is because with an <code class="literal">Arc</code>, the data will no longer be copied for each thread. The <code class="literal">Arc</code> acts as a reference to the shared data<a id="id279" class="indexterm"/> and only this reference is shared and cloned.</p><div class="section" title="The Sync trait"><div class="titlepage"><div><div><h2 class="title"><a id="ch08lvl2sec40"/>The Sync trait</h2></div></div></div><p>An <code class="literal">Arc&lt;T&gt;</code> object implements<a id="id280" class="indexterm"/> the <code class="literal">Sync</code> trait (while <code class="literal">Rc</code> does not), which indicates to the compiler<a id="id281" class="indexterm"/> that it is safe to use concurrently with multiple threads. Any data that has to be shared simultaneously among threads must implement the <code class="literal">Sync</code> trait. A <code class="literal">T</code> type is <code class="literal">Sync</code> if there is no possibility of data races when the <code class="literal">&amp;T</code> references are passed between threads; in short <code class="literal">&amp;T</code> is thread-safe. All simple types such as the integer and floating point types are <code class="literal">Sync</code>, as well as all composite types (such as structs, enums, and tuples) built with simple types; any type that only contains things that implement <code class="literal">Sync</code> is automatically <code class="literal">Sync</code>.</p></div></div>
<div class="section" title="Communication through channels"><div class="titlepage" id="aid-1VSLM2"><div><div><h1 class="title"><a id="ch08lvl1sec61"/>Communication through channels</h1></div></div></div><p>Data can also be exchanged <a id="id282" class="indexterm"/>between threads by passing messages among them. This is implemented in Rust by channels, which are like unidirectional pipes that connect two threads—data is processed first-in, first-out. Data flows over this channel between two end-points, from the <code class="literal">Sender&lt;T&gt;</code> to the <code class="literal">Receiver&lt;T&gt;</code>; both are generic and take the <code class="literal">T</code> type of the message to transfer (which obviously must be the same for the <code class="literal">Sender</code> and <code class="literal">Receiver</code> channels). In this mechanism, a copy of the data to be shared is made for the receiving thread, so you shouldn't use this for very large data:</p><div class="mediaobject"><img src="../Images/image00184.jpeg" alt="Communication through channels"/></div><p style="clear:both; height: 1em;"> </p><p>To create a channel, we need to import the <code class="literal">mpsc</code> submodule from <code class="literal">std::sync</code> (<code class="literal">mpsc</code> stands for<a id="id283" class="indexterm"/> <span class="strong"><strong>multi-producer, single-consumer communication</strong></span><a id="id284" class="indexterm"/>
<span class="strong"><strong> primitives</strong></span>) and then use the <code class="literal">channel()</code> method:</p><div class="informalexample"><pre class="programlisting">// code from Chapter 8/code/channels.rs:
use std::thread;
<span class="strong"><strong>use std::sync::mpsc::channel;</strong></span>
<span class="strong"><strong>use std::sync::mpsc::{Sender, Receiver};</strong></span>
fn main() {
<span class="strong"><strong>  let (tx, rx): (Sender&lt;i32&gt;, Receiver&lt;i32&gt;) = channel();</strong></span>
}</pre></div><p>This creates a tuple of endpoints; <code class="literal">tx</code> (<code class="literal">t</code> from transmission) is the <code class="literal">Sender</code> and <code class="literal">rx</code> (<code class="literal">r</code> from receiver) is the <code class="literal">Receiver</code>. We have indicated that we will send <code class="literal">i32</code> integers over the channel, but the type annotations are not needed if the compiler can deduce the channel's data type from the rest of the code.</p><div class="section" title="Sending and receiving data"><div class="titlepage"><div><div><h2 class="title"><a id="ch08lvl2sec41"/>Sending and receiving data</h2></div></div></div><p>So, which data types can be<a id="id285" class="indexterm"/> sent over a channel? Rust imposes the <a id="id286" class="indexterm"/>requirement that data to be sent over a channel must implement the <code class="literal">Send</code> trait, which guarantees the safe transfer of ownership between threads. Data that does not implement <code class="literal">Send</code> cannot leave the current thread. An <code class="literal">i32</code> is <code class="literal">Send</code> because we can make a copy, so let's do that in the following code snippet:</p><div class="informalexample"><pre class="programlisting">fn main() {
  let (tx, rx) = channel();
  thread::spawn(move|| {
<span class="strong"><strong>      tx.send(10).unwrap();</strong></span>
  });
<span class="strong"><strong>  let res = rx.recv().unwrap();</strong></span>
  println!("{:?}", res); 
}</pre></div><p>This, of course, prints <code class="literal">10</code>.</p><p>Here, <code class="literal">tx</code> is moved inside the closure. A better way to write <code class="literal">tx.send(10).unwrap()</code> is as follows:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>tx.send(10).ok().expect("Unable to send message");</strong></span>
</pre></div><p>This will ensure that, in case of a problem, a message is sent.</p><p>The <code class="literal">send()</code> is executed by the child thread; it queues a message (a data value; here, it is 10) in the channel and does not block. The <code class="literal">recv()</code> is done by the parent thread; it picks a message from the channel and blocks the current thread if there are no messages available. (If you need to do this in a non-blocking fashion, use <code class="literal">try_recv()</code>.) If you don't process the received value, this blocking can be written as follows:</p><div class="informalexample"><pre class="programlisting">let _ = rx.recv();</pre></div><p>The <code class="literal">send()</code> and <code class="literal">recv()</code> operations return a <code class="literal">Result</code>, which can be of the <code class="literal">Ok(value)</code> type or an <code class="literal">Err</code> error. Full error-handling is omitted here because in the case of <code class="literal">Err</code>, the channel does not work anymore, and it is better for the thread to fail (panic) and stop.</p><p>In a general scenario, we <a id="id287" class="indexterm"/>could make a child thread execute <a id="id288" class="indexterm"/>a long computation and then receive the result in the parent thread as follows:</p><div class="informalexample"><pre class="programlisting">// code from Chapter 8/code/channels2.rs:
use std::thread;
use std::sync::mpsc::channel;
fn main() {
  let (tx, rx) = channel();
    
    thread::spawn(move|| {
        let result = some_expensive_computation();
        tx.send(result).ok().expect("Unable to send message");
    });
    some_other_expensive_computation();
    let result = rx.recv();
    println!("{:?}", result);  
}
fn some_expensive_computation() -&gt; i32 { 1 }
fn some_other_expensive_computation() { }</pre></div><p>The <code class="literal">result</code> function here has the <code class="literal">Ok(1)</code> value.</p><p>An elegant code pattern is shown in the following code snippet where the channel is created in a <code class="literal">make_chan()</code> function, which returns the receiving endpoint for the calling code:</p><div class="informalexample"><pre class="programlisting">// code from Chapter 8/code/make_channel.rs:
use std::sync::mpsc::channel;
use std::sync::mpsc::Receiver;
<span class="strong"><strong>fn make_chan() -&gt; Receiver&lt;i32&gt; {</strong></span>
<span class="strong"><strong>    let (tx, rx) = channel();</strong></span>
<span class="strong"><strong>    tx.send(7).unwrap();</strong></span>
<span class="strong"><strong>    rx</strong></span>
<span class="strong"><strong>}</strong></span>

fn main() {
    let rx = make_chan();
<span class="strong"><strong>    if let Some(msg) = rx.recv().ok() {</strong></span>
        println!("received message {}", msg);
    };
}</pre></div><p>This prints out: <code class="literal">received message 7</code>.</p><p>Perform the following exercise:</p><p>Construct a <code class="literal">shared_channel.rs</code> program that lets any number of threads share a channel to send in a value and <a id="id289" class="indexterm"/>has one receiver that collects <a id="id290" class="indexterm"/>all the values. As a hint, use <code class="literal">clone()</code> to give each thread access to the sending <code class="literal">tx</code> endpoint. (Refer to the example code in <code class="literal">Chapter 8/exercises/shared_channel.rs</code>.)</p></div><div class="section" title="Synchronous and asynchronous communication"><div class="titlepage"><div><div><h2 class="title"><a id="ch08lvl2sec42"/>Synchronous and asynchronous communication</h2></div></div></div><p>The kind of sending channel we used until now is <a id="id291" class="indexterm"/>asynchronous; this <a id="id292" class="indexterm"/>means that it does not block the executing code. Rust also has a synchronous channel type called <code class="literal">sync_channel</code> where the <code class="literal">send()</code> blocks if its internal buffer becomes full—it waits until the parent thread starts receiving the data. In the following code, this type of channel is used to send a value of the <code class="literal">Msg</code> struct over the channel:</p><div class="informalexample"><pre class="programlisting">// code from Chapter 8/code/sync_channel.rs:
use std::sync::mpsc::sync_channel;
use std::thread;
type TokenType = i32;
struct Msg {
    typ: TokenType,
    val: String,
}

fn main() {
<span class="strong"><strong>    let (tx, rx) = sync_channel(1); // buffer size 1</strong></span>
    tx.send(Msg {typ: 42, val: "Rust is cool".to_string()}).unwrap();
    println!("message 1 is sent");
    thread::spawn(move|| {
    tx.send(Msg {typ: 43, val: "Rust is still cool".to_string()}).unwrap();
        println!("message 2 is sent");
    });
    println!("Waiting for 3 seconds ...");
    thread::sleep_ms(3000);
    if let Some(msg) = rx.recv().ok() {
      println!("received message of type {} and val {}", msg.typ, msg.val);
    };
    if let Some(msg) = rx.recv().ok() {
      println!("received second message of type {} and val {}", msg.typ, msg.val);
    };
}</pre></div><p>Which prints:</p><div class="informalexample"><pre class="programlisting">message 1 is sent
Waiting for 3 seconds</pre></div><p>Then, after 3 seconds, prints:</p><div class="informalexample"><pre class="programlisting">received message of type 42 and val Rust is cool
message 2 is sent
received second message of type 43 and val Rust is still cool</pre></div><p>This clearly shows that the <a id="id293" class="indexterm"/>second message could only be <a id="id294" class="indexterm"/>sent when the buffer was emptied by receiving the first message.</p><p>Perform the following exercise:</p><p>Explain what happens when the second message is also sent from within the main thread and not in a separate thread.</p></div></div>
<div class="section" title="Summary" id="aid-20R681"><div class="titlepage"><div><div><h1 class="title"><a id="ch08lvl1sec62"/>Summary</h1></div></div></div><p>In this chapter, we explored Rust's lightweight thread processes—how to create them, how to let them share data, and how to let them pass data through channels.</p><p>In the following chapter, we will have a look at the boundaries—we will see how a Rust program can take arguments to work with them. We will also examine what we have to do in Rust when we go to so such a low level that the compiler cannot guarantee safety anymore and how we can interface with other languages such as C.</p></div></body></html>