- en: The Rust Memory Model – Ownership, References and Manipulation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapter, [Chapter 2](8c61da2f-08c8-40be-89d4-d8afa8510850.xhtml),
    *Sequential Rust Performance and Testing*, we discussed factors that contribute
    or detract from the serial performance of a Rust program. We did not explicitly
    address concurrent performance for want of sufficient information about the way
    Rust's abstract memory model interacts with the real memory hierarchy of a machine.
    In this chapter, we'll discuss Rust's memory model, how to control the layout
    of types in memory, how types are aliased, and how Rust's memory safety works.
    We'll dig into the standard library to understand how this plays out in practice.
    This chapter will also examine common crates in the ecosystem that will be of
    interest to us later in this book. Please be aware that by the time you read this
    chapter, the `rustc` implementation will have changed, potentially making our
    code listings here no longer square with the naming patterns in `rustc` itself.
    If you wish to follow along, please check out Rust at SHA `da569fa9ddf8369a9809184d43c600dc06bd4b4d`.
  prefs: []
  type: TYPE_NORMAL
- en: 'By the close of this chapter, we will have:'
  prefs: []
  type: TYPE_NORMAL
- en: Investigated how Rust lays objects out in memory
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Discussed the various ways Rust points to memory and their guarantees
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Discussed how Rust allocates and deallocates memory
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Discussed how Rust denotes stack and heap allocations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Investigated the internal implementation of `Option`, `Cell`, `CellRef` , `Rc` and
    `Vec`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter requires a working Rust installation. The details of verifying
    your installation are covered in [Chapter 1](5f3aec9d-fd53-48ff-9ba8-43ce13e91cff.xhtml),
    *Preliminaries – Machine Architecture and Getting Started with Rust*. No additional
    software tools are required.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can find the source code for this book''s projects on GitHub: [https://github.com/PacktPublishing/Hands-On-Concurrency-with-Rust](https://github.com/PacktPublishing/Hands-On-Concurrency-with-Rust).
    This chapter has its source code under `Chapter03`.'
  prefs: []
  type: TYPE_NORMAL
- en: Memory layout
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Rust has a handful of mechanisms to lay out compound types in memory. They
    are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Arrays
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Enums
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Structs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tuples
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Exactly how these are laid out in memory depends on the representation chosen.
    By default, everything in Rust is `repr(Rust)`. All `repr(Rust)` types are aligned
    on byte boundaries to the power of two. Every type is at least one byte in memory,
    then two, then four, and so forth. Primitives—`u8`, `usize`, `bool`, and `&T`—are
    aligned to their size. In Rust, representation structures have alignment according
    to the largest field. Consider the following struct:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '`AGC` is aligned to `u32` with padding inserted as appropriate to match that
    32-bit alignment. Rust will re-order fields to achieve maximal packing. Enums
    are different, being subject to a host of optimizations, most notably null pointer
    optimization. See the following enumeration:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'This will be laid out as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The `data` field is wide enough to accommodate the largest inner value and the
    `tag` allows discrimination between variants. Where this gets complicated is in
    the case of an enum that holds a non-nullable pointer, and other variants cannot
    refer to the same. `Option<&T>` means if a null pointer is discovered when dereferencing
    the option Rust can assume that the `None` variant was discovered. Rust will optimize
    away the tag for `Option<&T>`.
  prefs: []
  type: TYPE_NORMAL
- en: Rust supports other representations. `repr(C) ` lays out types in memory in
    a manner that C would do and is often used in FFI projects, as we'll see later
    in this book. `repr(packed)` lays types out in memory like `repr(Rust)` except
    that no padding is added, and alignment occurs only to the byte. This representation
    is likely to cause unaligned loads and a severe effect on performance of common
    CPUs, certainly the two CPU architectures we concern ourselves with in this book.
    The remaining representations have to do with forcing the size of fieldless enumerations—that
    is, enumerations that have no data in their variants—and these are useful for
    forcing the size of such an enum with an eye towards ABI compatability.
  prefs: []
  type: TYPE_NORMAL
- en: 'Rust allocations happen by default on the hardware stack, as is common for
    other low-level languages. Heap allocations must be performed explicitly by the
    programmer or be done implicitly when creating a new type that holds some sort
    of internal storage. There are complications here. By default, Rust types obey
    move semantics: the bits of the type are moved as appropriate between contexts.
    For example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'The `project_flights` function allocates a new `Vec<(u16, u8)>` on the heap,
    populates it, and then returns ownership of the heap-allocated vector to the caller.
    This does not mean that the bits of `t` are copied from the stack frame of `project_flights`
    but, instead, that the pointer  `t` is returned from the `project_flights` stack
    to `main`. It is possible to achieve copy semantics in Rust through the use of
    the `Copy` trait. `Copy` types will have their bits copied in memory from one
    place to the other. Rust primitive types are `Copy`—copying them is as fast as
    moving them, especially when the type is smaller than the native pointer. It''s
    possible to implement `Copy` for your own type unless your type implements `Drop`,
    the trait that defines how a type deallocates itself. This restriction eliminates—in
    Rust code not using `unsafe` —the possibility of double frees. The following code
    block derives `Copy` for two user-defined types and is an example of a poor random
    generator:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Pointers to memory
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Rust defines several kinds of pointers, each with a specific purpose. `&T`
    is a shared reference and there may be many duplicates of that shared reference.
    The owner of `&T` does not necessarily, own `T` and may not modify it. Shared
    references are immutable. Mutable references—written `&mut T`—also do not imply
    that the other  `&mut T` owns `T` necessarily but the reference may be used to
    mutate `T`. There may be only one reference for any `T` with a `&mut T`. This
    complicates some code but means that Rust is able to prove that two variables
    do not overlap in memory, unlocking a variety of optimization opportunities absent
    from C/C++. Rust references are designed so that the compiler is able to prove
    the liveness of the referred to type: references cannot dangle. This is not true
    of Rust''s raw pointer types—`*const T` and `*mut T`—which work analogously to
    C pointers: they are, strictly, an address in memory and no guarantees about the
    data at that address are made. As such, many operations on raw pointers require
    the `unsafe` keyword and they are almost always seen solely in the context of
    performance-sensitive code or FFI interfaces. Put another way, a raw pointer may
    be null; a reference may never be null.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The rules around references often cause difficulty in situations where an immutable
    borrow is accidentally made of a mutable reference. The Rust documentation uses
    the following small program to illustrate the difficulty:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'The `println!` macro takes its arguments by reference, implicitly here, creating
    a `&x`. The compiler rejects this program as `y: &mut u8` is invalid. Were this
    program to compile, we would be subject to a race between the update of `y` and
    the read of `x`, depending on the CPU and memory ordering. The exclusive nature
    of references could be potentially limiting when working with structures. Rust
    allows programs to split borrows for a structure, providing that the disjoint
    fields cannot be aliased.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We demonstrate this in the following brief program:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'This same trick is difficult to impossible for general container types. Consider
    a map where two keys map to the same referenced `T`. Or, for now, a slice:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'This program fails to compile with the following error:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'We, the programmers*,* know that this was safe—`gemini_2` and `gemini_12` don''t
    overlap in memory—but it''s not possible for the compiler to prove this. What
    if we had done the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: By definition, `missions[0]` and `missions[1]` overlap in memory. We, the programmers,
    know we're breaking the aliasing rules and the compiler, being conservative, assumes
    that the rules are being broken.
  prefs: []
  type: TYPE_NORMAL
- en: Allocating and deallocating memory
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Deallocation happens in one of two ways, depending on whether the type is allocated
    on the stack or the heap. If it''s on the stack, the type is deallocated when
    the stack frame itself ceases to exist. Each Rust stack frame comes into the world
    fully allocated but uninitialized and exits the world when its associated function
    exits. Heap allocated types are deallocated when the last valid binding moves
    out of scope, either through the natural flow of the program or by an explicit
    `std::mem::drop` being called by the programmer. The implementation of `drop`
    is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: The value `_x` is moved into `drop` —meaning there are no other borrows of `_x`—and
    then immediately falls out of scope when `drop` exits. An explicit `drop` is not
    able to remove items from scope, however, so subtle interactions with structures
    where the Rust compiler is not able to prove non-overlapping aliases and the like
    will happen. The `drop` documentation discusses several cases and it is worth
    reviewing that material.
  prefs: []
  type: TYPE_NORMAL
- en: Any Rust type that can be deallocated—meaning it is not `Copy`—will implement
    the `Drop` trait, a trait whose sole function is `drop(&mut self)`. `Drop::drop`
    cannot be called explicitly and is called when the type goes out of scope or is
    invocable by `std::mem::drop`, as discussed  previously.
  prefs: []
  type: TYPE_NORMAL
- en: 'So far in this chapter, we''ve discussed the layout of types in memory and
    allocation on the heap but without fully discussing how allocation itself works
    in the Rust memory model. The simplest way of forcing a heap allocation is with
    `std::boxed::Box`. In fact, the Rust documentation for `Box`—which is also just
    called box—describes it as the simplest form of heap allocation in Rust. That
    is, a `Box<T>` allocates enough space on the heap for a type `T` and acts as the
    owner of that allocation. When the box is dropped, the drop of `T` occurs. Here''s
    the definition of `Box<T>` straight from the standard library, in the file `src/liballoc/boxed.rs`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: The size of a type
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There''s two important things here we have not come across yet in this book—`Sized`
    and `Unique`. First, `Sized`, or more properly, `std::marker::Sized`. `Sized`, is
    a Rust `trait` that bounds a type to have a known size at compile time. Almost
    everything in Rust has an implicit `Sized` bound, which we can inspect. For instance:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '`u8` is a single byte, Project is the byte to distinguish the enum variants
    plus the inner mission byte, pointers are the size of a machine word–a `usize-`
    and a `Vec<T>` is guaranteed to be a pointer and two `usize` fields no matter
    the size of `T`. There''s something interesting going on with `Vec<T>` and we''ll
    get into it in depth later in this chapter. Note that we said almost everything
    in Rust has an implicit `Sized` bound. Rust supports *dynamically sized types*,
    these being types that have no known size or alignment. Rust requires known size
    and alignment and so all DSTs must exist behind a reference or pointer. A slice—a
    view into contiguous memory—is one such type. In the following program, the compiler
    will not be able to determine the size of the slice of values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '*Slices are a view into a block of memory represented as a pointer and a length*, as
    the documentation for the primitive type slice puts it. The trick is that the
    length is determined at runtime. The following program will compile:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'However, the previous code will panic at runtime:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Rust allows programmers to include DSTs as the last field of a `struct`, like
    so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: However, this causes the struct itself to become a DST.
  prefs: []
  type: TYPE_NORMAL
- en: Static and dynamic dispatch
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Trait objects likewise have no statically known size in Rust. Trait objects
    are the mechanism by which Rust performs dynamic dispatch. Preferentially, Rust
    is a static dispatch language as there are increased opportunities for inlining
    and optimization—the compiler simply knows more. Consider the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we define a function, `sd_add<T: Add<Output=T>>(x: T, y: T) -> T`. Rust,
    like C++, will perform monomorphization at compile time, emitting two `sd_add`
    functions, one for `u8` and the other for `u64`. Like C++, this potentially increases
    the code size of a Rust program and slows compilation but at the benefit of allowing
    inlining at the caller site, potentially more efficient implementations owing
    to type specialization, and fewer branches.'
  prefs: []
  type: TYPE_NORMAL
- en: When static dispatch is not desirable, the programmer can construct trait objects
    to perform dynamic dispatch. Trait objects do not have a known size—indeed, they
    can be any `T` that implements the trait—and so, like slices, must exist behind
    a kind of pointer. Dynamic dispatch will not see much use in this book. The reader
    is warmly encouraged to consult the documentation for `std::raw::TraitObject`
    for full details on Rust's trait object notion.
  prefs: []
  type: TYPE_NORMAL
- en: Zero sized types
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Rust also supports *zero sized types* or ZSTs; structs with no fields, the
    unit type `()`, or arrays with no size are all zero sized. The fact that the type
    has no size is a boon to optimization and dead-tree removal. Rust APIs often include
    return types like so: `Result<(), a_mod::ErrorKind>`. This type signals that while
    the function may error, its return value in the happy path is the unit type. These
    types are somewhat rare in practice but unsafe, and Rust must be aware of them.
    Many allocators return null when asked to allocate zero bytes—making the allocation
    of a ZST indistinguishable from the allocator being unable to find free memory—and
    pointer offsets from a ZST are of zero offset. Both of these considerations will
    be important in this chapter.'
  prefs: []
  type: TYPE_NORMAL
- en: Boxed types
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'That''s the trait `Sized`, but what does `?Sized` mean? The `?` flags the relevant
    trait as optional. So, a box is a type in Rust parameterized over some other type
    `T` which may or may not have a size. A box is a kind of a pointer to heap allocated
    storage. Let''s look into its implementation further. What of `Unique<T>`? This
    type is a signal to the Rust compiler that some `*mut T` is non-null and that
    the unique is the sole owner of `T`, even though `T` was allocated outside the
    `Unique`. `Unique` is defined like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: '`NonZero<T>` is a struct that the `rustc` source describes as a wrapper type
    for raw pointers and integers that will never be `NULL` or `0` that might allow
    certain optimizations. It''s annotated in a special way to admit those null pointer
    optimizations discussed elsewhere in this chapter. Unique is also of interest
    for its use of `PhantomData<T>`. `PhantomData` is, in fact, a zero sized type,
    defined as `pub struct PhantomData<T:?Sized>;`. This type instructs the Rust compiler
    to consider `PhantomData<T>` as owning `T` even though, ultimately, there''s nowhere
    for `PhantomData` to store its newfound `T`. This works well for `Unique<T>`,
    which must take ownership of `<T>` by maintaining a non-zero constant pointer
    to `T` but does not, itself, have `T` stored anywhere other than in the heap.
    A box is then, a unique, non-null pointer to a thing allocated somewhere in memory
    but not inside the storage space of the box.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The internals of box are compiler intrinsics: they sit at the interplay of
    the allocator and are a special consideration in Rust''s borrow checker. With
    that in mind, we will avoid chasing down the internal details of `Box` as they
    will change from compiler version to compiler version and this book is explicitly
    not a `rustc` internals book. For our purposes, however, it is worth considering
    the API exposed by box. The key functions are:'
  prefs: []
  type: TYPE_NORMAL
- en: '`fn from_raw(raw: *mut T) -> Box<T>`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`fn from_unique(u: Unique<T>) -> Box<T>`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`fn into_raw(b: Box<T>) -> *mut T`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`fn into_unique(b: Box<T>) -> Unique<T>`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`fn leak<''a>(b: Box<T>) -> &''a mut T`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Both `from_raw` and `from_unique` are unsafe. Conversion from a raw pointer
    is unsafe if a raw pointer is *boxed* more than once or if a box is made from
    a pointer that overlaps with another, as examples. There are other possibilities.
    Conversion from a `Unique<T>` is unsafe as the `T` may or may not be owned by  `Unique`,
    resulting in a possibility of the box not being the sole owner of its memory.
    The `into_*` functions, however, are safe in the sense that the resulting pointers
    will be valid but the caller will not have full responsibility for managing the
    lifetime of the memory. The `Box` documentation notes that the caller can release
    the memory themselves or convert the pointer back into the type they came from
    and allow Rust to do it for them. The latter is the approach this book will take.
    Finally, there''s `leak`. Leak is a fun one and is not available on stable channel
    but is worth discussing for applications that will ship to embedded targets. A
    common memory management strategy for embedded systems is to pre-allocate all
    necessary memory and only operate on that memory for the lifetime of the program.
    In Rust, this is trivially accomplished if you desire uninitialized memory of
    a constant size: arrays and other primitive types. In the event you desire heap
    allocations at the start of your program, the situation is more complicated. That''s
    where leak comes in: it causes memory to leak from a box—a heap allocation—to
    wherever you please. When the leaked memory is intended to live for the lifetime
    of the program—into the `static` lifetime—there''s no issue. An example  is as
    follows, straight from the docs for `leak:`'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Here, we see a new `usize` allocated on the heap, leaked into `static_ref`—a
    mutable reference of static lifetime—and then fiddled with through the remaining
    lifetime of the program.
  prefs: []
  type: TYPE_NORMAL
- en: Custom allocators
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It is possible to plug in one's own allocator to Rust, as can be done in C++
    or similar system-level programming languages. By default, on most targets, Rust
    uses jemalloc with a backup alternative to the system-provided allocator. In embedded
    applications, there may not *be* a system, let alone an allocator, and the interested
    reader is recommended to peruse RFC 1183 ([https://github.com/rust-lang/rfcs/blob/master/text/1183-swap-out-jemalloc.md](https://github.com/rust-lang/rfcs/blob/master/text/1183-swap-out-jemalloc.md)),
    RFC 1398 ([https://github.com/rust-lang/rfcs/pull/1398](https://github.com/rust-lang/rfcs/pull/1398)),
    and related RFCs. As of writing this, an interface for plugging in custom allocators
    to stable Rust is under active discussion and any such capability is only available
    in nightly Rust. We will not make use of custom allocators in this book.
  prefs: []
  type: TYPE_NORMAL
- en: Implementations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In [Chapter 2](8c61da2f-08c8-40be-89d4-d8afa8510850.xhtml), *Sequential Rust
    Performance and Testing,* we very briefly dipped into the implementation of `std::collections::HashMap`.
    Let's continue with that approach of dissecting the standard library, paying special
    attention to the concerns of memory that pop up.
  prefs: []
  type: TYPE_NORMAL
- en: Option
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s examine `Option<T>`. We''ve already discussed `Option<T>` in this chapter;
    that it''s subject to *null pointer optimization* on account of its empty `None`
    variant in particular. `Option` is as simple as you might imagine, being defined
    in `src/libcore/option.rs`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'As is often the case with Rust internals, there are a great deal of flags around
    to control when and where new features land in which channel and how documentation
    is generated. A slightly tidier expression of `Option<T>` is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'This is refreshingly simple, much like how you may have implemented an option
    type yourself up on first thinking of it. `Option` is the owner of its inner `T`
    and is able to pass out references to that inner data per the usual restrictions.
    As an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Rust exposes a special trait type inside each `trait: Self`. It desugars simply
    to the referent trait type, in this case, `Option<T>`. The `&mut self` is shorthand
    for `self: &mut Self`, as is `&self` for `self: &Self` . `as_mut`  is then allocating
    a new option whose inner type is a mutable reference to the original inner type.
    Now, consider the humble `map`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Rust allows closures as arguments to functions. In this way, Rust is similar
    to higher-level and, especially, functional programming languages. Unlike these
    higher-level programming languages, Rust has restrictions on closures in terms
    of the way *variable capture* occurs and with regard to call totals and mutability.
    Here, we see the `FnOnce` trait being used, restricting the closure being passed
    in as `f` to the map function as being single-use. The function traits, all defined
    in `std::ops`, are:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Fn`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`FnMut`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`FnOnce`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The first trait, `Fn`, is described by the Rust documentation as being a *call
    operator that takes an immutable receiver*. This is maybe a little obscure until
    we look at the definition of `Fn` in `src/libcore/ops/function.rs`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Now it''s more obscure! But, we can work that back. `Args` is distinct from
    `std::env::Args` but plays a similar role of being a placeholder for function
    arguments, save at a type-level. `: FnMut<Args>` means that the `FnMut<Args>`
    is a *supertrait* of `Fn<Args>:` all of the methods available to `FnMut` are available
    to `Fn` when used as a trait object. Recall that trait objects find use in dynamic
    dispatch, discussed previously. This also means that any instance of `Fn` can
    be used where an `FnMut` is expected, in cases of static dispatch. Of particular
    interest to understanding `Fn` is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'We''ll approach this in parts. Firstly, `extern "rust-call"`. Here, we are
    defining an inline extern block that uses the `"rust-call"` ABI. Rust supports
    many ABIs, three of which are cross-platform and guaranteed to be supported no
    matter the platform:'
  prefs: []
  type: TYPE_NORMAL
- en: '`extern "Rust" fn`, implicit for all Rust functions unless otherwise specified'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`extern "C" fn`, often used in FFI and shorthanded to `extern fn`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`extern "system" fn`, equivalent to `extern "C" fn` save for some special platforms'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`"rust-call"` does not appear in that list because it is a rust-specific ABI,
    which also includes:'
  prefs: []
  type: TYPE_NORMAL
- en: '`extern "rust-intrinsic" fn`, specific to `rustc` intrinsics'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`extern "rust-call" fn`, the ABI for all `Fn::call` functions'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`extern "platform-intrinsic" fn`, which the documentation notes as being something
    the programmer should never have to deal with'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Here, we''re signalling to the Rust compiler that the function is to be treated
    with a special call ABI. This particular `extern` is important when writing traits
    that implement the `Fn` trait, as box will when the unstable `fnbox` feature flag
    is enabled:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Secondly, `fn call(&self, args: Args)`. The implementing type is taken in as
    an immutable reference, in addition to the passed args; this is the immutable
    receiver mentioned in the documentation. The final piece here is `-> Self::Output`,
    the returned type after the call operator is used. This associated type defaults
    to `Self` but can be set by the implementer.'
  prefs: []
  type: TYPE_NORMAL
- en: '`FnMut` is similar to `Fn` save that it takes `&mut self` rather than `&self`,
    and `FnOnce` is its supertrait:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Only `FnOnce` deviates in its definition:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we see where `Self::Output` makes its appearance as an associated type
    and note that the implementations of `FnOnce` are in terms of `call_once` rather
    than `call.` Also, we now know that `FnOnce` is a supertrait of `FnMut`, which
    is a supertrait of `Fn` and it just so happens that this property is transitive:
    if an `FnOnce` is called for an `Fn`, it can be used. Much of the exact implementation
    of the function traits are kept internal to the compiler, the details of which
    kind of jump around some as internals change. In fact, the `"rust-call"`, `extern`
    means that `Fn traits` cannot be implemented outside of special, compiler-specific
    contexts; the exact feature flags that need to be enabled in a nightly build,
    their use, and upcoming changes are not documented. Happily, closures and function
    pointers implement function traits implicitly. For example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: The compiler is good enough to figure out the details for us.
  prefs: []
  type: TYPE_NORMAL
- en: 'Conceptually, `Result<T>` is a type similar to `Option<T>`, save that it is
    able to communicate an extra piece of information in its `Err` variant. In fact,
    the implementation in `src/libcore/result.rs` is awfully similar to the way we''d
    likely write this at first though, as with `Option`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: Cell and RefCell
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far in this chapter, the mutable references we've been discussing have a
    property called, by Rust, inherited mutability. That is, values are made mutable
    when we inherit their ownership or the exclusive right—via a `&mut`—to mutate
    the value. Inherited mutability is preferred in Rust as it is statically enforcable—any
    defects in our program with regards to memory mutation will be caught at compilation
    time. Rust does provide facilities for interior mutability,  that being mutability
    that is available for pieces of an immutable type. The documentation calls interior
    mutability something of a last resort but, while not common, it is not exactly
    rare in practice, either. The two options for interior mutability in Rust are
    `Cell<T>` and `RefCell<T>`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s consider `Cell<T>`. How is it used? As suggested, `Cell<T>` is useful
    when some field or fields of an otherwise immutable structure need to be mutable
    and the `T` you''re concerned with is `T: Copy`. Consider a graph structure where
    a search operation is performed. This is logically immutable—the graph structure
    does not need to be modified during search. But, also consider the case where
    we would like to record the total number of traversals along the graph''s edges.
    Our options are to violate the logical immutability of the graph search, require
    storage outside of the graph, or insert an interior, mutable counter into the
    graph. Which choice is best will depend on the specific situation. Here is a significantly
    less complicated example of `Cell<T>`, compared to a graph search:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Of course, that''s a bit contrived. Interior mutability shows up when the situation
    is non-trivial, generally speaking. Note that `Cell<u8>` had to be manipulated
    with `get` and `set` methods, contrary to the normal process of setting and reading
    directly or through a pointer. Let''s dig into the implementation of `Cell<T>`,
    defined in `src/libcore/cell.rs`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: As is common in Rust internals, a safe interface hides an unsafe inner core,
    as we saw in [Chapter 2](8c61da2f-08c8-40be-89d4-d8afa8510850.xhtml), *Sequential
    Rust Performance and Testing*, with `HashMap`. What is the definition of `UnsafeCell`?
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'Of particular note is an implementation that follows shortly afterward:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'We will discuss `Sync` in the following chapter in greater detail. Suffice
    it to say, for now, any type that is threadsafe must implement `Sync`—and many
    do automatically—and by disabling the `Sync` trait for `UnsafeCell<T>`—which is
    what `!Sync` means—the type is specifically being marked as not thread-safe. That
    is, any thread may be manipulating the data owned by `UnsafeCell` at any time.
    As we''ve previously discussed, Rust is able to make a good deal of optimizations
    off the back of the knowledge that `&T` is guaranteed to also not be mutable somewhere
    and that `&mut T` is unique. `UnsafeCell<T>` is the *only* method Rust provides
    to turn these compiler optimizations off; it is possible to dip into an unsafe
    block and transmute `&T` to `&mut T`, but this is specifically called out as undefined
    behavior. They key to `UnsafeCell<T>` is that it is possible for a client to retrieve
    multiple mutable references to the interior data, even if the `UnsafeCell<T>`
    is itself mutable. It is up to the caller to ensure that there is *only* one mutable
    reference at any time. The implementation of `UnsafeCell` —stripped of its comments
    for clarity''s sake—is brief:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'This brings us back to `Cell<T>`. We know that `Cell<T>` is built on top of
    an unsafe abstraction and we will have to take care not to violate the `&mut T`
    uniqueness constraint. How is this done? First, construction of `Cell<T>` is straightforward,
    as you may expect:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'The `const fn` is likely a surprise, on account of it being a nightly-only
    feature as of writing this book. In Rust, a constant function is evaluated at
    compile time. The benefit to the programmer of this particular definition is that
    the result of `Cell::new` can be assigned to a constant variable, one which will
    exist for the lifetime of the program. Both `as_ptr` and `get_mut` are different
    views of the underlying `T`, one a raw mutable pointer and the other a mutable
    reference:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that while the internals of `get_mut` are unsafe, the borrow checker is
    brought to bear on the problem of keeping `&mut T` unique and so `Cell::get_mut`
    can itself be safe. `Cell::as_ptr` is not marked as unsafe—it''s safe to receive
    a raw pointer in Rust—but any caller will have to do deferencing of that raw pointer
    in an unsafe block: it''s possible that there will be more than one raw, mutable
    pointer floating around. Setting a new value into the cell is done in terms of
    replacement, discussed ahead, but with careful attention made towards forcefully
    dropping the `T` pulled from the cell:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: '`Cell::swap` and `Cell::replace` are done in terms of the lower-level memory
    manipulation tools from `std::ptr` and `std::mem`. `swap` is intended to replace
    the interior of one cell with another. Its definition is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: '`swap` is done in terms of `std::ptr::swap`, a function documented as copying
    the memory through the raw pointers passed to it as arguments*.* You''ll note
    that `Cell::swap` is careful to avoid the `swap` if the passed `other` is equivalent
    to `self`. The reason for this becomes clear when we take a peek at the definition
    of `std::ptr::swap`, defined in `src/libcore/ptr.rs`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'The exact details of `copy_nonoverlapping` and copy are unimportant here, except
    in noting that swapping does require allocation of uninitialized space and copying
    back and forth from that space. It''s wise to avoid the work if you don''t have
    to do it. `Cell::replace` works along similar lines:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: '`std::mem::replace` takes a `&mut T` and a `T` and then replaces the value
    at `&mut T` with the passed in `val`, returning the old value and dropping neither.
    The definition of `std::mem::replace` is in `src/libcore/mem.rs` and is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'Chasing the definition of `swap` in the same module, we find it is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: '`std::ptr::swap_nonoverlapping` is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, the private `std::ptr::swap_nonoverlapping_bytes` is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: Whew! That's some rabbit hole. Ultimately, what we've discovered here is that
    `std::mem::replace` is defined in terms of block copies from one non-overlapping
    location in memory to another, a process which the Rust developers have tried
    to make as efficient as possible by exploiting LLVM's ability to optimize a bitwise
    operation on common processors in terms of SIMD instructions. Neat.
  prefs: []
  type: TYPE_NORMAL
- en: 'What of `RefCell<T>`? It too is a safe abstraction over `UnsafeCell<T>` except
    that the copy restriction of `Cell<T>` is lifted. This makes the implementation
    a touch more complicated, as we''ll see:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'Like `Cell, RefCell` has an inner unsafe value, that much is the same. What''s
    fun here is `borrow: Cell<BorrowFlag>`. `RefCell<T>` is a client of `Cell<T>`,
    which makes good sense considering that the immutable `RefCell` is going to need
    interior mutability to track the total number of borrows of its inner data. `BorrowFlag`
    is defined like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'The implementation of `RefCell<T>` is like to that of `Cell<T>`. `RefCell::replace`
    is also implemented in terms of `std::mem::replace`, `RefCell::swap` in terms
    of `std::mem::swap`. Where things get interesting are the functions new to `RefCell`,
     which are those to do with borrowing. We''ll look at `try_borrow` and `try_borrow_mut`
    first as they''re used in the implementations of the other borrowing functions.
    `try_borrow` is defined like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'With `BorrowRef` being as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: '`BorrowRef` is a structure that holds a reference to the borrow field of `RefCell<T>`.
    Creating a new `BorrowRef` depends on the value of that borrow; if the value is
    `WRITING` then no `BorrowRef` is created—`None` gets returned—and otherwise the
    total number of borrows are incremented. This achieves the mutual exclusivity
    of writing needed while allowing for multiple readers—it''s not possible for `try_borrow`
    to hand out a reference when a write reference is out for the same data. Now,
    let''s consider `try_borrow_mut`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'Again, we find an implementation in terms of another type, `BorrowRefMut`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: The key, as with `BorrowRef`, is in `BorrowRefMut::new`. Here, we can see that
    if the inner borrow from `RefCell` is unused then the borrow is set to write,
    excluding any potential read references. Likewise, if there is a read reference
    in existence, the creation of a mutable reference will fail. And so, exclusive
    mutable references and multiple immutable references are held at runtime by abstracting
    over an unsafe structure that allows for the breaking of that guarantee.
  prefs: []
  type: TYPE_NORMAL
- en: Rc
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now, let''s consider one last single-item container before we get into a multi-item
    container. We''ll look into `Rc<T>`, described by the Rust documentation as being
    a single-threaded reference-counting pointer. Reference counting pointers are
    distinct from the usual Rust references in that, while they are allocated on the
    heap as a `Box<T>`, cloning a reference counter pointer does not cause a new heap
    allocation, bitwise copy. Instead, a counter inside the `Rc<T>` is incremented,
    somewhat analogously as to the way `RefCell<T>` works. The drop of an `Rc<T>`
    reduces that internal counter and when the counter''s value is equal to zero,
    the heap allocation is released. Let''s take a peek inside `src/liballoc/rc.s`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'We''ve already encountered `PhantomData<T>` in this chapter, so we know that
    `Rc<T>` will not directly hold the allocation of `T`, but the compiler will behave
    as if it does. Also, we know that `T` may or may not be sized. The pieces we need
    to catch up on then are `RcBox<T>` and `Shared<T>.` Let''s inspect `Shared<T>`
    first. Its full name is `std::ptr::Shared<T>` and it''s the same kind of pointer
    as `*mut X` except that it is non-zero. There are two variants for creating a
    new `Shared<T>`, `const unsafe fn new_unchecked(ptr: *mut X) -> Self` and  `fn
    new(ptr: *mut X) -> Option<Self>`. In the first variant, the caller is responsible
    for ensuring that the pointer is non-null, and in the second the nulled nature
    of the pointer is checked, like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'We find the definition and implementation of `NonZero<T>` in `src/libcore/nonzero.rs ` like
    so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: '`Zeroable` is an unstable trait, which is pretty straightforward:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'Every pointer type implements an `is_null() -> bool` and this trait defers
    to that function, and `NonZero::new` defers to `Zeroable::is_zero`. The presence
    of a `Shared<T>`, then, gives the programmer the same freedom as `*mut T` but
    with added guarantees about the pointer''s nullable situation. Jumping back up
    to `Rc::new`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: '`Box::into_unique` converts a `Box<T>` into a `Unique<T>`—discussed previously
    in this chapter—which is then converted into a `Shared<T>`. This chain preserves
    the non-null guarantee needed and ensures uniqueness. Now, what about strong and
    weak in `RcBox`? `Rc<T>` provides a method, `Self::downgrade(&self) -> Weak<T>`,
    that produces a non-owning pointer, a pointer which does not guarantee the liveness
    of the referenced data and does not extend its lifetime. This is called a *weak
    reference*. Dropping a `Weak<T>`, likewise, does not imply that `T` is dropped.
    The trick here is that a strong reference does extend the liveness of the underlying
    `T`—the drop of `T` is only called when the internal counter of `Rc<T>` hits zero.
    For the most part, things rarely require a weak reference, except when a cycle
    of references exist. Suppose a graph structure were to be constructed where each
    node holds an `Rc<T>` to its connected nodes and a cycle exists in the graph.
    Calling drop on the current node will recursively call drop on the connected nodes,
    which will recurse again onto the current node and so forth. Were the graph to
    store a vector of all nodes and have each node store weak references to connections,
    then a drop of the vector would cause a drop of all nodes, cycles or not. We can
    see how this works in practice by inspecting the `Drop` implementation of `Rc<T>`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'This is trimmed some for clarity but the notion is as we''ve described—when
    the total number of strong references is zero, a full deallocation occurs. The
    referenced `Heap` and `Layout` are compiler internals and won''t be discussed
    further here, but the interested reader is warmly encouraged to go spelunking
    on their own. Recall that in `Rc<T>::new`, both strong and weak counters started
    at `1`. To avoid invalidating the weak pointers, the actual `T` is only deallocated
    if there are no strong or weak pointers available. Let''s have a look at `Drop
    for Weak<T>`, again trimmed some for clarity:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: As expected, the `T` can only be deallocated when the weak pointer total falls
    to zero, which is only possible if there are no strong pointers left. That's `Rc<T>`—a
    handful of important traits, a specialized box, and a few compiler internals.
  prefs: []
  type: TYPE_NORMAL
- en: Vec
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As our last subject in this chapter, let's consider `Vec<T>`. The Rust vector
    is a growable array, that is, an area of contiguous, homogeneous storage that
    can be grown through reallocation as the need arises, or it cane be shrunk. The
    advantage compared to array is in not needing to know ahead of time exactly what
    size of storage you need, plus all the benefits of a slicable structure and additional
    functions in the type API. `Vec<T>` is an extremely common Rust structure, so
    much so that its actual name is `std::vec::Vec<T>` but Rust imports the type by
    default. Rust programs are full of vectors and it stands to reason we'd do well
    to understand how it interacts with the memory it holds.
  prefs: []
  type: TYPE_NORMAL
- en: '`Vec<T>` is defined in `src/liballoc/vec.rs` and is defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: 'The Rust documentation declares that a `Vec<T>` will be laid out as a pointer,
    a capacity of `usize`, and a length of `usize.` The order of these fields is completely
    unspecified. As we''ve already discussed, Rust will reorder fields as it sees
    fit. Moreover, the pointer is guaranteed to be non-null, allowing for a null-pointer
    optimization. Previously, we saw the usual trick of Rust: define a higher-level
    structure in terms of a lower-level—or raw – structure, or even in terms of a
    fully unsafe structure. We see the length `usize` already, called `len`. This
    means there''s a distinct difference between capacity and length, the distinction
    of which we''ll come back to as we dig into `RawVec<T>`. Let''s take a peek at
    `RawVec<T>`, defined in `src/liballoc/raw_vec.rs`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: 'What we have is a pointer to a `Unique<T>`, a `*mut T` with added guarantees
    that the `RawVec<T>` is the only possessor of the allocation and that the pointer
    is not null. The `cap` is the capacity of the raw vector. `a: A` is the allocator,
    `Heap` by default. Rust does allow for allocators to be swapped, so long as the
    implementation obeys—as of writing this book—the `std::heap::Alloc` trait. Swapping
    allocators is an unstable feature of Rust, available only in the nightly channel,
    but one that is stable enough to see common use in the embedded Rust community''s
    libraries. In this book, we won''t use anything other than the default allocator,
    but the reader is warmly encouraged to explore the topic in more detail. Allocator
    aside, there''s the pointers, length, and capacity that the Rust documentation
    promised. Let''s pop back to `Vec<T>` and take a look at `new`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, the new of raw `vec`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: 'This defers creation to `new_in`, a function on the same `trait`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: 'The `cap` computation is interesting. It''s possible to store a `T` in `Vec<T>`—and
    by extension `RawVec<T>`—that has zero size. The implementers knew this and came
    up with a fun solution: if the size of the type is zero, set the capacity to `usize::MAX`,
    else 0\. It''s not possible to cram `usize::MAX` elements into a vector since
    we''d run out of memory one allocation prior to hitting the cap and it''s now
    possible to discriminate the case of zero-sized types without having to introduce
    an enumeration or a flag variable. Tidy trick. If we bounce back to vector and
    inspect `with_capacity`, we''ll find that defers to `RawVec::with_capacity`, which
    defers to `RawVec::allocate_in`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: 'There''s a lot going on here, but it''s important, so let''s break it into
    small pieces. Firstly, see the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: 'At the head of the function, the size of the element is computed and the total
    allocation requested by the caller is confirmed to be no more than the available
    system memory. Note that `checked_mul` ensures we don''t overflow usize and accidentally
    allocate too little memory. Finally, a function called `alloc_guard` is called.
    That is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: 'This is a guarantee check. Remember that usize and isize are the signed and
    unsigned size of the system pointer. To understand this guard, we must understand
    the answer to two questions:'
  prefs: []
  type: TYPE_NORMAL
- en: On a given machine, how much memory can I allocate?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: On a given machine, how much memory can I address?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'It''s possible to allocate usize bytes from the operating system but here,
    Rust is checking that the allocation size is less than the maximum isize. The
    Rust reference ([https://doc.rust-lang.org/stable/reference/types.html#machine-dependent-integer-types](https://doc.rust-lang.org/stable/reference/types.html#machine-dependent-integer-types))
    explains why:'
  prefs: []
  type: TYPE_NORMAL
- en: '"The isize type is a signed integer type with the same number of bits as the
    platform''s pointer type. The theoretical upper bound on object and array size
    is the maximum isize value. This ensures that isize can be used to calculate differences
    between pointers into an object or array and can address every byte within an
    object along with one byte past the end."'
  prefs: []
  type: TYPE_NORMAL
- en: 'Combined with the capacity check from `checked_mul`, we know that the allocation
    is properly sized and that it''s addressable along the whole of itself:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: 'In the event that the desired capacity is zero *or* the size of `T` is zero,
    the implementation coerces the minimum alignment of `T` into a pointer to bytes,
    the `*mut u8`. This pointer is, well, it points nowhere useful but the implementation
    has avoided an allocation when there is nothing that could be allocated, whether
    there will never be anything to allocate because of zero-sized types or not. This
    is good, and all the implementation will have to do is be aware that when the
    capacity is zero, or if the type size is zero, the pointer cannot be dereferenced.
    Right:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: 'This branch is hit when there''s memory to be allocated. Notably, two sub-possibilities,
    controlled by the `zeroed` argument: either memory is zeroed or it is left uninitialized.
    `Vec<T>` does not expose this option to the end user but we know from inspection
    that memory starts off uninitialized, an optimization for non-trivial allocations:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: 'The lack of an initialization flag is kind of tricky in some cases. Consider
    `std::io::Read::read_exact`. This function takes a `&mut [u8]` and it''s common
    enough to create this slice from a specially created vec. This code will *not*
    read 1024 bytes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: 'Why? The slice that we pass in is actually of zero length! Rust dereferences
    are allowed on a type by two traits: `std::ops::Deref` and `std::ops::DerefMut`,
    depending on your desire for an immutable or mutable slide. The `Deref`  trait
    is defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: 'And the mutable version analogously. When we slice our vector as in the preceding
    code block, we''re calling this `DerefMut::deref`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: 'This is the very important part: `slice::from_raw_parts_mut(ptr, self.len)`.
    Vector slices are built by length, not capacity. The capacity of a vector serves
    to distinguish how much memory has been allocated versus how much memory has been
    initialized, either to zeros or some other inserted values. This is an important
    difference. It''s possible to initialize memory ourselves:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: 'Or to rely on the `Vec` API to convert from a fixed-size array:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: Either will work. Which you choose depends on if you know the size of the buffer
    ahead of time or not.
  prefs: []
  type: TYPE_NORMAL
- en: 'Befitting such an important type, there are a good many API functions on `Vec<T>`.
    In the remainder of this chapter, we''ll occupy ourselves with two mutations:
    `push` and `insert`. The `push` function is a constant operation, modulo any reallocations
    necessary to cope with the case of our capacity limit being reached. Here''s the
    `push` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: 'If you''ll recall, `self.buf` is the underlying `RawVec<T>`. The documentation
    for `Vec<T>` notes that when reallocation is required, the underlying memory will
    be doubled, which, it turns out, is handled by `RawVec<T>::double`. That function
    is fairly long and, as you might suspect, is a bunch of arithmetic to compute
    the new, doubled size matched with a realloc when there''s an existing allocation,
    else when there''s a new allocation. That is worth listing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs: []
  type: TYPE_PRE
- en: '`Alloc::alloc_array` allocates space for contiguous memory, which is suitable
    to hold `new_cap` number of elements the size of `T`, returning the pointer to
    the first address of this newly allocated space. Here then, is the contiguous
    memory promised in the documentation of `Vec<T>`! Back in `Vec<T>`, now that the
    capacity is twice that of what it was, at least, the value `T` can be inserted:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs: []
  type: TYPE_PRE
- en: Rust pointers are handy in that their offset function takes into account the
    size of `T`; there's no need to do additional multiplication as the caller. The
    implementation is determining the first of the unused `T` sized spaces in the
    contiguous allocation—denoted end—and then writes the moved `T` onto that address.
    The fact that the space is unused is important*, *`std::ptr::write` does not deallocate
    any memory that may have originally existed at the written-to pointer. If you
    `ptr::write` over the top of a live reference, wacky things will happen.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, `insert`. The `insert` function of `Vec<T>` allows for the insertion
    of `T` at any valid index in the vector. If the insertion is to the end of the
    vector, the method is functionally equivalent to pushing, though mechanically
    different, as we''ll see shortly. If, however, insertion occurs somewhere inside
    of the vector, all elements to the right of the insertion index are shifted over
    once, a non-trivial operation depending on the size of the allocation. Here''s
    the full listing of `insert`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs: []
  type: TYPE_PRE
- en: 'The index checking and potential buffering is straightforward at this point
    in the chapter. In the unsafe block, `p` is the proper offset for insertion. The
    two important lines are:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs: []
  type: TYPE_PRE
- en: When a value is inserted into a vector, no matter the location, all the memory
    starting from `p` to the end of the list is copied over the top of the memory,
    starting at `p+1`. Once this is done, the inserted value is written over the top
    of `p`. This is a non-trivial operation and can become incredibly slow, especially
    if the allocation to be shifted is fairly large. Performance-focused Rust will
    use `Vec::insert` sparingly, if at all. `Vec<T>` will almost surely make an appearance.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we covered the layout of Rust objects in memory, the way references
    work across both safe and unsafe Rust, and have addressed the various allocation
    strategies of a Rust program. We did a deep-dive on types in the Rust standard
    library to make these concepts concrete and it is hoped that the reader will now
    feel comfortable further exploring the compiler and will do so with confidence.
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The memory model of a programming language is a broad topic. Rust's, as of writing
    this book, must be understood from the inspection of the Rust documentation, the
    rustc source code, and research into LLVM. That is, Rust's memory model is not
    formally documented, though there are rumblings in the community of providing
    it. Independent of that, it is also important for the working programmer to understand
    the underlying machine. There's a staggering amount of material to be covered.
  prefs: []
  type: TYPE_NORMAL
- en: 'These notes are a small start, focusing especially on the Rust documentation
    that relates most to this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: '*High Performance Code 201: Hybrid Data Structures*, Chandler Carruth, available
    at [https://www.youtube.com/watch?v=vElZc6zSIXM&index=5&list=PLKW_WLANyJtqQ6IWm3BjzHZvrFxFSooey](https://www.youtube.com/watch?v=vElZc6zSIXM&index=5&list=PLKW_WLANyJtqQ6IWm3BjzHZvrFxFSooey).
    This, in point of fact, is a talk from CppCon 2016\. Carruth is an engaging speaker
    and is a member of the LLVM team focused on compiler performance. This talk is
    especially interesting from the point of view of building information-dense data
    structures that interact well with CPU caches. While the talk is in C++, the techniques
    apply directly to Rust.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Cache-oblivious Algorithms*, Matteo Frigo, Charles Leiserson, Harald Prokop,
    and Sridhar Ramachandran. This paper introduces the concept of building data structures
    that are cache oblivious, or, native to machines with memory hierarchies and interact
    with them well, in addition to a machine model to analyze such data structures.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Cache-Oblivious Algorithms and Data Structures*, Erik Demaine. This paper
    is a classic in the cache-oblivious space, building on the work presented in the
    last by Frigo et al and summarizing existing work. This is a highly recommended
    read, especially in conjunction with the previous paper. It is well worth scanning
    the bibliography as well.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*The Stack and the Heap*, available at [https://doc.rust-lang.org/book/first-edition/the-stack-and-the-heap.html](https://doc.rust-lang.org/book/first-edition/the-stack-and-the-heap.html). This
    chapter from the first edition of the Rust book explains the difference between
    the hardware stack and heap, allocations to each, and the implications for Rust.
    This chapter has gone into further detail in some areas, but the Rust book''s
    chapter is warmly recommended for anyone needing a refresher or a more gentle
    climb.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Splitting Borrows*, available at [https://doc.rust-lang.org/beta/nomicon/borrow-splitting.html](https://doc.rust-lang.org/beta/nomicon/borrow-splitting.html). The
    Nomicon is a Rust book intended to teach low-level Rust programming, not unlike
    this book. While it is a work-in-progress, the information in it is invaluable.
    *Splitting Borrows* explains the reasoning behind a common issue with new Rust
    developers: performing multiple mutable borrows out of a vector or array. The
    fact that this works with *structs* is often a source of great confusion and anguish.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Rust Reference*, available at [https://doc.rust-lang.org/reference/](https://doc.rust-lang.org/reference/). Like
    any established programming language, the Rust Reference is invaluable for understanding
    the subtle details of the language itself, which have been hashed out in mailing
    lists and over chat for years. The reference in its current form can be a touch
    hard to search—it used to be one long page—but it''s hoped the situation will
    be improved upon by the time our book here has gone to press.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Closures: Anonymous Functions that can Capture their Environment*, available
    at [http://doc.rust-lang.org/1.23.0/book/second-edition/ch13-01-closures.html](http://doc.rust-lang.org/1.23.0/book/second-edition/ch13-01-closures.html).
    Rust closures have some subtle implications to them that can be hard to internalize
    for new Rust developers. This chapter in the second edition of the Rust Book is
    excellent in this regard.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*External blocks*, available at [https://doc.rust-lang.org/reference/items/external-blocks.html](https://doc.rust-lang.org/reference/items/external-blocks.html). External
    blocks are relatively rare in this book—and, perhaps, in most of the Rust code
    you''re likely to see—but there''s a fair few of them available. It is well worth
    having a passing knowledge of this document''s existence.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Hacker''s Delight*, Henry Warren Jr.This book is a classic. Many of the tricks
    present in the book are now available as simple instructions on some chips, such
    as x86, but you''ll see the occasional delight here or there in the `rustc` source
    code, the `swap_nonoverlapping_bytes` trick especially.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
