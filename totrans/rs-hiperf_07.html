<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Built-in Macros and Configuration Items</h1>
                </header>
            
            <article>
                
<p class="mce-root">Now that we know how to improve our code efficiency, we can learn how to make it work on multiple platforms and how to make sure we take advantage of all possible native optimizations, while we make the code faster and easier to implement. Metaprogramming allows us to do all that with really easy code snippets, and you probably know some of these features.</p>
<p>In this chapter, you will learn how to use the following macros and configuration items built in with the compiler and the standard library:</p>
<ul>
<li>Attributes</li>
<li>Crate features</li>
<li>Macros</li>
<li>Nightly functionality</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Understanding attributes</h1>
                </header>
            
            <article>
                
<p>Rust allows us to conditionally compile certain parts of the code depending on what we call attributes. These attributes can be applied to either complete crates/modules or to specific functions, scopes, or even structure fields or enumeration variants. We saw some examples when we talked about Clippy, but these attributes allow for so much more that we will now look at them in depth.</p>
<p>Let's first see how an attribute works. An attribute that you want to apply to the whole current module/crate will be written like this: <kbd>#![{attribute}]</kbd>. Ones that apply to the scope/function/field/variant next to it will be written like this: <kbd>#[{attribute}]</kbd>. Note that the first has the <kbd>!</kbd> symbol between the hash tag and the attribute.</p>
<p>You have probably seen attributes such as <kbd>#[macro_use]</kbd> or <kbd>#[derive(Debug)]</kbd> somewhere in some code. The first one will allow using macros from an external crate, while the second one will derive the <kbd>Debug</kbd> trait in the given structure or enumeration. Let's start by checking what can we avoid typing thanks to the derivation of traits.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Trait derivations</h1>
                </header>
            
            <article>
                
<p>There are two types of trait derivations: built-in derives and custom derives. We will talk about the second ones in <a href="e869a4d7-e2a8-488a-a767-8c75364a8962.xhtml" target="_blank">Chapter 9</a>, <em>Creating Your Own Macros</em>, but let's see what deriving can help us achieve. Let's imagine the following structure:</p>
<pre style="padding-left: 60px">struct MyData {<br/>    field1: String,<br/>    field2: u64,<br/>}</pre>
<p>It's recommended that every structure implements the <kbd>Debug</kbd> trait so that if<span>, for example,</span> we need to debug what is happening with some part of the code, we can use the <kbd>println!("{:?}", element);</kbd> syntax. It should show the contents of the fields, so we could imagine something like the following:</p>
<pre style="padding-left: 60px">use std::fmt;<br/><br/>impl fmt::Debug for MyData {<br/>    fn fmt(&amp;self, f: &amp;mut fmt::Formatter) -&gt; fmt::Result {<br/>        write!(<br/>            f,<br/>            "MyData {{ field1: \"{}\", field2: {} }}",<br/>            self.field1, self.field2<br/>        )<br/>    }<br/>}</pre>
<p>This will print the field information. For example, suppose we have the following code:</p>
<pre style="padding-left: 60px">fn main() {<br/>    let data = MyData {<br/>        field1: "This is my string".to_owned(),<br/>        field2: 4402,<br/>    };<br/><br/>    println!("Data: {:?}", data);<br/>}</pre>
<p>We will receive this output:</p>
<pre><strong>Data: MyData { field1: "This is my string", field2: 4402 } </strong></pre>
<p>This is good, since it enables us to get information about our structure, but it's difficult to maintain and adds a lot of boilerplate code to our code base. Let's suppose we have a 20-field structure, and we need to remove 2 fields, and add 4 new ones. This rapidly escalates to a big mess. We will need to modify the trait implementation, maybe change the order of the fields, and so on.</p>
<p>This is where the <kbd>#[derive]</kbd> attribute comes into play: it will write that code for us, and if we change our structure it will rewrite that code. And, even better, it will not pollute our code base, since that code will be written at compile time. The whole <kbd>Debug</kbd> trait implementation can be replaced by adding <kbd>#[derive(Debug)]</kbd> to the beginning of the structure:</p>
<pre style="padding-left: 60px">#[derive(Debug)]<br/>struct MyData {<br/>    field1: String,<br/>    field2: u64,<br/>}</pre>
<p>And, if we run the program again, we will see that nothing has changed. There are multiple traits that can be derived: comparison traits (<kbd>PartialEq</kbd>, <kbd>Eq</kbd>, <kbd>PartialOrd</kbd>, and <kbd>Ord</kbd>), <kbd>Copy</kbd>, <kbd>Clone</kbd>, <kbd>Hash</kbd>, <kbd>Default</kbd> and, as we saw, <kbd>Debug</kbd>. Let's see what each of these traits does. We already talked about the <kbd>Debug</kbd> trait, so let's start with comparison traits.</p>
<p>The first two derivable traits are <kbd>PartialEq</kbd> and <kbd>Eq</kbd>. Both of them make it possible to use the <kbd>==</kbd> and the <kbd>!=</kbd> operators with the structure, but how do they work?</p>
<p><kbd>PartialEq</kbd> is meant to describe a partial equivalence relation, which means that if <em>A</em> is partially equal to <em>B</em>, <em>B</em> is partially equal to <em>A</em>, and if, in that example, <em>B</em> is partially equal to <em>C</em>, <em>A</em> is also partially equal to <em>C</em>, since the property is symmetric and transitive.</p>
<p>When derived for structures or enumerations, it will only be available if all members of the structure or enumeration already implement <kbd>PartialEq</kbd>, and it will consider two structures or enumerations equal if all of their fields are equal.</p>
<p>The <kbd>Eq</kbd> trait requires an extra condition, and it cannot be checked at compile time. It requires that <em>A</em> is equal to <em>A</em>. This might sound strange if we are talking about structures with simple fields, but there is a simple type in the standard library that shows the opposite behavior. The floating point types (<kbd>f32</kbd> and <kbd>f64</kbd>) do not respect this when they are <strong>NaN</strong> (<strong>Not a Number</strong>). Two <kbd>NaN</kbd> are not equal, even if both of them are <kbd>NaN</kbd>.</p>
<p>To derive the <kbd>Eq</kbd> trait, it requires all the fields in the structure or enumeration to implement <kbd>Eq</kbd>. This means that you will not be able to implement <kbd>Eq</kbd> for any structure or enumeration containing a floating point number. This trait does not require any method implementation, it just tells the compiler that the structure or enumeration is always equal to itself, without any extra code.</p>
<p>The next two traits, <kbd>PartialOrd</kbd> and <kbd>Ord</kbd>, work similarly to <kbd>PartialEq</kbd> and <kbd>Eq</kbd>, but they add the ability to compare two elements to know their order, so it allows you to use the <kbd>&lt;</kbd>, <kbd>&lt;=</kbd>, <kbd>=&gt;</kbd> and <kbd>&gt;</kbd> operators with the structure or enumeration. Both require that if <em>A &lt; B</em> and <em>B &lt; C</em>, then <em>A &lt; C</em> (and the same for <kbd>==</kbd> and <kbd>&gt;</kbd>), and that if <em>A &gt; B</em>, then <em>A &lt; B</em> is false. The <kbd>Ord</kbd> trait also requires that one and only one of <em>A &lt; B</em>, <em>A == B</em>, or <em>A &gt; B</em> is true.</p>
<p>As an extra point of information, the <kbd>PartialOrd</kbd> trait adds a <kbd>partial_cmp()</kbd> function, while the <kbd>Ord</kbd> trait adds the <kbd>cmp()</kbd> function. Both return an <kbd>Ordering</kbd>, but for the first function, it is optional (<kbd>Option&lt;Ordering&gt;</kbd>) and for the second one, it is mandatory. This is because a partial comparison could not have any defined order for a particular value; remember the <kbd>NaN</kbd> case for floats.</p>
<p>Implementing this function for structures that contain only <kbd>PartialOrd</kbd> or <kbd>Ord</kbd> fields is pretty easy: define which is the most relevant field for ordering and compare them between structures, then, if equal, compare the next relevant field. This can be avoided by using <kbd>#[derive(PartialOrd)]</kbd> or <kbd>#[derive(PartialOrd, Ord)]</kbd>.</p>
<p>The derivation will compare fields from first to last, so make sure you put the most relevant fields first. In the case of enumerations, it will consider first variants <em>smaller</em> than latest variants. If you want to change that, you can either change the order of fields or variants, or implement the trait yourself. You might also want to only compare one of the fields of a structure and consider the rest irrelevant. In this case, you will need to implement the trait yourself.</p>
<p>To implement any of these traits, you can simply compare the fields one by one. Note that <kbd>Ord</kbd> requires <kbd>Eq</kbd>, so we need to implement <kbd>PartialEq</kbd> to check only the day, month, and year and then derive <kbd>Eq</kbd>. You can check the details of the implementation as follows:</p>
<pre style="padding-left: 60px">use std::cmp::Ordering;<br/><br/>#[derive(Eq)]<br/>struct DateNotes {<br/>    day: u8,<br/>    month: u8,<br/>    year: i32,<br/>    comment: String,<br/>}<br/><br/>impl PartialEq for DateNotes {<br/>    fn eq(&amp;self, other: &amp;Self) -&gt; bool {<br/>        self.day == other.day &amp;&amp; self.month == other.month &amp;&amp; self.year == other.year<br/>    }<br/>}<br/><br/>impl Ord for DateNotes {<br/>    fn cmp(&amp;self, other: &amp;Self) -&gt; Ordering {<br/>        match self.year.cmp(&amp;other.year) {<br/>            Ordering::Equal =&gt; match self.month.cmp(&amp;other.month) {<br/>                Ordering::Equal =&gt; self.day.cmp(&amp;other.day),<br/>                o =&gt; o,<br/>            },<br/>            o =&gt; o,<br/>        }<br/>    }<br/>}<br/><br/>impl PartialOrd for DateNotes {<br/>    fn partial_cmp(&amp;self, other: &amp;Self) -&gt; Option&lt;Ordering&gt; {<br/>        Some(self.cmp(other))<br/>    }<br/>}</pre>
<p>In this example, we compare the date by first checking the year. If the year is the same, we compare the month, and if the month is equal, we compare the day. We do not check which comments are associated to the date because we do not need to. The <kbd>PartialOrd</kbd> trait implementation only returns the result from the <kbd>Ord</kbd> trait wrapped in an <kbd>Option::Some</kbd>.</p>
<p>The next two, the <kbd>Copy</kbd> and <kbd>Clone</kbd> traits, allow for a structure to be copied in memory. This means that you will be able to copy, one by one, all the contents of the instance to another instance. The <kbd>Clone</kbd> trait enables this by adding the <kbd>clone()</kbd> method, which usually only calls the <kbd>clone()</kbd> method of each of the fields. It can run any arbitrary code, though, and you never know whether it will be expensive to clone the object or not. This is why using it requires an explicit call to the <kbd>clone()</kbd> method.</p>
<p>The <kbd>Copy</kbd> trait, on the other hand, makes it implicit to copy one element. It means that, for example, when moving a variable to a function, if it's a <kbd>Copy</kbd> variable, you will be able to still use it after the move, because only a copy of it will be moved. We saw some examples of the benefits and drawbacks of this approach in <a href="ad672e4d-0f5e-4c59-b823-249da183abc8.xhtml" target="_blank">Chapter 1</a>,<em> Common Performance Pitfalls</em>.</p>
<p>You cannot implement the <kbd>Copy</kbd> trait, though, since Rust requires it to be extremely inexpensive and it's implemented using compiler intrinsics. So, you can safely use a <kbd>Copy</kbd> type knowing it will not be expensive to copy it, but you cannot implement it by yourself. You can derive it though. Deriving <kbd>Copy</kbd> for a structure or an enumeration requires the structure or enumeration to implement <kbd>Clone</kbd> (you can derive it too if all elements inside implement <kbd>Clone</kbd>) and all elements inside to implement <kbd>Copy</kbd>.</p>
<p>So, you can derive <kbd>Copy</kbd> for a structure with basic types such as the following:</p>
<pre style="padding-left: 60px">#[derive(Clone, Copy)]<br/>struct MyData {<br/>    field1: u64,<br/>    field2: f64,<br/>    field3: i32,<br/>}</pre>
<p>But, you cannot derive it for structures with complex non-copyable types:</p>
<pre style="padding-left: 60px">#[derive(Clone)]<br/>struct MyData {<br/>    field1: String,<br/>    field2: Vec&lt;u32&gt;,<br/>    field3: i32,<br/>}</pre>
<p>You can derive <kbd>Clone</kbd> in most cases, though, since most of the standard library types implement it. But, remember that the <kbd>clone()</kbd> method is usually expensive and should not be used too much. In fact, it's commonly said that if you use the <kbd>clone()</kbd> method directly, you are probably doing something wrong, and in most cases, it's true that other methods, such as <kbd>to_owned()</kbd> or <kbd>into()</kbd>, will do the trick more efficiently.</p>
<div class="packt_infobox"><kbd>to_owned()</kbd> will get the owned version of a variable, which in slices and strings means only to <kbd>memcpy()</kbd> the heap. The <kbd>into()</kbd> method, on the other hand, will use the specialized conversion implementation so that it produces the best output code. Both of them will change the type of the variable. Finally, <kbd>clone()</kbd> is usually generic, which means it will call <kbd>clone()</kbd> for each of its member attributes, making it slower sometimes.</div>
<p>Let's now talk about the <kbd>Hash</kbd> trait. This trait enables the use of the given structure or enumeration as a key in hashed structures such as <kbd>HashMap</kbd>. It gives us the possibility to hash the structure with a <kbd>Hasher</kbd> to get a hash of the information contained. A <kbd>Hasher</kbd> is a trait that receives input such as bytes or numbers, and once you call <kbd>finish()</kbd> on it, it will return a <kbd>u64</kbd> with the hash value.</p>
<p>Since <kbd>Hasher</kbd> is a trait, implementation details are not provided by the trait itself, but as we saw in <a href="da2d0480-3314-408b-9cad-60987754f45d.xhtml" target="_blank">Chapter 2</a>, <em>Extra Performance Enhancements</em>, some default implementations are provided in the standard library: <kbd>SipHasher</kbd>, <kbd>SipHasher13</kbd>, <kbd>SipHasher24</kbd>, and <kbd>DefaultHasher</kbd>. We have already seen some differences between them.</p>
<p>The main idea behind the <kbd>Hash</kbd> trait is that it enables hashing any structure and does not limit <kbd>HashMap</kbd> keys, for example, to be bytes or numbers. You could implement the trait yourself for your structure (if you want to fine-tune how the hashing is done), but if what you want is to simply be able to use your structure or enumeration as a key in a <kbd>HashMap</kbd>, you can simply derive the <kbd>Hash</kbd> trait and the compiler will write that code for you.</p>
<p>Not only that, you will probably want to also implement the <kbd>Eq</kbd> trait for it since, for <kbd>HashMap</kbd> keys, it's required. If you implement it yourself, you will need to make sure that if <em>A = B</em> then <em>hash(A) = hash(B)</em>, which might not be trivial. The best thing is to simply derive both. Let's check this example code with the structure we defined earlier:</p>
<pre style="padding-left: 60px">use std::collections::HashMap;<br/><br/>#[derive(Clone, Hash, PartialEq, Eq)]<br/>struct MyData {<br/>    field1: String,<br/>    field2: Vec&lt;u32&gt;,<br/>    field3: i32,<br/>}<br/><br/>fn main() {<br/>    let key1 = MyData {<br/>        field1: "myField".to_owned(),<br/>        field2: vec![0, 1, 2],<br/>        field3: 1898,<br/>    };<br/><br/>    let key2 = key1.clone();<br/><br/>    let key3 = MyData {<br/>        field1: "myField2".to_owned(),<br/>        field2: vec![5, 3, 1],<br/>        field3: 2345,<br/>    };<br/><br/>    let mut map = HashMap::new();<br/>    map.insert(key1, "MyFirst");<br/><br/>    assert!(map.get(&amp;key2).is_some());<br/>    assert!(map.get(&amp;key3).is_none());<br/>}</pre>
<p>Here, we first derive <kbd>Hash</kbd>, <kbd>PartialEq</kbd>, and <kbd>Eq</kbd> in the <kbd>MyData</kbd> structure, then we create two identical keys and a different one. I used clone for easier understanding, but creating another one with the same values would work too. We add a value to the map using the first key and check whether we can retrieve the element with the clone of the key without any issues. If we try with a different key, though, we won't be able to get the value. You can also check that if the <kbd>MyData</kbd> structure does not implement <kbd>Eq</kbd> or <kbd>Hash</kbd>, you won't be able to use the <kbd>HashMap</kbd> with it as a key.</p>
<p>As before, the only requirement for a structure to derive <kbd>Hash</kbd> is that all of its members already implement it, and most of the standard library types implement <kbd>Hash</kbd>. The default implementation will simply hash all attributes one by one with the given <kbd>Hasher</kbd>, which is what you would probably implement manually. An example of this implementation could be the following:</p>
<pre style="padding-left: 60px">use std::hash::{Hash, Hasher};<br/><br/>impl Hash for MyData {<br/>    fn hash&lt;H&gt;(&amp;self, state: &amp;mut H)<br/>    where<br/>        H: Hasher,<br/>    {<br/>        self.field1.hash(state);<br/>        self.field2.hash(state);<br/>        self.field3.hash(state);<br/>    }<br/>}</pre>
<p>As you can see, it's simple code, but you will keep everything cleaner and easier to maintain if you derive it. Implementing it yourself, though, can help you deal with fields that do not implement <kbd>Hash</kbd>, custom hashing techniques or avoiding some fields to be hashed for a little better performance if the comparison of the structure is still valid without taking them into account.</p>
<p>Finally, the last trait that you can derive out of the box with Rust is the <kbd>Default</kbd> trait. This trait gives the structure, or enumeration, a <kbd>default()</kbd> method that will create a structure with default values. These default values are, for example, <kbd>0</kbd> for numbers, empty strings for strings, empty vectors for vectors, and so on. It's usually used as a placeholder for future calculations.</p>
<p>If you have a structure where you would like to have a default value, you can implement the <kbd>Default</kbd> trait. And, doing it can be as simple as giving a value to each of the attributes. If you don't need particular default value (all zeros is OK with you), you will probably prefer to simply derive the <kbd>Default</kbd> trait. Let's check an example with the <kbd>MyData</kbd> structure:</p>
<pre style="padding-left: 60px">#[derive(Debug, Default)]<br/>struct MyData {<br/>    field1: String,<br/>    field2: Vec&lt;u32&gt;,<br/>    field3: i32,<br/>}<br/><br/>fn main() {<br/>    let test1 = MyData {<br/>        field1: "sth".to_owned(),<br/>        ..Default::default()<br/>    };<br/>    let test2 = MyData::default();<br/><br/>    println!("test1: {:?}", test1);<br/>    println!("test2: {:?}", test2);<br/>}</pre>
<p>As you can see, I derived the <kbd>Default</kbd> trait (and the <kbd>Debug</kbd> trait, just to print the structure). This allows to create the <kbd>test2</kbd> variable by only calling <kbd>MyData::default()</kbd>. You can also call <kbd>Default::default()</kbd> if you give a type hint for the variable:</p>
<pre style="padding-left: 60px">let test3: MyData = Default::default();</pre>
<p>As you can see, if some fields of a structure implement <kbd>Default</kbd>, you can use the trait to complete the fields you don't want to specify, as you can see with the <kbd>test1</kbd> variable. Simply specify the non-default fields, and then, after the last comma, add a couple of periods (<kbd>..</kbd>) and then <kbd>Default::default()</kbd>, so that the compiler uses the <kbd>Default</kbd> trait to fill the other fields. You can use any function that is generic over the rest of the fields with this syntax.</p>
<p>As you can see, the <kbd>Default</kbd> trait is a pretty useful trait and if you don't need any special treatment of any field for the default value of your structure, deriving it is a great idea. A potential implementation that you would be avoiding by doing this is the following:</p>
<pre style="padding-left: 60px">impl Default for MyData {<br/>    fn default() -&gt; Self {<br/>        Self {<br/>            field1: Default::default(),<br/>            field2: Default::default(),<br/>            field3: Default::default(),<br/>        }<br/>    }<br/>}</pre>
<p>As you can see, deriving it makes your work much easier. You can use this implementation, though, to customize any of the fields for a default instance of your structure, which could be a good idea if, for example, you would like all your structures to have the string field set to <kbd>"This is my data"</kbd> by default. Implementing it yourself will also enable you to customize it if any of your fields do not implement <kbd>Default</kbd>, which is rarely the case if using types of the standard library.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Crate features</h1>
                </header>
            
            <article>
                
<p>The second, very interesting, attribute use is to enable crate features. These features might encapsulate some functionality that some people using the crate don't need, therefore making it optional to compile. The Rust compiler will remove any unused code during the compilation, but not having some part of the code compile from the beginning will speed up the process.</p>
<p>You can define crate features in the <kbd>Cargo.toml</kbd> file by using the <kbd>[features]</kbd> section. You can specify some default features for the crate that will be built if nothing is specified:</p>
<pre style="padding-left: 60px">[features]<br/>default = ["add"]<br/>add = []<br/>multiply = ["expensive_dependency"]</pre>
<p>In this example, two features have been defined, the <kbd>add</kbd> feature and the <kbd>multiply</kbd> feature. The <kbd>add</kbd> feature does not have any extra dependency, but the <kbd>multiply</kbd> feature depends on the <kbd>expensive_dependency</kbd> crate. By default, only the <kbd>add</kbd> feature will be built. If this were a binary crate, you could specify which features to build with the <kbd>--features</kbd> command-line option for <kbd>cargo</kbd>:</p>
<pre><strong>cargo build --features "multiply"</strong></pre>
<p>If you want to opt out of default features, simply run it with the <kbd>--no-default-features</kbd> command-line option. If you want to use a crate that has features as a dependency for your project, you can specify which features to include when declaring the dependency in the <kbd>Cargo.toml</kbd> file:</p>
<pre style="padding-left: 60px">[dependencies.my_dep]<br/>version = "1.0"<br/>default-features = false<br/>features = ["nice_feat"]</pre>
<p>The <kbd>[section.subsection]</kbd> syntax is only so that we do not need to add an inline object to the <kbd>dependencies</kbd> section. In this case, it opts out of the default features and requests the <kbd>nice_feat</kbd> feature.</p>
<p>But, how does this look in the code? Let's see. If we have an <kbd>add</kbd> feature as we saw before, we might add an attribute to enable one function, or module, only for that case:</p>
<pre style="padding-left: 60px">#[cfg(feature = "add")]<br/>pub fn add(a: i32, b: i32) -&gt; i32 {<br/>    a + b<br/>}</pre>
<p>This will only be compiled when the <kbd>add</kbd> feature is requested. We already saw a similar syntax when using <kbd>cargo clippy</kbd>, since it will request the <kbd>cargo-clippy</kbd> feature from our crate, enabling us to cherry-pick the lints.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Configuration attributes</h1>
                </header>
            
            <article>
                
<p>The final type of attributes are <kbd>#[cfg]</kbd> attributes. These attributes are incredibly powerful, enabling us to compile certain parts of the code depending on the target we are compiling to. For example, we might want to use a specific Windows function and have a backup one for the rest, or we might want the code to do different things in little- and big-endian machines.</p>
<p>The syntax is pretty easy. For example, if you want to check the system architecture, you can use <kbd>#[cfg(target_arch = "arm")]</kbd>, and instead of ARM, you can check for <kbd>"x86"</kbd>, <kbd>"x86_64"</kbd>, <kbd>"mips"</kbd>, <kbd>"powerpc"</kbd>, <kbd>"powerpc64"</kbd>, or <kbd>"aarch64"</kbd> too. To compile something only for FreeBSD, we can use <kbd>#[cfg(target_os = "freebsd")]</kbd>. You can compare the <kbd>target_os</kbd> configuration attribute with <kbd>"windows"</kbd>, <kbd>"macos"</kbd>, <kbd>"ios"</kbd>, <kbd>"linux"</kbd>, <kbd>"android"</kbd>, <kbd>"freebsd"</kbd>, <kbd>"dragonfly"</kbd>, <kbd>"bitrig"</kbd> , <kbd>"openbsd"</kbd>, or <kbd>"netbsd"</kbd>.</p>
<p>If you only care about Windows/Unix differences, you can use <kbd>#[cfg(target_family = "windows")]</kbd> or <kbd>#[cfg(target_family = "unix")]</kbd>, or even directly <kbd>#[windows]</kbd> and <kbd>#[unix]</kbd>. This can be specified further by using <kbd>#[cfg(target_env = "gnu")]</kbd>, or <kbd>"msvc"</kbd>, or <kbd>"musl"</kbd>. The endianness of the system can be checked with <kbd>#[cfg(target_endian = "little")]</kbd> or <kbd>#[cfg(target_endian = "big")]</kbd>, and the pointer width (32 or 64 bits) with <kbd>#[cfg(target_pointer_width = "32")]</kbd> or <kbd>#[cfg(target_pointer_width = "64")]</kbd> respectively.</p>
<p>More complex details can also be checked, such as whether the target has atomic integer types, and what size those atomic integers are. For example, to check whether the target platform has atomic 8 bit integers, you will use <kbd>#[cfg(target_has_atomic = "8")]</kbd>. You can check for <kbd>8</kbd>, <kbd>16</kbd>, <kbd>32</kbd>, <kbd>64</kbd>, and pointer width integers (with <kbd>"ptr"</kbd>). You can even check the vendor of the target architecture by checking <kbd>#[cfg(target_vendor = "apple")]</kbd>. You can check for <kbd>"apple"</kbd>, <kbd>"pc"</kbd>, or <kbd>"unknown"</kbd>.</p>
<p>Finally, a couple of attributes let you know whether you are doing a test (using <kbd>#[test]</kbd>) and whether the debug assertions are turned on (using <kbd>#[debug_assertions]</kbd>). The first one could be useful if you want to change any particular behavior only for tests (not recommended; tests should run the same code as in production), and the second one lets you, for example, add some debug information if the application was compiled in debug mode.</p>
<p>You can set/use a configuration item selectively by using <kbd>#[cfg_attr(a, b)]</kbd>. This will have the same effect as doing <kbd>#[b]</kbd>, but will only do something if <kbd>a</kbd> is true. If it's false, it will be like nothing was written. This is useful, for example, if you want to enable or disable lints depending on other attributes, or if you want to derive a trait only for certain targets, and implement it for the rest.</p>
<p>You can also check these configuration attributes in the code inside the logic by using the <kbd>cfg!()</kbd> macro. Simply use the same syntax as with attributes:</p>
<pre style="padding-left: 60px">if cfg!(target_pointer_width = "32") {<br/>    do_something();<br/>}</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Macros</h1>
                </header>
            
            <article>
                
<p>One of the most useful Rust functionalities is its macro ecosystem. You probably already know the <kbd>println!()</kbd> macro, but there are many more. These macros allow you to write complex boilerplate code (such as <kbd>stdio</kbd> handling in the <kbd>println!()</kbd> case) in a simple way and without having to add a ton of boilerplate code. Let's check out some of the most used ones.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Console printing</h1>
                </header>
            
            <article>
                
<p>When you need to lock the standard I/O interface, then write bytes to it, and finally flush it for each call, the <kbd>print!()</kbd> and <kbd>println!()</kbd> macros allow you to do that by just giving them a formatting static string and a series of parameters. Not only that, you can use the whole <kbd>std::fmt</kbd> module to specify number precision, format things in debug mode, and so on.</p>
<p>Similar macros exist for the standard error output interface or <kbd>stderr</kbd>. They are called <kbd>eprint!()</kbd> and <kbd>eprintln!()</kbd>, and allow you to easily print in <kbd>stderr</kbd> with the same format as <kbd>print!()</kbd> and <kbd>println!()</kbd>. The four macros use the syntax from the <kbd>format!()</kbd> macro, which we will see next.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">String formatting</h1>
                </header>
            
            <article>
                
<p>Creating strings is easy: you just call <kbd>String::new()</kbd> and then use a static string or add characters to it. Sometimes, you might want easier access to how the string gets created. If you, for example, want the string to say <kbd>Hello {user}!</kbd>, even though you can probably do something such as creating a <kbd>String</kbd> with <kbd>Hello</kbd> in it, then appending the username and then the exclamation mark, this is not ideal.</p>
<p>This is where the <kbd>std::fmt</kbd> module comes in handy, with its <kbd>format!()</kbd> macro and all of its formatting options. These options apply to console printing, string formatting, and even buffer writing with <kbd>write!()</kbd> and <kbd>writeln!()</kbd> macros. You can find the complete guide in the <kbd>std::fmt</kbd> module documentation at the standard library documentation, by running <kbd>rustup doc --open</kbd>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Compilation environment</h1>
                </header>
            
            <article>
                
<p>You can check environment variables at compile time by using the <kbd>env!("VAR")</kbd> and <kbd>option_env!("VAR")</kbd> macros. The first will retrieve the environment variable as <kbd>&amp;'static str</kbd>. If the variable is not defined, the compilation will fail. The <kbd>option_env!()</kbd> macro avoids this by returning an <kbd>Option::None</kbd> if the environment variable is not set and an <kbd>Option::Some(&amp;'static str)</kbd> if the variable is set:</p>
<pre style="padding-left: 60px">const THE_KEY: &amp;str = env!("KEY");</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Loading byte arrays and strings at compile time</h1>
                </header>
            
            <article>
                
<p>You can load various types of constants at compile time. The <kbd>include_bytes!()</kbd> macro will create a byte (<kbd>u8</kbd>) array with the contents of the specified file. The <kbd>include_str!()</kbd> macro, on the other hand, will get the contents of the file as a string and create a <kbd>&amp;static str</kbd>. Both will make the compilation fail if the file does not exist at compile time.</p>
<p>You can also use the <kbd>include!()</kbd> macro that will include the code of the given file and add it to the current file at compile time. The compilation will also fail if the code in that file is not valid Rust code:</p>
<pre style="padding-left: 60px">const CRATE_CONFIG: &amp;str = include_str!("../Cargo.toml");</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Code paths</h1>
                </header>
            
            <article>
                
<p>Some paths should never be traversed and, in our code, that is usually a condition for our code to work properly. If we are receiving bad input data, we might want to return an error, but if our library is being misused, we might prefer to panic. Sometimes, we also want to make sure that it's impossible for a variable to be out of some bounds once it gets to the logic of our function, to avoid security flaws, for example. In those cases, the <kbd>unreachable!()</kbd> macro, or even the explicit <kbd>panic!()</kbd> macro, can help us.</p>
<p>There is another path that might not be ready to be traversed yet. While our crate is being implemented, we can use the <kbd>unimplemented!()</kbd> macro, as we saw before in some examples, to indicate that the code we are writing is not implemented. This will enable the code to compile but, if executed, it will panic with the <em>not yet implemented</em> message.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Checking preconditions and postconditions</h1>
                </header>
            
            <article>
                
<p>When testing, and even in our everyday code, we probably want to have some preconditions to our functions, or we might want to check some postconditions. We use assertions for this. They come in two variants, debug assertions and normal assertions.</p>
<p>Normal assertions will always be checked, but will slow down your production code since they need to run every time. Debug assertions will only run when compiling in debug mode, so you will be able to catch errors then, and the production code will run without performance issues.</p>
<p>In general, you should use all the debug assertions you can, and use normal assertions only in places where you receive output from the user or another crate (if building a library).</p>
<p>The three macros are <kbd>assert!()</kbd>, <kbd>assert_eq!()</kbd>, and <kbd>assert_ne!()</kbd>, and their debug counterparts are <kbd>debug_assert!()</kbd>, <kbd>debug_assert_eq!()</kbd>, and <kbd>debug_assert_ne!()</kbd>. The first accepts a Boolean returning expression as the first argument and an optional second argument can contain a message that will be printed when panicking if the first argument is false.</p>
<p>The other two macros accept two arguments that will be compared between them and a third optional comment string. The <kbd>assert_eq!()</kbd> macro will panic if the two elements are different and the <kbd>assert_ne!()</kbd> will panic if they are equal.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Others</h1>
                </header>
            
            <article>
                
<p>There are many more macros. We have already used some of them, such as the <kbd>cfg!()</kbd> and <kbd>vec![]</kbd> macros. You can also cause an explicit compile error with the <kbd>compile_error!("message")</kbd> macro, or use the <kbd>file!()</kbd>, <kbd>line!()</kbd>, and <kbd>column!()</kbd> macros to get the current position in the code, or even the <kbd>module_path!()</kbd> macro to get the current module.</p>
<p>If you want to know more, open the standard library documentation by running <kbd>rustup doc --open</kbd> and check out the rest of the macros there.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Nightly Rust</h1>
                </header>
            
            <article>
                
<p>Nightly Rust can speed up your code even more in certain situations. If you don't need compatibility with stable Rust, you might want to check all the nightly features. In some cases, such as kernel development, it's impossible to get all the required functionality using stable Rust. You can use nightly Rust by overriding the default compiler:</p>
<pre><strong>rustup override add nightly</strong></pre>
<p>Or, you can call cargo with the <kbd>+nightly</kbd> flag. These methods will only work if you use <kbd>rustup</kbd> to manage your Rust installation, which you probably should if you have the option.</p>
<p>To use nightly features, you will need to use the <kbd>#![feature]</kbd> attribute at the crate level. For example, if you want to use the <kbd>conservative_impl_trait</kbd> feature, you will need to add <kbd>#![feature(conservative_impl_trait)]</kbd> to the beginning of your <kbd>main.rs</kbd> or <kbd>lib.rs</kbd> files.</p>
<p>Let's see some of the most interesting unstable features. Note that these features will probably change rapidly, and they might have already changed by the time you read this book. Always check the latest Rust's unstable feature list (<a href="https://doc.rust-lang.org/unstable-book/the-unstable-book.html">https://doc.rust-lang.org/unstable-book/the-unstable-book.html</a>) to get the latest information. There are dozens of features and it's impossible to check all of them in this chapter, but here you can find an explanation of the most relevant ones so that you understand what can they do for you and how you can use them to improve the performance of your applications.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Conservative trait return</h1>
                </header>
            
            <article>
                
<p>This feature enables you to directly return a trait from a function. This means that in stable Rust, you will need to write this if you want to return a type that implements a trait without specifying the type:</p>
<pre style="padding-left: 60px">fn iterate_something() -&gt; Box&lt;Iterator&lt;Item = u32&gt;&gt; {<br/>    unimplemented!()<br/>}</pre>
<p>This means that, before returning the iterator, you will need to move all of its information to the heap (this is done easily, but is costly with <kbd>Box::new()</kbd>) and then return it. This should not be necessary, since Rust should be able to know what type you are returning at compile time and allocate stack accordingly, then only let you use the trait, since it's what you specified beforehand.</p>
<p>Well, this has already been implemented in nightly Rust, but you will need to use the <kbd>conservative_impl_trait</kbd> feature:</p>
<pre style="padding-left: 60px">#![feature(conservative_impl_trait)]<br/><br/>fn iterate_something() -&gt; impl Iterator&lt;Item = u32&gt; {<br/>    (0..3).into_iter()<br/>}</pre>
<p>This allows Rust to use the stack directly, which will avoid a costly allocation and make your code faster.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Constant functions</h1>
                </header>
            
            <article>
                
<p>The <kbd>const_fn</kbd> feature enables you to declare some functions as constant so that they can receive constant arguments at compile time and be executed then instead of at runtime. This is particularly useful for constructors or for constants that need to create an object as soon as possible.</p>
<p>For this last option, we have the <kbd>lazy_static!{}</kbd> macro, as we will see in the next chapter, but this macro runs all of its code at its first use, and not at compile time. Doing it at compile time would make compilations take a bit longer, but when running, it would not require computing anything as everything would already be a constant. It seems that not all <kbd>lazy_static!{}</kbd> cases can be solved with <kbd>const_fn</kbd>, though.</p>
<p>Let's see what it looks like:</p>
<pre style="padding-left: 60px">#![feature(const_fn)]<br/><br/>const FIRST_CONST: MyData = MyData::new(23, 275);<br/>const SECOND_CONST: MyData = MyData::new(336, 7);<br/><br/>#[derive(Debug)]<br/>struct MyData {<br/>    field1: u32,<br/>    field2: f32,<br/>}<br/><br/>impl MyData {<br/>    pub const fn new(a: u32, b: u32) -&gt; MyData {<br/>        MyData {<br/>            field1: a / b,<br/>            field2: b as f32 / a as f32,<br/>        }<br/>    }<br/>}<br/><br/>fn main() {<br/>    println!("FIRST_CONST: {:?}", FIRST_CONST);<br/>    println!("SECOND_CONST: {:?}", SECOND_CONST);<br/><br/>    let third = MyData::new(78, 22);<br/>    println!("third: {:?}", third);<br/>}</pre>
<p>In this case, as you can see, we created two constants that use the <kbd>MyData::new()</kbd> method to create them. The same method is then used at runtime in the <kbd>main()</kbd> function. The things you can do in a constant function are very limited. You cannot, for example, create bindings, and if you call another function or macro, it must also be constant. But you can still do pretty complex operations that won't affect the performance of the application. As you can imagine, this is the output of this code:</p>
<pre class="mce-root"><strong>FIRST_CONST: MyData { field1: 0, field2: 11.956522 }</strong><br/><strong>SECOND_CONST: MyData { field1: 48, field2: 0.020833334 }</strong><br/><strong>third: MyData { field1: 3, field2: 0.2820513 }</strong></pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Inline assembly and naked functions</h1>
                </header>
            
            <article>
                
<p>This might be one of the most interesting nightly features of Rust. Using <kbd>#[feature(asm)]</kbd>, we will get a new macro, <kbd>asm!()</kbd>, which we will be able to use in our code. With this macro, we can write inline assembly to perform fine-grained operations in the code if we need further performance optimizations.</p>
<p>The exact syntax is still being worked on, but it already enables you to write arbitrary assembly code within your functions. This is a must for kernel development, for example, where access to CPU features can only be done by direct CPU instructions. Make sure you thoroughly test this code, since it will be unsafe to use it.</p>
<p>Furthermore, <kbd>#[feature(naked_functions)]</kbd> allows you to add the <kbd>#[naked]</kbd> attribute to a function. This will remove some boilerplate assembly that gets added before and after each function so that you can write plain assembly code. Many times, this is essential for using some CPU intrinsics.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Using bigger integers</h1>
                </header>
            
            <article>
                
<p>The <kbd>i128_type</kbd> feature gives us the <kbd>i128</kbd> and <kbd>u128</kbd> integers, which work the same way as <kbd>i64</kbd> and <kbd>u64</kbd> types, but with 128 bits instead of 64, which gives them more capacity. They have the same API as the rest of the integers, so you can perform the same kind of operations. Sometimes it's great to have a bigger, full-precision integer and, in this case, since it uses LLVM intrinsics, the type is almost as lightweight as a <kbd>u64</kbd> or <kbd>i64</kbd> (more or less double the processing time in a 64-bit machine; it should be around the same in a 128-bit machine). A simple example is given in the main documentation:</p>
<pre style="padding-left: 60px">#![feature(i128_type)]<br/><br/>fn main() {<br/>    assert_eq!(1u128 + 1u128, 2u128);<br/>    assert_eq!(u128::min_value(), 0);<br/>    assert_eq!(u128::max_value(),<br/>               340282366920938463463374607431768211455);<br/><br/>    assert_eq!(1i128 - 2i128, -1i128);<br/>    assert_eq!(i128::min_value(),<br/>               -170141183460469231731687303715884105728);<br/>    assert_eq!(i128::max_value(),<br/>               170141183460469231731687303715884105727);<br/>}</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Single instruction multiple data</h1>
                </header>
            
            <article>
                
<p> The <strong>single instruction multiple data</strong> (<strong>SIMD</strong>) CPU features have revolutionized the way operations are performed in our CPUs. Using processor-specific features, we can now run the same operation with multiple inputs simultaneously. Let's suppose that we need to add four numbers in pairs. We could first add the first two and then the second two, and get the two results. SIMD allows us to compute both results at the same time, by applying that adding operation to both pairs at the same time.</p>
<p>This requires assembly, though, and even though LLVM does the best job it can to use as much SIMD as possible, it's sometimes not enough for some high-performance applications. We could use inline assembly, of course, but it's not rare to mess things up when using assembly, and you will need to rewrite it for each target, so a SIMD specific frontend is being developed.</p>
<p>The API is still a work in progress, but check the <kbd>simd</kbd> feature to get a grasp on how it will be done. It seems, for now, that an external crate will be developed with all the intrinsics. You will be able to generate groups of data and apply simultaneous operations to every element in supporting processors.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Allocation API</h1>
                </header>
            
            <article>
                
<p>Some specific projects require the ability to change the default heap allocation algorithm. Rust uses jemalloc by default for targets that allow it. As we saw in previous chapters, one of the features of this allocator is that, in collections, it will allocate the multiple of two of the last allocations.</p>
<p>You can change that by using the <kbd>alloc</kbd>, <kbd>allocator_api</kbd>, <kbd>alloc_jemalloc</kbd>, and <kbd>alloc_system</kbd> features. The last two specify the global allocator of the crate, which, in cases such as kernel development, must be specified and some functions implemented so that collections work. The other two allow for more customized allocator manipulation, <span>even </span><span>giving you the option to change the allocator for each collection.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Compiler plugins</h1>
                </header>
            
            <article>
                
<p>To finish with this list, we will talk about the compiler plugins. These plugins can be used by adding <kbd>#![feature(plugin)]</kbd> to the top of the <kbd>main.rs</kbd> or <kbd>lib.rs</kbd> files, as with the rest of the nightly features. If you want to actually create a plugin, you will need to use the <kbd>plugin_registrar</kbd> and <kbd>rustc_private</kbd> features.</p>
<p>The unstable feature list has an interesting guide to create plugins, which will be extended in <a href="e869a4d7-e2a8-488a-a767-8c75364a8962.xhtml" target="_blank">Chapter 9</a>, <em>Creating Your Own Macros</em>. You will need to use the <kbd>libsyntax</kbd> crate, along with the internals of the compiler syntax, and the compiler internals themselves, so that you can parse the <strong><span>advanced source tree </span><span>(</span><span>AST</span></strong><span><strong>)</strong> tokens, and perform the operations required by your plugin.</span></p>
<p>Plugins enable big syntax extensions to the language, which can let you run arbitrary Rust code inside a macro or derive any kind of boilerplate code. We will see a real example of a crate that makes heavy use of plugins to create a great web development experience in the next chapter.</p>
<p>Some of these features might not get stabilized in the short term, some might change a lot, and some might not even get implemented, even though I doubt it will happen for the list you just read. These changes could make your code obsolete from one day to the next, so you have to make sure that, if you use some of these features, you can maintain an always changing ecosystem.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In this chapter, we started with metaprogramming by learning about attributes and macros. Both of them will help you write less code and make sure that you get the best possible implementation for trivial details.</p>
<p>We then learned about nightly Rust and how some nightly features give us new language extensions that can greatly help improve the efficiency, performance, and clarity of our code.</p>
<p>In the next chapter, we will see how crates in <a href="https://crates.io/">crates.io</a> bring new macros and plugins to the ecosystem, and we will go through the most-used ones that improve the performance and development time for your applications.</p>


            </article>

            
        </section>
    </body></html>