- en: Logging
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Logging is an important, yet overlooked, practice in the software development
    life cycle. It is often integrated as an afterthought on facing the consequences
    of latent invalid states and errors that accumulate over time in software systems.
    Any moderate sized project should have logging support from the initial days of
    development.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we'll get to know why setting up logging in an application
    is important, the need for a logging framework, how to approach logging, and what
    crates are available in the Rust ecosystem to enable programmers to leverage the
    power of logging in their applications.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: What is logging and why do we need it?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The need for logging frameworks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Logging frameworks and their features
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exploring logging crates in Rust
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What is logging and why do we need it?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '"Generally, a program should say nothing unless and until it has something
    to say."                                                                     
                                                                                 
                                                                                 
                                    - Kernighan and Plauger'
  prefs: []
  type: TYPE_NORMAL
- en: Before we talk about the importance of logging, let's define the term so that
    we have a better context for it. Logging is the practice of making an application
    record its activity at runtime to any output, where the individual record is called
    an **event log**or simply a **log**. This is often associated with a timestamp
    describing when the event occurred. The event could be anything that changes the
    state of the program internally or externally. Logs help you in gaining insights
    on an application's runtime behavior over the course of time, or in getting more
    context on the application state when debugging a bug. They also find their use
    in generating analytics reports for business purposes. This is to say that the
    degree of utility logging provides to a user depends mainly on the application
    and consumers' needs.
  prefs: []
  type: TYPE_NORMAL
- en: Now, in an application without any kind of logging integration, there are limited
    options for us to know about the behavior of our program at runtime. We could
    use external utilities such as *htop* in Linux to monitor our program, but this
    gives us a view of the program from the outside and provides limited information
    regarding the internals.
  prefs: []
  type: TYPE_NORMAL
- en: Information from within a program while it's running is useful for debugging
    purposes or can be used for runtime performance analysis. In the case of fatal
    failures in our program, we can get to know about the whereabouts of our program
    when it crashes. At the very least, the program will leave a stack trace, thus
    providing a bit of context on where the program went wrong. However, there are
    classes of bugs and events that do not cause immediate problems but later turn
    into fatal errors, especially in long running systems. In these cases, event logs
    can help quickly narrow down the issue in the program. That's where adding logging
    capabilities to a program becomes tremendously helpful.
  prefs: []
  type: TYPE_NORMAL
- en: Systems that benefit greatly from logging and need to rely on event logs are
    web services, network servers, stream processing services, and similar long running
    systems. In these systems, individual event logs combined with subsequent logs
    over the course of time, when ingested and put into analysis by a log aggregation
    service, can provide useful statistics about the system.
  prefs: []
  type: TYPE_NORMAL
- en: For a commercial application such as a shopping website, you can leverage log
    analytics to get business insights, leading to better sales. In network servers,
    you can find useful activity logs to track any malicious attempts made to the
    server such as a distributed denial of service (DDoS) attack. Developers can assess
    the performance of their web API endpoints by getting request-response latency
    figures from the collected API request logs.
  prefs: []
  type: TYPE_NORMAL
- en: Logs also serve as an important debugging context and can minimize the time
    that's taken in performing root cause analysis during a debugging session, where
    you have time constraints to fix issues that happen in production.
  prefs: []
  type: TYPE_NORMAL
- en: Sometimes, logging is the only way to do this because debuggers are not always
    available or applicable. This is usually the case in distributed systems and multi-threaded
    applications. Anyone who has done a fair amount of development within these systems
    is quite aware of why logging is such an important part of the software development
    pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are three broad categories of users who benefit greatly from the practice
    of application logging:'
  prefs: []
  type: TYPE_NORMAL
- en: '**System administrators**: They need to monitor server logs for any malfunction,
    for example, a hard disk crash or network failures.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Developers**: During development, integrating logs in the project can help
    cut down development time by a lot and can later be used to get insights into
    the way users use their application.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Network security teams**: In the case of any attack on a remote server, the
    security folks benefit greatly from logging as they can get to know how a certain
    attack was carried out by tracing the event logs that the victim server logged.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Being a functional component in software development practices, and providing
    great value in the long run, integrating logging in a system demands dedicated
    frameworks, and we'll see why in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: The need for logging frameworks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We now know why logs are important. The next question however is how do we integrate
    logging capabilities in our application? The simplest and most straightforward
    way to get your application to log events is to have a bunch of print statements
    sprinkled in code at the required places. This way, we easily get our event logs
    to the standard output on our Terminal console, which gets our job done, but there's
    more to be desired. In quite a few cases, we also want our logs to persist for
    analysis at a later point in time. So, if we want to collect the output from our
    print statements to a file, we have to look for additional ways such as piping
    the output to a file using the shell output redirection facility, which is basically
    plumbing a different set of tools to get to the goal of getting logs from our
    application to different outputs. As it turns out, there are limitations to this
    approach.
  prefs: []
  type: TYPE_NORMAL
- en: You don't get to filter or turn off your print statements for cases where you
    don't need to log for a particular module. For that, you either have to comment
    them out or remove them and redeploy your services. Another limitation is that
    when your logging commands become large, you have to write and maintain shell
    scripts for collecting logs for multiple outputs. All of this gets unwieldy and
    less maintainable very quickly. Using a print statement is a quick and dirty logging
    practice and is not a very scalable solution. What we need is a better and more
    customizable architecture for application logging. The scalable and cleaner way
    is to have a dedicated logger that removes all of these limitations, and that
    is why logging frameworks exist. In addition to basic logging needs, these frameworks
    also provide additional features such as log file rotations when reaching a certain
    size limit, setting logging frequency, granular log configuration per module,
    and much more.
  prefs: []
  type: TYPE_NORMAL
- en: Logging frameworks and their key features
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are a wide variety of logging frameworks offered by mainstream languages.
    Some notable ones to mention include *Log4j* from Java, *Serilog* from C#, and *Bunyan*
    from Node.js. From the time of proliferation of these frameworks, and from their
    use cases, there are similarities in what features a logging framework should
    provides to its users. The following are the most desirable properties that logging
    frameworks should have:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Fast**: Logging frameworks must ensure that they are not doing expensive
    operations when logging and should be able to process efficiently using as few
    CPU cycles as possible. For instance, in Java, if your log statements contain
    objects with lots of `to_string()` calls to them to just interpolate the object
    within the log message, then that''s an expensive operation. This is considered
    an inefficient practice in Java.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Configurable outputs**: It''s very limiting to have the ability to log messages only
    to standard output. It stays only until the shell session and you need to manually
    paste the logs to a file to use them later. Logging frameworks should provide
    the ability to support multiple outputs, such as a file or even a network socket.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Log levels:** The prominent feature of logging frameworks that makes them
    stand out from normal print-based logging is the ability to control what and when
    things get logged. This is usually implemented using the idea of *log levels*.
    A log level is a configurable filter that''s usually implemented as a type that
    is checked for before sending the log output anywhere. The levels are usually
    in the following order, from lowest priority to highest priority:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Error**: This level is suitable for logging events that are critical and
    those that may lead to invalid outputs from the application.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Warn**: This level is suitable for events for which you have taken measures,
    but also want to know when it happens to take actions later if they occur frequently.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Info**: This level can be used for normal events such as printing the application
    version, user logins, connection successful messages, and so on.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Debug**: As the name suggests, this is used to support debugging. It is useful
    for monitoring the values of variables and how they get manipulated in different
    code paths when debugging.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Trace**: This level is used when you want a step-by-step execution of your
    algorithm or any non-trivial function that you wrote. Method invocations with
    parameter and return values are things that can be put as trace logs.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Some of these names might differ slightly across frameworks, but the priorities
    they signify are mostly the same. In major logging frameworks, these levels are
    set by the logger during its initialization and any subsequent logging invocations
    check for the set level and filters out the logs accordingly. For example, a `Logger`
    object with the call to `Logger.set_level(INFO)` would allow all logs using levels
    above `Info` to be logged, while ignoring `Debug` and `Trace` logs.
  prefs: []
  type: TYPE_NORMAL
- en: '**Log filtering**: It should be easy to log only the desired places in code
    and to turn off other logs based on the severity/importance of events.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Log Rotation**: When logging to a file, it is imminent that prolonged logging
    will fill up disk space. A logging framework should provide facilities to limit
    the log file size and allow for the deletion of older log files.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Asynchronous logging**: Logging invocations on the main thread have the possibility
    of blocking the main code from making progress. Even though an efficient logger
    would do as little as possible, it still does a blocking I/O call between the
    actual code. As such, it is desirable that most logging invocations are offloaded
    to a dedicated logger thread.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Log message attributes**: Another thing worth mentioning are the attributes
    on log messages that get sent to the logging API. At a minimum, a logging framework
    should provide the following attributes to log messages:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Timestamp**: The time at which the event happened'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Log Severity**: The importance of the message, for example, Error, Warning,
    Information, Debug, and so on'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Event location**: The place in the source code where the event happened'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Message**: The actual event message that describes what happened'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Depending on these features, there are differences in how logging frameworks
    approach logging. Let's explore them next.
  prefs: []
  type: TYPE_NORMAL
- en: Approaches to logging
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'When integrating logging in an application, we need to decide what information
    to log and how granular it should be. If there are too many logs, we lose the
    ability of easily finding relevant information in the sea of noise and if there''s
    not enough log messages, we risk missing that one important event. We also need
    to think about how to organize information in our log message so that it becomes
    easier to search and analyze it later. These questions lead to logging frameworks
    that are broadly divided into two categories: unstructured logging and structured
    logging.'
  prefs: []
  type: TYPE_NORMAL
- en: Unstructured logging
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The usual way to approach logging is the practice of logging events as plain
    strings and shoving any fields from required values into the log message by converting
    them into strings. This form of logging is called unstructured logging as the
    information in the log message doesn't have any predefined structure or order.
    Unstructured logging serves well for most use cases, but it has its downsides
    too.
  prefs: []
  type: TYPE_NORMAL
- en: After collecting log messages, a common use case with them is to be able search
    for them for a particular event at a later point in time. However, the retrieval
    of unstructured logs from a collection of logs can be a pain. The problem with
    unstructured log messages is that they don't have any predictable format and it
    becomes quite resource heavy for a log aggregation service to sift through all
    of the raw log messages using simple text matching queries. You need to write
    regular expressions that match on a chunk of text or grep them from the command
    line to get that particular event. With an increasing amount of logs, this approach
    eventually becomes a bottleneck in getting useful information from log files.
    The other approach is to log messages that have a predefined structure and for
    that we have structured logging.
  prefs: []
  type: TYPE_NORMAL
- en: Structured logging
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Structured logging is a scalable and better alternative to unstructured logging.
    As the name suggests, structured logging defines a structure and formatting to
    your log messages and every log message is guaranteed to have this format. The
    advantage of this is that it becomes very easy for log aggregation services to
    build a search index and present any particular event to the user, regardless
    of the amount of messages they have. There are quite a few structured logging
    frameworks such as Serilog in C# that provide support for structured logging.
    These frameworks provide a plugin-based log output abstraction called *Sinks. *Sinks
    are how you direct where you want your logs to be sent. A Sink can be your Terminal,
    a file, a database, or a log aggregation service such as logstash.
  prefs: []
  type: TYPE_NORMAL
- en: Structured logging frameworks know how to serialize a certain object and can
    do so in a proper format. They also automate the formatting of log messages by
    providing hierarchical log outputs, depending on which component the log is emitted
    from. The downside to structured logging is that it can be a bit time-consuming
    to integrate it into your application as you have to decide on the hierarchy and
    the format of your logs beforehand.
  prefs: []
  type: TYPE_NORMAL
- en: It's often a trade-off when choosing between structured logging and unstructured
    logging. Complex projects that log heavily can benefit from structured logging
    as they can get semantic and efficiently searchable logs from their modules, while
    small to moderate size projects can make do with unstructured logging. Ultimately,
    it's the application's needs that should decide how you integrate logging in your
    application. In the next section, we'll explore a couple of unstructured logging
    frameworks as well as structure logging frameworks in Rust that you can use for
    getting your application to log events.
  prefs: []
  type: TYPE_NORMAL
- en: Logging in Rust
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Rust has quite a few flexible and extensive logging solutions. Like popular
    logging frameworks in other languages, the logging ecosystem here is split into
    two parts:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Logging facade**: This part is implemented by the `log` crate and provides
    an implementation agnostic logging API. While other frameworks implement logging
    APIs as functions or methods on some object, the log crate provides us with macro-based
    logging APIs, which are categorized by log levels to log events to a configured
    log output.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Logging implementations**: These are community developed crates that provide
    actual logging implementation in terms of where the output goes and how it happens.
    There are many such crates, such as `env_logger`, `simple_logger`, `log4rs`, and `fern`.
    We''ll visit a couple of them in a moment. Crates that come under this category
    are meant to be used only by binary crates, that is, executables.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This separation of concerns between the logging API and the underlying mechanism
    by which logs go to an output is done so that developers don't need to change
    their log statements in code and can easily swap the underlying logging implementation
    on an as-needed basis.
  prefs: []
  type: TYPE_NORMAL
- en: log – Rust's logging facade
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `log` crate comes from the *rust-lang nursery* organization on GitHub and
    is managed by the community at [https://github.com/rust-lang-nursery/log](https://github.com/rust-lang-nursery/log).
    It provides separate macros for logging at different log levels such as `error!`,
    `warn!`, `info!`, `debug!`, and `trace!`, in the order of the most priority to
    the least priority. These macros are major points of interaction for consumers
    of this crate. They internally call the `log!` macro in this crate, which does
    all the bookkeeping such as checking for the log level and formatting log messages.
    The core component of this crate is the `log` trait that other backend crates
    implement. The trait defines operations that are required for a logger and has
    other APIs, such as for checking whether logging is enabled or for flushing any
    buffered logs.
  prefs: []
  type: TYPE_NORMAL
- en: 'The log crate also provides a maximum log level constant called `STATIC_MAX_LEVEL`,
    which can be configured project wide at compile time. With this constant, you
    can set the log level of an application statically using cargo feature flags,
    which allows for the compile time filtering of logs for the application and all
    of its dependencies. These level filters can be set in `Cargo.toml` separately
    for debug and release builds: `max_level_<LEVEL>` (debug) and `release_max_level_<LEVEL>`
    (release). In binary projects, you can specify the dependency on the `log` crate
    with compile time log levels as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: It's a good practice to set this constant to a desired value as, by default,
    the level is set to `Off`. It also allows the log macros to optimize away any
    log invocations at disabled levels. Libraries should only link to the `log` crate
    and not any logger implementation crate as binary crates should have control over
    what to log and how to log it. Using this crate solely in your application won't
    produce any log output as you need to use logging crates such as `env_logger`
    or `log4rs` along with it.
  prefs: []
  type: TYPE_NORMAL
- en: 'To see the `log` crate in action, we''ll build a library crate by running `cargo
    new user_auth --lib` and adding `log` as a dependency in our `Cargo.toml` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'This crate simulates a dummy user sign-in API. Our `lib.rs` file has a `User`
    struct, which has a method called `sign_in`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: In the `sign_in` method, we have a couple of log invocations on whether the
    sign in succeeded or failed. We'll use this library crate together with a binary
    crate thats creates a `User` instance and calls the `sign_in` method. Since depending
    on the `log` crate itself won't produce any log output, we'll use the `env_logger`
    as the logging backend for this example. Let's explore `env_logger` first.
  prefs: []
  type: TYPE_NORMAL
- en: The env_logger
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '`env_logger` is a simple logging implementation that allows you to control
    logs to `stdout` or `stderr` through the `RUST_LOG` environment variable. The
    values of this environment variable are comma-separated logger strings that correspond
    to module names and log levels. To demonstrate `env_logger`, we''ll create a new
    binary crate by running `cargo new env_logger_demo` and specifying dependencies
    for `log`, `env_logger`, and our `user_auth` library, which we created in the
    previous section. Here''s our `Cargo.toml` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Here''s our `main.rs` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'We create our `User` instance and call `sign_in`, passing in our password.
    The first sign in attempt is a failed one, which will get logged as an error.
    We can run it by setting the `RUST_LOG` environment variable, followed by `cargo
    run`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: We set the logs from the `user_auth` crate to `info` and the levels above it,
    while logs from our `env_logger_demo` crate are set to `debug` and above.
  prefs: []
  type: TYPE_NORMAL
- en: 'Running this gives us the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d1d12879-ec6b-44aa-8b5a-5ec66e5cd8bf.png)'
  prefs: []
  type: TYPE_IMG
- en: The `RUST_LOG` accepts the `RUST_LOG=path::to_module=log_level[,]` pattern,
    where `path::to_module` specifies the logger and should be a path to any module
    with the crate name as the base. The `log_level` is any of the log levels that
    are defined in the log crate. `[,]` at the end indicates that we can optionally
    have as many of these logger specifications separated by a comma.
  prefs: []
  type: TYPE_NORMAL
- en: 'An alternative way to run the preceding program is by setting the environment
    variable within the code itself using the `set_var` method from the `env` module
    in the standard library:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: This produces the same output as before. Next, let's take a look at a more complex
    and highly configurable logging crate.
  prefs: []
  type: TYPE_NORMAL
- en: log4rs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `log4rs` crate, as the name suggests, is inspired by the popular `log4j`
    library from Java. This crate is much more powerful than `env_logger` and allows
    for granular logger configuration via YAML files.
  prefs: []
  type: TYPE_NORMAL
- en: We'll build two crates to demonstrate integrating logging via the `log4rs` crate.
    One will be a library crate, `cargo new my_lib --lib`, and the other will be our
    binary crate, `cargo new my_app`, which uses `my_lib`. A cargo workspace directory,
    called `log4rs_demo`, contains both of our crates.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our `my_lib` crate has the following contents in the `lib.rs` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'It has a struct called `Config` with a dummy method called `load_global_config`,
    which logs a message at the debug level. Next, our `my_app` crate contains the
    following contents in the `main.rs` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding code, we initialize our `log4rs` logger via the `init_file`
    method, passing in the path to the `log4rs.yaml` config file. Next, we log a dummy
    error message, thus printing the app version. Following that, we call `load_global_config`,
    which logs another message. The following is the content of the `log4rs.yaml`
    configuration file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Let's go through this line by line. The first line, `refresh_rate`, specifies
    the time interval after which `log4rs` reloads the configuration file to account
    for any changes that are made to this file. This means that we can modify any
    value in our YAML file and `log4rs` will dynamically reconfigure its loggers for
    us. Then, we have the `root` logger, which is the parent of all loggers. We specify
    the default level as `error` and the appender as `stdout`, which is defined below
    it.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we have the `appenders` section. Appenders are places where logs go.
    We have specified two appenders: `stdout`, which is of `console` type, and `my_lib_append`,
    which is a `file` appender, which includes information about the path of the file
    and the log pattern to use under the `encoder` section.'
  prefs: []
  type: TYPE_NORMAL
- en: Next, there is the section of `loggers` where we can define loggers based on
    the crates or modules with different levels. We defined a logger called `my_lib`,
    which corresponds to our `my_lib` crate, with the `debug` level and appender as
    `my_lib_append`. This means that any logs from the `my_lib` crate will go to the
    `my_lib.log` file, as specified by the `my_lib_append` appender.
  prefs: []
  type: TYPE_NORMAL
- en: 'By running `cargo run` in the `log4rs_demo` directory, we get the following
    output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/613c23dc-a436-4634-ab2e-e1cfab50130e.png)'
  prefs: []
  type: TYPE_IMG
- en: That was a brief intro to `log4rs`. If you want to explore more on configuring
    these logs, head over to the documentation page at [https://docs.rs/log4rs](https://docs.rs/log4rs).
  prefs: []
  type: TYPE_NORMAL
- en: Structured logging using slog
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: All of the aforementioned crates are quite useful and are ideal for most use
    cases, but they do not support structured logging. In this section, we'll see
    how structured logging can be integrated into our application using the `slog`
    crate, one of the few popular structured logging crates in the Rust ecosystem.
    For this demo, we'll create a new project by running `cargo new slog_demo`, which
    simulates a shooting game.
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ll need the following dependencies in our `Cargo.toml` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'The `slog` framework is ideal for moderate to big projects where there is lot
    of interplay between modules as it helps to integrate detailed logs for the long-term
    monitoring of events. It works on the idea of providing hierarchical and composable
    logging configuration in the application and allows for semantic event logging.
    There are two important concepts under `slog` that you need to be aware of to
    successfully use the crate: *Loggers* and *Drains*. Logger objects are used to
    log events while a Drain is an abstraction specifying a place where the log messages
    go and how they get there. This can be your standard output, a file, or a network
    socket. Drains are similar to what you would call a `Sink` in the *Serilog* framework
    in C#.'
  prefs: []
  type: TYPE_NORMAL
- en: Our demo simulates game events from dummy game entities based on their actions.
    The entities have a parent-child relationship in the game, where we can attach
    the hierarchical logging capability in them quite easily with `slog` framework's
    structural logging configuration. We'll get to know about this when we see the
    code. At the root level, we have the `Game` instance, for which we can define
    a root logger to provide a baseline context in our log messages, such as the game
    name and version. So, we'll create a root logger attached to the `Game` instance.
    Next, we have the `Player` and `Enemy` types, which are child entities to the
    `Game`. These become child loggers of the root logger. Then, we have weapons for
    both the enemy and the player, which become the child logger for the player and
    the enemy logger. As you can see, setting up `slog` is a bit more involved than
    the previous frameworks we looked at.
  prefs: []
  type: TYPE_NORMAL
- en: 'Along with `slog` as the base crate, we''ll also use the following crates in
    our demo:'
  prefs: []
  type: TYPE_NORMAL
- en: '`slog-async`: Provides an asynchronous logging drain that decouples logging
    calls from the main thread.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`slog-json`: A drain that outputs messages to any `Writer` as JSON. We''ll
    use `stdout()` as the `Writer` instance for this demo.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let''s take a look at our `main.rs` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding code, we have a bunch of `use` statements, followed by our
    `PlayingCharacter` trait, which is implemented by our `Player` and `Enemy` structs.
    Our `Game` struct has a `simulate` method, which simply loops and randomly sleeps,
    thereby selecting at random either the player or the enemy before calling the `shoot`
    method on them. Let''s continue down the same file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: In `main`, we first create our `drain` using `slog_json::Json`, which can log
    messages as JSON objects, followed by passing it to another drain, `Async`, which
    will offload all log invocations to a separate thread. Then, we create our `root_logger` by
    passing in our `drain` with an initial context for our log messages using the
    convenient `o!` macro. In this macro, we simply print the name and version of
    our game using the `CARGO_PKG_VERSION` environment variable. Next, our `Game` struct
    takes our root logger and `enemy` and `player` instances. To the `Player` and
    `Enemy` instances, we pass a reference to the `root_logger`, using which they
    create their child loggers. Then, we call `simulate` on our game instance.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is the content of `player.rs`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, our `new` method on `Player` gets the root `logger`, to which it adds
    its own context with the `o!` macro. We also create a logger for `weapon` and
    pass the player logger to it, which add its own information such as the ID of
    the weapon. Finally, we return our configured `Player` instance:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: We also implement the `PlayingCharacter` trait for our `Player`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next is our `enemy.rs` file, which is identical to everything we had in `player.rs`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we have our `weapon.rs` file, which contains two weapons that are used
    by the enemy and player instances:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'That''s all that is required for our game simulation. We can now run it by
    invoking `cargo run`. Here''s the output on my machine:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1f3dabf7-78a6-43d3-bd3b-3b3001aa49c4.png)'
  prefs: []
  type: TYPE_IMG
- en: As you can see, our game entities send log messages, which are then formatted
    and output as JSON with the help of `slog` and its drains. Similar to the JSON
    drain we used previously, there are many such drains that have been built by the
    community for `slog`. We can have a drain that outputs log messages directly to
    a log aggregation service, which knows how to handle JSON data and can easily
    index them for the efficient retrieval of logs. The pluggable and composable nature
    of `slog` makes it stand out from other logging solutions. With this demo, we
    have come to the end of the logging story in Rust. However, there are other more
    interesting logging frameworks for you to explore, and you can find them at [http://www.arewewebyet.org/topics/logging/](http://www.arewewebyet.org/topics/logging/).
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we learned about the importance of logging in software development
    and the ways of approaching it, including what characteristics to look for when
    choosing a logging framework. We also got to know about unstructured and structured
    logging, their pros and cons, and explored the available crates in the Rust ecosystem
    to integrate logging into our applications.
  prefs: []
  type: TYPE_NORMAL
- en: The next chapter will be about network programming, where we will explore the
    built-in facilities and crates that Rust provides to create efficient applications
    that communicate with one another.
  prefs: []
  type: TYPE_NORMAL
