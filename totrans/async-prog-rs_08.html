<html><head></head><body>
		<div id="_idContainer038">
			<h1 id="_idParaDest-139" class="chapter-number"><a id="_idTextAnchor138"/>8</h1>
			<h1 id="_idParaDest-140"><a id="_idTextAnchor139"/>Runtimes, Wakers, and the Reactor-Executor Pattern</h1>
			<p>In the previous chapter, we created our own pausable tasks (coroutines) by writing them as state machines. We created a common API for these tasks by requiring them to implement the <strong class="source-inline">Future</strong> trait. We also showed how we can create these coroutines using some keywords and programmatically rewrite them so that we don’t have to implement these state machines by hand, and instead write our programs pretty much the same way we <span class="No-Break">normally would.</span></p>
			<p>If we stop for a moment and take a bird’s eye view over what we got so far, it’s conceptually pretty simple: we have an interface for pausable tasks (the <strong class="source-inline">Future</strong> trait), and we have two keywords (<strong class="source-inline">coroutine/wait</strong>) to indicate code segments we want rewritten as a state machine that divides our code into segments we can <span class="No-Break">pause between.</span></p>
			<p>However, we have no event loop, and we have no scheduler yet. In this chapter, we’ll expand on our example and add a runtime that allows us to run our program efficiently and opens up the possibility to schedule tasks concurrently much more efficiently than what we <span class="No-Break">do now.</span></p>
			<p>This chapter will take you on a journey where we implement our runtime in two stages, gradually making it more useful, efficient, and capable. We’ll start with a brief overview of what runtimes are and why we want to understand some of their characteristics.  We’ll build on what we just learned in <a href="B20892_07.xhtml#_idTextAnchor122"><span class="No-Break"><em class="italic">Chapter 7</em></span></a>, and show how we can make it much more efficient and avoid continuously polling the future to make it progress by leveraging the knowledge we gained in <a href="B20892_04.xhtml#_idTextAnchor081"><span class="No-Break"><em class="italic">Chapter 4</em></span></a><span class="No-Break">.</span></p>
			<p>Next, we’ll show how we can get a more flexible and loosely coupled design by dividing the runtime into two parts: an <strong class="bold">executor</strong> and <span class="No-Break">a </span><span class="No-Break"><strong class="bold">reactor</strong></span><span class="No-Break">.</span></p>
			<p>In this chapter, you will learn about basic runtime design, reactors, executors, wakers, and spawning, and we’ll build on a lot of the knowledge we’ve gained throughout <span class="No-Break">the book.</span></p>
			<p>This will be one of the big chapters in this book, not because the topic is too complex or difficult, but because we have quite a bit of code to write. In addition to that, I try to give you a good mental model of what’s happening by providing quite a few diagrams and explaining everything very thoroughly. It’s not one of those chapters you typically blaze through before going to bed, though, but I do promise it’s absolutely worth it in <span class="No-Break">the end.</span></p>
			<p>The chapter will be divided into the <span class="No-Break">following segments:</span></p>
			<ul>
				<li>Introduction to runtimes and why we <span class="No-Break">need them</span></li>
				<li>Improving our <span class="No-Break">base example</span></li>
				<li>Creating a <span class="No-Break">proper runtime</span></li>
				<li>Step 1 – Improving our runtime design by adding a Reactor and <span class="No-Break">a Waker</span></li>
				<li>Step 2 – Implementing a <span class="No-Break">proper Executor</span></li>
				<li>Step 3 – Implementing a <span class="No-Break">proper Reactor</span></li>
				<li>Experimenting with our <span class="No-Break">new runtime</span></li>
			</ul>
			<p>So, let’s dive <span class="No-Break">right in!</span></p>
			<h1 id="_idParaDest-141"><a id="_idTextAnchor140"/>Technical requirements</h1>
			<p>The examples in this chapter will build on the code from our last chapter, so the requirements are the same. The examples will all be cross-platform and work on all platforms that Rust (<a href="https://doc.rust-lang.org/beta/rustc/platform-support.html#tier-1-with-host-tools">https://doc.rust-lang.org/beta/rustc/platform-support.html#tier-1-with-host-tools</a>) and <strong class="source-inline">mio</strong> (<a href="https://github.com/tokio-rs/mio#platforms">https://github.com/tokio-rs/mio#platforms</a>) supports. The only thing you need is Rust installed and the repository that belongs to the book downloaded locally. All the code in this chapter will be found in the <span class="No-Break"><strong class="source-inline">ch08</strong></span><span class="No-Break"> folder.</span></p>
			<p>To follow the examples step by step, you’ll also need <strong class="source-inline">corofy</strong> installed on your machine. If you didn’t install it in <a href="B20892_07.xhtml#_idTextAnchor122"><span class="No-Break"><em class="italic">Chapter 7</em></span></a>, install it now by going into the <strong class="source-inline">ch08/corofy</strong> folder in the repository and running <span class="No-Break">this command:</span></p>
			<pre class="console">
cargo install --force --path .</pre>			<p>Alternatively, you can just copy the relevant files in the repository when we come to the points where we use <strong class="source-inline">corofy</strong> to rewrite our <strong class="source-inline">coroutine/wait</strong> syntax. Both versions will be available to you there <span class="No-Break">as well.</span></p>
			<p>We’ll also use <strong class="source-inline">delayserver</strong> in this example, so you need to open a separate terminal, enter the <strong class="source-inline">delayserver</strong> folder at the root of the repository, and write <strong class="source-inline">cargo run</strong> so that it’s ready and available for the examples <span class="No-Break">going forward.</span></p>
			<p>Remember to change the ports in the code if you for some reason have to change the port <strong class="source-inline">delayserver</strong> <span class="No-Break">listens on.</span></p>
			<h1 id="_idParaDest-142"><a id="_idTextAnchor141"/>Introduction to runtimes and why we need them</h1>
			<p>As you know by now, you<a id="_idIndexMarker463"/> need to bring your own runtime for driving and scheduling asynchronous tasks <span class="No-Break">in Rust.</span></p>
			<p>Runtimes come in many flavors, from the<a id="_idIndexMarker464"/> popular <strong class="bold">Embassy</strong> embedded runtime (<a href="https://github.com/embassy-rs/embassy">https://github.com/embassy-rs/embassy</a>), which centers more on general multitasking and <a id="_idIndexMarker465"/>can replace the need for a <strong class="bold">real-time operating system</strong> (<strong class="bold">RTOS</strong>) on many platforms, to <strong class="bold">Tokio</strong> (<a href="https://github.com/tokio-rs/tokio">https://github.com/tokio-rs/tokio</a>), which centers on non-blocking I/O on popular server and desktop <span class="No-Break">operating systems.</span></p>
			<p>All runtimes in Rust need to do at least two things: schedule and drive objects implementing Rust’s <strong class="source-inline">Future</strong> trait to completion. Going forward in this chapter, we’ll mostly focus on runtimes for doing non-blocking I/O on popular desktop and server operating systems such as Windows, Linux, and macOS. This is also by far the most common type of runtime most programmers will encounter <span class="No-Break">in Rust.</span></p>
			<p>Taking control over how tasks are scheduled is <em class="italic">very</em> invasive, and it’s pretty much a one-way street. If you rely on a userland scheduler to run your tasks, you cannot, at the same time, use the OS scheduler (without jumping through several hoops), since mixing them in your code will wreak havoc and might end up defeating the whole purpose of writing an <span class="No-Break">asynchronous program.</span></p>
			<p>The following diagram illustrates the <span class="No-Break">different schedulers:</span></p>
			<div>
				<div id="_idContainer031" class="IMG---Figure">
					<img src="image/B20892_09_1.jpg" alt="Figure 8.1 – Task scheduling in a single-threaded asynchronous system"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 8.1 – Task scheduling in a single-threaded asynchronous system</p>
			<p>An example of yielding to the OS<a id="_idIndexMarker466"/> scheduler is making a blocking call using the <span class="No-Break">default </span><span class="No-Break"><strong class="source-inline">std::net</strong></span><strong class="source-inline"> ::TcpStream</strong> or <strong class="source-inline">std::thread::sleep</strong> methods. Even <em class="italic">potentially</em> blocking calls using primitives such as <strong class="source-inline">Mutex</strong> provided by the standard library might yield to the <span class="No-Break">OS scheduler.</span></p>
			<p>That’s why you’ll often find that asynchronous programming tends to color everything it touches, and it’s tough to only run a part of your program <span class="No-Break">using </span><span class="No-Break"><strong class="source-inline">async/await</strong></span><span class="No-Break">.</span></p>
			<p>The consequence is that runtimes must use a non-blocking version of the standard library. In theory, you could make one non-blocking version of the standard library that all runtimes use, and that was one of the goals of the <strong class="source-inline">async_std</strong> initiative (<a href="https://book.async.rs/introduction">https://book.async.rs/introduction</a>). However, having the community agree upon one way to solve this task was a tall order and one that hasn’t really come to <span class="No-Break">fruition yet.</span></p>
			<p>Before we start implementing our <a id="_idIndexMarker467"/>examples, we’ll discuss the overall design of a typical async runtime in Rust. Most runtimes such as Tokio, Smol, or async-std will divide their runtime into <span class="No-Break">two parts.</span></p>
			<p>The part that tracks events we’re waiting on and makes sure to wait on notifications from the OS in an efficient<a id="_idIndexMarker468"/> manner is <a id="_idIndexMarker469"/>often called the <em class="italic">reactor</em> <span class="No-Break">or </span><span class="No-Break"><em class="italic">driver</em></span><span class="No-Break">.</span></p>
			<p>The part that schedules tasks and polls them to completion<a id="_idIndexMarker470"/> is called <span class="No-Break">the </span><span class="No-Break"><em class="italic">executor</em></span><span class="No-Break">.</span></p>
			<p>Let’s take a high-level look at this design so that we know what we’ll be implementing in <span class="No-Break">our example.</span></p>
			<h2 id="_idParaDest-143"><a id="_idTextAnchor142"/>Reactors and executors</h2>
			<p>Dividing the runtime into two distinct parts makes a lot of sense when we take a look at how Rust models asynchronous tasks. If you read the documentation for <strong class="source-inline">Future</strong> (<a href="https://doc.rust-lang.org/std/future/trait.Future.html">https://doc.rust-lang.org/std/future/trait.Future.html</a>) and <strong class="source-inline">Waker</strong> (<a href="https://doc.rust-lang.org/std/task/struct.Waker.html">https://doc.rust-lang.org/std/task/struct.Waker.html</a>), you’ll see that Rust doesn’t only define a <strong class="source-inline">Future</strong> trait and a <strong class="source-inline">Waker</strong> type but also comes with important information on how they’re supposed to <span class="No-Break">be used.</span></p>
			<p>One example of this is that <strong class="source-inline">Future</strong> traits are <em class="italic">inert</em>, as we covered in <a href="B20892_06.xhtml#_idTextAnchor113"><span class="No-Break"><em class="italic">Chapter 6</em></span></a>. Another example is that a call to <strong class="source-inline">Waker::wake</strong> will guarantee <em class="italic">at least one call</em> to <strong class="source-inline">Future::poll</strong> on the <span class="No-Break">corresponding task.</span></p>
			<p>So, already by reading the documentation, you will see that there is at least some thought put into how runtimes <span class="No-Break">should behave.</span></p>
			<p>The reason for learning this pattern is that it’s almost a glove-to-hand fit for Rust’s <span class="No-Break">asynchronous model.</span></p>
			<p>Since many readers, including me, will not have English as a first language, I’ll explain the names here at the start since, well, they seem to be easy <span class="No-Break">to misunderstand.</span></p>
			<p>If the name <strong class="bold">reactor</strong> gives you <a id="_idIndexMarker471"/>associations with <em class="italic">nuclear reactors</em>, and you start thinking of reactors as something that powers, or drives, a runtime, drop that thought right now. A reactor is simply something that reacts to a whole set of incoming events and dispatches them one by one to a handler. It’s an event loop, and in our case, it dispatches events to an executor. Events that are handled by a reactor could be anything from a timer that expires, an interrupt if you write programs for embedded systems, or an I/O event such as a <strong class="source-inline">READABLE</strong> event <span class="No-Break">on </span><span class="No-Break"><strong class="source-inline">TcpStream</strong></span><span class="No-Break">.</span></p>
			<p>You could have several kinds of reactors running in the <span class="No-Break">same runtime.</span></p>
			<p>If the name <strong class="bold">executor</strong> gives you <a id="_idIndexMarker472"/>associations to <em class="italic">executioners</em> (the medieval times kind) or <em class="italic">executables</em>, drop that thought as well. If you look up what an executor is, it’s a person, often a lawyer, who administers a person’s will. Most often, since that person is dead. Which is also the point where whatever mental model the naming suggests to you falls apart since nothing, and no one, needs to come in harm’s way for the executor to have work to do in an asynchronous runtime, but <span class="No-Break">I digress.</span></p>
			<p>The important point is that an executor simply decides who gets time on the CPU to progress and when they get it. The executor must also call <strong class="source-inline">Future::poll</strong> and advance the state machines to their next state. It’s a type <span class="No-Break">of scheduler.</span></p>
			<p>It can be frustrating to get the wrong idea from the start since the subject matter is already complex enough without thinking about how on earth nuclear reactors and executioners fit in the <span class="No-Break">whole picture.</span></p>
			<p>Since reactors will respond to events, they need some integration with the <em class="italic">source</em> of the event. If we continue using <strong class="source-inline">TcpStream</strong> as an example, something will call <em class="italic">read</em> or <em class="italic">write</em> on it, and at that point, the reactor needs to know that it should track certain events on <span class="No-Break">that source.</span></p>
			<p>For this reason, non-blocking I/O primitives and reactors need tight integration, and depending on how you look at it, the I/O primitives will either have to bring their own reactor or you’ll have a reactor that provides I/O primitives such as sockets, ports, <span class="No-Break">and streams.</span></p>
			<p>Now that we’ve covered some of the overarching design, we can start writing <span class="No-Break">some code.</span></p>
			<p>Runtimes tend to get complex pretty quickly, so to keep this as simple as possible, we’ll avoid any error handling in our code and use <strong class="source-inline">unwrap</strong> or <strong class="source-inline">expect</strong> for everything. We’ll also choose simplicity over cleverness and readability over efficiency to the best of <span class="No-Break">our abilities.</span></p>
			<p>Our first task will be to take the first example we wrote in <a href="B20892_07.xhtml#_idTextAnchor122"><span class="No-Break"><em class="italic">Chapter 7</em></span></a> and improve it by avoiding having to actively poll it to make progress. Instead, we lean on what we learned about non-blocking I/O and <strong class="source-inline">epoll</strong> in the <span class="No-Break">earlier chapters.</span></p>
			<h1 id="_idParaDest-144"><a id="_idTextAnchor143"/>Improving our base example</h1>
			<p>We’ll create a version of the first example in <a href="B20892_07.xhtml#_idTextAnchor122"><span class="No-Break"><em class="italic">Chapter 7</em></span></a> since it’s the simplest one to start with. Our only focus is<a id="_idIndexMarker473"/> showing how to schedule and drive the runtimes <span class="No-Break">more efficiently.</span></p>
			<p>We start with the <span class="No-Break">following steps:</span></p>
			<ol>
				<li>Create a new project and name it <strong class="source-inline">a-runtime</strong> (alternatively, navigate to <strong class="source-inline">ch08/a-runtime</strong> in the <span class="No-Break">book’s repository).</span></li>
				<li>Copy the <strong class="source-inline">future.rs</strong> and <strong class="source-inline">http.rs</strong> files in the <strong class="source-inline">src</strong> folder from the first project we created in <a href="B20892_07.xhtml#_idTextAnchor122"><span class="No-Break"><em class="italic">Chapter 7</em></span></a>, named <strong class="source-inline">a-coroutine</strong> (alternatively, copy the files from <strong class="source-inline">ch07/a-coroutine</strong> in the book’s repository) to the <strong class="source-inline">src</strong> folder in our <span class="No-Break">new project.</span></li>
				<li>Make sure to add <strong class="source-inline">mio</strong> as a dependency by adding the following <span class="No-Break">to </span><span class="No-Break"><strong class="source-inline">Cargo.toml</strong></span><span class="No-Break">:</span><pre class="source-code">
[dependencies]
mio = { version = "0.8", features = ["net", "os-poll"] }</pre></li>				<li>Create a new file in the <strong class="source-inline">src</strong> folder <span class="No-Break">called </span><span class="No-Break"><strong class="source-inline">runtime.rs</strong></span><span class="No-Break">.</span></li>
			</ol>
			<p>We’ll use <strong class="source-inline">corofy</strong> to change the following <strong class="source-inline">coroutine/wait</strong> program into its state machine representation that we <span class="No-Break">can run.</span></p>
			<p>In <strong class="source-inline">src/main.rs</strong>, add the <span class="No-Break">following code:</span></p>
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">ch08/a-runtime/src/main.rs</p>
			<pre class="source-code">
mod future;
mod http;
mod runtime;
use future::{Future, PollState};
use runtime::Runtime;
fn main() {
    let future = async_main();
    let mut runtime = Runtime::new();
    runtime.block_on(future);
}
coroutine fn async_main() {
    println!("Program starting");
    let txt = http::Http::get("/600/HelloAsyncAwait").wait;
    println!("{txt}");
    let txt = http::Http::get("/400/HelloAsyncAwait").wait;
    println!("{txt}");
}</pre>			<p>This program is basically the same<a id="_idIndexMarker474"/> one we created in <a href="B20892_07.xhtml#_idTextAnchor122"><span class="No-Break"><em class="italic">Chapter 7</em></span></a>, only this time, we create it from our <strong class="source-inline">coroutine/wait</strong> syntax instead of writing the state machine by hand. Next, we need to transform this into code by using <strong class="source-inline">corofy</strong> since the compiler doesn’t recognize our own <span class="No-Break"><strong class="source-inline">coroutine/wait</strong></span><span class="No-Break"> syntax.</span></p>
			<ol>
				<li>If you’re in the root folder of <strong class="source-inline">a-runtime</strong>, run <span class="No-Break"><strong class="source-inline">corofy ./src/main.rs</strong></span><span class="No-Break">.</span></li>
				<li>You should now have a file that’s <span class="No-Break">called </span><span class="No-Break"><strong class="source-inline">main_corofied.rs</strong></span><span class="No-Break">.</span></li>
				<li>Delete the code in <strong class="source-inline">main.rs</strong> and copy the contents of <strong class="source-inline">main_corofied.rs</strong> <span class="No-Break">into </span><span class="No-Break"><strong class="source-inline">main.rs</strong></span><span class="No-Break">.</span></li>
				<li>You can now delete <strong class="source-inline">main_corofied.rs</strong> since we won’t need it <span class="No-Break">going forward.</span></li>
			</ol>
			<p>If everything is done right, the project structure should now look <span class="No-Break">like this:</span></p>
			<pre class="console">
src
 |-- future.rs
 |-- http.rs
 |-- main.rs
 |-- runtime.rs</pre>			<p class="callout-heading">Tip</p>
			<p class="callout">You can always refer to the book’s repository to make sure everything is correct. The correct example is located in the <strong class="source-inline">ch08/a-runtime</strong> folder. In the repository, you’ll also find a file called <strong class="source-inline">main_orig.rs</strong> in the root folder that contains the <strong class="source-inline">coroutine/wait</strong> program if you want to <a id="_idIndexMarker475"/>rerun it or have problems getting everything <span class="No-Break">working correctly.</span></p>
			<h2 id="_idParaDest-145"><a id="_idTextAnchor144"/>Design</h2>
			<p>Before we go any further, let’s visualize how <a id="_idIndexMarker476"/>our system is currently working if we consider it with two futures created by <strong class="source-inline">coroutine/wait</strong> and two calls to <strong class="source-inline">Http::get</strong>. The loop that polls our <strong class="source-inline">Future</strong> trait to completion in the <strong class="source-inline">main</strong> function takes the role of the executor in our visualization, and as you see, we have a chain of futures <span class="No-Break">consisting of:</span></p>
			<ol>
				<li>Non-leaf futures created by <strong class="source-inline">async/await</strong> (or <strong class="source-inline">coroutine/wait</strong> in our example) that simply call <strong class="source-inline">poll</strong> on the next future until it reaches a <span class="No-Break">leaf future</span></li>
				<li>Leaf futures that poll an actual source that’s either <strong class="source-inline">Ready</strong> <span class="No-Break">or </span><span class="No-Break"><strong class="source-inline">NotReady</strong></span></li>
			</ol>
			<p>The following diagram shows a simplified overview of our <span class="No-Break">current design:</span></p>
			<div>
				<div id="_idContainer032" class="IMG---Figure">
					<img src="image/B20892_09_2.jpg" alt="Figure 8.2 – Executor and Future chain: current design"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 8.2 – Executor and Future chain: current design</p>
			<p>If we take a closer look at the future chain, we can see that when a future is polled, it polls all its child futures until it <a id="_idIndexMarker477"/>reaches a leaf future that represents something we’re actually waiting on. If that future returns <strong class="source-inline">NotReady</strong>, it will propagate that up the chain immediately. However, if it returns <strong class="source-inline">Ready</strong>, the state machine will advance all the way until the next time a future returns <strong class="source-inline">NotReady</strong>. The top-level future will not resolve until all child futures have <span class="No-Break">returned </span><span class="No-Break"><strong class="source-inline">Ready</strong></span><span class="No-Break">.</span></p>
			<p>The next diagram takes a closer look at the future chain and gives a simplified overview of how <span class="No-Break">it works:</span></p>
			<div>
				<div id="_idContainer033" class="IMG---Figure">
					<img src="image/B20892_09_3.jpg" alt="Figure 8.3 – Future chain: a detailed view"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 8.3 – Future chain: a detailed view</p>
			<p>The first improvement we’ll make is to avoid the need for continuous polling of our top-level future to drive <span class="No-Break">it </span><span class="No-Break"><a id="_idIndexMarker478"/></span><span class="No-Break">forward.</span></p>
			<p>We’ll change our design so that it looks more <span class="No-Break">like this:</span></p>
			<div>
				<div id="_idContainer034" class="IMG---Figure">
					<img src="image/B20892_09_4.jpg" alt="Figure 8.4 – Executor and Future chain: design 2"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 8.4 – Executor and Future chain: design 2</p>
			<p>In this design, we use the knowledge we gained in <a href="B20892_04.xhtml#_idTextAnchor081"><span class="No-Break"><em class="italic">Chapter 4</em></span></a>, but instead of simply relying on <strong class="source-inline">epoll</strong>, we’ll use <strong class="source-inline">mio</strong>’s cross-platform abstraction instead. The way it works should be well known to us by now <a id="_idIndexMarker479"/>since we already implemented a simplified version of <span class="No-Break">it earlier.</span></p>
			<p>Instead of continuously looping and polling our top-level future, we’ll register interest with the <strong class="source-inline">Poll</strong> instance, and when we get a <strong class="source-inline">NotReady</strong> result returned, we wait on <strong class="source-inline">Poll</strong>. This will put the thread to sleep, and no work will be done until the OS wakes us up again to notify us that an event we’re waiting on <span class="No-Break">is ready.</span></p>
			<p>This design will be much more efficient <span class="No-Break">and scalable.</span></p>
			<h2 id="_idParaDest-146"><a id="_idTextAnchor145"/>Changing the current implementation</h2>
			<p>Now that we have an overview of our design and know what to do, we can go on and make the necessary changes to our program, so let’s go through each file we need to change. We’ll start <span class="No-Break">with </span><span class="No-Break"><strong class="source-inline">main.rs</strong></span><span class="No-Break">.</span></p>
			<h3>main.rs</h3>
			<p>We already made some <a id="_idIndexMarker480"/>changes to <strong class="source-inline">main.rs</strong> when we ran <strong class="source-inline">corofy</strong> on our updated <strong class="source-inline">coroutine/wait</strong> example. I’ll just point out the<a id="_idIndexMarker481"/> change here so that you don’t miss it since there is really nothing more we need to <span class="No-Break">change here.</span></p>
			<p>Instead of polling the future in the <strong class="source-inline">main</strong> function, we created a new <strong class="source-inline">Runtime</strong> struct and passed the future as an argument to the <strong class="source-inline">Runtime::block_on</strong> method. There are no more changes that we need to in this file. Our <strong class="source-inline">main</strong> function changed <span class="No-Break">to this:</span></p>
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">ch08/a-runtime/src/main.rs</p>
			<pre class="source-code">
 fn main() {
    <strong class="bold">let future = async_main();</strong>
<strong class="bold">    let mut runtime = Runtime::new();</strong>
<strong class="bold">    runtime.block_on(future);</strong>
}</pre>			<p>The logic we had in the <strong class="source-inline">main</strong> function has now moved into the <strong class="source-inline">runtime</strong> module, and that’s also where we need to change the code that polls the future to completion from what we <span class="No-Break">had earlier.</span></p>
			<p>The next step will, therefore, be to <span class="No-Break">open </span><span class="No-Break"><strong class="source-inline">runtime.rs</strong></span><span class="No-Break">.</span></p>
			<h3>runtime.rs</h3>
			<p>The first thing we do in <strong class="source-inline">runtime.rs</strong> is pull in the <a id="_idIndexMarker482"/>dependencies <span class="No-Break">we need:</span></p>
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">ch08/a-runtime/src/runtime.rs</p>
			<pre class="source-code">
use crate::future::{Future, PollState};
use mio::{Events, Poll, Registry};
use std::sync::OnceLock;</pre>			<p>The next step is to create a static variable called <strong class="source-inline">REGISTRY</strong>. If you remember, <strong class="source-inline">Registry</strong> is the way we register interest in events with our <strong class="source-inline">Poll</strong> instance. We want to register interest in events on our <strong class="source-inline">TcpStream</strong> when making the actual HTTP <strong class="source-inline">GET</strong> request. We could have <strong class="source-inline">Http::get</strong> accept a <strong class="source-inline">Registry</strong> struct that it stored for later use, but we want to keep the API <a id="_idIndexMarker483"/>clean, and instead, we want to access <strong class="source-inline">Registry</strong> inside <strong class="source-inline">HttpGetFuture</strong> without having to pass it around as <span class="No-Break">a reference:</span></p>
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">ch08/a-runtime/src/runtime.rs</p>
			<pre class="source-code">
static REGISTRY: OnceLock&lt;Registry&gt; = OnceLock::new();
pub fn registry() -&gt; &amp;'static Registry {
    REGISTRY.get().expect("Called outside a runtime context")
}</pre>			<p>We use <strong class="source-inline">std::sync::OnceLock</strong> so that we can initialize <strong class="source-inline">REGISTRY</strong> when the runtime starts, thereby preventing anyone (including ourselves) from calling <strong class="source-inline">Http::get</strong> without having a <strong class="source-inline">Runtime</strong> instance running. If we did call <strong class="source-inline">Http::get</strong> without having our runtime initialized, it would panic since the only public way to access it outside the <strong class="source-inline">runtime</strong> module is through the <strong class="source-inline">pub fn registry(){…}</strong> function, and that call <span class="No-Break">would fail.</span></p>
			<p class="callout-heading">Note</p>
			<p class="callout">We might as well have used a thread-local static variable using the <strong class="source-inline">thread_local!</strong> macro from the standard library, but we’ll need to access this from multiple threads when we expand the example later in this chapter, so we start the design with this <span class="No-Break">in mind.</span></p>
			<p>The next thing we <a id="_idIndexMarker484"/>add is a <span class="No-Break"><strong class="source-inline">Runtime</strong></span><span class="No-Break"> struct:</span></p>
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">ch08/a-runtime/src/runtime.rs</p>
			<pre class="source-code">
pub struct Runtime {
    poll: Poll,
}</pre>			<p>For now, our runtime will only store a <strong class="source-inline">Poll</strong> instance. The interesting part is in the implementation of <strong class="source-inline">Runtime</strong>. Since it’s not too long, I’ll present the whole implementation here and explain <span class="No-Break">it next:</span></p>
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">ch08/a-runtime/src/runtime.rs</p>
			<pre class="source-code">
impl Runtime {
    pub fn new() -&gt; Self {
        let poll = Poll::new().unwrap();
        let registry = poll.registry().try_clone().unwrap();
        REGISTRY.set(registry).unwrap();
        Self { poll }
    }
    pub fn block_on&lt;F&gt;(&amp;mut self, future: F)
    where
        F: Future&lt;Output = String&gt;,
    {
        let mut future = future;
        loop {
            match future.poll() {
                PollState::NotReady =&gt; {
                    println!("Schedule other tasks\n");
                    let mut events = Events::with_capacity(100);
                    self.poll.poll(&amp;mut events, None).unwrap();
                }
                PollState::Ready(_) =&gt; break,
            }
        }
    }
}</pre>			<p>The first thing we do is create a <strong class="source-inline">new</strong> function. This will initialize our runtime and set everything we need up. We create a new <strong class="source-inline">Poll</strong> instance, and from the <strong class="source-inline">Poll</strong> instance, we get an owned version of <strong class="source-inline">Registry</strong>. If you remember from <a href="B20892_04.xhtml#_idTextAnchor081"><span class="No-Break"><em class="italic">Chapter 4</em></span></a>, this is one of the methods we mentioned but didn’t<a id="_idIndexMarker485"/> implement in our example. However, here, we take advantage of the ability to split the two <span class="No-Break">pieces up.</span></p>
			<p>We store <strong class="source-inline">Registry</strong> in the <strong class="source-inline">REGISTRY</strong> global variable so that we can access it from the <strong class="source-inline">http</strong> module later on without having a reference to the <span class="No-Break">runtime itself.</span></p>
			<p>The next function is the <strong class="source-inline">block_on</strong> function. I’ll go through it step <span class="No-Break">by step:</span></p>
			<ol>
				<li>First of all, this function takes a generic argument and will block on anything that implements our <strong class="source-inline">Future</strong> trait with an <strong class="source-inline">Output</strong> type of <strong class="source-inline">String</strong> (remember that this is currently the only kind of <strong class="source-inline">Future</strong> trait we support, so we’ll just return an empty string if there is no data <span class="No-Break">to return).</span></li>
				<li>Instead of having to take <strong class="source-inline">mut future</strong> as an argument, we define a variable that we declare as <strong class="source-inline">mut</strong> in the function<a id="_idIndexMarker486"/> body. It’s just to keep the API slightly cleaner and avoid us having to make minor changes <span class="No-Break">later on.</span></li>
				<li>Next, we create a loop. We’ll loop until the top-level future we received <span class="No-Break">returns </span><span class="No-Break"><strong class="source-inline">Ready</strong></span><span class="No-Break">.</span><p class="list-inset">If the future returns <strong class="source-inline">NotReady</strong>, we write out a message letting us know that at this point we could do other things, such as processing something unrelated to the future or, more likely, polling another top-level future if our runtime supported multiple top-level futures (don’t worry – it will be explained <span class="No-Break">later on).</span></p><p class="list-inset">Note that we need to pass in an <strong class="source-inline">Events</strong> collection to <strong class="source-inline">mio</strong>’s <strong class="source-inline">Poll::poll</strong> method, but since there is only one top-level future to run, we don’t really care which event happened; we only care that something happened and that it most likely means that data is ready (remember – we always have to account for false <span class="No-Break">wakeups anyway).</span></p></li>
			</ol>
			<p>That’s all the changes we need to make to the <strong class="source-inline">runtime</strong> module <span class="No-Break">for now.</span></p>
			<p>The last thing we need to do is register <em class="italic">interest</em> for <em class="italic">read</em> events after we’ve written the request to the server in our <span class="No-Break"><strong class="source-inline">http</strong></span><span class="No-Break"> module.</span></p>
			<p>Let’s open <strong class="source-inline">http.rs</strong> and make <span class="No-Break">some changes.</span></p>
			<h3>http.rs</h3>
			<p>First of all, let’s adjust our<a id="_idIndexMarker487"/> dependencies so that we pull in everything <span class="No-Break">we need:</span></p>
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">ch08/a-runtime/src/http.rs</p>
			<pre class="source-code">
use crate::{future::PollState, <strong class="bold">runtime,</strong> Future};
<strong class="bold">use mio::{Interest, Token};</strong>
use std::io::{ErrorKind, Read, Write};</pre>			<p>We need to add a dependency on our <strong class="source-inline">runtime</strong> module as well as a few types <span class="No-Break">from </span><span class="No-Break"><strong class="source-inline">mio</strong></span><span class="No-Break">.</span></p>
			<p>We only need to make one more change in this file, and that’s in our <strong class="source-inline">Future::poll</strong> implementation, so let’s go ahead and <span class="No-Break">locate that:</span></p>
			<p>We made one important change here that I’ve highlighted for you. The implementation is exactly the same, with one<a id="_idIndexMarker488"/> <span class="No-Break">important difference:</span></p>
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">ch08/a-runtime/src/http.rs</p>
			<pre class="source-code">
impl Future for HttpGetFuture {
  type Output = String;
  fn poll(&amp;mut self) -&gt; PollState&lt;Self::Output&gt; {
    if self.stream.is_none() {
      println!("FIRST POLL - START OPERATION");
      self.write_request();
      <strong class="bold">runtime::registry()</strong>
<strong class="bold">        .register(self.stream.as_mut().unwrap(), Token(0), Interest::READABLE)</strong>
<strong class="bold">                .unwrap();</strong>
        }
        let mut buff = vec![0u8; 4096];
        loop {
            match self.stream.as_mut().unwrap().read(&amp;mut buff) {
                Ok(0) =&gt; {
                    let s = String::from_utf8_lossy(&amp;self.buffer);
                    break PollState::Ready(s.to_string());
                }
                Ok(n) =&gt; {
                    self.buffer.extend(&amp;buff[0..n]);
                    continue;
                }
                Err(e) if e.kind() == ErrorKind::WouldBlock =&gt; {
                    break PollState::NotReady;
                }
                Err(e) =&gt; panic!("{e:?}"),
            }
        }
    }
}</pre>			<p>On the first poll, after we’ve written the request, we register interest in <strong class="source-inline">READABLE</strong> events on this <strong class="source-inline">TcpStream</strong>. We <a id="_idIndexMarker489"/>also removed <span class="No-Break">the line:</span></p>
			<pre class="source-code">
return PollState::NotReady;</pre>			<p>By removing his line, we’ll poll <strong class="source-inline">TcpStream</strong> immediately, which makes sense since we don’t really want to return control to our scheduler if we get the response immediately. You wouldn’t go wrong either way here since we registered our <strong class="source-inline">TcpStream</strong> as an event source with our reactor and would get a wakeup in any case. These changes were the last piece we needed to get our example back up <span class="No-Break">and running.</span></p>
			<p>If you remember the version from <a href="B20892_07.xhtml#_idTextAnchor122"><span class="No-Break"><em class="italic">Chapter 7</em></span></a>, we got<a id="_idIndexMarker490"/> the <span class="No-Break">following output:</span></p>
			<pre class="console">
Program starting
FIRST POLL - START OPERATION
Schedule other tasks
Schedule other tasks
Schedule other tasks
Schedule other tasks
Schedule other tasks
Schedule other tasks
Schedule other tasks
HTTP/1.1 200 OK
content-length: 11
connection: close
content-type: text/plain; charset=utf-8
date: Thu, 16 Nov xxxx xx:xx:xx GMT
HelloWorld1
FIRST POLL - START OPERATION
Schedule other tasks
Schedule other tasks
Schedule other tasks
Schedule other tasks
Schedule other tasks
HTTP/1.1 200 OK
content-length: 11
connection: close
content-type: text/plain; charset=utf-8
date: Thu, 16 Nov xxxx xx:xx:xx GMT
HelloWorld2</pre>			<p>In our new and improved version, we<a id="_idIndexMarker491"/> get the following output if we run it with <span class="No-Break"><strong class="source-inline">cargo run</strong></span><span class="No-Break">:</span></p>
			<pre class="console">
Program starting
FIRST POLL - START OPERATION
Schedule other tasks
HTTP/1.1 200 OK
content-length: 11
connection: close
content-type: text/plain; charset=utf-8
date: Thu, 16 Nov xxxx xx:xx:xx GMT
HelloAsyncAwait
FIRST POLL - START OPERATION
Schedule other tasks
HTTP/1.1 200 OK
content-length: 11
connection: close
content-type: text/plain; charset=utf-8
date: Thu, 16 Nov xxxx xx:xx:xx GMT
HelloAsyncAwait</pre>			<p class="callout-heading">Note</p>
			<p class="callout">If you run the example on Windows, you’ll see that you get two <strong class="source-inline">Schedule other tasks</strong> messages after each other. The reason for that is that Windows emits an extra event when the <strong class="source-inline">TcpStream</strong> is dropped on the server end. This doesn’t happen on Linux. Filtering out these events is quite simple, but we won’t focus on doing that in our example since it’s more of an optimization that we don’t really need for our example <span class="No-Break">to work.</span></p>
			<p>The thing to make a note of here is how<a id="_idIndexMarker492"/> many times we printed <strong class="source-inline">Schedule other tasks</strong>. We print this message every time we poll and get <strong class="source-inline">NotReady</strong>. In the first version, we printed this every 100 ms, but that’s just because we had to delay on each sleep to not get overwhelmed with printouts. Without it, our CPU would work 100% on polling <span class="No-Break">the future.</span></p>
			<p>If we add a delay, we also add latency even if we make the delay much shorter than 100 ms since we won’t be able to respond to <span class="No-Break">events immediately.</span></p>
			<p>Our new design makes sure that we respond to events as soon as they’re ready, and we do no <span class="No-Break">unnecessary work.</span></p>
			<p>So, by making these minor changes, we have already created a much better and more scalable version than we <span class="No-Break">had before.</span></p>
			<p>This version is fully single-threaded, which keeps things simple and avoids the complexity and overhead synchronization. When you use Tokio’s <strong class="source-inline">current-thread</strong> scheduler, you get a scheduler that is based on the same idea as we <span class="No-Break">showed here.</span></p>
			<p>However, there are also some drawbacks to our current implementation, and the most noticeable one is that it requires a very tight integration between the <em class="italic">reactor part</em> and the <em class="italic">executor part</em> of the runtime centered <span class="No-Break">on </span><span class="No-Break"><strong class="source-inline">Poll</strong></span><span class="No-Break">.</span></p>
			<p>We want to yield to the OS scheduler <em class="italic">when there is no work to do</em> and have the OS wake us up when an event has happened so that we can progress. In our current design, this is done through blocking <span class="No-Break">on </span><span class="No-Break"><strong class="source-inline">Poll::poll</strong></span><span class="No-Break">.</span></p>
			<p>Consequently, both the executor (scheduler) and the reactor must know about <strong class="source-inline">Poll</strong>. The downside is, then, that if you’ve created an executor that suits a specific use case perfectly and want to allow users to use a different reactor that doesn’t rely on <strong class="source-inline">Poll</strong>, <span class="No-Break">you can’t.</span></p>
			<p><em class="italic">More importantly, you might want to run multiple different reactors that wake up the executor for different reasons.</em> You might find that there is something that <strong class="source-inline">mio</strong> doesn’t support, so you create a different reactor for those tasks. How are they supposed to wake up the executor<a id="_idIndexMarker493"/> when it’s blocking <span class="No-Break">on </span><span class="No-Break"><strong class="source-inline">mio::Poll::poll(...)</strong></span><span class="No-Break">?</span></p>
			<p>To give you a few examples, you could use a separate reactor for handling timers (for example, when you want a task to sleep for a given time), or you might want to implement a thread pool for handling CPU-intensive or blocking tasks as a reactor that wakes up the corresponding future when the task <span class="No-Break">is ready.</span></p>
			<p>To solve these problems, we need a loose coupling between the reactor and executor part of the runtime by having a way to wake up the executor that’s not tightly coupled to a single <span class="No-Break">reactor implementation.</span></p>
			<p>Let’s look at how we can solve this problem by creating a better <span class="No-Break">runtime design.</span></p>
			<h1 id="_idParaDest-147"><a id="_idTextAnchor146"/>Creating a proper runtime</h1>
			<p>So, if we visualize the degree of dependency<a id="_idIndexMarker494"/> between the different parts of our runtime, our current design could be described <span class="No-Break">this way:</span></p>
			<div>
				<div id="_idContainer035" class="IMG---Figure">
					<img src="image/B20892_09_5.jpg" alt="Figure 8.5 – Tight coupling between reactor and executor"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 8.5 – Tight coupling between reactor and executor</p>
			<p>If we want a loose coupling between<a id="_idIndexMarker495"/> the reactor and executor, we need an interface provided to signal the executor that it should wake up when an event that allows a future to progress has occurred. It’s no coincidence that this type is called <strong class="source-inline">Waker</strong> (<a href="https://doc.rust-lang.org/stable/std/task/struct.Waker.html">https://doc.rust-lang.org/stable/std/task/struct.Waker.html</a>) in Rust’s standard library. If we change our visualization to reflect this, it will look something <span class="No-Break">like this:</span></p>
			<div>
				<div id="_idContainer036" class="IMG---Figure">
					<img src="image/B20892_09_6.jpg" alt="Figure 8.6 – A loosely coupled reactor and executor"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 8.6 – A loosely coupled reactor and executor</p>
			<p>It’s no coincidence that we land on the same design as what we have in Rust today. It’s a minimal design from Rust’s <a id="_idIndexMarker496"/>point of view, but it allows for a wide variety of runtime designs without laying too many restrictions for <span class="No-Break">the future.</span></p>
			<p class="callout-heading">Note</p>
			<p class="callout">Even though the design is pretty minimal today from a language perspective, there are plans to stabilize more async-related traits and interfaces in <span class="No-Break">the future.</span></p>
			<p class="callout">Rust has a working group tasked with including widely used traits and interfaces in the standard library, which you can find more information about here: <a href="https://rust-lang.github.io/wg-async/welcome.html">https://rust-lang.github.io/wg-async/welcome.html</a>. You can also get an overview of items they work on and track their progress <span class="No-Break">here: </span><a href="https://github.com/orgs/rust-lang/projects/28/views/1"><span class="No-Break">https://github.com/orgs/rust-lang/projects/28/views/1</span></a><span class="No-Break">.</span></p>
			<p class="callout">Maybe you even want to get involved (<a href="https://rust-lang.github.io/wg-async/welcome.html#-getting-involved">https://rust-lang.github.io/wg-async/welcome.html#-getting-involved</a>) in making async Rust better for everyone after reading <span class="No-Break">this book?</span></p>
			<p>If we change our system <a id="_idIndexMarker497"/>diagram to reflect the changes we need to make to our runtime going forward, it will look <span class="No-Break">like this:</span></p>
			<div>
				<div id="_idContainer037" class="IMG---Figure">
					<img src="image/B20892_09_7.jpg" alt="Figure 8.7 – Executor and reactor: final design"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 8.7 – Executor and reactor: final design</p>
			<p>We have two parts that have no direct dependency on each other. We have an <strong class="source-inline">Executor</strong> that schedules tasks and passes on a <strong class="source-inline">Waker</strong> when polling a future that eventually will be caught and <a id="_idIndexMarker498"/>stored by the <strong class="source-inline">Reactor</strong>. When the <strong class="source-inline">Reactor</strong> receives a notification that an event is ready, it locates the <strong class="source-inline">Waker</strong> associated with that task and calls <strong class="source-inline">Wake::wake</strong> <span class="No-Break">on it.</span></p>
			<p>This enables <span class="No-Break">us to:</span></p>
			<ul>
				<li>Run several OS threads that each have their own executor, but share the <span class="No-Break">same reactor</span></li>
				<li>Have multiple reactors that handle different kinds of leaf futures and make sure to wake up the correct executor when it <span class="No-Break">can progress</span></li>
			</ul>
			<p>So, now that we have an idea of what to do, it’s time to start writing it <span class="No-Break">in code.</span></p>
			<h1 id="_idParaDest-148"><a id="_idTextAnchor147"/>Step 1 – Improving our runtime design by adding a Reactor and a Waker</h1>
			<p>In this step, we’ll make the<a id="_idIndexMarker499"/> <span class="No-Break">following changes:</span></p>
			<ol>
				<li>Change the project structure so that it reflects our <span class="No-Break">new design.</span></li>
				<li>Find a way for the executor to sleep and wake up that does not rely directly on <strong class="source-inline">Poll</strong> and create a <strong class="source-inline">Waker</strong> based on this that allows us to wake up the executor and identify which task is ready <span class="No-Break">to progress.</span></li>
				<li>Change the trait definition for <strong class="source-inline">Future</strong> so that poll takes a <strong class="source-inline">&amp;Waker</strong> as <span class="No-Break">an argument.</span></li>
			</ol>
			<p class="callout-heading">Tip</p>
			<p class="callout">You’ll find this example in the <strong class="source-inline">ch08/b-reactor-executor</strong> folder. If you follow along by writing the examples from the book, I suggest that you create a new project called <strong class="source-inline">b-reactor-executor</strong> for this example by following <span class="No-Break">these steps:</span></p>
			<p class="callout">     1. Create a new folder <span class="No-Break">called </span><span class="No-Break"><strong class="source-inline">b-reactor-executor</strong></span><span class="No-Break">.</span></p>
			<p class="callout">     2. Enter the newly created folder and write <span class="No-Break"><strong class="source-inline">cargo init</strong></span><span class="No-Break">.</span></p>
			<p class="callout">     3. Copy everything in the <strong class="source-inline">src</strong> folder in the previous example, <strong class="source-inline">a-runtime</strong>, into the <strong class="source-inline">src</strong> folder of a <span class="No-Break">new project.</span></p>
			<p class="callout">     4. Copy the <strong class="source-inline">dependencies</strong> section of the <strong class="source-inline">Cargo.toml</strong> file into the <strong class="source-inline">Cargo.toml</strong> file in the <span class="No-Break">new project.</span></p>
			<p>Let’s start by making some<a id="_idIndexMarker500"/> changes to our project structure to set it up so that we can build on it going forward. The first thing we do is divide our <strong class="source-inline">runtime</strong> module into two submodules, <strong class="source-inline">reactor</strong> <span class="No-Break">and </span><span class="No-Break"><strong class="source-inline">executor</strong></span><span class="No-Break">:</span></p>
			<ol>
				<li>Create a new subfolder in the <strong class="source-inline">src</strong> folder <span class="No-Break">called </span><span class="No-Break"><strong class="source-inline">runtime</strong></span><span class="No-Break">.</span></li>
				<li>Create two new files in the <strong class="source-inline">runtime</strong> folder called <strong class="source-inline">reactor.rs</strong> <span class="No-Break">and </span><span class="No-Break"><strong class="source-inline">executor.rs</strong></span><span class="No-Break">.</span></li>
				<li>Just below the imports in <strong class="source-inline">runtime.rs</strong>, declare the two new modules by adding <span class="No-Break">these lines:</span><pre class="source-code">
mod executor;
mod reactor;</pre></li>			</ol>
			<p>You should now have a folder structure that looks <span class="No-Break">like this:</span></p>
			<pre class="console">
src
 |-- runtime
        |-- executor.rs
        |-- reactor.rs
 |-- future.rs
 |-- http.rs
 |-- main.rs
 |-- runtime.rs</pre>			<p>To set everything up, we start<a id="_idIndexMarker501"/> by deleting everything in <strong class="source-inline">runtime.rs</strong> and replacing it with the following lines <span class="No-Break">of code:</span></p>
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">ch08/b-reactor-executor/src/runtime.rs</p>
			<pre class="source-code">
pub use executor::{spawn, Executor, Waker};
pub use reactor::reactor;
mod executor;
mod reactor;
pub fn init() -&gt; Executor {
    reactor::start();
    Executor::new()
}</pre>			<p>The new content of <strong class="source-inline">runtime.rs</strong> first declares two submodules called <strong class="source-inline">executor</strong> and <strong class="source-inline">reactor</strong>. We then declare one function called <strong class="source-inline">init</strong> that starts our <strong class="source-inline">Reactor</strong> and creates a new <strong class="source-inline">Executor</strong> that it returns to <span class="No-Break">the caller.</span></p>
			<p>The next point on our list is to find a way for our <strong class="source-inline">Executor</strong> to sleep and wake up when needed without relying <span class="No-Break">on </span><span class="No-Break"><strong class="source-inline">Poll</strong></span><span class="No-Break">.</span></p>
			<h2 id="_idParaDest-149"><a id="_idTextAnchor148"/>Creating a Waker</h2>
			<p>So, we need to find a different way for our <a id="_idIndexMarker502"/>executor to sleep and get woken up that doesn’t rely directly <span class="No-Break">on </span><span class="No-Break"><strong class="source-inline">Poll</strong></span><span class="No-Break">.</span></p>
			<p>It turns out that this is quite easy. The standard library gives us what we need to get something working. By calling <strong class="source-inline">std::thread::current()</strong>, we can get a <strong class="source-inline">Thread</strong> object. This object is a handle to the current thread, and it gives us access to a few methods, one of which <span class="No-Break">is </span><span class="No-Break"><strong class="source-inline">unpark</strong></span><span class="No-Break">.</span></p>
			<p>The standard library also gives us a method called <strong class="source-inline">std::thread::park()</strong>, which simply asks the OS scheduler to park our thread until we ask for it to get <em class="italic">unparked</em> <span class="No-Break">later on.</span></p>
			<p>It turns out that if we combine these, we have a way to both <em class="italic">park</em> and <em class="italic">unpark</em> the executor, which is exactly what <span class="No-Break">we need.</span></p>
			<p>Let’s create a <strong class="source-inline">Waker</strong> type based on this. In our example, we’ll define the <strong class="source-inline">Waker</strong> inside the <strong class="source-inline">executor</strong> module <a id="_idIndexMarker503"/>since that’s where we create this exact type of <strong class="source-inline">Waker</strong>, but you could argue that it belongs to the <strong class="source-inline">future</strong> module since it’s a part of the <span class="No-Break"><strong class="source-inline">Future</strong></span><span class="No-Break"> trait.</span></p>
			<p class="callout-heading">Important note</p>
			<p class="callout">Our <strong class="source-inline">Waker</strong> relies on calling <strong class="source-inline">park/unpark</strong> on the <strong class="source-inline">Thread</strong> type from the standard library. This is OK for our example since it’s easy to understand, but given that any part of the code (including any libraries you use) can get a handle to the same thread by calling <strong class="source-inline">std::thread::current()</strong> and call <strong class="source-inline">park/unpark</strong> on it, it’s not a robust solution. If unrelated parts of the code call <strong class="source-inline">park/unpark</strong> on the same thread, we can miss wakeups or end up in deadlocks. Most production libraries create their own <strong class="source-inline">Parker</strong> type or rely on something such as <strong class="source-inline">crossbeam::sync::Parker</strong> (<a href="https://docs.rs/crossbeam/latest/crossbeam/sync/struct.Parker.html"><span class="No-Break">https://docs.rs/crossbeam/latest/crossbeam/sync/struct.Parker.html</span></a><span class="No-Break">) instead.</span></p>
			<p>We won’t implement <strong class="source-inline">Waker</strong> as a trait since passing trait objects around will significantly increase the complexity of our example, and it’s not in line with the current design of <strong class="source-inline">Future</strong> and <strong class="source-inline">Waker</strong> in <span class="No-Break">Rust either.</span></p>
			<p>Open the <strong class="source-inline">executor.rs</strong> file located inside the <strong class="source-inline">runtime</strong> folder, and let’s add all the imports we’re going to need right from <span class="No-Break">the start:</span></p>
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">ch08/b-reactor-executor/src/runtime/executor.rs</p>
			<pre class="source-code">
use crate::future::{Future, PollState};
use std::{
    cell::{Cell, RefCell},
    collections::HashMap,
    sync::{Arc, Mutex},
    thread::{self, Thread},
};</pre>			<p>The next thing we add is <span class="No-Break">our </span><span class="No-Break"><strong class="source-inline">Waker</strong></span><span class="No-Break">:</span></p>
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">ch08/b-reactor-executor/src/runtime/executor.rs</p>
			<pre class="source-code">
#[derive(Clone)]
pub struct Waker {
    thread: Thread,
    id: usize,
    ready_queue: Arc&lt;Mutex&lt;Vec&lt;usize&gt;&gt;&gt;,
}</pre>			<p>The <strong class="source-inline">Waker</strong> will hold three things<a id="_idIndexMarker504"/> <span class="No-Break">for us:</span></p>
			<ul>
				<li><strong class="source-inline">thread</strong> – A handle to the <strong class="source-inline">Thread</strong> object we <span class="No-Break">mentioned earlier.</span></li>
				<li><strong class="source-inline">id</strong> – An <strong class="source-inline">usize</strong> that identifies which task this <strong class="source-inline">Waker</strong> is <span class="No-Break">associated with.</span></li>
				<li><strong class="source-inline">ready_queue</strong> – This is a reference that can be shared between threads to a <strong class="source-inline">Vec&lt;usize&gt;</strong>, where <strong class="source-inline">usize</strong> represents the ID of a task that’s in the ready queue. We share this object with the executor so that we can push the task ID associated with the <strong class="source-inline">Waker</strong> onto that queue when <span class="No-Break">it’s ready.</span></li>
			</ul>
			<p>The implementation of our <strong class="source-inline">Waker</strong> will be <span class="No-Break">quite simple:</span></p>
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">ch08/b-reactor-executor/src/runtime/executor.rs</p>
			<pre class="source-code">
impl Waker {
    pub fn wake(&amp;self) {
        self.ready_queue
            .lock()
            .map(|mut q| q.push(self.id))
            .unwrap();
        self.thread.unpark();
    }
}</pre>			<p>When <strong class="source-inline">Waker::wake</strong> is called, we first take a lock on the <strong class="source-inline">Mutex</strong> that protects the ready queue we share with the executor. We then push the <strong class="source-inline">id</strong> value that identifies the task that this <strong class="source-inline">Waker</strong> is associated <a id="_idIndexMarker505"/>with onto the <span class="No-Break">ready queue.</span></p>
			<p>After that’s done, we call <strong class="source-inline">unpark</strong> on the executor thread and wake it up. It will now find the task associated with this <strong class="source-inline">Waker</strong> in the ready queue and call <strong class="source-inline">poll</strong> <span class="No-Break">on it.</span></p>
			<p>It’s worth mentioning that many designs take a <em class="italic">shared reference (for example, an Arc&lt;…&gt;)</em> to the <em class="italic">future/task itself</em>, and push that onto the queue. By doing so, they skip a level of indirection that we get here by representing the task as a <strong class="source-inline">usize</strong> instead of passing in a reference <span class="No-Break">to it.</span></p>
			<p>However, I personally think this way of doing it is easier to understand and reason about, and the end result will be <span class="No-Break">the same.</span></p>
			<p class="callout-heading">How does this Waker compare to the one in the standard library?</p>
			<p class="callout">The <strong class="source-inline">Waker</strong> we create here will take the same role as<a id="_idIndexMarker506"/> the <strong class="source-inline">Waker</strong> type from the standard library. The biggest difference is that the <strong class="source-inline">std::task::Waker</strong> method is wrapped in a <strong class="source-inline">Context</strong> struct and requires us to jump through a few hoops when we create it ourselves. Don’t worry – we’ll do all this at the end of this book, but neither of these differences is important for understanding the role it plays, so that’s why we stick to our own simplified version of asynchronous Rust <span class="No-Break">for now.</span></p>
			<p>The last thing we need to do is to change the definition of the <strong class="source-inline">Future</strong> trait so that it takes <strong class="source-inline">&amp;Waker</strong> as <span class="No-Break">an argument.</span></p>
			<h2 id="_idParaDest-150"><a id="_idTextAnchor149"/>Changing the Future definition</h2>
			<p>Since our <strong class="source-inline">Future</strong> definition is in the <strong class="source-inline">future.rs</strong> file, we start by opening <span class="No-Break">that file.</span></p>
			<p>The first thing we need to<a id="_idIndexMarker507"/> change is to pull in the <strong class="source-inline">Waker</strong> so that we can use it. At the top of the file, add the <span class="No-Break">following code:</span></p>
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">ch08/b-reactor-executor/src/future.rs</p>
			<pre class="source-code">
use crate::runtime::Waker;</pre>			<p>The next thing we do is to change our <strong class="source-inline">Future</strong> trait so that it takes <strong class="source-inline">&amp;Waker</strong> as <span class="No-Break">an argument:</span></p>
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">ch08/b-reactor-executor/src/future.rs</p>
			<pre class="source-code">
pub trait Future {
    type Output;
    fn poll(&amp;mut self<strong class="bold">, waker: &amp;Waker</strong>) -&gt; PollState&lt;Self::Output&gt;;
}</pre>			<p>At this point, you have a choice. We won’t be using the <strong class="source-inline">join_all</strong> function or the <strong class="source-inline">JoinAll&lt;F: Future&gt;</strong> struct <span class="No-Break">going forward.</span></p>
			<p>If you don’t want to keep them, you can just delete everything related to <strong class="source-inline">join_all</strong>, and that’s all you need to do <span class="No-Break">in </span><span class="No-Break"><strong class="source-inline">future.rs</strong></span><span class="No-Break">.</span></p>
			<p>If you want to keep them for further experimentation, you need to change the <strong class="source-inline">Future</strong> implementation for <strong class="source-inline">JoinAll</strong> so that it accepts a <strong class="source-inline">waker: &amp;Waker</strong> argument, and remember to pass the <strong class="source-inline">Waker</strong> when polling the joined futures in <span class="No-Break"><strong class="source-inline">match fut.poll(waker)</strong></span><span class="No-Break">.</span></p>
			<p>The remaining things to do in <em class="italic">step 1</em> are to make some minor changes where we implement the <span class="No-Break"><strong class="source-inline">Future</strong></span><span class="No-Break"> trait.</span></p>
			<p>Let’s start in <strong class="source-inline">http.rs</strong>. The first thing we do is adjust our dependencies a little to reflect the changes we made to our <strong class="source-inline">runtime</strong> module, and we add a dependency on our new <strong class="source-inline">Waker</strong>. Replace the <strong class="source-inline">dependencies</strong> section at the top of the file <span class="No-Break">with this:</span></p>
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">ch08/b-reactor-executor/src/http.rs</p>
			<pre class="source-code">
use crate::{future::PollState, runtime::{self, reactor, Waker}, Future};
use mio::Interest;
use std::io::{ErrorKind, Read, Write};</pre>			<p>The compiler will complain about not<a id="_idIndexMarker508"/> finding the reactor yet, but we’ll get to <span class="No-Break">that shortly.</span></p>
			<p>Next, we have to navigate to the <strong class="source-inline">impl Future for HttpGetFuture</strong> block, where we need to change the <strong class="source-inline">poll</strong> method so that it accepts a <strong class="source-inline">&amp;</strong><span class="No-Break"><strong class="source-inline">Waker</strong></span><span class="No-Break"> argument:</span></p>
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">ch08/b-reactor-executor/src/http.rs</p>
			<pre class="source-code">
impl Future for HttpGetFuture {
    type Output = String;
    fn poll(&amp;mut self<strong class="bold">, waker: &amp;Waker</strong>) -&gt; PollState&lt;Self::Output&gt; {
…</pre>			<p>The last file we need to change is <strong class="source-inline">main.rs</strong>. Since <strong class="source-inline">corofy</strong> doesn’t know about <strong class="source-inline">Waker</strong> types, we need to change a few lines in the coroutines it generated for us <span class="No-Break">in </span><span class="No-Break"><strong class="source-inline">main.rs</strong></span><span class="No-Break">.</span></p>
			<p>First of all, we have to add a dependency on our new <strong class="source-inline">Waker</strong>, so add this at the start of <span class="No-Break">the file:</span></p>
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">ch08/b-reactor-executor/src/main.rs</p>
			<pre class="source-code">
use runtime::Waker;</pre>			<p>In the <strong class="source-inline">impl Future for Coroutine</strong>block, change the following three lines of code that <span class="No-Break">I’ve highlighted:</span></p>
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">ch08/b-reactor-executor/src/main.rs</p>
			<pre class="source-code">
fn poll(&amp;mut self<strong class="bold">, waker: &amp;Waker</strong>)
match f1.poll(<strong class="bold">waker</strong>)
match f2.poll(<strong class="bold">waker</strong>)</pre>			<p>And that’s all we need to do in <em class="italic">step 1</em>. We’ll get back to fixing the errors in this file as the last step we do; for now, we<a id="_idIndexMarker509"/> just focus on everything concerning <span class="No-Break">the </span><span class="No-Break"><strong class="source-inline">Waker</strong></span><span class="No-Break">.</span></p>
			<p>The next step will be to create a <span class="No-Break">proper </span><span class="No-Break"><strong class="source-inline">Executor</strong></span><span class="No-Break">.</span></p>
			<h1 id="_idParaDest-151"><a id="_idTextAnchor150"/>Step 2 – Implementing a proper Executor</h1>
			<p>In this step, we’ll create an executor <span class="No-Break">that will:</span></p>
			<ul>
				<li>Hold many top-level futures and <a id="_idIndexMarker510"/>switch <span class="No-Break">between them</span></li>
				<li>Enable us to spawn new top-level futures from anywhere in our <span class="No-Break">asynchronous program</span></li>
				<li>Hand out <strong class="source-inline">Waker</strong> types so that they can sleep when there is nothing to do and wake up when one of the top-level futures <span class="No-Break">can progress</span></li>
				<li>Enable us to run several executors by having each run on its dedicated <span class="No-Break">OS thread</span></li>
			</ul>
			<p class="callout-heading">Note</p>
			<p class="callout">It’s worth mentioning that our executor won’t be fully multithreaded in the sense that tasks/futures can’t be sent from one thread to another, and the different <strong class="source-inline">Executor</strong> instances will not know of each other. Therefore, executors can’t steal work from each other (no work-stealing), and we can’t rely on executors picking tasks from a global <span class="No-Break">task queue.</span></p>
			<p class="callout">The reason is that the <strong class="source-inline">Executor</strong> design will be much more complex if we go down that route, not only because of the added logic but also because we have to add constraints, such as requiring everything to be <strong class="source-inline">Send + </strong><span class="No-Break"><strong class="source-inline">Sync</strong></span><span class="No-Break">.</span></p>
			<p class="callout">Some of the complexity in asynchronous Rust today can be attributed to the fact that many runtimes in Rust are multithreaded by default, which makes asynchronous Rust deviate more from “normal” Rust than it actually <span class="No-Break">needs to.</span></p>
			<p class="callout">It’s worth mentioning that since <a id="_idIndexMarker511"/>most production runtimes in Rust are multithreaded by default, most of them also have a work-stealing executor. This will be similar to the last version of our bartender example in <a href="B20892_01.xhtml#_idTextAnchor014"><span class="No-Break"><em class="italic">Chapter 1</em></span></a>, where we achieved a slightly increased efficiency by letting the bartenders “steal” tasks that are <em class="italic">in progress</em> from <span class="No-Break">each other.</span></p>
			<p class="callout">However, this example should still give you an idea of how we can leverage all the cores on a machine to run asynchronous tasks, giving us both concurrency and parallelism, even though it will have <span class="No-Break">limited capabilities.</span></p>
			<p>Let’s start by opening up <strong class="source-inline">executor.rs</strong> located in the <span class="No-Break"><strong class="source-inline">runtime</strong></span><span class="No-Break"> subfolder.</span></p>
			<p>This file should already contain our <strong class="source-inline">Waker</strong> and the dependencies we need, so let’s start by adding the following lines of code just below <span class="No-Break">our dependencies:</span></p>
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">ch08/b-reactor-executor/src/runtime/executor.rs</p>
			<pre class="source-code">
type Task = Box&lt;dyn Future&lt;Output = String&gt;&gt;;
thread_local! {
    static CURRENT_EXEC: ExecutorCore = ExecutorCore::default();
}</pre>			<p>The first line is a <em class="italic">type alias</em>; it simply lets us create an alias called <strong class="source-inline">Task</strong> that refers to the type: <strong class="source-inline">Box&lt;dyn Future&lt;Output = String&gt;&gt;</strong>. This will help keep our code a little <span class="No-Break">bit cleaner.</span></p>
			<p>The next line might be new to some readers. We define a thread-local static variable by using the <span class="No-Break"><strong class="source-inline">thread_local!</strong></span><span class="No-Break"> macro.</span></p>
			<p>The <strong class="source-inline">thread_local!</strong> macro lets us define a static variable that’s unique to the thread it’s first called from. This means that all threads we create will have their own instance, and it’s impossible for one thread to access another thread’s <span class="No-Break"><strong class="source-inline">CURRENT_EXEC</strong></span><span class="No-Break"> variable.</span></p>
			<p>We call the variable <strong class="source-inline">CURRENT_EXEC</strong> since it holds the <strong class="source-inline">Executor</strong> that’s currently running on <span class="No-Break">this thread.</span></p>
			<p>The next lines we add to this <a id="_idIndexMarker512"/>file is the definition <span class="No-Break">of </span><span class="No-Break"><strong class="source-inline">ExecutorCore</strong></span><span class="No-Break">:</span></p>
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">ch08/b-reactor-executor/src/runtime/executor.rs</p>
			<pre class="source-code">
#[derive(Default)]
struct ExecutorCore {
    tasks: RefCell&lt;HashMap&lt;usize, Task&gt;&gt;,
    ready_queue: Arc&lt;Mutex&lt;Vec&lt;usize&gt;&gt;&gt;,
    next_id: Cell&lt;usize&gt;,
}</pre>			<p><strong class="source-inline">ExecutorCore</strong> holds all the state for <span class="No-Break">our </span><span class="No-Break"><strong class="source-inline">Executor</strong></span><span class="No-Break">:</span></p>
			<ul>
				<li><strong class="source-inline">tasks</strong> – This is a <strong class="source-inline">HashMap</strong> with a <strong class="source-inline">usize</strong> as the <em class="italic">key</em> and a <strong class="source-inline">Task</strong> (remember the alias we created previously) as <em class="italic">data</em>. This will hold all the top-level futures associated with the executor on this thread and allow us to give each an <strong class="source-inline">id</strong> property to identify them. We can’t simply mutate a static variable, so we need internal mutability here. Since this will only be callable from one thread, a <strong class="source-inline">RefCell</strong> will do so since there is no need <span class="No-Break">for synchronization.</span></li>
				<li><strong class="source-inline">ready_queue</strong> – This is a simple <strong class="source-inline">Vec&lt;usize&gt;</strong> that stores the IDs of tasks that should be polled by the executor. If we refer back to <span class="No-Break"><em class="italic">Figure 8</em></span><em class="italic">.7</em>, you’ll see how this fits into the design we outlined there. As mentioned earlier, we could store something such as an <strong class="source-inline">Arc&lt;dyn Future&lt;…&gt;&gt;</strong> here instead, but that adds quite a bit of complexity to our example. The only downside with the current design is that instead of getting a reference to the task directly, we have to look it up in our <strong class="source-inline">tasks</strong> collection, which takes time. An <strong class="source-inline">Arc&lt;…&gt;</strong> (shared reference) to this collection will be given to each <strong class="source-inline">Waker</strong> that this executor creates. Since the <strong class="source-inline">Waker</strong> can (and will) be sent to a different thread and signal that a specific task is ready by <a id="_idIndexMarker513"/>adding the task’s ID to <strong class="source-inline">ready_queue</strong>, we need to wrap it in <span class="No-Break">an </span><span class="No-Break"><strong class="source-inline">Arc&lt;Mutex&lt;…&gt;&gt;</strong></span><span class="No-Break">.</span></li>
				<li><strong class="source-inline">next_id</strong> – This is a counter that gives out the next available I, which means that it should never hand out the same ID twice for this executor instance. We’ll use this to give each top-level future a unique ID. Since the executor instance will only be accessible on the same thread it was created, a simple <strong class="source-inline">Cell</strong> will suffice in giving us the internal mutability <span class="No-Break">we need.</span></li>
			</ul>
			<p><strong class="source-inline">ExecutorCore</strong> derives the <strong class="source-inline">Default</strong> trait since there is no special initial state we need here, and it keeps the code short <span class="No-Break">and concise.</span></p>
			<p>The next function is an important one. The <strong class="source-inline">spawn</strong> function allows us to register new top-level futures with our executor from anywhere in <span class="No-Break">our program:</span></p>
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">ch08/b-reactor-executor/src/runtime/executor.rs</p>
			<pre class="source-code">
pub fn spawn&lt;F&gt;(future: F)
where
    F: Future&lt;Output = String&gt; + 'static,
{
    CURRENT_EXEC.with(|e| {
        let id = e.next_id.get();
        e.tasks.borrow_mut().insert(id, Box::new(future));
        e.ready_queue.lock().map(|mut q| q.push(id)).unwrap();
        e.next_id.set(id + 1);
    });
}</pre>			<p>The <strong class="source-inline">spawn</strong> function does a <span class="No-Break">few things:</span></p>
			<ul>
				<li>It gets the next <span class="No-Break">available ID.</span></li>
				<li>It assigns the ID to the future it receives and stores it in <span class="No-Break">a </span><span class="No-Break"><strong class="source-inline">HashMap</strong></span><span class="No-Break">.</span></li>
				<li>It adds the ID that represents this task to <strong class="source-inline">ready_queue</strong> so that it’s polled at least once (remember that <strong class="source-inline">Future</strong> traits in Rust don’t do anything unless they’re polled at <span class="No-Break">least once).</span></li>
				<li>It increases the ID counter <span class="No-Break">by one.</span></li>
			</ul>
			<p>The unfamiliar syntax accessing <strong class="source-inline">CURRENT_EXEC</strong> by calling <strong class="source-inline">with</strong> and passing in a closure is just a consequence of how thread local statics is implemented in Rust. You’ll also notice that we must use a<a id="_idIndexMarker514"/> few special methods because we use <strong class="source-inline">RefCell</strong> and <strong class="source-inline">Cell</strong> for internal mutability for <strong class="source-inline">tasks</strong> and <strong class="source-inline">next_id</strong>, but there is really nothing inherently complex about this except being a <span class="No-Break">bit unfamiliar.</span></p>
			<p class="callout-heading">A quick note about static lifetimes</p>
			<p class="callout">When a <strong class="source-inline">'static</strong> lifetime is used as<a id="_idIndexMarker515"/> a trait bound as we do here, it doesn’t actually mean that the lifetime of the <strong class="source-inline">Future</strong> trait we pass in <em class="italic">must be</em> static (meaning it will have to live until the end of the program). It means that it <em class="italic">must be able to</em> last until the end of the program, or, put another way, the lifetime can’t be constrained in <span class="No-Break">any way.</span></p>
			<p class="callout">Most often, when you encounter something that requires a <strong class="source-inline">'static</strong> bound, it simply means that you’ll have to give ownership over the thing you pass in. If you pass in any references, they need to have a <strong class="source-inline">'static</strong> lifetime. It’s less difficult to satisfy this constraint than you <span class="No-Break">might expect.</span></p>
			<p>The final part of <em class="italic">step 2</em> will be to define and implement the <strong class="source-inline">Executor</strong> <span class="No-Break">struct itself.</span></p>
			<p>The <strong class="source-inline">Executor</strong> struct is very simple, and there is only one line of code <span class="No-Break">to add:</span></p>
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">ch08/b-reactor-executor/src/runtime/executor.rs</p>
			<pre class="source-code">
pub struct Executor;</pre>			<p>Since all the state we need for our example is held in <strong class="source-inline">ExecutorCore</strong>, which is a static thread-local variable, our <strong class="source-inline">Executor</strong> struct doesn’t need any state. This also means that we don’t strictly need a struct at all, but to keep the API somewhat familiar, we do <span class="No-Break">it anyway.</span></p>
			<p>Most of the executor implementation is a handful of simple helper methods that end up in a <strong class="source-inline">block_on</strong> function, which is<a id="_idIndexMarker516"/> where the interesting parts <span class="No-Break">really happen.</span></p>
			<p>Since these helper methods are short and easy to understand, I’ll present them all here and just briefly go over what <span class="No-Break">they do:</span></p>
			<p class="callout-heading">Note</p>
			<p class="callout">We open the <strong class="source-inline">impl Executor</strong> block here but will not close it until we’ve finished implementing the <span class="No-Break"><strong class="source-inline">block_on</strong></span><span class="No-Break"> function.</span></p>
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">ch08/b-reactor-executor/src/runtime/executor.rs</p>
			<pre class="source-code">
impl Executor {
    pub fn new() -&gt; Self {
        Self {}
    }
    fn pop_ready(&amp;self) -&gt; Option&lt;usize&gt; {
        CURRENT_EXEC.with(|q| q.ready_queue.lock().map(|mut q| q.pop()).unwrap())
    }
    fn get_future(&amp;self, id: usize) -&gt; Option&lt;Task&gt; {
        CURRENT_EXEC.with(|q| q.tasks.borrow_mut().remove(&amp;id))
    }
    fn get_waker(&amp;self, id: usize) -&gt; Waker {
        Waker {
            id,
            thread: thread::current(),
            ready_queue: CURRENT_EXEC.with(|q| q.ready_queue.clone()),
        }
    }
    fn insert_task(&amp;self, id: usize, task: Task) {
        CURRENT_EXEC.with(|q| q.tasks.borrow_mut().insert(id, task));
    }
    fn task_count(&amp;self) -&gt; usize {
        CURRENT_EXEC.with(|q| q.tasks.borrow().len())
    }</pre>			<p>So, we have six <span class="No-Break">methods here:</span></p>
			<ul>
				<li><strong class="source-inline">new</strong> – Creates a new <strong class="source-inline">Executor</strong> instance. For simplicity, we have no initialization here, and everything is done<a id="_idIndexMarker517"/> lazily by design in the <span class="No-Break"><strong class="source-inline">thread_local!</strong></span><span class="No-Break"> macro.</span></li>
				<li><strong class="source-inline">pop_ready</strong> – This function takes a lock on <strong class="source-inline">read_queue</strong> and pops off an ID that’s ready from the back of <strong class="source-inline">Vec</strong>. Calling <strong class="source-inline">pop</strong> here means that we also remove the item from the collection. As a side note, since <strong class="source-inline">Waker</strong> pushes its ID to the <em class="italic">back</em> of <strong class="source-inline">ready_queue</strong> and we pop off from the <em class="italic">back</em> as well, we essentially get a <strong class="bold">Last In First Out</strong> (<strong class="bold">LIFO</strong>) queue. Using<a id="_idIndexMarker518"/> something such as <strong class="source-inline">VecDeque</strong> from the standard library would easily allow us to choose the order in which we remove items from the queue if we wish to change <span class="No-Break">that behavior.</span></li>
				<li><strong class="source-inline">get_future</strong> – This function <a id="_idIndexMarker519"/>takes the ID of a top-level future as an argument, removes the future from the <strong class="source-inline">tasks</strong> collection, and returns it (if the task is found). This means that if the task returns <strong class="source-inline">NotReady</strong> (signaling that we’re not done with it), we need to remember to add it back to the <span class="No-Break">collection again.</span></li>
				<li><strong class="source-inline">get_waker</strong> – This function creates a new <span class="No-Break"><strong class="source-inline">Waker</strong></span><span class="No-Break"> instance.</span></li>
				<li><strong class="source-inline">insert_task</strong> – This function takes an <strong class="source-inline">id</strong> property and a <strong class="source-inline">Task</strong> property and inserts them into our <span class="No-Break"><strong class="source-inline">tasks</strong></span><span class="No-Break"> collection.</span></li>
				<li><strong class="source-inline">task_count</strong> – This function simply returns a count of how many tasks we have in <span class="No-Break">the queue.</span></li>
			</ul>
			<p>The final and last part of the <strong class="source-inline">Executor</strong> implementation is the <strong class="source-inline">block_on</strong> function. This is also where we close the <strong class="source-inline">impl </strong><span class="No-Break"><strong class="source-inline">Executor</strong></span><span class="No-Break"> block:</span></p>
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">ch08/b-reactor-executor/src/runtime/executor.rs</p>
			<pre class="source-code">
pub fn block_on&lt;F&gt;(&amp;mut self, future: F)
  where
      F: Future&lt;Output = String&gt; + 'static,
  {
      spawn(future);
      loop {
          while let Some(id) = self.pop_ready() {
        let mut future = match self.get_future(id) {
          Some(f) =&gt; f,
          // guard against false wakeups
          None =&gt; continue,
        };
        let waker = self.get_waker(id);
        match future.poll(&amp;waker) {
          PollState::NotReady =&gt; self.insert_task(id, future),
          PollState::Ready(_) =&gt; continue,
        }
      }
      let task_count = self.task_count();
      let name = thread::current().name().unwrap_or_default().to_string();
      if task_count &gt; 0 {
        println!("{name}: {task_count} pending tasks. Sleep until notified.");
        thread::park();
      } else {
        println!("{name}: All tasks are finished");
        break;
      }
    }
  }
}</pre>			<p><strong class="source-inline">block_on</strong> will be the entry point to our <strong class="source-inline">Executor</strong>. Often, you will pass in one top-level future first, and when the top-level future progresses, it will spawn new top-level futures onto our executor. Each new future can, of course, spawn new futures onto the <strong class="source-inline">Executor</strong> too, and that’s how an asynchronous program <span class="No-Break">basically works.</span></p>
			<p>In many ways, you can view this first top-level future in the same way you view the <strong class="source-inline">main</strong> function in a normal Rust program. <strong class="source-inline">spawn</strong> is similar to <strong class="source-inline">thread::spawn</strong>, with the exception that the tasks stay on the same OS thread in this example. This means the tasks won’t be able to run in parallel, which in turn allows us to avoid any need for synchronization between tasks to <a id="_idIndexMarker520"/>avoid <span class="No-Break">data races.</span></p>
			<p>Let’s go through the function step <span class="No-Break">by step:</span></p>
			<ol>
				<li>The first thing we do is spawn the future we received onto ourselves. There are many ways this could be implemented, but this is the easiest way to <span class="No-Break">do it.</span></li>
				<li>Then, we have a loop that will run as long as our asynchronous program <span class="No-Break">is running.</span></li>
				<li>Every time we loop, we create an inner <strong class="source-inline">while let Some(…)</strong> loop that runs as long as there are tasks <span class="No-Break">in </span><span class="No-Break"><strong class="source-inline">ready_queue</strong></span><span class="No-Break">.</span></li>
				<li>If there is a task in <strong class="source-inline">ready_queue</strong>, we take ownership of the <strong class="source-inline">Future</strong> object by removing it from the collection. We guard against false wakeups by just continuing if there is no future there anymore (meaning that we’re done with it but still get a wakeup). This will, for example, happen on Windows since we get a <strong class="source-inline">READABLE</strong> event when the connection closes, but even though we could filter those events out, <strong class="source-inline">mio</strong> doesn’t guarantee that false wakeups won’t happen, so we have to handle that <span class="No-Break">possibility anyway.</span></li>
				<li>Next, we create a new <strong class="source-inline">Waker</strong> instance that we can pass into <strong class="source-inline">Future::poll()</strong>. Remember that this <strong class="source-inline">Waker</strong> instance now holds the <strong class="source-inline">id</strong> property that identifies this specific <strong class="source-inline">Future</strong> trait and a handle to the thread we’re currently <span class="No-Break">running on.</span></li>
				<li>The next step is to <span class="No-Break">call </span><span class="No-Break"><strong class="source-inline">Future::poll</strong></span><span class="No-Break">.</span></li>
				<li>If we get <strong class="source-inline">NotReady</strong> in return, we insert the task back into our <strong class="source-inline">tasks</strong> collection. I want to emphasize that when a <strong class="source-inline">Future</strong> trait returns <strong class="source-inline">NotReady</strong>, we know it will arrange it so that <strong class="source-inline">Waker::wake</strong> is called at a later point in time. It’s not the executor’s responsibility to track the readiness of <span class="No-Break">this future.</span></li>
				<li>If the <strong class="source-inline">Future</strong> trait returns <strong class="source-inline">Ready</strong>, we simply continue to the next item in the ready queue. Since we took ownership over the <strong class="source-inline">Future</strong> trait, this will drop the object before we enter the next iteration of the <strong class="source-inline">while </strong><span class="No-Break"><strong class="source-inline">let</strong></span><span class="No-Break"> loop.</span></li>
				<li>Now that we’ve polled all the tasks in our ready queue, the first thing we do is get a task count to see how<a id="_idIndexMarker521"/> many tasks we <span class="No-Break">have left.</span></li>
				<li>We also get the name of the current thread for future logging purposes (it has nothing to do with how our <span class="No-Break">executor works).</span></li>
				<li>If the task count is larger than <strong class="source-inline">0</strong>, we print a message to the terminal and call <strong class="source-inline">thread::park()</strong>. Parking the thread will yield control to the OS scheduler, and our <strong class="source-inline">Executor</strong> does nothing until it’s woken <span class="No-Break">up again.</span></li>
				<li>If the task count is <strong class="source-inline">0</strong>, we’re done with our asynchronous program and exit the <span class="No-Break">main loop.</span></li>
			</ol>
			<p>That’s pretty much all there is to it. By this point, we’ve covered all our goals for <em class="italic">step 2</em>, so we can continue to the last and final step and implement a <strong class="source-inline">Reactor</strong> for our runtime that will wake up our executor when <span class="No-Break">something happens.</span></p>
			<h1 id="_idParaDest-152"><a id="_idTextAnchor151"/>Step 3 – Implementing a proper Reactor</h1>
			<p>The final part of our <a id="_idIndexMarker522"/>example is the <strong class="source-inline">Reactor</strong>. Our <span class="No-Break"><strong class="source-inline">Reactor</strong></span><span class="No-Break"> will:</span></p>
			<ul>
				<li>Efficiently wait and handle events that our runtime is <span class="No-Break">interested in</span></li>
				<li>Store a collection of <strong class="source-inline">Waker</strong> types and make sure to wake the correct <strong class="source-inline">Waker</strong> when it gets a notification on a source <span class="No-Break">it’s tracking</span></li>
				<li>Provide the necessary mechanisms for leaf futures such as <strong class="source-inline">HttpGetFuture</strong>, to register and deregister interests <span class="No-Break">in events</span></li>
				<li>Provide a way for leaf futures to store the last <span class="No-Break">received </span><span class="No-Break"><strong class="source-inline">Waker</strong></span></li>
			</ul>
			<p>When we’re done with this step, we should have everything we need for our runtime, so let’s get <span class="No-Break">to it.</span></p>
			<p>Start by opening the <span class="No-Break"><strong class="source-inline">reactor.rs</strong></span><span class="No-Break"> file.</span></p>
			<p>The first thing we do is<a id="_idIndexMarker523"/> add the dependencies <span class="No-Break">we need:</span></p>
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">ch08/b-reactor-executor/src/runtime/reactor.rs</p>
			<pre class="source-code">
use crate::runtime::Waker;
use mio::{net::TcpStream, Events, Interest, Poll, Registry, Token};
use std::{
    collections::HashMap,
    sync::{
        atomic::{AtomicUsize, Ordering},
        Arc, Mutex, OnceLock,
    },
    thread,
};</pre>			<p>After we’ve added our dependencies, we create a <em class="italic">type alias</em> called <strong class="source-inline">Wakers</strong> that aliases the type for our <span class="No-Break"><strong class="source-inline">wakers</strong></span><span class="No-Break"> collection:</span></p>
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">ch08/b-reactor-executor/src/runtime/reactor.rs</p>
			<pre class="source-code">
type Wakers = Arc&lt;Mutex&lt;HashMap&lt;usize, Waker&gt;&gt;&gt;;</pre>			<p>The next line will declare a static variable <span class="No-Break">called </span><span class="No-Break"><strong class="source-inline">REACTOR</strong></span><span class="No-Break">:</span></p>
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">ch08/b-reactor-executor/src/runtime/reactor.rs</p>
			<pre class="source-code">
static REACTOR: OnceLock&lt;Reactor&gt; = OnceLock::new();</pre>			<p>This variable will hold a <strong class="source-inline">OnceLock&lt;Reactor&gt;</strong>. In contrast to our <strong class="source-inline">CURRENT_EXEC</strong> static variable, this will be possible to access from different threads. <strong class="source-inline">OnceLock</strong> allows us to define a static variable that we can write to once so that we can initialize it when we start our <strong class="source-inline">Reactor</strong>. By doing so, we also make sure that there can only be a single instance of this specific reactor<a id="_idIndexMarker524"/> running in <span class="No-Break">our program.</span></p>
			<p>The variable will be private to this module, so we create a public function allowing other parts of our program to <span class="No-Break">access it:</span></p>
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">ch08/b-reactor-executor/src/runtime/reactor.rs</p>
			<pre class="source-code">
pub fn reactor() -&gt; &amp;'static Reactor {
    REACTOR.get().expect("Called outside an runtime context")
}</pre>			<p>The next thing we do is define our <span class="No-Break"><strong class="source-inline">Reactor</strong></span><span class="No-Break"> struct:</span></p>
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">ch08/b-reactor-executor/src/runtime/reactor.rs</p>
			<pre class="source-code">
pub struct Reactor {
    wakers: Wakers,
    registry: Registry,
    next_id: AtomicUsize,
}</pre>			<p>This will be all the state our <strong class="source-inline">Reactor</strong> struct needs <span class="No-Break">to hold:</span></p>
			<ul>
				<li><strong class="source-inline">wakers</strong> – A <strong class="source-inline">HashMap</strong> of <strong class="source-inline">Waker</strong> objects, each identified by <span class="No-Break">an integer</span></li>
				<li><strong class="source-inline">registry</strong> – Holds a <strong class="source-inline">Registry</strong> instance so that we can interact with the event queue <span class="No-Break">in </span><span class="No-Break"><strong class="source-inline">mio</strong></span></li>
				<li><strong class="source-inline">next_id</strong> – Stores the next available ID so that we can track which event occurred and which <strong class="source-inline">Waker</strong> should <span class="No-Break">be woken</span></li>
			</ul>
			<p>The implementation of <strong class="source-inline">Reactor</strong> is actually<a id="_idIndexMarker525"/> quite simple. It’s only four short methods for interacting with the <strong class="source-inline">Reactor</strong> instance, so I’ll present them all here and give a brief <span class="No-Break">explanation next:</span></p>
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">ch08/b-reactor-executor/src/runtime/reactor.rs</p>
			<pre class="source-code">
impl Reactor {
    pub fn register(&amp;self, stream: &amp;mut TcpStream, interest: Interest, id: usize) {
        self.registry.register(stream, Token(id), interest).unwrap();
    }
    pub fn set_waker(&amp;self, waker: &amp;Waker, id: usize) {
        let _ = self
            .wakers
            .lock()
            .map(|mut w| w.insert(id, waker.clone()).is_none())
            .unwrap();
    }
    pub fn deregister(&amp;self, stream: &amp;mut TcpStream, id: usize) {
        self.wakers.lock().map(|mut w| w.remove(&amp;id)).unwrap();
        self.registry.deregister(stream).unwrap();
    }
    pub fn next_id(&amp;self) -&gt; usize {
        self.next_id.fetch_add(1, Ordering::Relaxed)
    }
}</pre>			<p>Let’s briefly explain what these four <span class="No-Break">methods do:</span></p>
			<ul>
				<li><strong class="source-inline">register</strong> – This method is a thin wrapper around <strong class="source-inline">Registry::register</strong>, which we know from <a href="B20892_04.xhtml#_idTextAnchor081"><span class="No-Break"><em class="italic">Chapter 4</em></span></a>. The one thing to make a note of here is that we pass in an <strong class="source-inline">id</strong> property so that we can identify which event has occurred when we receive a notification <span class="No-Break">later on.</span></li>
				<li><strong class="source-inline">set_waker</strong> – This method<a id="_idIndexMarker526"/> adds a <strong class="source-inline">Waker</strong> to our <strong class="source-inline">HashMap</strong> using the provided <strong class="source-inline">id</strong> property as a key to identify it. If there is a <strong class="source-inline">Waker</strong> there already, we replace it and drop the old one. An important point to remember is that <strong class="bold">we should always store the most recent Waker</strong> so that this function can be called multiple times, even though there is already a <strong class="source-inline">Waker</strong> associated with <span class="No-Break">the </span><span class="No-Break"><strong class="source-inline">TcpStream</strong></span><span class="No-Break">.</span></li>
				<li><strong class="source-inline">deregister</strong> – This function does two things. First, it removes the <strong class="source-inline">Waker</strong> from our <strong class="source-inline">wakers</strong> collection. Then, it deregisters the <strong class="source-inline">TcpStream</strong> from our <span class="No-Break"><strong class="source-inline">Poll</strong></span><span class="No-Break"> instance.</span></li>
				<li>I want to remind you at this point that while we only work with <strong class="source-inline">TcpStream</strong> in our examples, this could, in theory, be done with anything that implements <strong class="source-inline">mio</strong>’s <strong class="source-inline">Source</strong> trait, so the same thought process is valid in a much broader context than what we deal <span class="No-Break">with here.</span></li>
				<li><strong class="source-inline">next_id</strong> – This simply gets the current <strong class="source-inline">next_id</strong> value and increments the counter atomically. We don’t care about any happens before/after relationships happening here; we only care about not handing out the same value twice, so <strong class="source-inline">Ordering::Relaxed</strong> will suffice here. Memory ordering in atomic operations is a complex topic that we won’t be able to dive into in this book, but if you want to know more about the different memory orderings in Rust and what they mean, the official documentation is the right place to <span class="No-Break">start: </span><a href="https://doc.rust-lang.org/stable/std/sync/atomic/enum.Ordering.html"><span class="No-Break">https://doc.rust-lang.org/stable/std/sync/atomic/enum.Ordering.html</span></a><span class="No-Break">.</span></li>
			</ul>
			<p>Now that our <strong class="source-inline">Reactor</strong> is set up, we<a id="_idIndexMarker527"/> only have two short functions left. The first one is <strong class="source-inline">event_loop</strong>, which will hold the logic for our event loop that waits and reacts to <span class="No-Break">new events:</span></p>
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">ch08/b-reactor-executor/src/runtime/reactor.rs</p>
			<pre class="source-code">
fn event_loop(mut poll: Poll, wakers: Wakers) {
    let mut events = Events::with_capacity(100);
    loop {
        poll.poll(&amp;mut events, None).unwrap();
        for e in events.iter() {
            let Token(id) = e.token();
            let wakers = wakers.lock().unwrap();
            if let Some(waker) = wakers.get(&amp;id) {
                waker.wake();
            }
        }
    }
}</pre>			<p>This function takes a <strong class="source-inline">Poll</strong> instance and a <strong class="source-inline">Wakers</strong> collection as arguments. Let’s go through it step <span class="No-Break">by step:</span></p>
			<ul>
				<li>The first thing we do is create an <strong class="source-inline">events</strong> collection. This should be familiar since we did the exact same thing in <a href="B20892_04.xhtml#_idTextAnchor081"><span class="No-Break"><em class="italic">Chapter 4</em></span></a><span class="No-Break">.</span></li>
				<li>The next thing we do is create a <strong class="source-inline">loop</strong> that in our case will continue to loop for eternity. This makes our example short and simple, but it has the downside that we have no way of shutting our event loop down once it’s started. Fixing that is not especially difficult, but since it won’t be necessary for our example, we don’t cover <span class="No-Break">this here.</span></li>
				<li>Inside the loop, we call <strong class="source-inline">Poll::poll</strong> with a timeout of <strong class="source-inline">None</strong>, which means it will never time out<a id="_idIndexMarker528"/> and block until it receives an <span class="No-Break">event notification.</span></li>
				<li>When the call returns, we loop through every event <span class="No-Break">we receive.</span></li>
				<li>If we receive an event, it means that something we registered interest in happened, so we get the <strong class="source-inline">id</strong> we passed in when we first registered an interest in events on <span class="No-Break">this </span><span class="No-Break"><strong class="source-inline">TcpStream</strong></span><span class="No-Break">.</span></li>
				<li>Lastly, we try to get the associated <strong class="source-inline">Waker</strong> and call <strong class="source-inline">Waker::wake</strong> on it. We guard ourselves from the fact that the <strong class="source-inline">Waker</strong> may have been removed from our collection already, in which case we <span class="No-Break">do nothing.</span></li>
			</ul>
			<p>It’s worth noting that we can filter events if we want to here. Tokio provides some methods on the <strong class="source-inline">Event</strong> object to check several things about the event it reported. For our use in this example, we don’t need to <span class="No-Break">filter events.</span></p>
			<p>Finally, the last function is the second public function in this module and the one that initializes and starts <span class="No-Break">the runtime:</span></p>
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">ch08/b-reactor-executor/src/runtime/runtime.rs</p>
			<pre class="source-code">
pub fn start() {
    use thread::spawn;
    let wakers = Arc::new(Mutex::new(HashMap::new()));
    let poll = Poll::new().unwrap();
    let registry = poll.registry().try_clone().unwrap();
    let next_id = AtomicUsize::new(1);
    let reactor = Reactor {
        wakers: wakers.clone(),
        registry,
        next_id,
    };
    REACTOR.set(reactor).ok().expect("Reactor already running");
    spawn(move || event_loop(poll, wakers));
}</pre>			<p>The <strong class="source-inline">start</strong> method should be fairly easy to understand. The first thing we do is create our <strong class="source-inline">Wakers</strong> collection and our <strong class="source-inline">Poll</strong> instance. From the <strong class="source-inline">Poll</strong> instance, we get an owned version of <strong class="source-inline">Registry</strong>. We initialize <strong class="source-inline">next_id</strong> to <strong class="source-inline">1</strong> (for debugging purposes, I wanted to initialize it to a different start value than our <strong class="source-inline">Executor</strong>) and create our <span class="No-Break"><strong class="source-inline">Reactor</strong></span><span class="No-Break"> object.</span></p>
			<p>Then, we set the static variable we named <strong class="source-inline">REACTOR</strong> by giving it our <span class="No-Break"><strong class="source-inline">Reactor</strong></span><span class="No-Break"> instance.</span></p>
			<p>The last thing is probably the <em class="italic">most important one to pay attention to</em>. We spawn a new OS thread and start our <strong class="source-inline">event_loop</strong> function on that one. This also means that we pass on our <strong class="source-inline">Poll</strong> instance to <a id="_idIndexMarker529"/>the event loop thread <span class="No-Break">for good.</span></p>
			<p>Now, the best practice would be to store the <strong class="source-inline">JoinHandle</strong> returned from <strong class="source-inline">spawn</strong> so that we can join the thread later on, but our thread has no way to shut down the event loop anyway, so joining it later makes little sense, and we simply discard <span class="No-Break">the handle.</span></p>
			<p>I don’t know if you agree with me, but the logic here is not that complex when we break it down into smaller pieces. Since we know how <strong class="source-inline">epoll</strong> and <strong class="source-inline">mio</strong> work already, the rest is pretty easy <span class="No-Break">to understand.</span></p>
			<p>Now, we’re not done yet. We still have some small changes to make to our <strong class="source-inline">HttpGetFuture</strong> leaf future since it doesn’t register with the reactor at the moment. Let’s <span class="No-Break">fix that.</span></p>
			<p>Start by opening the <span class="No-Break"><strong class="source-inline">http.rs</strong></span><span class="No-Break"> file.</span></p>
			<p>Since we already added the correct imports when we opened the file to adapt everything to the new <strong class="source-inline">Future</strong> interface, there are<a id="_idIndexMarker530"/> only a few places we need to change that so this leaf future integrates nicely with <span class="No-Break">our reactor.</span></p>
			<p>The first thing we do is give <strong class="source-inline">HttpGetFuture</strong> an identity. It’s the source of events we want to track with our <strong class="source-inline">Reactor</strong>, so we want it to have the same ID until we’re done <span class="No-Break">with it:</span></p>
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">ch08/b-reactor-executor/src/http.rs</p>
			<pre class="source-code">
struct HttpGetFuture {
    stream: Option&lt;mio::net::TcpStream&gt;,
    buffer: Vec&lt;u8&gt;,
    path: String,
    <strong class="bold">id: usize,</strong>
}</pre>			<p>We also need to retrieve a new ID from the reactor when the future <span class="No-Break">is created:</span></p>
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">ch08/b-reactor-executor/src/http.rs</p>
			<pre class="source-code">
impl HttpGetFuture {
    fn new(path: String) -&gt; Self {
        <strong class="bold">let id = reactor().next_id();</strong>
        Self {
            stream: None,
            buffer: vec![],
            path,
            <strong class="bold">id,</strong>
        }
    }</pre>			<p>Next, we have to locate the <strong class="source-inline">poll</strong> implementation <span class="No-Break">for </span><span class="No-Break"><strong class="source-inline">HttpGetFuture</strong></span><span class="No-Break">.</span></p>
			<p>The first thing we need to do is make sure that we register interest with our <strong class="source-inline">Poll</strong> instance and register the <strong class="source-inline">Waker</strong> we receive with the <strong class="source-inline">Reactor</strong> the first time the future gets polled. Since we don’t register directly<a id="_idIndexMarker531"/> with <strong class="source-inline">Registry</strong> anymore, we remove that line of code and add these new <span class="No-Break">lines instead:</span></p>
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">ch08/b-reactor-executor/src/http.rs</p>
			<pre class="source-code">
if self.stream.is_none() {
            println!("FIRST POLL - START OPERATION");
            self.write_request();
            <strong class="bold">let stream = self.stream.as_mut().unwrap();</strong>
<strong class="bold">            runtime::reactor().register(stream, Interest::READABLE, self.id);</strong>
            <strong class="bold">runtime::reactor().set_waker(waker, self.id);</strong>
        }</pre>			<p>Lastly, we need to make some minor changes to how we handle the different conditions when reading <span class="No-Break">from </span><span class="No-Break"><strong class="source-inline">TcpStream</strong></span><span class="No-Break">:</span></p>
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">ch08/b-reactor-executor/src/http.rs</p>
			<pre class="source-code">
match self.stream.as_mut().unwrap().read(&amp;mut buff) {
                Ok(0) =&gt; {
                    let s = String::from_utf8_lossy(&amp;self.buffer);
                    <strong class="bold">runtime::reactor().deregister(self.stream.as_mut().unwrap(), self.id);</strong>
                    break PollState::Ready(s.to_string());
                }
                Ok(n) =&gt; {
                    self.buffer.extend(&amp;buff[0..n]);
                    continue;
                }
                Err(e) if e.kind() == ErrorKind::WouldBlock =&gt; {
                    <strong class="bold">runtime::reactor().set_waker(waker, self.id);</strong>
                    break PollState::NotReady;
                }
                Err(e) =&gt; panic!("{e:?}"),
            }</pre>			<p>The first change is to deregister the<a id="_idIndexMarker532"/> stream from our <strong class="source-inline">Poll</strong> instance when <span class="No-Break">we’re done.</span></p>
			<p>The second change is a little more subtle. If you read the documentation for <strong class="source-inline">Future::poll</strong> in Rust (<a href="https://doc.rust-lang.org/stable/std/future/trait.Future.html#tymethod.poll">https://doc.rust-lang.org/stable/std/future/trait.Future.html#tymethod.poll</a>) carefully, you’ll see that it’s expected that the <strong class="source-inline">Waker</strong> from the <em class="italic">most recent call</em> should be scheduled to wake up. That means that every time we get a <strong class="source-inline">WouldBlock</strong> error, we need to make sure we store the most <span class="No-Break">recent </span><span class="No-Break"><strong class="source-inline">Waker</strong></span><span class="No-Break">.</span></p>
			<p>The reason is that the future could have moved to a different executor in between calls, and we need to wake up the correct one (it won’t be possible to move futures like those in our example, but let’s play by the <span class="No-Break">same rules).</span></p>
			<p>And <span class="No-Break">that’s it!</span></p>
			<p>Congratulations! You’ve now created a fully working runtime based on the reactor-executor pattern. <span class="No-Break">Well done!</span></p>
			<p>Now, it’s time to test it and run a few experiments <span class="No-Break">with it.</span></p>
			<p>Let’s go back to <strong class="source-inline">main.rs</strong> and change the <strong class="source-inline">main</strong> function so that we get our program running correctly with our <span class="No-Break">new runtime.</span></p>
			<p>First of all, let’s remove the <a id="_idIndexMarker533"/>dependency on the <strong class="source-inline">Runtime</strong> struct and make sure our imports look <span class="No-Break">like this:</span></p>
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">ch08/b-reactor-executor/src/main.rs</p>
			<pre class="source-code">
mod future;
mod http;
mod runtime;
use future::{Future, PollState};
use runtime::Waker;</pre>			<p>Next, we need to make sure that we initialize our runtime and pass in our future to <strong class="source-inline">executor.block_on</strong>. Our <strong class="source-inline">main</strong> function should look <span class="No-Break">like this:</span></p>
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">ch08/b-reactor-executor/src/main.rs</p>
			<pre class="source-code">
fn main() {
    let mut executor = runtime::init();
    executor.block_on(async_main());
}</pre>			<p>And finally, let’s try it out by <span class="No-Break">running it:</span></p>
			<pre class="source-code">
<strong class="source-inline">cargo run</strong>.</pre>			<p>You should get the <span class="No-Break">following output:</span></p>
			<pre class="console">
Program starting
FIRST POLL - START OPERATION
main: 1 pending tasks. Sleep until notified.
HTTP/1.1 200 OK
content-length: 15
connection: close
content-type: text/plain; charset=utf-8
date: Thu, xx xxx xxxx 15:38:08 GMT
HelloAsyncAwait
FIRST POLL - START OPERATION
main: 1 pending tasks. Sleep until notified.
HTTP/1.1 200 OK
content-length: 15
connection: close
content-type: text/plain; charset=utf-8
date: Thu, xx xxx xxxx 15:38:08 GMT
HelloAsyncAwait
main: All tasks are finished</pre>			<p>Great – it’s working just <span class="No-Break">as expected!!!</span></p>
			<p>However, we’re not really<a id="_idIndexMarker534"/> using any of the new capabilities of our runtime yet so before we leave this chapter, let’s have some fun and see what it <span class="No-Break">can do.</span></p>
			<h1 id="_idParaDest-153"><a id="_idTextAnchor152"/>Experimenting with our new runtime</h1>
			<p>If you remember from <a href="B20892_07.xhtml#_idTextAnchor122"><span class="No-Break"><em class="italic">Chapter 7</em></span></a>, we implemented a <strong class="source-inline">join_all</strong> method to get our futures running concurrently. In libraries such as Tokio, you’ll find a <strong class="source-inline">join_all</strong> function too, and the slightly more versatile <strong class="source-inline">FuturesUnordered</strong> API that allows you to join a set of predefined futures and run <span class="No-Break">them concurrently.</span></p>
			<p>These are convenient<a id="_idIndexMarker535"/> methods to have, but it does force you to know which futures you want to run concurrently in advance. If the futures you run using <strong class="source-inline">join_all</strong> want to spawn new futures that run concurrently with their “parent” future, there is no way to do that using only <span class="No-Break">these methods.</span></p>
			<p>However, our newly created spawn functionality does exactly this. Let’s put it to <span class="No-Break">the test!</span></p>
			<h2 id="_idParaDest-154"><a id="_idTextAnchor153"/>An example using concurrency</h2>
			<p class="callout-heading">Note</p>
			<p class="callout">The exact same version of this <a id="_idIndexMarker536"/>program can be found in the <span class="No-Break"><strong class="source-inline">ch08/c-runtime-executor</strong></span><span class="No-Break"> folder.</span></p>
			<p>Let’s try a new program that looks <span class="No-Break">like this:</span></p>
			<pre class="source-code">
fn main() {
    let mut executor = runtime::init();
    executor.block_on(async_main());
}
coro fn request(i: usize) {
    let path = format!("/{}/HelloWorld{i}", i * 1000);
    let txt = Http::get(&amp;path).wait;
    println!("{txt}");
}
coro fn async_main() {
    println!("Program starting");
    for i in 0..5 {
        let future = request(i);
        runtime::spawn(future);
    }
}</pre>			<p>This is pretty much the same example we used to show how <strong class="source-inline">join_all</strong> works in <a href="B20892_07.xhtml#_idTextAnchor122"><span class="No-Break"><em class="italic">Chapter 7</em></span></a>, only this time, we spawn them as top-level <span class="No-Break">futures instead.</span></p>
			<p>To run this example, follow <span class="No-Break">these steps:</span></p>
			<ol>
				<li>Replace everything <em class="italic">below the imports</em> in <strong class="source-inline">main.rs</strong> with the <span class="No-Break">preceding code.</span></li>
				<li>Run <span class="No-Break"><strong class="source-inline">corofy ./src/main.rs</strong></span><span class="No-Break">.</span></li>
				<li>Copy everything from <strong class="source-inline">main_corofied.rs</strong> to <strong class="source-inline">main.rs</strong> and <span class="No-Break">delete </span><span class="No-Break"><strong class="source-inline">main_corofied.rs</strong></span><span class="No-Break">.</span></li>
				<li>Fix the fact that <strong class="source-inline">corofy</strong> doesn’t know we changed our futures to take <strong class="source-inline">waker: &amp;Waker</strong> as an argument. The easiest way is to simply run <strong class="source-inline">cargo check</strong> and let the compiler guide you to the places we need <span class="No-Break">to change.</span></li>
			</ol>
			<p>Now, you can run the example and see<a id="_idIndexMarker537"/> that the tasks run concurrently, just as they did using <strong class="source-inline">join_all</strong> in <a href="B20892_07.xhtml#_idTextAnchor122"><span class="No-Break"><em class="italic">Chapter 7</em></span></a>. If you measured the time it takes to run the tasks, you’d find that it all takes around 4 seconds, which makes sense if you consider that you just spawned 5 futures, and ran them concurrently. The longest wait time for a single future was <span class="No-Break">4 seconds.</span></p>
			<p>Now, let’s finish off this chapter with another <span class="No-Break">interesting example.</span></p>
			<h2 id="_idParaDest-155"><a id="_idTextAnchor154"/>Running multiple futures concurrently and in parallel</h2>
			<p>This time, we spawn multiple threads and <a id="_idIndexMarker538"/>give each thread its own <strong class="source-inline">Executor</strong> so that we can run the previous example simultaneously in parallel using the same <strong class="source-inline">Reactor</strong> for all <span class="No-Break"><strong class="source-inline">Executor</strong></span><span class="No-Break"> instances.</span></p>
			<p>We’ll also make a small adjustment to the printout so that we don’t get overwhelmed <span class="No-Break">with data.</span></p>
			<p>Our new program will look <span class="No-Break">like this:</span></p>
			<pre class="source-code">
mod future;
mod http;
mod runtime;
use crate::http::Http;
use future::{Future, PollState};
use runtime::{Executor, Waker};
use std::thread::Builder;
fn main() {
    let mut executor = runtime::init();
    let mut handles = vec![];
    for i in 1..12 {
        let name = format!("exec-{i}");
        let h = Builder::new().name(name).spawn(move || {
            let mut executor = Executor::new();
            executor.block_on(async_main());
        }).unwrap();
        handles.push(h);
    }
    executor.block_on(async_main());
    handles.into_iter().for_each(|h| h.join().unwrap());
}
coroutine fn request(i: usize) {
    let path = format!("/{}/HelloWorld{i}", i * 1000);
    let txt = Http::get(&amp;path).wait;
    let txt = txt.lines().last().unwrap_or_default();
    println!(«{txt}»);
}
coroutine fn async_main() {
    println!("Program starting");
    for i in 0..5 {
        let future = request(i);
        runtime::spawn(future);
    }
}</pre>			<p>The machine I’m currently running has 12 cores, so when I create 11 new threads to run the same asynchronous tasks, I’ll use all the<a id="_idIndexMarker539"/> cores on my machine. As you’ll notice, we also give each thread a unique name that we’ll use when logging so that it’s easier to track what happens behind <span class="No-Break">the scenes.</span></p>
			<p class="callout-heading">Note</p>
			<p class="callout">While I use 12 cores, you should use the number of cores on your machine. If we increase this number too much, our OS will not be able to give us more cores to run our program in parallel on and instead start pausing/resuming the threads we create, which adds no value to us since we handle the concurrency aspect ourselves in an <span class="No-Break"><strong class="source-inline">a^tsync</strong></span><span class="No-Break"> runtime.</span></p>
			<p>You’ll have to do the same steps as we did in the <span class="No-Break">last example:</span></p>
			<ol>
				<li>Replace the code that’s currently in <strong class="source-inline">main.rs</strong> with the <span class="No-Break">preceding code.</span></li>
				<li>Run <span class="No-Break"><strong class="source-inline">corofy ./src/main.rs</strong></span><span class="No-Break">.</span></li>
				<li>Copy everything from <strong class="source-inline">main_corofied.rs</strong> to <strong class="source-inline">main.rs</strong> and <span class="No-Break">delete </span><span class="No-Break"><strong class="source-inline">main_corofied.rs</strong></span><span class="No-Break">.</span></li>
				<li>Fix the fact that <strong class="source-inline">corofy</strong> doesn’t know we changed our futures to take <strong class="source-inline">waker: &amp;Waker</strong> as an argument. The<a id="_idIndexMarker540"/> easiest way is to simply run <strong class="source-inline">cargo check</strong> and let the compiler guide you to the places we need <span class="No-Break">to change.</span></li>
			</ol>
			<p>Now, if you run the program, you’ll see that it still only takes around 4 seconds to run, but this time we made <strong class="bold">60 GET requests instead of 5</strong>. This time, we ran our futures both concurrently and <span class="No-Break">in parallel.</span></p>
			<p>At this point, you can continue experimenting with shorter delays or more requests and see how many concurrent tasks you can have before the system <span class="No-Break">breaks down.</span></p>
			<p>Pretty quickly, printouts to <strong class="source-inline">stdout</strong> will be a bottleneck, but you can disable those. Create a blocking version using OS threads and see how many threads you can run concurrently before the system breaks down compared to <span class="No-Break">this version.</span></p>
			<p>Only imagination sets the limit, but do take the time to have some fun with what you’ve created before we continue with the <span class="No-Break">next chapter.</span></p>
			<p>The only thing to be careful about is testing the concurrency limit of your system by sending these kinds of requests to a random server you don’t control yourself since you can potentially overwhelm it and cause problems <span class="No-Break">for others.</span></p>
			<h1 id="_idParaDest-156"><a id="_idTextAnchor155"/>Summary</h1>
			<p>So, what a ride! As I said in the introduction for this chapter, this is one of the biggest ones in this book, but even though you might not realize it, you’ve already got a better grasp of how asynchronous Rust works than most people do. <span class="No-Break"><strong class="bold">Great work!</strong></span></p>
			<p>In this chapter, you learned a lot about runtimes and why Rust designed the <strong class="source-inline">Future</strong> trait and the <strong class="source-inline">Waker</strong> the way it did. You also learned about reactors and executors, <strong class="source-inline">Waker</strong> types, <strong class="source-inline">Futures</strong> traits, and different ways of achieving concurrency through the <strong class="source-inline">join_all</strong> function and spawning new top-level futures on <span class="No-Break">the executor.</span></p>
			<p>By now, you also have an idea of how we can achieve both concurrency and parallelism by combining our own runtime with <span class="No-Break">OS threads.</span></p>
			<p>Now, we’ve created our own async universe consisting of <strong class="source-inline">coro/wait</strong>, our own <strong class="source-inline">Future</strong> trait, our own <strong class="source-inline">Waker</strong> definition, and our own runtime. I’ve made sure that we don’t stray away from the core ideas behind asynchronous programming in Rust so that everything is directly applicable to <strong class="source-inline">async/await</strong>, <strong class="source-inline">Future</strong> traits, <strong class="source-inline">Waker</strong> types, and runtimes in <span class="No-Break">day-to-day programming.</span></p>
			<p>By now, we’re in the final stretch of this book. The last chapter will finally convert our example to use the real <strong class="source-inline">Future</strong> trait, <strong class="source-inline">Waker</strong>, <strong class="source-inline">async/await</strong>, and so on instead of our own versions of it. In that chapter, we’ll also reserve some space to talk about the state of asynchronous Rust today, including some of the most popular runtimes, but before we get that far, there is one more topic I want to <span class="No-Break">cover: pinning.</span></p>
			<p>One of the topics that seems hardest to understand and most different from all other languages is the concept of pinning. When writing asynchronous Rust, you will at some point have to deal with the fact that <strong class="source-inline">Future</strong> traits in Rust must be pinned before <span class="No-Break">they’re polled.</span></p>
			<p>So, the next chapter will explain pinning in Rust in a practical way so that you understand why we need it, what it does, and how to <span class="No-Break">do it.</span></p>
			<p>However, you absolutely deserve a break after this chapter, so take some fresh air, sleep, clear your mind, and grab some coffee before we enter the last parts of <span class="No-Break">this book.</span></p>
		</div>
	</body></html>