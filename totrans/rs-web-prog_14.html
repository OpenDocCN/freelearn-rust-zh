<html><head></head><body>
		<div><h1 id="_idParaDest-278" class="chapter-number"><a id="_idTextAnchor279"/>14</h1>
			<h1 id="_idParaDest-279"><a id="_idTextAnchor280"/>Exploring the Tokio Framework</h1>
			<p>So far in this book, we have been building web apps using frameworks and packaging them in Docker to be deployed on a server. Building standard servers is useful and will enable us to solve a range of problems. However, there will come a point in your web development career where a standard REST API server will not be the best solution. It is useful to reach for another tool to implement more custom solutions.</p>
			<p>In this chapter, we will explore<a id="_idIndexMarker1255"/> the <strong class="bold">Tokio</strong> framework to enable async programming. We will then use the Tokio runtime to build safe custom async systems, by sending messages to async code blocks using channels. These messages can even be sent over different threads. We will then facilitate async solutions to complex problems by implementing the actor model.</p>
			<p>In this chapter, we will cover the following topics:</p>
			<ul>
				<li>Exploring the Tokio framework for async programming</li>
				<li>Working with workers</li>
				<li>Exploring the actor model for async programming</li>
				<li>Working with channels</li>
				<li>Working with actors in Tokio</li>
			</ul>
			<p>By the end of this chapter, you will be able to create async programs that solve complex problems using the actor model. Your async program will not need any external infrastructure such as a database, and the implementation of our async program will be safe and isolated because you will be able to pass data around your system and threads using channels. You will be able to understand and implement the building blocks of highly concurrent async programs and network applications.</p>
			<h1 id="_idParaDest-280"><a id="_idTextAnchor281"/>Technical requirements</h1>
			<p>In this chapter, no previous code is needed.</p>
			<p>The code for this chapter can be found at <a href="https://github.com/PacktPublishing/Rust-Web-Programming-2nd-Edition/tree/main/chapter14">https://github.com/PacktPublishing/Rust-Web-Programming-2nd-Edition/tree/main/chapter14</a>.</p>
			<h1 id="_idParaDest-281"><a id="_idTextAnchor282"/>Exploring the Tokio framework for async programming</h1>
			<p>Before we explore <a id="_idIndexMarker1256"/>what Tokio is and how it works, we should try to execute some async code in normal Rust. Throughout this chapter, we will be building a basic simulation using Tokio. Therefore, the Tokio code that we will be writing is in the <code>simulation</code> directory as its own Cargo project. Seeing as we are running <code>async</code> functions in our Rust server code to process views, we can see if we can execute a basic <code>async</code> function in our <code>main</code> function in the <code>main.rs</code> file with the following code:</p>
			<pre class="source-code">
async fn hello() {
    println!("Hello, world!");
}
fn main() {
    hello();
}</pre>
			<p>This looks simple enough; however, if we try to run our <code>main</code> function, we get the following output:</p>
			<pre class="console">
warning: unused implementer of `Future` that must be used
 --&gt; src/main.rs:9:5
  |
9 |     hello();
  |     ^^^^^^^^
  |
  = note: `#[warn(unused_must_use)]` on by default
  = note: futures do nothing unless you `.await` or poll them</pre>
			<p>Here, we are reminded that our <code>async</code> function is a <code>Hello, world!</code> message because we did not wait for the <code>hello</code> function<a id="_idIndexMarker1257"/> to execute. However, if we implement <code>await</code> on our <code>hello</code> function, we will get the following error:</p>
			<pre class="console">
8 | fn main() {
  |    ---- this is not `async`
9 |     hello().await;
  |            ^^^^^^ only allowed inside `async`
                      functions and blocks</pre>
			<p>The <code>main</code> function is not <code>async</code>. If we try to turn our <code>main</code> function into an <code>async</code> function, we get a very clear error message that the <code>main</code> function is not allowed to be <code>async</code>.</p>
			<p>We could implement our own structs that implement a <code>Future</code> trait and then create our own poll method. However, creating our own futures from scratch would be excessive for the context of this book, as this book is not dedicated to async Rust. Luckily, the Tokio framework comes to the rescue by turning our <code>main</code> runtime function into an <code>async</code> runtime function. To run our <code>hello</code> function, we first need to add Tokio to our <code>Cargo.toml</code> file with the following code:</p>
			<pre class="source-code">
[dependencies]
tokio = { version = "1", features = ["full"] }</pre>
			<p>We then import the following Tokio macro and <code>Error</code> struct in our <code>main.rs</code> file to enable an async runtime:</p>
			<pre class="source-code">
use tokio::main;
use std::error::Error;</pre>
			<p>We can then apply our Tokio macro to make our <code>main</code> function async and execute our <code>hello</code> function with the following code:</p>
			<pre class="source-code">
#[main]
async fn main() -&gt; Result&lt;(), Box&lt;dyn Error&gt;&gt; {
    let outcome = hello().await;
    Ok(outcome)
}</pre>
			<p>Here, we <a id="_idIndexMarker1258"/>can see that we are either returning a <code>Result</code> with an empty tuple, which is the same as <code>None</code> or <code>Void</code> in other languages, or an error. If we return an error, we return a struct that implements the <code>Error</code> trait that is on heap memory due to the <code>Box</code> notation. When we run our program now, we will get the <code>hello world</code> message. From this, we can deduce that our program is blocked until the <code>hello</code> function has executed. However, the preceding code requires us to return something, and there is a bit of boilerplate code in the definition. If we drop all imports, we can have the following simpler <code>main</code> function:</p>
			<pre class="source-code">
#[tokio::main]
async fn main() {
    hello().await;
    println!("program has run");
}</pre>
			<p>Here, we can see that we are not having to bother with <code>return</code> definitions, and we can do whatever we want in the last statement of the <code>main</code> function. We still block the thread on <code>await</code>, as we can see with the following printout:</p>
			<pre class="console">
Hello, world!
program has run</pre>
			<p>Now that we have got basic <code>async</code> functions running in Tokio, we can do an experiment. We can run multiple <code>async</code> functions and wait for them with the following code:</p>
			<pre class="source-code">
async fn hello(input_int: i32) -&gt; i32 {
    println!("Hello, world! {}", input_int);
    return input_int
}
#[tokio::main]
async fn main() {
    let one = hello(1);
    let two = hello(2);
    let three = hello(3);
    let one = one.await;
    let three = three.await;
    let two = two.await;
    println!("{} {} {}", one, two, three);
}</pre>
			<p>Running this code will give the following output:</p>
			<pre class="console">
Hello, world! 1
Hello, world! 3
Hello, world! 2
1 2 3</pre>
			<p>Here, we <a id="_idIndexMarker1259"/>can see that the operations are executed in the order <code>main</code> is executed. This means that when we use <code>await</code> to wait on a future to complete, the runtime is blocked until the future has completed. Even though the <code>two</code> future was defined before the <code>three</code> future, the <code>three</code> future executes before the <code>two</code> future because the <code>three</code> future was awaited before the <code>two</code> future.</p>
			<p>So what? What’s the big deal? If our <code>async</code> functions are blocking the runtime, then why don’t we just define normal functions? We can do one last experiment to get to know Tokio: the standard sleep test. First, we need to import the following:</p>
			<pre class="source-code">
use std::time::Instant;
use std::{thread, time};</pre>
			<p>We then redefine our <code>hello</code> function to sleep for 5 seconds before printing out to the terminal with the following code:</p>
			<pre class="source-code">
async fn hello(input_int: i32) -&gt; i32 {
    let five_seconds = time::Duration::from_secs(5);
    tokio::time::sleep(five_seconds).await;
    println!("Hello, world! {}", input_int);
    input_int
}</pre>
			<p>We then <a id="_idIndexMarker1260"/>spawn Tokio tasks when waiting for our futures to execute in our hello function. We spawn a Tokio task using <code>tokio::spawn</code>. A Tokio task is a light weight, non-blocking unit of execution. While Tokio tasks are like OS threads, they are not managed by the OS scheduler but by the Tokio runtime instead. The Tokio task spawned is run on a thread pool. The spawned task could correspond to a thread, but it could also not. It is up to the Tokio runtime. We spawn our tasks with the following code:</p>
			<pre class="source-code">
#[tokio::main]
async fn main() {
    let now = Instant::now();
    let one = tokio::spawn({
        hello(1)
    });
    let two = tokio::spawn({
        hello(2)
    });
    let three = tokio::spawn({
        hello(3)
    });
    one.await;
    two.await;
    three.await;
    let elapsed = now.elapsed();
    println!("Elapsed: {:.2?}", elapsed);
}</pre>
			<p>If our futures<a id="_idIndexMarker1261"/> block the entire runtime, then the time elapsed will be 15 seconds. However, running our program will give us the following output:</p>
			<pre class="console">
Hello, world! 2
Hello, world! 3
Hello, world! 1
Elapsed: 5.00s</pre>
			<p>Here, we can see that there is some asynchronous order in which the futures can be executed. However, the total time is 5 seconds because they are running concurrently. Again, at face value, this does not seem too impressive. However, this is where it gets exciting. The super smart people building Tokio keep track of threading using polling. This is where the Tokio runtime keeps checking to see if a future has executed by polling a bit of memory. Because of polling, checking up on threads does not take a lot of resources. Because checking up on threads does not take a lot of resources, Tokio can literally keep millions of tasks open. If there is an <code>await</code> instance in the thread and it is blocking the runtime of that thread, Tokio will merely switch over to another thread and start executing the new thread. A future running in the background would occasionally poll the task executor end query if there is a result or not. As a result, Tokio is powerful, and therefore we used Tokio as a runtime for our Actix Web server when exploring Actix in <a href="B18722_03.xhtml#_idTextAnchor059"><em class="italic">Chapter 3</em></a>, <em class="italic">Handling HTTP Requests</em>. Getting to know Tokio will enable us to build our own networking applications at a lower level.</p>
			<p>While spinning off multiple threads using Tokio is exciting, we must explore the trade-offs of working with multiple workers.</p>
			<h1 id="_idParaDest-282"><a id="_idTextAnchor283"/>Working with workers</h1>
			<p>When <a id="_idIndexMarker1262"/>it comes to defining workers, we can augment<a id="_idIndexMarker1263"/> the Tokio runtime macro with the following code:</p>
			<pre class="source-code">
#[tokio::main(flavor = "multi_thread", worker_threads = 4)]
async fn main() {
    ...
}</pre>
			<p>Here, we can see that we state that the runtime is multithreaded, and we have four worker threads. Workers are essentially processes that run in constant loops. Each worker consumes tasks through a channel, putting them in a queue. The worker then works through the tasks, executing them in the order received. If a worker has finished all the tasks, it will search other queues belonging to other workers, stealing tasks if they are available, as seen here:</p>
			<div><div><img src="img/Figure_14.1_B18722.jpg" alt="Figure 14.1 – Worker event loops (Work stealing runtime. By Carl Lerche – License MIT: https://tokio.rs/blog/2019-10-scheduler#the-next-generation-tokio-scheduler)"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.1 – Worker event loops (Work stealing runtime. By Carl Lerche – License MIT: https://tokio.rs/blog/2019-10-scheduler#the-next-generation-tokio-scheduler)</p>
			<p>Now that we<a id="_idIndexMarker1264"/> know we can alter the number of workers, we can test how the number of worker threads affects how our runtime. First, we <a id="_idIndexMarker1265"/>must change our <code>hello</code> function to sleep for only 1 second at a time. We then loop through a range of numbers where we spawn a task for each iteration of that range, pushing the handle of the spawned task to a vector. We then await all the futures in the vector with the following code:</p>
			<pre class="source-code">
#[tokio::main(flavor = "multi_thread", worker_threads = 4)]
async fn main() {
    let now = Instant::now();
    let mut buffer = Vec::new();
    for i in 0..20 {
        let handle = tokio::spawn(async move {
            hello(i).await
        });
        buffer.push(handle);
    }
    for i in buffer {
        i.await;
    }
    let elapsed = now.elapsed();
    println!("Elapsed: {:.2?}", elapsed);
}</pre>
			<p>We could keep<a id="_idIndexMarker1266"/> running the program with a different <a id="_idIndexMarker1267"/>number of worker threads to see how the number of threads affects the time taken. To save you time, this has been done, providing the graph shown in <em class="italic">Figure 14</em><em class="italic">.2</em>:</p>
			<div><div><img src="img/Figure_14.2_B18722.jpg" alt="Figure 14.2 – Time versus the number of workers"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.2 – Time versus the number of workers</p>
			<p>We can <a id="_idIndexMarker1268"/>see that the first four workers have a big effect on the overall time of the program. However, the returns sharply diminish as we increase the number of workers to more than four. This might be different for you. I got this graph because my computer that is running our program has four cores. It is advised that we have one worker thread per core.</p>
			<p>We have now<a id="_idIndexMarker1269"/> managed to speed up our program using Tokio worker threads. We have also gotten a deeper appreciation for the trade-off of worker threads and how they process tasks. However, what advantage is there to understanding this? We could just use a higher-level framework like Actix Web or Rocket to concurrently handle API endpoints. Yes, higher-level frameworks are useful and do solve a problem, but these are just one solution to the problems. In the next section, we will cover the actor model as this is an asynchronous solution that can run in a program or a web server depending on your needs.</p>
			<h1 id="_idParaDest-283"><a id="_idTextAnchor284"/>Exploring the actor model for async programming</h1>
			<p>If you have <a id="_idIndexMarker1270"/>coded complex<a id="_idIndexMarker1271"/> solutions to complex problems before in an object-oriented fashion, you will be familiar with objects, attributes, and class inheritance. If you are not familiar, do not worry—we are not going to implement them in this chapter. However, it is advised that you read up on the concepts of object-oriented programming to gain a full appreciation for the actor model.</p>
			<p>For objects, we<a id="_idIndexMarker1272"/> have a range of processes and an encapsulated state around those processes, which can be attributes of the object. Objects are useful for compartmentalizing logic and state around a concept or process. Some people merely see objects as a tool to reduce repeated code; however, objects can be used as interfaces between modules or can be used to orchestrate<a id="_idIndexMarker1273"/> processes. Objects are the cornerstone of many complex systems. However, when it comes to asynchronous programming, objects can get messy—for instance, when we have two objects referencing data from another object or in general when we have shared common resources between objects, modifying them simultaneously, as seen in the following diagram:</p>
			<div><div><img src="img/Figure_14.3_B18722.jpg" alt="Figure 14.3 – Objects and async"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.3 – Objects and async</p>
			<p>In this diagram, we can imagine a system where <em class="italic">Object C</em> is keeping track of investments. We have a rule coded into <em class="italic">Object C</em> that we do not spend over £50. However, <em class="italic">Object A</em> and <em class="italic">Object B</em> are both performing processes that invest in different stocks. For a range of reasons, from network latency to maybe different price calculation strategies, the processes for deciding to invest in a stock can vary. Even though both <em class="italic">Object A</em> and <em class="italic">Object B</em> get approved by getting the total amount already invested from <em class="italic">Object C</em>, <em class="italic">Object B</em> places the order first due to <em class="italic">Object B</em>’s process finishing first. So, when <em class="italic">Object A</em> finishes its process and places an order, it could tip our total investment over £50. This is a data race problem. We can potentially spend over our investment budget because two competing investment executions are operating too <a id="_idIndexMarker1274"/>close to each other. When we consider that we could be keeping track of potentially hundreds of positions, it will become certain that data races will end up breaking the rules of our strategy.</p>
			<p>To solve the <a id="_idIndexMarker1275"/>data race problem, we could implement a database, or try to keep an eye on all the threads running to implement locks in the form of Mutexes, RwLocks, and so on. However, the database solution requires more memory, infrastructure, and code to handle the data. The data is also persisted when the program has been shut down, which adds to the complexity of the management. The locking system and keeping track of common shared resources also introduce potential bugs and excessive complexity for the simple problem that we have defined. This is where actors come in. Actors are essentially units of computation with their own state. However, it must be noted that actors are not free; they require heavier RAM usage. Also, actors can die, which will also kill their state, so database backups can be helpful to persist the state if and when actors die. Actors only communicate through channels using messages. These messages are queued and then processed in the order the messages were sent. This gives us the following system dynamic:</p>
			<p class="IMG---Figure"> </p>
			<div><div><img src="img/Figure_14.4_B18722.jpg" alt="Figure 14.4 – Actors and async"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.4 – Actors and async</p>
			<p>Here, we <a id="_idIndexMarker1276"/>can see that <em class="italic">Actor C</em> accepts messages and places an order if we have not exceeded our investment budget. We can<a id="_idIndexMarker1277"/> have hundreds of actors sending buy-and-sell messages to <em class="italic">Actor C</em> and still be confident that the budget would not be exceeded. Our system does not get increasingly complicated as we add more actors. There is nothing stopping us from getting our <em class="italic">Actor C</em> to send messages to other actors to stop or increase the number of buy-or-sell positions, depending on the current state of our investment budget.</p>
			<p>To build more complex systems, you must be familiar with the following terms:</p>
			<ul>
				<li><strong class="bold">Actor</strong>: A unit <a id="_idIndexMarker1278"/>of work that can contain state and modifies that state by processing messages it receives. You never have reference to an actor state or actor directly.</li>
				<li><strong class="bold">Actor reference</strong>: A <a id="_idIndexMarker1279"/>handle to an actor. This allows you to send the actor messages without knowing its implementation type or location on the network. All I need to know is that if we send a message to an actor, we get <em class="italic">X</em> back. We do not need to know if the actor is local somewhere else.</li>
				<li><strong class="bold">Actor system</strong>: A <a id="_idIndexMarker1280"/>collection of actors that exist inside a single process and communicate via in-memory message passing.</li>
				<li><strong class="bold">Cluster</strong>: A<a id="_idIndexMarker1281"/> collection of networked actor systems whose actors communicate via TCP message passing.</li>
			</ul>
			<p>What <a id="_idIndexMarker1282"/>makes this exciting is that we can achieve asynchronism without having to rely on a database or on keeping track of threads. We can run it all in our Tokio runtime in one static binary! This is very powerful. However, there<a id="_idIndexMarker1283"/> is nothing stopping us from using the actor model on a microservices-cluster scale in the form of nanoservices. At the time of writing this book, nano services are lightly written about and used by some companies such as Netflix. However, with what we have explored with Rust and distroless containers, we can deploy Rust servers into a cluster at 50 MB a server. With what we have covered so far in this book, there is nothing stopping you from pushing the boundaries and building nano services, and implementing the actor model using nano services.</p>
			<p>The actor model is being used in a lot of IoT devices and real-time event systems. Some applications that make use of the actor model are listed as follows:</p>
			<ul>
				<li>Event-driven applications (chat, workflow, CRM)</li>
				<li>Finance (pricing, fraud detection, algorithmic trading)</li>
				<li>Gaming (multi-player)</li>
				<li>Analytics and monitoring</li>
				<li>Marketing automation</li>
				<li>Systems integration</li>
				<li>IoT (healthcare, transportation, security)</li>
			</ul>
			<p>OK—we may <a id="_idIndexMarker1284"/>never truly understand <a id="_idIndexMarker1285"/>Hollywood actors, but at least we are familiar with computational actors. With the high-level concepts out of the way, we can move on to constructing the building blocks of an actor system: actors. Before we work with actors, we need to get actors to communicate with each other. This is achieved using channels in Tokio.</p>
			<h1 id="_idParaDest-284"><a id="_idTextAnchor285"/>Working with channels</h1>
			<p>We <a id="_idIndexMarker1286"/>can experiment with channels by rewriting<a id="_idIndexMarker1287"/> our <code>main.rs</code> file. First, we need to import channels and implement the <code>main</code> trait for the <code>main</code> function with the following code:</p>
			<pre class="source-code">
use tokio::sync::mpsc;
#[tokio::main]
async fn main() {
    ...
}</pre>
			<p>Here, we can see that we import the <code>mpsc</code> module. <code>mpsc</code>. We can now create our channel and spawn a thread that sends multiple messages to a receiver down the channel we created in our <code>main</code> function with the following code:</p>
			<pre class="source-code">
let (tx, mut rx) = mpsc::channel(1);
tokio::spawn(async move {
    for i in 0..10 {
        if let Err(e) = tx.send(i).await {
            println!("send error: {:?}", e);
            break;
        }
        println!("sent: {}", i);
    }
});</pre>
			<p>Here, we <a id="_idIndexMarker1289"/>can see that the creation of a channel <a id="_idIndexMarker1290"/>returns a tuple, which we unpack to transmit (<code>tx</code>) and receive (<code>rx</code>). We then loop through a range of integers from 0 to 10, sending them down the channel we created. If there is an error, we print it out and return an empty tuple, breaking the loop. In the following loop, we print out what we sent down the channel. We can then receive the messages with the code shown next:</p>
			<pre class="source-code">
while let Some(i) = rx.recv().await {
    println!("got: {}", i);
}</pre>
			<p>It must be noted that split halves of channels implement the <code>Iterator</code> trait, enabling us to read messages from these channels in a <code>while</code> loop. If we run our code now, we get the following output:</p>
			<pre class="console">
sent: 0
got: 0
sent: 1
got: 1
sent: 2
got: 2
...</pre>
			<p>The printout continues to <code>9</code>, but we get the idea of what is going on. We are not sending all our messages and then processing them. Both code blocks are executing side by side, sending and receiving messages. If we make one of the code blocks sleep between iterations, we will still get the same printout.</p>
			<p>While getting<a id="_idIndexMarker1291"/> the basis of async message sending and receiving is a nice step in the right direction, it is not useful. Right now, we are just sending a number. If we want to be able to implement actors that communicate with each other, we need to be able to send more <a id="_idIndexMarker1292"/>comprehensive messages over the channel. To work out how to do this, we can inspect the <code>channel</code> source code, which reveals the following:</p>
			<pre class="source-code">
pub fn channel&lt;T&gt;(buffer: usize) -&gt; (Sender&lt;T&gt;, Receiver&lt;T&gt;) {
    assert!(buffer &gt; 0, "mpsc bounded channel requires
            buffer &gt; 0");
    let semaphore = (semaphore::Semaphore::new(buffer),
                     buffer);
    let (tx, rx) = chan::channel(semaphore);
    let tx = Sender::new(tx);
    let rx = Receiver::new(rx);
    (tx, rx)
}</pre>
			<p>We can see that the <code>channel</code> function is implementing generics. The sender and receiver can send anything if it is consistent, as denoted in the <code>(Sender&lt;T&gt;, Receiver&lt;T&gt;)</code> return type. Now that we know the <code>channel</code> function can load any type, we can create a message struct outside of the <code>channel</code> function with the following code:</p>
			<pre class="source-code">
#[derive(Debug, Clone)]
pub enum Order {
    BUY,
    SELL
}
#[derive(Debug, Clone)]
pub struct Message {
    pub order: Order,
    pub ticker: String,
    pub amount: f32
}</pre>
			<p>Here, we have<a id="_idIndexMarker1293"/> a struct that has an order, which can <a id="_idIndexMarker1294"/>either be <code>BUY</code> or <code>SELL</code>. Our <code>Message</code> struct also has a ticker to denote the name of the stock being processed and the amount of stock being processed. Inside our <code>main</code> function, we then pass our <code>Message</code> struct into the <code>channel</code> function and define the stocks that we are going to buy with the following code:</p>
			<pre class="source-code">
let (tx, mut rx) = mpsc::channel::&lt;Message&gt;(1);
let orders = [
    Message { order: Order::BUY,
              amount: 5.5, ticker: "BYND".to_owned()},
    Message { order: Order::BUY,
              amount: 5.5, ticker: "NET".to_owned()},
    Message { order: Order::BUY,
              amount: 5.5, ticker: "PLTR".to_owned()},
];</pre>
			<p>Now that our orders are defined, we loop through the orders, sending and receiving them with the following code:</p>
			<pre class="source-code">
tokio::spawn(async move {
    for order in orders {
        if let Err(e) = tx.send(order.clone()).await {
            println!("send error: {:?}", e);
            return;
        }
        println!("sent: {:?}", order);
    }
});
while let Some(i) = rx.recv().await {
    println!("got: {:?}", i);
}</pre>
			<p>Running our<a id="_idIndexMarker1295"/> program now gives us the following <a id="_idIndexMarker1296"/>output:</p>
			<pre class="console">
sent: Message { order: "BUY", ticker: "BYND", amount: 5.5 }
sent: Message { order: "BUY", ticker: "NET", amount: 5.5 }
got: Message { order: "BUY", ticker: "BYND", amount: 5.5 }
got: Message { order: "BUY", ticker: "NET", amount: 5.5 }
sent: Message { order: "BUY", ticker: "PLTR", amount: 5.5 }
got: Message { order: "BUY", ticker: "PLTR", amount: 5.5 }</pre>
			<p>We can see here that we are sending and receiving messages across the channel. However, it must be noted before we move on that if we increase the size of the buffer passed into the <code>channel</code> function from 1 to 300, we get the following printout:</p>
			<pre class="console">
sent: Message { order: "BUY", ticker: "BYND", amount: 5.5 }
sent: Message { order: "BUY", ticker: "NET", amount: 5.5 }
sent: Message { order: "BUY", ticker: "PLTR", amount: 5.5 }
got: Message { order: "BUY", ticker: "BYND", amount: 5.5 }
got: Message { order: "BUY", ticker: "NET", amount: 5.5 }
got: Message { order: "BUY", ticker: "PLTR", amount: 5.5 }</pre>
			<p>This is because the <a id="_idIndexMarker1297"/>buffer is so large that multiple <a id="_idIndexMarker1298"/>messages can be sent without having to wait for the channel to be read (drained) until there is a new buffer that is more available.</p>
			<h1 id="_idParaDest-285"><a id="_idTextAnchor286"/>Working with actors in Tokio</h1>
			<p>This will <a id="_idIndexMarker1299"/>be the last time we rewrite our <code>main.rs</code> file. However, once<a id="_idIndexMarker1300"/> we have finished this section, we will have built a basic actor model system. In our system, we will create an actor that keeps track of the orders so that we do not exceed our budget threshold. We then need to build an actor that sends the order, resulting in the following process:</p>
			<p class="IMG---Figure"> </p>
			<div><div><img src="img/Figure_14.5_B18722.jpg" alt="Figure 14.5 – Our stock order interaction for actors"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.5 – Our stock order interaction for actors</p>
			<p>We can see that this time round, we need to send the address of the actor that is making the order with the order message. This is a design choice because, in our system, <em class="italic">order</em> actors spin up and die quickly after the order has been made. We cannot keep track of the addresses for all the <em class="italic">order</em> actors in our program in our <em class="italic">order book</em> actor. Instead, the <em class="italic">order book</em> actor can get the address from the message to send the response to the <em class="italic">order</em> actor. First, we must import the following:</p>
			<pre class="source-code">
use tokio::sync::{mpsc, oneshot, mpsc::Sender};</pre>
			<p>Here, we import the <code>mpsc</code> channel to send the message to the <em class="italic">order book</em>. We then import the <code>oneshot</code> channel to facilitate the outcome being sent back to the <em class="italic">order</em>. A <code>oneshot</code> channel is a channel that stays open until a message is sent. This is because a <code>oneshot</code> channel<a id="_idIndexMarker1301"/> has a capacity/buffer size of one, so it is bounded to only one message being sent before the channel is closed.</p>
			<p>Now that we <a id="_idIndexMarker1302"/>have imported all that we need, we can move on to defining the message with the following code:</p>
			<pre class="source-code">
#[derive(Debug)]
pub struct Message {
    pub order: Order,
    pub ticker: String,
    pub amount: f32,
    pub respond_to: oneshot::Sender&lt;u32&gt;
}</pre>
			<p>Here, we can see that we have attached the <code>Sender</code> struct, which enables the receiver to send values to the sender through a channel. With this message, we can build out our <em class="italic">order book</em> actor with the following code:</p>
			<pre class="source-code">
pub struct OrderBookActor {
    pub receiver: mpsc::Receiver&lt;Message&gt;,
    pub total_invested: f32,
    pub investment_cap: f32
}</pre>
			<p>The state of the <em class="italic">order book</em> actor will live on throughout the lifetime of the program. The <code>receiver</code> field will be used to accept incoming messages from all <em class="italic">order</em> actors, and a decision on how to process the order will be made on the total invested and the investment cap that we define when we are creating the actor. We now must implement functions that create the <em class="italic">order book</em> actor, handle incoming messages, and run the actor <a id="_idIndexMarker1303"/>with the following outline:</p>
			<pre class="source-code">
impl OrderBookActor {
    fn new(receiver: mpsc::Receiver&lt;Message&gt;,
           investment_cap: f32) -&gt; Self {
        . . .
    }
    fn handle_message(&amp;mut self, message: Message) {
        . . .
    }
    async fn run(mut self) {
        . . .
    }
}</pre>
			<p>We can start <a id="_idIndexMarker1304"/>with the constructor (the <code>new</code> function), which takes the following form:</p>
			<pre class="source-code">
fn new(receiver: mpsc::Receiver&lt;Message&gt;, investment_cap:
       f32) -&gt; Self {
    return OrderBookActor {
        receiver,
        total_invested: 0.0,
        investment_cap
    }
}</pre>
			<p>The implementation of the constructor is not surprising. We merely pass in a receiver and the investment cap, and automatically set the total invested to <code>0</code>. Now that the <em class="italic">order</em> actor can be<a id="_idIndexMarker1305"/> constructed, we can handle the messages the <em class="italic">order</em> actor received with the following code:</p>
			<pre class="source-code">
fn handle_message(&amp;mut self, message: Message) {
    if message.amount + self.total_invested &gt;=
        self.investment_cap {
        println!("rejecting purchase, total invested: {}",
                  self.total_invested);
        let _ = message.respond_to.send(0);
    } else {
        self.total_invested += message.amount;
        println!("processing purchase, total invested: {}",
                  self.total_invested);
        let _ = message.respond_to.send(1);
    }
}</pre>
			<p>Here, we<a id="_idIndexMarker1306"/> have kept the implementation basic. If the new order brings our invested capital over our threshold, we print out that we have rejected the order and return a <code>0</code>. If our new order does not breach the threshold, we then print out that we are processing the order and send a <code>1</code>. For our example, the <em class="italic">order</em> actor is not going to act on the response from the <em class="italic">order book</em> actor; however, if you were to build in a system where another order is placed (such as a sell order), it is advised that you create another <em class="italic">order</em> actor based on the outcome.</p>
			<p>The only function left for our <em class="italic">order book</em> actor is the <code>run</code> function, which is defined with the following code:</p>
			<pre class="source-code">
async fn run(mut self) {
    println!("actor is running");
    while let Some(msg) = self.receiver.recv().await {
        self.handle_message(msg);
    }
}</pre>
			<p>Here, we merely wait for messages until all the senders in our channel have been killed. If a message is sent to our actor, we process it with our <code>handle_message</code> function.</p>
			<p>Our <em class="italic">order book</em> actor<a id="_idIndexMarker1307"/> can now be constructed, run, and receive messages returning a response through a channel with three separate functions. We need to build an <em class="italic">order</em> actor struct so that we can send messages to our <em class="italic">order book</em> actor. First, we define our order fields with the following code:</p>
			<pre class="source-code">
struct BuyOrder {
    pub ticker: String,
    pub amount: f32,
    pub order: Order,
    pub sender: Sender&lt;Message&gt;
}</pre>
			<p>Here, we need <a id="_idIndexMarker1308"/>to define the ticker symbol that we are buying, the amount that we are buying, and the type of order. We then have the <code>Sender</code> struct so that we can send messages to the <em class="italic">order book</em>. For the <em class="italic">order</em> actor, we only need two functions: the <code>constructor</code> function and the <code>send</code> function. This is because our <em class="italic">order</em> actor is the one sending the initial message, so the <em class="italic">order</em> actor does not need a separate function to wait for messages. Our two functions for our <em class="italic">order</em> actor have the following outline:</p>
			<pre class="source-code">
impl BuyOrder {
    fn new(amount: f32, ticker: String,
           sender: Sender&lt;Message&gt;) -&gt; Self {
        . . .
    }
    async fn send(self) {
        . . .
    }
}</pre>
			<p>At this point in time, you should be able to code the constructor for the <em class="italic">order</em> actor yourself. If you stop to have an attempt at this, your code should look like this:</p>
			<pre class="source-code">
fn new(amount: f32, ticker: String,
       sender: Sender&lt;Message&gt;) -&gt; Self {
    return BuyOrder { ticker, amount,
                      order: Order::BUY, sender }
}</pre>
			<p>Here, we <a id="_idIndexMarker1309"/>merely pass the parameters into the creation of<a id="_idIndexMarker1310"/> the struct, with the <code>order</code> field being automatically set to <code>BUY</code>.</p>
			<p>With the constructor built, the only function left to define is the <code>send</code> function, which takes the following form:</p>
			<pre class="source-code">
async fn send(self) {
    let (send, recv) = oneshot::channel();
    let message = Message { order: self.order,
                            amount: self.amount,
                            ticker: self.ticker,
                            respond_to: send};
    let _ = self.sender.send(message).await;
    match recv.await {
        Err(e) =&gt; println!("{}", e),
        Ok(outcome) =&gt; println!("here is the outcome: {}",
                                 outcome)
    }
}</pre>
			<p>Here, we set up a one-shot channel that will close once the response from the <em class="italic">order book</em> actor has been received. We then package our message with the fields of our <em class="italic">order</em> actor struct and include the address of the <em class="italic">order</em> actor in the <code>respond_to</code> field of the message. The <em class="italic">order</em> actor then sends the message and awaits a response, which we merely print out as it is an example.</p>
			<p>Our system<a id="_idIndexMarker1311"/> components are now built. We can now <a id="_idIndexMarker1312"/>orchestrate our actors to work with each other in our <code>main</code> function with the following code:</p>
			<pre class="source-code">
#[tokio::main]
async fn main() {
    let (tx, rx) = mpsc::channel::&lt;Message&gt;(1);
    let tx_one = tx.clone();
    tokio::spawn(async move {
        . . .
    });
    tokio::spawn(async move {
        . . .
    });
    let actor = OrderBookActor::new(rx, 20.0);
    actor.run().await;
}</pre>
			<p>Here, we define the channel and clone the sender to the channel once so that we have two senders for the same channel. This is because we have two Tokio threads sending order messages. We then create our <em class="italic">order book</em> actor and run it. If we cloned another sender but did not use it, our program would hang forever until we shut it down because the <em class="italic">order book</em> actor would be waiting for all senders for the channel to be killed before stopping.</p>
			<p>Inside our <a id="_idIndexMarker1313"/>threads, we will simply be sending a lot of stocks using loops with the following <a id="_idIndexMarker1314"/>code:</p>
			<pre class="source-code">
tokio::spawn(async move {
    for _ in 0..5 {
        let buy_actor = BuyOrder::new(5.5,
                                      "BYND".to_owned(),
                                      tx_one.clone());
        buy_actor.send().await;
    }
    drop(tx_one);
});
tokio::spawn(async move {
    for _ in 0..5 {
        let buy_actor = BuyOrder::new(5.5,
                                      "PLTR".to_owned(),
                                      tx.clone());
        buy_actor.send().await;
    }
    drop(tx);
});</pre>
			<p>It must be noted that we drop the <code>tx_one</code> and <code>tx</code> transmitters after we have sent all of our messages to signal early the task has completed, instead of having to wait for the end of the runtime to close the channel. We have two threads running because we want to properly check if our <em class="italic">order book</em> is safe to handle concurrent messages. If we run our program, we get the following printout:</p>
			<pre class="console">
processing purchase, total invested: 5.5
here is the outcome: 1
processing purchase, total invested: 11
processing purchase, total invested: 16.5
here is the outcome: 1
here is the outcome: 1
rejecting purchase, total invested: 16.5
here is the outcome: 0
rejecting purchase, total invested: 16.5
here is the outcome: 0
. . .</pre>
			<p>Here, we<a id="_idIndexMarker1315"/> can see messages are being sent and processed <a id="_idIndexMarker1316"/>to our <em class="italic">order book</em> actor in an async manner. However, no matter how many times you run the program, you will never exceed your threshold of investment.</p>
			<p>And here we have it. Tokio enables us to run async code in the <code>main</code> function, and the actor model enables us to build safe async code that is easy to understand without having to rely on locks, handling of threads, passing state over threads, or external infrastructure such as a database. This does not mean that we should run around applying the actor model to everything. However, if you want to write safe async code that has a simple, testable implementation without external infrastructure and fast access to local memory, then the actor model combined with Tokio is very powerful.</p>
			<h1 id="_idParaDest-286"><a id="_idTextAnchor287"/>Summary</h1>
			<p>In this chapter, we managed to revisit async programming. Initially, we explored the Tokio framework by looking into what the Tokio framework enabled us to do and then implementing basic async code, which was then implemented by the Tokio framework. We then increased the number of worker threads to demonstrate the point that we get diminishing returns when we simply increase the number of worker threads. We then worked with channels to facilitate sending messages through these channels. This enabled us to send data between different areas of the code even if the code is running in a different thread.</p>
			<p>However, while async programming with the Tokio framework is interesting and fun, the basic combination of Tokio and async programming with channels does not directly lead to practical applications by itself. To gain some practical skills with Tokio and async programming, we explored the actor framework. This is where we define structs with their own state, and then communicate between the structs that we now call actors using channels. We then used actors to build a basic system that places orders where the amount of money invested does not exceed a defined threshold, even though we are placing these orders in an async manner. Implementing the actor model in Tokio has enabled us to build safe async systems without having any external infrastructure such as a database. In the next chapter, we take the ability to build custom async systems to the next level by building TCP listeners for our Tokio async application, meaning that we can listen for commands sent to our application from other applications and clients across a network.</p>
			<h1 id="_idParaDest-287"><a id="_idTextAnchor288"/>Further reading</h1>
			<ul>
				<li>Tokio documentation: <a href="https://tokio.rs/tokio/tutorial&#13;">https://tokio.rs/tokio/tutorial</a></li>
			</ul>
			<h1 id="_idParaDest-288"><a id="_idTextAnchor289"/>Questions</h1>
			<ol>
				<li>How does an actor model prevent data race issues?</li>
				<li>How can we engineer a two-way communication where an actor can send a message to another actor and get a response back?</li>
				<li>What happens to our program if we have two actors sending one message each to a third actor but we have cloned three instances of the sender for the MPSC channel facilitating the communication between the actors?</li>
				<li>What are the advantages of using channels and messages to communicate data between code blocks?</li>
			</ol>
			<h1 id="_idParaDest-289"><a id="_idTextAnchor290"/>Answers</h1>
			<ol>
				<li value="1">The actor model is where actors send messages to each other. Each actor has a queue for processing the incoming messages for the actor. Because of this, the incoming messages are processed in the order they are received.</li>
				<li>The actor receiving the initial message has the receiver of the MPSC channel. The actor sending the initial message has the sender for the MPSC channel and creates a one-shot channel. The actor sending the initial message then sends the sender from the one-shot channel in the initial message. The actor sending the initial message then waits for the actor receiving the initial message to process the data and then uses the sender in the initial sender to send back a response.</li>
				<li>Our program will run as we expect; however, only two of the senders for the MSPC channel will be killed as we only have two actors that are sending messages. This means that one sender will be left over. As one sender is not used up, the channel is not closed, so the receiving actor will continue to keep the program running indefinitely.</li>
				<li>Channels and messages give us a lot of flexibility. We can send messages across threads. We also do not have to pass data across multiple different areas of code. If a block has a connection to a channel, the code block can receive/send data. We also must note that we can implement different patterns. For instance, we can have a message emitted into a channel and received by multiple subscribers. We can also enforce the direction of traffic or rules such as one-shot. This means we have a lot of control over the flow of the data.</li>
			</ol>
		</div>
	</body></html>