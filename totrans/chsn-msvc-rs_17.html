<html><head></head><body>
        

                            
                    <h1 class="header-title">Bounded Microservices with AWS Lambda</h1>
                
            
            
                
<p>In the Last chapter we learned how to create serverless applications using AWS Lambda and the official <kbd>lambda-runtime</kbd> crate. It is useful for developers who use <strong>Amazon Web Services</strong> (<strong>AWS</strong>) and who especially want to use AWS Lambda. It differs from the approach where we created a standalone web server, because AWS Lambda stores, scales, and runs automatically, and the only thing we should provide is the compiled code of a microservice.</p>
<p>The following topics will be covered in this chapter:</p>
<ul>
<li>Dealing with the AWS Lambda Rust runtime</li>
<li>Deploying a microservice to AWS using the Serverless Framework</li>
</ul>


            

            
        
    

        

                            
                    <h1 class="header-title">Technical requirements</h1>
                
            
            
                
<p>To use the techniques from this chapter, you need a configured Docker instance, because AWS uses Amazon Linux AMI distribution to run lambdas, and we need the special environment to compile Rust code for that environment. You also need an account in AWS. Create one if you don't have one. AWS provides a free trial period called Free Tier, which includes 1 million requests to AWS Lambda per month over the course of one year. You can read more about this trial period here: <a href="https://aws.amazon.com/free/">https://aws.amazon.com/free/.</a></p>
<p>You should also know how to use AWS Console. There will be some examples of using it in this chapter, but for production you have to know all its features, including using access controls to prevent malicious penetration to your microservice. You can read about AWS in a book called <em>Learning AWS</em>: <a href="https://www.packtpub.com/virtualization-and-cloud/learning-aws-second-edition">https://www.packtpub.com/virtualization-and-cloud/learning-aws-second-edition</a>.</p>
<p>In this chapter, we will create two examples of a serverless application. The first requires the Rust compiler 1.31 version or above and the <kbd>musl</kbd> library, and the second needs npm and Docker.</p>
<p>You can find sources of all examples of this chapter on GitHub: <a href="https://github.com/PacktPublishing/Hands-On-Microservices-with-Rust/tree/master/Chapter17/">https://github.com/PacktPublishing/Hands-On-Microservices-with-Rust/tree/master/Chapter17/</a></p>


            

            
        
    

        

                            
                    <h1 class="header-title">Serverless architecture</h1>
                
            
            
                
<p>For the most part, in this book we have created microservices as standalone server applications. To deploy them you have to upload binaries to remote servers using continuous delivery tools. If you don't want to worry about making the binaries compatible with operating systems, you can use containers to deliver and deploy applications packed to images. It gives you the opportunity to use container orchestration services, such as Kubernetes. Container orchestration software simplifies scaling and configuring large applications that use containers to run microservices. If you try to think about this simplification further, you can find it helpful to use a predefined and preinstalled pool of containers with generic environment that will run small binaries with request-handling functions and without any HTTP middleware. In other words, you could write handlers for events and no more HTTP code. This approach is called serverless.</p>
<p>In the next section we list the platforms that provide serverless infrastructure and that can be used to deploy serverless applications.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">AWS Lambda</h1>
                
            
            
                
<p>AWS Lambda is an Amazon product that you can find here: <a href="https://aws.amazon.com/lambda/">https://aws.amazon.com/lambda/</a>.</p>
<p>There is official support for the Rust programming language with the <kbd>lambda-runtime</kbd> crate: <a href="https://github.com/awslabs/aws-lambda-rust-runtime">https://github.com/awslabs/aws-lambda-rust-runtime</a>. We will use this crate in this chapter to demonstrate the serverless approach.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Azure Functions</h1>
                
            
            
                
<p>Azure Functions is the serverless product of Microsoft, and is part of the Azure platform: <a href="https://azure.microsoft.com/en-us/services/functions/">https://azure.microsoft.com/en-us/services/functions/</a><a href="https://azure.microsoft.com/en-us/services/functions/">.</a></p>
<p>There is no official Rust support at the moment, but you can use the <kbd>azure-functions</kbd> crate, which uses the internal worker protocol of Azure Functions based on GRPC to interact between the host and the language worker.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Cloudflare Workers</h1>
                
            
            
                
<p>Cloudflare offers its own serverless product called Cloudflare Workers: <a href="https://www.cloudflare.com/products/cloudflare-workers/">https://www.cloudflare.com/products/cloudflare-workers/</a>.</p>
<p>This service is compatible with Rust because Cloudflare Workers implemented an awesome idea: <strong>workers compiled to WebAssebly</strong> (<strong>WASM</strong>). Since Rust has good support for WASM, you can easily use it to produce serverless workers for Cloudflare.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">IBM Cloud Functions</h1>
                
            
            
                
<p>IBM provides its own serverless product based on Apache OpenWhisk: <a href="https://console.bluemix.net/openwhisk/">https://console.bluemix.net/openwhisk/</a>.</p>
<p>You can write serverless functions using Rust, because the platform supports functions provided as Docker images and you can create a Docker image with your Rust functions.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Google Cloud Functions</h1>
                
            
            
                
<p>Google Cloud Functions is a product of Google provided as a part of Google Cloud: <a href="https://cloud.google.com/functions/">https://cloud.google.com/functions/</a>.</p>
<p>There is no support for Rust. Potentially, you can write native modules for Python environments using Rust and try to start them using Python code, but I can't find confirmation that this approach will work. In any case, I'm sure there will be an opportunity in the future to run Rust code.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Minimal Rust microservices for AWS Lambda</h1>
                
            
            
                
<p>In this section, we will create a microservice that works in a serverless environment using AWS Lambda. We will reimplement the random number generator from <a href="be6bf2c7-c1dd-4d9f-b036-bbb12e1de809.xhtml">Chapter 4</a>, <em>Data Serialization and Deserialization with Serde Crate,</em> in the <em>Data format for interaction with microservices</em> section.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Dependencies</h1>
                
            
            
                
<p>First, we need to create a new <kbd>minimal-lambda</kbd> crate and add the following dependencies to it:</p>
<pre>[dependencies]<br/>lambda_runtime = { git = "https://github.com/awslabs/aws-lambda-rust-runtime" }<br/>log = "0.4"<br/>rand = "0.5"<br/>serde = "1.0"<br/>serde_derive = "1.0"<br/>simple_logger = "1.0"</pre>
<p>The main dependency we need is <kbd>lambda_runtime</kbd>, which is an official crate for writing <kbd>lambda</kbd> functions for AWS Lambda platform using Rust. We used a version from GitHub because, at the time of writing, this crate was in active development.</p>
<p>AWS prints the output of all the <kbd>lambda</kbd> functions as logs, and we will use the <kbd>simple_logger</kbd> crate, which prints all logs to <em>stdout</em>.</p>
<p class="mce-root"/>
<p>We also need to override the name of a binary with lambda, because an environment that run, AWS Lambda expects to find a binary called <kbd>bootstrap</kbd> that implements the <kbd>lambda</kbd> function. Let's rename the binary produced by our example:</p>
<pre>[[bin]]<br/>name = "bootstrap"<br/>path = "src/main.rs"</pre>
<p>That's enough to start writing a minimal microservice for a serverless environment.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Developing a microservice</h1>
                
            
            
                
<p>We need the following types in our code:</p>
<pre>use serde_derive::{Serialize, Deserialize};<br/>use lambda_runtime::{lambda, Context, error::HandlerError};<br/>use rand::Rng;<br/>use rand::distributions::{Bernoulli, Normal, Uniform};<br/>use std::error::Error;<br/>use std::ops::Range;</pre>
<p>It make sense to look at imports from the <kbd>lambda_runtime</kbd> crate. The <kbd>lambda</kbd> macro is used to export a handler from a binary, which will be used by the AWS Lambda runtime. <kbd>Context</kbd> is a required parameter of a handler, and we also have   imported <kbd>HandlerError</kbd> to use in the returning <kbd>Result</kbd> value of a handler.</p>
<p>Then we can write a main function that initializes <kbd>simple_logger</kbd> and wraps <kbd>rng_handler</kbd>, which we will implement in the following code, to export the handler of a lambda function:</p>
<pre>fn main() -&gt; Result&lt;(), Box&lt;dyn Error&gt;&gt; {<br/>    simple_logger::init_with_level(log::Level::Debug).unwrap();<br/>    lambda!(rng_handler);<br/>    Ok(())<br/>}</pre>
<p><kbd>rng_handler</kbd> is a function that expects a request and returns a response:</p>
<pre>fn rng_handler(event: RngRequest, _ctx: Context) -&gt; Result&lt;RngResponse, HandlerError&gt; {<br/>    let mut rng = rand::thread_rng();<br/>    let value = {<br/>        match event {<br/>            RngRequest::Uniform { range } =&gt; {<br/>                rng.sample(Uniform::from(range)) as f64<br/>            },<br/>            RngRequest::Normal { mean, std_dev } =&gt; {<br/>                rng.sample(Normal::new(mean, std_dev)) as f64<br/>            },<br/>            RngRequest::Bernoulli { p } =&gt; {<br/>                rng.sample(Bernoulli::new(p)) as i8 as f64<br/>            },<br/>        }<br/>    };<br/>    Ok(RngResponse { value })<br/>}</pre>
<p>In the implementation, we used a generator from the example in <a href="be6bf2c7-c1dd-4d9f-b036-bbb12e1de809.xhtml">Chapter 4</a>, <em>Data Serialization and Deserialization with the Serde Crate,</em> in the <em>Data format for interaction with microservices</em> section, and also borrowed a request type that has to be deserializable:</p>
<pre>#[derive(Deserialize)]<br/>#[serde(tag = "distribution", content = "parameters", rename_all = "lowercase")]<br/>enum RngRequest {<br/>    Uniform {<br/>        #[serde(flatten)]<br/>        range: Range&lt;i32&gt;,<br/>    },<br/>    Normal {<br/>        mean: f64,<br/>        std_dev: f64,<br/>    },<br/>    Bernoulli {<br/>        p: f64,<br/>    },<br/>}</pre>
<p class="mce-root">The preceding request type is an enumeration that has three variants that let a client choose one of three probability distributions to generate a random value. We also need a type to return responses with random values. We will also borrow it from the preceding code. Look at the struct we will use for responses:</p>
<pre>#[derive(Serialize)]<br/>struct RngResponse {<br/>    value: f64,<br/>}</pre>
<p>Now, this lambda function expects an <kbd>RngRequest</kbd> value in JSON format as a request that will be deserialized automatically, and a <kbd>RngResponse</kbd> result that will be serialized to JSON and returned to a client. Let's build this code and check how it works.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Building</h1>
                
            
            
                
<p>To build a lambda function, we need to produce a binary that is compatible with Amazon Linux. You can use three methods to build a corresponding binary:</p>
<ul>
<li>Build it with a Linux distribution (compatible with x86_64).</li>
<li>Build it in a Docker container of Amazon Linux.</li>
<li>Build it with the <kbd>musl</kbd> standard C library.</li>
</ul>
<p>We will use the latter method, because it minimizes the external dependencies of the produced binary. First, you have to install the <kbd>musl</kbd> library, which you can get here: <a href="https://www.musl-libc.org/">https://www.musl-libc.org/</a>.</p>
<p>I did this with the following commands:</p>
<pre><strong>git clone git://git.musl-libc.org/musl</strong><br/><strong> cd musl</strong><br/><strong> ./configure</strong><br/><strong> make</strong><br/><strong> sudo make install</strong></pre>
<p>But if there is a package for your operating system, you should to install that instead.</p>
<p>To build the code with the <kbd>musl</kbd> library we have to use <kbd>x86_64-unknown-linux-musl</kbd> as the target value. But we can set this target as the default for this project with a configuration file for cargo. Add a <kbd>.cargo/config</kbd> file to the project's folder and add the following configuration to it:</p>
<pre>[build]<br/>target = "x86_64-unknown-linux-musl"</pre>
<p>Make sure the compiler supports <kbd>musl</kbd> or add it using <kbd>rustup</kbd>:</p>
<pre><strong>rustup target add x86_64-unknown-linux-musl</strong></pre>
<p>Now you can simply build the lambda using the <kbd>cargo build</kbd> command. That produces a binary that's compiled with the <kbd>musl</kbd> library that we can upload to AWS.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Deployment</h1>
                
            
            
                
<p>We can deploy lambda to AWS using two tools:</p>
<ul>
<li>AWS CLI tool</li>
<li>Web AWS Console</li>
</ul>
<p>The first is a little tedious, and in the next section of this chapter, you will see how to use the Serverless Framework to deploy an application consists of <kbd>lambda</kbd> functions. For this example, enter the AWS Console and go to the AWS Lambda product page. Click the <em>Create Function</em> button and, in the form that appears, enter the following values:</p>
<ul>
<li><strong>Name</strong>: <kbd>minimal-lambda</kbd></li>
<li><strong>Runtime</strong>: Choose Use custom runtime in function code or layer</li>
<li><strong>Role</strong>: Choose Create a new role from one or more templates</li>
<li><strong>Role name</strong>: <kbd>minimal-lambda-role</kbd></li>
</ul>
<p>This is what the form should look like when you've finished:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/de5fedcd-8b29-4790-aae4-85866bafd712.png" style="width:49.25em;height:50.08em;"/></p>
<p>Click the Create function button, and while the function is being created, pack the binary to the zip file using the following command:</p>
<pre><strong>zip -j minimal-lambda.zip target/x86_64-unknown-linux-musl/debug/bootstrap</strong></pre>
<p>In the form that appears, choose <em>Upload a .zip file</em> in the <em>Code entry type</em> of the <em>Function code</em> section:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/d9965478-fd90-4c67-a0c7-6ffe4599c0a3.png"/></p>
<p>Choose the file and upload it using the form. When the archive with the Rust function is uploaded, the function is ready to be called. Click on the Test button, and you will see a form in which you can enter the testing request in JSON format:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/39db553d-f8e4-48ac-859c-8f4b2714986d.png"/></p>
<p>Enter the following JSON in it:</p>
<pre>{<br/>  "distribution": "uniform",<br/>  "parameters": {<br/>    "start": 0,<br/>    "end": 100<br/>  }<br/>}</pre>
<p class="mce-root"/>
<p>This is a serialized <kbd>RngRequest</kbd> value that generates random a value in the range 0-100 using uniform distribution. Enter <kbd>uniform</kbd> in the Event name field and click the <em>Create</em> button, and the testing prerequisites will be stored. Now you can choose this request in the drop-down list to the left of the <em>Test</em> button. Choose <em>uniform</em> value and click the <em>Test</em> button to see the result of the response:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/58dd8017-b4da-4479-ad57-1204f568ca71.png" style="width:43.50em;height:45.92em;"/></p>
<p>Our microservice generated a value. If you click the <em>Test</em> button again, it will generate the next value. As you can see, there are log records printed by the <kbd>simple_logger</kbd> crate in the <em>Log output</em> section. And the execution of this function takes about 20 milliseconds.</p>
<p>The main benefit of AWS Lambda is access to all other AWS services. Let's create a more complex example that utilizes more services in order to show how to integrate <kbd>lambda</kbd> functions with other AWS infrastructure.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Serverless Framework</h1>
                
            
            
                
<p>In this section, we will port a serverless application from the Wild Rydes Serverless Workshops to Rust: <a href="https://github.com/aws-samples/aws-serverless-workshops">https://github.com/aws-samples/aws-serverless-workshops</a>. The idea of this example to provide a service that emulates ordering a ride on a unicorn.</p>
<p>We will use the Serverless Framework, which provides a useful tool that simplifies the deployment of applications using a declaration of the resources and their relations. This section was inspired by an example of Serverless Framework usage created by Andrei Maksimov, which is located here: <a href="https://github.com/andreivmaksimov/serverless-framework-aws-lambda-amazon-api-gateway-s3-dynamodb-and-cognito">https://github.com/andreivmaksimov/serverless-framework-aws-lambda-amazon-api-gateway-s3-dynamodb-and-cognito</a>. Let's prepare the environment to write and build an application using the Serverless Framework.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Preparation</h1>
                
            
            
                
<p>First, you need to install the Serverless Framework using <kbd>npm</kbd>, which is supplied with Node.js:</p>
<pre><strong>sudo npm install -g serverless</strong></pre>
<p>I installed it globally because I want to use it to create a new project from a Rust template of an application with multiple lambdas:</p>
<pre><strong>sls install --url https://github.com/softprops/serverless-aws-rust-multi --name rust-sls</strong></pre>
<p>This command downloads the template automatically and will use the name provided to construct a blank application. It prints the following to the console:</p>
<pre><strong>Serverless: Downloading and installing "serverless-aws-rust-multi"...</strong><br/><strong>Serverless: Successfully installed "rust-sls"</strong></pre>
<p>When the project is initialized, enter a folder of this project and add the <strong><kbd>serverless-finch</kbd></strong> plugin, which we will use to upload the assets of our application:</p>
<pre><strong>npm install --save serverless-finch</strong></pre>
<p>The <kbd>serverless-aws-rust-multi</kbd> template is a workspace and contains two crates: <kbd>hello</kbd> and <kbd>world</kbd>. Let's rename them <kbd>lambda_1</kbd> and <kbd>lambda_2</kbd>. I have used this template to show you how an application can include more than one crate. After renaming the folders, we also have to replace the <kbd>members</kbd> of a <kbd>workspace</kbd> in the <kbd>Cargo.toml</kbd> configuration of the project:</p>
<pre>[workspace]<br/> members = [<br/>     "lambda_1",<br/>     "lambda_2",<br/> ]</pre>
<p>Now we can leave <kbd>lambda_2</kbd> without changes and implement the functionality of the Wild Rydes example in the <kbd>lambda_1</kbd> crate.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Implementation</h1>
                
            
            
                
<p>The original sources of the templates contain some code similar to the previous example, but we will write the code from scratch, and you have to remove the original <kbd>main.rs</kbd> file.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Dependencies</h1>
                
            
            
                
<p>In the <kbd>lambda_1</kbd> crate's folder, add the following dependencies to <kbd>Cargo.toml</kbd>:</p>
<pre>[dependencies]<br/>chrono = "0.4"<br/>lambda_runtime = { git = "https://github.com/awslabs/aws-lambda-rust-runtime" }<br/>log = "0.4"<br/>rand = "0.6"<br/>rusoto_core = {version = "0.35.0", default_features = false, features=["rustls"]}<br/>rusoto_dynamodb = {version = "0.35.0", default_features = false, features=["rustls"]}<br/>serde = "1.0"<br/>serde_derive = "1.0"<br/>serde_json = "1.0"<br/>simple_logger = "1.0"<br/>uuid = { version = "0.7", features = ["v4"] }</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p>If you read the previous chapters, you will be familiar with all crates from the list, including <kbd>lambda_runtime</kbd>, which we used in the previous section of this chapter. Let's look at the types in <kbd>src/main.rs</kbd> that we will use from this crate:</p>
<pre>use chrono::Utc;<br/>use lambda_runtime::{error::HandlerError, lambda, Context};<br/>use log::debug;<br/>use rand::thread_rng;<br/>use rand::seq::IteratorRandom;<br/>use rusoto_core::Region;<br/>use rusoto_dynamodb::{AttributeValue, DynamoDb, DynamoDbClient, PutItemError, PutItemInput, PutItemOutput};<br/>use serde_derive::{Serialize, Deserialize};<br/>use std::collections::HashMap;<br/>use std::error::Error;<br/>use uuid::Uuid;</pre>
<p>We used the preceding types to implement the following sequence of actions:</p>
<ul>
<li>Parsing the request</li>
<li>Finding (generating) a <kbd>Unicorn</kbd> instance that will be declared later</li>
<li>Adding a record to the <kbd>DynamoDb</kbd> table</li>
</ul>
<p>Our <kbd>main</kbd> function only calls a handler function that performs these steps:</p>
<pre>fn main() -&gt; Result&lt;(), Box&lt;dyn Error&gt;&gt; {<br/>     simple_logger::init_with_level(log::Level::Debug)?;<br/>     debug!("Starting lambda with Rust...");<br/>     lambda!(handler);<br/>     Ok(())<br/> }</pre>
<p>We also initialized the logger to have to read them with CloudWatch services.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Handler</h1>
                
            
            
                
<p>The handler performs the same logic as the original example, but it is completely rewritten with Rust and the <kbd>lambda_runtime</kbd> crate. Look at the implementation of the <kbd>handler</kbd> function:</p>
<pre>fn handler(event: Request, _: Context) -&gt; Result&lt;Response, HandlerError&gt; {<br/>     let region = Region::default();<br/>     let client = DynamoDbClient::new(region);<br/>     let username = event<br/>         .request_context<br/>         .authorizer<br/>         .claims<br/>         .get("cognito:username")<br/>         .unwrap()<br/>         .to_owned();<br/>     debug!("USERNAME: {}", username);<br/>     let ride_id = Uuid::new_v4().to_string();<br/>     let request: RequestBody = serde_json::from_str(&amp;event.body).unwrap();<br/>     let unicorn = find_unicorn(&amp;request.pickup_location);<br/>     record_ride(&amp;client, &amp;ride_id, &amp;username, &amp;unicorn).unwrap();<br/>     let body = ResponseBody {<br/>         ride_id: ride_id.clone(),<br/>         unicorn_name: unicorn.name.clone(),<br/>         unicorn,<br/>         eta: "30 seconds".into(),<br/>         rider: username.clone(),<br/>     };<br/>     let mut headers = HashMap::new();<br/>     headers.insert("Access-Control-Allow-Origin".into(), "*".into());<br/>     let body = serde_json::to_string(&amp;body).unwrap();<br/>     let resp = Response {<br/>         status_code: 201,<br/>         body,<br/>         headers,<br/>     };<br/>     Ok(resp)<br/> }</pre>
<p>Initially, this function creates a connection to DynamoDB using the default <kbd>Region</kbd> value, which initially reads environment variables to get an actual value, and if it doesn't find a region, it uses the <kbd>us-east-1</kbd> region. Then, the <kbd>handler</kbd> extracts a username provided by <kbd>Cognito</kbd> that we will use to authorize users and won't implement user registration manually.</p>
<p>Then we generate the unique ID of a ride and extract the body of a request that is provided by a JSON string. You can't declare a complete <kbd>Request</kbd> struct, you have to parse it with two steps. The first uses the <kbd>lambda!</kbd> macro, and the second uses the <kbd>serde_json::from_str</kbd> function call. Then, we call the <kbd>find_unicorn</kbd> function, which we will implement later, and add a record to a database using the <kbd>record_ride</kbd> function call, which we will implement later in this section.</p>
<p>When the record is added, we construct a response in two steps. First, we create the body of a response, and then we wrap it with extra values. We have to do this wrapping because we will use API Gateway to call the lambda with an external application shared by <kbd>S3</kbd>.</p>
<p>Now we can have a look at structs that we need.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Request and response types</h1>
                
            
            
                
<p>The main struct is <kbd>Unicorn</kbd>, which contains the creature we will ride:</p>
<pre>#[derive(Clone, Serialize)]<br/> #[serde(rename_all = "PascalCase")]<br/> struct Unicorn {<br/>     name: String,<br/>     color: String,<br/>     gender: String,<br/> }</pre>
<p>Every <kbd>Unicorn</kbd> has a <kbd>name</kbd>, <kbd>color</kbd>, and <kbd>gender</kbd>. We will store these values as items in a DynamoDB record. To simplify the creation of the instance in the code, we will add the following constructor:</p>
<pre>impl Unicorn {<br/>     fn new(name: &amp;str, color: &amp;str, gender: &amp;str) -&gt; Self {<br/>         Unicorn {<br/>             name: name.to_owned(),<br/>             color: color.to_owned(),<br/>             gender: gender.to_owned(),<br/>         }<br/>     }<br/> }</pre>
<p>You may ask why we don't represent color and gender with enumerations. It's possible, but you have to be sure that the serialized values are exactly what you want.</p>
<p>The <kbd>Location</kbd> struct represents a point on a map that will be set by the UI of the application:</p>
<pre>#[derive(Deserialize)]<br/> #[serde(rename_all = "PascalCase")]<br/> struct Location {<br/>     latitude: f64,<br/>     longitude: f64,<br/> }</pre>
<p>Now we can declare a <kbd>Request</kbd> struct that contains <kbd>body</kbd> and <kbd>request_context</kbd> fields, which we will use to get a username provided by <kbd>Cognito</kbd>. You may have noticed that the <kbd>Location</kbd> structs have different renaming rules than other structs. That's because the <kbd>Request</kbd> struct was parsed by API Gateway, but <kbd>Location</kbd> and <kbd>RequestBody</kbd> will be created by the frontend application, which uses other identifiers. <kbd>Request</kbd> represents the body as a <kbd>String</kbd>:</p>
<pre>#[derive(Deserialize)]<br/> #[serde(rename_all = "camelCase")]<br/> struct Request {<br/>     body: String,<br/>     request_context: RequestContext,<br/> }</pre>
<p><kbd>RequestContext</kbd> is a map that is filled by the runtime, and we will parse it to a struct:</p>
<pre>#[derive(Deserialize)]<br/> #[serde(rename_all = "camelCase")]<br/> struct RequestContext {<br/>     authorizer: Authorizer,<br/> }</pre>
<p>We need an <kbd>Authorizer</kbd> field that only contains <kbd>claims</kbd> values:</p>
<pre>#[derive(Deserialize)]<br/> #[serde(rename_all = "camelCase")]<br/> struct Authorizer {<br/>     claims: HashMap&lt;String, String&gt;,<br/> }</pre>
<p>We used <kbd>claims</kbd> to get the <kbd>cognito:username</kbd> value in the <kbd>handler</kbd>.</p>
<pre>#[derive(Deserialize)]<br/> #[serde(rename_all = "PascalCase")]<br/> struct RequestBody {<br/>     pickup_location: Location,<br/> }</pre>
<p>Now we can declare a <kbd>Response</kbd>. It is also used by API Gateway and has to contain <kbd>status_code</kbd> and <kbd>headers</kbd>:</p>
<pre>#[derive(Serialize)]<br/> #[serde(rename_all = "camelCase")]<br/> struct Response {<br/>     body: String,<br/>     status_code: u16,<br/>     headers: HashMap&lt;String, String&gt;,<br/> }</pre>
<p>The <kbd>body</kbd> field is represented by a <kbd>String</kbd> type that we will deserialize separately to the <kbd>ResponseBody</kbd> struct:</p>
<pre>#[derive(Serialize)]<br/> #[serde(rename_all = "PascalCase")]<br/> struct ResponseBody {<br/>     ride_id: String,<br/>     unicorn: Unicorn,<br/>     unicorn_name: String,<br/>     eta: String,<br/>     rider: String,<br/> }</pre>
<p>The preceding fields are necessary for frontend applications from the workshop.</p>
<p>Now we can add functions to generate the <kbd>Unicorn</kbd> instance and to add a record to a database.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Functions</h1>
                
            
            
                
<p>The <kbd>find_unicorn</kbd> function picks one of the three predefined values of <kbd>Unicorn</kbd>:</p>
<pre>fn find_unicorn(location: &amp;Location) -&gt; Unicorn {<br/>     debug!("Finding unicorn for {}, {}", location.latitude, location.longitude);<br/>     let unicorns = [<br/>         Unicorn::new("Bucephalus", "Golden", "Male"),<br/>         Unicorn::new("Shadowfax", "White", "Male"),<br/>         Unicorn::new("Rocinante", "Yellow", "Female"),<br/>     ];<br/>     let mut rng = thread_rng();<br/>     unicorns.iter().choose(&amp;mut rng).cloned().unwrap()<br/> }</pre>
<p class="mce-root"/>
<p>The <kbd>record_ride</kbd> function constructs put requests from DynamoDB. To make this kind of request, we need to fill a <kbd>HashMap</kbd> with attributes only. If you want to learn more about how to interact with DynamoDB, you can return to <a href="e09a1e76-ae09-41d4-99dc-9bad95fa3de7.xhtml"/><a href="e09a1e76-ae09-41d4-99dc-9bad95fa3de7.xhtml">Chapter 7</a>, <em>Reliable Integration with Databases,</em> in which we explored interaction with databases in detail.</p>
<pre>fn record_ride(<br/>     conn: &amp;DynamoDbClient,<br/>     ride_id: &amp;str,<br/>     username: &amp;str,<br/>     unicorn: &amp;Unicorn,<br/> ) -&gt; Result&lt;PutItemOutput, PutItemError&gt; {<br/>     let mut item: HashMap&lt;String, AttributeValue&gt; = HashMap::new();<br/>     item.insert("RideId".into(), s_attr(ride_id));<br/>     item.insert("User".into(), s_attr(username));<br/>     item.insert("UnicornName".into(), s_attr(&amp;unicorn.name));<br/>     let timestamp = Utc::now().to_string();<br/>     item.insert("RequestTime".into(), s_attr(&amp;timestamp));<br/>     item.insert("Unicorn".into(), unicorn_map(unicorn));<br/>     let put = PutItemInput {<br/>         table_name: "Rides".into(),<br/>         item,<br/>         ..Default::default()<br/>     };<br/>     conn.put_item(put).sync()<br/> }</pre>
<p>We also need a function to prepare <kbd>AttributeValues</kbd> used by the <kbd>rusoto_dynamodb</kbd> crate from the types that can be represented as references to a string value:</p>
<pre>fn s_attr&lt;T: AsRef&lt;str&gt;&gt;(s: T) -&gt; AttributeValue {<br/>     AttributeValue {<br/>         s: Some(s.as_ref().to_owned()),<br/>         ..Default::default()<br/>     }<br/> }</pre>
<p>The last function we need is to convert the fields of <kbd>Unicorn</kbd> into a map:</p>
<pre>fn unicorn_map(unicorn: &amp;Unicorn) -&gt; AttributeValue {<br/>     let mut item = HashMap::new();<br/>     item.insert("Name".into(), s_attr(&amp;unicorn.name));<br/>     item.insert("Color".into(), s_attr(&amp;unicorn.color));<br/>     item.insert("Gender".into(), s_attr(&amp;unicorn.gender));<br/>     AttributeValue {<br/>         m: Some(item),<br/>         ..Default::default()<br/>     }<br/> }</pre>
<p>You will see a stored value that uses this layout with AWS Console later in this chapter.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Configuration</h1>
                
            
            
                
<p>The Serverless Framework uses a <kbd>serverless.yml</kbd> configuration file to deploy lambdas to AWS. Since we installed the <kbd>serverless-rust</kbd> plugin (which comes with the Rust template), we can use it to set a runtime. Fill in the parameters of the service described:</p>
<pre>service: rust-sls<br/> provider:<br/>   name: aws<br/>   runtime: rust<br/>   memorySize: 128</pre>
<p>The following parameter takes more control for configuring functions:</p>
<pre>package:<br/>   individually: true</pre>
<p>We also have to activate two plugins: one for building Rust lambdas and another for uploading assets to <kbd>S3</kbd>:</p>
<pre>plugins:<br/>   - serverless-rust<br/>   - serverless-finch</pre>
<p>Now we can declare our functions:</p>
<pre>functions:<br/>   lambda_1:<br/>     handler: lambda_1<br/>     role: RustSlsLambdaRole<br/>     events:<br/>       - http:<br/>           path: ride<br/>           method: post<br/>           cors: true<br/>           authorizer:<br/>             type: COGNITO_USER_POOLS<br/>             authorizerId:<br/>               Ref: RustSlsApiGatewayAuthorizer<br/>   lambda_2:<br/>     handler: lambda_2<br/>     events:<br/>       - http:<br/>           path: check<br/>           method: get</pre>
<p>The first function has the associated <kbd>RustSlsLambdaRole</kbd> role that we will declare later. We need it to get access to some resources. The lambda takes a post and supports CORS to be called from the frontend, which works in a browser. We have also associated an authorizer, and use <kbd>RustSlsApiGatewayAuthorizer</kbd>, which we will declare later.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Resources</h1>
                
            
            
                
<p>Add a resources section that contains <kbd>Resources</kbd> and <kbd>Outputs</kbd> maps to declare the necessary resources and output variables. Let's add <kbd>Resources</kbd>:</p>
<pre>resources:<br/>   Resources:</pre>
<p>Add an <kbd>S3</kbd> bucket declaration, where we place all the assets and set <kbd>WebsiteConfiguration</kbd> to set the default index file:</p>
<pre>RustSlsBucket:<br/>   Type: AWS::S3::Bucket<br/>   Properties:<br/>     BucketName: rust-sls-aws<br/>     WebsiteConfiguration:<br/>       IndexDocument: index.html</pre>
<p>We also have to add a policy to allow these files to be read by an external client, such as a browser:</p>
<pre>RustSlsBucketPolicy:<br/>   Type: AWS::S3::BucketPolicy<br/>   Properties:<br/>     Bucket:<br/>       Ref: "RustSlsBucket"<br/>     PolicyDocument:<br/>       Statement:<br/>         -<br/>           Effect: "Allow"<br/>           Principal: "*"<br/>           Action:<br/>             - "s3:GetObject"<br/>           Resource:<br/>             Fn::Join:<br/>               - ""<br/>               -<br/>                 - "arn:aws:s3:::"<br/>                 -<br/>                   Ref: "RustSlsBucket"<br/>                 - "/*"</pre>
<p>The Wild Rydes application is configured to use <kbd>Cognito</kbd> with a client to authorize users with their accounts. Let's configure it with the following declaration and activate email confirmations:</p>
<pre>RustSlsCognitoUserPool:<br/>   Type: AWS::Cognito::UserPool<br/>   Properties:<br/>     UserPoolName: RustSls<br/>     UsernameAttributes:<br/>       - email<br/>     AutoVerifiedAttributes:<br/>       - email<br/>RustSlsCognitoUserPoolClient:<br/>   Type: AWS::Cognito::UserPoolClient<br/>   Properties:<br/>     ClientName: RustSlsWebApp<br/>     GenerateSecret: false<br/>     UserPoolId:<br/>       Ref: "RustSlsCognitoUserPool"</pre>
<p>In <a href="e09a1e76-ae09-41d4-99dc-9bad95fa3de7.xhtml">Chapter 7</a>, <em>Reliable Integration with Databases,</em> we used a JSON declaration of a table. You can configure a <kbd>DynamoDB</kbd> table using the Serverless Framework as well:</p>
<pre>RustSlsDynamoDBTable:<br/>   Type: AWS::DynamoDB::Table<br/>   Properties:<br/>     TableName: Rides<br/>     AttributeDefinitions:<br/>       - AttributeName: RideId<br/>         AttributeType: S<br/>     KeySchema:<br/>       - AttributeName: RideId<br/>         KeyType: HASH<br/>     ProvisionedThroughput:<br/>       ReadCapacityUnits: 1<br/>       WriteCapacityUnits: 1</pre>
<p>Add a role for our <kbd>lambda_1</kbd> crate:</p>
<pre>RustSlsLambdaRole:<br/>   Type: AWS::IAM::Role<br/>   Properties:<br/>     RoleName: RustSlsLambda<br/>     AssumeRolePolicyDocument:<br/>       Version: '2012-10-17'<br/>       Statement:<br/>         - Effect: Allow<br/>           Principal:<br/>             Service:<br/>               - lambda.amazonaws.com<br/>           Action: sts:AssumeRole</pre>
<p>And add these policies to this role:</p>
<pre>Policies:<br/>   - PolicyName: DynamoDBWriteAccess<br/>     PolicyDocument:<br/>       Version: '2012-10-17'<br/>       Statement:<br/>         - Effect: Allow<br/>           Action:<br/>             - logs:CreateLogGroup<br/>             - logs:CreateLogStream<br/>             - logs:PutLogEvents<br/>           Resource:<br/>             - 'Fn::Join':<br/>               - ':'<br/>               -<br/>                 - 'arn:aws:logs'<br/>                 - Ref: 'AWS::Region'<br/>                 - Ref: 'AWS::AccountId'<br/>                 - 'log-group:/aws/lambda/*:*:*'<br/>         - Effect: Allow<br/>           Action:<br/>             - dynamodb:PutItem<br/>           Resource:<br/>             'Fn::GetAtt': [ RustSlsDynamoDBTable, Arn ]</pre>
<p>We have to provide write access to the <kbd>DynamoDB</kbd> table for this role.</p>
<p>Create an <kbd>authorizer</kbd>:</p>
<pre>RustSlsApiGatewayAuthorizer:<br/>   Type: AWS::ApiGateway::Authorizer<br/>   Properties:<br/>     Name: RustSls<br/>     RestApiId:<br/>       Ref: ApiGatewayRestApi<br/>     Type: COGNITO_USER_POOLS<br/>     ProviderARNs:<br/>       - Fn::GetAtt: [ RustSlsCognitoUserPool, Arn ]<br/>     IdentitySource: method.request.header.Authorization</pre>
<p class="mce-root">Declare the output variables:</p>
<pre>Outputs:<br/>   RustSlsBucketURL:<br/>     Description: "RustSls Bucket Website URL"<br/>     Value:<br/>       "Fn::GetAtt": [ RustSlsBucket, WebsiteURL ]<br/>   RustSlsCognitoUserPoolId:<br/>     Description: "RustSls Cognito User Pool ID"<br/>     Value:<br/>       Ref: "RustSlsCognitoUserPool"<br/>   RustSlsCognitoUserPoolClientId:<br/>     Description: "RustSls Cognito User Pool Client ID"<br/>     Value:<br/>       Ref: "RustSlsCognitoUserPoolClient"<br/>   RustSlsDynamoDbARN:<br/>     Description: "RustSls DynamoDB ARN"<br/>     Value:<br/>       "Fn::GetAtt": [ RustSlsDynamoDBTable, Arn ]</pre>
<p class="mce-root">The last section of this long config declares the folder that the <kbd>serverless-finch</kbd> plugin will use to upload:</p>
<pre>custom:<br/>   client:<br/>     bucketName: rust-sls-aws<br/>     distributionFolder: assets</pre>
<p class="mce-root">As you can see, I used <kbd>rust-sls-aws</kbd> as the bucket name, but every <kbd>S3</kbd> bucket needs a unique global name, and you have to replace the bucket name in all the configs to deploy it.</p>
<p class="mce-root"/>


            

            
        
    

        

                            
                    <h1 class="header-title">Deployment</h1>
                
            
            
                
<p>Everything is ready for deployment. You need a working AWS account to run this application. But let's start by creating a user with the necessary permissions to deploy the application using AWS CLI.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Permissions</h1>
                
            
            
                
<p>To deploy this application, you need to have configured the AWS CLI tool and a user with the following permissions:</p>
<ul>
<li>AWSLambdaFullAccess</li>
<li>IAMFullAccess</li>
<li>AmazonDynamoDBFullAccess</li>
<li>AmazonAPIGatewayAdministrator</li>
<li>AmazonCognitoPowerUser</li>
<li>CloudFormationAdministrator</li>
</ul>
<p>It is worth noting that the latter was created manually and can be added when configuring the user by adding a JSON definition to the policy:</p>
<pre>{<br/>    "Version": "2012-10-17",<br/>    "Statement": [<br/>        {<br/>            "Sid": "Stmt1449904348000",<br/>            "Effect": "Allow",<br/>            "Action": [<br/>                "cloudformation:CreateStack",<br/>                "cloudformation:CreateChangeSet",<br/>                "cloudformation:ListStacks",<br/>                "cloudformation:UpdateStack",<br/>                "cloudformation:DeleteStack",<br/>                "cloudformation:DescribeStacks",<br/>                "cloudformation:DescribeStackResource",<br/>                "cloudformation:DescribeStackEvents",<br/>                "cloudformation:ValidateTemplate",<br/>                "cloudformation:DescribeChangeSet",<br/>                "cloudformation:ExecuteChangeSet"<br/>            ],<br/>            "Resource": [<br/>                "*"<br/>            ]<br/>        }<br/>    ]<br/>}</pre>
<p>When you have created a user with the necessary credentials, you can build and deploy the application using the Serverless Framework, which builds all the lambdas automatically.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Script</h1>
                
            
            
                
<p>We need some values that are not known before deployment. We will use the <kbd>sls info -v</kbd> command to get the actual values that we need to configure the frontend. Create a bash script to add the necessary deployment functions. First, we need an <kbd>extract</kbd> function to get the second column aster space delimited of <kbd>sls info</kbd> output:</p>
<pre>extract() {<br/>     echo "$DATA" | grep $1 | cut -d " " -f2<br/> }</pre>
<p>To deploy an application with the Serverless Framework, you have to call the <kbd>sls deploy</kbd> command, but our application is more complex and we have to use a sequence of commands:</p>
<pre>deploy() {<br/>     echo "ASSETS DOWNLOADING"<br/>     curl -L https://api.github.com/repos/aws-samples/aws-serverless-workshops/tarball \<br/>         | tar xz --directory assets --wildcards "*/WebApplication/1_StaticWebHosting/website" --strip-components=4<br/>     echo "LAMBDAS BUILDING"<br/>     sls deploy<br/>     echo "ASSETS UPLOADING"<br/>     sls client deploy<br/>     echo "CONFIGURATION UPLOADING"<br/>     DATA=`sls info -v`<br/>     POOL_ID=`extract PoolId`<br/>     POOL_CLIENT_ID=`extract PoolClientId`<br/>     REGION=`extract region`<br/>     ENDPOINT=`extract ServiceEndpoint`<br/>     CONFIG="<br/>     window._config = {<br/>         cognito: {<br/>             userPoolId: '$POOL_ID',<br/>             userPoolClientId: '$POOL_CLIENT_ID',<br/>             region: '$REGION'<br/>         },<br/>         api: {<br/>             invokeUrl: '$ENDPOINT'<br/>         }<br/>     };<br/>     "<br/>     echo "$CONFIG" | aws s3 cp - s3://rust-sls-aws/js/config.js<br/>     INDEX=`extract BucketURL`<br/>     echo "INDEX: $INDEX"<br/> }</pre>
<p>In the <kbd>deploy</kbd> function we download the frontend part of the Wild Rydes application from GitHub and only extract the folder we need to the <kbd>assets</kbd> folder of our project. Then we call <kbd>sls deploy</kbd> to deploy a stack of the application. Then we call <kbd>sls client deploy</kbd> to publish all assets to <kbd>S3</kbd>. When all parts are deployed we use the <kbd>extract</kbd> function to get all the necessary values to fill the <kbd>config.js</kbd> file, which is necessary to connect the deployed frontend with our lambda implemented with Rust. We construct a <kbd>config.js</kbd> file from the embedded template and upload it with the <kbd>aws s3 cp</kbd> command.</p>
<p>Let's run this command.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Running</h1>
                
            
            
                
<p>If you have downloaded the sources of the project for this chapter from GitHub, you can use the <kbd>deploy.sh</kbd> script to call the function we implemented previously. Provide the name of the <kbd>deploy</kbd> function to call it:</p>
<pre><strong>./deploy.sh deploy</strong></pre>
<p>It will start the building and deployment process with the Serverless Framework and will print something like this:</p>
<pre>ASSETS DOWNLOADING<br/>   % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current<br/>                                  Dload  Upload   Total   Spent    Left  Speed<br/>   0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0<br/> 100 65.7M    0 65.7M    0     0  7647k      0 --:--:--  0:00:08 --:--:-- 9968k<br/> LAMBDAS BUILDING<br/> Serverless: Building native Rust lambda_1 func...<br/>     Finished release [optimized] target(s) in 0.56s                                                                                                                                                                <br/>   adding: bootstrap (deflated 60%)<br/> Serverless: Building native Rust lambda_2 func...<br/>     Finished release [optimized] target(s) in 0.32s                                                                                                                                                                <br/>   adding: bootstrap (deflated 61%)<br/> Serverless: Packaging service...<br/> Serverless: Creating Stack...<br/> Serverless: Checking Stack create progress...<br/> .....<br/> Serverless: Stack create finished...<br/> Serverless: Uploading CloudFormation file to S3...<br/> Serverless: Uploading artifacts...<br/> Serverless: Uploading service .zip file to S3 (2.75 MB)...<br/> Serverless: Uploading service .zip file to S3 (1.12 MB)...<br/> Serverless: Validating template...<br/> Serverless: Updating Stack...<br/> Serverless: Checking Stack update progress...<br/> ........................................................................<br/> Serverless: Stack update finished...<br/> Service Information<br/> service: rust-sls<br/> stage: dev<br/> region: us-east-1<br/> stack: rust-sls-dev<br/> api keys:<br/>   None<br/> endpoints:<br/>   POST - https://48eggoi698.execute-api.us-east-1.amazonaws.com/dev/ride<br/>   GET - https://48eggoi698.execute-api.us-east-1.amazonaws.com/dev/check<br/> functions:<br/>   lambda_1: rust-sls-dev-lambda_1<br/>   lambda_2: rust-sls-dev-lambda_2<br/> layers:<br/>   None</pre>
<p>The deployment takes time, and when it is finished the second command, <kbd>sls client deploy</kbd>, will be called to upload the assets folder with the <kbd>serverless-finch</kbd> plugin, and it prints the following:</p>
<pre><br/>ASSETS UPLOADING<br/>Serverless: This deployment will:<br/>Serverless: - Upload all files from 'assets' to bucket 'rust-sls-aws'<br/>Serverless: - Set (and overwrite) bucket 'rust-sls-aws' configuration<br/>Serverless: - Set (and overwrite) bucket 'rust-sls-aws' bucket policy<br/>Serverless: - Set (and overwrite) bucket 'rust-sls-aws' CORS policy<br/>? Do you want to proceed? true<br/>Serverless: Looking for bucket...<br/>Serverless: Bucket found...<br/>Serverless: Deleting all objects from bucket...<br/>Serverless: Configuring bucket...<br/>Serverless: Configuring policy for bucket...<br/>Serverless: Configuring CORS for bucket...<br/>Serverless: Uploading client files to bucket...<br/>Serverless: Success! Your site should be available at http://rust-sls-aws.s3-website-us-east-1.amazonaws.com/<br/>CONFIGURATION UPLOADING<br/>INDEX: http://rust-sls-aws.s3-website-us-east-1.amazonaws.com</pre>
<p>The script printed the link that we can use to connect to and test the application.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Testing</h1>
                
            
            
                
<p>Open the provided URL in a browser, and you will see the frontend Wild Rydes app.</p>
<p>Users have to click the GIDDY UP! button and register an account using <kbd>Cognito</kbd>, which is actually used in the background, and users don't need to interact directly with that service.</p>
<p>You will see the cute UI. Click on the map and click the <em>Set Pickup</em> button, and you will see how the head of a unicorn moves to the point you set:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/33b5290a-8241-4acf-b0ea-cff979995aeb.png" style="width:38.92em;height:34.25em;"/></p>
<p>The name and the color of unicorn is generated by our <kbd>lambda</kbd> function that was created with Rust. If you open some pages of AWS Console you can see that there is a registered user on the <em>Users and groups</em> page of the <em>User Pools</em> section:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/685ef40a-da5b-4092-bd5c-9ab2738814b2.png"/></p>
<p>We have two deployed lambdas, but actually the application only uses the first, which is called <kbd>rust-sls-dev-lambda_1</kbd>:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/f0c392c6-1c8f-40f4-9154-8311801837c6.png"/></p>
<p>If you enter the lambda's page, click on the Monitoring tab, and open <kbd>CloudWatch</kbd> logs of the lambda, you can see the lambda generated a username and, is stored in the location we set:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/a6e64cbe-9197-4616-ba68-a001cad0af5c.png"/></p>
<p class="mce-root">The lambda also stored a record in DynamoDB, and you can also  find it on the <em>Tables</em> page of the DynamoDB section:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/6da41e95-f05a-407f-8292-4690ce0abd40.png"/></p>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root">You can see the record that the lambda added. And if you click on the record, you will see the all the fields we populated with the <kbd>record_ride</kbd> function earlier:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/9d7976d8-9b11-46c7-aba3-c64136a42344.png"/></p>
<p class="mce-root">The application has been successfully ported to Rust, and it works as expected. Let's look at how we can clean up the resources we've used.</p>
<p class="mce-root"/>
<p class="mce-root"/>


            

            
        
    

        

                            
                    <h1 class="header-title">Updating and removing</h1>
                
            
            
                
<p>The Serverless Framework also provides the ability to update resources automatically if you call <kbd>sls deploy</kbd> again. We can add this as a function to the deployment bash script:</p>
<pre>update() {<br/>     sls deploy<br/> }</pre>
<p>This command is useful if you want to update the code of some of the lambdas, but don't want to leave the session maintained by <kbd>Cognito</kbd>.</p>
<p>To remove everything we deployed, we can use the following function:</p>
<pre>remove() {<br/>     echo "ASSETS REMOVING"<br/>     sls client remove<br/>     echo "LAMBDAS REMOVING"<br/>     sls remove<br/>     echo "ASSETS CLEANUP"<br/>     rm -rf assets<br/>     mkdir assets<br/>     touch assets/.gitkeep<br/> }</pre>
<p>It works because the Serverless Framework supports removing declared resources. I recommend you clean up everything after experimenting, because AWS will produce bills for services even if you don't use this demo.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Summary</h1>
                
            
            
                
<p>In this chapter, we studied an alternative approach to microservice implementation—serverless architecture. This approach involves direct usage of functions that handle incoming requests. There are many providers of serverless infrastructure, and we used the popular AWS platform to port a serverless application to Rust.</p>


            

            
        
    </body></html>