<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Algorithms of the Standard Library</h1>
                </header>
            
            <article>
                
<p>Rust's standard library provides a few fundamental data types that cover the basic needs of many projects and, typically, there is no need to implement your own algorithms if the appropriate data structure is available. If, for some reason, the data type is not perfectly suited to the task, the standard library has you covered as well. In this quick round-up, you can look forward to learning about the following:</p>
<ul>
<li>The <kbd>slice</kbd> primitive type</li>
<li>The <kbd>Iterator</kbd> trait</li>
<li><kbd>binary_search()</kbd></li>
<li><kbd>sort()</kbd>, stable, and unstable</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Slicing and iteration</h1>
                </header>
            
            <article>
                
<p>Similar to how interfaces standardize access to functionality in the libraries of other languages, Rust's standard library utilizes a type and a trait to provide fundamental implementations. The trait, <kbd>Iterator&lt;T&gt;</kbd>, has been looked at and used over the course of this book several times. The slice type, however, was not explicitly used a lot, especially since the Rust compiler automatically uses slices when <kbd>Vec&lt;T&gt;</kbd> is borrowed for a function call. How can you leverage this type, though? We have seen the <kbd>Iterator&lt;T&gt;</kbd> implementation in action, but does it provide more than that?</p>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Iterator</h1>
                </header>
            
            <article>
                
<p>To recap: an iterator is a pattern to traverse a collection, providing a pointer to each element in the process. This pattern is mentioned in the book <em>Design Patterns</em>, by Erich Gamma, Richard Helm, Ralph Johnson, and John Vlissides (the Gang of Four), in 1994 and can be found in basically every language one way or another.</p>
<p>In Rust, the term pointer to each element gets a new dimension: is it a borrowed or owned item? Can this be mutably borrowed as well?</p>
<p>Using the standard library's <kbd>Iterator&lt;T&gt;</kbd> trait makes a lot of sense, since it provides a serious amount of useful functions, which are all based around a single implementation of <kbd>next()</kbd>.</p>
<p><kbd>next()</kbd> returns an <kbd>Option&lt;Self::Item&gt;</kbd>, which is the associated type that has to be declared when implementing the trait—and it can be anything you like!</p>
<p>Therefore, using <kbd>&amp;MyType</kbd>, <kbd>&amp;mut MyType</kbd>, and <kbd>MyType</kbd> can all be implemented separately to achieve the desired functionality. <kbd>IntoIter&lt;T&gt;</kbd> is a trait that is specifically designed to facilitate this workflow and to integrate it neatly with the <kbd>for</kbd> loop syntax. The following code is from the Rust standard library's source code:</p>
<pre class="rust">impl&lt;T&gt; IntoIterator for Vec&lt;T&gt; {<br/>    type Item = T;<br/>    type IntoIter = IntoIter&lt;T&gt;;<br/><br/>    /// Creates a consuming iterator, that is, <br/>    /// one that moves each value out of<br/>    /// the vector (from start to end). <br/>    /// The vector cannot be used after calling<br/>    /// this.<br/>    ///<br/>    /// # Examples<br/>    ///<br/>    /// ```<br/>    /// let v = vec!["a".to_string(), "b".to_string()];<br/>    /// for s in v.into_iter() {<br/>    /// // s has type String, not &amp;String<br/>    /// println!("{}", s);<br/>    /// }<br/>    /// ```<br/>    #[inline]<br/>    fn into_iter(mut self) -&gt; IntoIter&lt;T&gt; {<br/>        unsafe {<br/>            let begin = self.as_mut_ptr();<br/>            assume(!begin.is_null());<br/>            let end = if mem::size_of::&lt;T&gt;() == 0 {<br/>                arith_offset(begin as *const i8, self.len() <br/>                             as isize) as *const T<br/>            } else {<br/>                begin.add(self.len()) as *const T<br/>            };<br/>            let cap = self.buf.cap();<br/>            mem::forget(self);<br/>            IntoIter {<br/>                buf: NonNull::new_unchecked(begin),<br/>                phantom: PhantomData,<br/>                cap,<br/>                ptr: begin,<br/>                end,<br/>            }<br/>        }<br/>    }<br/>}</pre>
<p>Rust's <kbd>Vec&lt;T&gt;</kbd> implements precisely this pattern, but with a nice twist. The preceding code consumes the original data structure, potentially transforming the original into something that's easier to iterate, in the same way as trees can be expanded into a sorted <kbd>Vec&lt;T&gt;</kbd> or a stack. To return to the original theme, the <kbd>Iterator&lt;T&gt;</kbd> provides functions (implemented in further structures) that add many possible ways to search and filter through a collection.</p>
<p>Any Rust user will be aware of the <kbd>iter()</kbd> function of <kbd>Vec&lt;T&gt;</kbd><span>,</span> however, which is actually provided by the slice type that <kbd>Vec</kbd> is implicitly converted into?</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Slices</h1>
                </header>
            
            <article>
                
<p>Slices are views into sequences to provide a more unified interface for accessing, iterating, or otherwise interacting with these memory areas. Consequently, they are available through <kbd>Vec&lt;T&gt;</kbd>, especially since they implement the <a href="https://doc.rust-lang.org/std/ops/trait.Deref.html"><kbd>Deref</kbd></a> trait to implicitly treat <kbd>Vec&lt;T&gt;</kbd> as a <kbd>[T]</kbd>—a slice of <kbd>T</kbd>.</p>
<p>The <kbd>Vec&lt;T&gt;</kbd> implementation also hints at that for the <kbd>IntoIterator</kbd> implementation for immutable and mutable references:</p>
<pre class="rust">impl&lt;'a, T&gt; IntoIterator for &amp;'a Vec&lt;T&gt; {<br/>    type Item = &amp;'a T;<br/>    type IntoIter = slice::Iter&lt;'a, T&gt;;<br/><br/>    fn into_iter(self) -&gt; slice::Iter&lt;'a, T&gt; {<br/>        self.iter()<br/>    }<br/>}<br/><br/>impl&lt;'a, T&gt; IntoIterator for &amp;'a mut Vec&lt;T&gt; {<br/>    type Item = &amp;'a mut T;<br/>    type IntoIter = slice::IterMut&lt;'a, T&gt;;<br/><br/>    fn into_iter(self) -&gt; slice::IterMut&lt;'a, T&gt; {<br/>        self.iter_mut()<br/>    }<br/>}</pre>
<p>The slice itself is only a view, represented by a pointer to the memory part and its length. Since the compiler knows the nature of the data contained within, it can also figure out individual elements to provide type safety.</p>
<p>A more detailed explanation of slices and the way they work would warrant its own book, so it is recommended at least reading the documentation (or the source code) of the <kbd>slice</kbd> module (<a href="https://doc.rust-lang.org/std/slice/index.html">https://doc.rust-lang.org/std/slice/index.html</a>)<a href="https://doc.rust-lang.org/std/slice/index.html">.</a></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Search</h1>
                </header>
            
            <article>
                
<p>Finding things in a collection has been discussed throughout this book, and the Rust standard library provides a few ways by default. These functions are attached to the <kbd>Iterator&lt;T&gt;</kbd> trait or slice types and work regardless of the actual type, provided that a function to compare two elements is furnished.</p>
<p>This can either be the <kbd>Ord</kbd> trait or a custom comparator function, such as the <kbd>position()</kbd> function on the <kbd>Iterator&lt;T&gt;</kbd>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Linear search</h1>
                </header>
            
            <article>
                
<p>The classic linear search is provided via <kbd>position()</kbd> (or <kbd>rposition()</kbd>) on the <kbd>Iterator&lt;T&gt;</kbd> trait, and it even utilizes other iterator functions that are implemented on the trait itself:</p>
<pre>fn position&lt;P&gt;(&amp;mut self, mut predicate: P) -&gt; Option&lt;usize&gt; where<br/>    Self: Sized,<br/>    P: FnMut(Self::Item) -&gt; bool,<br/>{<br/>    // The addition might panic on overflow<br/>    self.try_fold(0, move |i, x| {<br/>        if predicate(x) { LoopState::Break(i) }<br/>        else { LoopState::Continue(i + 1) }<br/>    }).break_value()<br/>}</pre>
<p><kbd>try_fold()</kbd> is a short-circuit variation on the <kbd>fold()</kbd> (or <kbd>reduce()</kbd>, following the map/reduce pattern) function that returns whenever <kbd>LoopState::Break</kbd> is returned. The call to <kbd>break_value()</kbd> transforms the result from the value returned in the <kbd>LoopState::Break</kbd> enumeration into <kbd>Option</kbd> and <kbd>None</kbd> if it ran through the entire collection.</p>
<p>This is the brute-force approach to searching and can be useful if the collection is unsorted and short. For anything longer, sorting and using the binary search function might pay off.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Binary search</h1>
                </header>
            
            <article>
                
<p class="mce-root">A generic fast search function is provided through slices as well, called <kbd>binary_search()</kbd>. As discussed in <a href="32002bad-c2bb-46e9-918d-12d7dabfe579.xhtml">Chapter 10</a>, <em>Finding Stuff</em>, a binary search returns the index of an element after closing in on its position by repeatedly choosing a half.</p>
<p>To achieve that, there are two prerequisites that the input slice has to satisfy:</p>
<ul>
<li>It's sorted</li>
<li>The element type implements the <kbd>Ord</kbd> trait</li>
</ul>
<p><kbd>binary_search()</kbd> cannot check whether the collection that's <span>provided</span> is sorted, which means that if an unordered collection returns the expected result, it can only be coincidental. Additionally, if there are multiple elements with the same value, any of those can be the result.</p>
<p>Other than using the implicitly provided comparison function (by implementing <kbd>Ord</kbd>), <kbd>binary_search()</kbd> also has a more flexible sibling—<kbd>binary_search_by()</kbd>, which requires a comparison function to be supplied.</p>
<p>Under the hood, this function is comparable to the naive implementation we created in <a href="32002bad-c2bb-46e9-918d-12d7dabfe579.xhtml">Chapter 10</a>, <em>Finding Stuff</em>; on occasion, it was even faster by a nanosecond or two. The code is just as simple, however:</p>
<pre class="rust">pub fn binary_search_by&lt;'a, F&gt;(&amp;'a self, mut f: F) -&gt; Result&lt;usize, usize&gt;<br/>        where F: FnMut(&amp;'a T) -&gt; Ordering<br/>    {<br/>        let s = self;<br/>        let mut size = s.len();<br/>        if size == 0 {<br/>            return Err(0);<br/>        }<br/>        let mut base = 0usize;<br/>        while size &gt; 1 {<br/>            let half = size / 2;<br/>            let mid = base + half;<br/>            // mid is always in [0, size), <br/>            // that means mid is &gt;= 0 and &lt; size.<br/>            // mid &gt;= 0: by definition<br/>            // mid &lt; size: mid = size / 2 + size / 4 + size / 8 ...<br/>            let cmp = f(unsafe { s.get_unchecked(mid) });<br/>            base = if cmp == Greater { base } else { mid };<br/>            size -= half;<br/>        }<br/>        // base is always in [0, size) because base &lt;= mid.<br/>        let cmp = f(unsafe { s.get_unchecked(base) });<br/>        if cmp == Equal { Ok(base) } else { <br/>                     Err(base + (cmp == Less) as usize) }<br/><br/>    }</pre>
<p>Other variants of the function include searching by key or by the comparator function of the <kbd>Ord</kbd> trait (as mentioned previously). One major caveat can be the requirement to provide a sorted collection to the binary search function, but luckily, Rust provides sorting in its standard library.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Sorting</h1>
                </header>
            
            <article>
                
<p>Sorting is an important feature in user interfaces, but also provides the predictability that's necessary for many algorithms. Whenever there is no way to use an appropriate data structure (such as a tree), a generic sorting algorithm can take care of creating that order. One important question arises regarding equal values: will they end up at the same exact spot every time? When using a stable sorting algorithm, the answer is <em>yes</em>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Stable sorting</h1>
                </header>
            
            <article>
                
<p>The key to stable sorting is not reordering equal elements, so in <kbd>[1, 1, 2, 3, 4, 5]</kbd>, <kbd>1</kbd>s never change their positions relative to each other. In Rust, this is actually used when <kbd>sort()</kbd> is called on <kbd>Vec&lt;T&gt;</kbd>.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>The current (2018 edition) implementation of <kbd>Vec&lt;T&gt;</kbd> uses a merge sort variation based on Timsort. Here is the source code:</p>
<pre>pub fn sort(&amp;mut self)<br/>    where T: Ord<br/>{<br/>    merge_sort(self, |a, b| a.lt(b));<br/>}</pre>
<p>The code is quite verbose, but can be split into smaller parts. The first step is to sort smaller (20 elements or less) slices by deleting and reinserting the elements in order (in other words, insertion sort):</p>
<pre>fn merge_sort&lt;T, F&gt;(v: &amp;mut [T], mut is_less: F)<br/>    where F: FnMut(&amp;T, &amp;T) -&gt; bool<br/>{<br/>    // Slices of up to this length get sorted using insertion sort.<br/>    const MAX_INSERTION: usize = 20;<br/>    // Very short runs are extended using insertion sort <br/>    // to span at least this many elements.<br/>    const MIN_RUN: usize = 10;<br/><br/>    // Sorting has no meaningful behavior on zero-sized types.<br/>    if size_of::&lt;T&gt;() == 0 {<br/>        return;<br/>    }<br/><br/>    let len = v.len();<br/><br/>    // Short arrays get sorted in-place via insertion <br/>    // sort to avoid allocations.<br/>    if len &lt;= MAX_INSERTION {<br/>        if len &gt;= 2 {<br/>            for i in (0..len-1).rev() {<br/>                insert_head(&amp;mut v[i..], &amp;mut is_less);<br/>            }<br/>        }<br/>        return;<br/>    }</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p>If the collection is longer, the algorithm resorts to traversing the items back to front, identifying natural runs. The constant <kbd>MIN_RUN</kbd> (<kbd>10</kbd> in the preceding code) defines a minimum length of such a run, so a shorter run (such as <kbd>5, 9, 10, 11, 13, 19, 31, 55, 56</kbd> in <kbd>[5, 9, 10, 11, 13, 19, 31, 55, 56, 1, ...]</kbd>) is expanded by doing an insertion sort on the 1 to get to 10 elements. The metadata of the resulting block (for <kbd>[1, 5, 9, 10, 11, 13, 19, 31, 55, 56]</kbd>, it would start at <kbd>0</kbd>, with a length of 10) is then pushed onto a stack for subsequent merging (note: we recommend reading the comments from the code authors):</p>
<pre>    // Allocate a buffer to use as scratch memory. <br/>    // We keep the length 0 so we can keep in it<br/>    // shallow copies of the contents of `v` without risking the dtors     <br/>    // running on copies if `is_less` panics. <br/>    // When merging two sorted runs, this buffer holds a copy of the <br/>    // shorter run, which will always have length at most `len / 2`.<br/>    let mut buf = Vec::with_capacity(len / 2);<br/><br/>    // In order to identify natural runs in `v`, we traverse it <br/>    // backwards. That might seem like a strange decision, but consider <br/>    // the fact that merges more often go in the opposite direction<br/>    // (forwards). According to benchmarks, merging forwards is <br/>    // slightly faster than merging backwards. To conclude, identifying <br/>    // runs by traversing backwards improves performance.<br/>    let mut runs = vec![];<br/>    let mut end = len;<br/>    while end &gt; 0 {<br/>        // Find the next natural run, <br/>        // and reverse it if it's strictly descending.<br/>        let mut start = end - 1;<br/>        if start &gt; 0 {<br/>            start -= 1;<br/>            unsafe {<br/>                if is_less(v.get_unchecked(start + 1), <br/>                           v.get_unchecked(start)) {<br/>                    while start &gt; 0 &amp;&amp; is_less(v.get_unchecked(start),<br/>                                       v.get_unchecked(start - 1)) {<br/>                        start -= 1;<br/>                    }<br/>                    v[start..end].reverse();<br/>                } else {<br/>                    while start &gt; 0 &amp;&amp; !is_less(v.get_unchecked(start),<br/>                                       v.get_unchecked(start - 1)) {<br/>                        start -= 1;<br/>                    }<br/>                }<br/>            }<br/>        }<br/><br/>        // Insert some more elements into the run if it's too short. <br/>        // Insertion sort is faster than<br/>        // merge sort on short sequences, <br/>        // so this significantly improves performance.<br/>        while start &gt; 0 &amp;&amp; end - start &lt; MIN_RUN {<br/>            start -= 1;<br/>            insert_head(&amp;mut v[start..end], &amp;mut is_less);<br/>        }<br/><br/>        // Push this run onto the stack.<br/>        runs.push(Run {<br/>            start,<br/>            len: end - start,<br/>        });<br/>        end = start;</pre>
<p>To conclude the iteration, some pairs on the stack are already merged, collapsing them in an insertion sort:</p>
<pre>        while let Some(r) = collapse(&amp;runs) {<br/>            let left = runs[r + 1];<br/>            let right = runs[r];<br/>            unsafe {<br/>                merge(&amp;mut v[left.start .. right.start + right.len], <br/>                      left.len, buf.as_mut_ptr(), &amp;mut is_less);<br/>            }<br/>            runs[r] = Run {<br/>                start: left.start,<br/>                len: left.len + right.len,<br/>            };<br/>            runs.remove(r + 1);<br/>        }<br/>    }</pre>
<p>This <kbd>collapse</kbd> loop ensures that there is only a single item left on the stack, which is the sorted sequence. Finding out which runs to collapse is the essential part of Timsort, since merging is simply done using insertion sort. The collapse function checks for two essential conditions:</p>
<ul>
<li>The lengths of the runs are in descending order (the top of the stack holds the longest run)</li>
<li>The length of each generated run is greater than the sum of the next two runs</li>
</ul>
<p class="mce-root"/>
<p>With this in mind, let's look at the collapse function:</p>
<pre>    // [...]<br/>    fn collapse(runs: &amp;[Run]) -&gt; Option&lt;usize&gt; {<br/>        let n = runs.len();<br/>        if n &gt;= 2 &amp;&amp; (runs[n - 1].start == 0 ||<br/>                      runs[n - 2].len &lt;= runs[n - 1].len ||<br/>                      (n &gt;= 3 &amp;&amp; runs[n - 3].len &lt;= <br/>                       runs[n - 2].len + runs[n - 1].len) ||<br/>                      (n &gt;= 4 &amp;&amp; runs[n - 4].len &lt;= <br/>                       runs[n - 3].len + runs[n - 2].len)) {<br/>            if n &gt;= 3 &amp;&amp; runs[n - 3].len &lt; runs[n - 1].len {<br/>                Some(n - 3)<br/>            } else {<br/>                Some(n - 2)<br/>            }<br/>        } else {<br/>            None<br/>        }<br/>    }<br/>    // [...]<br/>}</pre>
<p>It returns the index of the run that is to be merged with its successor (<kbd>r</kbd> and <kbd>r + 1</kbd>; refer to the <kbd>collapse</kbd> loop for more information). The collapse function checks the top four runs to satisfy the aforementioned <span>conditions</span> if the topmost run (at the highest index) does not start at the beginning. If it does, the end is almost reached and a merge is necessary, regardless of any conditions that are violated, thereby ensuring the final sequence to be merged last.</p>
<p>Timsort's combination of insertion sort and merge sort make it a really fast and efficient sorting algorithm that is also stable and operates on "blocks" by building these naturally occurring runs. Unstable sorting, on the other hand, uses a familiar Quicksort.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Unstable sorting</h1>
                </header>
            
            <article>
                
<p>Unstable sorting does not retain the relative position of equal values, and can therefore achieve better speeds thanks to the lack of additionally allocated memory that stable sorting requires. The slice's <kbd>sort_unstable()</kbd> function uses a Quicksort variation that is called a pattern-defeating Quicksort by Orson Peters, combining heap sort and Quicksort to achieve an excellent performance in most cases.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>The slice implementation simply refers to it as Quicksort:</p>
<pre>    pub fn sort_unstable_by&lt;F&gt;(&amp;mut self, mut compare: F)<br/>        where F: FnMut(&amp;T, &amp;T) -&gt; Ordering<br/>    {<br/>        sort::quicksort(self, |a, b| compare(a, b) == Ordering::Less);<br/>    }</pre>
<p>Looking at the Quicksort implementation, it spans the entire module—about 700 lines of code. Therefore, let's look at the highest level function to understand the basics; curious readers should dive into the source code (<a href="https://doc.rust-lang.org/src/core/slice/sort.rs.html">https://doc.rust-lang.org/src/core/slice/sort.rs.html</a>) to find out more.</p>
<p>The Quicksort function performs a few preliminary checks to rule out invalid cases:</p>
<pre class="rust">/// Sorts `v` using pattern-defeating quicksort, which is `O(n log n)` worst-case.<br/>pub fn quicksort&lt;T, F&gt;(v: &amp;mut [T], mut is_less: F)<br/>    where F: FnMut(&amp;T, &amp;T) -&gt; bool<br/>{<br/>    // Sorting has no meaningful behavior on zero-sized types.<br/>    if mem::size_of::&lt;T&gt;() == 0 {<br/>        return;<br/>    }<br/>    // Limit the number of imbalanced <br/>    // partitions to `floor(log2(len)) + 1`.<br/>    let limit = mem::size_of::&lt;usize&gt;() * 8 - v.len()<br/>                .leading_zeros() as usize;<br/><br/>    recurse(v, &amp;mut is_less, None, limit);<br/>}</pre>
<p>The <kbd>recurse</kbd> function is at the heart of this implementation and is even a recursive function:</p>
<pre>/// Sorts `v` recursively.<br/>///<br/>/// If the slice had a predecessor in the original array, <br/>/// it is specified as `pred`.<br/>///<br/>/// `limit` is the number of allowed imbalanced partitions <br/>///  before switching to `heapsort`. If zero,<br/>/// this function will immediately switch to heapsort.<br/>fn recurse&lt;'a, T, F&gt;(mut v: &amp;'a mut [T], is_less: &amp;mut F, mut pred: Option&lt;&amp;'a T&gt;, mut limit: usize)<br/>    where F: FnMut(&amp;T, &amp;T) -&gt; bool<br/>{<br/>    // Slices of up to this length get sorted using insertion sort.<br/>    const MAX_INSERTION: usize = 20;<br/><br/>    // True if the last partitioning was reasonably balanced.<br/>    let mut was_balanced = true;<br/>    // True if the last partitioning didn't shuffle elements <br/>    // (the slice was already partitioned).<br/>    let mut was_partitioned = true;<br/><br/>    loop {<br/>        let len = v.len();<br/>        // Very short slices get sorted using insertion sort.<br/>        if len &lt;= MAX_INSERTION {<br/>            insertion_sort(v, is_less);<br/>            return;<br/>        }<br/>        // If too many bad pivot choices were made, <br/>        // simply fall back to heapsort in order to<br/>        // guarantee `O(n log n)` worst-case.<br/>        if limit == 0 {<br/>            heapsort(v, is_less);<br/>            return;<br/>        }<br/>        // If the last partitioning was imbalanced, <br/>        // try breaking patterns in the slice by shuffling<br/>        // some elements around. <br/>        // Hopefully we'll choose a better pivot this time.<br/>        if !was_balanced {<br/>            break_patterns(v);<br/>            limit -= 1;<br/>        }<br/>        // Choose a pivot and try guessing <br/>        // whether the slice is already sorted.<br/>        let (pivot, likely_sorted) = choose_pivot(v, is_less);<br/><br/>        // If the last partitioning was decently balanced <br/>        // and didn't shuffle elements, and if pivot<br/>        // selection predicts the slice is likely already sorted...<br/>        if was_balanced &amp;&amp; was_partitioned &amp;&amp; likely_sorted {<br/>            // Try identifying several out-of-order elements <br/>            // and shifting them to correct<br/>            // positions. If the slice ends up being completely sorted, <br/>            // we're done.<br/>            if partial_insertion_sort(v, is_less) {<br/>                return;<br/>            }<br/>        }<br/>        // If the chosen pivot is equal to the predecessor, <br/>        // then it's the smallest element in the<br/>        // slice. Partition the slice into elements equal to and <br/>        // elements greater than the pivot.<br/>        // This case is usually hit when the slice contains many <br/>        // duplicate elements.<br/>        if let Some(p) = pred {<br/>            if !is_less(p, &amp;v[pivot]) {<br/>                let mid = partition_equal(v, pivot, is_less);<br/><br/>                // Continue sorting elements greater than the pivot.<br/>                v = &amp;mut {v}[mid..];<br/>                continue;<br/>            }<br/>        }<br/>        // Partition the slice.<br/>        let (mid, was_p) = partition(v, pivot, is_less);<br/>        was_balanced = cmp::min(mid, len - mid) &gt;= len / 8;<br/>        was_partitioned = was_p;<br/><br/>        // Split the slice into `left`, `pivot`, and `right`.<br/>        let (left, right) = {v}.split_at_mut(mid);<br/>        let (pivot, right) = right.split_at_mut(1);<br/>        let pivot = &amp;pivot[0];<br/><br/>        // Recurse into the shorter side only in order to <br/>        // minimize the total number of recursive<br/>        // calls and consume less stack space. <br/>        // Then just continue with the longer side (this is<br/>        // akin to tail recursion).<br/>        if left.len() &lt; right.len() {<br/>            recurse(left, is_less, pred, limit);<br/>            v = right;<br/>            pred = Some(pivot);<br/>        } else {<br/>            recurse(right, is_less, Some(pivot), limit);<br/>            v = left;<br/>        }<br/>    }<br/>}</pre>
<p>Thankfully, the standard library's source has many helpful comments. Therefore, it's highly recommended to read through all the comments in the preceding snippet. In short, the algorithms make a lot of guesses to avoid making a bad choice for the pivot. If you recall, when Quicksort chooses a bad pivot element, it will split into uneven partitions, thereby creating very bad runtime behavior. Therefore, choosing a good pivot is critical, which is why so many heuristics around that process are employed and, if all else fails, the algorithm runs heap sort to at least have <em>O(n log n)</em> runtime complexity.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>Rust's standard library includes several implementations for basic things such as sorting or searching on its primitive slice <span>type</span> and the <kbd>Iterator&lt;T&gt;</kbd> trait. The slice type in particular has many highly important functions to offer.</p>
<p><kbd>binary_search()</kbd> is a generic implementation of the binary search concepts provided on the slice type. <kbd>Vec&lt;T&gt;</kbd> can be quickly and easily (and implicitly) converted into a slice, making this a universally available function. However, it requires a sorting order to be present in the slice to work (and it won't fail if it's not) and, if custom types are used, an implementation of the <kbd>Ord</kbd> trait.</p>
<p>In case the slice cannot be sorted beforehand, the <kbd>Iterator&lt;T&gt;</kbd> variable's implementation of <kbd>position()</kbd> (of <kbd>find()</kbd>) provides a basic linear search that returns the first position of the element.</p>
<p>Sorting is provided in a generic function, but comes in two flavors: stable and unstable. The regular <kbd>sort()</kbd> function uses a merge sort variation called Timsort to achieve an efficient and stable sorting performance.</p>
<p class="mce-root"><kbd>sort_unstable()</kbd> utilizes a pattern-defeating Quicksort to combine the efficiency of heap sort and Quicksort in a smart way, which typically leads to a better absolute runtime than <kbd>sort()</kbd>.</p>
<p>This was the final chapter of this book and, if you made it to here, you finally deserve some answers! You can find the answers to all of the questions that have been asked in the <em>Assessments</em> section.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Questions</h1>
                </header>
            
            <article>
                
<ul>
<li>Where is Rust's implementation of generic algorithms on collections?</li>
<li>When is a linear search better than a binary search?</li>
<li><em>Potential job interview question:</em> What are stable and unstable sorting algorithms?</li>
<li>What is a bad behavior exhibited by Quicksort that pattern-defeating Quicksort mitigates?</li>
</ul>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Further reading</h1>
                </header>
            
            <article>
                
<p><span>Here is some additional reference material that you may refer to regarding what has been covered in this chapter:</span></p>
<ul>
<li><em><span>D</span></em><span><em>esign Patterns</em>, by</span> <span>Erich Gamma</span><span>,</span> <span>Richard Helm,</span> <span>Ralph Johnson</span><span>, and</span> <span>John Vlissides</span></li>
<li>Iterator pattern on Wikipedia (<a href="https://en.wikipedia.org/wiki/Iterator_pattern">https://en.wikipedia.org/wiki/Iterator_pattern</a>)</li>
<li><em>OpenJDK's java.utils.Collection.sort() is broken: The good, the bad and the worst case</em>, by de Gow et al. (<a href="http://envisage-project.eu/wp-content/uploads/2015/02/sorting.pdf">http://envisage-project.eu/wp-content/uploads/2015/02/sorting.pdf</a>)</li>
<li>Pattern-defeating Quicksort (<a href="http://envisage-project.eu/wp-content/uploads/2015/02/sorting.pdf">http://envisage-project.eu/wp-content/uploads/2015/02/sorting.pdf</a>)</li>
</ul>


            </article>

            
        </section>
    </body></html>