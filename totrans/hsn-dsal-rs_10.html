<html><head></head><body>
        

                            
                    <h1 class="header-title">Finding Stuff</h1>
                
            
            
                
<p>The issue with searching for <em>something</em> is always directly related to the space in which you are searching. You will certainly have experienced looking for your keys in your house: the search space contains anything from jackets worn the previous day to the sock drawer into which the key might have slipped the last time you did the washing. Upon finding the item (and after a lot of wasted time spent running up and down stairs and searching in various rooms), you then swear to keep things tidier in the future....</p>
<p>We have encountered this issue more often than we are comfortable with admitting, but it illustrates a fundamental issue that we can solve algorithmically without any particular order to build on. In this chapter, we'll explore how to do the following:</p>
<ul>
<li>Finding items in an unordered array of chaos</li>
<li>Making a trade-off between preparation and search</li>
</ul>


            

            
        
    

        

                            
                    <h1 class="header-title">Finding the best</h1>
                
            
            
                
<p>The search domain is present on various levels of abstraction: finding a word in a body of text is typically more complex than simply calling the <kbd>contains()</kbd> function, and if there are several results, which is the one that was searched for? This entire class of problem is summed up under the umbrella of <strong>information retrieval</strong>, where problems of ranking, indexing, understanding, storing, and searching are solved in order to retrieve the optimum result (for all definitions). This chapter focuses only on the latter part, where we actually look through a collection of items (for example, an index) in order to find a match.</p>
<p class="mce-root">This means that we will compare items directly (<em>a == b</em>) to determine closeness, rather than using something such as a distance - or locally-sensitive hashing function. These can be found in more specific domains such as a fuzzy search or matching bodies of text, which is a field of its own. To learn more about hashing, please check out <a href="95653045-6e1c-4ef7-bd0c-8e45b1ccfa1d.xhtml"/><a href="95653045-6e1c-4ef7-bd0c-8e45b1ccfa1d.xhtml"/><a href="95653045-6e1c-4ef7-bd0c-8e45b1ccfa1d.xhtml">Chapter 6</a>, <em>Exploring Maps and Sets</em> or the <em>Further reading</em> section in this chapter.</p>
<p>Starting off with the most naive implementation, let's look at linear searches.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Linear searches</h1>
                
            
            
                
<p>Linear searching is a fancy name for something that we do in almost every program and our everyday lives: going through a collection of items to find the first match. There is no need for any preprocessing or similar steps; the collection can be used as-is, which means that standard libraries commonly provide a generic implementation already. In Rust's case, the iterator trait offers this feature with functions called <kbd>position()</kbd> (or <kbd>rposition()</kbd>), <kbd>find()</kbd>, <kbd>filter()</kbd>, or even <kbd>any()</kbd>. <kbd>fold()</kbd> can also be used to find the thing you are looking for. The following is a diagram of the process:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/b0e2e878-c1f8-48ee-a94f-b4222c8b5f1f.png" style="width:23.58em;height:7.75em;"/></p>
<p>Fundamentally, however, it's a loop over each item that either exits or collects all items where a predicate (an evaluation function that takes in an item of a type to return a Boolean value) matches:</p>
<pre>pub fn linear_search&lt;T: Eq + Clone&gt;(haystack: &amp;[T], needle: &amp;T) -&gt; Option&lt;usize&gt; {<br/>    for (i, h) in haystack.iter().enumerate() {<br/>        if h.eq(needle) {<br/>            return Some(i);<br/>        }<br/>    }<br/>    None<br/>}</pre>
<p>This algorithm obviously exhibits <em>O(n)</em> runtime complexity, growing with the collection size. Iterating over 10,000 items will take a while, even if the predicate executes quickly, so how can this strategy be improved?</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Jump search</h1>
                
            
            
                
<p>Going linearly over a collection one-by-one is only efficient if you are already close to a potential match, but it is very hard to determineâ€”what does <em>close to a match</em> mean? In unordered collections, this is indeed impossible to know this since any item can follow. Consequently, what about sorting the collection first? As discussed in <a href="a9ba9f9e-59a2-411f-8998-831fe4e69266.xhtml"/><a href="a9ba9f9e-59a2-411f-8998-831fe4e69266.xhtml">Chapter 9</a>, <em>Ordering Things</em>, sorting at quasi-linear runtime complexity can be significantly faster than going over each item of a long collection past a certain size.</p>
<p>A jump search makes use of knowing about the range it jumps over, not unlike a skip list:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/bb372dc5-b290-4553-92cf-5d71d9621ef3.png" style="width:17.83em;height:13.50em;"/></p>
<p>After sorting, a search can be significantly faster and a number of elements can be skipped in order to search in a linear fashion once the algorithm is close to a match. How many elements can be skipped at each jump? This is something to be tested, but first here is the code that does the work:</p>
<pre class="mce-root">pub fn jump_search&lt;T: Eq + PartialOrd + Clone&gt;(<br/>    haystack: &amp;[T],<br/>    needle: &amp;T,<br/>    jump_size: usize,<br/>) -&gt; Option&lt;usize&gt; {<br/>    if jump_size &lt; haystack.len() {<br/>        let mut i = 0;<br/>        while i &lt; haystack.len() - 1 {<br/>            if i + jump_size &lt; haystack.len() {<br/>                i += jump_size<br/>            } else {<br/>                i = haystack.len() - 1;<br/>            }<br/>            if &amp;haystack[i] == needle {<br/>                return Some(i);<br/>            } else if &amp;haystack[i] &gt; needle {<br/>                return linear_search(&amp;haystack[<br/>                                    (i - jump_size)..i], needle);<br/>            }<br/>        }<br/>    }<br/>    None<br/>}</pre>
<p class="mce-root">The API expects a pre-sorted slice, which means that sorting, strictly speaking, is not part of the algorithm's runtime. Without the sorting, the runtime complexity might be something around <em>O(n / k + k)</em>, with k being the step size, which can be reduced to <em>O(n)</em> in a worst-case scenario.</p>
<p>Including the sorting mechanism, the sorting algorithm will trump the search's runtime complexity easily, raising it to <em>O(n log n)</em>. While various choices for the jumps can improve the absolute runtime of this search algorithm by a significant amount, it will not perform as well as something like a tree structure. Binary searching as a strategy achieves that nicely, however.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Binary searching</h1>
                
            
            
                
<p>Binary trees greatly reduce the number of comparison operations by creating branches from the collection, just like a binary tree would. This creates a tree on-the-fly, resulting in superior search performance. The significance is predictability, which allows us to build the tree and provides the options for what branch the algorithm can expect the result in.</p>
<p>A binary search, just like a jump search, requires the incoming slice to be ordered for it to work. Then the algorithm splits the array in half and chooses the side that will most likely contain the item. Once there are two collections, the behavior is very similar to that of a binary tree walk, as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/3a76371f-cf74-4e75-915c-3c4793b9bf10.png" style="width:15.83em;height:26.00em;"/></p>
<p>Again, given that the sorting effort trumps the algorithm's runtime complexity, it's that of the sorting algorithm that will be considered the outcome: <em>O(n log n)</em>. However, we should also be interested in the real performance, if the collection is already sorted; it's significantly lower! First, let's look at some code to make this easier to understand:</p>
<pre>pub fn binary_search&lt;T: Eq + PartialOrd&gt;(<br/>    haystack: &amp;[T],<br/>    needle: &amp;T,<br/>) -&gt; Option&lt;usize&gt; {<br/>    let (mut left, mut right) = (0, haystack.len() - 1);<br/>    while left &lt;= right {<br/>        let pivot = left + (right - left) / 2;<br/>        if needle &lt; &amp;haystack[pivot] {<br/>            right = pivot - 1;<br/>        } else if needle &gt; &amp;haystack[pivot] {<br/>            left = pivot + 1;<br/>        } else {<br/>            return Some(pivot); // lucky find<br/>        }<br/>    }<br/>    None<br/>}</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p>While the recursive implementation of the algorithm would have worked too, though it is not significantly shorter it harbors the risk of a stack overflow, hence the iterative approach.</p>
<p>After choosing a pivot (center) element, the algorithm has to determine the collection for the next iteration by one of the following three scenarios:</p>
<ul>
<li>The left part containing smaller values</li>
<li>The right chunk with larger values</li>
<li>Not at all; the pivot element is the result too</li>
</ul>
<p>This tree-like behavior allows for a great runtime complexity of <em>O(log n)</em>, since the number of items searched keeps halving until the desired element has been found. However, how does all this compare?</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Wrap up</h1>
                
            
            
                
<p>The three approaches differ somewhat, with the binary search being the established state-of-the-art type algorithm. In fact, it can be used on any Rust slices (if they are sorted, of course) and used to find whatever is required.</p>
<p>Comparing these algorithms is tricky: a linear search works well on unordered datasets and is the only way to search those if sorting is not an option. If sorting is an option, then a binary search is faster by a large margin (<kbd>asc</kbd> is the sorting direction: ascending):</p>
<pre><strong>test tests::bench_binary_search_10k_asc ... bench: 80 ns/iter (+/- 32)</strong><br/><strong>test tests::bench_binary_search_1k_asc ... bench: 63 ns/iter (+/- 17)</strong><br/><strong>test tests::bench_binary_search_5k_asc ... bench: 86 ns/iter (+/- 28)</strong><br/><strong>test tests::bench_jump_search_10k_asc ... bench: 707 ns/iter (+/- 160)</strong><br/><strong>test tests::bench_jump_search_1k_asc ... bench: 92 ns/iter (+/- 10)</strong><br/><strong>test tests::bench_jump_search_5k_asc ... bench: 355 ns/iter (+/- 46)</strong><br/><strong>test tests::bench_linear_search_10k_asc ... bench: 2,046 ns/iter (+/- 352)</strong><br/><strong>test tests::bench_linear_search_1k_asc ... bench: 218 ns/iter (+/- 22)</strong><br/><strong>test tests::bench_linear_search_5k_asc ... bench: 1,076 ns/iter (+/- 527)</strong><br/><strong>test tests::bench_std_binary_search_10k_asc ... bench: 93 ns/iter (+/- 10)</strong><br/><strong>test tests::bench_std_binary_search_1k_asc ... bench: 62 ns/iter (+/- 7)</strong><br/><strong>test tests::bench_std_binary_search_5k_asc ... bench: 89 ns/iter (+/- 27)</strong></pre>
<p class="mce-root">When plotted, the difference is clearly visible, with the linear search showing its linear characteristics. Taking the absolute runtime out of the game will show the runtime complexity as well, as demonstrated in the following chart:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/25c07135-7660-498b-8709-5bfab286bfee.png"/></p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>This chart shows the relative behavior of each algorithm in order to show its runtime complexities: a binary search with <em>O(log n)</em>, a linear search with <em>O(n)</em>, and a jump search, which is almost linear because of the parameter choice (the jump size is one-third of the length of the array):</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/4ab2b266-cb10-45c6-b21a-adbece5d85bd.png"/></p>
<p>And that is itâ€”a short introduction to search algorithms. Typically, it's more about the data, and having some way to sort beforehand creates a powerful opportunity to quickly find the item you are looking for.</p>
<p class="mce-root"/>
<p class="mce-root"/>


            

            
        
    

        

                            
                    <h1 class="header-title">Summary</h1>
                
            
            
                
<p>Search, as a part of the information retrieval (among others) process, is an elementary way of finding something independently of the data structure being used. There are three popular types of algorithm: linear search, jump search, and binary search. Completely different approaches (such as locally-sensitive hashing) have been discussed in an earlier chapter about maps and sets, but they still need a mechanism to compare quickly.</p>
<p>A linear search is the least complex approach: iterate over a collection and compare the items with the element that is to be found. This has also been implemented in Rust's iterator and exhibits <em>O(n)</em> runtime complexity.</p>
<p>Jump searches are superior. By operating on a sorted collection, they can use a step size that is greater than 1 (like a linear search) in order to skip to the required parts faster by checking whether the relevant section has already passed. While faster in absolute terms, the worst-case runtime complexity is still <em>O(n)</em>.</p>
<p>The (at the time of writing) fastest approach is a binary search, which also operates on a sorted collection and repeatedly splits the desired sections in half to work with a tree-like strategy. In fact, the runtime complexity of the algorithm itself is <em>O(log n)</em> as well.</p>
<p>In the next chapter, we will explore some more exotic algorithms: backtracking, random number generation, and more!</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Questions</h1>
                
            
            
                
<ol>
<li>What is information retrieval?</li>
<li>Do modern search engines and databases use simple search algorithms?</li>
<li>Why do linear searches have <em>O(n)</em> runtime complexity?</li>
<li>What does a jump search do better than a linear search?</li>
<li>What is a binary search and why is it comparable to a tree?</li>
</ol>


            

            
        
    

        

                            
                    <h1 class="header-title">Further reading</h1>
                
            
            
                
<p>Here is some additional reference material that you may refer to regarding what has been covered in this chapter: <a href="https://www.aaai.org/ocs/index.php/AAAI/AAAI14/paper/view/8357">https://www.aaai.org/ocs/index.php/AAAI/AAAI14/paper/view/8357/8643</a>.</p>


            

            
        
    </body></html>